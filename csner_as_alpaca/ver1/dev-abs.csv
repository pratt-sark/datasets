instruction,input,output,text
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","This paper describes an approach to the treatment of nominal compounds in a machine translation project employing a modern unification-based system . General problems connected with the analysis of compounds are briefly reviewed , and the project , for the automatic translation of Swiss avalanche bulletins , is introduced . Avalanche bulletins deal with a limited semantic domain and employ a sublanguage in which nominal compounds occur frequently . These and other properties of the texts affect the treatment of compounds , permitting certain simplifications , while leaving a number of possible alternative analyses . We discuss the different problems involving the translation of compounds between German and French , and show how the computational environment in use permits two different approaches to the problem : an interlingua-based approach and a transfer-based approach . Finally , wc evaluate these approaches with respect to linguistic and computational considerations applicable in a MT-system dealing with a limited semantic domain and describe the solution that has actually been implemented .",machine translation : RESEARCH_PROBLEM; unification-based : METHOD; translation : RESEARCH_PROBLEM; translation : RESEARCH_PROBLEM; interlingua-based : METHOD; transfer-based : METHOD; MT-system : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: This paper describes an approach to the treatment of nominal compounds in a machine translation project employing a modern unification-based system . General problems connected with the analysis of compounds are briefly reviewed , and the project , for the automatic translation of Swiss avalanche bulletins , is introduced . Avalanche bulletins deal with a limited semantic domain and employ a sublanguage in which nominal compounds occur frequently . These and other properties of the texts affect the treatment of compounds , permitting certain simplifications , while leaving a number of possible alternative analyses . We discuss the different problems involving the translation of compounds between German and French , and show how the computational environment in use permits two different approaches to the problem : an interlingua-based approach and a transfer-based approach . Finally , wc evaluate these approaches with respect to linguistic and computational considerations applicable in a MT-system dealing with a limited semantic domain and describe the solution that has actually been implemented . ### Response: machine translation : RESEARCH_PROBLEM; unification-based : METHOD; translation : RESEARCH_PROBLEM; translation : RESEARCH_PROBLEM; interlingua-based : METHOD; transfer-based : METHOD; MT-system : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Text corpora which are tagged with part-of-speech information are useful in many areas of linguistic research . In this paper , a new part-of-speech tagging method hased on neural networks -LRB- Net-Tagger -RRB- is presented and its performance is compared to that of a llMM-tagger -LRB- Cutting et al. , 1992 -RRB- and a trigrambased tagger -LRB- Kempe , 1993 -RRB- . It is shown that the Net-Tagger performs as well as the trigram-based tagger and better than the iIMM-tagger .",part-of-speech : RESEARCH_PROBLEM; part-of-speech tagging : RESEARCH_PROBLEM; neural networks : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Text corpora which are tagged with part-of-speech information are useful in many areas of linguistic research . In this paper , a new part-of-speech tagging method hased on neural networks -LRB- Net-Tagger -RRB- is presented and its performance is compared to that of a llMM-tagger -LRB- Cutting et al. , 1992 -RRB- and a trigrambased tagger -LRB- Kempe , 1993 -RRB- . It is shown that the Net-Tagger performs as well as the trigram-based tagger and better than the iIMM-tagger . ### Response: part-of-speech : RESEARCH_PROBLEM; part-of-speech tagging : RESEARCH_PROBLEM; neural networks : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","This paper describes a program for handling `` scope ambiguities '' in individual English sentences . The program operates on initial logical translations , generated by a parser\/translator , in which `` unscoped elements '' such as quantifiers , coordinators and negation are left in place to be extracted and positioned by the scoping program . The program produces the set of valid scoped readings , omitting logically redundant readings , and places the readings in an approximate order of preference using a set of domain-independent heuristics . The heuristics are based on information about the lexical type of each operator and on `` structural relations '' between pairs of operators . The need for such domain-independent heuristics is emphasized ; in some cases they can be decisive and in general they will serve as a guide to the use of further heuristics based on domain-specific knowledge and on the context of discourse . The emphasis of this paper is on discussing several of the more problematic aspects of the scoping protocol which wcre encountered during the design of the scoping program .",scope ambiguities : RESEARCH_PROBLEM; logical translations : METHOD; scoping : RESEARCH_PROBLEM; domain-independent heuristics : METHOD; lexical type : METHOD; structural relations : METHOD; domain-independent heuristics : METHOD; scoping : RESEARCH_PROBLEM; scoping : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: This paper describes a program for handling `` scope ambiguities '' in individual English sentences . The program operates on initial logical translations , generated by a parser\/translator , in which `` unscoped elements '' such as quantifiers , coordinators and negation are left in place to be extracted and positioned by the scoping program . The program produces the set of valid scoped readings , omitting logically redundant readings , and places the readings in an approximate order of preference using a set of domain-independent heuristics . The heuristics are based on information about the lexical type of each operator and on `` structural relations '' between pairs of operators . The need for such domain-independent heuristics is emphasized ; in some cases they can be decisive and in general they will serve as a guide to the use of further heuristics based on domain-specific knowledge and on the context of discourse . The emphasis of this paper is on discussing several of the more problematic aspects of the scoping protocol which wcre encountered during the design of the scoping program . ### Response: scope ambiguities : RESEARCH_PROBLEM; logical translations : METHOD; scoping : RESEARCH_PROBLEM; domain-independent heuristics : METHOD; lexical type : METHOD; structural relations : METHOD; domain-independent heuristics : METHOD; scoping : RESEARCH_PROBLEM; scoping : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET",This paper presents a new active learning paradigm which considers not only the uncertainty of the classifier but also the diversity of the corpus . The two measures for uncertainty and diversity were combined using the MMR -LRB- Maximal Marginal Relevance -RRB- method to give the sampling scores in our active learning strategy . We incorporated MMR-based active machinelearning idea into the biomedical namedentity recognition system . Our experimental results indicated that our strategies for active-learning based sample selection could significantly reduce the human effort .,active learning : METHOD; MMR : METHOD; Maximal Marginal Relevance : METHOD; active learning : METHOD; MMR-based active machinelearning : METHOD; biomedical namedentity recognition : RESEARCH_PROBLEM; active-learning : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: This paper presents a new active learning paradigm which considers not only the uncertainty of the classifier but also the diversity of the corpus . The two measures for uncertainty and diversity were combined using the MMR -LRB- Maximal Marginal Relevance -RRB- method to give the sampling scores in our active learning strategy . We incorporated MMR-based active machinelearning idea into the biomedical namedentity recognition system . Our experimental results indicated that our strategies for active-learning based sample selection could significantly reduce the human effort . ### Response: active learning : METHOD; MMR : METHOD; Maximal Marginal Relevance : METHOD; active learning : METHOD; MMR-based active machinelearning : METHOD; biomedical namedentity recognition : RESEARCH_PROBLEM; active-learning : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Partial parsing techniques try to recover syntactic information e?ciently and reliably by sacrificing completeness and depth of analysis . One of the di?culties of partial parsing is finding a means to extract the grammar involved automatically . In this paper , we present a method for automatically extracting partial parsing rules from a tree-annotated corpus using decision tree induction . We define the partial parsing rules as those that can decide the structure of a substring in an input sentence deterministically . This decision can be considered as a classification ; as such , for a substring in an input sentence , a proper structure is chosen among the structures occurred in the corpus . For the classification , we use decision tree induction , and induce partial parsing rules from the decision tree . The acquired grammar is similar to a phrase structure grammar , with contextual and lexical information , but it allows building structures of depth one or more . Our experiments showed that the proposed partial parser using the automatically extracted rules is not only accurate and e?cient , but also achieves reasonable coverage for Korean .",Partial parsing : RESEARCH_PROBLEM; partial parsing : RESEARCH_PROBLEM; partial parsing rules : RESEARCH_PROBLEM; decision tree : METHOD; partial parsing rules : RESEARCH_PROBLEM; classification : METHOD; decision tree : METHOD; partial parsing rules : RESEARCH_PROBLEM; decision tree : METHOD; partial parser : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Partial parsing techniques try to recover syntactic information e?ciently and reliably by sacrificing completeness and depth of analysis . One of the di?culties of partial parsing is finding a means to extract the grammar involved automatically . In this paper , we present a method for automatically extracting partial parsing rules from a tree-annotated corpus using decision tree induction . We define the partial parsing rules as those that can decide the structure of a substring in an input sentence deterministically . This decision can be considered as a classification ; as such , for a substring in an input sentence , a proper structure is chosen among the structures occurred in the corpus . For the classification , we use decision tree induction , and induce partial parsing rules from the decision tree . The acquired grammar is similar to a phrase structure grammar , with contextual and lexical information , but it allows building structures of depth one or more . Our experiments showed that the proposed partial parser using the automatically extracted rules is not only accurate and e?cient , but also achieves reasonable coverage for Korean . ### Response: Partial parsing : RESEARCH_PROBLEM; partial parsing : RESEARCH_PROBLEM; partial parsing rules : RESEARCH_PROBLEM; decision tree : METHOD; partial parsing rules : RESEARCH_PROBLEM; classification : METHOD; decision tree : METHOD; partial parsing rules : RESEARCH_PROBLEM; decision tree : METHOD; partial parser : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Grammatical relationships are an important level of natural language processing . We present a trainable approach to find these relationships through transformation sequences and-error-driven learning . Our approach finds grammatical relationships between core syntax groups and bypasses much of the parsing phase . On our training and test set , our procedure achieves 63.6 % recall and 77.3 % precision -LRB- f-score = 69.8 -RRB- .",Grammatical relationships : RESEARCH_PROBLEM; transformation sequences and-error-driven learning : METHOD; grammatical relationships : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Grammatical relationships are an important level of natural language processing . We present a trainable approach to find these relationships through transformation sequences and-error-driven learning . Our approach finds grammatical relationships between core syntax groups and bypasses much of the parsing phase . On our training and test set , our procedure achieves 63.6 % recall and 77.3 % precision -LRB- f-score = 69.8 -RRB- . ### Response: Grammatical relationships : RESEARCH_PROBLEM; transformation sequences and-error-driven learning : METHOD; grammatical relationships : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET",The main aim of this paper is to analyze the e # 0Bects of applying pronominal anaphora resolution to Question Answering # 28QA # 29 systems . For this task a complete QA system has been implemented . System evaluation measures performance improvements obtained when information that is referenced anaphorically in documents is not ignored .,pronominal anaphora resolution : METHOD; Question Answering : RESEARCH_PROBLEM; QA : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: The main aim of this paper is to analyze the e # 0Bects of applying pronominal anaphora resolution to Question Answering # 28QA # 29 systems . For this task a complete QA system has been implemented . System evaluation measures performance improvements obtained when information that is referenced anaphorically in documents is not ignored . ### Response: pronominal anaphora resolution : METHOD; Question Answering : RESEARCH_PROBLEM; QA : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","This paper presents a set of tools and methods for acquiring , manipulating , and analyzing machinereadable dictionaries . We give several detailed examples of the use of these tools and methods for particular analyses . A novel aspect of our work is that it allows the combined processing of multiple machine-readable dictionaries . Our examples describe analyses of data from Webster 's Seventh Collegiate Dictionary , the Longman Dictionary of Contemporary English , the Collins bilingual dictionaries , the Collins Thesaurus , and the Zingarelli Italian dictionary . We describe existing facilities and results they have produced as well as planned enhancements to those facilities , particularly in the area of managing associations involving the senses of polysemous words . We show how these enhancements expand the ways in which we can exploit machine-readable dictionaries in the construction of large lexicons for natural language processing systems .",machinereadable dictionaries : RESEARCH_PROBLEM; machine-readable dictionaries : RESEARCH_PROBLEM; senses of polysemous words : METHOD; machine-readable dictionaries : RESEARCH_PROBLEM; lexicons : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: This paper presents a set of tools and methods for acquiring , manipulating , and analyzing machinereadable dictionaries . We give several detailed examples of the use of these tools and methods for particular analyses . A novel aspect of our work is that it allows the combined processing of multiple machine-readable dictionaries . Our examples describe analyses of data from Webster 's Seventh Collegiate Dictionary , the Longman Dictionary of Contemporary English , the Collins bilingual dictionaries , the Collins Thesaurus , and the Zingarelli Italian dictionary . We describe existing facilities and results they have produced as well as planned enhancements to those facilities , particularly in the area of managing associations involving the senses of polysemous words . We show how these enhancements expand the ways in which we can exploit machine-readable dictionaries in the construction of large lexicons for natural language processing systems . ### Response: machinereadable dictionaries : RESEARCH_PROBLEM; machine-readable dictionaries : RESEARCH_PROBLEM; senses of polysemous words : METHOD; machine-readable dictionaries : RESEARCH_PROBLEM; lexicons : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Anaphora resolution has proven to be a very difficult problem ; it requires the integrated application of syntactic , semantic , and pragmatic knowledge . This paper examines the hypothesis that instead of attempting to construct a monolithic method for resolving anaphora , the combination of multiple strategies , each exploiting a different knowledge source , proves more effective , theoretically and computationally . Cognitive plausibility is established in that human judgements of the optimal anaphoric referent accord with those of the strategy-based method , and human inability to determine a unique referent corresponds to the cases where different strategies offer conflicting candidates for the anaphoric referent .",Anaphora resolution : RESEARCH_PROBLEM; resolving anaphora : RESEARCH_PROBLEM; multiple strategies : METHOD; strategy-based : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Anaphora resolution has proven to be a very difficult problem ; it requires the integrated application of syntactic , semantic , and pragmatic knowledge . This paper examines the hypothesis that instead of attempting to construct a monolithic method for resolving anaphora , the combination of multiple strategies , each exploiting a different knowledge source , proves more effective , theoretically and computationally . Cognitive plausibility is established in that human judgements of the optimal anaphoric referent accord with those of the strategy-based method , and human inability to determine a unique referent corresponds to the cases where different strategies offer conflicting candidates for the anaphoric referent . ### Response: Anaphora resolution : RESEARCH_PROBLEM; resolving anaphora : RESEARCH_PROBLEM; multiple strategies : METHOD; strategy-based : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","This paper describes ETK -LRB- Ensemble of Transformation-based Keys -RRB- a new algorithm for inducing search keys for name filtering . ETK has the low computational cost and ability to filter by phonetic similarity characteristic of phonetic keys such as Soundex , but is adaptable to alternative similarity models . The accuracy of ETK in a preliminary empirical evaluation suggests that it is well-suited for phonetic filtering applications such as recognizing alternative cross-lingual transliterations .",ETK : METHOD; Ensemble of Transformation-based Keys : METHOD; search keys for name filtering : RESEARCH_PROBLEM; ETK : METHOD; filter : RESEARCH_PROBLEM; phonetic similarity : METHOD; ETK : METHOD; filtering : RESEARCH_PROBLEM; cross-lingual transliterations : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: This paper describes ETK -LRB- Ensemble of Transformation-based Keys -RRB- a new algorithm for inducing search keys for name filtering . ETK has the low computational cost and ability to filter by phonetic similarity characteristic of phonetic keys such as Soundex , but is adaptable to alternative similarity models . The accuracy of ETK in a preliminary empirical evaluation suggests that it is well-suited for phonetic filtering applications such as recognizing alternative cross-lingual transliterations . ### Response: ETK : METHOD; Ensemble of Transformation-based Keys : METHOD; search keys for name filtering : RESEARCH_PROBLEM; ETK : METHOD; filter : RESEARCH_PROBLEM; phonetic similarity : METHOD; ETK : METHOD; filtering : RESEARCH_PROBLEM; cross-lingual transliterations : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","For Information Retrieval , users are more concerned about the precision of top ranking documents in most practical situations . In this paper , we propose a method to improve the precision of top N ranking documents by reordering the retrieved documents from the initial retrieval . To reorder documents , we first automatically extract Global Key Terms from document set , then use extracted Global Key Terms to identify Local Key Terms in a single document or query topic , finally we make use of Local Key Terms in query and documents to reorder the initial ranking documents . The experiment with NTCIR3 CLIR dataset shows that an average 10 % -11 % improvement and 2 % -5 % improvement in precision can be achieved at top 10 and 100 ranking documents level respectively .",Information Retrieval : RESEARCH_PROBLEM; ranking documents : RESEARCH_PROBLEM; Global Key Terms : METHOD; Global Key Terms : METHOD; Local Key Terms : METHOD; Local Key Terms : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: For Information Retrieval , users are more concerned about the precision of top ranking documents in most practical situations . In this paper , we propose a method to improve the precision of top N ranking documents by reordering the retrieved documents from the initial retrieval . To reorder documents , we first automatically extract Global Key Terms from document set , then use extracted Global Key Terms to identify Local Key Terms in a single document or query topic , finally we make use of Local Key Terms in query and documents to reorder the initial ranking documents . The experiment with NTCIR3 CLIR dataset shows that an average 10 % -11 % improvement and 2 % -5 % improvement in precision can be achieved at top 10 and 100 ranking documents level respectively . ### Response: Information Retrieval : RESEARCH_PROBLEM; ranking documents : RESEARCH_PROBLEM; Global Key Terms : METHOD; Global Key Terms : METHOD; Local Key Terms : METHOD; Local Key Terms : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Data sparsity is one of the main factors that make word sense disambiguation -LRB- WSD -RRB- difficult . To overcome this problem we need to find effective ways to use resources other than sense labeled data . In this paper I describe a WSD system that uses a statistical language model based on a large unannotated corpus . The model is used to evaluate the likelihood of various substitutes for a word in a given context . These likelihoods are then used to determine the best sense for the word in novel contexts . The resulting system participated in three tasks in the SemEval 2007 workshop . The WSD of prepositions task proved to be challenging for the system , possibly illustrating some of its limitations : e.g. not all words have good substitutes . The system achieved promising results for the English lexical sample and English lexical substitution tasks .",word sense disambiguation : RESEARCH_PROBLEM; WSD : RESEARCH_PROBLEM; WSD : RESEARCH_PROBLEM; statistical language model : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Data sparsity is one of the main factors that make word sense disambiguation -LRB- WSD -RRB- difficult . To overcome this problem we need to find effective ways to use resources other than sense labeled data . In this paper I describe a WSD system that uses a statistical language model based on a large unannotated corpus . The model is used to evaluate the likelihood of various substitutes for a word in a given context . These likelihoods are then used to determine the best sense for the word in novel contexts . The resulting system participated in three tasks in the SemEval 2007 workshop . The WSD of prepositions task proved to be challenging for the system , possibly illustrating some of its limitations : e.g. not all words have good substitutes . The system achieved promising results for the English lexical sample and English lexical substitution tasks . ### Response: word sense disambiguation : RESEARCH_PROBLEM; WSD : RESEARCH_PROBLEM; WSD : RESEARCH_PROBLEM; statistical language model : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","This paper describes a syntactic representation for modeling speech repairs . This representation makes use of a right corner transform of syntax trees to produce a tree representation in which speech repairs require very few special syntax rules , making better use of training data . PCFGs trained on syntax trees using this model achieve high accuracy on the standard Switchboard parsing task .",syntactic representation : METHOD; speech repairs : RESEARCH_PROBLEM; syntax trees : METHOD; speech repairs : RESEARCH_PROBLEM; syntax rules : METHOD; PCFGs : METHOD; syntax trees : METHOD; parsing : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: This paper describes a syntactic representation for modeling speech repairs . This representation makes use of a right corner transform of syntax trees to produce a tree representation in which speech repairs require very few special syntax rules , making better use of training data . PCFGs trained on syntax trees using this model achieve high accuracy on the standard Switchboard parsing task . ### Response: syntactic representation : METHOD; speech repairs : RESEARCH_PROBLEM; syntax trees : METHOD; speech repairs : RESEARCH_PROBLEM; syntax rules : METHOD; PCFGs : METHOD; syntax trees : METHOD; parsing : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","We discuss Image Sense Discrimination -LRB- ISD -RRB- , and apply a method based on spectral clustering , using multimodal features from the image and text of the embedding web page . We evaluate our method on a new data set of annotated web images , retrieved with ambiguous query terms . Experiments investigate different levels of sense granularity , as well as the impact of text and image features , and global versus local text features .",Image Sense Discrimination : RESEARCH_PROBLEM; ISD : RESEARCH_PROBLEM; spectral clustering : METHOD; multimodal features : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: We discuss Image Sense Discrimination -LRB- ISD -RRB- , and apply a method based on spectral clustering , using multimodal features from the image and text of the embedding web page . We evaluate our method on a new data set of annotated web images , retrieved with ambiguous query terms . Experiments investigate different levels of sense granularity , as well as the impact of text and image features , and global versus local text features . ### Response: Image Sense Discrimination : RESEARCH_PROBLEM; ISD : RESEARCH_PROBLEM; spectral clustering : METHOD; multimodal features : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","This paper describes an algorithm for computing optimal structural descriptions for Optimality Theory grammars with context-free position structures . This algorithm extends Tesar 's dynamic programming approach -LRB- Tesar , 1994 -RRB- -LRB- Tesar , 1995 @ to computing optimal structural descriptions from regular to context-free structures . The generalization to contextfree structures creates several complications , all of which are overcome without compromising the core dynamic programming approach . The resulting algorithm has a time complexity cubic in the length of the input , and is applicable to grammars with universal constraints that exhibit context-free locality .",optimal structural descriptions for Optimality Theory grammars : RESEARCH_PROBLEM; context-free position structures : METHOD; dynamic programming : METHOD; optimal structural descriptions : RESEARCH_PROBLEM; contextfree structures : METHOD; dynamic programming : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: This paper describes an algorithm for computing optimal structural descriptions for Optimality Theory grammars with context-free position structures . This algorithm extends Tesar 's dynamic programming approach -LRB- Tesar , 1994 -RRB- -LRB- Tesar , 1995 @ to computing optimal structural descriptions from regular to context-free structures . The generalization to contextfree structures creates several complications , all of which are overcome without compromising the core dynamic programming approach . The resulting algorithm has a time complexity cubic in the length of the input , and is applicable to grammars with universal constraints that exhibit context-free locality . ### Response: optimal structural descriptions for Optimality Theory grammars : RESEARCH_PROBLEM; context-free position structures : METHOD; dynamic programming : METHOD; optimal structural descriptions : RESEARCH_PROBLEM; contextfree structures : METHOD; dynamic programming : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","The system presented in this paper produces bilingual passages of text from an original -LRB- source -RRB- text and one -LRB- or more -RRB- of its translated versions . The source text passage includes words or word compounds which a translator wants to retrieve for the current translating of another text . The target text passage is the equivalent version of the source text passage . On the basis of a comparison of the contexts of these words in the concorded passage and his own text , the translator has to decide on the utility of the translation proposed in the target text passage . The program might become a component of translator 's work bench .",bilingual passages of text : RESEARCH_PROBLEM; contexts : METHOD; translation : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: The system presented in this paper produces bilingual passages of text from an original -LRB- source -RRB- text and one -LRB- or more -RRB- of its translated versions . The source text passage includes words or word compounds which a translator wants to retrieve for the current translating of another text . The target text passage is the equivalent version of the source text passage . On the basis of a comparison of the contexts of these words in the concorded passage and his own text , the translator has to decide on the utility of the translation proposed in the target text passage . The program might become a component of translator 's work bench . ### Response: bilingual passages of text : RESEARCH_PROBLEM; contexts : METHOD; translation : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Target task matched parallel corpora are required for statistical translation model training . However , training corpora sometimes include both target task matched and unmatched sentences . In such a case , training set selection can reduce the size of the translation model . In this paper , we propose a training set selection method for translation model training using linear translation model interpolation and a language model technique . According to the experimental results , the proposed method reduces the translation model size by 50 % and improves BLEU score by 1.76 % in comparison with a baseline training corpus usage .",statistical translation : RESEARCH_PROBLEM; training set selection : METHOD; translation : RESEARCH_PROBLEM; linear : METHOD; translation : RESEARCH_PROBLEM; language model : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Target task matched parallel corpora are required for statistical translation model training . However , training corpora sometimes include both target task matched and unmatched sentences . In such a case , training set selection can reduce the size of the translation model . In this paper , we propose a training set selection method for translation model training using linear translation model interpolation and a language model technique . According to the experimental results , the proposed method reduces the translation model size by 50 % and improves BLEU score by 1.76 % in comparison with a baseline training corpus usage . ### Response: statistical translation : RESEARCH_PROBLEM; training set selection : METHOD; translation : RESEARCH_PROBLEM; linear : METHOD; translation : RESEARCH_PROBLEM; language model : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","This paper explores two classes of model adaptation methods for Web search ranking : Model Interpolation and error-driven learning approaches based on a boosting algorithm . The results show that model interpolation , though simple , achieves the best results on all the open test sets where the test data is very different from the training data . The tree-based boosting algorithm achieves the best performance on most of the closed test sets where the test data and the training data are similar , but its performance drops significantly on the open test sets due to the instability of trees . Several methods are explored to improve the robustness of the algorithm , with limited success .",model adaptation : RESEARCH_PROBLEM; Web search ranking : RESEARCH_PROBLEM; Model Interpolation and error-driven learning : METHOD; boosting : METHOD; model interpolation : METHOD; tree-based boosting : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: This paper explores two classes of model adaptation methods for Web search ranking : Model Interpolation and error-driven learning approaches based on a boosting algorithm . The results show that model interpolation , though simple , achieves the best results on all the open test sets where the test data is very different from the training data . The tree-based boosting algorithm achieves the best performance on most of the closed test sets where the test data and the training data are similar , but its performance drops significantly on the open test sets due to the instability of trees . Several methods are explored to improve the robustness of the algorithm , with limited success . ### Response: model adaptation : RESEARCH_PROBLEM; Web search ranking : RESEARCH_PROBLEM; Model Interpolation and error-driven learning : METHOD; boosting : METHOD; model interpolation : METHOD; tree-based boosting : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Machine transliteration\/back-transliteration plays an important role in many multilingual speech and language applications . In this paper , a novel framework for machine transliteration\/backtransliteration that allows us to carry out direct orthographical mapping -LRB- DOM -RRB- between two different languages is presented . Under this framework , a joint source-channel transliteration model , also called n-gram transliteration model -LRB- ngram TM -RRB- , is further proposed to model the transliteration process . We evaluate the proposed methods through several transliteration\/backtransliteration experiments for English\/Chinese and English\/Japanese language pairs . Our study reveals that the proposed method not only reduces an extensive system development effort but also improves the transliteration accuracy significantly .",orthographical mapping : RESEARCH_PROBLEM; joint source-channel : METHOD; n-gram : METHOD; ngram : METHOD; transliteration : RESEARCH_PROBLEM; transliteration : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Machine transliteration\/back-transliteration plays an important role in many multilingual speech and language applications . In this paper , a novel framework for machine transliteration\/backtransliteration that allows us to carry out direct orthographical mapping -LRB- DOM -RRB- between two different languages is presented . Under this framework , a joint source-channel transliteration model , also called n-gram transliteration model -LRB- ngram TM -RRB- , is further proposed to model the transliteration process . We evaluate the proposed methods through several transliteration\/backtransliteration experiments for English\/Chinese and English\/Japanese language pairs . Our study reveals that the proposed method not only reduces an extensive system development effort but also improves the transliteration accuracy significantly . ### Response: orthographical mapping : RESEARCH_PROBLEM; joint source-channel : METHOD; n-gram : METHOD; ngram : METHOD; transliteration : RESEARCH_PROBLEM; transliteration : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","When a lexical item is selected in the language production process , it needs to be explained why none of its superordinates gets selected instead , since their applicability conditions are fulfilled all the same . This question has received much attention in cognitive modelling and not as much in other branches of NLG . This paper describes the various approaches taken , discusses the reasons why they are so different , and argues that production models using symbolic representations should make a distinction between conceptual and lexical hierarchies , which can be organized along fixed levels as studied in -LRB- some branches of -RRB- lexical semantics .",language production : RESEARCH_PROBLEM; production : RESEARCH_PROBLEM; symbolic representations : METHOD; conceptual and lexical hierarchies : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: When a lexical item is selected in the language production process , it needs to be explained why none of its superordinates gets selected instead , since their applicability conditions are fulfilled all the same . This question has received much attention in cognitive modelling and not as much in other branches of NLG . This paper describes the various approaches taken , discusses the reasons why they are so different , and argues that production models using symbolic representations should make a distinction between conceptual and lexical hierarchies , which can be organized along fixed levels as studied in -LRB- some branches of -RRB- lexical semantics . ### Response: language production : RESEARCH_PROBLEM; production : RESEARCH_PROBLEM; symbolic representations : METHOD; conceptual and lexical hierarchies : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","The paper illustrates a linguistic knowledge acquisition model making use of data types , infinite nlenlory , and an inferential mechanism tbr inducing new intbrmation Dora known data . The mode -RRB- is colnpared with standard stochastic lnethods applied to data tokens , and tested on a task of lexico semantic classification .",linguistic knowledge acquisition : RESEARCH_PROBLEM; data types : METHOD; infinite nlenlory : METHOD; inferential mechanism : METHOD; lexico semantic classification : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: The paper illustrates a linguistic knowledge acquisition model making use of data types , infinite nlenlory , and an inferential mechanism tbr inducing new intbrmation Dora known data . The mode -RRB- is colnpared with standard stochastic lnethods applied to data tokens , and tested on a task of lexico semantic classification . ### Response: linguistic knowledge acquisition : RESEARCH_PROBLEM; data types : METHOD; infinite nlenlory : METHOD; inferential mechanism : METHOD; lexico semantic classification : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","This paper describes a method of adapting a domain-independent HPSG parser to a biomedical domain . Without modifying the grammar and the probabilistic model of the original HPSG parser , we develop a log-linear model with additional features on a treebank of the biomedical domain . Since the treebank of the target domain is limited , we need to exploit an original disambiguation model that was trained on a larger treebank . Our model incorporates the original model as a reference probabilistic distribution . The experimental results for our model trained with a small amount of a treebank demonstrated an improvement in parsing accuracy .",HPSG : METHOD; parser : RESEARCH_PROBLEM; biomedical : RESEARCH_PROBLEM; probabilistic : METHOD; HPSG : METHOD; parser : RESEARCH_PROBLEM; log-linear : METHOD; biomedical : RESEARCH_PROBLEM; probabilistic : METHOD; parsing : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: This paper describes a method of adapting a domain-independent HPSG parser to a biomedical domain . Without modifying the grammar and the probabilistic model of the original HPSG parser , we develop a log-linear model with additional features on a treebank of the biomedical domain . Since the treebank of the target domain is limited , we need to exploit an original disambiguation model that was trained on a larger treebank . Our model incorporates the original model as a reference probabilistic distribution . The experimental results for our model trained with a small amount of a treebank demonstrated an improvement in parsing accuracy . ### Response: HPSG : METHOD; parser : RESEARCH_PROBLEM; biomedical : RESEARCH_PROBLEM; probabilistic : METHOD; HPSG : METHOD; parser : RESEARCH_PROBLEM; log-linear : METHOD; biomedical : RESEARCH_PROBLEM; probabilistic : METHOD; parsing : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","We present a novel neural network for processing sequences . The ByteNet is a one-dimensional convolutional neural network that is composed of two parts , one to encode the source sequence and the other to decode the target sequence . The two network parts are connected by stacking the decoder on top of the encoder and preserving the temporal resolution of the sequences . To address the differing lengths of the source and the target , we introduce an efficient mechanism by which the decoder is dynamically unfolded over the representation of the encoder . The ByteNet uses dilation in the convolutional layers to increase its receptive field . The resulting network has two core properties : it runs in time that is linear in the length of the sequences and it sidesteps the need for excessive memorization . The ByteNet decoder attains state - of - the - art performance on character - level language modelling and outperforms the previous best results obtained with recurrent networks .",character - level language modelling : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: We present a novel neural network for processing sequences . The ByteNet is a one-dimensional convolutional neural network that is composed of two parts , one to encode the source sequence and the other to decode the target sequence . The two network parts are connected by stacking the decoder on top of the encoder and preserving the temporal resolution of the sequences . To address the differing lengths of the source and the target , we introduce an efficient mechanism by which the decoder is dynamically unfolded over the representation of the encoder . The ByteNet uses dilation in the convolutional layers to increase its receptive field . The resulting network has two core properties : it runs in time that is linear in the length of the sequences and it sidesteps the need for excessive memorization . The ByteNet decoder attains state - of - the - art performance on character - level language modelling and outperforms the previous best results obtained with recurrent networks . ### Response: character - level language modelling : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","The dominant sequence transduction models are based on complex recurrent or convolutional neural networks that include an encoder and a decoder . The best performing models also connect the encoder and decoder through an attention mechanism . We propose a new simple network architecture , the Transformer , based solely on attention mechanisms , dispensing with recurrence and convolutions entirely . Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train . Our model achieves 28.4 BLEU on the WMT 2014 Englishto - German translation task , improving over the existing best results , including ensembles , by over 2 BLEU . On the WMT 2014 English - to - French translation task , our model establishes a new single - model state - of - the - art BLEU score of 41.8 after training for 3.5 days on eight GPUs , a small fraction of the training costs of the best models from the literature . We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data .",attention mechanisms : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: The dominant sequence transduction models are based on complex recurrent or convolutional neural networks that include an encoder and a decoder . The best performing models also connect the encoder and decoder through an attention mechanism . We propose a new simple network architecture , the Transformer , based solely on attention mechanisms , dispensing with recurrence and convolutions entirely . Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train . Our model achieves 28.4 BLEU on the WMT 2014 Englishto - German translation task , improving over the existing best results , including ensembles , by over 2 BLEU . On the WMT 2014 English - to - French translation task , our model establishes a new single - model state - of - the - art BLEU score of 41.8 after training for 3.5 days on eight GPUs , a small fraction of the training costs of the best models from the literature . We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data . ### Response: attention mechanisms : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Neural machine translation ( NT12 ) aims at solving machine translation ( MT ) problems using neural networks and has exhibited promising results in recent years . However , most of the existing NMT models are shallow and there is still a performance gap between a single NMT model and the best conventional MT system . In this work , we introduce a new type of linear connections , named fastforward connections , based on deep Long Short - Term Memory ( LSTM ) networks , and an interleaved bi-directional architecture for stacking the LSTM layers . Fast - forward connections play an essential role in propagating the gradients and building a deep topology of depth 16 . On the WMT ' 14 Englishto - French task , we achieve BLEU = 37.7 with a single attention model , which outperforms the corresponding single shallow model by 6.2 BLEU points . This is the first time that a single NMT model achieves state - of - the - art performance and outperforms the best conventional model by 0.7 BLEU points . We can still achieve BLEU = 36.3 even without using an attention mechanism .",Neural machine translation : RESEARCH_PROBLEM; machine translation : RESEARCH_PROBLEM; MT : RESEARCH_PROBLEM; NMT : RESEARCH_PROBLEM; NMT : RESEARCH_PROBLEM; MT : RESEARCH_PROBLEM; NMT : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Neural machine translation ( NT12 ) aims at solving machine translation ( MT ) problems using neural networks and has exhibited promising results in recent years . However , most of the existing NMT models are shallow and there is still a performance gap between a single NMT model and the best conventional MT system . In this work , we introduce a new type of linear connections , named fastforward connections , based on deep Long Short - Term Memory ( LSTM ) networks , and an interleaved bi-directional architecture for stacking the LSTM layers . Fast - forward connections play an essential role in propagating the gradients and building a deep topology of depth 16 . On the WMT ' 14 Englishto - French task , we achieve BLEU = 37.7 with a single attention model , which outperforms the corresponding single shallow model by 6.2 BLEU points . This is the first time that a single NMT model achieves state - of - the - art performance and outperforms the best conventional model by 0.7 BLEU points . We can still achieve BLEU = 36.3 even without using an attention mechanism . ### Response: Neural machine translation : RESEARCH_PROBLEM; machine translation : RESEARCH_PROBLEM; MT : RESEARCH_PROBLEM; NMT : RESEARCH_PROBLEM; NMT : RESEARCH_PROBLEM; MT : RESEARCH_PROBLEM; NMT : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Unsupervised neural machine translation ( NMT ) is a recently proposed approach for machine translation which aims to train the model without using any labeled data . The models proposed for unsupervised NMT often use only one shared encoder to map the pairs of sentences from different languages to a shared - latent space , which is weak in keeping the unique and internal characteristics of each language , such as the style , terminology , and sentence structure . To address this issue , we introduce an extension by utilizing two independent encoders but sharing some partial weights which are responsible for extracting high - level representations of the input sentences . Besides , two different generative adversarial networks ( GANs ) , namely the local GAN and global GAN , are proposed to enhance the cross - language translation . With this new approach , we achieve significant improvements on English - German , English - French and Chinese - to - English translation tasks .",Unsupervised neural machine translation : RESEARCH_PROBLEM; NMT : RESEARCH_PROBLEM; machine translation : RESEARCH_PROBLEM; unsupervised NMT : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Unsupervised neural machine translation ( NMT ) is a recently proposed approach for machine translation which aims to train the model without using any labeled data . The models proposed for unsupervised NMT often use only one shared encoder to map the pairs of sentences from different languages to a shared - latent space , which is weak in keeping the unique and internal characteristics of each language , such as the style , terminology , and sentence structure . To address this issue , we introduce an extension by utilizing two independent encoders but sharing some partial weights which are responsible for extracting high - level representations of the input sentences . Besides , two different generative adversarial networks ( GANs ) , namely the local GAN and global GAN , are proposed to enhance the cross - language translation . With this new approach , we achieve significant improvements on English - German , English - French and Chinese - to - English translation tasks . ### Response: Unsupervised neural machine translation : RESEARCH_PROBLEM; NMT : RESEARCH_PROBLEM; machine translation : RESEARCH_PROBLEM; unsupervised NMT : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","The paper describes the development process of the Tilde 's NMT systems that were submitted for the WMT 2018 shared task on news translation . We describe the data filtering and pre-processing workflows , the NMT system training architectures , and automatic evaluation results . For the WMT 2018 shared task , we submitted seven systems ( both constrained and unconstrained ) for English - Estonian and Estonian - English translation directions . The submitted systems were trained using Transformer models .",NMT : RESEARCH_PROBLEM; news translation : RESEARCH_PROBLEM; NMT : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: The paper describes the development process of the Tilde 's NMT systems that were submitted for the WMT 2018 shared task on news translation . We describe the data filtering and pre-processing workflows , the NMT system training architectures , and automatic evaluation results . For the WMT 2018 shared task , we submitted seven systems ( both constrained and unconstrained ) for English - Estonian and Estonian - English translation directions . The submitted systems were trained using Transformer models . ### Response: NMT : RESEARCH_PROBLEM; news translation : RESEARCH_PROBLEM; NMT : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Continuous word representation ( aka word embedding ) is a basic building block in many neural network - based models used in natural language processing tasks . Although it is widely accepted that words with similar semantics should be close to each other in the embedding space , we find that word embeddings learned in several tasks are biased towards word frequency : the embeddings of highfrequency and low - frequency words lie in different subregions of the embedding space , and the embedding of a rare word and a popular word can be far from each other even if they are semantically similar . This makes learned word embeddings ineffective , especially for rare words , and consequently limits the performance of these neural network models . In this paper , we develop a neat , simple yet effective way to learn FRequency - AGnostic word Embedding ( FRAGE ) using adversarial training . We conducted comprehensive studies on ten datasets across four natural language processing tasks , including word similarity , language modeling , machine translation and text classification . Results show that with FRAGE , we achieve higher performance than the baselines in all tasks .",word embeddings learned in several tasks are biased towards word frequency : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Continuous word representation ( aka word embedding ) is a basic building block in many neural network - based models used in natural language processing tasks . Although it is widely accepted that words with similar semantics should be close to each other in the embedding space , we find that word embeddings learned in several tasks are biased towards word frequency : the embeddings of highfrequency and low - frequency words lie in different subregions of the embedding space , and the embedding of a rare word and a popular word can be far from each other even if they are semantically similar . This makes learned word embeddings ineffective , especially for rare words , and consequently limits the performance of these neural network models . In this paper , we develop a neat , simple yet effective way to learn FRequency - AGnostic word Embedding ( FRAGE ) using adversarial training . We conducted comprehensive studies on ten datasets across four natural language processing tasks , including word similarity , language modeling , machine translation and text classification . Results show that with FRAGE , we achieve higher performance than the baselines in all tasks . ### Response: word embeddings learned in several tasks are biased towards word frequency : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","The capacity of a neural network to absorb information is limited by its number of parameters . Conditional computation , where parts of the network are active on a per-example basis , has been proposed in theory as away of dramatically increasing model capacity without a proportional increase in computation . In practice , however , there are significant algorithmic and performance challenges . In this work , we address these challenges and finally realize the promise of conditional computation , achieving greater than 1000x improvements in model capacity with only minor losses in computational efficiency on modern GPU clusters . We introduce a Sparsely - Gated Mixture - of - Experts layer ( MoE ) , consisting of up to thousands of feed - forward sub - networks . A trainable gating network determines a sparse combination of these experts to use for each example . We apply the MoE to the tasks of language modeling and machine translation , where model capacity is critical for absorbing the vast quantities of knowledge available in the training corpora .",Conditional computation : RESEARCH_PROBLEM; increasing model capacity without a proportional increase in computation : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: The capacity of a neural network to absorb information is limited by its number of parameters . Conditional computation , where parts of the network are active on a per-example basis , has been proposed in theory as away of dramatically increasing model capacity without a proportional increase in computation . In practice , however , there are significant algorithmic and performance challenges . In this work , we address these challenges and finally realize the promise of conditional computation , achieving greater than 1000x improvements in model capacity with only minor losses in computational efficiency on modern GPU clusters . We introduce a Sparsely - Gated Mixture - of - Experts layer ( MoE ) , consisting of up to thousands of feed - forward sub - networks . A trainable gating network determines a sparse combination of these experts to use for each example . We apply the MoE to the tasks of language modeling and machine translation , where model capacity is critical for absorbing the vast quantities of knowledge available in the training corpora . ### Response: Conditional computation : RESEARCH_PROBLEM; increasing model capacity without a proportional increase in computation : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Neural machine translation is a recently proposed approach to machine translation . Unlike the traditional statistical machine translation , the neural machine translation aims at building a single neural network that can be jointly tuned to maximize the translation performance . The models proposed recently for neural machine translation often belong to a family of encoder - decoders and encode a source sentence into a fixed - length vector from which a decoder generates a translation . In this paper , we conjecture that the use of a fixed - length vector is a bottleneck in improving the performance of this basic encoder - decoder architecture , and propose to extend this by allowing a model to automatically ( soft - ) search for parts of a source sentence that are relevant to predicting a target word , without having to form these parts as a hard segment explicitly . With this new approach , we achieve a translation performance comparable to the existing state - of - the - art phrase - based system on the task of English - to - French translation . Furthermore , qualitative analysis reveals that the ( soft - ) alignments found by the model agree well with our intuition . INTRODUCTION",machine translation : RESEARCH_PROBLEM; machine translation : RESEARCH_PROBLEM; machine translation : RESEARCH_PROBLEM; machine translation : RESEARCH_PROBLEM; machine translation : RESEARCH_PROBLEM; use of a fixed - length vector is a bottleneck in improving the performance of this basic encoder - decoder architecture : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Neural machine translation is a recently proposed approach to machine translation . Unlike the traditional statistical machine translation , the neural machine translation aims at building a single neural network that can be jointly tuned to maximize the translation performance . The models proposed recently for neural machine translation often belong to a family of encoder - decoders and encode a source sentence into a fixed - length vector from which a decoder generates a translation . In this paper , we conjecture that the use of a fixed - length vector is a bottleneck in improving the performance of this basic encoder - decoder architecture , and propose to extend this by allowing a model to automatically ( soft - ) search for parts of a source sentence that are relevant to predicting a target word , without having to form these parts as a hard segment explicitly . With this new approach , we achieve a translation performance comparable to the existing state - of - the - art phrase - based system on the task of English - to - French translation . Furthermore , qualitative analysis reveals that the ( soft - ) alignments found by the model agree well with our intuition . INTRODUCTION ### Response: machine translation : RESEARCH_PROBLEM; machine translation : RESEARCH_PROBLEM; machine translation : RESEARCH_PROBLEM; machine translation : RESEARCH_PROBLEM; machine translation : RESEARCH_PROBLEM; use of a fixed - length vector is a bottleneck in improving the performance of this basic encoder - decoder architecture : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Natural language processing ( NLP ) models often require a massive number of parameters for word embeddings , resulting in a large storage or memory footprint . Deploying neural NLP models to mobile devices requires compressing the word embeddings without any significant sacrifices in performance . For this purpose , we propose to construct the embeddings with few basis vectors . For each word , the composition of basis vectors is determined by a hash code . To maximize the compression rate , we adopt the multi-codebook quantization approach instead of binary coding scheme . Each code is composed of multiple discrete numbers , such as ( 3 , 2 , 1 , 8 ) , where the value of each component is limited to a fixed range . We propose to directly learn the discrete codes in an end - to - end neural network by applying the Gumbel - softmax trick .",compressing the word embeddings without any significant sacrifices in performance : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Natural language processing ( NLP ) models often require a massive number of parameters for word embeddings , resulting in a large storage or memory footprint . Deploying neural NLP models to mobile devices requires compressing the word embeddings without any significant sacrifices in performance . For this purpose , we propose to construct the embeddings with few basis vectors . For each word , the composition of basis vectors is determined by a hash code . To maximize the compression rate , we adopt the multi-codebook quantization approach instead of binary coding scheme . Each code is composed of multiple discrete numbers , such as ( 3 , 2 , 1 , 8 ) , where the value of each component is limited to a fixed range . We propose to directly learn the discrete codes in an end - to - end neural network by applying the Gumbel - softmax trick . ### Response: compressing the word embeddings without any significant sacrifices in performance : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Subset selection from massive data with noised information is increasingly popular for various applications . This problem is still highly challenging as current methods are generally slow in speed and sensitive to outliers . To address the above two issues , we propose an accelerated robust subset selection ( ARSS ) method . Specifically in the subset selection area , this is the first attempt to employ the p ( 0 < p ? 1 ) - norm based measure for the representation loss , preventing large errors from dominating our objective . As a result , the robustness against outlier elements is greatly enhanced . Actually , data size is generally much larger than feature length , i.e. N L. Based on this observation , we propose a speedup solver ( via ALM and equivalent derivations ) to highly reduce the computational cost , theoretically from ON 4 to ON 2 L . Extensive experiments on ten benchmark datasets verify that our method not only outperforms state of the art methods , but also runs 10,000 + times faster than the most related method .",Subset selection from massive data : RESEARCH_PROBLEM; subset selection : RESEARCH_PROBLEM; subset selection : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Subset selection from massive data with noised information is increasingly popular for various applications . This problem is still highly challenging as current methods are generally slow in speed and sensitive to outliers . To address the above two issues , we propose an accelerated robust subset selection ( ARSS ) method . Specifically in the subset selection area , this is the first attempt to employ the p ( 0 < p ? 1 ) - norm based measure for the representation loss , preventing large errors from dominating our objective . As a result , the robustness against outlier elements is greatly enhanced . Actually , data size is generally much larger than feature length , i.e. N L. Based on this observation , we propose a speedup solver ( via ALM and equivalent derivations ) to highly reduce the computational cost , theoretically from ON 4 to ON 2 L . Extensive experiments on ten benchmark datasets verify that our method not only outperforms state of the art methods , but also runs 10,000 + times faster than the most related method . ### Response: Subset selection from massive data : RESEARCH_PROBLEM; subset selection : RESEARCH_PROBLEM; subset selection : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","State - of - the - art named entity recognition systems rely heavily on hand - crafted features and domain - specific knowledge in order to learn effectively from the small , supervised training corpora thatare available . In this paper , we introduce two new neural architectures - one based on bidirectional LSTMs and conditional random fields , and the other that constructs and labels segments using a transition - based approach inspired by shift - reduce parsers . Our models rely on two sources of information about words : character - based word representations learned from the supervised corpus and unsupervised word representations learned from unannotated corpora . Our models obtain state - of - the - art performance in NER in four languages without resorting to any language - specific knowledge or resources such as gazetteers . 1",NER : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: State - of - the - art named entity recognition systems rely heavily on hand - crafted features and domain - specific knowledge in order to learn effectively from the small , supervised training corpora thatare available . In this paper , we introduce two new neural architectures - one based on bidirectional LSTMs and conditional random fields , and the other that constructs and labels segments using a transition - based approach inspired by shift - reduce parsers . Our models rely on two sources of information about words : character - based word representations learned from the supervised corpus and unsupervised word representations learned from unannotated corpora . Our models obtain state - of - the - art performance in NER in four languages without resorting to any language - specific knowledge or resources such as gazetteers . 1 ### Response: NER : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Today when many practitioners run basic NLP on the entire web and large - volume traffic , faster methods are paramount to saving time and energy costs . Recent advances in GPU hardware have led to the emergence of bi-directional LSTMs as a standard method for obtaining pertoken vector representations serving as input to labeling tasks such as NER ( often followed by prediction in a linear - chain CRF ) . Though expressive and accurate , these models fail to fully exploit GPU parallelism , limiting their computational efficiency . This paper proposes a faster alternative to Bi - LSTMs for NER : Iterated Dilated Convolutional Neural Networks ( ID - CNNs ) , which have better capacity than traditional CNNs for large context and structured prediction . Unlike LSTMs whose sequential processing on sentences of length N requires O(N ) time even in the face of parallelism , ID - CNNs permit fixed - depth convolutions to run in parallel across entire documents . We describe a distinct combination of network structure , parameter sharing and training procedures that enable dramatic 14 - 20x testtime speedups while retaining accuracy comparable to the Bi - LSTM - CRF . Moreover , ID - CNNs trained to aggregate context from the entire document are even more accurate while maintaining 8 x faster test time speeds .",faster alternative to Bi - LSTMs for NER : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Today when many practitioners run basic NLP on the entire web and large - volume traffic , faster methods are paramount to saving time and energy costs . Recent advances in GPU hardware have led to the emergence of bi-directional LSTMs as a standard method for obtaining pertoken vector representations serving as input to labeling tasks such as NER ( often followed by prediction in a linear - chain CRF ) . Though expressive and accurate , these models fail to fully exploit GPU parallelism , limiting their computational efficiency . This paper proposes a faster alternative to Bi - LSTMs for NER : Iterated Dilated Convolutional Neural Networks ( ID - CNNs ) , which have better capacity than traditional CNNs for large context and structured prediction . Unlike LSTMs whose sequential processing on sentences of length N requires O(N ) time even in the face of parallelism , ID - CNNs permit fixed - depth convolutions to run in parallel across entire documents . We describe a distinct combination of network structure , parameter sharing and training procedures that enable dramatic 14 - 20x testtime speedups while retaining accuracy comparable to the Bi - LSTM - CRF . Moreover , ID - CNNs trained to aggregate context from the entire document are even more accurate while maintaining 8 x faster test time speeds . ### Response: faster alternative to Bi - LSTMs for NER : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Pre-trained word embeddings learned from unlabeled text have become a standard component of neural network architectures for NLP tasks . However , in most cases , the recurrent network that operates on word - level representations to produce context sensitive representations is trained on relatively little labeled data . In this paper , we demonstrate a general semi-supervised approach for adding pretrained context embeddings from bidirectional language models to NLP systems and apply it to sequence labeling tasks . We evaluate our model on two standard datasets for named entity recognition ( NER ) and chunking , and in both cases achieve state of the art results , surpassing previous systems that use other forms of transfer or joint learning with additional labeled data and task specific gazetteers .",general semi-supervised approach for adding pretrained context embeddings from bidirectional language models to NLP systems : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Pre-trained word embeddings learned from unlabeled text have become a standard component of neural network architectures for NLP tasks . However , in most cases , the recurrent network that operates on word - level representations to produce context sensitive representations is trained on relatively little labeled data . In this paper , we demonstrate a general semi-supervised approach for adding pretrained context embeddings from bidirectional language models to NLP systems and apply it to sequence labeling tasks . We evaluate our model on two standard datasets for named entity recognition ( NER ) and chunking , and in both cases achieve state of the art results , surpassing previous systems that use other forms of transfer or joint learning with additional labeled data and task specific gazetteers . ### Response: general semi-supervised approach for adding pretrained context embeddings from bidirectional language models to NLP systems : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Bi-directional LSTMs are a powerful tool for text representation . On the other hand , they have been shown to suffer various limitations due to their sequential nature . We investigate an alternative LSTM structure for encoding text , which consists of a parallel state for each word . Recurrent steps are used to perform local and global information exchange between words simultaneously , rather than incremental reading of a sequence of words . Results on various classification and sequence labelling benchmarks show that the proposed model has strong representation power , giving highly competitive performances compared to stacked BiLSTM models with similar parameter numbers .",alternative LSTM structure for encoding text : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Bi-directional LSTMs are a powerful tool for text representation . On the other hand , they have been shown to suffer various limitations due to their sequential nature . We investigate an alternative LSTM structure for encoding text , which consists of a parallel state for each word . Recurrent steps are used to perform local and global information exchange between words simultaneously , rather than incremental reading of a sequence of words . Results on various classification and sequence labelling benchmarks show that the proposed model has strong representation power , giving highly competitive performances compared to stacked BiLSTM models with similar parameter numbers . ### Response: alternative LSTM structure for encoding text : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Neural network approaches to Named - Entity Recognition reduce the need for carefully handcrafted features . While some features do remain in state - of - the - art systems , lexical features have been mostly discarded , with the exception of gazetteers . In this work , we show that this is unfair : lexical features are actually quite useful . We propose to embed words and entity types into a lowdimensional vector space we train from annotated data produced by distant supervision thanks to Wikipedia . From this , we compute - offline - a feature vector representing each word . When used with a vanilla recurrent neural network model , this representation yields substantial improvements . We establish a new state - of - the - art F1 score of 87.95 on ONTONOTES 5.0 , while matching state - of - the - art performance with a F 1 score of 91.73 on the over - studied CONLL - 2003 dataset .",Neural network approaches to Named - Entity Recognition : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Neural network approaches to Named - Entity Recognition reduce the need for carefully handcrafted features . While some features do remain in state - of - the - art systems , lexical features have been mostly discarded , with the exception of gazetteers . In this work , we show that this is unfair : lexical features are actually quite useful . We propose to embed words and entity types into a lowdimensional vector space we train from annotated data produced by distant supervision thanks to Wikipedia . From this , we compute - offline - a feature vector representing each word . When used with a vanilla recurrent neural network model , this representation yields substantial improvements . We establish a new state - of - the - art F1 score of 87.95 on ONTONOTES 5.0 , while matching state - of - the - art performance with a F 1 score of 91.73 on the over - studied CONLL - 2003 dataset . ### Response: Neural network approaches to Named - Entity Recognition : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","It is common that entity mentions can contain other mentions recursively . This paper introduces a scalable transition - based method to model the nested structure of mentions . We first map a sentence with nested mentions to a designated forest where each mention corresponds to a constituent of the forest . Our shiftreduce based system then learns to construct the forest structure in a bottom - up manner through an action sequence whose maximal length is guaranteed to be three times of the sentence length . Based on Stack - LSTM which is employed to efficiently and effectively represent the states of the system in a continuous space , our system is further incorporated with a character - based component to capture letterlevel patterns . Our model achieves the stateof - the - art results on ACE datasets , showing its effectiveness in detecting nested mentions . 1",model the nested structure of mentions : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: It is common that entity mentions can contain other mentions recursively . This paper introduces a scalable transition - based method to model the nested structure of mentions . We first map a sentence with nested mentions to a designated forest where each mention corresponds to a constituent of the forest . Our shiftreduce based system then learns to construct the forest structure in a bottom - up manner through an action sequence whose maximal length is guaranteed to be three times of the sentence length . Based on Stack - LSTM which is employed to efficiently and effectively represent the states of the system in a continuous space , our system is further incorporated with a character - based component to capture letterlevel patterns . Our model achieves the stateof - the - art results on ACE datasets , showing its effectiveness in detecting nested mentions . 1 ### Response: model the nested structure of mentions : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","We introduce a new language representation model called BERT , which stands for Bidirectional Encoder Representations from Transformers . Unlike recent ( Peters et al. , 2018 a ; Radford et al. , 2018 ) , BERT is designed to pretrain deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers . As a result , the pre-trained BERT model can be finetuned with just one additional output layer to create state - of - the - art models for a wide range of tasks , such as question answering and language inference , without substantial taskspecific architecture modifications . BERT is conceptually simple and empirically powerful . It obtains new state - of - the - art results on eleven natural language processing tasks , including pushing the GLUE score to 80.5 % ( 7.7 % point absolute improvement ) , MultiNLI accuracy to 86.7 % ( 4.6 % absolute improvement ) , SQ u AD v 1.1 question answering Test F1 to 93.2 ( 1.5 point absolute improvement ) and SQ u AD v2.0 Test F1 to 83.1 ( 5.1 point absolute improvement ) . Jeremy Howard and Sebastian Ruder . 2018 . Universal language model fine - tuning for text classification .",language representation model : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: We introduce a new language representation model called BERT , which stands for Bidirectional Encoder Representations from Transformers . Unlike recent ( Peters et al. , 2018 a ; Radford et al. , 2018 ) , BERT is designed to pretrain deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers . As a result , the pre-trained BERT model can be finetuned with just one additional output layer to create state - of - the - art models for a wide range of tasks , such as question answering and language inference , without substantial taskspecific architecture modifications . BERT is conceptually simple and empirically powerful . It obtains new state - of - the - art results on eleven natural language processing tasks , including pushing the GLUE score to 80.5 % ( 7.7 % point absolute improvement ) , MultiNLI accuracy to 86.7 % ( 4.6 % absolute improvement ) , SQ u AD v 1.1 question answering Test F1 to 93.2 ( 1.5 point absolute improvement ) and SQ u AD v2.0 Test F1 to 83.1 ( 5.1 point absolute improvement ) . Jeremy Howard and Sebastian Ruder . 2018 . Universal language model fine - tuning for text classification . ### Response: language representation model : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Motivation : Biomedical text mining is becoming increasingly important as the number of biomedical documents rapidly grows . With the progress in natural language processing ( NLP ) , extracting valuable information from biomedical literature has gained popularity among researchers , and deep learning has boosted the development of effective biomedical text mining models . However , directly applying the advancements in NLP to biomedical text mining often yields unsatisfactory results due to a word distribution shift from general domain corpora to biomedical corpora . In this article , we investigate how the recently introduced pre-trained language model BERT can be adapted for biomedical corpora . Results : We introduce BioBERT ( Bidirectional Encoder Representations from Transformers for Biomedical Text Mining ) , which is a domain - specific language representation model pre-trained on large - scale biomedical corpora .",extracting valuable information from biomedical literature : RESEARCH_PROBLEM; biomedical text mining often yields unsatisfactory results due to a word distribution shift from general domain corpora to biomedical corpora : RESEARCH_PROBLEM; pre-trained language model BERT can be adapted for biomedical corpora : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Motivation : Biomedical text mining is becoming increasingly important as the number of biomedical documents rapidly grows . With the progress in natural language processing ( NLP ) , extracting valuable information from biomedical literature has gained popularity among researchers , and deep learning has boosted the development of effective biomedical text mining models . However , directly applying the advancements in NLP to biomedical text mining often yields unsatisfactory results due to a word distribution shift from general domain corpora to biomedical corpora . In this article , we investigate how the recently introduced pre-trained language model BERT can be adapted for biomedical corpora . Results : We introduce BioBERT ( Bidirectional Encoder Representations from Transformers for Biomedical Text Mining ) , which is a domain - specific language representation model pre-trained on large - scale biomedical corpora . ### Response: extracting valuable information from biomedical literature : RESEARCH_PROBLEM; biomedical text mining often yields unsatisfactory results due to a word distribution shift from general domain corpora to biomedical corpora : RESEARCH_PROBLEM; pre-trained language model BERT can be adapted for biomedical corpora : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Building computers able to answer questions on any subject is along standing goal of artificial intelligence . Promising progress has recently been achieved by methods that learn to map questions to logical forms or data base queries . Such approaches can be effective but at the cost of either large amounts of human - labeled data or by defining lexicons and grammars tailored by practitioners . In this paper , we instead take the radical approach of learning to map questions to vectorial feature representations . By mapping answers into the same space one can query any knowledge base independent of its schema , without requiring any grammar or lexicon . Our method is trained with a new optimization procedure combining stochastic gradient descent followed by a fine - tuning step using the weak supervision provided by blending automatically and collaboratively generated resources . We empirically demonstrate that our model can capture meaningful signals from its noisy supervision leading to major improvements over paralex , the only existing method able to be trained on similar weakly labeled data .",Building computers able to answer questions on any subject : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Building computers able to answer questions on any subject is along standing goal of artificial intelligence . Promising progress has recently been achieved by methods that learn to map questions to logical forms or data base queries . Such approaches can be effective but at the cost of either large amounts of human - labeled data or by defining lexicons and grammars tailored by practitioners . In this paper , we instead take the radical approach of learning to map questions to vectorial feature representations . By mapping answers into the same space one can query any knowledge base independent of its schema , without requiring any grammar or lexicon . Our method is trained with a new optimization procedure combining stochastic gradient descent followed by a fine - tuning step using the weak supervision provided by blending automatically and collaboratively generated resources . We empirically demonstrate that our model can capture meaningful signals from its noisy supervision leading to major improvements over paralex , the only existing method able to be trained on similar weakly labeled data . ### Response: Building computers able to answer questions on any subject : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Semantic matching is of central importance to many natural language tasks [ 2,28 ] . A successful matching algorithm needs to adequately model the internal structures of language objects and the interaction between them . As a step toward this goal , we propose convolutional neural network models for matching two sentences , by adapting the convolutional strategy in vision and speech . The proposed models not only nicely represent the hierarchical structures of sentences with their layerby - layer composition and pooling , but also capture the rich matching patterns at different levels . Our models are rather generic , requiring no prior knowledge on language , and can hence be applied to matching tasks of different nature and in different languages . The empirical study on a variety of matching tasks demonstrates the efficacy of the proposed model on a variety of matching tasks and its superiority to competitor models .",Semantic matching : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Semantic matching is of central importance to many natural language tasks [ 2,28 ] . A successful matching algorithm needs to adequately model the internal structures of language objects and the interaction between them . As a step toward this goal , we propose convolutional neural network models for matching two sentences , by adapting the convolutional strategy in vision and speech . The proposed models not only nicely represent the hierarchical structures of sentences with their layerby - layer composition and pooling , but also capture the rich matching patterns at different levels . Our models are rather generic , requiring no prior knowledge on language , and can hence be applied to matching tasks of different nature and in different languages . The empirical study on a variety of matching tasks demonstrates the efficacy of the proposed model on a variety of matching tasks and its superiority to competitor models . ### Response: Semantic matching : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Training large - scale question answering systems is complicated because training sources usually cover a small portion of the range of possible questions . This paper studies the impact of multitask and transfer learning for simple question answering ; a setting for which the reasoning required to answer is quite easy , as long as one can retrieve the correct evidence given a question , which can be difficult in large - scale conditions . To this end , we introduce a new dataset of 100 k questions that we use in conjunction with existing benchmarks . We conduct our study within the framework of Memory Networks ( Weston et al. , 2015 ) because this perspective allows us to eventually scale up to more complex reasoning , and show that Memory Networks can be successfully trained to achieve excellent performance .",Training large - scale question answering systems : RESEARCH_PROBLEM; simple question answering : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Training large - scale question answering systems is complicated because training sources usually cover a small portion of the range of possible questions . This paper studies the impact of multitask and transfer learning for simple question answering ; a setting for which the reasoning required to answer is quite easy , as long as one can retrieve the correct evidence given a question , which can be difficult in large - scale conditions . To this end , we introduce a new dataset of 100 k questions that we use in conjunction with existing benchmarks . We conduct our study within the framework of Memory Networks ( Weston et al. , 2015 ) because this perspective allows us to eventually scale up to more complex reasoning , and show that Memory Networks can be successfully trained to achieve excellent performance . ### Response: Training large - scale question answering systems : RESEARCH_PROBLEM; simple question answering : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Most conventional sentence similarity methods only focus on similar parts of two input sentences , and simply ignore the dissimilar parts , which usually give us some clues and semantic meanings about the sentences . In this work , we propose a model to take into account both the similarities and dissimilarities by decomposing and composing lexical semantics over sentences . The model represents each word as a vector , and calculates a semantic matching vector for each word based on all words in the other sentence . Then , each word vector is decomposed into a similar component and a dissimilar component based on the semantic matching vector . After this , a two - channel CNN model is employed to capture features by composing the similar and dissimilar components . Finally , a similarity score is estimated over the composed feature vectors . Experimental results show that our model gets the state - of - the - art performance on the answer sentence selection task , and achieves a comparable result on the paraphrase identification task .",sentence similarity : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Most conventional sentence similarity methods only focus on similar parts of two input sentences , and simply ignore the dissimilar parts , which usually give us some clues and semantic meanings about the sentences . In this work , we propose a model to take into account both the similarities and dissimilarities by decomposing and composing lexical semantics over sentences . The model represents each word as a vector , and calculates a semantic matching vector for each word based on all words in the other sentence . Then , each word vector is decomposed into a similar component and a dissimilar component based on the semantic matching vector . After this , a two - channel CNN model is employed to capture features by composing the similar and dissimilar components . Finally , a similarity score is estimated over the composed feature vectors . Experimental results show that our model gets the state - of - the - art performance on the answer sentence selection task , and achieves a comparable result on the paraphrase identification task . ### Response: sentence similarity : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Understanding unstructured text is a major goal within natural language processing . Comprehension tests pose questions based on short text passages to evaluate such understanding . In this work , we investigate machine comprehension on the challenging benchmark . Partly because of its limited size , prior work on MCTest has focused mainly on engineering better features . We tackle the dataset with a neural approach , harnessing simple neural networks arranged in a parallel hierarchy . The parallel hierarchy enables our model to compare the passage , question , and answer from a variety of trainable perspectives , as opposed to using a manually designed , rigid feature set . Perspectives range from the word level to sentence fragments to sequences of sentences ; the networks operate only on word - embedding representations of text .",Understanding unstructured text : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Understanding unstructured text is a major goal within natural language processing . Comprehension tests pose questions based on short text passages to evaluate such understanding . In this work , we investigate machine comprehension on the challenging benchmark . Partly because of its limited size , prior work on MCTest has focused mainly on engineering better features . We tackle the dataset with a neural approach , harnessing simple neural networks arranged in a parallel hierarchy . The parallel hierarchy enables our model to compare the passage , question , and answer from a variety of trainable perspectives , as opposed to using a manually designed , rigid feature set . Perspectives range from the word level to sentence fragments to sequences of sentences ; the networks operate only on word - embedding representations of text . ### Response: Understanding unstructured text : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","We propose a novel neural attention architecture to tackle machine comprehension tasks , such as answering Cloze - style queries with respect to a document . Unlike previous models , we do not collapse the query into a single vector , instead we deploy an iterative alternating attention mechanism that allows a fine - grained exploration of both the query and the document . Our model outperforms state - of - the - art baselines in standard machine comprehension benchmarks such as CNN news articles and the Children 's Book Test ( CBT ) dataset .",machine comprehension : RESEARCH_PROBLEM; answering Cloze - style queries with respect to a document : RESEARCH_PROBLEM; machine comprehension : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: We propose a novel neural attention architecture to tackle machine comprehension tasks , such as answering Cloze - style queries with respect to a document . Unlike previous models , we do not collapse the query into a single vector , instead we deploy an iterative alternating attention mechanism that allows a fine - grained exploration of both the query and the document . Our model outperforms state - of - the - art baselines in standard machine comprehension benchmarks such as CNN news articles and the Children 's Book Test ( CBT ) dataset . ### Response: machine comprehension : RESEARCH_PROBLEM; answering Cloze - style queries with respect to a document : RESEARCH_PROBLEM; machine comprehension : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","In this paper , we study the problem of question answering when reasoning over multiple facts is required . We propose Query - Reduction Network ( QRN ) , a variant of Recurrent Neural Network ( RNN ) that effectively handles both short - term ( local ) and long - term ( global ) sequential dependencies to reason over multiple facts . QRN considers the context sentences as a sequence of state - changing triggers , and reduces the original query to a more informed query as it observes each trigger ( context sentence ) through time . Our experiments show that QRN produces the state - of - the - art results in bAbI QA and dialog tasks , and in are al goal - oriented dialog dataset . In addition , QRN formulation allows parallelization on RNN 's time axis , saving an order of magnitude in time complexity for training and inference . INTRODUCTION In this paper , we address the problem of question answering ( QA ) when reasoning over multiple facts is required .",question answering when reasoning over multiple facts is required : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: In this paper , we study the problem of question answering when reasoning over multiple facts is required . We propose Query - Reduction Network ( QRN ) , a variant of Recurrent Neural Network ( RNN ) that effectively handles both short - term ( local ) and long - term ( global ) sequential dependencies to reason over multiple facts . QRN considers the context sentences as a sequence of state - changing triggers , and reduces the original query to a more informed query as it observes each trigger ( context sentence ) through time . Our experiments show that QRN produces the state - of - the - art results in bAbI QA and dialog tasks , and in are al goal - oriented dialog dataset . In addition , QRN formulation allows parallelization on RNN 's time axis , saving an order of magnitude in time complexity for training and inference . INTRODUCTION In this paper , we address the problem of question answering ( QA ) when reasoning over multiple facts is required . ### Response: question answering when reasoning over multiple facts is required : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","We present a memory augmented neural network for natural language understanding : Neural Semantic Encoders . NSE is equipped with a novel memory update rule and has a variable sized encoding memory that evolves overtime and maintains the understanding of input sequences through read , compose and write operations . NSE can also access 1 multiple and shared memories . In this paper , we demonstrated the effectiveness and the flexibility of NSE on five different natural language tasks : natural language inference , question answering , sentence classification , document sentiment analysis and machine translation where NSE achieved state - of - the - art performance when evaluated on publically available benchmarks . For example , our shared - memory model showed an encouraging result on neural machine translation , improving an attention - based baseline by approximately 1.0 BLEU . Recurrent neural networks ( RNNs ) have been successful for modeling sequences [ 1 ] .",natural language understanding : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: We present a memory augmented neural network for natural language understanding : Neural Semantic Encoders . NSE is equipped with a novel memory update rule and has a variable sized encoding memory that evolves overtime and maintains the understanding of input sequences through read , compose and write operations . NSE can also access 1 multiple and shared memories . In this paper , we demonstrated the effectiveness and the flexibility of NSE on five different natural language tasks : natural language inference , question answering , sentence classification , document sentiment analysis and machine translation where NSE achieved state - of - the - art performance when evaluated on publically available benchmarks . For example , our shared - memory model showed an encouraging result on neural machine translation , improving an attention - based baseline by approximately 1.0 BLEU . Recurrent neural networks ( RNNs ) have been successful for modeling sequences [ 1 ] . ### Response: natural language understanding : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Machine comprehension of text is an important problem in natural language processing . A recently released dataset , the Stanford Question Answering Dataset ( SQuAD ) , offers a large number of real questions and their answers created by humans through crowdsourcing . SQuAD provides a challenging testbed for evaluating machine comprehension algorithms , partly because compared with previous datasets , in SQuAD the answers do not come from a small set of candidate answers and they have variable lengths . We propose an end - to - end neural architecture for the task . The architecture is based on match - LSTM , a model we proposed previously for textual entailment , and Pointer Net , a sequence - to - sequence model proposed by Vinyals et al. ( 2015 ) to constrain the output tokens to be from the input sequences . We propose two ways of using Pointer Net for our task . Our experiments show that both of our two models substantially outperform the best results obtained by Rajpurkar et al. ( 2016 ) using logistic regression and manually crafted features .",Machine comprehension of text : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Machine comprehension of text is an important problem in natural language processing . A recently released dataset , the Stanford Question Answering Dataset ( SQuAD ) , offers a large number of real questions and their answers created by humans through crowdsourcing . SQuAD provides a challenging testbed for evaluating machine comprehension algorithms , partly because compared with previous datasets , in SQuAD the answers do not come from a small set of candidate answers and they have variable lengths . We propose an end - to - end neural architecture for the task . The architecture is based on match - LSTM , a model we proposed previously for textual entailment , and Pointer Net , a sequence - to - sequence model proposed by Vinyals et al. ( 2015 ) to constrain the output tokens to be from the input sequences . We propose two ways of using Pointer Net for our task . Our experiments show that both of our two models substantially outperform the best results obtained by Rajpurkar et al. ( 2016 ) using logistic regression and manually crafted features . ### Response: Machine comprehension of text : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","The reading comprehension task , that asks questions about a given evidence document , is a central problem in natural language understanding . Recent formulations of this task have typically focused on answer selection from a set of candidates pre-defined manually or through the use of an external NLP pipeline . However , Rajpurkar et al . ( 2016 ) recently released the SQUAD dataset in which the answers can be arbitrary strings from the supplied text . In this paper , we focus on this answer extraction task , presenting a novel model architecture that efficiently builds fixed length representations of all spans in the evidence document with a recurrent network . We show that scoring explicit span representations significantly improves performance over other approaches that factor the prediction into separate predictions about words or start and end markers . Our approach improves upon the best published results of Wang & Jiang ( 2016 ) by 5 % and decreases the error of Rajpurkar et al. 's baseline by > 50 %. Recently , Rajpurkar et al. ( 2016 ) released the less restricted SQUAD dataset 1 that does not place any constraints on the set of allowed answers , other than that they should be drawn from the evidence document .",reading comprehension : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: The reading comprehension task , that asks questions about a given evidence document , is a central problem in natural language understanding . Recent formulations of this task have typically focused on answer selection from a set of candidates pre-defined manually or through the use of an external NLP pipeline . However , Rajpurkar et al . ( 2016 ) recently released the SQUAD dataset in which the answers can be arbitrary strings from the supplied text . In this paper , we focus on this answer extraction task , presenting a novel model architecture that efficiently builds fixed length representations of all spans in the evidence document with a recurrent network . We show that scoring explicit span representations significantly improves performance over other approaches that factor the prediction into separate predictions about words or start and end markers . Our approach improves upon the best published results of Wang & Jiang ( 2016 ) by 5 % and decreases the error of Rajpurkar et al. 's baseline by > 50 %. Recently , Rajpurkar et al. ( 2016 ) released the less restricted SQUAD dataset 1 that does not place any constraints on the set of allowed answers , other than that they should be drawn from the evidence document . ### Response: reading comprehension : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","We present a novel end - to - end neural model to extract entities and relations between them . Our recurrent neural network based model captures both word sequence and dependency tree substructure information by stacking bidirectional treestructured LSTM - RNNs on bidirectional sequential LSTM - RNNs . This allows our model to jointly represent both entities and relations with shared parameters in a single model . We further encourage detection of entities during training and use of entity information in relation extraction via entity pretraining and scheduled sampling . Our model improves over the stateof - the - art feature - based model on end -toend relation extraction , achieving 12.1 % and 5.7 % relative error reductions in F1score on ACE2005 and ACE2004 , respectively . We also show that our LSTM - RNN based model compares favorably to the state - of - the - art CNN based model ( in F1-score ) on nominal relation classification ( Sem Eval - 2010 Task 8 ) . Finally , we present an extensive ablation analysis of several model components .",end - to - end neural model to extract entities and relations between them : RESEARCH_PROBLEM; jointly represent both entities and relations with shared parameters in a single model : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: We present a novel end - to - end neural model to extract entities and relations between them . Our recurrent neural network based model captures both word sequence and dependency tree substructure information by stacking bidirectional treestructured LSTM - RNNs on bidirectional sequential LSTM - RNNs . This allows our model to jointly represent both entities and relations with shared parameters in a single model . We further encourage detection of entities during training and use of entity information in relation extraction via entity pretraining and scheduled sampling . Our model improves over the stateof - the - art feature - based model on end -toend relation extraction , achieving 12.1 % and 5.7 % relative error reductions in F1score on ACE2005 and ACE2004 , respectively . We also show that our LSTM - RNN based model compares favorably to the state - of - the - art CNN based model ( in F1-score ) on nominal relation classification ( Sem Eval - 2010 Task 8 ) . Finally , we present an extensive ablation analysis of several model components . ### Response: end - to - end neural model to extract entities and relations between them : RESEARCH_PROBLEM; jointly represent both entities and relations with shared parameters in a single model : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","State - of - the - art models for joint entity recognition and relation extraction strongly rely on external natural language processing ( NLP ) tools such as POS ( part - of - speech ) taggers and dependency parsers . Thus , the performance of such joint models depends on the quality of the features obtained from these NLP tools . However , these features are not always accurate for various languages and contexts . In this paper , we propose a joint neural model which performs entity recognition and relation extraction simultaneously , without the need of any manually extracted features or the use of any external tool . Specifically , we model the entity recognition task using a CRF ( Conditional Random Fields ) layer and the relation extraction task as a multi-head selection problem ( i.e. , potentially identify multiple relations for each entity ) . We present an extensive experimental setup , to demonstrate the effectiveness of our method using datasets from various contexts ( i.e. , news , biomedical , real estate ) and languages ( i.e. , English , Dutch ) . Our model outperforms the previous neural models that use automatically extracted features , while it performs within a reasonable margin of feature - based neural models , or even beats them .",entity recognition and relation extraction simultaneously : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: State - of - the - art models for joint entity recognition and relation extraction strongly rely on external natural language processing ( NLP ) tools such as POS ( part - of - speech ) taggers and dependency parsers . Thus , the performance of such joint models depends on the quality of the features obtained from these NLP tools . However , these features are not always accurate for various languages and contexts . In this paper , we propose a joint neural model which performs entity recognition and relation extraction simultaneously , without the need of any manually extracted features or the use of any external tool . Specifically , we model the entity recognition task using a CRF ( Conditional Random Fields ) layer and the relation extraction task as a multi-head selection problem ( i.e. , potentially identify multiple relations for each entity ) . We present an extensive experimental setup , to demonstrate the effectiveness of our method using datasets from various contexts ( i.e. , news , biomedical , real estate ) and languages ( i.e. , English , Dutch ) . Our model outperforms the previous neural models that use automatically extracted features , while it performs within a reasonable margin of feature - based neural models , or even beats them . ### Response: entity recognition and relation extraction simultaneously : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Adversarial training ( AT ) is a regularization method that can be used to improve the robustness of neural network methods by adding small perturbations in the training data . We show how to use AT for the tasks of entity recognition and relation extraction . In particular , we demonstrate that applying AT to a general purpose baseline model for jointly extracting entities and relations , allows improving the state - of - the - art effectiveness on several datasets in different contexts ( i.e. , news , biomedical , and real estate data ) and for different languages ( English and Dutch ) .",entity recognition and relation extraction : RESEARCH_PROBLEM; jointly extracting entities and relations : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Adversarial training ( AT ) is a regularization method that can be used to improve the robustness of neural network methods by adding small perturbations in the training data . We show how to use AT for the tasks of entity recognition and relation extraction . In particular , we demonstrate that applying AT to a general purpose baseline model for jointly extracting entities and relations , allows improving the state - of - the - art effectiveness on several datasets in different contexts ( i.e. , news , biomedical , and real estate data ) and for different languages ( English and Dutch ) . ### Response: entity recognition and relation extraction : RESEARCH_PROBLEM; jointly extracting entities and relations : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Dependency trees help relation extraction models capture long - range relations between words . However , existing dependency - based models either neglect crucial information ( e.g. , negation ) by pruning the dependency trees too aggressively , or are computationally inefficient because it is difficult to parallelize over different tree structures . We propose an extension of graph convolutional networks that is tailored for relation extraction , which pools information over arbitrary dependency structures efficiently in parallel . To incorporate relevant information while maximally removing irrelevant content , we further apply a novel pruning strategy to the input trees by keeping words immediately around the shortest path between the two entities among which a relation might hold . The resulting model achieves state - of - the - art performance on the large - scale TACRED dataset , outperforming existing sequence and dependency - based neural models . We also show through detailed analysis that this model has complementary strengths to sequence models , and combining them further improves the state of the art . * Equal contribution .",capture long - range relations between words : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Dependency trees help relation extraction models capture long - range relations between words . However , existing dependency - based models either neglect crucial information ( e.g. , negation ) by pruning the dependency trees too aggressively , or are computationally inefficient because it is difficult to parallelize over different tree structures . We propose an extension of graph convolutional networks that is tailored for relation extraction , which pools information over arbitrary dependency structures efficiently in parallel . To incorporate relevant information while maximally removing irrelevant content , we further apply a novel pruning strategy to the input trees by keeping words immediately around the shortest path between the two entities among which a relation might hold . The resulting model achieves state - of - the - art performance on the large - scale TACRED dataset , outperforming existing sequence and dependency - based neural models . We also show through detailed analysis that this model has complementary strengths to sequence models , and combining them further improves the state of the art . * Equal contribution . ### Response: capture long - range relations between words : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","We propose a neural network model for joint extraction of named entities and relations between them , without any hand - crafted features . The key contribution of our model is to extend a BiLSTM - CRF - based entity recognition model with a deep biaffine attention layer to model second - order interactions between latent features for relation classification , specifically attending to the role of an entity in a directional relationship . On the benchmark "" relation and entity recognition "" dataset CoNLL04 , experimental results show that our model outperforms previous models , producing new state - of - the - art performances .",joint extraction of named entities and relations between them : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: We propose a neural network model for joint extraction of named entities and relations between them , without any hand - crafted features . The key contribution of our model is to extend a BiLSTM - CRF - based entity recognition model with a deep biaffine attention layer to model second - order interactions between latent features for relation classification , specifically attending to the role of an entity in a directional relationship . On the benchmark "" relation and entity recognition "" dataset CoNLL04 , experimental results show that our model outperforms previous models , producing new state - of - the - art performances . ### Response: joint extraction of named entities and relations between them : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Classifying semantic relations between entity pairs in sentences is an important task in Natural Language Processing ( NLP ) . Most previous models for relation classification rely on the high - level lexical and syntatic features obtained by NLP tools such as WordNet , dependency parser , part - ofspeech ( POS ) tagger , and named entity recognizers ( NER ) . In addition , state - of - the - art neural models based on attention mechanisms do not fully utilize information of entity that maybe the most crucial features for relation classification . To address these issues , we propose a novel end - to - end recurrent neural model which incorporates an entity - aware attention mechanism with a latent entity typing ( LET ) method . Our model not only utilizes entities and their latent types as features effectively but also is more interpretable by visualizing attention mechanisms applied to our model and results of LET . Experimental results on the SemEval - 2010 Task 8 , one of the most popular relation classification task , demonstrate that our model outperforms existing state - of the - art models without any high - level features .",Classifying semantic relations between entity pairs in sentences : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Classifying semantic relations between entity pairs in sentences is an important task in Natural Language Processing ( NLP ) . Most previous models for relation classification rely on the high - level lexical and syntatic features obtained by NLP tools such as WordNet , dependency parser , part - ofspeech ( POS ) tagger , and named entity recognizers ( NER ) . In addition , state - of - the - art neural models based on attention mechanisms do not fully utilize information of entity that maybe the most crucial features for relation classification . To address these issues , we propose a novel end - to - end recurrent neural model which incorporates an entity - aware attention mechanism with a latent entity typing ( LET ) method . Our model not only utilizes entities and their latent types as features effectively but also is more interpretable by visualizing attention mechanisms applied to our model and results of LET . Experimental results on the SemEval - 2010 Task 8 , one of the most popular relation classification task , demonstrate that our model outperforms existing state - of the - art models without any high - level features . ### Response: Classifying semantic relations between entity pairs in sentences : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Motivation : Biomedical text mining is becoming increasingly important as the number of biomedical documents rapidly grows . With the progress in natural language processing ( NLP ) , extracting valuable information from biomedical literature has gained popularity among researchers , and deep learning has boosted the development of effective biomedical text mining models . However , directly applying the advancements in NLP to biomedical text mining often yields unsatisfactory results due to a word distribution shift from general domain corpora to biomedical corpora . In this article , we investigate how the recently introduced pre-trained language model BERT can be adapted for biomedical corpora . Results : We introduce BioBERT ( Bidirectional Encoder Representations from Transformers for Biomedical Text Mining ) , which is a domain - specific language representation model pre-trained on large - scale biomedical corpora .",extracting valuable information from biomedical literature : RESEARCH_PROBLEM; biomedical text mining often yields unsatisfactory results due to a word distribution shift from general domain corpora to biomedical corpora : RESEARCH_PROBLEM; pre-trained language model BERT can be adapted for biomedical corpora : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Motivation : Biomedical text mining is becoming increasingly important as the number of biomedical documents rapidly grows . With the progress in natural language processing ( NLP ) , extracting valuable information from biomedical literature has gained popularity among researchers , and deep learning has boosted the development of effective biomedical text mining models . However , directly applying the advancements in NLP to biomedical text mining often yields unsatisfactory results due to a word distribution shift from general domain corpora to biomedical corpora . In this article , we investigate how the recently introduced pre-trained language model BERT can be adapted for biomedical corpora . Results : We introduce BioBERT ( Bidirectional Encoder Representations from Transformers for Biomedical Text Mining ) , which is a domain - specific language representation model pre-trained on large - scale biomedical corpora . ### Response: extracting valuable information from biomedical literature : RESEARCH_PROBLEM; biomedical text mining often yields unsatisfactory results due to a word distribution shift from general domain corpora to biomedical corpora : RESEARCH_PROBLEM; pre-trained language model BERT can be adapted for biomedical corpora : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","The state - of - the - art solutions for extracting multiple entity - relations from an input paragraph always require a multiple - pass encoding on the input . This paper proposes a new solution that can complete the multiple entityrelations extraction task with only one - pass encoding on the input corpus , and achieve a new state - of - the - art accuracy performance , as demonstrated in the ACE 2005 benchmark . Our solution is built on top of the pre-trained self - attentive models ( Transformer ) . Since our method uses a single - pass to compute all relations at once , it scales to larger datasets easily ; which makes it more usable in real - world applications . 1",extracting multiple entity - relations from an input paragraph : RESEARCH_PROBLEM; multiple entityrelations extraction task with only one - pass : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: The state - of - the - art solutions for extracting multiple entity - relations from an input paragraph always require a multiple - pass encoding on the input . This paper proposes a new solution that can complete the multiple entityrelations extraction task with only one - pass encoding on the input corpus , and achieve a new state - of - the - art accuracy performance , as demonstrated in the ACE 2005 benchmark . Our solution is built on top of the pre-trained self - attentive models ( Transformer ) . Since our method uses a single - pass to compute all relations at once , it scales to larger datasets easily ; which makes it more usable in real - world applications . 1 ### Response: extracting multiple entity - relations from an input paragraph : RESEARCH_PROBLEM; multiple entityrelations extraction task with only one - pass : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Obtaining large - scale annotated data for NLP tasks in the scientific domain is challenging and expensive . We release SCIBERT , a pretrained language model based on BERT ( Devlin et al. , 2019 ) to address the lack of high - quality , large - scale labeled scientific data . SCIBERT leverages unsupervised pretraining on a large multi-domain corpus of scientific publications to improve performance on downstream scientific NLP tasks . We evaluate on a suite of tasks including sequence tagging , sentence classification and dependency parsing , with datasets from a variety of scientific domains . We demonstrate statistically significant improvements over BERT and achieve new state - of - theart results on several of these tasks . The code and pretrained models are available at https://github.com/allenai/scibert/.","Obtaining large - scale annotated data for NLP tasks in the scientific domain : RESEARCH_PROBLEM; address the lack of high - quality , large - scale labeled scientific data : RESEARCH_PROBLEM","Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Obtaining large - scale annotated data for NLP tasks in the scientific domain is challenging and expensive . We release SCIBERT , a pretrained language model based on BERT ( Devlin et al. , 2019 ) to address the lack of high - quality , large - scale labeled scientific data . SCIBERT leverages unsupervised pretraining on a large multi-domain corpus of scientific publications to improve performance on downstream scientific NLP tasks . We evaluate on a suite of tasks including sequence tagging , sentence classification and dependency parsing , with datasets from a variety of scientific domains . We demonstrate statistically significant improvements over BERT and achieve new state - of - theart results on several of these tasks . The code and pretrained models are available at https://github.com/allenai/scibert/. ### Response: Obtaining large - scale annotated data for NLP tasks in the scientific domain : RESEARCH_PROBLEM; address the lack of high - quality , large - scale labeled scientific data : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","One - hot CNN ( convolutional neural network ) has been shown to be effective for text categorization ( Johnson & Zhang , 2015a ; b ) . We view it as a special case of a general framework which jointly trains a linear model with a non-linear feature generator consisting of ' text region embedding + pooling ' . Under this framework , we explore a more sophisticated region embedding method using Long Short - Term Memory ( LSTM ) . LSTM can embed text regions of variable ( and possibly large ) sizes , whereas the region size needs to be fixed in a CNN . We seek effective and efficient use of LSTM for this purpose in the supervised and semi-supervised settings . The best results were obtained by combining region embeddings in the form of LSTM and convolution layers trained on unlabeled data . The results indicate that on this task , embeddings of text regions , which can convey complex concepts , are more useful than embeddings of single words in isolation .",text categorization : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: One - hot CNN ( convolutional neural network ) has been shown to be effective for text categorization ( Johnson & Zhang , 2015a ; b ) . We view it as a special case of a general framework which jointly trains a linear model with a non-linear feature generator consisting of ' text region embedding + pooling ' . Under this framework , we explore a more sophisticated region embedding method using Long Short - Term Memory ( LSTM ) . LSTM can embed text regions of variable ( and possibly large ) sizes , whereas the region size needs to be fixed in a CNN . We seek effective and efficient use of LSTM for this purpose in the supervised and semi-supervised settings . The best results were obtained by combining region embeddings in the form of LSTM and convolution layers trained on unlabeled data . The results indicate that on this task , embeddings of text regions , which can convey complex concepts , are more useful than embeddings of single words in isolation . ### Response: text categorization : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","This paper explores a simple and efficient baseline for text classification . Our experiments show that our fast text classifier fastText is often on par with deep learning classifiers in terms of accuracy , and many orders of magnitude faster for training and evaluation . We can train fastText on more than one billion words in less than ten minutes using a standard multicore CPU , and classify half a million sentences among 312K classes in less than a minute .",text classification : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: This paper explores a simple and efficient baseline for text classification . Our experiments show that our fast text classifier fastText is often on par with deep learning classifiers in terms of accuracy , and many orders of magnitude faster for training and evaluation . We can train fastText on more than one billion words in less than ten minutes using a standard multicore CPU , and classify half a million sentences among 312K classes in less than a minute . ### Response: text classification : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Text preprocessing is often the first step in the pipeline of a Natural Language Processing ( NLP ) system , with potential impact in its final performance . Despite its importance , text preprocessing has not received much attention in the deep learning literature . In this paper we investigate the impact of simple text preprocessing decisions ( particularly tokenizing , lemmatizing , lowercasing and multiword grouping ) on the performance of a standard neural text classifier . We perform an extensive evaluation on standard benchmarks from text categorization and sentiment analysis . While our experiments show that a simple tokenization of input text is generally adequate , they also highlight significant degrees of variability across preprocessing techniques . This reveals the importance of paying attention to this usually - overlooked step in the pipeline , particularly when comparing different models . Finally , our evaluation provides insights into the best preprocessing practices for training word embeddings .",Text preprocessing : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Text preprocessing is often the first step in the pipeline of a Natural Language Processing ( NLP ) system , with potential impact in its final performance . Despite its importance , text preprocessing has not received much attention in the deep learning literature . In this paper we investigate the impact of simple text preprocessing decisions ( particularly tokenizing , lemmatizing , lowercasing and multiword grouping ) on the performance of a standard neural text classifier . We perform an extensive evaluation on standard benchmarks from text categorization and sentiment analysis . While our experiments show that a simple tokenization of input text is generally adequate , they also highlight significant degrees of variability across preprocessing techniques . This reveals the importance of paying attention to this usually - overlooked step in the pipeline , particularly when comparing different models . Finally , our evaluation provides insights into the best preprocessing practices for training word embeddings . ### Response: Text preprocessing : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Convolutional neural networks ( CNNs ) have recently emerged as a popular building block for natural language processing ( NLP ) . Despite their success , most existing CNN models employed in NLP share the same learned ( and static ) set of filters for all input sentences . In this paper , we consider an approach of using a small meta network to learn contextsensitive convolutional filters for text processing . The role of meta network is to abstract the contextual information of a sentence or document into a set of input -aware filters . We further generalize this framework to model sentence pairs , where a bidirectional filter generation mechanism is introduced to encapsulate co-dependent sentence representations . In our benchmarks on four different tasks , including ontology classification , sentiment analysis , answer sentence selection , and paraphrase identification , our proposed model , a modified CNN with context - sensitive filters , consistently outperforms the standard CNN and attention - based CNN baselines . By visualizing the learned context - sensitive filters , we further validate and rationalize the effectiveness of proposed framework .",learn contextsensitive convolutional filters for text processing : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Convolutional neural networks ( CNNs ) have recently emerged as a popular building block for natural language processing ( NLP ) . Despite their success , most existing CNN models employed in NLP share the same learned ( and static ) set of filters for all input sentences . In this paper , we consider an approach of using a small meta network to learn contextsensitive convolutional filters for text processing . The role of meta network is to abstract the contextual information of a sentence or document into a set of input -aware filters . We further generalize this framework to model sentence pairs , where a bidirectional filter generation mechanism is introduced to encapsulate co-dependent sentence representations . In our benchmarks on four different tasks , including ontology classification , sentiment analysis , answer sentence selection , and paraphrase identification , our proposed model , a modified CNN with context - sensitive filters , consistently outperforms the standard CNN and attention - based CNN baselines . By visualizing the learned context - sensitive filters , we further validate and rationalize the effectiveness of proposed framework . ### Response: learn contextsensitive convolutional filters for text processing : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","We present models for encoding sentences into embedding vectors that specifically target transfer learning to other NLP tasks . The models are efficient and result in accurate performance on diverse transfer tasks . Two variants of the encoding models allow for trade - offs between accuracy and compute resources . For both variants , we investigate and report the relationship between model complexity , resource consumption , the availability of transfer task training data , and task performance . Comparisons are made with baselines that use word level transfer learning via pretrained word embeddings as well as baselines do not use any transfer learning . We find that transfer learning using sentence embeddings tends to outperform word level transfer . With transfer learning via sentence embeddings , we observe surprisingly good performance with minimal amounts of supervised training data for a transfer task .",encoding sentences into embedding vectors that specifically target transfer learning : RESEARCH_PROBLEM; transfer learning using sentence embeddings : RESEARCH_PROBLEM; transfer learning via sentence embeddings : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: We present models for encoding sentences into embedding vectors that specifically target transfer learning to other NLP tasks . The models are efficient and result in accurate performance on diverse transfer tasks . Two variants of the encoding models allow for trade - offs between accuracy and compute resources . For both variants , we investigate and report the relationship between model complexity , resource consumption , the availability of transfer task training data , and task performance . Comparisons are made with baselines that use word level transfer learning via pretrained word embeddings as well as baselines do not use any transfer learning . We find that transfer learning using sentence embeddings tends to outperform word level transfer . With transfer learning via sentence embeddings , we observe surprisingly good performance with minimal amounts of supervised training data for a transfer task . ### Response: encoding sentences into embedding vectors that specifically target transfer learning : RESEARCH_PROBLEM; transfer learning using sentence embeddings : RESEARCH_PROBLEM; transfer learning via sentence embeddings : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Many deep learning architectures have been proposed to model the compositionality in text sequences , requiring a substantial number of parameters and expensive computations . However , there has not been a rigorous evaluation regarding the added value of sophisticated compositional functions . In this paper , we conduct a point - by - point comparative study between Simple Word - Embeddingbased Models ( SWEMs ) , consisting of parameter - free pooling operations , relative to word - embedding - based RNN / CNN models . Surprisingly , SWEMs exhibit comparable or even superior performance in the majority of cases considered . Based upon this understanding , we propose two additional pooling strategies over learned word embeddings : ( i ) a max - pooling operation for improved interpretability ; and ( ii ) a hierarchical pooling operation , which preserves spatial ( n - gram ) information within text sequences . We present experiments on 17 datasets encompassing three tasks : ( i ) ( long ) document classification ; ( ii ) text sequence matching ; and ( iii ) short text tasks , including classification and tagging . The source code and datasets can be obtained from https://github.com/dinghanshen/SWEM .",model the compositionality in text sequences : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Many deep learning architectures have been proposed to model the compositionality in text sequences , requiring a substantial number of parameters and expensive computations . However , there has not been a rigorous evaluation regarding the added value of sophisticated compositional functions . In this paper , we conduct a point - by - point comparative study between Simple Word - Embeddingbased Models ( SWEMs ) , consisting of parameter - free pooling operations , relative to word - embedding - based RNN / CNN models . Surprisingly , SWEMs exhibit comparable or even superior performance in the majority of cases considered . Based upon this understanding , we propose two additional pooling strategies over learned word embeddings : ( i ) a max - pooling operation for improved interpretability ; and ( ii ) a hierarchical pooling operation , which preserves spatial ( n - gram ) information within text sequences . We present experiments on 17 datasets encompassing three tasks : ( i ) ( long ) document classification ; ( ii ) text sequence matching ; and ( iii ) short text tasks , including classification and tagging . The source code and datasets can be obtained from https://github.com/dinghanshen/SWEM . ### Response: model the compositionality in text sequences : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Spoken Language Understanding (SLU) systems parse speech into semantic structures like dialog acts and slots. This involves the use of an Automatic Speech Recognizer (ASR) to transcribe speech into multiple text alternatives (hypotheses). Transcription errors, common in ASRs, impact downstream SLU performance negatively. Approaches to mitigate such errors involve using richer information from the ASR, either in form of N-best hypotheses or word-lattices. We hypothesize that transformer models learn better with a simpler utterance representation using the concatenation of the N-best ASR alternatives, where each alternative is separated by a special delimiter [SEP]. In our work, we test our hypothesis by using concatenated N-best ASR alternatives as the input to transformer encoder models, namely BERT and XLM-RoBERT a, and achieve performance equivalent to the prior state-of-the-art model on DSTC2 dataset. We also show that our approach significantly outperforms the prior state-of-the-art when subjected to the low data regime. Additionally, this methodology is accessible to users of third-party ASR APIs which do not provide word-lattice information.",Spoken Language Understanding : RESEARCH_PROBLEM; BERT : METHOD; XLM-RoBERT : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Spoken Language Understanding (SLU) systems parse speech into semantic structures like dialog acts and slots. This involves the use of an Automatic Speech Recognizer (ASR) to transcribe speech into multiple text alternatives (hypotheses). Transcription errors, common in ASRs, impact downstream SLU performance negatively. Approaches to mitigate such errors involve using richer information from the ASR, either in form of N-best hypotheses or word-lattices. We hypothesize that transformer models learn better with a simpler utterance representation using the concatenation of the N-best ASR alternatives, where each alternative is separated by a special delimiter [SEP]. In our work, we test our hypothesis by using concatenated N-best ASR alternatives as the input to transformer encoder models, namely BERT and XLM-RoBERT a, and achieve performance equivalent to the prior state-of-the-art model on DSTC2 dataset. We also show that our approach significantly outperforms the prior state-of-the-art when subjected to the low data regime. Additionally, this methodology is accessible to users of third-party ASR APIs which do not provide word-lattice information. ### Response: Spoken Language Understanding : RESEARCH_PROBLEM; BERT : METHOD; XLM-RoBERT : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Question Answering (QA) is a task in natural language processing that has seen considerable growth after the advent of transformers. There has been a surge in QA datasets that have been proposed to challenge natural language processing models to improve human and existing model performance. Many pre-trained language models have proven to be incredibly effective at the task of extractive question answering. However, generalizability remains as a challenge for the majority of these models. That is, some datasets require models to reason more than others. In this paper, we train various pre-trained language models and fine-tune them on multiple question answering datasets of varying levels of difficulty to determine which of the models are capable of generalizing the most comprehensively across different datasets. Further, we propose a new architecture, BERT-BiLSTM, and compare it with other language models to determine if adding more bidirectionality can improve model performance. Using the F1-score as our metric, we find that the RoBERTa and BART pre-trained models perform the best across all datasets and that our BERT-BiLSTM model outperforms the baseline BERT model.",Question Answering : RESEARCH_PROBLEM; RoBERTa : METHOD; BART : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Question Answering (QA) is a task in natural language processing that has seen considerable growth after the advent of transformers. There has been a surge in QA datasets that have been proposed to challenge natural language processing models to improve human and existing model performance. Many pre-trained language models have proven to be incredibly effective at the task of extractive question answering. However, generalizability remains as a challenge for the majority of these models. That is, some datasets require models to reason more than others. In this paper, we train various pre-trained language models and fine-tune them on multiple question answering datasets of varying levels of difficulty to determine which of the models are capable of generalizing the most comprehensively across different datasets. Further, we propose a new architecture, BERT-BiLSTM, and compare it with other language models to determine if adding more bidirectionality can improve model performance. Using the F1-score as our metric, we find that the RoBERTa and BART pre-trained models perform the best across all datasets and that our BERT-BiLSTM model outperforms the baseline BERT model. ### Response: Question Answering : RESEARCH_PROBLEM; RoBERTa : METHOD; BART : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Optimal trade execution is an important problem faced by essentially all traders. Much research into optimal execution uses stringent model assumptions and applies continuous time stochastic control to solve them. Here, we instead take a model free approach and develop a variation of Deep Q-Learning to estimate the optimal actions of a trader. The model is a fully connected Neural Network trained using Experience Replay and Double DQN with input features given by the current state of the limit order book, other trading signals, and available execution actions, while the output is the Q-value function estimating the future rewards under an arbitrary action. We apply our model to nine different stocks and find that it outperforms the standard benchmark approach on most stocks using the measures of (i) mean and median out-performance, (ii) probability of out-performance, and (iii) gain-loss ratios.",Q-Learning : RESEARCH_PROBLEM; Experience Replay : METHOD; Double DQN : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Optimal trade execution is an important problem faced by essentially all traders. Much research into optimal execution uses stringent model assumptions and applies continuous time stochastic control to solve them. Here, we instead take a model free approach and develop a variation of Deep Q-Learning to estimate the optimal actions of a trader. The model is a fully connected Neural Network trained using Experience Replay and Double DQN with input features given by the current state of the limit order book, other trading signals, and available execution actions, while the output is the Q-value function estimating the future rewards under an arbitrary action. We apply our model to nine different stocks and find that it outperforms the standard benchmark approach on most stocks using the measures of (i) mean and median out-performance, (ii) probability of out-performance, and (iii) gain-loss ratios. ### Response: Q-Learning : RESEARCH_PROBLEM; Experience Replay : METHOD; Double DQN : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Automatic Speech Recognition (ASR) robustness toward slot entities are critical in e-commerce voice assistants that involve monetary transactions and purchases. Along with effective domain adaptation, it is intuitive that cross utterance contextual cues play an important role in disambiguating domain specific content words from speech. In this paper, we investigate various techniques to improve contextualization, content word robustness and domain adaptation of a Transformer-XL neural language model (NLM) to rescore ASR N-best hypotheses. To improve contextualization, we utilize turn level dialogue acts along with cross utterance context carry over. Additionally, to adapt our domain-general NLM towards e-commerce on-the-fly, we use embeddings derived from a finetuned masked LM on in-domain data. Finally, to improve robustness towards in-domain content words, we propose a multi-task model that can jointly perform content word detection and language modeling tasks. Compared to a non-contextual LSTM LM baseline, our best performing NLM rescorer results in a content WER reduction of 19.2% on e-commerce audio test set and a slot labeling F1 improvement of 6.4%.",Speech Recognition : RESEARCH_PROBLEM; Transformer-XL : METHOD; LSTM : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Automatic Speech Recognition (ASR) robustness toward slot entities are critical in e-commerce voice assistants that involve monetary transactions and purchases. Along with effective domain adaptation, it is intuitive that cross utterance contextual cues play an important role in disambiguating domain specific content words from speech. In this paper, we investigate various techniques to improve contextualization, content word robustness and domain adaptation of a Transformer-XL neural language model (NLM) to rescore ASR N-best hypotheses. To improve contextualization, we utilize turn level dialogue acts along with cross utterance context carry over. Additionally, to adapt our domain-general NLM towards e-commerce on-the-fly, we use embeddings derived from a finetuned masked LM on in-domain data. Finally, to improve robustness towards in-domain content words, we propose a multi-task model that can jointly perform content word detection and language modeling tasks. Compared to a non-contextual LSTM LM baseline, our best performing NLM rescorer results in a content WER reduction of 19.2% on e-commerce audio test set and a slot labeling F1 improvement of 6.4%. ### Response: Speech Recognition : RESEARCH_PROBLEM; Transformer-XL : METHOD; LSTM : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Key properties of brain-inspired hyperdimensional (HD) computing make it aprime candidate for energy-efficient and fast learning in biosignal processing.The main challenge is however to formulate embedding methods that map biosignalmeasures to a binary HD space. In this paper, we explore variety of suchembedding methods and examine them with a challenging application of motorimagery brain-computer interface (MI-BCI) from electroencephalography (EEG )recordings. We explore embedding methods including random projections,quantization based thermometer and Gray coding, and learning HD representationsusing end-to-end training. All these methods, differing in complexity, aim torepresent EEG signals in binary HD space, e.g. with 10,000 bits. This leads todevelopment of a set of HD learning and classification methods that can beselectively chosen (or configured) based on accuracy and/or computationalcomplexity requirements of a given task. We compare them with state-of-the-artlinear support vector machine (SVM ) on an NVIDIA TX2 board using the 4-classBCI competition IV-2a dataset as well as a new 3-class dataset. Compared toSVM , results on 3-class dataset show that simple thermometer embedding achievesmoderate average accuracy (79.56% vs. 82.67%) with 26.8$\times$ faster trainingtime and 22.3$\times$ lower energy; on the other hand, switching to end-to-endtraining with learned HD representations wipes out these training benefitswhile boosting the accuracy to 84.22% (1.55% higher than SVM ). Similar trend isobserved on the 4-class dataset where SVM achieves on average 74.29%: thethermometer embedding achieves 89.9$\times$ faster training time and58.7$\times$ lower energy, but a lower accuracy (67.09%) than the learnedrepresentation of 72.54%.",(EEG : RESEARCH_PROBLEM; EEG : RESEARCH_PROBLEM; (SVM : METHOD; toSVM : METHOD; SVM : METHOD; SVM : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Key properties of brain-inspired hyperdimensional (HD) computing make it aprime candidate for energy-efficient and fast learning in biosignal processing.The main challenge is however to formulate embedding methods that map biosignalmeasures to a binary HD space. In this paper, we explore variety of suchembedding methods and examine them with a challenging application of motorimagery brain-computer interface (MI-BCI) from electroencephalography (EEG )recordings. We explore embedding methods including random projections,quantization based thermometer and Gray coding, and learning HD representationsusing end-to-end training. All these methods, differing in complexity, aim torepresent EEG signals in binary HD space, e.g. with 10,000 bits. This leads todevelopment of a set of HD learning and classification methods that can beselectively chosen (or configured) based on accuracy and/or computationalcomplexity requirements of a given task. We compare them with state-of-the-artlinear support vector machine (SVM ) on an NVIDIA TX2 board using the 4-classBCI competition IV-2a dataset as well as a new 3-class dataset. Compared toSVM , results on 3-class dataset show that simple thermometer embedding achievesmoderate average accuracy (79.56% vs. 82.67%) with 26.8$\times$ faster trainingtime and 22.3$\times$ lower energy; on the other hand, switching to end-to-endtraining with learned HD representations wipes out these training benefitswhile boosting the accuracy to 84.22% (1.55% higher than SVM ). Similar trend isobserved on the 4-class dataset where SVM achieves on average 74.29%: thethermometer embedding achieves 89.9$\times$ faster training time and58.7$\times$ lower energy, but a lower accuracy (67.09%) than the learnedrepresentation of 72.54%. ### Response: (EEG : RESEARCH_PROBLEM; EEG : RESEARCH_PROBLEM; (SVM : METHOD; toSVM : METHOD; SVM : METHOD; SVM : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","The Dynamical Gaussian Process Latent Variable Models provide an elegant non-parametric framework for learning the low dimensional representations of the high-dimensional time-series. Real world observational studies, however, are often ill-conditioned: the observations can be noisy, not assuming the luxury of relatively complete and equally spaced like those in time series. Such conditions make it difficult to learn reasonable representations in the high dimensional longitudinal data set by way of Gaussian Process Latent Variable Model as well as other dimensionality reduction procedures. In this study, we approach the inference of Gaussian Process Dynamical Systems in Longitudinal scenario by augmenting the bound in the variational approximation to include systematic samples of the unseen observations. We demonstrate the usefulness of this approach on synthetic as well as the human motion capture data set.",Gaussian Process : METHOD; Latent Variable Models : RESEARCH_PROBLEM; Gaussian Process : METHOD; Gaussian Process : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: The Dynamical Gaussian Process Latent Variable Models provide an elegant non-parametric framework for learning the low dimensional representations of the high-dimensional time-series. Real world observational studies, however, are often ill-conditioned: the observations can be noisy, not assuming the luxury of relatively complete and equally spaced like those in time series. Such conditions make it difficult to learn reasonable representations in the high dimensional longitudinal data set by way of Gaussian Process Latent Variable Model as well as other dimensionality reduction procedures. In this study, we approach the inference of Gaussian Process Dynamical Systems in Longitudinal scenario by augmenting the bound in the variational approximation to include systematic samples of the unseen observations. We demonstrate the usefulness of this approach on synthetic as well as the human motion capture data set. ### Response: Gaussian Process : METHOD; Latent Variable Models : RESEARCH_PROBLEM; Gaussian Process : METHOD; Gaussian Process : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","With the recent success of Recurrent Neural Networks (RNNs) in Machine Translation (MT), attention mechanisms have become increasingly popular. The purpose of this paper is two-fold; firstly, we propose a novel attention model on Tree Long Short-Term Memory Networks (Tree-LSTM s), a tree-structured generalization of standard LSTM . Secondly, we study the interaction between attention and syntactic structures, by experimenting with three LSTM variants: bidirectional-LSTM s, Constituency Tree-LSTM s, and Dependency Tree-LSTM s. Our models are evaluated on two semantic relatedness tasks: semantic relatedness scoring for sentence pairs (SemEval 2012, Task 6 and SemEval 2014, Task 1) and paraphrase detection for question pairs (Quora, 2017).",Machine Translation : RESEARCH_PROBLEM; (Tree-LSTM : METHOD; LSTM : METHOD; LSTM : METHOD; bidirectional-LSTM : METHOD; Tree-LSTM : METHOD; Tree-LSTM : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: With the recent success of Recurrent Neural Networks (RNNs) in Machine Translation (MT), attention mechanisms have become increasingly popular. The purpose of this paper is two-fold; firstly, we propose a novel attention model on Tree Long Short-Term Memory Networks (Tree-LSTM s), a tree-structured generalization of standard LSTM . Secondly, we study the interaction between attention and syntactic structures, by experimenting with three LSTM variants: bidirectional-LSTM s, Constituency Tree-LSTM s, and Dependency Tree-LSTM s. Our models are evaluated on two semantic relatedness tasks: semantic relatedness scoring for sentence pairs (SemEval 2012, Task 6 and SemEval 2014, Task 1) and paraphrase detection for question pairs (Quora, 2017). ### Response: Machine Translation : RESEARCH_PROBLEM; (Tree-LSTM : METHOD; LSTM : METHOD; LSTM : METHOD; bidirectional-LSTM : METHOD; Tree-LSTM : METHOD; Tree-LSTM : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","This paper studies video inpainting detection, which localizes an inpainted region in a video both spatially and temporally. In particular, we introduce VIDNet, Video Inpainting Detection Network, which contains a two-stream encoder-decoder architecture with attention module. To reveal artifacts encoded in compression, VIDNet additionally takes in Error Level Analysis frames to augment RGB frames, producing multimodal features at different levels with an encoder. Exploring spatial and temporal relationships, these features are further decoded by a Convolutional LSTM to predict masks of inpainted regions. In addition, when detecting whether a pixel is inpainted or not, we present a quad-directional local attention module that borrows information from its surrounding pixels from four directions. Extensive experiments are conducted to validate our approach. We demonstrate, among other things, that VIDNet not only outperforms by clear margins alternative inpainting detection methods but also generalizes well on novel videos that are unseen during training.",Video Inpainting : RESEARCH_PROBLEM; LSTM : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: This paper studies video inpainting detection, which localizes an inpainted region in a video both spatially and temporally. In particular, we introduce VIDNet, Video Inpainting Detection Network, which contains a two-stream encoder-decoder architecture with attention module. To reveal artifacts encoded in compression, VIDNet additionally takes in Error Level Analysis frames to augment RGB frames, producing multimodal features at different levels with an encoder. Exploring spatial and temporal relationships, these features are further decoded by a Convolutional LSTM to predict masks of inpainted regions. In addition, when detecting whether a pixel is inpainted or not, we present a quad-directional local attention module that borrows information from its surrounding pixels from four directions. Extensive experiments are conducted to validate our approach. We demonstrate, among other things, that VIDNet not only outperforms by clear margins alternative inpainting detection methods but also generalizes well on novel videos that are unseen during training. ### Response: Video Inpainting : RESEARCH_PROBLEM; LSTM : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Human motion prediction aims to generate future motions based on the observed human motions. Witnessing the success of Recurrent Neural Networks (RNN) in modeling the sequential data, recent works utilize RNN to model human-skeleton motion on the observed motion sequence and predict future human motions. However, these methods did not consider the existence of the spatial coherence among joints and the temporal evolution among skeletons, which reflects the crucial characteristics of human motion in spatiotemporal space. To this end, we propose a novel Skeleton-joint Co-attention Recurrent Neural Networks (SC-RNN) to capture the spatial coherence among joints, and the temporal evolution among skeletons simultaneously on a skeleton-joint co-attention feature map in spatiotemporal space. First, a skeleton-joint feature map is constructed as the representation of the observed motion sequence. Second, we design a new Skeleton-joint Co-Attention (SCA) mechanism to dynamically learn a skeleton-joint co-attention feature map of this skeleton-joint feature map, which can refine the useful observed motion information to predict one future motion. Third, a variant of GRU embedded with SCA collaboratively models the human-skeleton motion and human-joint motion in spatiotemporal space by regarding the skeleton-joint co-attention feature map as the motion context. Experimental results on human motion prediction demonstrate the proposed method outperforms the related methods.",Human motion prediction : RESEARCH_PROBLEM; GRU : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Human motion prediction aims to generate future motions based on the observed human motions. Witnessing the success of Recurrent Neural Networks (RNN) in modeling the sequential data, recent works utilize RNN to model human-skeleton motion on the observed motion sequence and predict future human motions. However, these methods did not consider the existence of the spatial coherence among joints and the temporal evolution among skeletons, which reflects the crucial characteristics of human motion in spatiotemporal space. To this end, we propose a novel Skeleton-joint Co-attention Recurrent Neural Networks (SC-RNN) to capture the spatial coherence among joints, and the temporal evolution among skeletons simultaneously on a skeleton-joint co-attention feature map in spatiotemporal space. First, a skeleton-joint feature map is constructed as the representation of the observed motion sequence. Second, we design a new Skeleton-joint Co-Attention (SCA) mechanism to dynamically learn a skeleton-joint co-attention feature map of this skeleton-joint feature map, which can refine the useful observed motion information to predict one future motion. Third, a variant of GRU embedded with SCA collaboratively models the human-skeleton motion and human-joint motion in spatiotemporal space by regarding the skeleton-joint co-attention feature map as the motion context. Experimental results on human motion prediction demonstrate the proposed method outperforms the related methods. ### Response: Human motion prediction : RESEARCH_PROBLEM; GRU : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Bilevel optimization problems can be used to represent the collaborative interaction between a power system and grid-connected entities, called the followers, such as data centers. Most existing approaches assume that such followers' response behaviors are made available to the power system in the operation decision-making, which may be untenable in reality. This work presents a novel idea of solving bilevel optimization problems without assuming power systems' omniscience. The followers' responses will be represented by a function of the power system's decisions using Gaussian Process Regression. Then the two layers in the bilevel problem can be solved separately by the power system and its followers. This not only avoids the omniscience assumption, but also significantly increases the computational efficiency without compromising accuracy, especially for the problems with a complex lower layer. Moreover, a bilevel critical load restoration model is developed to test the proposed technique. Compared to the conventional methods, the proposed restoration model considers the load-side operation and the varying load marginal value, and can accurately estimate load-side loss and achieve better restoration solutions. Two case studies validate the advantages of the proposed approaches from different perspectives.",bilevel optimization : RESEARCH_PROBLEM; Gaussian Process : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Bilevel optimization problems can be used to represent the collaborative interaction between a power system and grid-connected entities, called the followers, such as data centers. Most existing approaches assume that such followers' response behaviors are made available to the power system in the operation decision-making, which may be untenable in reality. This work presents a novel idea of solving bilevel optimization problems without assuming power systems' omniscience. The followers' responses will be represented by a function of the power system's decisions using Gaussian Process Regression. Then the two layers in the bilevel problem can be solved separately by the power system and its followers. This not only avoids the omniscience assumption, but also significantly increases the computational efficiency without compromising accuracy, especially for the problems with a complex lower layer. Moreover, a bilevel critical load restoration model is developed to test the proposed technique. Compared to the conventional methods, the proposed restoration model considers the load-side operation and the varying load marginal value, and can accurately estimate load-side loss and achieve better restoration solutions. Two case studies validate the advantages of the proposed approaches from different perspectives. ### Response: bilevel optimization : RESEARCH_PROBLEM; Gaussian Process : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","In this work, we propose a two-stage method for named entity recognition (NER ), especially for nested NER . We borrowed the idea from the two-stage Object Detection in computer vision and the way how they construct the loss function. First, a region proposal network generates region candidates and then a second-stage model discriminates and classifies the entity and makes the final prediction. We also designed a special loss function for the second-stage training that predicts the entityness and entity type at the same time. The model is built on top of pretrained BERT encoders, and we tried both BERT base and BERT large models. For experiments, we first applied it to flat NER tasks such as CoNLL2003 and OntoNotes 5.0 and got comparable results with traditional NER models using sequence labeling methodology. We then tested the model on the nested named entity recognition task ACE2005 and Genia, and got F1 score of 85.6$\%$ and 76.8$\%$ respectively. In terms of the second-stage training, we found that adding extra randomly selected regions plays an important role in improving the precision. We also did error profiling to better evaluate the performance of the model in different circumstances for potential improvements in the future.",(NER : RESEARCH_PROBLEM; NER : RESEARCH_PROBLEM; Object Detection : RESEARCH_PROBLEM; BERT : METHOD; BERT : METHOD; BERT : METHOD; NER : RESEARCH_PROBLEM; NER : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: In this work, we propose a two-stage method for named entity recognition (NER ), especially for nested NER . We borrowed the idea from the two-stage Object Detection in computer vision and the way how they construct the loss function. First, a region proposal network generates region candidates and then a second-stage model discriminates and classifies the entity and makes the final prediction. We also designed a special loss function for the second-stage training that predicts the entityness and entity type at the same time. The model is built on top of pretrained BERT encoders, and we tried both BERT base and BERT large models. For experiments, we first applied it to flat NER tasks such as CoNLL2003 and OntoNotes 5.0 and got comparable results with traditional NER models using sequence labeling methodology. We then tested the model on the nested named entity recognition task ACE2005 and Genia, and got F1 score of 85.6$\%$ and 76.8$\%$ respectively. In terms of the second-stage training, we found that adding extra randomly selected regions plays an important role in improving the precision. We also did error profiling to better evaluate the performance of the model in different circumstances for potential improvements in the future. ### Response: (NER : RESEARCH_PROBLEM; NER : RESEARCH_PROBLEM; Object Detection : RESEARCH_PROBLEM; BERT : METHOD; BERT : METHOD; BERT : METHOD; NER : RESEARCH_PROBLEM; NER : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","End-to-end Automatic Speech Recognition (ASR) models are commonly trained over spoken utterances using optimization methods like Stochastic Gradient Descent (SGD ). In distributed settings like Federated Learning, model training requires transmission of gradients over a network. In this work, we design the first method for revealing the identity of the speaker of a training utterance with access only to a gradient. We propose Hessian-Free Gradients Matching, an input reconstruction technique that operates without second derivatives of the loss function (required in prior works), which can be expensive to compute. We show the effectiveness of our method using the DeepSpeech model architecture, demonstrating that it is possible to reveal the speaker's identity with 34% top-1 accuracy (51% top-5 accuracy) on the LibriSpeech dataset. Further, we study the effect of two well-known techniques, Differentially Private SGD and Dropout, on the success of our method. We show that a dropout rate of 0.2 can reduce the speaker identity accuracy to 0% top-1 (0.5% top-5).",Speech Recognition : RESEARCH_PROBLEM; (SGD : METHOD; SGD : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: End-to-end Automatic Speech Recognition (ASR) models are commonly trained over spoken utterances using optimization methods like Stochastic Gradient Descent (SGD ). In distributed settings like Federated Learning, model training requires transmission of gradients over a network. In this work, we design the first method for revealing the identity of the speaker of a training utterance with access only to a gradient. We propose Hessian-Free Gradients Matching, an input reconstruction technique that operates without second derivatives of the loss function (required in prior works), which can be expensive to compute. We show the effectiveness of our method using the DeepSpeech model architecture, demonstrating that it is possible to reveal the speaker's identity with 34% top-1 accuracy (51% top-5 accuracy) on the LibriSpeech dataset. Further, we study the effect of two well-known techniques, Differentially Private SGD and Dropout, on the success of our method. We show that a dropout rate of 0.2 can reduce the speaker identity accuracy to 0% top-1 (0.5% top-5). ### Response: Speech Recognition : RESEARCH_PROBLEM; (SGD : METHOD; SGD : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Biomedical Named Entity Recognition (NER ) is a challenging problem in biomedical information processing due to the widespread ambiguity of out of context terms and extensive lexical variations. Performance on bioNER benchmarks continues to improve due to advances like BERT , GPT, and XLNet. FLAIR (1) is an alternative embedding model which is less computationally intensive than the others mentioned. We test FLAIR and its pretrained PubMed embeddings (which we term BioFLAIR) on a variety of bio NER tasks and compare those with results from BERT -type networks. We also investigate the effects of a small amount of additional pretraining on PubMed content, and of combining FLAIR and ELMO models. We find that with the provided embeddings, FLAIR performs on-par with the BERT networks - even establishing a new state of the art on one benchmark. Additional pretraining did not provide a clear benefit, although this might change with even more pretraining being done. Stacking the FLAIR embeddings with others typically does provide a boost in the benchmark results.",Named Entity Recognition : RESEARCH_PROBLEM; (NER : RESEARCH_PROBLEM; bioNER : RESEARCH_PROBLEM; BERT : METHOD; NER : RESEARCH_PROBLEM; BERT : METHOD; BERT : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Biomedical Named Entity Recognition (NER ) is a challenging problem in biomedical information processing due to the widespread ambiguity of out of context terms and extensive lexical variations. Performance on bioNER benchmarks continues to improve due to advances like BERT , GPT, and XLNet. FLAIR (1) is an alternative embedding model which is less computationally intensive than the others mentioned. We test FLAIR and its pretrained PubMed embeddings (which we term BioFLAIR) on a variety of bio NER tasks and compare those with results from BERT -type networks. We also investigate the effects of a small amount of additional pretraining on PubMed content, and of combining FLAIR and ELMO models. We find that with the provided embeddings, FLAIR performs on-par with the BERT networks - even establishing a new state of the art on one benchmark. Additional pretraining did not provide a clear benefit, although this might change with even more pretraining being done. Stacking the FLAIR embeddings with others typically does provide a boost in the benchmark results. ### Response: Named Entity Recognition : RESEARCH_PROBLEM; (NER : RESEARCH_PROBLEM; bioNER : RESEARCH_PROBLEM; BERT : METHOD; NER : RESEARCH_PROBLEM; BERT : METHOD; BERT : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Background: Independent Component Analysis (ICA ) is a widespread tool for exploration and denoising of electroencephalography (EEG ) or magnetoencephalography (MEG) signals. In its most common formulation, ICA assumes that the signal matrix is a noiseless linear mixture of independent sources that are assumed non-Gaussian. A limitation is that it enforces to estimate as many sources as sensors or to rely on a detrimental PCA step. Methods: We present the Spectral Matching ICA (SMICA ) model. Signals are modelled as a linear mixing of independent sources corrupted by additive noise, where sources and the noise are stationary Gaussian time series. Thanks to the Gaussian assumption, the negative log-likelihood has a simple expression as a sum of divergences between the empirical spectral covariance matrices of the signals and those predicted by the model. The model parameters can then be estimated by the expectation-maximization (EM) algorithm. Results: Experiments on phantom MEG datasets show that SMICA can recover dipole locations more precisely than usual ICA algorithms or Maxwell filtering when the dipole amplitude is low. Experiments on EEG datasets show that SMICA identifies a source subspace which contains sources that have less pairwise mutual information, and are better explained by the projection of a single dipole on the scalp. Comparison with existing methods: Noiseless ICA models lead to degenerate likelihood when there are fewer sources than sensors, while SMICA succeeds without resorting to prior dimension reduction. Conclusions: SMICA is a promising alternative to other noiseless ICA models based on non-Gaussian assumptions.",(ICA : METHOD; (EEG : RESEARCH_PROBLEM; ICA : METHOD; PCA : METHOD; ICA : METHOD; (SMICA : METHOD; SMICA : METHOD; ICA : METHOD; EEG : RESEARCH_PROBLEM; SMICA : METHOD; ICA : METHOD; SMICA : METHOD; SMICA : METHOD; ICA : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Background: Independent Component Analysis (ICA ) is a widespread tool for exploration and denoising of electroencephalography (EEG ) or magnetoencephalography (MEG) signals. In its most common formulation, ICA assumes that the signal matrix is a noiseless linear mixture of independent sources that are assumed non-Gaussian. A limitation is that it enforces to estimate as many sources as sensors or to rely on a detrimental PCA step. Methods: We present the Spectral Matching ICA (SMICA ) model. Signals are modelled as a linear mixing of independent sources corrupted by additive noise, where sources and the noise are stationary Gaussian time series. Thanks to the Gaussian assumption, the negative log-likelihood has a simple expression as a sum of divergences between the empirical spectral covariance matrices of the signals and those predicted by the model. The model parameters can then be estimated by the expectation-maximization (EM) algorithm. Results: Experiments on phantom MEG datasets show that SMICA can recover dipole locations more precisely than usual ICA algorithms or Maxwell filtering when the dipole amplitude is low. Experiments on EEG datasets show that SMICA identifies a source subspace which contains sources that have less pairwise mutual information, and are better explained by the projection of a single dipole on the scalp. Comparison with existing methods: Noiseless ICA models lead to degenerate likelihood when there are fewer sources than sensors, while SMICA succeeds without resorting to prior dimension reduction. Conclusions: SMICA is a promising alternative to other noiseless ICA models based on non-Gaussian assumptions. ### Response: (ICA : METHOD; (EEG : RESEARCH_PROBLEM; ICA : METHOD; PCA : METHOD; ICA : METHOD; (SMICA : METHOD; SMICA : METHOD; ICA : METHOD; EEG : RESEARCH_PROBLEM; SMICA : METHOD; ICA : METHOD; SMICA : METHOD; SMICA : METHOD; ICA : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Although attention-based Neural Machine Translation has achieved remarkable progress in recent layers, it still suffers from issue of making insufficient use of the output of each layer. In transformer, it only uses the top layer of encoder and decoder in the subsequent process, which makes it impossible to take advantage of the useful information in other layers. To address this issue, we propose a residual tree aggregation of layers for Transformer (RTAL), which helps to fuse information across layers. Specifically, we try to fuse the information across layers by constructing a post-order binary tree. In additional to the last node, we add the residual connection to the process of generating child nodes. Our model is based on the Neural Machine Translation model Transformer and we conduct our experiments on WMT14 English-to-German and WMT17 English-to-France translation tasks. Experimental results across language pairs show that the proposed approach outperforms the strong baseline model significantly",Machine Translation : RESEARCH_PROBLEM; Transformer : METHOD; Machine Translation : RESEARCH_PROBLEM; Transformer : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Although attention-based Neural Machine Translation has achieved remarkable progress in recent layers, it still suffers from issue of making insufficient use of the output of each layer. In transformer, it only uses the top layer of encoder and decoder in the subsequent process, which makes it impossible to take advantage of the useful information in other layers. To address this issue, we propose a residual tree aggregation of layers for Transformer (RTAL), which helps to fuse information across layers. Specifically, we try to fuse the information across layers by constructing a post-order binary tree. In additional to the last node, we add the residual connection to the process of generating child nodes. Our model is based on the Neural Machine Translation model Transformer and we conduct our experiments on WMT14 English-to-German and WMT17 English-to-France translation tasks. Experimental results across language pairs show that the proposed approach outperforms the strong baseline model significantly ### Response: Machine Translation : RESEARCH_PROBLEM; Transformer : METHOD; Machine Translation : RESEARCH_PROBLEM; Transformer : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Human motion prediction is a challenging task due to the stochasticity and aperiodicity of future poses. Recently, graph convolutional network has been proven to be very effective to learn dynamic relations among pose joints, which is helpful for pose prediction. On the other hand, one can abstract a human pose recursively to obtain a set of poses at multiple scales. With the increase of the abstraction level, the motion of the pose becomes more stable, which benefits pose prediction too. In this paper, we propose a novel Multi-Scale Residual Graph Convolution Network (MSR-GCN) for human pose prediction task in the manner of end-to-end. The GCNs are used to extract features from fine to coarse scale and then from coarse to fine scale. The extracted features at each scale are then combined and decoded to obtain the residuals between the input and target poses. Intermediate supervisions are imposed on all the predicted poses, which enforces the network to learn more representative features. Our proposed approach is evaluated on two standard benchmark datasets, i.e., the Human3.6M dataset and the CMU Mocap dataset. Experimental results demonstrate that our method outperforms the state-of-the-art approaches. Code and pre-trained models are available at https://github.com/Droliven/MSRGCN.",Human motion prediction : RESEARCH_PROBLEM; Convolution : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Human motion prediction is a challenging task due to the stochasticity and aperiodicity of future poses. Recently, graph convolutional network has been proven to be very effective to learn dynamic relations among pose joints, which is helpful for pose prediction. On the other hand, one can abstract a human pose recursively to obtain a set of poses at multiple scales. With the increase of the abstraction level, the motion of the pose becomes more stable, which benefits pose prediction too. In this paper, we propose a novel Multi-Scale Residual Graph Convolution Network (MSR-GCN) for human pose prediction task in the manner of end-to-end. The GCNs are used to extract features from fine to coarse scale and then from coarse to fine scale. The extracted features at each scale are then combined and decoded to obtain the residuals between the input and target poses. Intermediate supervisions are imposed on all the predicted poses, which enforces the network to learn more representative features. Our proposed approach is evaluated on two standard benchmark datasets, i.e., the Human3.6M dataset and the CMU Mocap dataset. Experimental results demonstrate that our method outperforms the state-of-the-art approaches. Code and pre-trained models are available at https://github.com/Droliven/MSRGCN. ### Response: Human motion prediction : RESEARCH_PROBLEM; Convolution : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Analyzing the abnormality of morphological characteristics of male human sperm has been studied for a long time mainly because it has many implications on the male infertility problem, which accounts for approximately half of the infertility problems in the world. Yet, detecting such abnormalities by embryologists has several downsides. To clarify, analyzing sperms through visual inspection of an expert embryologist is a highly subjective and biased process. Furthermore, it takes much time for a specialist to make a diagnosis. Hence, in this paper, we proposed two deep learning algorithms that are able to automate this process. The first algorithm uses a network-based deep transfer learning approach, while the second technique, named Deep Multi-task Transfer Learning (DMTL), employs a novel combination of network-based deep transfer learning and multi-task learning to classify sperm's head, vacuole, and acrosome as either normal or abnormal. This DMTL technique is capable of classifying all the aforementioned parts of the sperm in a single prediction. Moreover, this is the first time that the concept of multi-task learning has been introduced to the field of Sperm Morphology Analysis (SMA ). To benchmark our algorithms, we employed a freely-available SMA dataset named MHSMA . During our experiments, our algorithms reached the state-of-the-art results on the accuracy, precision, and f0.5, as well as other important metrics, such as the Matthews Correlation Coefficient on one, two, or all three labels. Notably, our algorithms increased the accuracy of the head, acrosome, and vacuole by 6.66%,3.00% , and 1.33%, and reached the accuracy of 84.00% ,80.66%, and 94.00% on these labels, respectively. Consequently, our algorithms can be used in health institutions, such as fertility clinics, with further recommendations to practically improve the performance of our algorithms.",Transfer Learning : RESEARCH_PROBLEM; (SMA : METHOD; SMA : METHOD; MHSMA : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Analyzing the abnormality of morphological characteristics of male human sperm has been studied for a long time mainly because it has many implications on the male infertility problem, which accounts for approximately half of the infertility problems in the world. Yet, detecting such abnormalities by embryologists has several downsides. To clarify, analyzing sperms through visual inspection of an expert embryologist is a highly subjective and biased process. Furthermore, it takes much time for a specialist to make a diagnosis. Hence, in this paper, we proposed two deep learning algorithms that are able to automate this process. The first algorithm uses a network-based deep transfer learning approach, while the second technique, named Deep Multi-task Transfer Learning (DMTL), employs a novel combination of network-based deep transfer learning and multi-task learning to classify sperm's head, vacuole, and acrosome as either normal or abnormal. This DMTL technique is capable of classifying all the aforementioned parts of the sperm in a single prediction. Moreover, this is the first time that the concept of multi-task learning has been introduced to the field of Sperm Morphology Analysis (SMA ). To benchmark our algorithms, we employed a freely-available SMA dataset named MHSMA . During our experiments, our algorithms reached the state-of-the-art results on the accuracy, precision, and f0.5, as well as other important metrics, such as the Matthews Correlation Coefficient on one, two, or all three labels. Notably, our algorithms increased the accuracy of the head, acrosome, and vacuole by 6.66%,3.00% , and 1.33%, and reached the accuracy of 84.00% ,80.66%, and 94.00% on these labels, respectively. Consequently, our algorithms can be used in health institutions, such as fertility clinics, with further recommendations to practically improve the performance of our algorithms. ### Response: Transfer Learning : RESEARCH_PROBLEM; (SMA : METHOD; SMA : METHOD; MHSMA : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Activity recognition in smart homes is essential when we wish to propose automatic services for the inhabitants. However, it poses challenges in terms of variability of the environment, sensorimotor system, but also user habits. Therefore, endto-end systems fail at automatically extracting key features, without extensive pre-processing. We propose to tackle feature extraction for activity recognition in smart homes by merging methods from the Natural Language Processing (NLP) and the Time Series Classification (TSC) domains. We evaluate the performance of our method on two datasets issued from the Center for Advanced Studies in Adaptive Systems (CASAS). Moreover, we analyze the contributions of the use of NLP encoding Bag-Of-Word with Embedding as well as the ability of the FCN algorithm to automatically extract features and classify. The method we propose shows good performance in offline activity classification. Our analysis also shows that FCN is a suitable algorithm for smart home activity recognition and hightlights the advantages of automatic feature extraction.",Time Series Classification : RESEARCH_PROBLEM; FCN : METHOD; FCN : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Activity recognition in smart homes is essential when we wish to propose automatic services for the inhabitants. However, it poses challenges in terms of variability of the environment, sensorimotor system, but also user habits. Therefore, endto-end systems fail at automatically extracting key features, without extensive pre-processing. We propose to tackle feature extraction for activity recognition in smart homes by merging methods from the Natural Language Processing (NLP) and the Time Series Classification (TSC) domains. We evaluate the performance of our method on two datasets issued from the Center for Advanced Studies in Adaptive Systems (CASAS). Moreover, we analyze the contributions of the use of NLP encoding Bag-Of-Word with Embedding as well as the ability of the FCN algorithm to automatically extract features and classify. The method we propose shows good performance in offline activity classification. Our analysis also shows that FCN is a suitable algorithm for smart home activity recognition and hightlights the advantages of automatic feature extraction. ### Response: Time Series Classification : RESEARCH_PROBLEM; FCN : METHOD; FCN : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Since the superiority of Transformer in learning long-term dependency, the sign language Transformer model achieves remarkable progress in Sign Language Recognition (SLR) and Translation (SLT). However, there are several issues with the Transformer that prevent it from better sign language understanding. The first issue is that the self-attention mechanism learns sign video representation in a frame-wise manner, neglecting the temporal semantic structure of sign gestures. Secondly, the attention mechanism with absolute position encoding is direction and distance unaware, thus limiting its ability. To address these issues, we propose a new model architecture, namely PiSLTRc, with two distinctive characteristics: (i) content-aware and position-aware convolution layers. Specifically, we explicitly select relevant features using a novel content-aware neighborhood gathering method. Then we aggregate these features with position-informed temporal convolution layers, thus generating robust neighborhood-enhanced sign representation. (ii) injecting the relative position information to the attention mechanism in the encoder, decoder, and even encoder-decoder cross attention. Compared with the vanilla Transformer model, our model performs consistently better on three large-scale sign language benchmarks: PHOENIX-2014, PHOENIX-2014-T and CSL. Furthermore, extensive experiments demonstrate that the proposed method achieves state-of-the-art performance on translation quality with $+1.6$ BLEU improvements.",Transformer : METHOD; Transformer : METHOD; Sign Language Recognition : RESEARCH_PROBLEM; Translation : RESEARCH_PROBLEM; Transformer : METHOD; Transformer : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Since the superiority of Transformer in learning long-term dependency, the sign language Transformer model achieves remarkable progress in Sign Language Recognition (SLR) and Translation (SLT). However, there are several issues with the Transformer that prevent it from better sign language understanding. The first issue is that the self-attention mechanism learns sign video representation in a frame-wise manner, neglecting the temporal semantic structure of sign gestures. Secondly, the attention mechanism with absolute position encoding is direction and distance unaware, thus limiting its ability. To address these issues, we propose a new model architecture, namely PiSLTRc, with two distinctive characteristics: (i) content-aware and position-aware convolution layers. Specifically, we explicitly select relevant features using a novel content-aware neighborhood gathering method. Then we aggregate these features with position-informed temporal convolution layers, thus generating robust neighborhood-enhanced sign representation. (ii) injecting the relative position information to the attention mechanism in the encoder, decoder, and even encoder-decoder cross attention. Compared with the vanilla Transformer model, our model performs consistently better on three large-scale sign language benchmarks: PHOENIX-2014, PHOENIX-2014-T and CSL. Furthermore, extensive experiments demonstrate that the proposed method achieves state-of-the-art performance on translation quality with $+1.6$ BLEU improvements. ### Response: Transformer : METHOD; Transformer : METHOD; Sign Language Recognition : RESEARCH_PROBLEM; Translation : RESEARCH_PROBLEM; Transformer : METHOD; Transformer : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Modern machine learning techniques are successfully being adapted to data modeled as graphs. However, many real-world graphs are typically very large and do not fit in memory, often making the problem of training machine learning models on them intractable. Distributed training has been successfully employed to alleviate memory problems and speed up training in machine learning domains in which the input data is assumed to be independently identical distributed (i.i.d). However, distributing the training of non i.i.d data such as graphs that are used as training inputs in Graph Convolutional Networks (GCNs) causes accuracy problems since information is lost at the graph partitioning boundaries. In this paper, we propose a training strategy that mitigates the lost information across multiple partitions of a graph through a subgraph approximation scheme. Our proposed approach augments each sub-graph with a small amount of edge and vertex information that is approximated from all other sub-graphs. The subgraph approximation approach helps the distributed training system converge at single-machine accuracy, while keeping the memory footprint low and minimizing synchronization overhead between the machines.",Graph Convolutional Networks : METHOD; graph partitioning : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Modern machine learning techniques are successfully being adapted to data modeled as graphs. However, many real-world graphs are typically very large and do not fit in memory, often making the problem of training machine learning models on them intractable. Distributed training has been successfully employed to alleviate memory problems and speed up training in machine learning domains in which the input data is assumed to be independently identical distributed (i.i.d). However, distributing the training of non i.i.d data such as graphs that are used as training inputs in Graph Convolutional Networks (GCNs) causes accuracy problems since information is lost at the graph partitioning boundaries. In this paper, we propose a training strategy that mitigates the lost information across multiple partitions of a graph through a subgraph approximation scheme. Our proposed approach augments each sub-graph with a small amount of edge and vertex information that is approximated from all other sub-graphs. The subgraph approximation approach helps the distributed training system converge at single-machine accuracy, while keeping the memory footprint low and minimizing synchronization overhead between the machines. ### Response: Graph Convolutional Networks : METHOD; graph partitioning : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Aspect-based Sentiment Analysis (ABSA), aiming at predicting the polarities for aspects, is a fine-grained task in the field of sentiment analysis. Previous work showed syntactic information, e.g. dependency trees, can effectively improve the ABSA performance. Recently, pre-trained models (PTMs) also have shown their effectiveness on ABSA. Therefore, the question naturally arises whether PTMs contain sufficient syntactic information for ABSA so that we can obtain a good ABSA model only based on PTMs. In this paper, we firstly compare the induced trees from PTMs and the dependency parsing trees on several popular models for the ABSA task, showing that the induced tree from fine-tuned RoBERTa (FT-RoBERTa ) outperforms the parser-provided tree. The further analysis experiments reveal that the FT-RoBERTa Induced Tree is more sentiment-word-oriented and could benefit the ABSA task. The experiments also show that the pure RoBERTa -based model can outperform or approximate to the previous SOTA performances on six datasets across four languages since it implicitly incorporates the task-oriented syntactic information.",Sentiment Analysis : RESEARCH_PROBLEM; RoBERTa : METHOD; (FT-RoBERTa : METHOD; FT-RoBERTa : METHOD; RoBERTa : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Aspect-based Sentiment Analysis (ABSA), aiming at predicting the polarities for aspects, is a fine-grained task in the field of sentiment analysis. Previous work showed syntactic information, e.g. dependency trees, can effectively improve the ABSA performance. Recently, pre-trained models (PTMs) also have shown their effectiveness on ABSA. Therefore, the question naturally arises whether PTMs contain sufficient syntactic information for ABSA so that we can obtain a good ABSA model only based on PTMs. In this paper, we firstly compare the induced trees from PTMs and the dependency parsing trees on several popular models for the ABSA task, showing that the induced tree from fine-tuned RoBERTa (FT-RoBERTa ) outperforms the parser-provided tree. The further analysis experiments reveal that the FT-RoBERTa Induced Tree is more sentiment-word-oriented and could benefit the ABSA task. The experiments also show that the pure RoBERTa -based model can outperform or approximate to the previous SOTA performances on six datasets across four languages since it implicitly incorporates the task-oriented syntactic information. ### Response: Sentiment Analysis : RESEARCH_PROBLEM; RoBERTa : METHOD; (FT-RoBERTa : METHOD; FT-RoBERTa : METHOD; RoBERTa : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","In this paper, we propose a new adversarial augmentation method for Neural Machine Translation (NMT). The main idea is to minimize the vicinal risk over virtual sentences sampled from two vicinity distributions, of which the crucial one is a novel vicinity distribution for adversarial sentences that describes a smooth interpolated embedding space centered around observed training sentence pairs. We then discuss our approach, AdvAug, to train NMT models using the embeddings of virtual sentences in sequence-to-sequence learning. Experiments on Chinese-English, English-French, and English-German translation benchmarks show that AdvAug achieves significant improvements over the Transformer (up to 4.9 BLEU points), and substantially outperforms other data augmentation techniques (e.g. back-translation) without using extra corpora.",Machine Translation : RESEARCH_PROBLEM; Transformer : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: In this paper, we propose a new adversarial augmentation method for Neural Machine Translation (NMT). The main idea is to minimize the vicinal risk over virtual sentences sampled from two vicinity distributions, of which the crucial one is a novel vicinity distribution for adversarial sentences that describes a smooth interpolated embedding space centered around observed training sentence pairs. We then discuss our approach, AdvAug, to train NMT models using the embeddings of virtual sentences in sequence-to-sequence learning. Experiments on Chinese-English, English-French, and English-German translation benchmarks show that AdvAug achieves significant improvements over the Transformer (up to 4.9 BLEU points), and substantially outperforms other data augmentation techniques (e.g. back-translation) without using extra corpora. ### Response: Machine Translation : RESEARCH_PROBLEM; Transformer : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Dynamic Time Warping (DTW ) is a popular similarity measure for aligning and comparing time series. Due to DTW 's high computation time, lower bounds are often employed to screen poor matches. Many alternative lower bounds have been proposed, providing a range of different trade-offs between tightness and computational efficiency. LB Keogh provides a useful trade-off in many applications. Two recent lower bounds, LB Improved and LB Enhanced, are substantially tighter than LB Keogh. All three have the same worst case computational complexity - linear with respect to series length and constant with respect to window size. We present four new DTW lower bounds in the same complexity class. LB Petitjean is substantially tighter than LB Improved, with only modest additional computational overhead. LB Webb is more efficient than LB Improved, while often providing a tighter bound. LB Webb is always tighter than LB Keogh. The parameter free LB Webb is usually tighter than LB Enhanced. A parameterized variant, LB Webb Enhanced, is always tighter than LB Enhanced. A further variant, LB Webb*, is useful for some constrained distance functions. In extensive experiments, LB Webb proves to be very effective for nearest neighbor search.",Dynamic Time Warping : RESEARCH_PROBLEM; (DTW : METHOD; DTW : METHOD; DTW : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Dynamic Time Warping (DTW ) is a popular similarity measure for aligning and comparing time series. Due to DTW 's high computation time, lower bounds are often employed to screen poor matches. Many alternative lower bounds have been proposed, providing a range of different trade-offs between tightness and computational efficiency. LB Keogh provides a useful trade-off in many applications. Two recent lower bounds, LB Improved and LB Enhanced, are substantially tighter than LB Keogh. All three have the same worst case computational complexity - linear with respect to series length and constant with respect to window size. We present four new DTW lower bounds in the same complexity class. LB Petitjean is substantially tighter than LB Improved, with only modest additional computational overhead. LB Webb is more efficient than LB Improved, while often providing a tighter bound. LB Webb is always tighter than LB Keogh. The parameter free LB Webb is usually tighter than LB Enhanced. A parameterized variant, LB Webb Enhanced, is always tighter than LB Enhanced. A further variant, LB Webb*, is useful for some constrained distance functions. In extensive experiments, LB Webb proves to be very effective for nearest neighbor search. ### Response: Dynamic Time Warping : RESEARCH_PROBLEM; (DTW : METHOD; DTW : METHOD; DTW : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","This paper describes our method for the task of Semantic Question Similarity in Arabic in the workshop on NLP Solutions for Under-Resourced Languages (NSURL). The aim is to build a model that is able to detect similar semantic questions in the Arabic language for the provided dataset. Different methods of determining questions similarity are explored in this work. The proposed models achieved high F1-scores, which range from (88% to 96%). Our official best result is produced from the ensemble model of using a pre-trained multilingual BERT model with different random seeds with 95.924% F1-Score, which ranks the first among nine participants teams.",Question Similarity : RESEARCH_PROBLEM; BERT : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: This paper describes our method for the task of Semantic Question Similarity in Arabic in the workshop on NLP Solutions for Under-Resourced Languages (NSURL). The aim is to build a model that is able to detect similar semantic questions in the Arabic language for the provided dataset. Different methods of determining questions similarity are explored in this work. The proposed models achieved high F1-scores, which range from (88% to 96%). Our official best result is produced from the ensemble model of using a pre-trained multilingual BERT model with different random seeds with 95.924% F1-Score, which ranks the first among nine participants teams. ### Response: Question Similarity : RESEARCH_PROBLEM; BERT : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","The use of supervised Machine Learning (ML) to enhance Intrusion Detection Systems has been the subject of significant research. Supervised ML is based upon learning by example, demanding significant volumes of representative instances for effective training and the need to re-train the model for every unseen cyber-attack class. However, retraining the models in-situ renders the network susceptible to attacks owing to the time-window required to acquire a sufficient volume of data. Although anomaly detection systems provide a coarse-grained defence against unseen attacks, these approaches are significantly less accurate and suffer from high false-positive rates. Here, a complementary approach referred to as 'One-Shot Learning', whereby a limited number of examples of a new attack-class is used to identify a new attack-class (out of many) is detailed. The model grants a new cyber-attack classification without retraining. A Siamese Network is trained to differentiate between classes based on pairs similarities, rather than features, allowing to identify new and previously unseen attacks. The performance of a pre-trained model to classify attack-classes based only on one example is evaluated using three datasets. Results confirm the adaptability of the model in classifying unseen attacks and the trade-off between performance and the need for distinctive class representation.",Intrusion Detection : RESEARCH_PROBLEM; Siamese Network : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: The use of supervised Machine Learning (ML) to enhance Intrusion Detection Systems has been the subject of significant research. Supervised ML is based upon learning by example, demanding significant volumes of representative instances for effective training and the need to re-train the model for every unseen cyber-attack class. However, retraining the models in-situ renders the network susceptible to attacks owing to the time-window required to acquire a sufficient volume of data. Although anomaly detection systems provide a coarse-grained defence against unseen attacks, these approaches are significantly less accurate and suffer from high false-positive rates. Here, a complementary approach referred to as 'One-Shot Learning', whereby a limited number of examples of a new attack-class is used to identify a new attack-class (out of many) is detailed. The model grants a new cyber-attack classification without retraining. A Siamese Network is trained to differentiate between classes based on pairs similarities, rather than features, allowing to identify new and previously unseen attacks. The performance of a pre-trained model to classify attack-classes based only on one example is evaluated using three datasets. Results confirm the adaptability of the model in classifying unseen attacks and the trade-off between performance and the need for distinctive class representation. ### Response: Intrusion Detection : RESEARCH_PROBLEM; Siamese Network : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Contrastive learning (CL) has been successful as a powerful representation learning method. In this work we propose CLIM: Contrastive Learning with mutual Information Maximization, to explore the potential of CL on cross-domain sentiment classification. To the best of our knowledge, CLIM is the first to adopt contrastive learning for natural language processing (NLP) tasks across domains. Due to scarcity of labels on the target domain, we introduce mutual information maximization (MIM ) apart from CL to exploit the features that best support the final prediction. Furthermore, MIM is able to maintain a relatively balanced distribution of the model's prediction, and enlarges the margin between classes on the target domain. The larger margin increases our model's robustness and enables the same classifier to be optimal across domains. Consequently, we achieve new state-of-the-art results on the Amazon-review dataset as well as the airlines dataset, showing the efficacy of our proposed method CLIM.",Contrastive Learning : RESEARCH_PROBLEM; (MIM : METHOD; MIM : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Contrastive learning (CL) has been successful as a powerful representation learning method. In this work we propose CLIM: Contrastive Learning with mutual Information Maximization, to explore the potential of CL on cross-domain sentiment classification. To the best of our knowledge, CLIM is the first to adopt contrastive learning for natural language processing (NLP) tasks across domains. Due to scarcity of labels on the target domain, we introduce mutual information maximization (MIM ) apart from CL to exploit the features that best support the final prediction. Furthermore, MIM is able to maintain a relatively balanced distribution of the model's prediction, and enlarges the margin between classes on the target domain. The larger margin increases our model's robustness and enables the same classifier to be optimal across domains. Consequently, we achieve new state-of-the-art results on the Amazon-review dataset as well as the airlines dataset, showing the efficacy of our proposed method CLIM. ### Response: Contrastive Learning : RESEARCH_PROBLEM; (MIM : METHOD; MIM : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","The analysis of electroencephalogram (EEG ) waves is of critical importance for the diagnosis of sleep disorders, such as sleep apnea and insomnia, besides that, seizures, epilepsy, head injuries, dizziness, headaches and brain tumors. In this context, one important task is the identification of visible structures in the EEG signal, such as sleep spindles and K-complexes. The identification of these structures is usually performed by visual inspection from human experts, a process that can be error prone and susceptible to biases. Therefore there is interest in developing technologies for the automated analysis of EEG . In this paper, we propose a new Genetic Programming (GP) framework for feature construction and dimensionality reduction from EEG signals. We use these features to automatically identify spindles and K-complexes on data from the DREAMS project. Using 5 different classifiers, the set of attributes produced by GP obtained better AUC scores than those obtained from PCA or the full set of attributes. Also, the results obtained from the proposed framework obtained a better balance of Specificity and Recall than other models recently proposed in the literature. Analysis of the features most used by GP also suggested improvements for data acquisition protocols in future EEG examinations.",(EEG : RESEARCH_PROBLEM; EEG : RESEARCH_PROBLEM; EEG : RESEARCH_PROBLEM; EEG : RESEARCH_PROBLEM; PCA : METHOD; EEG : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: The analysis of electroencephalogram (EEG ) waves is of critical importance for the diagnosis of sleep disorders, such as sleep apnea and insomnia, besides that, seizures, epilepsy, head injuries, dizziness, headaches and brain tumors. In this context, one important task is the identification of visible structures in the EEG signal, such as sleep spindles and K-complexes. The identification of these structures is usually performed by visual inspection from human experts, a process that can be error prone and susceptible to biases. Therefore there is interest in developing technologies for the automated analysis of EEG . In this paper, we propose a new Genetic Programming (GP) framework for feature construction and dimensionality reduction from EEG signals. We use these features to automatically identify spindles and K-complexes on data from the DREAMS project. Using 5 different classifiers, the set of attributes produced by GP obtained better AUC scores than those obtained from PCA or the full set of attributes. Also, the results obtained from the proposed framework obtained a better balance of Specificity and Recall than other models recently proposed in the literature. Analysis of the features most used by GP also suggested improvements for data acquisition protocols in future EEG examinations. ### Response: (EEG : RESEARCH_PROBLEM; EEG : RESEARCH_PROBLEM; EEG : RESEARCH_PROBLEM; EEG : RESEARCH_PROBLEM; PCA : METHOD; EEG : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","In this paper, we formulate a more realistic and difficult problem setup for the intent detection task in natural language understanding, namely Generalized Few-Shot Intent Detection (GFSID). GFSID aims to discriminate a joint label space consisting of both existing intents which have enough labeled data and novel intents which only have a few examples for each class. To approach this problem, we propose a novel model, Conditional Text Generation with BERT (CG-BERT ). CG-BERT effectively leverages a large pre-trained language model to generate text conditioned on the intent label. By modeling the utterance distribution with variational inference, CG-BERT can generate diverse utterances for the novel intents even with only a few utterances available. Experimental results show that CG-BERT achieves state-of-the-art performance on the GFSID task with 1-shot and 5-shot settings on two real-world datasets.",Intent Detection : RESEARCH_PROBLEM; Conditional Text Generation : RESEARCH_PROBLEM; BERT : METHOD; (CG-BERT : METHOD; CG-BERT : METHOD; CG-BERT : METHOD; CG-BERT : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: In this paper, we formulate a more realistic and difficult problem setup for the intent detection task in natural language understanding, namely Generalized Few-Shot Intent Detection (GFSID). GFSID aims to discriminate a joint label space consisting of both existing intents which have enough labeled data and novel intents which only have a few examples for each class. To approach this problem, we propose a novel model, Conditional Text Generation with BERT (CG-BERT ). CG-BERT effectively leverages a large pre-trained language model to generate text conditioned on the intent label. By modeling the utterance distribution with variational inference, CG-BERT can generate diverse utterances for the novel intents even with only a few utterances available. Experimental results show that CG-BERT achieves state-of-the-art performance on the GFSID task with 1-shot and 5-shot settings on two real-world datasets. ### Response: Intent Detection : RESEARCH_PROBLEM; Conditional Text Generation : RESEARCH_PROBLEM; BERT : METHOD; (CG-BERT : METHOD; CG-BERT : METHOD; CG-BERT : METHOD; CG-BERT : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","A novel coronavirus disease 2019 (COVID-19) was detected and has spread rapidly across various countries around the world since the end of the year 2019, Computed Tomography (CT) images have been used as a crucial alternative to the time-consuming RT-PCR test. However, pure manual segmentation of CT images faces a serious challenge with the increase of suspected cases, resulting in urgent requirements for accurate and automatic segmentation of COVID-19 infections. Unfortunately, since the imaging characteristics of the COVID-19 infection are diverse and similar to the backgrounds, existing medical image segmentation methods cannot achieve satisfactory performance. In this work, we try to establish a new deep convolutional neural network tailored for segmenting the chest CT images with COVID-19 infections. We firstly maintain a large and new chest CT image dataset consisting of 165,667 annotated chest CT images from 861 patients with confirmed COVID-19. Inspired by the observation that the boundary of the infected lung can be enhanced by adjusting the global intensity, in the proposed deep CNN, we introduce a feature variation block which adaptively adjusts the global properties of the features for segmenting COVID-19 infection. The proposed FV block can enhance the capability of feature representation effectively and adaptively for diverse cases. We fuse features at different scales by proposing Progressive Atrous Spatial Pyramid Pooling to handle the sophisticated infection areas with diverse appearance and shapes. We conducted experiments on the data collected in China and Germany and show that the proposed deep CNN can produce impressive performance effectively.",Computed Tomography (CT) : RESEARCH_PROBLEM; Spatial Pyramid Pooling : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: A novel coronavirus disease 2019 (COVID-19) was detected and has spread rapidly across various countries around the world since the end of the year 2019, Computed Tomography (CT) images have been used as a crucial alternative to the time-consuming RT-PCR test. However, pure manual segmentation of CT images faces a serious challenge with the increase of suspected cases, resulting in urgent requirements for accurate and automatic segmentation of COVID-19 infections. Unfortunately, since the imaging characteristics of the COVID-19 infection are diverse and similar to the backgrounds, existing medical image segmentation methods cannot achieve satisfactory performance. In this work, we try to establish a new deep convolutional neural network tailored for segmenting the chest CT images with COVID-19 infections. We firstly maintain a large and new chest CT image dataset consisting of 165,667 annotated chest CT images from 861 patients with confirmed COVID-19. Inspired by the observation that the boundary of the infected lung can be enhanced by adjusting the global intensity, in the proposed deep CNN, we introduce a feature variation block which adaptively adjusts the global properties of the features for segmenting COVID-19 infection. The proposed FV block can enhance the capability of feature representation effectively and adaptively for diverse cases. We fuse features at different scales by proposing Progressive Atrous Spatial Pyramid Pooling to handle the sophisticated infection areas with diverse appearance and shapes. We conducted experiments on the data collected in China and Germany and show that the proposed deep CNN can produce impressive performance effectively. ### Response: Computed Tomography (CT) : RESEARCH_PROBLEM; Spatial Pyramid Pooling : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","In this paper, we tackle the task of Word Sense Disambiguation (WSD). We present our system submitted to the Word-in-Context Target Sense Verification challenge, part of the SemDeep workshop at IJCAI 2020 (Breit et al., 2020). That challenge asks participants to predict if a specific mention of a word in a text matches a pre-defined sense. Our approach uses pre-trained transformer models such as BERT that are fine-tuned on the task using different architecture strategies. Our model achieves the best accuracy and precision on Subtask 1 ? make use of definitions for deciding whether the target word in context corresponds to the given sense or not. We believe the strategies we explored in the context of this challenge can be useful to other Natural Language Processing tasks.",Word Sense Disambiguation : RESEARCH_PROBLEM; BERT : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: In this paper, we tackle the task of Word Sense Disambiguation (WSD). We present our system submitted to the Word-in-Context Target Sense Verification challenge, part of the SemDeep workshop at IJCAI 2020 (Breit et al., 2020). That challenge asks participants to predict if a specific mention of a word in a text matches a pre-defined sense. Our approach uses pre-trained transformer models such as BERT that are fine-tuned on the task using different architecture strategies. Our model achieves the best accuracy and precision on Subtask 1 ? make use of definitions for deciding whether the target word in context corresponds to the given sense or not. We believe the strategies we explored in the context of this challenge can be useful to other Natural Language Processing tasks. ### Response: Word Sense Disambiguation : RESEARCH_PROBLEM; BERT : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Brief fragments of sleep shorter than 15 s are defined as microsleep episodes (MSEs), often subjectively perceived as sleepiness. Their main characteristic is a slowing in frequency in the electroencephalogram (EEG ), similar to stage N1 sleep according to standard criteria. The maintenance of wakefulness test (MWT) is often used in a clinical setting to assess vigilance. Scoring of the MWT in most sleep-wake centers is limited to classical definition of sleep (30-s epochs), and MSEs are mostly not considered in the absence of established scoring criteria defining MSEs but also because of the laborious work. We aimed for automatic detection of MSEs with machine learning, i.e. with deep learning based on raw EEG and EOG data as input. We analyzed MWT data of 76 patients. Experts visually scored wakefulness, and according to recently developed scoring criteria MSEs, microsleep episode candidates (MSEc), and episodes of drowsiness (ED). We implemented segmentation algorithms based on convolutional neural networks (CNNs) and a combination of a CNN with a long-short term memory (LSTM ) network. A LSTM network is a type of a recurrent neural network which has a memory for past events and takes them into account. Data of 53 patients were used for training of the classifiers, 12 for validation and 11 for testing. Our algorithms showed a good performance close to human experts. The detection was very good for wakefulness and MSEs and poor for MSEc and ED, similar to the low inter-expert reliability for these borderline segments. We provide a proof of principle that it is feasible to reliably detect MSEs with deep neuronal networks based on raw EEG and EOG data with a performance close to that of human experts. Code of algorithms ( https://github.com/alexander-malafeev/microsleep-detection ) and data ( https://zenodo.org/record/3251716 ) are available.",(EEG : RESEARCH_PROBLEM; EEG : RESEARCH_PROBLEM; (LSTM : METHOD; LSTM : METHOD; EEG : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Brief fragments of sleep shorter than 15 s are defined as microsleep episodes (MSEs), often subjectively perceived as sleepiness. Their main characteristic is a slowing in frequency in the electroencephalogram (EEG ), similar to stage N1 sleep according to standard criteria. The maintenance of wakefulness test (MWT) is often used in a clinical setting to assess vigilance. Scoring of the MWT in most sleep-wake centers is limited to classical definition of sleep (30-s epochs), and MSEs are mostly not considered in the absence of established scoring criteria defining MSEs but also because of the laborious work. We aimed for automatic detection of MSEs with machine learning, i.e. with deep learning based on raw EEG and EOG data as input. We analyzed MWT data of 76 patients. Experts visually scored wakefulness, and according to recently developed scoring criteria MSEs, microsleep episode candidates (MSEc), and episodes of drowsiness (ED). We implemented segmentation algorithms based on convolutional neural networks (CNNs) and a combination of a CNN with a long-short term memory (LSTM ) network. A LSTM network is a type of a recurrent neural network which has a memory for past events and takes them into account. Data of 53 patients were used for training of the classifiers, 12 for validation and 11 for testing. Our algorithms showed a good performance close to human experts. The detection was very good for wakefulness and MSEs and poor for MSEc and ED, similar to the low inter-expert reliability for these borderline segments. We provide a proof of principle that it is feasible to reliably detect MSEs with deep neuronal networks based on raw EEG and EOG data with a performance close to that of human experts. Code of algorithms ( https://github.com/alexander-malafeev/microsleep-detection ) and data ( https://zenodo.org/record/3251716 ) are available. ### Response: (EEG : RESEARCH_PROBLEM; EEG : RESEARCH_PROBLEM; (LSTM : METHOD; LSTM : METHOD; EEG : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Recently several datasets have been proposed to encourage research in Question Answering domains where commonsense knowledge is expected to play an important role. Recent language models such as ROBERT A, BERT and GPT that have been pre-trained on Wikipedia articles and books have shown reasonable performance with little fine-tuning on several such Multiple Choice Question-Answering (MCQ) datasets. Our goal in this work is to develop methods to incorporate additional (commonsense) knowledge into language model-based approaches for better question-answering in such domains. In this work, we first categorize external knowledge sources, and show performance does improve on using such sources. We then explore three different strategies for knowledge incorporation and four different models for question-answering using external commonsense knowledge. We analyze our predictions to explore the scope of further improvements.",Question Answering : RESEARCH_PROBLEM; ROBERT : METHOD; BERT : METHOD; GPT : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Recently several datasets have been proposed to encourage research in Question Answering domains where commonsense knowledge is expected to play an important role. Recent language models such as ROBERT A, BERT and GPT that have been pre-trained on Wikipedia articles and books have shown reasonable performance with little fine-tuning on several such Multiple Choice Question-Answering (MCQ) datasets. Our goal in this work is to develop methods to incorporate additional (commonsense) knowledge into language model-based approaches for better question-answering in such domains. In this work, we first categorize external knowledge sources, and show performance does improve on using such sources. We then explore three different strategies for knowledge incorporation and four different models for question-answering using external commonsense knowledge. We analyze our predictions to explore the scope of further improvements. ### Response: Question Answering : RESEARCH_PROBLEM; ROBERT : METHOD; BERT : METHOD; GPT : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Heavily pre-trained transformer models such as BERT have recently shown to be remarkably powerful at language modelling by achieving impressive results on numerous downstream tasks. It has also been shown that they are able to implicitly store factual knowledge in their parameters after pre-training. Understanding what the pre-training procedure of LMs actually learns is a crucial step for using and improving them for Conversational Recommender Systems (CRS). We first study how much off-the-shelf pre-trained BERT ""knows"" about recommendation items such as books, movies and music. In order to analyze the knowledge stored in BERT 's parameters, we use different probes that require different types of knowledge to solve, namely content-based and collaborative-based. Content-based knowledge is knowledge that requires the model to match the titles of items with their content information, such as textual descriptions and genres. In contrast, collaborative-based knowledge requires the model to match items with similar ones, according to community interactions such as ratings. We resort to BERT 's Masked Language Modelling head to probe its knowledge about the genre of items, with cloze style prompts. In addition, we employ BERT 's Next Sentence Prediction head and representations' similarity to compare relevant and non-relevant search and recommendation query-document inputs to explore whether BERT can, without any fine-tuning, rank relevant items first. Finally, we study how BERT performs in a conversational recommendation downstream task. Overall, our analyses and experiments show that: (i) BERT has knowledge stored in its parameters about the content of books, movies and music; (ii) it has more content-based knowledge than collaborative-based knowledge; and (iii) fails on conversational recommendation when faced with adversarial data.",BERT : METHOD; BERT : METHOD; BERT : METHOD; BERT : METHOD; Language Modelling : RESEARCH_PROBLEM; BERT : METHOD; BERT : METHOD; BERT : METHOD; BERT : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Heavily pre-trained transformer models such as BERT have recently shown to be remarkably powerful at language modelling by achieving impressive results on numerous downstream tasks. It has also been shown that they are able to implicitly store factual knowledge in their parameters after pre-training. Understanding what the pre-training procedure of LMs actually learns is a crucial step for using and improving them for Conversational Recommender Systems (CRS). We first study how much off-the-shelf pre-trained BERT ""knows"" about recommendation items such as books, movies and music. In order to analyze the knowledge stored in BERT 's parameters, we use different probes that require different types of knowledge to solve, namely content-based and collaborative-based. Content-based knowledge is knowledge that requires the model to match the titles of items with their content information, such as textual descriptions and genres. In contrast, collaborative-based knowledge requires the model to match items with similar ones, according to community interactions such as ratings. We resort to BERT 's Masked Language Modelling head to probe its knowledge about the genre of items, with cloze style prompts. In addition, we employ BERT 's Next Sentence Prediction head and representations' similarity to compare relevant and non-relevant search and recommendation query-document inputs to explore whether BERT can, without any fine-tuning, rank relevant items first. Finally, we study how BERT performs in a conversational recommendation downstream task. Overall, our analyses and experiments show that: (i) BERT has knowledge stored in its parameters about the content of books, movies and music; (ii) it has more content-based knowledge than collaborative-based knowledge; and (iii) fails on conversational recommendation when faced with adversarial data. ### Response: BERT : METHOD; BERT : METHOD; BERT : METHOD; BERT : METHOD; Language Modelling : RESEARCH_PROBLEM; BERT : METHOD; BERT : METHOD; BERT : METHOD; BERT : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Named Entity Recognition is one of the most important text processing requirement in many NLP tasks. In this paper we use a deep architecture to accomplish the task of recognizing named entities in a given Hindi text sentence. Bidirectional Long Short Term Memory (BiLSTM ) based techniques have been used for NER task in literature. In this paper, we first tune BiLSTM low-resource scenario to work for Hindi NER and propose two enhancements namely (a) de-noising auto-encoder (DAE) LSTM and (b) conditioning LSTM which show improvement in NER task compared to the BiLSTM approach. We use pre-trained word embedding to represent the words in the corpus, and the NER tags of the words are as defined by the used annotated corpora. Experiments have been performed to analyze the performance of different word embeddings and batch sizes which is essential for training deep models.",Named Entity Recognition : RESEARCH_PROBLEM; (BiLSTM : METHOD; NER : RESEARCH_PROBLEM; BiLSTM : METHOD; NER : RESEARCH_PROBLEM; NER : RESEARCH_PROBLEM; BiLSTM : METHOD; NER : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Named Entity Recognition is one of the most important text processing requirement in many NLP tasks. In this paper we use a deep architecture to accomplish the task of recognizing named entities in a given Hindi text sentence. Bidirectional Long Short Term Memory (BiLSTM ) based techniques have been used for NER task in literature. In this paper, we first tune BiLSTM low-resource scenario to work for Hindi NER and propose two enhancements namely (a) de-noising auto-encoder (DAE) LSTM and (b) conditioning LSTM which show improvement in NER task compared to the BiLSTM approach. We use pre-trained word embedding to represent the words in the corpus, and the NER tags of the words are as defined by the used annotated corpora. Experiments have been performed to analyze the performance of different word embeddings and batch sizes which is essential for training deep models. ### Response: Named Entity Recognition : RESEARCH_PROBLEM; (BiLSTM : METHOD; NER : RESEARCH_PROBLEM; BiLSTM : METHOD; NER : RESEARCH_PROBLEM; NER : RESEARCH_PROBLEM; BiLSTM : METHOD; NER : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","It is well understood that Dynamic Time Warping (DTW ) is effective in revealing similarities between time series that do not align perfectly. In this paper, we illustrate this on spectroscopy time-series data. We show that DTW is effective in improving accuracy on a regression task when only a single wavelength is considered. When combined with k-Nearest Neighbour, DTW has the added advantage that it can reveal similarities and differences between samples at the level of the time-series. However, in the problem, we consider here data is available across a spectrum of wavelengths. If aggregate statistics (means, variances) are used across many wavelengths the benefits of DTW are no longer apparent. We present this as another example of a situation where big data trumps sophisticated models in Machine Learning.",Dynamic Time Warping : RESEARCH_PROBLEM; (DTW : METHOD; DTW : METHOD; DTW : METHOD; DTW : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: It is well understood that Dynamic Time Warping (DTW ) is effective in revealing similarities between time series that do not align perfectly. In this paper, we illustrate this on spectroscopy time-series data. We show that DTW is effective in improving accuracy on a regression task when only a single wavelength is considered. When combined with k-Nearest Neighbour, DTW has the added advantage that it can reveal similarities and differences between samples at the level of the time-series. However, in the problem, we consider here data is available across a spectrum of wavelengths. If aggregate statistics (means, variances) are used across many wavelengths the benefits of DTW are no longer apparent. We present this as another example of a situation where big data trumps sophisticated models in Machine Learning. ### Response: Dynamic Time Warping : RESEARCH_PROBLEM; (DTW : METHOD; DTW : METHOD; DTW : METHOD; DTW : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","In this work, we propose an ensemble of classifiers to distinguish betweenvarious degrees of abnormalities of the heart using Phonocardiogram (PCG)signals acquired using digital stethoscopes in a clinical setting, for theINTERSPEECH 2018 Computational Paralinguistics (ComParE) Heart BeatsSubChallenge. Our primary classification framework constitutes a convolutionalneural network with 1D-CNN time-convolution (tConv) layers, which uses featurestransferred from a model trained on the 2016 Physionet Heart Sound Database. Wealso employ a Representation Learning (RL) approach to generate features in anunsupervised manner using Deep Recurrent Autoencoders and use Support VectorMachine (SVM ) and Linear Discriminant Analysis (LDA) classifiers. Finally, weutilize an SVM classifier on a high-dimensional segment-level feature extractedusing various functionals on short-term acoustic features, i.e., Low-LevelDescriptors (LLD). An ensemble of the three different approaches provides arelative improvement of 11.13% compared to our best single sub-system in termsof the Unweighted Average Recall (UAR) performance metric on the evaluationdataset.",Representation Learning : RESEARCH_PROBLEM; (SVM : METHOD; SVM : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: In this work, we propose an ensemble of classifiers to distinguish betweenvarious degrees of abnormalities of the heart using Phonocardiogram (PCG)signals acquired using digital stethoscopes in a clinical setting, for theINTERSPEECH 2018 Computational Paralinguistics (ComParE) Heart BeatsSubChallenge. Our primary classification framework constitutes a convolutionalneural network with 1D-CNN time-convolution (tConv) layers, which uses featurestransferred from a model trained on the 2016 Physionet Heart Sound Database. Wealso employ a Representation Learning (RL) approach to generate features in anunsupervised manner using Deep Recurrent Autoencoders and use Support VectorMachine (SVM ) and Linear Discriminant Analysis (LDA) classifiers. Finally, weutilize an SVM classifier on a high-dimensional segment-level feature extractedusing various functionals on short-term acoustic features, i.e., Low-LevelDescriptors (LLD). An ensemble of the three different approaches provides arelative improvement of 11.13% compared to our best single sub-system in termsof the Unweighted Average Recall (UAR) performance metric on the evaluationdataset. ### Response: Representation Learning : RESEARCH_PROBLEM; (SVM : METHOD; SVM : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Real-world Relation Extraction (RE) tasks are challenging to deal with, either due to limited training data or class imbalance issues. In this work, we present Data Augmented Relation Extraction (DARE), a simple method to augment training data by properly fine-tuning GPT-2 to generate examples for specific relation types. The generated training data is then used in combination with the gold dataset to train a BERT-based RE classifier. In a series of experiments we show the advantages of our method, which leads in improvements of up to 11 F1 score points against a strong base-line. Also, DARE achieves new state of the art in three widely used biomedical RE datasets surpassing the previous best results by 4.7 F1 points on average.",Relation Extraction : RESEARCH_PROBLEM; Relation Extraction : RESEARCH_PROBLEM; GPT-2 : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Real-world Relation Extraction (RE) tasks are challenging to deal with, either due to limited training data or class imbalance issues. In this work, we present Data Augmented Relation Extraction (DARE), a simple method to augment training data by properly fine-tuning GPT-2 to generate examples for specific relation types. The generated training data is then used in combination with the gold dataset to train a BERT-based RE classifier. In a series of experiments we show the advantages of our method, which leads in improvements of up to 11 F1 score points against a strong base-line. Also, DARE achieves new state of the art in three widely used biomedical RE datasets surpassing the previous best results by 4.7 F1 points on average. ### Response: Relation Extraction : RESEARCH_PROBLEM; Relation Extraction : RESEARCH_PROBLEM; GPT-2 : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","BERT and its variants have achieved state-of-the-art performance in various NLP tasks. Since then, various works have been proposed to analyze the linguistic information being captured in BERT . However, the current works do not provide an insight into how BERT is able to achieve near human-level performance on the task of Reading Comprehension based Question Answering. In this work, we attempt to interpret BERT for RCQA. Since BERT layers do not have predefined roles, we define a layer's role or functionality using Integrated Gradients. Based on the defined roles, we perform a preliminary analysis across all layers. We observed that the initial layers focus on query-passage interaction, whereas later layers focus more on contextual understanding and enhancing the answer prediction. Specifically for quantifier questions (how much/how many), we notice that BERT focuses on confusing words (i.e., on other numerical quantities in the passage) in the later layers, but still manages to predict the answer correctly. The fine-tuning and analysis scripts will be publicly available at https://github.com/iitmnlp/BERT -Analysis-RCQA .",BERT : METHOD; BERT : METHOD; BERT : METHOD; Reading Comprehension : RESEARCH_PROBLEM; BERT : METHOD; BERT : METHOD; BERT : METHOD; https://github.com/iitmnlp/BERT : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: BERT and its variants have achieved state-of-the-art performance in various NLP tasks. Since then, various works have been proposed to analyze the linguistic information being captured in BERT . However, the current works do not provide an insight into how BERT is able to achieve near human-level performance on the task of Reading Comprehension based Question Answering. In this work, we attempt to interpret BERT for RCQA. Since BERT layers do not have predefined roles, we define a layer's role or functionality using Integrated Gradients. Based on the defined roles, we perform a preliminary analysis across all layers. We observed that the initial layers focus on query-passage interaction, whereas later layers focus more on contextual understanding and enhancing the answer prediction. Specifically for quantifier questions (how much/how many), we notice that BERT focuses on confusing words (i.e., on other numerical quantities in the passage) in the later layers, but still manages to predict the answer correctly. The fine-tuning and analysis scripts will be publicly available at https://github.com/iitmnlp/BERT -Analysis-RCQA . ### Response: BERT : METHOD; BERT : METHOD; BERT : METHOD; Reading Comprehension : RESEARCH_PROBLEM; BERT : METHOD; BERT : METHOD; BERT : METHOD; https://github.com/iitmnlp/BERT : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","This paper considers an architecture referred to as Cascade Region Proposal Network (Cascade RPN ) for improving the region-proposal quality and detection performance by \textit{systematically} addressing the limitation of the conventional RPN that \textit{heuristically defines} the anchors and \textit{aligns} the features to the anchors. First, instead of using multiple anchors with predefined scales and aspect ratios, Cascade RPN relies on a \textit{single anchor} per location and performs multi-stage refinement. Each stage is progressively more stringent in defining positive samples by starting out with an anchor-free metric followed by anchor-based metrics in the ensuing stages. Second, to attain alignment between the features and the anchors throughout the stages, \textit{adaptive convolution} is proposed that takes the anchors in addition to the image features as its input and learns the sampled features guided by the anchors. A simple implementation of a two-stage Cascade RPN achieves AR 13.4 points higher than that of the conventional RPN , surpassing any existing region proposal methods. When adopting to Fast R-CNN and Faster R-CNN, Cascade RPN can improve the detection mAP by 3.1 and 3.5 points, respectively. The code is made publicly available at \url{https://github.com/thangvubk/Cascade-RPN .git}.",Region Proposal : RESEARCH_PROBLEM; RPN : METHOD; RPN : METHOD; RPN : METHOD; RPN : METHOD; RPN : METHOD; Fast R-CNN : METHOD; RPN : METHOD; \url{https://github.com/thangvubk/Cascade-RPN : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: This paper considers an architecture referred to as Cascade Region Proposal Network (Cascade RPN ) for improving the region-proposal quality and detection performance by \textit{systematically} addressing the limitation of the conventional RPN that \textit{heuristically defines} the anchors and \textit{aligns} the features to the anchors. First, instead of using multiple anchors with predefined scales and aspect ratios, Cascade RPN relies on a \textit{single anchor} per location and performs multi-stage refinement. Each stage is progressively more stringent in defining positive samples by starting out with an anchor-free metric followed by anchor-based metrics in the ensuing stages. Second, to attain alignment between the features and the anchors throughout the stages, \textit{adaptive convolution} is proposed that takes the anchors in addition to the image features as its input and learns the sampled features guided by the anchors. A simple implementation of a two-stage Cascade RPN achieves AR 13.4 points higher than that of the conventional RPN , surpassing any existing region proposal methods. When adopting to Fast R-CNN and Faster R-CNN, Cascade RPN can improve the detection mAP by 3.1 and 3.5 points, respectively. The code is made publicly available at \url{https://github.com/thangvubk/Cascade-RPN .git}. ### Response: Region Proposal : RESEARCH_PROBLEM; RPN : METHOD; RPN : METHOD; RPN : METHOD; RPN : METHOD; RPN : METHOD; Fast R-CNN : METHOD; RPN : METHOD; \url{https://github.com/thangvubk/Cascade-RPN : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","We introduce coroICA , confounding-robust independent component analysis, a novel ICA algorithm which decomposes linearly mixed multivariate observations into independent components that are corrupted (and rendered dependent) by hidden group-wise stationary confounding. It extends the ordinary ICA model in a theoretically sound and explicit way to incorporate group-wise (or environment-wise) confounding. We show that our proposed general noise model allows to perform ICA in settings where other noisy ICA procedures fail. Additionally, it can be used for applications with grouped data by adjusting for different stationary noise within each group. Our proposed noise model has a natural relation to causality and we explain how it can be applied in the context of causal inference. In addition to our theoretical framework, we provide an efficient estimation procedure and prove identifiability of the unmixing matrix under mild assumptions. Finally, we illustrate the performance and robustness of our method on simulated data, provide audible and visual examples, and demonstrate the applicability to real-world scenarios by experiments on publicly available Antarctic ice core data as well as two EEG data sets. We provide a scikit-learn compatible pip-installable Python package coroICA as well as R and Matlab implementations accompanied by a documentation at https://sweichwald.de/coroICA /",coroICA : METHOD; ICA : METHOD; ICA : METHOD; ICA : METHOD; ICA : METHOD; EEG : RESEARCH_PROBLEM; coroICA : METHOD; https://sweichwald.de/coroICA : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: We introduce coroICA , confounding-robust independent component analysis, a novel ICA algorithm which decomposes linearly mixed multivariate observations into independent components that are corrupted (and rendered dependent) by hidden group-wise stationary confounding. It extends the ordinary ICA model in a theoretically sound and explicit way to incorporate group-wise (or environment-wise) confounding. We show that our proposed general noise model allows to perform ICA in settings where other noisy ICA procedures fail. Additionally, it can be used for applications with grouped data by adjusting for different stationary noise within each group. Our proposed noise model has a natural relation to causality and we explain how it can be applied in the context of causal inference. In addition to our theoretical framework, we provide an efficient estimation procedure and prove identifiability of the unmixing matrix under mild assumptions. Finally, we illustrate the performance and robustness of our method on simulated data, provide audible and visual examples, and demonstrate the applicability to real-world scenarios by experiments on publicly available Antarctic ice core data as well as two EEG data sets. We provide a scikit-learn compatible pip-installable Python package coroICA as well as R and Matlab implementations accompanied by a documentation at https://sweichwald.de/coroICA / ### Response: coroICA : METHOD; ICA : METHOD; ICA : METHOD; ICA : METHOD; ICA : METHOD; EEG : RESEARCH_PROBLEM; coroICA : METHOD; https://sweichwald.de/coroICA : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","We address the problem of defining a group sparse formulation for Principal Components Analysis (PCA ) - or its equivalent formulations as Low Rank approximation or Dictionary Learning problems - which achieves a compromise between maximizing the variance explained by the components and promoting sparsity of the loadings. So we propose first a new definition of the variance explained by non necessarily orthogonal components, which is optimal in some aspect and compatible with the principal components situation. Then we use a specific regularization of this variance by the group-$\ell_{1}$ norm to define a Group Sparse Maximum Variance (GSMV) formulation of PCA . The GSMV formulation achieves our objective by construction, and has the nice property that the inner non smooth optimization problem can be solved analytically, thus reducing GSMV to the maximization of a smooth and convex function under unit norm and orthogonality constraints, which generalizes Journee et al. (2010) to group sparsity. Numerical comparison with deflation on synthetic data shows that GSMV produces steadily slightly better and more robust results for the retrieval of hidden sparse structures, and is about three times faster on these examples. Application to real data shows the interest of group sparsity for variables selection in PCA of mixed data (categorical/numerical) .",(PCA : METHOD; Dictionary Learning : RESEARCH_PROBLEM; PCA : METHOD; PCA : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: We address the problem of defining a group sparse formulation for Principal Components Analysis (PCA ) - or its equivalent formulations as Low Rank approximation or Dictionary Learning problems - which achieves a compromise between maximizing the variance explained by the components and promoting sparsity of the loadings. So we propose first a new definition of the variance explained by non necessarily orthogonal components, which is optimal in some aspect and compatible with the principal components situation. Then we use a specific regularization of this variance by the group-$\ell_{1}$ norm to define a Group Sparse Maximum Variance (GSMV) formulation of PCA . The GSMV formulation achieves our objective by construction, and has the nice property that the inner non smooth optimization problem can be solved analytically, thus reducing GSMV to the maximization of a smooth and convex function under unit norm and orthogonality constraints, which generalizes Journee et al. (2010) to group sparsity. Numerical comparison with deflation on synthetic data shows that GSMV produces steadily slightly better and more robust results for the retrieval of hidden sparse structures, and is about three times faster on these examples. Application to real data shows the interest of group sparsity for variables selection in PCA of mixed data (categorical/numerical) . ### Response: (PCA : METHOD; Dictionary Learning : RESEARCH_PROBLEM; PCA : METHOD; PCA : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Model extraction attacks attempt to replicate a target machine learning model from predictions obtained by querying its inference API. Most existing attacks on Deep Neural Networks achieve this by supervised training of the copy using the victim's predictions. An emerging class of attacks exploit algebraic properties of DNNs to obtain high-fidelity copies using orders of magnitude fewer queries than the prior state-of-the-art. So far, such powerful attacks have been limited to networks with few hidden layers and ReLU activations.In this paper we present algebraic attacks on large-scale natural language models in a grey-box setting, targeting models with a pre-trained (public) encoder followed by a single (private) classification layer. Our key observation is that a small set of arbitrary embedding vectors is likely to form a basis of the classification layer's input space, which a grey-box adversary can compute. We show how to use this information to solve an equation system that determines the classification layer from the corresponding probability outputs.We evaluate the effectiveness of our attacks on different sizes of transformer models and downstream tasks. Our key findings are that (i) with frozen base layers, high-fidelity extraction is possible with a number of queries that is as small as twice the input dimension of the last layer. This is true even for queries that are entirely in-distribution, making extraction attacks indistinguishable from legitimate use; (ii) with fine-tuned base layers, the effectiveness of algebraic attacks decreases with the learning rate, showing that fine-tuning is not only beneficial for accuracy but also indispensable for model confidentiality.",Model extraction : RESEARCH_PROBLEM; ReLU : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Model extraction attacks attempt to replicate a target machine learning model from predictions obtained by querying its inference API. Most existing attacks on Deep Neural Networks achieve this by supervised training of the copy using the victim's predictions. An emerging class of attacks exploit algebraic properties of DNNs to obtain high-fidelity copies using orders of magnitude fewer queries than the prior state-of-the-art. So far, such powerful attacks have been limited to networks with few hidden layers and ReLU activations.In this paper we present algebraic attacks on large-scale natural language models in a grey-box setting, targeting models with a pre-trained (public) encoder followed by a single (private) classification layer. Our key observation is that a small set of arbitrary embedding vectors is likely to form a basis of the classification layer's input space, which a grey-box adversary can compute. We show how to use this information to solve an equation system that determines the classification layer from the corresponding probability outputs.We evaluate the effectiveness of our attacks on different sizes of transformer models and downstream tasks. Our key findings are that (i) with frozen base layers, high-fidelity extraction is possible with a number of queries that is as small as twice the input dimension of the last layer. This is true even for queries that are entirely in-distribution, making extraction attacks indistinguishable from legitimate use; (ii) with fine-tuned base layers, the effectiveness of algebraic attacks decreases with the learning rate, showing that fine-tuning is not only beneficial for accuracy but also indispensable for model confidentiality. ### Response: Model extraction : RESEARCH_PROBLEM; ReLU : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","We present AIA-BDE, a corpus of 380 domain-oriented FAQs in Portuguese and their variations, i.e., paraphrases or entailed questions, created manually, by humans, or automatically, with Google Translate. Its aims to be used as a benchmark for FAQ retrieval and automatic question-answering, but may be useful in other contexts, such as the development of task-oriented dialogue systems, or models for natural language inference in an interrogative context. We also report on two experiments. Matching variations with their original questions was not trivial with a set of unsupervised baselines, especially for manually created variations. Besides high performances obtained with ELMo and BERT embeddings, an Information Retrieval system was surprisingly competitive when considering only the first hit. In the second experiment, text classifiers were trained with the original questions, and tested when assigning each variation to one of three possible sources, or assigning them as out-of-domain. Here, the difference between manual and automatic variations was not so significant.",ELMo : METHOD; BERT : METHOD; Information Retrieval : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: We present AIA-BDE, a corpus of 380 domain-oriented FAQs in Portuguese and their variations, i.e., paraphrases or entailed questions, created manually, by humans, or automatically, with Google Translate. Its aims to be used as a benchmark for FAQ retrieval and automatic question-answering, but may be useful in other contexts, such as the development of task-oriented dialogue systems, or models for natural language inference in an interrogative context. We also report on two experiments. Matching variations with their original questions was not trivial with a set of unsupervised baselines, especially for manually created variations. Besides high performances obtained with ELMo and BERT embeddings, an Information Retrieval system was surprisingly competitive when considering only the first hit. In the second experiment, text classifiers were trained with the original questions, and tested when assigning each variation to one of three possible sources, or assigning them as out-of-domain. Here, the difference between manual and automatic variations was not so significant. ### Response: ELMo : METHOD; BERT : METHOD; Information Retrieval : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","This paper describes the work done by team tearsofjoy participating in the VarDial 2019 Evaluation Campaign. We developed two systems based on Support Vector Machines: SVM with a flat combination of features and SVM ensembles. We participated in all language/dialect identification tasks, as well as the Moldavian vs. Romanian cross-dialect topic identification (MRC) task. Our team achieved first place in German Dialect identification (GDI) and MRC subtasks 2 and 3, second place in the simplified variant of Discriminating between Mainland and Taiwan variation of Mandarin Chinese (DMT) as well as Cuneiform Language Identification (CLI), and third and fifth place in DMT traditional and MRC subtask 1 respectively. In most cases, the SVM with a flat combination of features performed better than SVM ensembles. Besides describing the systems and the results obtained by them, we provide a tentative comparison between the feature combination methods, and present additional experiments with a method of adaptation to the test set, which may indicate potential pitfalls with some of the data sets.",SVM : METHOD; SVM : METHOD; Language Identification : RESEARCH_PROBLEM; SVM : METHOD; SVM : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: This paper describes the work done by team tearsofjoy participating in the VarDial 2019 Evaluation Campaign. We developed two systems based on Support Vector Machines: SVM with a flat combination of features and SVM ensembles. We participated in all language/dialect identification tasks, as well as the Moldavian vs. Romanian cross-dialect topic identification (MRC) task. Our team achieved first place in German Dialect identification (GDI) and MRC subtasks 2 and 3, second place in the simplified variant of Discriminating between Mainland and Taiwan variation of Mandarin Chinese (DMT) as well as Cuneiform Language Identification (CLI), and third and fifth place in DMT traditional and MRC subtask 1 respectively. In most cases, the SVM with a flat combination of features performed better than SVM ensembles. Besides describing the systems and the results obtained by them, we provide a tentative comparison between the feature combination methods, and present additional experiments with a method of adaptation to the test set, which may indicate potential pitfalls with some of the data sets. ### Response: SVM : METHOD; SVM : METHOD; Language Identification : RESEARCH_PROBLEM; SVM : METHOD; SVM : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","The design of small molecules with bespoke properties is of central importance to drug discovery. However significant challenges yet remain for computational methods, despite recent advances such as deep recurrent networks and reinforcement learning strategies for sequence generation, and it can be difficult to compare results across different works. This work proposes 19 benchmarks selected by subject experts, expands smaller datasets previously used to approximately 1.1 million training molecules, and explores how to apply new reinforcement learning techniques effectively for molecular design. The benchmarks here, built as OpenAI Gym environments, will be open-sourced to encourage innovation in molecular design algorithms and to enable usage by those without a background in chemistry. Finally, this work explores recent development in reinforcement-learning methods with excellent sample complexity (the A2C and PPO algorithms) and investigates their behavior in molecular generation, demonstrating significant performance gains compared to standard reinforcement learning techniques.",OpenAI Gym : RESEARCH_PROBLEM; A2C : METHOD; PPO : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: The design of small molecules with bespoke properties is of central importance to drug discovery. However significant challenges yet remain for computational methods, despite recent advances such as deep recurrent networks and reinforcement learning strategies for sequence generation, and it can be difficult to compare results across different works. This work proposes 19 benchmarks selected by subject experts, expands smaller datasets previously used to approximately 1.1 million training molecules, and explores how to apply new reinforcement learning techniques effectively for molecular design. The benchmarks here, built as OpenAI Gym environments, will be open-sourced to encourage innovation in molecular design algorithms and to enable usage by those without a background in chemistry. Finally, this work explores recent development in reinforcement-learning methods with excellent sample complexity (the A2C and PPO algorithms) and investigates their behavior in molecular generation, demonstrating significant performance gains compared to standard reinforcement learning techniques. ### Response: OpenAI Gym : RESEARCH_PROBLEM; A2C : METHOD; PPO : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Automated segmentation of human cardiac magnetic resonance datasets has been steadily improving during recent years. However, these methods are not directly applicable in preclinical context due to limited datasets and lower image resolution. Successful application of deep architectures for rat cardiac segmentation, although of critical importance for preclinical evaluation of cardiac function, has to our knowledge not yet been reported. We developed segmentation models that expand on the standard U-Net architecture and evaluated separate models for systole and diastole phases, 2MSA, and one model for all timepoints, 1MSA. Furthermore, we calibrated model outputs using a Gaussian Process (GP)-based prior to improve phase selection. Resulting models approach human performance in terms of left ventricular segmentation quality and ejection fraction (EF) estimation in both 1MSA and 2MSA settings (S{\o}rensen-Dice score 0.91 +/- 0.072 and 0.93 +/- 0.032, respectively). 2MSA achieved a mean absolute difference between estimated and reference EF of 3.5 +/- 2.5 %, while 1MSA resulted in 4.1 +/- 3.0 %. Applying Gaussian Processes to 1MSA allows to automate the selection of systole and diastole phases. Combined with a novel cardiac phase selection strategy, our work presents an important first step towards a fully automated segmentation pipeline in the context of rat cardiac analysis.",U-Net : METHOD; Gaussian Processes : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Automated segmentation of human cardiac magnetic resonance datasets has been steadily improving during recent years. However, these methods are not directly applicable in preclinical context due to limited datasets and lower image resolution. Successful application of deep architectures for rat cardiac segmentation, although of critical importance for preclinical evaluation of cardiac function, has to our knowledge not yet been reported. We developed segmentation models that expand on the standard U-Net architecture and evaluated separate models for systole and diastole phases, 2MSA, and one model for all timepoints, 1MSA. Furthermore, we calibrated model outputs using a Gaussian Process (GP)-based prior to improve phase selection. Resulting models approach human performance in terms of left ventricular segmentation quality and ejection fraction (EF) estimation in both 1MSA and 2MSA settings (S{\o}rensen-Dice score 0.91 +/- 0.072 and 0.93 +/- 0.032, respectively). 2MSA achieved a mean absolute difference between estimated and reference EF of 3.5 +/- 2.5 %, while 1MSA resulted in 4.1 +/- 3.0 %. Applying Gaussian Processes to 1MSA allows to automate the selection of systole and diastole phases. Combined with a novel cardiac phase selection strategy, our work presents an important first step towards a fully automated segmentation pipeline in the context of rat cardiac analysis. ### Response: U-Net : METHOD; Gaussian Processes : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","We investigate the problem of multi-domain Dialogue State Tracking (DST) with open vocabulary, which aims to extract the state from the dialogue. Existing approaches usually concatenate previous dialogue state with dialogue history as the input to a bi-directional Transformer encoder. They rely on the self-attention mechanism of Transformer to connect tokens in them. However, attention may be paid to spurious connections, leading to wrong inference. In this paper, we propose to construct a dialogue state graph in which domains, slots and values from the previous dialogue state are connected properly. Through training, the graph node and edge embeddings can encode co-occurrence relations between domain-domain, slot-slot and domain-slot, reflecting the strong transition paths in general dialogue. The state graph, encoded with relational-GCN, is fused into the Transformer encoder. Experimental results show that our approach achieves a new state of the art on the task while remaining efficient. It outperforms existing open-vocabulary DST approaches.",Dialogue State Tracking : RESEARCH_PROBLEM; Transformer : METHOD; Transformer : METHOD; Transformer : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: We investigate the problem of multi-domain Dialogue State Tracking (DST) with open vocabulary, which aims to extract the state from the dialogue. Existing approaches usually concatenate previous dialogue state with dialogue history as the input to a bi-directional Transformer encoder. They rely on the self-attention mechanism of Transformer to connect tokens in them. However, attention may be paid to spurious connections, leading to wrong inference. In this paper, we propose to construct a dialogue state graph in which domains, slots and values from the previous dialogue state are connected properly. Through training, the graph node and edge embeddings can encode co-occurrence relations between domain-domain, slot-slot and domain-slot, reflecting the strong transition paths in general dialogue. The state graph, encoded with relational-GCN, is fused into the Transformer encoder. Experimental results show that our approach achieves a new state of the art on the task while remaining efficient. It outperforms existing open-vocabulary DST approaches. ### Response: Dialogue State Tracking : RESEARCH_PROBLEM; Transformer : METHOD; Transformer : METHOD; Transformer : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Unlike melody extraction and other aspects of music transcription, research on playing technique detection is still in its early stages. Compared to existing work mostly focused on playing technique detection for individual single notes, we propose a general end-to-end method based on Sound Event Detection by FCN for musical instrument playing technique detection. In our case, we choose Erhu, a well-known Chinese bowed-stringed instrument, to experiment with our method. Because of the limitation of FCN , we present an algorithm to detect on variable length audio. The effectiveness of the proposed framework is tested on a new dataset, its categorization of techniques is similar to our training dataset. The highest accuracy of our 3 experiments on the new test set is 87.31%. Furthermore, we also evaluate the performance of the proposed framework on 10 real-world studio music (produced by midi) and 7 real-world recording samples to address the ability of generalization on our model.",Sound Event Detection : RESEARCH_PROBLEM; FCN : METHOD; FCN : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Unlike melody extraction and other aspects of music transcription, research on playing technique detection is still in its early stages. Compared to existing work mostly focused on playing technique detection for individual single notes, we propose a general end-to-end method based on Sound Event Detection by FCN for musical instrument playing technique detection. In our case, we choose Erhu, a well-known Chinese bowed-stringed instrument, to experiment with our method. Because of the limitation of FCN , we present an algorithm to detect on variable length audio. The effectiveness of the proposed framework is tested on a new dataset, its categorization of techniques is similar to our training dataset. The highest accuracy of our 3 experiments on the new test set is 87.31%. Furthermore, we also evaluate the performance of the proposed framework on 10 real-world studio music (produced by midi) and 7 real-world recording samples to address the ability of generalization on our model. ### Response: Sound Event Detection : RESEARCH_PROBLEM; FCN : METHOD; FCN : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","In few-shot learning scenarios, the challenge is to generalize and perform well on new unseen examples when only very few labeled examples are available for each task. Model-agnostic meta-learning (MAML ) has gained the popularity as one of the representative few-shot learning methods for its flexibility and applicability to diverse problems. However, MAML and its variants often resort to a simple loss function without any auxiliary loss function or regularization terms that can help achieve better generalization. The problem lies in that each application and task may require different auxiliary loss function, especially when tasks are diverse and distinct. Instead of attempting to hand-design an auxiliary loss function for each application and task, we introduce a new meta-learning framework with a loss function that adapts to each task. Our proposed framework, named Meta-Learning with Task-Adaptive Loss Function (MeTAL), demonstrates the effectiveness and the flexibility across various domains, such as few-shot classification and few-shot regression.",(MAML : METHOD; MAML : METHOD; Meta-Learning : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: In few-shot learning scenarios, the challenge is to generalize and perform well on new unseen examples when only very few labeled examples are available for each task. Model-agnostic meta-learning (MAML ) has gained the popularity as one of the representative few-shot learning methods for its flexibility and applicability to diverse problems. However, MAML and its variants often resort to a simple loss function without any auxiliary loss function or regularization terms that can help achieve better generalization. The problem lies in that each application and task may require different auxiliary loss function, especially when tasks are diverse and distinct. Instead of attempting to hand-design an auxiliary loss function for each application and task, we introduce a new meta-learning framework with a loss function that adapts to each task. Our proposed framework, named Meta-Learning with Task-Adaptive Loss Function (MeTAL), demonstrates the effectiveness and the flexibility across various domains, such as few-shot classification and few-shot regression. ### Response: (MAML : METHOD; MAML : METHOD; Meta-Learning : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","The application of machine learning(ML) and genetic programming(GP) to the image compression domain has produced promising results in many cases. The need for compression arises due to the exorbitant size of data shared on the internet. Compression is required for text, videos, or images, which are used almost everywhere on web be it news articles, social media posts, blogs, educational platforms, medical domain, government services, and many other websites, need packets for transmission and hence compression is necessary to avoid overwhelming the network. This paper discusses some of the implementations of image compression algorithms that use techniques such as Artificial Neural Networks, Residual Learning, Fuzzy Neural Networks, Convolutional Neural Nets, Deep Learning, Genetic Algorithms. The paper also describes an implementation of Vector Quantization using GA to generate codebook which is used for Lossy image compression. All these approaches prove to be very contrasting to the standard approaches to processing images due to the highly parallel and computationally extensive nature of machine learning algorithms. Such non-linear abilities of ML and GP make it widely popular for use in multiple domains. Traditional approaches are also combined with artificially intelligent systems, leading to hybrid systems, to achieve better results.",Quantization : RESEARCH_PROBLEM; GA : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: The application of machine learning(ML) and genetic programming(GP) to the image compression domain has produced promising results in many cases. The need for compression arises due to the exorbitant size of data shared on the internet. Compression is required for text, videos, or images, which are used almost everywhere on web be it news articles, social media posts, blogs, educational platforms, medical domain, government services, and many other websites, need packets for transmission and hence compression is necessary to avoid overwhelming the network. This paper discusses some of the implementations of image compression algorithms that use techniques such as Artificial Neural Networks, Residual Learning, Fuzzy Neural Networks, Convolutional Neural Nets, Deep Learning, Genetic Algorithms. The paper also describes an implementation of Vector Quantization using GA to generate codebook which is used for Lossy image compression. All these approaches prove to be very contrasting to the standard approaches to processing images due to the highly parallel and computationally extensive nature of machine learning algorithms. Such non-linear abilities of ML and GP make it widely popular for use in multiple domains. Traditional approaches are also combined with artificially intelligent systems, leading to hybrid systems, to achieve better results. ### Response: Quantization : RESEARCH_PROBLEM; GA : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Data augmentation has been an indispensable tool to improve the performance of deep neural networks, however the augmentation can hardly transfer among different tasks and datasets. Consequently, a recent trend is to adopt AutoML technique to learn proper augmentation policy without extensive hand-crafted tuning. In this paper, we propose an efficient differentiable search algorithm called Direct Differentiable Augmentation Search (DDAS). It exploits meta-learning with one-step gradient update and continuous relaxation to the expected training loss for efficient search. Our DDAS can achieve efficient augmentation search without relying on approximations such as Gumbel Softmax or second order gradient approximation. To further reduce the adverse effect of improper augmentations, we organize the search space into a two level hierarchy, in which we first decide whether to apply augmentation, and then determine the specific augmentation policy. On standard image classification benchmarks, our DDAS achieves state-of-the-art performance and efficiency tradeoff while reducing the search cost dramatically, e.g. 0.15 GPU hours for CIFAR-10. In addition, we also use DDAS to search augmentation for object detection task and achieve comparable performance with AutoAugment, while being 1000x faster.",AutoML : RESEARCH_PROBLEM; Gumbel Softmax : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Data augmentation has been an indispensable tool to improve the performance of deep neural networks, however the augmentation can hardly transfer among different tasks and datasets. Consequently, a recent trend is to adopt AutoML technique to learn proper augmentation policy without extensive hand-crafted tuning. In this paper, we propose an efficient differentiable search algorithm called Direct Differentiable Augmentation Search (DDAS). It exploits meta-learning with one-step gradient update and continuous relaxation to the expected training loss for efficient search. Our DDAS can achieve efficient augmentation search without relying on approximations such as Gumbel Softmax or second order gradient approximation. To further reduce the adverse effect of improper augmentations, we organize the search space into a two level hierarchy, in which we first decide whether to apply augmentation, and then determine the specific augmentation policy. On standard image classification benchmarks, our DDAS achieves state-of-the-art performance and efficiency tradeoff while reducing the search cost dramatically, e.g. 0.15 GPU hours for CIFAR-10. In addition, we also use DDAS to search augmentation for object detection task and achieve comparable performance with AutoAugment, while being 1000x faster. ### Response: AutoML : RESEARCH_PROBLEM; Gumbel Softmax : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Compressive Sensing (CS) is an effective approach for fast Magnetic Resonance Imaging (MRI). It aims at reconstructing MR image from a small number of under-sampled data in k-space, and accelerating the data acquisition in MRI. To improve the current MRI system in reconstruction accuracy and computational speed, in this paper, we propose a novel deep architecture, dubbed ADMM -Net. ADMM -Net is defined over a data flow graph, which is derived from the iterative procedures in Alternating Direction Method of Multipliers (ADMM ) algorithm for optimizing a CS-based MRI model. In the training phase, all parameters of the net, e.g., image transforms, shrinkage functions, etc., are discriminatively trained end-to-end using L-BFGS algorithm. In the testing phase, it has computational overhead similar to ADMM but uses optimized parameters learned from the training data for CS-based reconstruction task. Experiments on MRI image reconstruction under different sampling ratios in k-space demonstrate that it significantly improves the baseline ADMM algorithm and achieves high reconstruction accuracies with fast computational speed.",Compressive Sensing : RESEARCH_PROBLEM; ADMM : METHOD; ADMM : METHOD; (ADMM : METHOD; ADMM : METHOD; ADMM : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Compressive Sensing (CS) is an effective approach for fast Magnetic Resonance Imaging (MRI). It aims at reconstructing MR image from a small number of under-sampled data in k-space, and accelerating the data acquisition in MRI. To improve the current MRI system in reconstruction accuracy and computational speed, in this paper, we propose a novel deep architecture, dubbed ADMM -Net. ADMM -Net is defined over a data flow graph, which is derived from the iterative procedures in Alternating Direction Method of Multipliers (ADMM ) algorithm for optimizing a CS-based MRI model. In the training phase, all parameters of the net, e.g., image transforms, shrinkage functions, etc., are discriminatively trained end-to-end using L-BFGS algorithm. In the testing phase, it has computational overhead similar to ADMM but uses optimized parameters learned from the training data for CS-based reconstruction task. Experiments on MRI image reconstruction under different sampling ratios in k-space demonstrate that it significantly improves the baseline ADMM algorithm and achieves high reconstruction accuracies with fast computational speed. ### Response: Compressive Sensing : RESEARCH_PROBLEM; ADMM : METHOD; ADMM : METHOD; (ADMM : METHOD; ADMM : METHOD; ADMM : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","We develop a Vector Quantized Spectral Clustering (VQSC) algorithm that is acombination of Spectral Clustering (SC) and Vector Quantization (VQ) samplingfor grouping Soybean genomes. The inspiration here is to use SC for itsaccuracy and VQ to make the algorithm computationally cheap (the complexity ofSC is cubic in-terms of the input size). Although the combination of SC and VQis not new, the novelty of our work is in developing the crucial similaritymatrix in SC as well as use of k-medoids in VQ, both adapted for the Soybeangenome data. We compare our approach with commonly used techniques like UPGMA(Un-weighted Pair Graph Method with Arithmetic Mean) and NJ (NeighbourJoining). Experimental results show that our approach outperforms both thesetechniques significantly in terms of cluster quality (up to 25% better clusterquality) and time complexity (order of magnitude faster).",Spectral Clustering : METHOD; Spectral Clustering : METHOD; Quantization : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: We develop a Vector Quantized Spectral Clustering (VQSC) algorithm that is acombination of Spectral Clustering (SC) and Vector Quantization (VQ) samplingfor grouping Soybean genomes. The inspiration here is to use SC for itsaccuracy and VQ to make the algorithm computationally cheap (the complexity ofSC is cubic in-terms of the input size). Although the combination of SC and VQis not new, the novelty of our work is in developing the crucial similaritymatrix in SC as well as use of k-medoids in VQ, both adapted for the Soybeangenome data. We compare our approach with commonly used techniques like UPGMA(Un-weighted Pair Graph Method with Arithmetic Mean) and NJ (NeighbourJoining). Experimental results show that our approach outperforms both thesetechniques significantly in terms of cluster quality (up to 25% better clusterquality) and time complexity (order of magnitude faster). ### Response: Spectral Clustering : METHOD; Spectral Clustering : METHOD; Quantization : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","In this work, we present a unified model that can handle both Keyword Spotting and Word Recognition with the same network architecture. The proposed network is comprised of a non-recurrent CTC branch and a Seq2Seq branch that is further augmented with an Autoencoding module. The related joint loss leads to a boost in recognition performance, while the Seq2Seq branch is used to create efficient word representations. We show how to further process these representations with binarization and a retraining scheme to provide compact and highly efficient descriptors, suitable for keyword spotting. Numerical results validate the usefulness of the proposed architecture, as our method outperforms the previous state-of-the-art in keyword spotting, and provides results in the ballpark of the leading methods for word recognition.",Keyword Spotting : RESEARCH_PROBLEM; Seq2Seq : METHOD; Seq2Seq : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: In this work, we present a unified model that can handle both Keyword Spotting and Word Recognition with the same network architecture. The proposed network is comprised of a non-recurrent CTC branch and a Seq2Seq branch that is further augmented with an Autoencoding module. The related joint loss leads to a boost in recognition performance, while the Seq2Seq branch is used to create efficient word representations. We show how to further process these representations with binarization and a retraining scheme to provide compact and highly efficient descriptors, suitable for keyword spotting. Numerical results validate the usefulness of the proposed architecture, as our method outperforms the previous state-of-the-art in keyword spotting, and provides results in the ballpark of the leading methods for word recognition. ### Response: Keyword Spotting : RESEARCH_PROBLEM; Seq2Seq : METHOD; Seq2Seq : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Named Entity Recognition (NER) is a fundamental Natural Language Processing (NLP) task and has remained an active research field. In recent years, transformer models and more specifically the BERT model developed at Google revolutionised the field of NLP. While the performance of transformer-based approaches such as BERT has been studied for NER, there has not yet been a study for the fine-grained Named Entity Recognition (FG-NER) task. In this paper, we compare three transformer-based models (BERT , RoBERT a, and XLNet) to two non-transformer-based models (CRF and BiLSTM-CNN-CRF). Furthermore, we apply each model to a multitude of distinct domains. We find that transformer-based models incrementally outperform the studied non-transformer-based models in most domains with respect to the F1 score. Furthermore, we find that the choice of domains significantly influenced the performance regardless of the respective data size or the model chosen.",Named Entity Recognition : RESEARCH_PROBLEM; BERT : METHOD; BERT : METHOD; Named Entity Recognition : RESEARCH_PROBLEM; (BERT : METHOD; RoBERT : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Named Entity Recognition (NER) is a fundamental Natural Language Processing (NLP) task and has remained an active research field. In recent years, transformer models and more specifically the BERT model developed at Google revolutionised the field of NLP. While the performance of transformer-based approaches such as BERT has been studied for NER, there has not yet been a study for the fine-grained Named Entity Recognition (FG-NER) task. In this paper, we compare three transformer-based models (BERT , RoBERT a, and XLNet) to two non-transformer-based models (CRF and BiLSTM-CNN-CRF). Furthermore, we apply each model to a multitude of distinct domains. We find that transformer-based models incrementally outperform the studied non-transformer-based models in most domains with respect to the F1 score. Furthermore, we find that the choice of domains significantly influenced the performance regardless of the respective data size or the model chosen. ### Response: Named Entity Recognition : RESEARCH_PROBLEM; BERT : METHOD; BERT : METHOD; Named Entity Recognition : RESEARCH_PROBLEM; (BERT : METHOD; RoBERT : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Differentiable ARchiTecture Search (DARTS ) uses a continuous relaxation of network representation and dramatically accelerates Neural Architecture Search (NAS) by almost thousands of times in GPU-day. However, the searching process of DARTS is unstable, which suffers severe degradation when training epochs become large, thus limiting its application. In this paper, we claim that this degradation issue is caused by the imbalanced norms between different nodes and the highly correlated outputs from various operations. We then propose an improved version of DARTS , namely iDARTS , to deal with the two problems. In the training phase, it introduces node normalization to maintain the norm balance. In the discretization phase, the continuous architecture is approximated based on the similarity between the outputs of the node and the decorrelated operations rather than the values of the architecture parameters. Extensive evaluation is conducted on CIFAR-10 and ImageNet, and the error rates of 2.25\% and 24.7\% are reported within 0.2 and 1.9 GPU-day for architecture search respectively, which shows its effectiveness. Additional analysis also reveals that iDARTS has the advantage in robustness and generalization over other DARTS -based counterparts.",(DARTS : METHOD; Neural Architecture Search : RESEARCH_PROBLEM; DARTS : METHOD; DARTS : METHOD; iDARTS : METHOD; iDARTS : METHOD; DARTS : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Differentiable ARchiTecture Search (DARTS ) uses a continuous relaxation of network representation and dramatically accelerates Neural Architecture Search (NAS) by almost thousands of times in GPU-day. However, the searching process of DARTS is unstable, which suffers severe degradation when training epochs become large, thus limiting its application. In this paper, we claim that this degradation issue is caused by the imbalanced norms between different nodes and the highly correlated outputs from various operations. We then propose an improved version of DARTS , namely iDARTS , to deal with the two problems. In the training phase, it introduces node normalization to maintain the norm balance. In the discretization phase, the continuous architecture is approximated based on the similarity between the outputs of the node and the decorrelated operations rather than the values of the architecture parameters. Extensive evaluation is conducted on CIFAR-10 and ImageNet, and the error rates of 2.25\% and 24.7\% are reported within 0.2 and 1.9 GPU-day for architecture search respectively, which shows its effectiveness. Additional analysis also reveals that iDARTS has the advantage in robustness and generalization over other DARTS -based counterparts. ### Response: (DARTS : METHOD; Neural Architecture Search : RESEARCH_PROBLEM; DARTS : METHOD; DARTS : METHOD; iDARTS : METHOD; iDARTS : METHOD; DARTS : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","This paper presents to integrate the auxiliary information (e.g., additional attributes for data such as the hashtags for Instagram images) in the self-supervised learning process. We first observe that the auxiliary information may bring us useful information about data structures: for instance, the Instagram images with the same hashtags can be semantically similar. Hence, to leverage the structural information from the auxiliary information, we present to construct data clusters according to the auxiliary information. Then, we introduce the Clustering InfoNCE (Cl-InfoNCE ) objective that learns similar representations for augmented variants of data from the same cluster and dissimilar representations for data from different clusters. Our approach contributes as follows: 1) Comparing to conventional self-supervised representations, the auxiliary-information-infused self-supervised representations bring the performance closer to the supervised representations; 2) The presented Cl-InfoNCE can also work with unsupervised constructed clusters (e.g., k-means clusters) and outperform strong clustering-based self-supervised learning approaches, such as the Prototypical Contrastive Learning (PCL) method; 3) We show that Cl-InfoNCE may be a better approach to leverage the data clustering information, by comparing it to the baseline approach - learning to predict the clustering assignments with cross-entropy loss. For analysis, we connect the goodness of the learned representations with the statistical relationships: i) the mutual information between the labels and the clusters and ii) the conditional entropy of the clusters given the labels.",InfoNCE : METHOD; (Cl-InfoNCE : METHOD; Cl-InfoNCE : METHOD; Contrastive Learning : RESEARCH_PROBLEM; Cl-InfoNCE : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: This paper presents to integrate the auxiliary information (e.g., additional attributes for data such as the hashtags for Instagram images) in the self-supervised learning process. We first observe that the auxiliary information may bring us useful information about data structures: for instance, the Instagram images with the same hashtags can be semantically similar. Hence, to leverage the structural information from the auxiliary information, we present to construct data clusters according to the auxiliary information. Then, we introduce the Clustering InfoNCE (Cl-InfoNCE ) objective that learns similar representations for augmented variants of data from the same cluster and dissimilar representations for data from different clusters. Our approach contributes as follows: 1) Comparing to conventional self-supervised representations, the auxiliary-information-infused self-supervised representations bring the performance closer to the supervised representations; 2) The presented Cl-InfoNCE can also work with unsupervised constructed clusters (e.g., k-means clusters) and outperform strong clustering-based self-supervised learning approaches, such as the Prototypical Contrastive Learning (PCL) method; 3) We show that Cl-InfoNCE may be a better approach to leverage the data clustering information, by comparing it to the baseline approach - learning to predict the clustering assignments with cross-entropy loss. For analysis, we connect the goodness of the learned representations with the statistical relationships: i) the mutual information between the labels and the clusters and ii) the conditional entropy of the clusters given the labels. ### Response: InfoNCE : METHOD; (Cl-InfoNCE : METHOD; Cl-InfoNCE : METHOD; Contrastive Learning : RESEARCH_PROBLEM; Cl-InfoNCE : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Question Answering (QA) is a widely-used framework for developing and evaluating an intelligent machine. In this light, QA on Electronic Health Records (EHR), namely EHR QA, can work as a crucial milestone towards developing an intelligent agent in healthcare. EHR data are typically stored in a relational database, which can also be converted to a directed acyclic graph, allowing two approaches for EHR QA: Table-based QA and Knowledge Graph-based QA. We hypothesize that the graph-based approach is more suitable for EHR QA as graphs can represent relations between entities and values more naturally compared to tables, which essentially require JOIN operations. In this paper, we propose a graph-based EHR QA where natural language queries are converted to SPARQL instead of SQL. To validate our hypothesis, we create four EHR QA datasets (graph-based VS table-based, and simplified database schema VS original database schema), based on a table-based dataset MIMICSQL. We test both a simple Seq2Seq model and a state-of-the-art EHR QA model on all datasets where the graph-based datasets facilitated up to 34% higher accuracy than the table-based dataset without any modification to the model architectures. Finally, all datasets are open-sourced to encourage further EHR QA research in both directions.",Question Answering : RESEARCH_PROBLEM; Seq2Seq : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Question Answering (QA) is a widely-used framework for developing and evaluating an intelligent machine. In this light, QA on Electronic Health Records (EHR), namely EHR QA, can work as a crucial milestone towards developing an intelligent agent in healthcare. EHR data are typically stored in a relational database, which can also be converted to a directed acyclic graph, allowing two approaches for EHR QA: Table-based QA and Knowledge Graph-based QA. We hypothesize that the graph-based approach is more suitable for EHR QA as graphs can represent relations between entities and values more naturally compared to tables, which essentially require JOIN operations. In this paper, we propose a graph-based EHR QA where natural language queries are converted to SPARQL instead of SQL. To validate our hypothesis, we create four EHR QA datasets (graph-based VS table-based, and simplified database schema VS original database schema), based on a table-based dataset MIMICSQL. We test both a simple Seq2Seq model and a state-of-the-art EHR QA model on all datasets where the graph-based datasets facilitated up to 34% higher accuracy than the table-based dataset without any modification to the model architectures. Finally, all datasets are open-sourced to encourage further EHR QA research in both directions. ### Response: Question Answering : RESEARCH_PROBLEM; Seq2Seq : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Anomaly detection is a significant and hence well-studied problem. However,developing effective anomaly detection methods for complex and high-dimensionaldata remains a challenge. As Generative Adversarial Networks (GAN s) are able tomodel the complex high-dimensional distributions of real-world data, they offera promising approach to address this challenge. In this work, we propose ananomaly detection method, Adversarially Learned Anomaly Detection (ALAD) basedon bi-directional GAN s, that derives adversarially learned features for theanomaly detection task. ALAD then uses reconstruction errors based on theseadversarially learned features to determine if a data sample is anomalous. ALADbuilds on recent advances to ensure data-space and latent-spacecycle-consistencies and stabilize GAN training, which results in significantlyimproved anomaly detection performance. ALAD achieves state-of-the-artperformance on a range of image and tabular datasets while being severalhundred-fold faster at test time than the only published GAN -based method.",(GAN : METHOD; Anomaly Detection : RESEARCH_PROBLEM; GAN : METHOD; GAN : METHOD; GAN : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Anomaly detection is a significant and hence well-studied problem. However,developing effective anomaly detection methods for complex and high-dimensionaldata remains a challenge. As Generative Adversarial Networks (GAN s) are able tomodel the complex high-dimensional distributions of real-world data, they offera promising approach to address this challenge. In this work, we propose ananomaly detection method, Adversarially Learned Anomaly Detection (ALAD) basedon bi-directional GAN s, that derives adversarially learned features for theanomaly detection task. ALAD then uses reconstruction errors based on theseadversarially learned features to determine if a data sample is anomalous. ALADbuilds on recent advances to ensure data-space and latent-spacecycle-consistencies and stabilize GAN training, which results in significantlyimproved anomaly detection performance. ALAD achieves state-of-the-artperformance on a range of image and tabular datasets while being severalhundred-fold faster at test time than the only published GAN -based method. ### Response: (GAN : METHOD; Anomaly Detection : RESEARCH_PROBLEM; GAN : METHOD; GAN : METHOD; GAN : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Currently, many applications in Machine Learning are based on define new models to extract more information about data, In this case Deep Reinforcement Learning with the most common application in video games like Atari, Mario, and others causes an impact in how to computers can learning by himself with only information called rewards obtained from any action. There is a lot of algorithms modeled and implemented based on Deep Recurrent Q-Learning proposed by DeepMind used in AlphaZero and Go. In this document, We proposed Deep Recurrent Double Q-Learning that is an implementation of Deep Reinforcement Learning using Double Q-Learning algorithms and Recurrent Networks like LSTM and DRQN.",Q-Learning : RESEARCH_PROBLEM; AlphaZero : METHOD; Q-Learning : RESEARCH_PROBLEM; Q-Learning : RESEARCH_PROBLEM; LSTM : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Currently, many applications in Machine Learning are based on define new models to extract more information about data, In this case Deep Reinforcement Learning with the most common application in video games like Atari, Mario, and others causes an impact in how to computers can learning by himself with only information called rewards obtained from any action. There is a lot of algorithms modeled and implemented based on Deep Recurrent Q-Learning proposed by DeepMind used in AlphaZero and Go. In this document, We proposed Deep Recurrent Double Q-Learning that is an implementation of Deep Reinforcement Learning using Double Q-Learning algorithms and Recurrent Networks like LSTM and DRQN. ### Response: Q-Learning : RESEARCH_PROBLEM; AlphaZero : METHOD; Q-Learning : RESEARCH_PROBLEM; Q-Learning : RESEARCH_PROBLEM; LSTM : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Plot-based Graphic API recommendation (Plot2API) is an unstudied but meaningful issue, which has several important applications in the context of software engineering and data visualization, such as the plotting guidance of the beginner, graphic API correlation analysis, and code conversion for plotting. Plot2API is a very challenging task, since each plot is often associated with multiple APIs and the appearances of the graphics drawn by the same API can be extremely varied due to the different settings of the parameters. Additionally, the samples of different APIs also suffer from extremely imbalanced. Considering the lack of technologies in Plot2API, we present a novel deep multi-task learning approach named Semantic Parsing Guided Neural Network (SPGNN) which translates the Plot2API issue as a multi-label image classification and an image semantic parsing tasks for the solution. In SPGNN, the recently advanced Convolutional Neural Network (CNN) named EfficientNet is employed as the backbone network for API recommendation. Meanwhile, a semantic parsing module is complemented to exploit the semantic relevant visual information in feature learning and eliminate the appearance-relevant visual information which may confuse the visual-information-based API recommendation. Moreover, the recent data augmentation technique named random erasing is also applied for alleviating the imbalance of API categories. We collect plots with the graphic APIs used to drawn them from Stack Overflow, and release three new Plot2API datasets corresponding to the graphic APIs of R and Python programming languages for evaluating the effectiveness of Plot2API techniques. Extensive experimental results not only demonstrate the superiority of our method over the recent deep learning baselines but also show the practicability of our method in the recommendation of graphic APIs.",Semantic Parsing : RESEARCH_PROBLEM; EfficientNet : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Plot-based Graphic API recommendation (Plot2API) is an unstudied but meaningful issue, which has several important applications in the context of software engineering and data visualization, such as the plotting guidance of the beginner, graphic API correlation analysis, and code conversion for plotting. Plot2API is a very challenging task, since each plot is often associated with multiple APIs and the appearances of the graphics drawn by the same API can be extremely varied due to the different settings of the parameters. Additionally, the samples of different APIs also suffer from extremely imbalanced. Considering the lack of technologies in Plot2API, we present a novel deep multi-task learning approach named Semantic Parsing Guided Neural Network (SPGNN) which translates the Plot2API issue as a multi-label image classification and an image semantic parsing tasks for the solution. In SPGNN, the recently advanced Convolutional Neural Network (CNN) named EfficientNet is employed as the backbone network for API recommendation. Meanwhile, a semantic parsing module is complemented to exploit the semantic relevant visual information in feature learning and eliminate the appearance-relevant visual information which may confuse the visual-information-based API recommendation. Moreover, the recent data augmentation technique named random erasing is also applied for alleviating the imbalance of API categories. We collect plots with the graphic APIs used to drawn them from Stack Overflow, and release three new Plot2API datasets corresponding to the graphic APIs of R and Python programming languages for evaluating the effectiveness of Plot2API techniques. Extensive experimental results not only demonstrate the superiority of our method over the recent deep learning baselines but also show the practicability of our method in the recommendation of graphic APIs. ### Response: Semantic Parsing : RESEARCH_PROBLEM; EfficientNet : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Polyphone disambiguation serves as an essential part of Mandarin text-to-speech (TTS) system. However, conventional system modeling the entire Pinyin set causes the case that prediction belongs to the unrelated polyphonic character instead of the current input one, which has negative impacts on TTS performance. To address this issue, we introduce a mask-based model for polyphone disambiguation. The model takes a mask vector extracted from the context as an extra input. In our model, the mask vector not only acts as a weighting factor in Weightedsoftmax to prevent the case of mis-prediction but also eliminates the contribution of non-candidate set to the overall loss. Moreover, to mitigate the uneven distribution of pronunciation, we introduce a new loss called Modified Focal Loss . The experimental result shows the effectiveness of the proposed mask based model. We also empirically studied the impact of Weighted-softmax and Modified Focal Loss . It was found that Weighted-softmax can effectively prevent the model from predicting outside the candidate set. Besides, Modified Focal Loss can reduce the adverse impacts of the uneven distribution of pronunciation.",Polyphone disambiguation : RESEARCH_PROBLEM; Focal Loss : METHOD; Focal Loss : METHOD; Focal Loss : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Polyphone disambiguation serves as an essential part of Mandarin text-to-speech (TTS) system. However, conventional system modeling the entire Pinyin set causes the case that prediction belongs to the unrelated polyphonic character instead of the current input one, which has negative impacts on TTS performance. To address this issue, we introduce a mask-based model for polyphone disambiguation. The model takes a mask vector extracted from the context as an extra input. In our model, the mask vector not only acts as a weighting factor in Weightedsoftmax to prevent the case of mis-prediction but also eliminates the contribution of non-candidate set to the overall loss. Moreover, to mitigate the uneven distribution of pronunciation, we introduce a new loss called Modified Focal Loss . The experimental result shows the effectiveness of the proposed mask based model. We also empirically studied the impact of Weighted-softmax and Modified Focal Loss . It was found that Weighted-softmax can effectively prevent the model from predicting outside the candidate set. Besides, Modified Focal Loss can reduce the adverse impacts of the uneven distribution of pronunciation. ### Response: Polyphone disambiguation : RESEARCH_PROBLEM; Focal Loss : METHOD; Focal Loss : METHOD; Focal Loss : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","We present our contribution to the EvaLatin shared task, which is the first evaluation campaign devoted to the evaluation of NLP tools for Latin. We submitted a system based on UDPipe 2.0, one of the winners of the CoNLL 2018 Shared Task, The 2018 Shared Task on Extrinsic Parser Evaluation and SIGMORPHON 2019 Shared Task. Our system places first by a wide margin both in lemmatization and POS tagging in the open modality, where additional supervised data is allowed, in which case we utilize all Universal Dependency Latin treebanks. In the closed modality, where only the EvaLatin training data is allowed, our system achieves the best performance in lemmatization and in classical subtask of POS tagging, while reaching second place in cross-genre and cross-time settings. In the ablation experiments, we also evaluate the influence of BERT and XLM-RoBERT a contextualized embeddings, and the treebank encodings of the different flavors of Latin treebanks.",POS : RESEARCH_PROBLEM; POS : RESEARCH_PROBLEM; BERT : METHOD; XLM-RoBERT : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: We present our contribution to the EvaLatin shared task, which is the first evaluation campaign devoted to the evaluation of NLP tools for Latin. We submitted a system based on UDPipe 2.0, one of the winners of the CoNLL 2018 Shared Task, The 2018 Shared Task on Extrinsic Parser Evaluation and SIGMORPHON 2019 Shared Task. Our system places first by a wide margin both in lemmatization and POS tagging in the open modality, where additional supervised data is allowed, in which case we utilize all Universal Dependency Latin treebanks. In the closed modality, where only the EvaLatin training data is allowed, our system achieves the best performance in lemmatization and in classical subtask of POS tagging, while reaching second place in cross-genre and cross-time settings. In the ablation experiments, we also evaluate the influence of BERT and XLM-RoBERT a contextualized embeddings, and the treebank encodings of the different flavors of Latin treebanks. ### Response: POS : RESEARCH_PROBLEM; POS : RESEARCH_PROBLEM; BERT : METHOD; XLM-RoBERT : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","This paper describes the BLCU Group submissions to the Building Educational Applications (BEA) 2019 Shared Task on Grammatical Error Correction (GEC). The task is to detect and correct grammatical errors that occurred in essays. We participate in 2 tracks including the Restricted Track and the Unrestricted Track. Our system is based on a Transformer model architecture. We integrate many effective methods proposed in recent years. Such as, Byte Pair Encoding, model ensemble, checkpoints average and spell checker. We also corrupt the public monolingual data to further improve the performance of the model. On the test data of the BEA 2019 Shared Task, our system yields F0.5 = 58.62 and 59.50, ranking twelfth and fourth respectively.",Grammatical Error Correction : RESEARCH_PROBLEM; Transformer : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: This paper describes the BLCU Group submissions to the Building Educational Applications (BEA) 2019 Shared Task on Grammatical Error Correction (GEC). The task is to detect and correct grammatical errors that occurred in essays. We participate in 2 tracks including the Restricted Track and the Unrestricted Track. Our system is based on a Transformer model architecture. We integrate many effective methods proposed in recent years. Such as, Byte Pair Encoding, model ensemble, checkpoints average and spell checker. We also corrupt the public monolingual data to further improve the performance of the model. On the test data of the BEA 2019 Shared Task, our system yields F0.5 = 58.62 and 59.50, ranking twelfth and fourth respectively. ### Response: Grammatical Error Correction : RESEARCH_PROBLEM; Transformer : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","The breakthrough of deep Q-Learning on different types of environments revolutionized the algorithmic design of Reinforcement Learning to introduce more stable and robust algorithms, to that end many extensions to deep Q-Learning algorithm have been proposed to reduce the variance of the target values and the overestimation phenomena. In this paper, we examine new methodology to solve these issues, we propose using Dropout techniques on deep Q-Learning algorithm as a way to reduce variance and overestimation. We further present experiments on some of the benchmark environments that demonstrate significant improvement of the stability of the performance and a reduction in variance and overestimation.",Q-Learning : RESEARCH_PROBLEM; Q-Learning : RESEARCH_PROBLEM; Dropout : METHOD; Q-Learning : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: The breakthrough of deep Q-Learning on different types of environments revolutionized the algorithmic design of Reinforcement Learning to introduce more stable and robust algorithms, to that end many extensions to deep Q-Learning algorithm have been proposed to reduce the variance of the target values and the overestimation phenomena. In this paper, we examine new methodology to solve these issues, we propose using Dropout techniques on deep Q-Learning algorithm as a way to reduce variance and overestimation. We further present experiments on some of the benchmark environments that demonstrate significant improvement of the stability of the performance and a reduction in variance and overestimation. ### Response: Q-Learning : RESEARCH_PROBLEM; Q-Learning : RESEARCH_PROBLEM; Dropout : METHOD; Q-Learning : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Zero-Shot Learning (ZSL) aims to recognise unseen object classes, which are not observed during the training phase. The existing body of works on ZSL mostly relies on pretrained visual features and lacks the explicit attribute localisation mechanism on images. In this work, we propose an attention-based model in the problem settings of ZSL to learn attributes useful for unseen class recognition. Our method uses an attention mechanism adapted from Vision Transformer to capture and learn discriminative attributes by splitting images into small patches. We conduct experiments on three popular ZSL benchmarks (i.e., AWA2, CUB and SUN) and set new state-of-the-art harmonic mean results {on all the three datasets}, which illustrate the effectiveness of our proposed method.",Zero-Shot Learning : RESEARCH_PROBLEM; Vision Transformer : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Zero-Shot Learning (ZSL) aims to recognise unseen object classes, which are not observed during the training phase. The existing body of works on ZSL mostly relies on pretrained visual features and lacks the explicit attribute localisation mechanism on images. In this work, we propose an attention-based model in the problem settings of ZSL to learn attributes useful for unseen class recognition. Our method uses an attention mechanism adapted from Vision Transformer to capture and learn discriminative attributes by splitting images into small patches. We conduct experiments on three popular ZSL benchmarks (i.e., AWA2, CUB and SUN) and set new state-of-the-art harmonic mean results {on all the three datasets}, which illustrate the effectiveness of our proposed method. ### Response: Zero-Shot Learning : RESEARCH_PROBLEM; Vision Transformer : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","The usefulness and value of Multi-step Machine Learning (ML), where a task is organized into connected sub-tasks with known intermediate inference goals, as opposed to a single large model learned end-to-end without intermediate sub-tasks, is presented. Pre-optimized ML models are connected and better performance is obtained by re-optimizing the connected one. The selection of an ML model from several small ML model candidates for each sub-task has been performed by using the idea based on Neural Architecture Search (NAS). In this paper, Differentiable Architecture Search (DARTS ) and Single Path One-Shot NAS (SPOS-NAS) are tested, where the construction of loss functions is improved to keep all ML models smoothly learning. Using DARTS and SPOS-NAS as an optimization and selection as well as the connections for multi-step machine learning systems, we find that (1) such a system can quickly and successfully select highly performant model combinations, and (2) the selected models are consistent with baseline algorithms, such as grid search, and their outputs are well controlled.",Neural Architecture Search : RESEARCH_PROBLEM; (DARTS : METHOD; DARTS : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: The usefulness and value of Multi-step Machine Learning (ML), where a task is organized into connected sub-tasks with known intermediate inference goals, as opposed to a single large model learned end-to-end without intermediate sub-tasks, is presented. Pre-optimized ML models are connected and better performance is obtained by re-optimizing the connected one. The selection of an ML model from several small ML model candidates for each sub-task has been performed by using the idea based on Neural Architecture Search (NAS). In this paper, Differentiable Architecture Search (DARTS ) and Single Path One-Shot NAS (SPOS-NAS) are tested, where the construction of loss functions is improved to keep all ML models smoothly learning. Using DARTS and SPOS-NAS as an optimization and selection as well as the connections for multi-step machine learning systems, we find that (1) such a system can quickly and successfully select highly performant model combinations, and (2) the selected models are consistent with baseline algorithms, such as grid search, and their outputs are well controlled. ### Response: Neural Architecture Search : RESEARCH_PROBLEM; (DARTS : METHOD; DARTS : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Biomedical data are widely accepted in developing prediction models for identifying a specific tumor, drug discovery and classification of human cancers. However, previous studies usually focused on different classifiers, and overlook the class imbalance problem in real-world biomedical datasets. There are a lack of studies on evaluation of data pre-processing techniques, such as resampling and feature selection, on imbalanced biomedical data learning. The relationship between data pre-processing techniques and the data distributions has never been analysed in previous studies. This article mainly focuses on reviewing and evaluating some popular and recently developed resampling and feature selection methods for class imbalance learning. We analyse the effectiveness of each technique from data distribution perspective. Extensive experiments have been done based on five classifiers, four performance measures, eight learning techniques across twenty real-world datasets. Experimental results show that: (1) resampling and feature selection techniques exhibit better performance using support vector machine (SVM ) classifier. However, resampling and Feature Selection techniques perform poorly when using C4.5 decision tree and Linear discriminant analysis classifiers; (2) for datasets with different distributions, techniques such as Random undersampling and Feature Selection perform better than other data pre-processing methods with T Location-Scale distribution when using SVM and KNN (K-nearest neighbours) classifiers. Random oversampling outperforms other methods on Negative Binomial distribution using Random Forest classifier with lower level of imbalance ratio; (3) Feature Selection outperforms other data pre-processing methods in most cases, thus, Feature Selection with SVM classifier is the best choice for imbalanced biomedical data learning.",(SVM : METHOD; Feature Selection : RESEARCH_PROBLEM; Feature Selection : RESEARCH_PROBLEM; SVM : METHOD; Feature Selection : RESEARCH_PROBLEM; Feature Selection : RESEARCH_PROBLEM; SVM : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Biomedical data are widely accepted in developing prediction models for identifying a specific tumor, drug discovery and classification of human cancers. However, previous studies usually focused on different classifiers, and overlook the class imbalance problem in real-world biomedical datasets. There are a lack of studies on evaluation of data pre-processing techniques, such as resampling and feature selection, on imbalanced biomedical data learning. The relationship between data pre-processing techniques and the data distributions has never been analysed in previous studies. This article mainly focuses on reviewing and evaluating some popular and recently developed resampling and feature selection methods for class imbalance learning. We analyse the effectiveness of each technique from data distribution perspective. Extensive experiments have been done based on five classifiers, four performance measures, eight learning techniques across twenty real-world datasets. Experimental results show that: (1) resampling and feature selection techniques exhibit better performance using support vector machine (SVM ) classifier. However, resampling and Feature Selection techniques perform poorly when using C4.5 decision tree and Linear discriminant analysis classifiers; (2) for datasets with different distributions, techniques such as Random undersampling and Feature Selection perform better than other data pre-processing methods with T Location-Scale distribution when using SVM and KNN (K-nearest neighbours) classifiers. Random oversampling outperforms other methods on Negative Binomial distribution using Random Forest classifier with lower level of imbalance ratio; (3) Feature Selection outperforms other data pre-processing methods in most cases, thus, Feature Selection with SVM classifier is the best choice for imbalanced biomedical data learning. ### Response: (SVM : METHOD; Feature Selection : RESEARCH_PROBLEM; Feature Selection : RESEARCH_PROBLEM; SVM : METHOD; Feature Selection : RESEARCH_PROBLEM; Feature Selection : RESEARCH_PROBLEM; SVM : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","The Transformer has shown tremendous progress in Automatic Speech Recognition (ASR), outperforming recurrent neural network-based approaches. Transformer architecture is good at parallelizing data to accelerate as well as capturing content-based global interaction. However, most studies with Transformer have been utilized only shallow features extracted from the backbone without taking advantage of the deep feature that possesses invariant property. In this paper, we propose a novel framework with the Two Streams and Two Resolution spectrograms Model (TSTRM) that consists of different resolution spectrograms for different streams aiming to capture both shallow and deep features. The feature extraction module consists of a deep network for low-resolution spectrogram and a shallow network for high-resolution spectrogram. The backbone obtains not only detailed acoustic information for speech-text alignment but also utterance-level representation that contains speaker information. Both features are fused with our proposed fusion method and then input into the Transformer encoder-decoder. The proposed framework shows the state-of-the-art results on the HKUST Mandarin telephone and Librispeech corpora. To the best of our knowledge, this is the first investigation of incorporating deep features to the backbone and use both low and high resolutions spectrogram to focus on global and local information. Code is available at https://github.com/happyjin/TSTRM",Transformer : METHOD; Speech Recognition : RESEARCH_PROBLEM; Transformer : METHOD; Transformer : METHOD; Transformer : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: The Transformer has shown tremendous progress in Automatic Speech Recognition (ASR), outperforming recurrent neural network-based approaches. Transformer architecture is good at parallelizing data to accelerate as well as capturing content-based global interaction. However, most studies with Transformer have been utilized only shallow features extracted from the backbone without taking advantage of the deep feature that possesses invariant property. In this paper, we propose a novel framework with the Two Streams and Two Resolution spectrograms Model (TSTRM) that consists of different resolution spectrograms for different streams aiming to capture both shallow and deep features. The feature extraction module consists of a deep network for low-resolution spectrogram and a shallow network for high-resolution spectrogram. The backbone obtains not only detailed acoustic information for speech-text alignment but also utterance-level representation that contains speaker information. Both features are fused with our proposed fusion method and then input into the Transformer encoder-decoder. The proposed framework shows the state-of-the-art results on the HKUST Mandarin telephone and Librispeech corpora. To the best of our knowledge, this is the first investigation of incorporating deep features to the backbone and use both low and high resolutions spectrogram to focus on global and local information. Code is available at https://github.com/happyjin/TSTRM ### Response: Transformer : METHOD; Speech Recognition : RESEARCH_PROBLEM; Transformer : METHOD; Transformer : METHOD; Transformer : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Incorporating lexicons into character-level Chinese NER by lattices is proven effective to exploitrich word boundary information. Previous work has extended RNNs to consume lattice inputsand achieved great success. However, due to the DAG structure and the inherently unidirectionalsequential nature, this method precludes batched computation and sufficient semantic interaction.In this paper, we propose PLTE, an extension of transformer encoder that is tailored for ChineseNER , which models all the characters and matched lexical words in parallel with batch process-ing. PLTE augments self-attention with positional relation representations to incorporate latticestructure. It also introduces a porous mechanism to augment localness modeling and maintainthe strength of capturing the rich long-term dependencies. Experimental results show that PLTEperforms up to 11.4 times faster than state-of-the-art methods while realizing better performance.We also demonstrate that using BERT representations further substantially boosts the performanceand brings out the best in PLTE.",NER : RESEARCH_PROBLEM; ChineseNER : RESEARCH_PROBLEM; BERT : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Incorporating lexicons into character-level Chinese NER by lattices is proven effective to exploitrich word boundary information. Previous work has extended RNNs to consume lattice inputsand achieved great success. However, due to the DAG structure and the inherently unidirectionalsequential nature, this method precludes batched computation and sufficient semantic interaction.In this paper, we propose PLTE, an extension of transformer encoder that is tailored for ChineseNER , which models all the characters and matched lexical words in parallel with batch process-ing. PLTE augments self-attention with positional relation representations to incorporate latticestructure. It also introduces a porous mechanism to augment localness modeling and maintainthe strength of capturing the rich long-term dependencies. Experimental results show that PLTEperforms up to 11.4 times faster than state-of-the-art methods while realizing better performance.We also demonstrate that using BERT representations further substantially boosts the performanceand brings out the best in PLTE. ### Response: NER : RESEARCH_PROBLEM; ChineseNER : RESEARCH_PROBLEM; BERT : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Children acquire language subconsciously by observing the surrounding world and listening to descriptions. They can discover the meaning of words even without explicit language knowledge, and generalize to novel compositions effortlessly. In this paper, we bring this ability to AI, by studying the task of Visually grounded Language Acquisition (VLA). We propose a multimodal transformer model augmented with a novel mechanism for analogical reasoning, which approximates novel compositions by learning semantic mapping and reasoning operations from previously seen compositions. Our proposed method, Analogical Reasoning Transformer Networks (ARTNet), is trained on raw multimedia data (video frames and transcripts), and after observing a set of compositions such as ""washing apple"" or ""cutting carrot"", it can generalize and recognize new compositions in new video frames, such as ""washing carrot"" or ""cutting apple"". To this end, ARTNet refers to relevant instances in the training data and uses their visual features and captions to establish analogies with the query image. Then it chooses the suitable verb and noun to create a new composition that describes the new image best. Extensive experiments on an instructional video dataset demonstrate that the proposed method achieves significantly better generalization capability and recognition accuracy compared to state-of-the-art transformer models.",Language Acquisition : RESEARCH_PROBLEM; Transformer : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Children acquire language subconsciously by observing the surrounding world and listening to descriptions. They can discover the meaning of words even without explicit language knowledge, and generalize to novel compositions effortlessly. In this paper, we bring this ability to AI, by studying the task of Visually grounded Language Acquisition (VLA). We propose a multimodal transformer model augmented with a novel mechanism for analogical reasoning, which approximates novel compositions by learning semantic mapping and reasoning operations from previously seen compositions. Our proposed method, Analogical Reasoning Transformer Networks (ARTNet), is trained on raw multimedia data (video frames and transcripts), and after observing a set of compositions such as ""washing apple"" or ""cutting carrot"", it can generalize and recognize new compositions in new video frames, such as ""washing carrot"" or ""cutting apple"". To this end, ARTNet refers to relevant instances in the training data and uses their visual features and captions to establish analogies with the query image. Then it chooses the suitable verb and noun to create a new composition that describes the new image best. Extensive experiments on an instructional video dataset demonstrate that the proposed method achieves significantly better generalization capability and recognition accuracy compared to state-of-the-art transformer models. ### Response: Language Acquisition : RESEARCH_PROBLEM; Transformer : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Large-scale language models such as BERT have achieved state-of-the-art performance across a wide range of NLP tasks. Recent studies, however, show that such BERT -based models are vulnerable facing the threats of textual adversarial attacks. We aim to address this problem from an information-theoretic perspective, and propose InfoBERT , a novel learning framework for robust fine-tuning of pre-trained language models. InfoBERT contains two mutual-information-based regularizers for model training: (i) an Information Bottleneck regularizer, which suppresses noisy mutual information between the input and the feature representation; and (ii) a Robust Feature regularizer, which increases the mutual information between local robust features and global features. We provide a principled way to theoretically analyze and improve the robustness of representation learning for language models in both standard and adversarial training. Extensive experiments demonstrate that InfoBERT achieves state-of-the-art robust accuracy over several adversarial datasets on Natural Language Inference (NLI) and Question Answering (QA) tasks. Our code is available at https://github.com/AI-secure/InfoBERT .",BERT : METHOD; BERT : METHOD; InfoBERT : METHOD; InfoBERT : METHOD; InfoBERT : METHOD; Natural Language Inference : RESEARCH_PROBLEM; Question Answering : RESEARCH_PROBLEM; https://github.com/AI-secure/InfoBERT : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Large-scale language models such as BERT have achieved state-of-the-art performance across a wide range of NLP tasks. Recent studies, however, show that such BERT -based models are vulnerable facing the threats of textual adversarial attacks. We aim to address this problem from an information-theoretic perspective, and propose InfoBERT , a novel learning framework for robust fine-tuning of pre-trained language models. InfoBERT contains two mutual-information-based regularizers for model training: (i) an Information Bottleneck regularizer, which suppresses noisy mutual information between the input and the feature representation; and (ii) a Robust Feature regularizer, which increases the mutual information between local robust features and global features. We provide a principled way to theoretically analyze and improve the robustness of representation learning for language models in both standard and adversarial training. Extensive experiments demonstrate that InfoBERT achieves state-of-the-art robust accuracy over several adversarial datasets on Natural Language Inference (NLI) and Question Answering (QA) tasks. Our code is available at https://github.com/AI-secure/InfoBERT . ### Response: BERT : METHOD; BERT : METHOD; InfoBERT : METHOD; InfoBERT : METHOD; InfoBERT : METHOD; Natural Language Inference : RESEARCH_PROBLEM; Question Answering : RESEARCH_PROBLEM; https://github.com/AI-secure/InfoBERT : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","A typical pipeline for Zero-Shot Learning (ZSL) is to integrate the visualfeatures and the class semantic descriptors into a multimodal framework with alinear or bilinear model. However, the visual features and the class semanticdescriptors locate in different structural spaces, a linear or bilinear modelcan not capture the semantic interactions between different modalities well. Inthis letter, we propose a nonlinear approach to impose ZSL as a multi-classclassification problem via a Semantic Softmax Loss by embedding the classsemantic descriptors into the softmax layer of multi-class classificationnetwork. To narrow the structural differences between the visual features andsemantic descriptors, we further use an L2 normalization constraint to thedifferences between the visual features and visual prototypes reconstructedwith the semantic descriptors. The results on three benchmark datasets, i.e.,AwA, CUB and SUN demonstrate the proposed approach can boost the performancessteadily and achieve the state-of-the-art performance for both zero-shotclassification and zero-shot retrieval.",Zero-Shot Learning : RESEARCH_PROBLEM; Softmax : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: A typical pipeline for Zero-Shot Learning (ZSL) is to integrate the visualfeatures and the class semantic descriptors into a multimodal framework with alinear or bilinear model. However, the visual features and the class semanticdescriptors locate in different structural spaces, a linear or bilinear modelcan not capture the semantic interactions between different modalities well. Inthis letter, we propose a nonlinear approach to impose ZSL as a multi-classclassification problem via a Semantic Softmax Loss by embedding the classsemantic descriptors into the softmax layer of multi-class classificationnetwork. To narrow the structural differences between the visual features andsemantic descriptors, we further use an L2 normalization constraint to thedifferences between the visual features and visual prototypes reconstructedwith the semantic descriptors. The results on three benchmark datasets, i.e.,AwA, CUB and SUN demonstrate the proposed approach can boost the performancessteadily and achieve the state-of-the-art performance for both zero-shotclassification and zero-shot retrieval. ### Response: Zero-Shot Learning : RESEARCH_PROBLEM; Softmax : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Hand gestures form an intuitive means of interaction in Mixed Reality (MR)applications. However, accurate gesture recognition can be achieved onlythrough state-of-the-art deep learning models or with the use of expensivesensors. Despite the robustness of these deep learning models, they aregenerally computationally expensive and obtaining real-time performanceon-device is still a challenge. To this end, we propose a novel lightweighthand gesture recognition framework that works in First Person View for wearabledevices. The models are trained on a GPU machine and ported on an Androidsmartphone for its use with frugal wearable devices such as the GoogleCardboard and VR Box. The proposed hand gesture recognition framework is drivenby a cascade of state-of-the-art deep learning models: MobileNetV2 for handlocalisation, our custom fingertip regression architecture followed by aBi-LSTM model for gesture classification. We extensively evaluate the frameworkon our EgoGestAR dataset. The overall framework works in real-time on mobiledevices and achieves a classification accuracy of 80% on EgoGestAR videodataset with an average latency of only 0.12 s.",Mixed Reality : RESEARCH_PROBLEM; MobileNetV2 : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Hand gestures form an intuitive means of interaction in Mixed Reality (MR)applications. However, accurate gesture recognition can be achieved onlythrough state-of-the-art deep learning models or with the use of expensivesensors. Despite the robustness of these deep learning models, they aregenerally computationally expensive and obtaining real-time performanceon-device is still a challenge. To this end, we propose a novel lightweighthand gesture recognition framework that works in First Person View for wearabledevices. The models are trained on a GPU machine and ported on an Androidsmartphone for its use with frugal wearable devices such as the GoogleCardboard and VR Box. The proposed hand gesture recognition framework is drivenby a cascade of state-of-the-art deep learning models: MobileNetV2 for handlocalisation, our custom fingertip regression architecture followed by aBi-LSTM model for gesture classification. We extensively evaluate the frameworkon our EgoGestAR dataset. The overall framework works in real-time on mobiledevices and achieves a classification accuracy of 80% on EgoGestAR videodataset with an average latency of only 0.12 s. ### Response: Mixed Reality : RESEARCH_PROBLEM; MobileNetV2 : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","In this work, we present a simple and general search space shrinking method, called Angle-Based search space Shrinking (ABS), for Neural Architecture Search (NAS). Our approach progressively simplifies the original search space by dropping unpromising candidates, thus can reduce difficulties for existing NAS methods to find superior architectures. In particular, we propose an angle-based metric to guide the shrinking process. We provide comprehensive evidences showing that, in weight-sharing supernet, the proposed metric is more stable and accurate than accuracy-based and magnitude-based metrics to predict the capability of child models. We also show that the angle-based metric can converge fast while training supernet, enabling us to get promising shrunk search spaces efficiently. ABS can easily apply to most of NAS approaches (e.g. SPOS, FairNAS, ProxylessNAS, DARTS and PDARTS ). Comprehensive experiments show that ABS can dramatically enhance existing NAS approaches by providing a promising shrunk search space.",Neural Architecture Search : RESEARCH_PROBLEM; DARTS : METHOD; PDARTS : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: In this work, we present a simple and general search space shrinking method, called Angle-Based search space Shrinking (ABS), for Neural Architecture Search (NAS). Our approach progressively simplifies the original search space by dropping unpromising candidates, thus can reduce difficulties for existing NAS methods to find superior architectures. In particular, we propose an angle-based metric to guide the shrinking process. We provide comprehensive evidences showing that, in weight-sharing supernet, the proposed metric is more stable and accurate than accuracy-based and magnitude-based metrics to predict the capability of child models. We also show that the angle-based metric can converge fast while training supernet, enabling us to get promising shrunk search spaces efficiently. ABS can easily apply to most of NAS approaches (e.g. SPOS, FairNAS, ProxylessNAS, DARTS and PDARTS ). Comprehensive experiments show that ABS can dramatically enhance existing NAS approaches by providing a promising shrunk search space. ### Response: Neural Architecture Search : RESEARCH_PROBLEM; DARTS : METHOD; PDARTS : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Convolutional Neural Networks (CNNs) have proven very effective in imageclassification and show promise for audio. We use various CNN architectures toclassify the soundtracks of a dataset of 70M training videos (5.24 millionhours) with 30,871 video-level labels. We examine fully connected Deep NeuralNetworks (DNNs), AlexNet [1], VGG [2], Inception [3], and ResNet [4]. Weinvestigate varying the size of both training set and label vocabulary, findingthat analogs of the CNNs used in image classification do well on our audioclassification task, and larger training and label sets help up to a point. Amodel using embeddings from these classifiers does much better than rawfeatures on the Audio Set [5] Acoustic Event Detection (AED) classificationtask.",AlexNet : METHOD; VGG : METHOD; ResNet : METHOD; Event Detection : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Convolutional Neural Networks (CNNs) have proven very effective in imageclassification and show promise for audio. We use various CNN architectures toclassify the soundtracks of a dataset of 70M training videos (5.24 millionhours) with 30,871 video-level labels. We examine fully connected Deep NeuralNetworks (DNNs), AlexNet [1], VGG [2], Inception [3], and ResNet [4]. Weinvestigate varying the size of both training set and label vocabulary, findingthat analogs of the CNNs used in image classification do well on our audioclassification task, and larger training and label sets help up to a point. Amodel using embeddings from these classifiers does much better than rawfeatures on the Audio Set [5] Acoustic Event Detection (AED) classificationtask. ### Response: AlexNet : METHOD; VGG : METHOD; ResNet : METHOD; Event Detection : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Generating longer textual sequences when conditioned on the visual information is an interesting problem to explore. The challenge here proliferate over the standard vision conditioned sentence-level generation (e.g., image or video captioning) as it requires to produce a brief and coherent story describing the visual content. In this paper, we mask this Vision-to-Sequence as Graph-to-Sequence learning problem and approach it with the Transformer architecture. To be specific, we introduce Sparse Graph-to-Sequence Transformer (SGST) for encoding the graph and decoding a sequence. The encoder aims to directly encode graph-level semantics, while the decoder is used to generate longer sequences. Experiments conducted with the benchmark image paragraph dataset show that our proposed achieve 13.3% improvement on the CIDEr evaluation measure when comparing to the previous state-of-the-art approach.",Graph-to-Sequence : RESEARCH_PROBLEM; Transformer : METHOD; Graph-to-Sequence : RESEARCH_PROBLEM; Transformer : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Generating longer textual sequences when conditioned on the visual information is an interesting problem to explore. The challenge here proliferate over the standard vision conditioned sentence-level generation (e.g., image or video captioning) as it requires to produce a brief and coherent story describing the visual content. In this paper, we mask this Vision-to-Sequence as Graph-to-Sequence learning problem and approach it with the Transformer architecture. To be specific, we introduce Sparse Graph-to-Sequence Transformer (SGST) for encoding the graph and decoding a sequence. The encoder aims to directly encode graph-level semantics, while the decoder is used to generate longer sequences. Experiments conducted with the benchmark image paragraph dataset show that our proposed achieve 13.3% improvement on the CIDEr evaluation measure when comparing to the previous state-of-the-art approach. ### Response: Graph-to-Sequence : RESEARCH_PROBLEM; Transformer : METHOD; Graph-to-Sequence : RESEARCH_PROBLEM; Transformer : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Recently, remarkable progress has been made in learning transferable representation across domains. Previous works in domain adaptation are majorly based on two techniques: domain-adversarial learning and self-training. However, domain-adversarial learning only aligns feature distributions between domains but does not consider whether the target features are discriminative. On the other hand, self-training utilizes the model predictions to enhance the discrimination of target features, but it is unable to explicitly align domain distributions. In order to combine the strengths of these two methods, we propose a novel method called Adversarial-Learned Loss for Domain Adaptation (ALDA ). We first analyze the pseudo-label method, a typical self-training method. Nevertheless, there is a gap between pseudo-labels and the ground truth, which can cause incorrect training. Thus we introduce the confusion matrix, which is learned through an adversarial manner in ALDA , to reduce the gap and align the feature distributions. Finally, a new loss function is auto-constructed from the learned confusion matrix, which serves as the loss for unlabeled target samples. Our ALDA outperforms state-of-the-art approaches in four standard domain adaptation datasets. Our code is available at https://github.com/ZJULearning/ALDA .",Domain Adaptation : RESEARCH_PROBLEM; (ALDA : METHOD; ALDA : METHOD; ALDA : METHOD; https://github.com/ZJULearning/ALDA : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Recently, remarkable progress has been made in learning transferable representation across domains. Previous works in domain adaptation are majorly based on two techniques: domain-adversarial learning and self-training. However, domain-adversarial learning only aligns feature distributions between domains but does not consider whether the target features are discriminative. On the other hand, self-training utilizes the model predictions to enhance the discrimination of target features, but it is unable to explicitly align domain distributions. In order to combine the strengths of these two methods, we propose a novel method called Adversarial-Learned Loss for Domain Adaptation (ALDA ). We first analyze the pseudo-label method, a typical self-training method. Nevertheless, there is a gap between pseudo-labels and the ground truth, which can cause incorrect training. Thus we introduce the confusion matrix, which is learned through an adversarial manner in ALDA , to reduce the gap and align the feature distributions. Finally, a new loss function is auto-constructed from the learned confusion matrix, which serves as the loss for unlabeled target samples. Our ALDA outperforms state-of-the-art approaches in four standard domain adaptation datasets. Our code is available at https://github.com/ZJULearning/ALDA . ### Response: Domain Adaptation : RESEARCH_PROBLEM; (ALDA : METHOD; ALDA : METHOD; ALDA : METHOD; https://github.com/ZJULearning/ALDA : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","We propose two neural network architectures for nested named entity recognition (NER ), a setting in which named entities may overlap and also be labeled with more than one label. We encode the nested labels using a linearized scheme. In our first proposed approach, the nested labels are modeled as multilabels corresponding to the Cartesian product of the nested labels in a standard LSTM-CRF architecture. In the second one, the nested NER is viewed as a sequence-to-sequence problem, in which the input sequence consists of the tokens and output sequence of the labels, using hard attention on the word whose label is being predicted. The proposed methods outperform the nested NER state of the art on four corpora: ACE-2004, ACE-2005, GENIA and Czech CNEC. We also enrich our architectures with the recently published contextual embeddings: ELMo, BERT and Flair, reaching further improvements for the four nested entity corpora. In addition, we report flat NER state-of-the-art results for CoNLL-2002 Dutch and Spanish and for CoNLL-2003 English.",(NER : RESEARCH_PROBLEM; NER : RESEARCH_PROBLEM; NER : RESEARCH_PROBLEM; BERT : METHOD; NER : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: We propose two neural network architectures for nested named entity recognition (NER ), a setting in which named entities may overlap and also be labeled with more than one label. We encode the nested labels using a linearized scheme. In our first proposed approach, the nested labels are modeled as multilabels corresponding to the Cartesian product of the nested labels in a standard LSTM-CRF architecture. In the second one, the nested NER is viewed as a sequence-to-sequence problem, in which the input sequence consists of the tokens and output sequence of the labels, using hard attention on the word whose label is being predicted. The proposed methods outperform the nested NER state of the art on four corpora: ACE-2004, ACE-2005, GENIA and Czech CNEC. We also enrich our architectures with the recently published contextual embeddings: ELMo, BERT and Flair, reaching further improvements for the four nested entity corpora. In addition, we report flat NER state-of-the-art results for CoNLL-2002 Dutch and Spanish and for CoNLL-2003 English. ### Response: (NER : RESEARCH_PROBLEM; NER : RESEARCH_PROBLEM; NER : RESEARCH_PROBLEM; BERT : METHOD; NER : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Neural Architecture Search (NAS) is one of the most rapidly growing research fields in machine learning due to its ability to discover high-performance architectures automatically. Although conventional NAS algorithms focus on improving search efficiency (e.g., high performance with less search time), they often require a lot of memory footprint and power consumption. To remedy this problem, we propose a new paradigm for NAS that effectively reduces the use of memory while maintaining high performance. The proposed algorithm is motivated by our observation that manually designed and NAS-based architectures share similar low-level representations, regardless of the difference in the network's topology. Reflecting this, we propose a new architectural paradigm for NAS, called $\textbf{Transfer-NAS}$, that replaces several first cells in the generated architecture with conventional (hand-crafted) pre-trained blocks. As the replaced pre-trained blocks are kept frozen during training, the memory footprint can significantly be reduced. We demonstrate the effectiveness of the proposed method by incorporating it into Regularized Evolution and Differentiable ARchiTecture Search with Perturbation-based architecture selection (DARTS +PT) on NAS-Bench-201 and DARTS search spaces. Extensive experiments show that Transfer-NAS significantly decreases the memory usage up-to $\textbf{50\%}$ while achieving higher/comparable performance compared to the baselines. Furthermore, the proposed method is $\textbf{1.98$\times$}$ faster in terms of search time when incorporated to DARTS +PT on NAS-Bench-201 compared to the conventional method.",Neural Architecture Search : RESEARCH_PROBLEM; (DARTS : METHOD; DARTS : METHOD; DARTS : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Neural Architecture Search (NAS) is one of the most rapidly growing research fields in machine learning due to its ability to discover high-performance architectures automatically. Although conventional NAS algorithms focus on improving search efficiency (e.g., high performance with less search time), they often require a lot of memory footprint and power consumption. To remedy this problem, we propose a new paradigm for NAS that effectively reduces the use of memory while maintaining high performance. The proposed algorithm is motivated by our observation that manually designed and NAS-based architectures share similar low-level representations, regardless of the difference in the network's topology. Reflecting this, we propose a new architectural paradigm for NAS, called $\textbf{Transfer-NAS}$, that replaces several first cells in the generated architecture with conventional (hand-crafted) pre-trained blocks. As the replaced pre-trained blocks are kept frozen during training, the memory footprint can significantly be reduced. We demonstrate the effectiveness of the proposed method by incorporating it into Regularized Evolution and Differentiable ARchiTecture Search with Perturbation-based architecture selection (DARTS +PT) on NAS-Bench-201 and DARTS search spaces. Extensive experiments show that Transfer-NAS significantly decreases the memory usage up-to $\textbf{50\%}$ while achieving higher/comparable performance compared to the baselines. Furthermore, the proposed method is $\textbf{1.98$\times$}$ faster in terms of search time when incorporated to DARTS +PT on NAS-Bench-201 compared to the conventional method. ### Response: Neural Architecture Search : RESEARCH_PROBLEM; (DARTS : METHOD; DARTS : METHOD; DARTS : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Mention detection is an important preprocessing step for annotation and interpretation in applications such as NER and coreference resolution, but few stand-alone neural models have been proposed able to handle the full range of mentions. In this work, we propose and compare three neural network-based approaches to mention detection. The first approach is based on the mention detection part of a state of the art coreference resolution system; the second uses ELMO embeddings together with a bidirectional LSTM and a biaffine classifier; the third approach uses the recently introduced BERT model. Our best model (using a biaffine classifier) achieves gains of up to 1.8 percentage points on mention recall when compared with a strong baseline in a HIGH RECALL coreference annotation setting. The same model achieves improvements of up to 5.3 and 6.2 p.p. when compared with the best-reported mention detection F1 on the CONLL and CRAC coreference data sets respectively in a HIGH F1 annotation setting. We then evaluate our models for coreference resolution by using mentions predicted by our best model in start-of-the-art coreference systems. The enhanced model achieved absolute improvements of up to 1.7 and 0.7 p.p. when compared with our strong baseline systems (pipeline system and end-to-end system) respectively. For nested NER , the evaluation of our model on the GENIA corpora shows that our model matches or outperforms state-of-the-art models despite not being specifically designed for this task.",NER : RESEARCH_PROBLEM; LSTM : METHOD; BERT : METHOD; NER : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Mention detection is an important preprocessing step for annotation and interpretation in applications such as NER and coreference resolution, but few stand-alone neural models have been proposed able to handle the full range of mentions. In this work, we propose and compare three neural network-based approaches to mention detection. The first approach is based on the mention detection part of a state of the art coreference resolution system; the second uses ELMO embeddings together with a bidirectional LSTM and a biaffine classifier; the third approach uses the recently introduced BERT model. Our best model (using a biaffine classifier) achieves gains of up to 1.8 percentage points on mention recall when compared with a strong baseline in a HIGH RECALL coreference annotation setting. The same model achieves improvements of up to 5.3 and 6.2 p.p. when compared with the best-reported mention detection F1 on the CONLL and CRAC coreference data sets respectively in a HIGH F1 annotation setting. We then evaluate our models for coreference resolution by using mentions predicted by our best model in start-of-the-art coreference systems. The enhanced model achieved absolute improvements of up to 1.7 and 0.7 p.p. when compared with our strong baseline systems (pipeline system and end-to-end system) respectively. For nested NER , the evaluation of our model on the GENIA corpora shows that our model matches or outperforms state-of-the-art models despite not being specifically designed for this task. ### Response: NER : RESEARCH_PROBLEM; LSTM : METHOD; BERT : METHOD; NER : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Temporal-difference (TD) learning is an important field in reinforcementlearning. Sarsa and Q-Learning are among the most used TD algorithms. TheQ($\sigma$) algorithm (Sutton and Barto (2017)) unifies both. This paperextends the Q($\sigma$) algorithm to an online multi-step algorithm Q($\sigma,\lambda$) using eligibility traces and introduces Double Q($\sigma$) as theextension of Q($\sigma$) to double learning. Experiments suggest that the newQ($\sigma, \lambda$) algorithm can outperform the classical TD control methodsSarsa ($\lambda$), Q($\lambda$) and Q($\sigma$).",Sarsa : METHOD; Q-Learning : RESEARCH_PROBLEM; methodsSarsa : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Temporal-difference (TD) learning is an important field in reinforcementlearning. Sarsa and Q-Learning are among the most used TD algorithms. TheQ($\sigma$) algorithm (Sutton and Barto (2017)) unifies both. This paperextends the Q($\sigma$) algorithm to an online multi-step algorithm Q($\sigma,\lambda$) using eligibility traces and introduces Double Q($\sigma$) as theextension of Q($\sigma$) to double learning. Experiments suggest that the newQ($\sigma, \lambda$) algorithm can outperform the classical TD control methodsSarsa ($\lambda$), Q($\lambda$) and Q($\sigma$). ### Response: Sarsa : METHOD; Q-Learning : RESEARCH_PROBLEM; methodsSarsa : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Although modern named entity recognition (NER ) systems show impressive performance on standard datasets, they perform poorly when presented with noisy data. In particular, capitalization is a strong signal for entities in many languages, and even state of the art models overfit to this feature, with drastically lower performance on uncapitalized text. In this work, we address the problem of robustness of NER systems in data with noisy or uncertain casing, using a pretraining objective that predicts casing in text, or a truecaser, leveraging unlabeled data. The pretrained truecaser is combined with a standard BiLSTM-CRF model for NER by appending output distributions to character embeddings. In experiments over several datasets of varying domain and casing quality, we show that our new model improves performance in uncased text, even adding value to uncased BERT embeddings. Our method achieves a new state of the art on the WNUT17 shared task dataset.",(NER : RESEARCH_PROBLEM; NER : RESEARCH_PROBLEM; NER : RESEARCH_PROBLEM; BERT : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Although modern named entity recognition (NER ) systems show impressive performance on standard datasets, they perform poorly when presented with noisy data. In particular, capitalization is a strong signal for entities in many languages, and even state of the art models overfit to this feature, with drastically lower performance on uncapitalized text. In this work, we address the problem of robustness of NER systems in data with noisy or uncertain casing, using a pretraining objective that predicts casing in text, or a truecaser, leveraging unlabeled data. The pretrained truecaser is combined with a standard BiLSTM-CRF model for NER by appending output distributions to character embeddings. In experiments over several datasets of varying domain and casing quality, we show that our new model improves performance in uncased text, even adding value to uncased BERT embeddings. Our method achieves a new state of the art on the WNUT17 shared task dataset. ### Response: (NER : RESEARCH_PROBLEM; NER : RESEARCH_PROBLEM; NER : RESEARCH_PROBLEM; BERT : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Multilingual BERT (M-BERT ) has been a huge success in both supervised and zero-shot cross-lingual transfer learning. However, this success has focused only on the top 104 languages in Wikipedia that it was trained on. In this paper, we propose a simple but effective approach to extend M-BERT (E-BERT ) so that it can benefit any new language, and show that our approach benefits languages that are already in M-BERT as well. We perform an extensive set of experiments with Named Entity Recognition (NER) on 27 languages, only 16 of which are in M-BERT , and show an average increase of about 6% F1 on languages that are already in M-BERT and 23% F1 increase on new languages.",BERT : METHOD; (M-BERT : METHOD; M-BERT : METHOD; (E-BERT : METHOD; M-BERT : METHOD; Named Entity Recognition : RESEARCH_PROBLEM; M-BERT : METHOD; M-BERT : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Multilingual BERT (M-BERT ) has been a huge success in both supervised and zero-shot cross-lingual transfer learning. However, this success has focused only on the top 104 languages in Wikipedia that it was trained on. In this paper, we propose a simple but effective approach to extend M-BERT (E-BERT ) so that it can benefit any new language, and show that our approach benefits languages that are already in M-BERT as well. We perform an extensive set of experiments with Named Entity Recognition (NER) on 27 languages, only 16 of which are in M-BERT , and show an average increase of about 6% F1 on languages that are already in M-BERT and 23% F1 increase on new languages. ### Response: BERT : METHOD; (M-BERT : METHOD; M-BERT : METHOD; (E-BERT : METHOD; M-BERT : METHOD; Named Entity Recognition : RESEARCH_PROBLEM; M-BERT : METHOD; M-BERT : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Clustering genotypes based upon their phenotypic characteristics is used to obtain diverse sets of parents that are useful in their breeding programs. The Hierarchical Clustering (HC) algorithm is the current standard in clustering of phenotypic data. This algorithm suffers from low accuracy and high computational complexity issues. To address the accuracy challenge, we propose the use of Spectral Clustering (SC) algorithm. To make the algorithm computationally cheap, we propose using sampling, specifically, Pivotal Sampling that is probability based. Since application of samplings to phenotypic data has not been explored much, for effective comparison, another sampling technique called Vector Quantization (VQ) is adapted for this data as well. VQ has recently given promising results for genome data. The novelty of our SC with Pivotal Sampling algorithm is in constructing the crucial similarity matrix for the clustering algorithm and defining probabilities for the sampling technique. Although our algorithm can be applied to any plant genotypes, we test it on the phenotypic data obtained from about 2400 Soybean genotypes. SC with Pivotal Sampling achieves substantially more accuracy (in terms of Silhouette Values) than all the other proposed competitive clustering with sampling algorithms (i.e. SC with VQ, HC with Pivotal Sampling, and HC with VQ). The complexities of our SC with Pivotal Sampling algorithm and these three variants are almost same because of the involved sampling. In addition to this, SC with Pivotal Sampling outperforms the standard HC algorithm in both accuracy and computational complexity. We experimentally show that we are up to 45% more accurate than HC in terms of clustering accuracy. The computational complexity of our algorithm is more than a magnitude lesser than HC.",Spectral Clustering : METHOD; Quantization : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Clustering genotypes based upon their phenotypic characteristics is used to obtain diverse sets of parents that are useful in their breeding programs. The Hierarchical Clustering (HC) algorithm is the current standard in clustering of phenotypic data. This algorithm suffers from low accuracy and high computational complexity issues. To address the accuracy challenge, we propose the use of Spectral Clustering (SC) algorithm. To make the algorithm computationally cheap, we propose using sampling, specifically, Pivotal Sampling that is probability based. Since application of samplings to phenotypic data has not been explored much, for effective comparison, another sampling technique called Vector Quantization (VQ) is adapted for this data as well. VQ has recently given promising results for genome data. The novelty of our SC with Pivotal Sampling algorithm is in constructing the crucial similarity matrix for the clustering algorithm and defining probabilities for the sampling technique. Although our algorithm can be applied to any plant genotypes, we test it on the phenotypic data obtained from about 2400 Soybean genotypes. SC with Pivotal Sampling achieves substantially more accuracy (in terms of Silhouette Values) than all the other proposed competitive clustering with sampling algorithms (i.e. SC with VQ, HC with Pivotal Sampling, and HC with VQ). The complexities of our SC with Pivotal Sampling algorithm and these three variants are almost same because of the involved sampling. In addition to this, SC with Pivotal Sampling outperforms the standard HC algorithm in both accuracy and computational complexity. We experimentally show that we are up to 45% more accurate than HC in terms of clustering accuracy. The computational complexity of our algorithm is more than a magnitude lesser than HC. ### Response: Spectral Clustering : METHOD; Quantization : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Named Entity Recognition (NER ) is a crucial upstream task in Natural Language Processing (NLP). Traditional tag scheme approaches offer a single recognition that does not meet the needs of many downstream tasks such as coreference resolution. Meanwhile, Tag scheme approaches ignore the continuity of entities. Inspired by one-stage object detection models in computer vision (CV), this paper proposes a new no-tag scheme, the Whole-Aware Detection, which makes NER an object detection task. Meanwhile, this paper presents a novel model, Entity Candidate Network (ECNet), and a specific convolution network, Adaptive Context Convolution Network (ACCN), to fuse multi-scale contexts and encode entity information at each position. ECNet identifies the full span of a named entity and its type at each position based on Entity Loss. Furthermore, ECNet is regulable between the highest precision and the highest recall, while the tag scheme approaches are not. Experimental results on the CoNLL 2003 English dataset and the WNUT 2017 dataset show that ECNet outperforms other previous state-of-the-art methods.",Named Entity Recognition : RESEARCH_PROBLEM; (NER : RESEARCH_PROBLEM; NER : RESEARCH_PROBLEM; Convolution : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Named Entity Recognition (NER ) is a crucial upstream task in Natural Language Processing (NLP). Traditional tag scheme approaches offer a single recognition that does not meet the needs of many downstream tasks such as coreference resolution. Meanwhile, Tag scheme approaches ignore the continuity of entities. Inspired by one-stage object detection models in computer vision (CV), this paper proposes a new no-tag scheme, the Whole-Aware Detection, which makes NER an object detection task. Meanwhile, this paper presents a novel model, Entity Candidate Network (ECNet), and a specific convolution network, Adaptive Context Convolution Network (ACCN), to fuse multi-scale contexts and encode entity information at each position. ECNet identifies the full span of a named entity and its type at each position based on Entity Loss. Furthermore, ECNet is regulable between the highest precision and the highest recall, while the tag scheme approaches are not. Experimental results on the CoNLL 2003 English dataset and the WNUT 2017 dataset show that ECNet outperforms other previous state-of-the-art methods. ### Response: Named Entity Recognition : RESEARCH_PROBLEM; (NER : RESEARCH_PROBLEM; NER : RESEARCH_PROBLEM; Convolution : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","This paper introduces BReG-NeXt, a residual-based network architecture using a function wtih bounded derivative instead of a simple shortcut path (a.k.a. identity mapping) in the residual units for automatic recognition of facial expressions based on the categorical and dimensional models of affect. Compared to ResNet , our proposed adaptive complex mapping results in a shallower network with less numbers of training parameters and floating point operations per second (FLOPs). Adding trainable parameters to the bypass function further improves fitting and training the network and hence recognizing subtle facial expressions such as contempt with a higher accuracy. We conducted comprehensive experiments on the categorical and dimensional models of affect on the challenging in-the-wild databases of AffectNet, FER2013, and Affect-in-Wild. Our experimental results show that our adaptive complex mapping approach outperforms the original ResNet consisting of a simple identity mapping as well as other state-of-the-art methods for Facial Expression Recognition (FER). Various metrics are reported in both affect models to provide a comprehensive evaluation of our method. In the categorical model, BReG-NeXt-50 with only 3.1M training parameters and 15 MFLOPs, achieves 68.50% and 71.53% accuracy on AffectNet and FER2013 databases, respectively. In the dimensional model, BReG-NeXt achieves 0.2577 and 0.2882 RMSE value on AffectNet and Affect-in-Wild databases, respectively.",ResNet : METHOD; ResNet : METHOD; Facial Expression Recognition : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: This paper introduces BReG-NeXt, a residual-based network architecture using a function wtih bounded derivative instead of a simple shortcut path (a.k.a. identity mapping) in the residual units for automatic recognition of facial expressions based on the categorical and dimensional models of affect. Compared to ResNet , our proposed adaptive complex mapping results in a shallower network with less numbers of training parameters and floating point operations per second (FLOPs). Adding trainable parameters to the bypass function further improves fitting and training the network and hence recognizing subtle facial expressions such as contempt with a higher accuracy. We conducted comprehensive experiments on the categorical and dimensional models of affect on the challenging in-the-wild databases of AffectNet, FER2013, and Affect-in-Wild. Our experimental results show that our adaptive complex mapping approach outperforms the original ResNet consisting of a simple identity mapping as well as other state-of-the-art methods for Facial Expression Recognition (FER). Various metrics are reported in both affect models to provide a comprehensive evaluation of our method. In the categorical model, BReG-NeXt-50 with only 3.1M training parameters and 15 MFLOPs, achieves 68.50% and 71.53% accuracy on AffectNet and FER2013 databases, respectively. In the dimensional model, BReG-NeXt achieves 0.2577 and 0.2882 RMSE value on AffectNet and Affect-in-Wild databases, respectively. ### Response: ResNet : METHOD; ResNet : METHOD; Facial Expression Recognition : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Learning on graph structured data has drawn increasing interest in recent years. Frameworks like Graph Convolutional Networks (GCNs) have demonstrated their ability to capture structural information and obtain good performance in various tasks. In these frameworks, node aggregation schemes are typically used to capture structural information: a node's feature vector is recursively computed by aggregating features of its neighboring nodes. However, most of aggregation schemes treat all connections in a graph equally, ignoring node feature similarities. In this paper, we re-interpret node aggregation from the perspective of kernel weighting, and present a framework to consider feature similarity in an aggregation scheme. Specifically, we show that normalized adjacency matrix is equivalent to a neighbor-based kernel matrix in a Krein Space. We then propose feature aggregation as the composition of the original neighbor-based kernel and a learnable kernel to encode feature similarities in a feature space. We further show how the proposed method can be extended to Graph Attention Network (GAT). Experimental results demonstrate better performance of our proposed framework in several real-world applications.",Graph Convolutional Networks : METHOD; Graph Attention : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Learning on graph structured data has drawn increasing interest in recent years. Frameworks like Graph Convolutional Networks (GCNs) have demonstrated their ability to capture structural information and obtain good performance in various tasks. In these frameworks, node aggregation schemes are typically used to capture structural information: a node's feature vector is recursively computed by aggregating features of its neighboring nodes. However, most of aggregation schemes treat all connections in a graph equally, ignoring node feature similarities. In this paper, we re-interpret node aggregation from the perspective of kernel weighting, and present a framework to consider feature similarity in an aggregation scheme. Specifically, we show that normalized adjacency matrix is equivalent to a neighbor-based kernel matrix in a Krein Space. We then propose feature aggregation as the composition of the original neighbor-based kernel and a learnable kernel to encode feature similarities in a feature space. We further show how the proposed method can be extended to Graph Attention Network (GAT). Experimental results demonstrate better performance of our proposed framework in several real-world applications. ### Response: Graph Convolutional Networks : METHOD; Graph Attention : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Deep convolutional neural networks continue to advance the state-of-the-artin many domains as they grow bigger and more complex. It has been observed thatmany of the parameters of a large network are redundant, allowing for thepossibility of learning a smaller network that mimics the outputs of the largenetwork through a process called Knowledge Distillation . We show, however, thatstandard Knowledge Distillation is not effective for learning small models forthe task of pedestrian detection. To improve this process, we introduce ahigher-dimensional hint layer to increase information flow. We also estimatethe variance in the outputs of the large network and propose a loss function toincorporate this uncertainty. Finally, we attempt to boost the complexity ofthe small network without increasing its size by using as input hand-designedfeatures that have been demonstrated to be effective for pedestrian detection.We succeed in training a model that contains $400\times$ fewer parameters thanthe large network while outperforming AlexNet on the Caltech PedestrianDataset.",Knowledge Distillation : RESEARCH_PROBLEM; Knowledge Distillation : RESEARCH_PROBLEM; AlexNet : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Deep convolutional neural networks continue to advance the state-of-the-artin many domains as they grow bigger and more complex. It has been observed thatmany of the parameters of a large network are redundant, allowing for thepossibility of learning a smaller network that mimics the outputs of the largenetwork through a process called Knowledge Distillation . We show, however, thatstandard Knowledge Distillation is not effective for learning small models forthe task of pedestrian detection. To improve this process, we introduce ahigher-dimensional hint layer to increase information flow. We also estimatethe variance in the outputs of the large network and propose a loss function toincorporate this uncertainty. Finally, we attempt to boost the complexity ofthe small network without increasing its size by using as input hand-designedfeatures that have been demonstrated to be effective for pedestrian detection.We succeed in training a model that contains $400\times$ fewer parameters thanthe large network while outperforming AlexNet on the Caltech PedestrianDataset. ### Response: Knowledge Distillation : RESEARCH_PROBLEM; Knowledge Distillation : RESEARCH_PROBLEM; AlexNet : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Chemical patents are an important resource for chemical information. However, few chemical Named Entity Recognition (NER ) systems have been evaluated on patent documents, due in part to their structural and linguistic complexity. In this paper, we explore the NER performance of a BiLSTM-CRF model utilising pre-trained word embeddings, character-level word representations and contextualized ELMo word representations for chemical patents. We compare word embeddings pre-trained on biomedical and chemical patent corpora. The effect of tokenizers optimized for the chemical domain on NER performance in chemical patents is also explored. The results on two patent corpora show that contextualized word representations generated from ELMo substantially improve chemical NER performance w.r.t. the current state-of-the-art. We also show that domain-specific resources such as word embeddings trained on chemical patents and chemical-specific tokenizers have a positive impact on NER performance.",Named Entity Recognition : RESEARCH_PROBLEM; (NER : RESEARCH_PROBLEM; NER : RESEARCH_PROBLEM; ELMo : METHOD; NER : RESEARCH_PROBLEM; ELMo : METHOD; NER : RESEARCH_PROBLEM; NER : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Chemical patents are an important resource for chemical information. However, few chemical Named Entity Recognition (NER ) systems have been evaluated on patent documents, due in part to their structural and linguistic complexity. In this paper, we explore the NER performance of a BiLSTM-CRF model utilising pre-trained word embeddings, character-level word representations and contextualized ELMo word representations for chemical patents. We compare word embeddings pre-trained on biomedical and chemical patent corpora. The effect of tokenizers optimized for the chemical domain on NER performance in chemical patents is also explored. The results on two patent corpora show that contextualized word representations generated from ELMo substantially improve chemical NER performance w.r.t. the current state-of-the-art. We also show that domain-specific resources such as word embeddings trained on chemical patents and chemical-specific tokenizers have a positive impact on NER performance. ### Response: Named Entity Recognition : RESEARCH_PROBLEM; (NER : RESEARCH_PROBLEM; NER : RESEARCH_PROBLEM; ELMo : METHOD; NER : RESEARCH_PROBLEM; ELMo : METHOD; NER : RESEARCH_PROBLEM; NER : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","We present a new approach for pretraining a bi-directional transformer modelthat provides significant performance gains across a variety of languageunderstanding problems. Our model solves a cloze-style word reconstructiontask, where each word is ablated and must be predicted given the rest of thetext. Experiments demonstrate large performance gains on GLUE and new state ofthe art results on NER as well as constituency parsing benchmarks, consistentwith the concurrently introduced BERT model. We also present a detailedanalysis of a number of factors that contribute to effective pretraining,including data domain and size, model capacity, and variations on the clozeobjective.",NER : RESEARCH_PROBLEM; BERT : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: We present a new approach for pretraining a bi-directional transformer modelthat provides significant performance gains across a variety of languageunderstanding problems. Our model solves a cloze-style word reconstructiontask, where each word is ablated and must be predicted given the rest of thetext. Experiments demonstrate large performance gains on GLUE and new state ofthe art results on NER as well as constituency parsing benchmarks, consistentwith the concurrently introduced BERT model. We also present a detailedanalysis of a number of factors that contribute to effective pretraining,including data domain and size, model capacity, and variations on the clozeobjective. ### Response: NER : RESEARCH_PROBLEM; BERT : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","The representation used for Facial Expression Recognition (FER) usually contain expression information along with other variations such as identity and illumination. In this paper, we propose a novel Disentangled Expression learning-Generative Adversarial Network (DE-GAN) to explicitly disentangle facial expression representation from identity information. In this learning by reconstruction method, facial expression representation is learned by reconstructing an expression image employing an encoder-decoder based generator. This expression representation is disentangled from identity component by explicitly providing the identity code to the decoder part of DE-GAN. The process of expression image reconstruction and disentangled expression representation learning is improved by performing expression and identity classification in the discriminator of DE-GAN. The disentangled facial expression representation is then used for facial expression recognition employing simple classifiers like SVM or MLP. The experiments are performed on publicly available and widely used face expression databases (CK+, MMI, Oulu-CASIA). The experimental results show that the proposed technique produces comparable results with state-of-the-art methods.",Facial Expression Recognition : RESEARCH_PROBLEM; SVM : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: The representation used for Facial Expression Recognition (FER) usually contain expression information along with other variations such as identity and illumination. In this paper, we propose a novel Disentangled Expression learning-Generative Adversarial Network (DE-GAN) to explicitly disentangle facial expression representation from identity information. In this learning by reconstruction method, facial expression representation is learned by reconstructing an expression image employing an encoder-decoder based generator. This expression representation is disentangled from identity component by explicitly providing the identity code to the decoder part of DE-GAN. The process of expression image reconstruction and disentangled expression representation learning is improved by performing expression and identity classification in the discriminator of DE-GAN. The disentangled facial expression representation is then used for facial expression recognition employing simple classifiers like SVM or MLP. The experiments are performed on publicly available and widely used face expression databases (CK+, MMI, Oulu-CASIA). The experimental results show that the proposed technique produces comparable results with state-of-the-art methods. ### Response: Facial Expression Recognition : RESEARCH_PROBLEM; SVM : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Contextual word-representations became a standard in modern natural language processing systems. These models use subword tokenization to handle large vocabularies and unknown words. Word-level usage of such systems requires a way of pooling multiple subwords that correspond to a single word. In this paper we investigate how the choice of subword pooling affects the downstream performance on three tasks: morphological probing, POS tagging and NER , in 9 typologically diverse languages. We compare these in two massively multilingual models, mBERT and XLM-RoBERTa. For morphological tasks, the widely used `choose the first subword' is the worst strategy and the best results are obtained by using attention over the subwords. For POS tagging both of these strategies perform poorly and the best choice is to use a small LSTM over the subwords. The same strategy works best for NER and we show that mBERT is better than XLM-RoBERTa in all 9 languages. We publicly release all code, data and the full result tables at \url{https://github.com/juditacs/subword-choice}.",POS : RESEARCH_PROBLEM; NER : RESEARCH_PROBLEM; POS : RESEARCH_PROBLEM; LSTM : METHOD; NER : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Contextual word-representations became a standard in modern natural language processing systems. These models use subword tokenization to handle large vocabularies and unknown words. Word-level usage of such systems requires a way of pooling multiple subwords that correspond to a single word. In this paper we investigate how the choice of subword pooling affects the downstream performance on three tasks: morphological probing, POS tagging and NER , in 9 typologically diverse languages. We compare these in two massively multilingual models, mBERT and XLM-RoBERTa. For morphological tasks, the widely used `choose the first subword' is the worst strategy and the best results are obtained by using attention over the subwords. For POS tagging both of these strategies perform poorly and the best choice is to use a small LSTM over the subwords. The same strategy works best for NER and we show that mBERT is better than XLM-RoBERTa in all 9 languages. We publicly release all code, data and the full result tables at \url{https://github.com/juditacs/subword-choice}. ### Response: POS : RESEARCH_PROBLEM; NER : RESEARCH_PROBLEM; POS : RESEARCH_PROBLEM; LSTM : METHOD; NER : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","The road is vital for many aspects of life, and road maintenance is crucial for human safety. One of the critical tasks to allow timely repair of road damages is to quickly and efficiently detect and classify them. This work details the strategies and experiments evaluated for these tasks. Specifically, we evaluate Detectron2's implementation of Faster R-CNN using different base models and configurations. We also experiment with these approaches using the Global Road Damage Detection Challenge 2020, A Track in the IEEE Big Data 2020 Big Data Cup Challenge dataset. The results show that the X101-FPN base model for Faster R-CNN with Detectron2's default configurations are efficient and general enough to be transferable to different countries in this challenge. This approach results in F1 scores of 51.0% and 51.4% for the test1 and test2 sets of the challenge, respectively. Though the visualizations show good prediction results, the F1 scores are low. Therefore, we also evaluate the prediction results against the existing annotations and discover some discrepancies. Thus, we also suggest strategies to improve the labeling process for this dataset.",Faster R-CNN : METHOD; Road Damage Detection : RESEARCH_PROBLEM; Faster R-CNN : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: The road is vital for many aspects of life, and road maintenance is crucial for human safety. One of the critical tasks to allow timely repair of road damages is to quickly and efficiently detect and classify them. This work details the strategies and experiments evaluated for these tasks. Specifically, we evaluate Detectron2's implementation of Faster R-CNN using different base models and configurations. We also experiment with these approaches using the Global Road Damage Detection Challenge 2020, A Track in the IEEE Big Data 2020 Big Data Cup Challenge dataset. The results show that the X101-FPN base model for Faster R-CNN with Detectron2's default configurations are efficient and general enough to be transferable to different countries in this challenge. This approach results in F1 scores of 51.0% and 51.4% for the test1 and test2 sets of the challenge, respectively. Though the visualizations show good prediction results, the F1 scores are low. Therefore, we also evaluate the prediction results against the existing annotations and discover some discrepancies. Thus, we also suggest strategies to improve the labeling process for this dataset. ### Response: Faster R-CNN : METHOD; Road Damage Detection : RESEARCH_PROBLEM; Faster R-CNN : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Visible-Infrared person re-identification (VI-ReID) aims to match cross-modality pedestrian images, breaking through the limitation of single-modality person ReID in dark environment. In order to mitigate the impact of large modality discrepancy, existing works manually design various two-stream architectures to separately learn modality-specific and modality-sharable representations. Such a manual design routine, however, highly depends on massive experiments and empirical practice, which is time consuming and labor intensive. In this paper, we systematically study the manually designed architectures, and identify that appropriately separating Batch Normalization (BN) layers is the key to bring a great boost towards cross-modality matching. Based on this observation, the essential objective is to find the optimal separation scheme for each BN layer. To this end, we propose a novel method, named Cross-Modality Neural Architecture Search (CM-NAS). It consists of a BN-oriented search space in which the standard optimization can be fulfilled subject to the cross-modality task. Equipped with the searched architecture, our method outperforms state-of-the-art counterparts in both two benchmarks, improving the Rank-1/mAP by 6.70%/6.13% on SYSU-MM01 and by 12.17%/11.23% on RegDB. Code is released at https://github.com/JDAI-CV/CM-NAS.",Batch Normalization : METHOD; Neural Architecture Search : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Visible-Infrared person re-identification (VI-ReID) aims to match cross-modality pedestrian images, breaking through the limitation of single-modality person ReID in dark environment. In order to mitigate the impact of large modality discrepancy, existing works manually design various two-stream architectures to separately learn modality-specific and modality-sharable representations. Such a manual design routine, however, highly depends on massive experiments and empirical practice, which is time consuming and labor intensive. In this paper, we systematically study the manually designed architectures, and identify that appropriately separating Batch Normalization (BN) layers is the key to bring a great boost towards cross-modality matching. Based on this observation, the essential objective is to find the optimal separation scheme for each BN layer. To this end, we propose a novel method, named Cross-Modality Neural Architecture Search (CM-NAS). It consists of a BN-oriented search space in which the standard optimization can be fulfilled subject to the cross-modality task. Equipped with the searched architecture, our method outperforms state-of-the-art counterparts in both two benchmarks, improving the Rank-1/mAP by 6.70%/6.13% on SYSU-MM01 and by 12.17%/11.23% on RegDB. Code is released at https://github.com/JDAI-CV/CM-NAS. ### Response: Batch Normalization : METHOD; Neural Architecture Search : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Zero-shot Neural Architecture Search (ZS-NAS) is a recently developed low-cost NAS framework which identifies top-performer neural architectures from a large candidate pool without training their parameters. Despite its popularity in recent NAS literatures, the effectiveness of ZS-NAS has not been comprehensively understood. Previous works analyze ZS-NAS methods on NAS benchmark datasets such as NAS-Bench-101/201/301 which are initially designed for learning network topology with irregular connections. However, most modern state-of-the-art networks as well as popular classical ones are designed in more conventional, well-established search spaces such as ResNet (RS) and MobileNet (MB) search space. This imposes a significant gap between the benchmark dataset and real-world practice, hindering a deeper understanding of ZS-NAS. In this work, we aim to bridge the gap systematically. First, we collect a novel large-scale dataset termed NAS-Bench-Zero for benchmarking and understanding popular ZS-NAS methods in the conventional RS/MB search spaces. Then the characteristics of these ZS-NAS methods are extensively examined from various aspects. Notably, we find that: 1) the performance of ZS-NAS on NAS-Bench-101/201/301 cannot transfer to RS/MB search spaces; 2) A proxy with higher ranking correlation score may actually perform worse in constrained NAS; 3) existing zero-shot proxies cannot outperform naive proxies such as FLOPs/params in RS/MB search spaces; 4) Top best zero-shot proxies as well as FLOPs/params compensate each other. Based on these new discoveries, we propose i) a novel hybrid zero-shot proxy which outperforms existing ones by a large margin and is transferable among popular search spaces; ii) a new index for better measuring the true performance of ZS-NAS proxies in constrained NAS. Source code and the NAS-Bench-Zero dataset will be released after publication.",Neural Architecture Search : RESEARCH_PROBLEM; ResNet : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Zero-shot Neural Architecture Search (ZS-NAS) is a recently developed low-cost NAS framework which identifies top-performer neural architectures from a large candidate pool without training their parameters. Despite its popularity in recent NAS literatures, the effectiveness of ZS-NAS has not been comprehensively understood. Previous works analyze ZS-NAS methods on NAS benchmark datasets such as NAS-Bench-101/201/301 which are initially designed for learning network topology with irregular connections. However, most modern state-of-the-art networks as well as popular classical ones are designed in more conventional, well-established search spaces such as ResNet (RS) and MobileNet (MB) search space. This imposes a significant gap between the benchmark dataset and real-world practice, hindering a deeper understanding of ZS-NAS. In this work, we aim to bridge the gap systematically. First, we collect a novel large-scale dataset termed NAS-Bench-Zero for benchmarking and understanding popular ZS-NAS methods in the conventional RS/MB search spaces. Then the characteristics of these ZS-NAS methods are extensively examined from various aspects. Notably, we find that: 1) the performance of ZS-NAS on NAS-Bench-101/201/301 cannot transfer to RS/MB search spaces; 2) A proxy with higher ranking correlation score may actually perform worse in constrained NAS; 3) existing zero-shot proxies cannot outperform naive proxies such as FLOPs/params in RS/MB search spaces; 4) Top best zero-shot proxies as well as FLOPs/params compensate each other. Based on these new discoveries, we propose i) a novel hybrid zero-shot proxy which outperforms existing ones by a large margin and is transferable among popular search spaces; ii) a new index for better measuring the true performance of ZS-NAS proxies in constrained NAS. Source code and the NAS-Bench-Zero dataset will be released after publication. ### Response: Neural Architecture Search : RESEARCH_PROBLEM; ResNet : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Graph neural networks (GNN) have shown great success in learning from graph-structured data. They are widely used in various applications, such as recommendation, fraud detection, and search. In these domains, the graphs are typically large, containing hundreds of millions of nodes and several billions of edges. To tackle this challenge, we develop DistDGL , a system for training GNNs in a mini-batch fashion on a cluster of machines. DistDGL is based on the Deep Graph Library (DGL), a popular GNN development framework. DistDGL distributes the graph and its associated data (initial features and embeddings) across the machines and uses this distribution to derive a computational decomposition by following an owner-compute rule. DistDGL follows a synchronous training approach and allows ego-networks forming the mini-batches to include non-local nodes. To minimize the overheads associated with distributed computations, DistDGL uses a high-quality and light-weight min-cut graph partitioning algorithm along with multiple balancing constraints. This allows it to reduce communication overheads and statically balance the computations. It further reduces the communication by replicating halo nodes and by using sparse embedding updates. The combination of these design choices allows DistDGL to train high-quality models while achieving high parallel efficiency and memory scalability. We demonstrate our optimizations on both inductive and transductive GNN models. Our results show that DistDGL achieves linear speedup without compromising model accuracy and requires only 13 seconds to complete a training epoch for a graph with 100 million nodes and 3 billion edges on a cluster with 16 machines. DistDGL is now publicly available as part of DGL:https://github.com/dmlc/dgl/tree/master/python/dgl/distributed.",DistDGL : METHOD; DistDGL : METHOD; DistDGL : METHOD; DistDGL : METHOD; DistDGL : METHOD; graph partitioning : RESEARCH_PROBLEM; DistDGL : METHOD; DistDGL : METHOD; DistDGL : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Graph neural networks (GNN) have shown great success in learning from graph-structured data. They are widely used in various applications, such as recommendation, fraud detection, and search. In these domains, the graphs are typically large, containing hundreds of millions of nodes and several billions of edges. To tackle this challenge, we develop DistDGL , a system for training GNNs in a mini-batch fashion on a cluster of machines. DistDGL is based on the Deep Graph Library (DGL), a popular GNN development framework. DistDGL distributes the graph and its associated data (initial features and embeddings) across the machines and uses this distribution to derive a computational decomposition by following an owner-compute rule. DistDGL follows a synchronous training approach and allows ego-networks forming the mini-batches to include non-local nodes. To minimize the overheads associated with distributed computations, DistDGL uses a high-quality and light-weight min-cut graph partitioning algorithm along with multiple balancing constraints. This allows it to reduce communication overheads and statically balance the computations. It further reduces the communication by replicating halo nodes and by using sparse embedding updates. The combination of these design choices allows DistDGL to train high-quality models while achieving high parallel efficiency and memory scalability. We demonstrate our optimizations on both inductive and transductive GNN models. Our results show that DistDGL achieves linear speedup without compromising model accuracy and requires only 13 seconds to complete a training epoch for a graph with 100 million nodes and 3 billion edges on a cluster with 16 machines. DistDGL is now publicly available as part of DGL:https://github.com/dmlc/dgl/tree/master/python/dgl/distributed. ### Response: DistDGL : METHOD; DistDGL : METHOD; DistDGL : METHOD; DistDGL : METHOD; DistDGL : METHOD; graph partitioning : RESEARCH_PROBLEM; DistDGL : METHOD; DistDGL : METHOD; DistDGL : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Performance of fingerprint recognition algorithms substantially rely on fine features extracted from fingerprints. Apart from minutiae and ridge patterns, pore features have proven to be usable for fingerprint recognition. Although features from minutiae and ridge patterns are quite attainable from low-resolution images, using pore features is practical only if the fingerprint image is of high resolution which necessitates a model that enhances the image quality of the conventional 500 ppi legacy fingerprints preserving the fine details. To find a solution for recovering pore information from low-resolution fingerprints, we adopt a joint learning-based approach that combines both super-resolution and pore detection networks. Our modified single image Super-Resolution Generative Adversarial Network (SRGAN ) framework helps to reliably reconstruct high-resolution fingerprint samples from low-resolution ones assisting the pore detection network to identify pores with a high accuracy. The network jointly learns a distinctive feature representation from a real low-resolution fingerprint sample and successfully synthesizes a high-resolution sample from it. To add discriminative information and uniqueness for all the subjects, we have integrated features extracted from a deep fingerprint verifier with the SRGAN quality discriminator. We also add ridge reconstruction loss, utilizing ridge patterns to make the best use of extracted features. Our proposed method solves the recognition problem by improving the quality of fingerprint images. High recognition accuracy of the synthesized samples that is close to the accuracy achieved using the original high-resolution images validate the effectiveness of our proposed model.",Super-Resolution : RESEARCH_PROBLEM; (SRGAN : METHOD; SRGAN : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Performance of fingerprint recognition algorithms substantially rely on fine features extracted from fingerprints. Apart from minutiae and ridge patterns, pore features have proven to be usable for fingerprint recognition. Although features from minutiae and ridge patterns are quite attainable from low-resolution images, using pore features is practical only if the fingerprint image is of high resolution which necessitates a model that enhances the image quality of the conventional 500 ppi legacy fingerprints preserving the fine details. To find a solution for recovering pore information from low-resolution fingerprints, we adopt a joint learning-based approach that combines both super-resolution and pore detection networks. Our modified single image Super-Resolution Generative Adversarial Network (SRGAN ) framework helps to reliably reconstruct high-resolution fingerprint samples from low-resolution ones assisting the pore detection network to identify pores with a high accuracy. The network jointly learns a distinctive feature representation from a real low-resolution fingerprint sample and successfully synthesizes a high-resolution sample from it. To add discriminative information and uniqueness for all the subjects, we have integrated features extracted from a deep fingerprint verifier with the SRGAN quality discriminator. We also add ridge reconstruction loss, utilizing ridge patterns to make the best use of extracted features. Our proposed method solves the recognition problem by improving the quality of fingerprint images. High recognition accuracy of the synthesized samples that is close to the accuracy achieved using the original high-resolution images validate the effectiveness of our proposed model. ### Response: Super-Resolution : RESEARCH_PROBLEM; (SRGAN : METHOD; SRGAN : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","The growing interest in argument mining and computational argumentation brings with it a plethora of Natural Language Understanding (NLU) tasks and corresponding datasets. However, as with many other NLU tasks, the dominant language is English, with resources in other languages being few and far between. In this work, we explore the potential of transfer learning using the multilingual BERT model to address argument mining tasks in non-English languages, based on English datasets and the use of machine translation. We show that such methods are well suited for classifying the stance of arguments and detecting evidence, but less so for assessing the quality of arguments, presumably because quality is harder to preserve under translation. In addition, focusing on the translate-train approach, we show how the choice of languages for translation, and the relations among them, affect the accuracy of the resultant model. Finally, to facilitate evaluation of transfer learning on argument mining tasks, we provide a human-generated dataset with more than 10k arguments in multiple languages, as well as machine translation of the English datasets.",Natural Language Understanding : RESEARCH_PROBLEM; BERT : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: The growing interest in argument mining and computational argumentation brings with it a plethora of Natural Language Understanding (NLU) tasks and corresponding datasets. However, as with many other NLU tasks, the dominant language is English, with resources in other languages being few and far between. In this work, we explore the potential of transfer learning using the multilingual BERT model to address argument mining tasks in non-English languages, based on English datasets and the use of machine translation. We show that such methods are well suited for classifying the stance of arguments and detecting evidence, but less so for assessing the quality of arguments, presumably because quality is harder to preserve under translation. In addition, focusing on the translate-train approach, we show how the choice of languages for translation, and the relations among them, affect the accuracy of the resultant model. Finally, to facilitate evaluation of transfer learning on argument mining tasks, we provide a human-generated dataset with more than 10k arguments in multiple languages, as well as machine translation of the English datasets. ### Response: Natural Language Understanding : RESEARCH_PROBLEM; BERT : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Human motion prediction is a necessary component for many applications in robotics and autonomous driving. Recent methods propose using sequence-to-sequence deep learning models to tackle this problem. However, they do not focus on exploiting different temporal scales for different length inputs. We argue that the diverse temporal scales are important as they allow us to look at the past frames with different receptive fields, which can lead to better predictions. In this paper, we propose a Temporal Inception Module (TIM) to encode human motion. Making use of TIM, our framework produces input embeddings using convolutional layers, by using different kernel sizes for different input lengths. The experimental results on standard motion prediction benchmark datasets Human3.6M and CMU motion capture dataset show that our approach consistently outperforms the state of the art methods.",Human motion prediction : RESEARCH_PROBLEM; Inception Module : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Human motion prediction is a necessary component for many applications in robotics and autonomous driving. Recent methods propose using sequence-to-sequence deep learning models to tackle this problem. However, they do not focus on exploiting different temporal scales for different length inputs. We argue that the diverse temporal scales are important as they allow us to look at the past frames with different receptive fields, which can lead to better predictions. In this paper, we propose a Temporal Inception Module (TIM) to encode human motion. Making use of TIM, our framework produces input embeddings using convolutional layers, by using different kernel sizes for different input lengths. The experimental results on standard motion prediction benchmark datasets Human3.6M and CMU motion capture dataset show that our approach consistently outperforms the state of the art methods. ### Response: Human motion prediction : RESEARCH_PROBLEM; Inception Module : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","We explore an ensembled $\Sigma$-net for fast parallel MR imaging, including parallel coil networks, which perform implicit coil weighting, and sensitivity networks, involving explicit sensitivity maps. The networks in $\Sigma$-net are trained in a supervised way, including content and GAN losses, and with various ways of data consistency, i.e., proximal mappings, gradient descent and variable splitting. A semi-supervised finetuning scheme allows us to adapt to the k-space data at test time, which, however, decreases the quantitative metrics, although generating the visually most textured and sharp images. For this challenge, we focused on robust and high SSIM scores, which we achieved by ensembling all models to a $\Sigma$-net.",GAN : METHOD; SSIM : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: We explore an ensembled $\Sigma$-net for fast parallel MR imaging, including parallel coil networks, which perform implicit coil weighting, and sensitivity networks, involving explicit sensitivity maps. The networks in $\Sigma$-net are trained in a supervised way, including content and GAN losses, and with various ways of data consistency, i.e., proximal mappings, gradient descent and variable splitting. A semi-supervised finetuning scheme allows us to adapt to the k-space data at test time, which, however, decreases the quantitative metrics, although generating the visually most textured and sharp images. For this challenge, we focused on robust and high SSIM scores, which we achieved by ensembling all models to a $\Sigma$-net. ### Response: GAN : METHOD; SSIM : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","This paper describes the machine translation systems developed by the Barcelona Supercomputing (BSC) team for the biomedical translation shared task of WMT19. Our system is based on Neural Machine Translation unsing the OpenNMT-py toolkit and Transformer architecture. We participated in four translation directions for the English/Spanish and English/Portuguese language pairs. To create our training data, we concatenated several parallel corpora, both from in-domain and out-of-domain sources, as well as terminological resources from UMLS.",Machine Translation : RESEARCH_PROBLEM; Transformer : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: This paper describes the machine translation systems developed by the Barcelona Supercomputing (BSC) team for the biomedical translation shared task of WMT19. Our system is based on Neural Machine Translation unsing the OpenNMT-py toolkit and Transformer architecture. We participated in four translation directions for the English/Spanish and English/Portuguese language pairs. To create our training data, we concatenated several parallel corpora, both from in-domain and out-of-domain sources, as well as terminological resources from UMLS. ### Response: Machine Translation : RESEARCH_PROBLEM; Transformer : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","In graphs with rich texts, incorporating textual information with structural information would benefit constructing expressive graph embeddings. Among various graph embedding models, random walk (RW)-based is one of the most popular and successful groups. However, it is challenged by two issues when applied on graphs with rich texts: (i) sampling efficiency: deriving from the training objective of RW-based models (e.g., DeepWalk and node2vec), we show that RW-based models are likely to generate large amounts of redundant training samples due to three main drawbacks. (ii) text utilization: these models have difficulty in dealing with zero-shot scenarios where graph embedding models have to infer graph structures directly from texts. To solve these problems, we propose a novel framework, namely Text-driven Graph Embedding with Pairs Sampling (TGE-PS). TGE-PS uses Pairs Sampling (PS) to improve the sampling strategy of RW, being able to reduce ~99% training samples while preserving competitive performance. TGE-PS uses Text-driven Graph Embedding (TGE), an inductive graph embedding approach, to generate node embeddings from texts. Since each node contains rich texts, TGE is able to generate high-quality embeddings and provide reasonable predictions on existence of links to unseen nodes. We evaluate TGE-PS on several real-world datasets, and experiment results demonstrate that TGE-PS produces state-of-the-art results on both traditional and zero-shot link prediction tasks.",DeepWalk : METHOD; Graph Embedding : RESEARCH_PROBLEM; Graph Embedding : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: In graphs with rich texts, incorporating textual information with structural information would benefit constructing expressive graph embeddings. Among various graph embedding models, random walk (RW)-based is one of the most popular and successful groups. However, it is challenged by two issues when applied on graphs with rich texts: (i) sampling efficiency: deriving from the training objective of RW-based models (e.g., DeepWalk and node2vec), we show that RW-based models are likely to generate large amounts of redundant training samples due to three main drawbacks. (ii) text utilization: these models have difficulty in dealing with zero-shot scenarios where graph embedding models have to infer graph structures directly from texts. To solve these problems, we propose a novel framework, namely Text-driven Graph Embedding with Pairs Sampling (TGE-PS). TGE-PS uses Pairs Sampling (PS) to improve the sampling strategy of RW, being able to reduce ~99% training samples while preserving competitive performance. TGE-PS uses Text-driven Graph Embedding (TGE), an inductive graph embedding approach, to generate node embeddings from texts. Since each node contains rich texts, TGE is able to generate high-quality embeddings and provide reasonable predictions on existence of links to unseen nodes. We evaluate TGE-PS on several real-world datasets, and experiment results demonstrate that TGE-PS produces state-of-the-art results on both traditional and zero-shot link prediction tasks. ### Response: DeepWalk : METHOD; Graph Embedding : RESEARCH_PROBLEM; Graph Embedding : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Today's Automatic Speech Recognition systems only rely on acoustic signalsand often don't perform well under noisy conditions. Performing multi-modalspeech recognition - processing acoustic speech signals and lip-reading videosimultaneously - significantly enhances the performance of such systems,especially in noisy environments. This work presents the design of such anaudio-visual system for Automated Speech Recognition , taking memory andcomputation requirements into account. First, a Long-Short-Term-Memory neuralnetwork for acoustic speech recognition is designed. Second, ConvolutionalNeural Networks are used to model lip-reading features. These are combined withan LSTM network to model temporal dependencies and perform automaticlip-reading on video. Finally, acoustic-speech and visual lip-reading networksare combined to process acoustic and visual features simultaneously. Anattention mechanism ensures performance of the model in noisy environments.This system is evaluated on the TCD-TIMIT 'lipspeaker' dataset for audio-visualphoneme recognition with clean audio and with additive white noise at an SNR of0dB. It achieves 75.70% and 58.55% phoneme accuracy respectively, over 14percentage points better than the state-of-the-art for all noise levels.",Speech Recognition : RESEARCH_PROBLEM; Speech Recognition : RESEARCH_PROBLEM; LSTM : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Today's Automatic Speech Recognition systems only rely on acoustic signalsand often don't perform well under noisy conditions. Performing multi-modalspeech recognition - processing acoustic speech signals and lip-reading videosimultaneously - significantly enhances the performance of such systems,especially in noisy environments. This work presents the design of such anaudio-visual system for Automated Speech Recognition , taking memory andcomputation requirements into account. First, a Long-Short-Term-Memory neuralnetwork for acoustic speech recognition is designed. Second, ConvolutionalNeural Networks are used to model lip-reading features. These are combined withan LSTM network to model temporal dependencies and perform automaticlip-reading on video. Finally, acoustic-speech and visual lip-reading networksare combined to process acoustic and visual features simultaneously. Anattention mechanism ensures performance of the model in noisy environments.This system is evaluated on the TCD-TIMIT 'lipspeaker' dataset for audio-visualphoneme recognition with clean audio and with additive white noise at an SNR of0dB. It achieves 75.70% and 58.55% phoneme accuracy respectively, over 14percentage points better than the state-of-the-art for all noise levels. ### Response: Speech Recognition : RESEARCH_PROBLEM; Speech Recognition : RESEARCH_PROBLEM; LSTM : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","In this paper, we present various systems submitted by our team problemConquero for SemEval-2020 Shared Task 12 Multilingual Offensive Language Identification in Social Media. We participated in all the three sub-tasks of OffensEval-2020, and our final submissions during the evaluation phase included transformer-based approaches and a soft label-based approach. BERT based fine-tuned models were submitted for each language of sub-task A (offensive tweet identification). RoBERTa based fine-tuned model for sub-task B (automatic categorization of offense types) was submitted. We submitted two models for sub-task C (offense target identification), one using soft labels and the other using BERT based fine-tuned model. Our ranks for sub-task A were Greek-19 out of 37, Turkish-22 out of 46, Danish-26 out of 39, Arabic-39 out of 53, and English-20 out of 85. We achieved a rank of 28 out of 43 for sub-task B. Our best rank for sub-task C was 20 out of 39 using BERT based fine-tuned model.",Language Identification : RESEARCH_PROBLEM; RoBERTa : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: In this paper, we present various systems submitted by our team problemConquero for SemEval-2020 Shared Task 12 Multilingual Offensive Language Identification in Social Media. We participated in all the three sub-tasks of OffensEval-2020, and our final submissions during the evaluation phase included transformer-based approaches and a soft label-based approach. BERT based fine-tuned models were submitted for each language of sub-task A (offensive tweet identification). RoBERTa based fine-tuned model for sub-task B (automatic categorization of offense types) was submitted. We submitted two models for sub-task C (offense target identification), one using soft labels and the other using BERT based fine-tuned model. Our ranks for sub-task A were Greek-19 out of 37, Turkish-22 out of 46, Danish-26 out of 39, Arabic-39 out of 53, and English-20 out of 85. We achieved a rank of 28 out of 43 for sub-task B. Our best rank for sub-task C was 20 out of 39 using BERT based fine-tuned model. ### Response: Language Identification : RESEARCH_PROBLEM; RoBERTa : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Residual-based neural networks have shown remarkable results in variousvisual recognition tasks including Facial Expression Recognition (FER). Despitethe tremendous efforts have been made to improve the performance of FER systemsusing DNNs, existing methods are not generalizable enough for practicalapplications. This paper introduces Bounded Residual Gradient Networks(BReG-Net) for facial expression recognition, in which the shortcut connectionbetween the input and the output of the ResNet module is replaced with adifferentiable function with a bounded gradient. This configuration preventsthe network from facing the vanishing or exploding gradient problem. We showthat utilizing such non-linear units will result in shallower networks withbetter performance. Further, by using a weighted loss function which gives ahigher priority to less represented categories, we can achieve an overallbetter recognition rate. The results of our experiments show that BReG-Netsoutperform state-of-the-art methods on three publicly available facialdatabases in the wild, on both the categorical and dimensional models ofaffect.",Facial Expression Recognition : RESEARCH_PROBLEM; ResNet : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Residual-based neural networks have shown remarkable results in variousvisual recognition tasks including Facial Expression Recognition (FER). Despitethe tremendous efforts have been made to improve the performance of FER systemsusing DNNs, existing methods are not generalizable enough for practicalapplications. This paper introduces Bounded Residual Gradient Networks(BReG-Net) for facial expression recognition, in which the shortcut connectionbetween the input and the output of the ResNet module is replaced with adifferentiable function with a bounded gradient. This configuration preventsthe network from facing the vanishing or exploding gradient problem. We showthat utilizing such non-linear units will result in shallower networks withbetter performance. Further, by using a weighted loss function which gives ahigher priority to less represented categories, we can achieve an overallbetter recognition rate. The results of our experiments show that BReG-Netsoutperform state-of-the-art methods on three publicly available facialdatabases in the wild, on both the categorical and dimensional models ofaffect. ### Response: Facial Expression Recognition : RESEARCH_PROBLEM; ResNet : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Automated medical image segmentation is a priority research area for computational methods. In particular, detection of cancerous tumors represents a current challenge in this area with potential for real-world impact. This paper describes a method developed in response to the 2019 Kidney Tumor Segmentation Challenge (KiTS19). Axial computed tomography (CT) scans from 210 kidney cancer patients were used to develop and evaluate this automatic segmentation method based on a logical ensemble of fully-convolutional network (FCN ) architectures, followed by volumetric validation. Data was pre-processed using conventional computer vision techniques, thresholding, histogram equalization, morphological operations, centering, zooming and resizing. Three binary FCN segmentation models were trained to classify kidney and tumor (2), and only tumor (1), respectively. Model output images were stacked and volumetrically validated to produce the final segmentation for each patient scan. The average F1 score from kidney and tumor pixel classifications was calculated as 0.6758 using preprocessed images and annotations; although restoring to the original image format reduced this score. It remains to be seen how this compares to other solutions.",Tumor Segmentation : RESEARCH_PROBLEM; (FCN : METHOD; FCN : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Automated medical image segmentation is a priority research area for computational methods. In particular, detection of cancerous tumors represents a current challenge in this area with potential for real-world impact. This paper describes a method developed in response to the 2019 Kidney Tumor Segmentation Challenge (KiTS19). Axial computed tomography (CT) scans from 210 kidney cancer patients were used to develop and evaluate this automatic segmentation method based on a logical ensemble of fully-convolutional network (FCN ) architectures, followed by volumetric validation. Data was pre-processed using conventional computer vision techniques, thresholding, histogram equalization, morphological operations, centering, zooming and resizing. Three binary FCN segmentation models were trained to classify kidney and tumor (2), and only tumor (1), respectively. Model output images were stacked and volumetrically validated to produce the final segmentation for each patient scan. The average F1 score from kidney and tumor pixel classifications was calculated as 0.6758 using preprocessed images and annotations; although restoring to the original image format reduced this score. It remains to be seen how this compares to other solutions. ### Response: Tumor Segmentation : RESEARCH_PROBLEM; (FCN : METHOD; FCN : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Multi-Task Learning (MTL) networks have emerged as a promising method for transferring learned knowledge across different tasks. However, MTL must deal with challenges such as: overfitting to low resource tasks, catastrophic forgetting, and negative task transfer, or learning interference. Often, in Natural Language Processing (NLP), a separate model per task is needed to obtain the best performance. However, many fine-tuning approaches are both parameter inefficient, i.e., potentially involving one new model per task, and highly susceptible to losing knowledge acquired during pretraining. We propose a novel Transformer architecture consisting of a new conditional attention mechanism as well as a set of task-conditioned modules that facilitate weight sharing. Through this construction, we achieve more efficient parameter sharing and mitigate forgetting by keeping half of the weights of a pretrained model fixed. We also use a new multi-task data sampling strategy to mitigate the negative effects of data imbalance across tasks. Using this approach, we are able to surpass single task fine-tuning methods while being parameter and data efficient (using around 66% of the data for weight updates). Compared to other BERT Large methods on GLUE, our 8-task model surpasses other Adapter methods by 2.8% and our 24-task model outperforms by 0.7-1.0% models that use MTL and single task fine-tuning. We show that a larger variant of our single multi-task model approach performs competitively across 26 NLP tasks and yields state-of-the-art results on a number of test and development sets. Our code is publicly available at https://github.com/CAMTL/CA-MTL.",Multi-Task Learning : RESEARCH_PROBLEM; Transformer : METHOD; BERT : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Multi-Task Learning (MTL) networks have emerged as a promising method for transferring learned knowledge across different tasks. However, MTL must deal with challenges such as: overfitting to low resource tasks, catastrophic forgetting, and negative task transfer, or learning interference. Often, in Natural Language Processing (NLP), a separate model per task is needed to obtain the best performance. However, many fine-tuning approaches are both parameter inefficient, i.e., potentially involving one new model per task, and highly susceptible to losing knowledge acquired during pretraining. We propose a novel Transformer architecture consisting of a new conditional attention mechanism as well as a set of task-conditioned modules that facilitate weight sharing. Through this construction, we achieve more efficient parameter sharing and mitigate forgetting by keeping half of the weights of a pretrained model fixed. We also use a new multi-task data sampling strategy to mitigate the negative effects of data imbalance across tasks. Using this approach, we are able to surpass single task fine-tuning methods while being parameter and data efficient (using around 66% of the data for weight updates). Compared to other BERT Large methods on GLUE, our 8-task model surpasses other Adapter methods by 2.8% and our 24-task model outperforms by 0.7-1.0% models that use MTL and single task fine-tuning. We show that a larger variant of our single multi-task model approach performs competitively across 26 NLP tasks and yields state-of-the-art results on a number of test and development sets. Our code is publicly available at https://github.com/CAMTL/CA-MTL. ### Response: Multi-Task Learning : RESEARCH_PROBLEM; Transformer : METHOD; BERT : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","The emergence and rapid progress of the Internet have brought ever-increasing impact on financial domain. How to rapidly and accurately mine the key information from the massive negative financial texts has become one of the key issues for investors and decision makers. Aiming at the issue, we propose a sentiment analysis and key entity detection approach based on BERT , which is applied in online financial text mining and public opinion analysis in social media. By using pre-train model, we first study sentiment analysis, and then we consider key entity detection as a sentence matching or Machine Reading Comprehension (MRC) task in different granularity. Among them, we mainly focus on negative sentimental information. We detect the specific entity by using our approach, which is different from traditional Named Entity Recognition (NER). In addition, we also use ensemble learning to improve the performance of proposed approach. Experimental results show that the performance of our approach is generally higher than SVM, LR, NBM, and BERT for two financial sentiment analysis and key entity detection datasets.",BERT : METHOD; Machine Reading Comprehension : RESEARCH_PROBLEM; Named Entity Recognition : RESEARCH_PROBLEM; BERT : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: The emergence and rapid progress of the Internet have brought ever-increasing impact on financial domain. How to rapidly and accurately mine the key information from the massive negative financial texts has become one of the key issues for investors and decision makers. Aiming at the issue, we propose a sentiment analysis and key entity detection approach based on BERT , which is applied in online financial text mining and public opinion analysis in social media. By using pre-train model, we first study sentiment analysis, and then we consider key entity detection as a sentence matching or Machine Reading Comprehension (MRC) task in different granularity. Among them, we mainly focus on negative sentimental information. We detect the specific entity by using our approach, which is different from traditional Named Entity Recognition (NER). In addition, we also use ensemble learning to improve the performance of proposed approach. Experimental results show that the performance of our approach is generally higher than SVM, LR, NBM, and BERT for two financial sentiment analysis and key entity detection datasets. ### Response: BERT : METHOD; Machine Reading Comprehension : RESEARCH_PROBLEM; Named Entity Recognition : RESEARCH_PROBLEM; BERT : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","We propose a novel semantic tagging task, sem-tagging, tailored for thepurpose of multilingual semantic parsing, and present the first tagger usingdeep residual networks (ResNet s). Our tagger uses both word and characterrepresentations and includes a novel residual bypass architecture. We evaluatethe tagset both intrinsically on the new task of semantic tagging, as well ason Part-of-Speech (POS ) tagging. Our system, consisting of a ResNet and anauxiliary loss function predicting our semantic tags, significantly outperformsprior results on English Universal Dependencies POS tagging (95.71% accuracy onUD v1.2 and 95.67% accuracy on UD v1.3).",(ResNet : METHOD; (POS : RESEARCH_PROBLEM; ResNet : METHOD; POS : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: We propose a novel semantic tagging task, sem-tagging, tailored for thepurpose of multilingual semantic parsing, and present the first tagger usingdeep residual networks (ResNet s). Our tagger uses both word and characterrepresentations and includes a novel residual bypass architecture. We evaluatethe tagset both intrinsically on the new task of semantic tagging, as well ason Part-of-Speech (POS ) tagging. Our system, consisting of a ResNet and anauxiliary loss function predicting our semantic tags, significantly outperformsprior results on English Universal Dependencies POS tagging (95.71% accuracy onUD v1.2 and 95.67% accuracy on UD v1.3). ### Response: (ResNet : METHOD; (POS : RESEARCH_PROBLEM; ResNet : METHOD; POS : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Traditional model training for sentence generation employs cross-entropy loss as the loss function. While cross-entropy loss has convenient properties for supervised learning, it is unable to evaluate sentences as a whole, and lacks flexibility. We present the approach of training the generation model using the estimated semantic similarity between the output and reference sentences to alleviate the problems faced by the training with cross-entropy loss. We use the BERT-based scorer fine-tuned to the Semantic Textual Similarity (STS) task for semantic similarity estimation, and train the model with the estimated scores through reinforcement learning (RL). Our experiments show that reinforcement learning with semantic similarity reward improves the BLEU scores from the baseline LSTM NMT model.",Semantic Textual Similarity : RESEARCH_PROBLEM; LSTM : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Traditional model training for sentence generation employs cross-entropy loss as the loss function. While cross-entropy loss has convenient properties for supervised learning, it is unable to evaluate sentences as a whole, and lacks flexibility. We present the approach of training the generation model using the estimated semantic similarity between the output and reference sentences to alleviate the problems faced by the training with cross-entropy loss. We use the BERT-based scorer fine-tuned to the Semantic Textual Similarity (STS) task for semantic similarity estimation, and train the model with the estimated scores through reinforcement learning (RL). Our experiments show that reinforcement learning with semantic similarity reward improves the BLEU scores from the baseline LSTM NMT model. ### Response: Semantic Textual Similarity : RESEARCH_PROBLEM; LSTM : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Deep learning methods, in particular trained Convolutional Neural Networks(CNNs) have recently been shown to produce compelling state-of-the-art resultsfor single image Super-Resolution (SR). Invariably, a CNN is learned to map thelow resolution (LR) image to its corresponding high resolution (HR) version inthe spatial domain. Aiming for faster inference and more efficient solutionsthan solving the SR problem in the spatial domain, we propose a novel networkstructure for learning the SR mapping function in an image transform domain,specifically the Discrete Cosine Transform (DCT). As a first contribution, weshow that DCT can be integrated into the network structure as a ConvolutionalDCT (CDCT) layer. We further extend the network to allow the CDCT layer tobecome trainable (i.e. optimizable). Because this layer represents an imagetransform, we enforce pairwise orthogonality constraints on the individualbasis functions/filters. This Orthogonally Regularized Deep SR network (ORDSR)simplifies the SR task by taking advantage of image transform domain whileadapting the design of transform basis to the training image set.",Super-Resolution : RESEARCH_PROBLEM; Discrete Cosine Transform : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Deep learning methods, in particular trained Convolutional Neural Networks(CNNs) have recently been shown to produce compelling state-of-the-art resultsfor single image Super-Resolution (SR). Invariably, a CNN is learned to map thelow resolution (LR) image to its corresponding high resolution (HR) version inthe spatial domain. Aiming for faster inference and more efficient solutionsthan solving the SR problem in the spatial domain, we propose a novel networkstructure for learning the SR mapping function in an image transform domain,specifically the Discrete Cosine Transform (DCT). As a first contribution, weshow that DCT can be integrated into the network structure as a ConvolutionalDCT (CDCT) layer. We further extend the network to allow the CDCT layer tobecome trainable (i.e. optimizable). Because this layer represents an imagetransform, we enforce pairwise orthogonality constraints on the individualbasis functions/filters. This Orthogonally Regularized Deep SR network (ORDSR)simplifies the SR task by taking advantage of image transform domain whileadapting the design of transform basis to the training image set. ### Response: Super-Resolution : RESEARCH_PROBLEM; Discrete Cosine Transform : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","An Intrusion Detection System (IDS) is a key cybersecurity tool for network administrators as it identifies malicious traffic and cyberattacks. With the recent successes of machine learning techniques such as deep learning, more and more IDS are now using machine learning algorithms to detect attacks faster. However, these systems lack robustness when facing previously unseen types of attacks. With the increasing number of new attacks, especially against Internet of Things devices, having a robust IDS able to spot unusual and new attacks becomes necessary. This work explores the possibility of leveraging generative adversarial models to improve the robustness of machine learning based IDS. More specifically, we propose a new method named SIGMA, that leverages adversarial examples to strengthen IDS against new types of attacks. Using Generative Adversarial Networks (GAN ) and metaheuristics, SIGMA %Our method consists in generates adversarial examples, iteratively, and uses it to retrain a machine learning-based IDS, until a convergence of the detection rate (i.e. until the detection system is not improving anymore). A round of improvement consists of a generative phase, in which we use GAN s and metaheuristics to generate instances ; an evaluation phase in which we calculate the detection rate of those newly generated attacks ; and a training phase, in which we train the IDS with those attacks. We have evaluated the SIGMA method for four standard machine learning classification algorithms acting as IDS, with a combination of GAN and a hybrid local-search and genetic algorithm, to generate new datasets of attacks. Our results show that SIGMA can successfully generate adversarial attacks against different machine learning based IDS. Also, using SIGMA, we can improve the performance of an IDS to up to 100\% after as little as two rounds of improvement.",Intrusion Detection : RESEARCH_PROBLEM; (GAN : METHOD; GAN : METHOD; GAN : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: An Intrusion Detection System (IDS) is a key cybersecurity tool for network administrators as it identifies malicious traffic and cyberattacks. With the recent successes of machine learning techniques such as deep learning, more and more IDS are now using machine learning algorithms to detect attacks faster. However, these systems lack robustness when facing previously unseen types of attacks. With the increasing number of new attacks, especially against Internet of Things devices, having a robust IDS able to spot unusual and new attacks becomes necessary. This work explores the possibility of leveraging generative adversarial models to improve the robustness of machine learning based IDS. More specifically, we propose a new method named SIGMA, that leverages adversarial examples to strengthen IDS against new types of attacks. Using Generative Adversarial Networks (GAN ) and metaheuristics, SIGMA %Our method consists in generates adversarial examples, iteratively, and uses it to retrain a machine learning-based IDS, until a convergence of the detection rate (i.e. until the detection system is not improving anymore). A round of improvement consists of a generative phase, in which we use GAN s and metaheuristics to generate instances ; an evaluation phase in which we calculate the detection rate of those newly generated attacks ; and a training phase, in which we train the IDS with those attacks. We have evaluated the SIGMA method for four standard machine learning classification algorithms acting as IDS, with a combination of GAN and a hybrid local-search and genetic algorithm, to generate new datasets of attacks. Our results show that SIGMA can successfully generate adversarial attacks against different machine learning based IDS. Also, using SIGMA, we can improve the performance of an IDS to up to 100\% after as little as two rounds of improvement. ### Response: Intrusion Detection : RESEARCH_PROBLEM; (GAN : METHOD; GAN : METHOD; GAN : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","The field of conversational agents is growing fast and there is an increasing need for algorithms that enhance natural interaction. In this work we show how we achieved state of the art results in the Keyword Spotting field by adapting and tweaking the Xception algorithm, which achieved outstanding results in several computer vision tasks. We obtained about 96\% accuracy when classifying audio clips belonging to 35 different categories, beating human annotation at the most complex tasks proposed.",Keyword Spotting : RESEARCH_PROBLEM; Xception : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: The field of conversational agents is growing fast and there is an increasing need for algorithms that enhance natural interaction. In this work we show how we achieved state of the art results in the Keyword Spotting field by adapting and tweaking the Xception algorithm, which achieved outstanding results in several computer vision tasks. We obtained about 96\% accuracy when classifying audio clips belonging to 35 different categories, beating human annotation at the most complex tasks proposed. ### Response: Keyword Spotting : RESEARCH_PROBLEM; Xception : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Text Simplification (TS ) aims to reduce the linguistic complexity of content to make it easier to understand. Research in TS has been of keen interest, especially as approaches to TS have shifted from manual, hand-crafted rules to automated simplification. This survey seeks to provide a comprehensive overview of TS , including a brief description of earlier approaches used, discussion of various aspects of simplification (lexical, semantic and syntactic), and latest techniques being utilized in the field. We note that the research in the field has clearly shifted towards utilizing deep learning techniques to perform TS , with a specific focus on developing solutions to combat the lack of data available for simplification. We also include a discussion of datasets and evaluations metrics commonly used, along with discussion of related fields within Natural Language Processing (NLP), like semantic similarity.",Text Simplification : RESEARCH_PROBLEM; (TS : METHOD; TS : METHOD; TS : METHOD; TS : METHOD; TS : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Text Simplification (TS ) aims to reduce the linguistic complexity of content to make it easier to understand. Research in TS has been of keen interest, especially as approaches to TS have shifted from manual, hand-crafted rules to automated simplification. This survey seeks to provide a comprehensive overview of TS , including a brief description of earlier approaches used, discussion of various aspects of simplification (lexical, semantic and syntactic), and latest techniques being utilized in the field. We note that the research in the field has clearly shifted towards utilizing deep learning techniques to perform TS , with a specific focus on developing solutions to combat the lack of data available for simplification. We also include a discussion of datasets and evaluations metrics commonly used, along with discussion of related fields within Natural Language Processing (NLP), like semantic similarity. ### Response: Text Simplification : RESEARCH_PROBLEM; (TS : METHOD; TS : METHOD; TS : METHOD; TS : METHOD; TS : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","The goal of Word Sense Disambiguation (WSD) is to identify the sense of a polysemous word in a specific context. Deep-learning techniques using BERT have achieved very promising results in the field and different methods have been proposed to integrate structured knowledge to enhance performance. At the same time, an increasing number of data augmentation techniques have been proven to be useful for NLP tasks. Building upon previous works leveraging BERT and WordNet knowledge, we explore different data augmentation techniques on context-gloss pairs to improve the performance of WSD. In our experiment, we show that both sentence-level and word-level augmentation methods are effective strategies for WSD. Also, we find out that performance can be improved by adding hypernyms' glosses obtained from a lexical knowledge base. We compare and analyze different context-gloss augmentation techniques, and the results show that applying back translation on gloss performs the best.",Word Sense Disambiguation : RESEARCH_PROBLEM; BERT : METHOD; BERT : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: The goal of Word Sense Disambiguation (WSD) is to identify the sense of a polysemous word in a specific context. Deep-learning techniques using BERT have achieved very promising results in the field and different methods have been proposed to integrate structured knowledge to enhance performance. At the same time, an increasing number of data augmentation techniques have been proven to be useful for NLP tasks. Building upon previous works leveraging BERT and WordNet knowledge, we explore different data augmentation techniques on context-gloss pairs to improve the performance of WSD. In our experiment, we show that both sentence-level and word-level augmentation methods are effective strategies for WSD. Also, we find out that performance can be improved by adding hypernyms' glosses obtained from a lexical knowledge base. We compare and analyze different context-gloss augmentation techniques, and the results show that applying back translation on gloss performs the best. ### Response: Word Sense Disambiguation : RESEARCH_PROBLEM; BERT : METHOD; BERT : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Recent advancements in Neural Machine Translation (NMT) models have proved to produce a state of the art results on machine translation for low resource Indian languages. This paper describes the neural machine translation systems for the English-Hindi language presented in AdapMT Shared Task ICON 2020. The shared task aims to build a translation system for Indian languages in specific domains like Artificial Intelligence (AI) and Chemistry using a small in-domain parallel corpus. We evaluated the effectiveness of two popular NMT models i.e, LSTM, and Transformer architectures for the English-Hindi machine translation task based on BLEU scores. We train these models primarily using the out of domain data and employ simple domain adaptation techniques based on the characteristics of the in-domain dataset. The fine-tuning and mixed-domain data approaches are used for domain adaptation. Our team was ranked first in the chemistry and general domain En-Hi translation task and second in the AI domain En-Hi translation task.",Machine Translation : RESEARCH_PROBLEM; Transformer : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Recent advancements in Neural Machine Translation (NMT) models have proved to produce a state of the art results on machine translation for low resource Indian languages. This paper describes the neural machine translation systems for the English-Hindi language presented in AdapMT Shared Task ICON 2020. The shared task aims to build a translation system for Indian languages in specific domains like Artificial Intelligence (AI) and Chemistry using a small in-domain parallel corpus. We evaluated the effectiveness of two popular NMT models i.e, LSTM, and Transformer architectures for the English-Hindi machine translation task based on BLEU scores. We train these models primarily using the out of domain data and employ simple domain adaptation techniques based on the characteristics of the in-domain dataset. The fine-tuning and mixed-domain data approaches are used for domain adaptation. Our team was ranked first in the chemistry and general domain En-Hi translation task and second in the AI domain En-Hi translation task. ### Response: Machine Translation : RESEARCH_PROBLEM; Transformer : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","The use of code-switched languages (\textit{e.g.}, Hinglish, which is derived by the blending of Hindi with the English language) is getting much popular on Twitter due to their ease of communication in native languages. However, spelling variations and absence of grammar rules introduce ambiguity and make it difficult to understand the text automatically. This paper presents the Multi-Input Multi-Channel Transfer Learning based model (MIMCT) to detect offensive (hate speech or abusive) Hinglish tweets from the proposed Hinglish Offensive Tweet (HOT) dataset using transfer learning coupled with multiple feature inputs. Specifically, it takes multiple primary word embedding along with secondary extracted features as inputs to train a multi-channel CNN-LSTM architecture that has been pre-trained on English tweets through transfer learning. The proposed MIMCT model outperforms the baseline supervised classification models, transfer learning based CNN and LSTM models to establish itself as the state of the art in the unexplored domain of Hinglish offensive text classification.",Transfer Learning : RESEARCH_PROBLEM; CNN-LSTM : METHOD; LSTM : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: The use of code-switched languages (\textit{e.g.}, Hinglish, which is derived by the blending of Hindi with the English language) is getting much popular on Twitter due to their ease of communication in native languages. However, spelling variations and absence of grammar rules introduce ambiguity and make it difficult to understand the text automatically. This paper presents the Multi-Input Multi-Channel Transfer Learning based model (MIMCT) to detect offensive (hate speech or abusive) Hinglish tweets from the proposed Hinglish Offensive Tweet (HOT) dataset using transfer learning coupled with multiple feature inputs. Specifically, it takes multiple primary word embedding along with secondary extracted features as inputs to train a multi-channel CNN-LSTM architecture that has been pre-trained on English tweets through transfer learning. The proposed MIMCT model outperforms the baseline supervised classification models, transfer learning based CNN and LSTM models to establish itself as the state of the art in the unexplored domain of Hinglish offensive text classification. ### Response: Transfer Learning : RESEARCH_PROBLEM; CNN-LSTM : METHOD; LSTM : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","This report describes the systems submitted to the first and second tracks of the VoxCeleb Speaker Recognition Challenge (VoxSRC) 2020, which ranked second in both tracks. Three key points of the system pipeline are explored: (1) investigating multiple CNN architectures including ResNet, Res2Net and dual path network (DPN) to extract the x-vectors, (2) using a composite angular margin softmax loss to train the speaker models, and (3) applying score normalization and system fusion to boost the performance. Measured on the VoxSRC-20 Eval set, the best submitted systems achieve an EER of $3.808\%$ and a MinDCF of $0.1958$ in the close-condition track 1, and an EER of $3.798\%$ and a MinDCF of $0.1942$ in the open-condition track 2, respectively.",Speaker Recognition : RESEARCH_PROBLEM; Res2Net : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: This report describes the systems submitted to the first and second tracks of the VoxCeleb Speaker Recognition Challenge (VoxSRC) 2020, which ranked second in both tracks. Three key points of the system pipeline are explored: (1) investigating multiple CNN architectures including ResNet, Res2Net and dual path network (DPN) to extract the x-vectors, (2) using a composite angular margin softmax loss to train the speaker models, and (3) applying score normalization and system fusion to boost the performance. Measured on the VoxSRC-20 Eval set, the best submitted systems achieve an EER of $3.808\%$ and a MinDCF of $0.1958$ in the close-condition track 1, and an EER of $3.798\%$ and a MinDCF of $0.1942$ in the open-condition track 2, respectively. ### Response: Speaker Recognition : RESEARCH_PROBLEM; Res2Net : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Most existing methods for biomedical entity recognition task rely on explicitfeature engineering where many features either are specific to a particulartask or depends on output of other existing NLP tools. Neural architectureshave been shown across various domains that efforts for explicit feature designcan be reduced. In this work we propose an unified framework usingbi-directional long short term memory network (BLSTM) for named entityrecognition (NER ) tasks in biomedical and clinical domains. Three importantcharacteristics of the framework are as follows - (1) model learns contextualas well as morphological features using two different BLSTM in hierarchy, (2)model uses first order linear conditional random field (CRF ) in its outputlayer in cascade of BLSTM to infer label or tag sequence, (3) model does notuse any domain specific features or dictionary, i.e., in another words, sameset of features are used in the three NER tasks, namely, disease namerecognition (Disease NER ), drug name recognition (Drug NER ) and clinical entityrecognition (Clinical NER ). We compare performance of the proposed model withexisting state-of-the-art models on the standard benchmark datasets of thethree tasks. We show empirically that the proposed framework outperforms allexisting models. Further our analysis of CRF layer and word-embedding obtainedusing character based embedding show their importance.",(NER : RESEARCH_PROBLEM; (CRF : METHOD; NER : RESEARCH_PROBLEM; NER : RESEARCH_PROBLEM; NER : RESEARCH_PROBLEM; NER : RESEARCH_PROBLEM; CRF : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Most existing methods for biomedical entity recognition task rely on explicitfeature engineering where many features either are specific to a particulartask or depends on output of other existing NLP tools. Neural architectureshave been shown across various domains that efforts for explicit feature designcan be reduced. In this work we propose an unified framework usingbi-directional long short term memory network (BLSTM) for named entityrecognition (NER ) tasks in biomedical and clinical domains. Three importantcharacteristics of the framework are as follows - (1) model learns contextualas well as morphological features using two different BLSTM in hierarchy, (2)model uses first order linear conditional random field (CRF ) in its outputlayer in cascade of BLSTM to infer label or tag sequence, (3) model does notuse any domain specific features or dictionary, i.e., in another words, sameset of features are used in the three NER tasks, namely, disease namerecognition (Disease NER ), drug name recognition (Drug NER ) and clinical entityrecognition (Clinical NER ). We compare performance of the proposed model withexisting state-of-the-art models on the standard benchmark datasets of thethree tasks. We show empirically that the proposed framework outperforms allexisting models. Further our analysis of CRF layer and word-embedding obtainedusing character based embedding show their importance. ### Response: (NER : RESEARCH_PROBLEM; (CRF : METHOD; NER : RESEARCH_PROBLEM; NER : RESEARCH_PROBLEM; NER : RESEARCH_PROBLEM; NER : RESEARCH_PROBLEM; CRF : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Modeling sequential data has become more and more important in practice. Someapplications are autonomous driving, virtual sensors and weather forecasting.To model such systems so called recurrent models are used. In this article weintroduce two new Deep Recurrent Gaussian Process (DRGP) models based on theSparse Spectrum Gaussian Process (SSGP) and the improved variational versioncalled Variational Sparse Spectrum Gaussian Process (VSSGP). We follow therecurrent structure given by an existing DRGP based on a specific sparseNystr\""om approximation. Therefore, we also variationally integrate out theinput-space and hence can propagate uncertainty through the layers. We can showthat for the resulting lower bound an optimal variational distribution exists.Training is realized through optimizing the variational lower bound. UsingDistributed Variational Inference (DVI), we can reduce the computationalcomplexity. We improve over current state of the art methods in predictionaccuracy for experimental data-sets used for their evaluation and introduce anew data-set for engine control, named Emission. Furthermore, our method caneasily be adapted for unsupervised learning, e.g. the latent variable model andits deep version.",Gaussian Process : METHOD; Gaussian Process : METHOD; Gaussian Process : METHOD; Variational Inference : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Modeling sequential data has become more and more important in practice. Someapplications are autonomous driving, virtual sensors and weather forecasting.To model such systems so called recurrent models are used. In this article weintroduce two new Deep Recurrent Gaussian Process (DRGP) models based on theSparse Spectrum Gaussian Process (SSGP) and the improved variational versioncalled Variational Sparse Spectrum Gaussian Process (VSSGP). We follow therecurrent structure given by an existing DRGP based on a specific sparseNystr\""om approximation. Therefore, we also variationally integrate out theinput-space and hence can propagate uncertainty through the layers. We can showthat for the resulting lower bound an optimal variational distribution exists.Training is realized through optimizing the variational lower bound. UsingDistributed Variational Inference (DVI), we can reduce the computationalcomplexity. We improve over current state of the art methods in predictionaccuracy for experimental data-sets used for their evaluation and introduce anew data-set for engine control, named Emission. Furthermore, our method caneasily be adapted for unsupervised learning, e.g. the latent variable model andits deep version. ### Response: Gaussian Process : METHOD; Gaussian Process : METHOD; Gaussian Process : METHOD; Variational Inference : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Many mission-critical systems are based on GPU for inference. It requires not only high recognition accuracy but also low latency in responding time. Although many studies are devoted to optimizing the structure of deep models for efficient inference, most of them do not leverage the architecture of \textbf{modern GPU} for fast inference, leading to suboptimal performance. To address this issue, we propose a general principle for designing GPU-efficient networks based on extensive empirical studies. This design principle enables us to search for GPU-efficient network structures effectively by a simple and lightweight method as opposed to most Neural Architecture Search (NAS) methods that are complicated and computationally expensive. Based on the proposed framework, we design a family of GPU-Efficient Networks, or GENet s in short. We did extensive evaluations on multiple GPU platforms and inference engines. While achieving $\geq 81.3\%$ top-1 accuracy on ImageNet, GENet is up to $6.4$ times faster than EfficienNet on GPU. It also outperforms most state-of-the-art models that are more efficient than EfficientNet in high precision regimes. Our source code and pre-trained models are available from \url{https://github.com/idstcv/GPU-Efficient-Networks}.",Neural Architecture Search : RESEARCH_PROBLEM; GENet : METHOD; GENet : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Many mission-critical systems are based on GPU for inference. It requires not only high recognition accuracy but also low latency in responding time. Although many studies are devoted to optimizing the structure of deep models for efficient inference, most of them do not leverage the architecture of \textbf{modern GPU} for fast inference, leading to suboptimal performance. To address this issue, we propose a general principle for designing GPU-efficient networks based on extensive empirical studies. This design principle enables us to search for GPU-efficient network structures effectively by a simple and lightweight method as opposed to most Neural Architecture Search (NAS) methods that are complicated and computationally expensive. Based on the proposed framework, we design a family of GPU-Efficient Networks, or GENet s in short. We did extensive evaluations on multiple GPU platforms and inference engines. While achieving $\geq 81.3\%$ top-1 accuracy on ImageNet, GENet is up to $6.4$ times faster than EfficienNet on GPU. It also outperforms most state-of-the-art models that are more efficient than EfficientNet in high precision regimes. Our source code and pre-trained models are available from \url{https://github.com/idstcv/GPU-Efficient-Networks}. ### Response: Neural Architecture Search : RESEARCH_PROBLEM; GENet : METHOD; GENet : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Designing effective architectures is one of the key factors behind the success of deep neural networks. Existing deep architectures are either manually designed or automatically searched by some Neural Architecture Search (NAS) methods. However, even a well-searched architecture may still contain many non-significant or redundant modules or operations (e.g., convolution or pooling), which may not only incur substantial memory consumption and computation cost but also deteriorate the performance. Thus, it is necessary to optimize the operations inside an architecture to improve the performance without introducing extra computation cost. Unfortunately, such a constrained optimization problem is NP-hard. To make the problem feasible, we cast the optimization problem into a Markov decision process (MDP) and seek to learn a Neural Architecture Transformer (NAT) to replace the redundant operations with the more computationally efficient ones (e.g., skip connection or directly removing the connection). Based on MDP, we learn NAT by exploiting reinforcement learning to obtain the optimization policies w.r.t. different architectures. To verify the effectiveness of the proposed strategies, we apply NAT on both hand-crafted architectures and NAS based architectures. Extensive experiments on two benchmark datasets, i.e., CIFAR-10 and ImageNet, demonstrate that the transformed architecture by NAT significantly outperforms both its original form and those architectures optimized by existing methods.",Neural Architecture Search : RESEARCH_PROBLEM; Transformer : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Designing effective architectures is one of the key factors behind the success of deep neural networks. Existing deep architectures are either manually designed or automatically searched by some Neural Architecture Search (NAS) methods. However, even a well-searched architecture may still contain many non-significant or redundant modules or operations (e.g., convolution or pooling), which may not only incur substantial memory consumption and computation cost but also deteriorate the performance. Thus, it is necessary to optimize the operations inside an architecture to improve the performance without introducing extra computation cost. Unfortunately, such a constrained optimization problem is NP-hard. To make the problem feasible, we cast the optimization problem into a Markov decision process (MDP) and seek to learn a Neural Architecture Transformer (NAT) to replace the redundant operations with the more computationally efficient ones (e.g., skip connection or directly removing the connection). Based on MDP, we learn NAT by exploiting reinforcement learning to obtain the optimization policies w.r.t. different architectures. To verify the effectiveness of the proposed strategies, we apply NAT on both hand-crafted architectures and NAS based architectures. Extensive experiments on two benchmark datasets, i.e., CIFAR-10 and ImageNet, demonstrate that the transformed architecture by NAT significantly outperforms both its original form and those architectures optimized by existing methods. ### Response: Neural Architecture Search : RESEARCH_PROBLEM; Transformer : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Smart systems for Universities powered by Artificial Intelligence have been massively developed to help humans in various tasks. The chatbot concept is not something new in today society which is developing with recent technology. College students or candidates of college students often need actual information like asking for something to customer service, especially during this pandemic, when it is difficult to have an immediate face-to-face meeting. Chatbot s are functionally helping in several things such as curriculum information, admission for new students, schedule info for any lecture courses, students grade information, and some adding features for Muslim worships schedule, also weather forecast information. This Chatbot is developed by Deep Learning models, which was adopted by an artificial intelligence model that replicates human intelligence with some specific training schemes. This kind of Deep Learning is based on RNN which has some specific memory savings scheme for the Deep Learning Model, specifically this chatbot using LSTM which already integrates by RASA framework. LSTM is also known as Long Short Term Memory which efficiently saves some required memory but will remove some memory that is not needed. This Chatbot uses the FB platform because of the FB users have already reached up to 60.8% of its entire population in Indonesia. Here's the chatbot only focuses on case studies at campus of the Magister Informatics FTI University of Islamic Indonesia. This research is a first stage development within fairly sufficient simulate data.",Chatbot : RESEARCH_PROBLEM; Chatbot : RESEARCH_PROBLEM; LSTM : METHOD; LSTM : METHOD; Chatbot : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Smart systems for Universities powered by Artificial Intelligence have been massively developed to help humans in various tasks. The chatbot concept is not something new in today society which is developing with recent technology. College students or candidates of college students often need actual information like asking for something to customer service, especially during this pandemic, when it is difficult to have an immediate face-to-face meeting. Chatbot s are functionally helping in several things such as curriculum information, admission for new students, schedule info for any lecture courses, students grade information, and some adding features for Muslim worships schedule, also weather forecast information. This Chatbot is developed by Deep Learning models, which was adopted by an artificial intelligence model that replicates human intelligence with some specific training schemes. This kind of Deep Learning is based on RNN which has some specific memory savings scheme for the Deep Learning Model, specifically this chatbot using LSTM which already integrates by RASA framework. LSTM is also known as Long Short Term Memory which efficiently saves some required memory but will remove some memory that is not needed. This Chatbot uses the FB platform because of the FB users have already reached up to 60.8% of its entire population in Indonesia. Here's the chatbot only focuses on case studies at campus of the Magister Informatics FTI University of Islamic Indonesia. This research is a first stage development within fairly sufficient simulate data. ### Response: Chatbot : RESEARCH_PROBLEM; Chatbot : RESEARCH_PROBLEM; LSTM : METHOD; LSTM : METHOD; Chatbot : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","In this paper we consider the problem of maximizing the Area under the ROC curve (AUC) which is a widely used performance metric in imbalanced classification and anomaly detection. Due to the pairwise nonlinearity of the objective function, classical SGD algorithms do not apply to the task of AUC maximization. We propose a novel stochastic proximal algorithm for AUC maximization which is scalable to large scale streaming data. Our algorithm can accommodate general penalty terms and is easy to implement with favorable $O(d)$ space and per-iteration time complexities. We establish a high-probability convergence rate $O(1/\sqrt{T})$ for the general convex setting, and improve it to a fast convergence rate $O(1/T)$ for the cases of strongly convex regularizers and no regularization term (without strong convexity). Our proof does not need the uniform boundedness assumption on the loss function or the iterates which is more fidelity to the practice. Finally, we perform extensive experiments over various benchmark data sets from real-world application domains which show the superior performance of our algorithm over the existing AUC maximization algorithms.",imbalanced classification : RESEARCH_PROBLEM; SGD : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: In this paper we consider the problem of maximizing the Area under the ROC curve (AUC) which is a widely used performance metric in imbalanced classification and anomaly detection. Due to the pairwise nonlinearity of the objective function, classical SGD algorithms do not apply to the task of AUC maximization. We propose a novel stochastic proximal algorithm for AUC maximization which is scalable to large scale streaming data. Our algorithm can accommodate general penalty terms and is easy to implement with favorable $O(d)$ space and per-iteration time complexities. We establish a high-probability convergence rate $O(1/\sqrt{T})$ for the general convex setting, and improve it to a fast convergence rate $O(1/T)$ for the cases of strongly convex regularizers and no regularization term (without strong convexity). Our proof does not need the uniform boundedness assumption on the loss function or the iterates which is more fidelity to the practice. Finally, we perform extensive experiments over various benchmark data sets from real-world application domains which show the superior performance of our algorithm over the existing AUC maximization algorithms. ### Response: imbalanced classification : RESEARCH_PROBLEM; SGD : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Signal alignment has become a popular problem in robotics due in part to itsfundamental role in action recognition. Currently, the most successfulalgorithms for signal alignment are Dynamic Time Warping (DTW ) and its variant'Fast' Dynamic Time Warping (FastDTW ). Here we introduce a new framework forsignal alignment, namely the Globally Optimal Reparameterization Algorithm(GORA). We review the algorithm's mathematical foundation and provide anumerical verification of its theoretical basis. We compare the performance ofGORA with that of the DTW and FastDTW algorithms, in terms of computationalefficiency and accuracy in matching signals. Our results show a significantimprovement in both speed and accuracy over the DTW and FastDTW algorithms andsuggest that GORA has the potential to provide a highly effective framework forsignal alignment and action recognition.",Dynamic Time Warping : RESEARCH_PROBLEM; (DTW : METHOD; Dynamic Time Warping : RESEARCH_PROBLEM; (FastDTW : METHOD; DTW : METHOD; FastDTW : METHOD; DTW : METHOD; FastDTW : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Signal alignment has become a popular problem in robotics due in part to itsfundamental role in action recognition. Currently, the most successfulalgorithms for signal alignment are Dynamic Time Warping (DTW ) and its variant'Fast' Dynamic Time Warping (FastDTW ). Here we introduce a new framework forsignal alignment, namely the Globally Optimal Reparameterization Algorithm(GORA). We review the algorithm's mathematical foundation and provide anumerical verification of its theoretical basis. We compare the performance ofGORA with that of the DTW and FastDTW algorithms, in terms of computationalefficiency and accuracy in matching signals. Our results show a significantimprovement in both speed and accuracy over the DTW and FastDTW algorithms andsuggest that GORA has the potential to provide a highly effective framework forsignal alignment and action recognition. ### Response: Dynamic Time Warping : RESEARCH_PROBLEM; (DTW : METHOD; Dynamic Time Warping : RESEARCH_PROBLEM; (FastDTW : METHOD; DTW : METHOD; FastDTW : METHOD; DTW : METHOD; FastDTW : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Named Entity Recognition (NER ) from social media posts is a challenging task. User generated content that forms the nature of social media, is noisy and contains grammatical and linguistic errors. This noisy content makes it much harder for tasks such as named entity recognition. We propose two novel deep learning approaches utilizing multimodal deep learning and Transformers. Both of our approaches use image features from short social media posts to provide better results on the NER task. On the first approach, we extract image features using InceptionV3 and use fusion to combine textual and image features. This presents more reliable name entity recognition when the images related to the entities are provided by the user. On the second approach, we use image features combined with text and feed it into a BERT like Transformer. The experimental results, namely, the precision, recall and F1 score metrics show the superiority of our work compared to other state-of-the-art NER solutions.",Named Entity Recognition : RESEARCH_PROBLEM; (NER : RESEARCH_PROBLEM; NER : RESEARCH_PROBLEM; BERT : METHOD; NER : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Named Entity Recognition (NER ) from social media posts is a challenging task. User generated content that forms the nature of social media, is noisy and contains grammatical and linguistic errors. This noisy content makes it much harder for tasks such as named entity recognition. We propose two novel deep learning approaches utilizing multimodal deep learning and Transformers. Both of our approaches use image features from short social media posts to provide better results on the NER task. On the first approach, we extract image features using InceptionV3 and use fusion to combine textual and image features. This presents more reliable name entity recognition when the images related to the entities are provided by the user. On the second approach, we use image features combined with text and feed it into a BERT like Transformer. The experimental results, namely, the precision, recall and F1 score metrics show the superiority of our work compared to other state-of-the-art NER solutions. ### Response: Named Entity Recognition : RESEARCH_PROBLEM; (NER : RESEARCH_PROBLEM; NER : RESEARCH_PROBLEM; BERT : METHOD; NER : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","An important research direction in machine learning has centered around developing meta-learning algorithms to tackle few-shot learning. An especially successful algorithm has been Model Agnostic Meta-Learning (MAML ), a method that consists of two optimization loops, with the outer loop finding a meta-initialization, from which the inner loop can efficiently learn new tasks. Despite MAML 's popularity, a fundamental open question remains -- is the effectiveness of MAML due to the meta-initialization being primed for rapid learning (large, efficient changes in the representations) or due to feature reuse, with the meta initialization already containing high quality features? We investigate this question, via ablation studies and analysis of the latent representations, finding that feature reuse is the dominant factor. This leads to the ANIL (Almost No Inner Loop) algorithm, a simplification of MAML where we remove the inner loop for all but the (task-specific) head of a MAML -trained network. ANIL matches MAML 's performance on benchmark few-shot image classification and RL and offers computational improvements over MAML . We further study the precise contributions of the head and body of the network, showing that performance on the test tasks is entirely determined by the quality of the learned features, and we can remove even the head of the network (the NIL algorithm). We conclude with a discussion of the rapid learning vs feature reuse question for meta-learning algorithms more broadly.",Meta-Learning : RESEARCH_PROBLEM; (MAML : METHOD; MAML : METHOD; MAML : METHOD; MAML : METHOD; MAML : METHOD; MAML : METHOD; MAML : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: An important research direction in machine learning has centered around developing meta-learning algorithms to tackle few-shot learning. An especially successful algorithm has been Model Agnostic Meta-Learning (MAML ), a method that consists of two optimization loops, with the outer loop finding a meta-initialization, from which the inner loop can efficiently learn new tasks. Despite MAML 's popularity, a fundamental open question remains -- is the effectiveness of MAML due to the meta-initialization being primed for rapid learning (large, efficient changes in the representations) or due to feature reuse, with the meta initialization already containing high quality features? We investigate this question, via ablation studies and analysis of the latent representations, finding that feature reuse is the dominant factor. This leads to the ANIL (Almost No Inner Loop) algorithm, a simplification of MAML where we remove the inner loop for all but the (task-specific) head of a MAML -trained network. ANIL matches MAML 's performance on benchmark few-shot image classification and RL and offers computational improvements over MAML . We further study the precise contributions of the head and body of the network, showing that performance on the test tasks is entirely determined by the quality of the learned features, and we can remove even the head of the network (the NIL algorithm). We conclude with a discussion of the rapid learning vs feature reuse question for meta-learning algorithms more broadly. ### Response: Meta-Learning : RESEARCH_PROBLEM; (MAML : METHOD; MAML : METHOD; MAML : METHOD; MAML : METHOD; MAML : METHOD; MAML : METHOD; MAML : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Most of the recently proposed neural models for named entity recognition have been purely data-driven, with a strong emphasis on getting rid of the efforts for collecting external resources or designing hand-crafted features. This could increase the chance of overfitting since the models cannot access any supervision signal beyond the small amount of annotated data, limiting their power to generalize beyond the annotated entities. In this work, we show that properly utilizing external gazetteers could benefit segmental neural NER models. We add a simple module on the recently proposed hybrid semi-Markov CRF architecture and observe some promising results.",NER : RESEARCH_PROBLEM; CRF : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Most of the recently proposed neural models for named entity recognition have been purely data-driven, with a strong emphasis on getting rid of the efforts for collecting external resources or designing hand-crafted features. This could increase the chance of overfitting since the models cannot access any supervision signal beyond the small amount of annotated data, limiting their power to generalize beyond the annotated entities. In this work, we show that properly utilizing external gazetteers could benefit segmental neural NER models. We add a simple module on the recently proposed hybrid semi-Markov CRF architecture and observe some promising results. ### Response: NER : RESEARCH_PROBLEM; CRF : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Recent work has shown the efficiency of deep learning models such as Fully Convolutional Networks (FCN) or Recurrent Neural Networks (RNN) to deal with Time Series Regression (TSR) problems. These models sometimes need a lot of data to be able to generalize, yet the time series are sometimes not long enough to be able to learn patterns. Therefore, it is important to make use of information across time series to improve learning. In this paper, we will explore the idea of using meta-learning for quickly adapting model parameters to new short-history time series by modifying the original idea of Model Agnostic Meta-Learning (MAML ) \cite{finn2017model}. Moreover, based on prior work on multimodal MAML \cite{vuorio2019multimodal}, we propose a method for conditioning parameters of the model through an auxiliary network that encodes global information of the time series to extract meta-features. Finally, we apply the data to time series of different domains, such as pollution measurements, heart-rate sensors, and electrical battery data. We show empirically that our proposed meta-learning method learns TSR with few data fast and outperforms the baselines in 9 of 12 experiments.",Time Series Regression : RESEARCH_PROBLEM; Meta-Learning : RESEARCH_PROBLEM; (MAML : METHOD; MAML : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Recent work has shown the efficiency of deep learning models such as Fully Convolutional Networks (FCN) or Recurrent Neural Networks (RNN) to deal with Time Series Regression (TSR) problems. These models sometimes need a lot of data to be able to generalize, yet the time series are sometimes not long enough to be able to learn patterns. Therefore, it is important to make use of information across time series to improve learning. In this paper, we will explore the idea of using meta-learning for quickly adapting model parameters to new short-history time series by modifying the original idea of Model Agnostic Meta-Learning (MAML ) \cite{finn2017model}. Moreover, based on prior work on multimodal MAML \cite{vuorio2019multimodal}, we propose a method for conditioning parameters of the model through an auxiliary network that encodes global information of the time series to extract meta-features. Finally, we apply the data to time series of different domains, such as pollution measurements, heart-rate sensors, and electrical battery data. We show empirically that our proposed meta-learning method learns TSR with few data fast and outperforms the baselines in 9 of 12 experiments. ### Response: Time Series Regression : RESEARCH_PROBLEM; Meta-Learning : RESEARCH_PROBLEM; (MAML : METHOD; MAML : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Named Entity Recognition (NER ) is a fundamental Natural Language Processing (NLP) task to extract entities from unstructured data. The previous methods for NER were based on machine learning or deep learning. Recently, pre-training models have significantly improved performance on multiple NLP tasks. In this paper, firstly, we introduce the architecture and pre-training tasks of four common pre-training models: BERT, ERNIE, ERNIE2.0-tiny, and RoBERTa . Then, we apply these pre-training models to a NER task by fine-tuning, and compare the effects of the different model architecture and pre-training tasks on the NER task. The experiment results showed that RoBERTa achieved state-of-the-art results on the MSRA-2006 dataset.",Named Entity Recognition : RESEARCH_PROBLEM; (NER : RESEARCH_PROBLEM; NER : RESEARCH_PROBLEM; RoBERTa : METHOD; NER : RESEARCH_PROBLEM; NER : RESEARCH_PROBLEM; RoBERTa : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Named Entity Recognition (NER ) is a fundamental Natural Language Processing (NLP) task to extract entities from unstructured data. The previous methods for NER were based on machine learning or deep learning. Recently, pre-training models have significantly improved performance on multiple NLP tasks. In this paper, firstly, we introduce the architecture and pre-training tasks of four common pre-training models: BERT, ERNIE, ERNIE2.0-tiny, and RoBERTa . Then, we apply these pre-training models to a NER task by fine-tuning, and compare the effects of the different model architecture and pre-training tasks on the NER task. The experiment results showed that RoBERTa achieved state-of-the-art results on the MSRA-2006 dataset. ### Response: Named Entity Recognition : RESEARCH_PROBLEM; (NER : RESEARCH_PROBLEM; NER : RESEARCH_PROBLEM; RoBERTa : METHOD; NER : RESEARCH_PROBLEM; NER : RESEARCH_PROBLEM; RoBERTa : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Neural Machine Translation (NMT) in low-resource settings and ofmorphologically rich languages is made difficult in part by data sparsity ofvocabulary words. Several methods have been used to help reduce this sparsity,notably Byte-Pair Encoding (BPE ) and a character-based CNN layer (charCNN).However, the charCNN has largely been neglected, possibly because it has onlybeen compared to BPE rather than combined with it. We argue for areconsideration of the charCNN, based on cross-lingual improvements onlow-resource data. We translate from 8 languages into English, using amulti-way parallel collection of TED transcripts. We find that in most cases,using both BPE and a charCNN performs best, while in Hebrew, using a charCNNover words is best.",Machine Translation : RESEARCH_PROBLEM; (BPE : METHOD; BPE : METHOD; BPE : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Neural Machine Translation (NMT) in low-resource settings and ofmorphologically rich languages is made difficult in part by data sparsity ofvocabulary words. Several methods have been used to help reduce this sparsity,notably Byte-Pair Encoding (BPE ) and a character-based CNN layer (charCNN).However, the charCNN has largely been neglected, possibly because it has onlybeen compared to BPE rather than combined with it. We argue for areconsideration of the charCNN, based on cross-lingual improvements onlow-resource data. We translate from 8 languages into English, using amulti-way parallel collection of TED transcripts. We find that in most cases,using both BPE and a charCNN performs best, while in Hebrew, using a charCNNover words is best. ### Response: Machine Translation : RESEARCH_PROBLEM; (BPE : METHOD; BPE : METHOD; BPE : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Reinforcement Learning (RL) is an area of machine learning concerned with enabling an agent to navigate an environment with uncertainty in order to maximize some notion of cumulative long-term reward. In this paper, we implement and analyze two different RL techniques, Sarsa and Deep QLearning, on OpenAI Gym's LunarLander-v2 environment. We then introduce additional uncertainty to the original problem to test the robustness of the mentioned techniques. With our best models, we are able to achieve average rewards of 170+ with the Sarsa agent and 200+ with the Deep Q-Learning agent on the original problem. We also show that these techniques are able to overcome the additional uncertainities and achieve positive average rewards of 100+ with both agents. We then perform a comparative analysis of the two techniques to conclude which agent peforms better.",Sarsa : METHOD; Sarsa : METHOD; Q-Learning : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Reinforcement Learning (RL) is an area of machine learning concerned with enabling an agent to navigate an environment with uncertainty in order to maximize some notion of cumulative long-term reward. In this paper, we implement and analyze two different RL techniques, Sarsa and Deep QLearning, on OpenAI Gym's LunarLander-v2 environment. We then introduce additional uncertainty to the original problem to test the robustness of the mentioned techniques. With our best models, we are able to achieve average rewards of 170+ with the Sarsa agent and 200+ with the Deep Q-Learning agent on the original problem. We also show that these techniques are able to overcome the additional uncertainities and achieve positive average rewards of 100+ with both agents. We then perform a comparative analysis of the two techniques to conclude which agent peforms better. ### Response: Sarsa : METHOD; Sarsa : METHOD; Q-Learning : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Understanding the dynamic behavior of tires and their interactions with road plays an important role in designing integrated vehicle control strategies. Accordingly, having access to reliable information about the tire-road interactions through tire embedded sensors is very demanding for developing enhanced vehicle control systems. Thus, the main objectives of the present research work are i. to analyze data from an experimental accelerometer-based intelligent tire acquired over a wide range of maneuvers, with different vertical loads, velocities, and high slip angles; and ii. to develop a lateral force predictor based on a machine learning tool, more specifically the Gaussian Process Regression (GPR ) technique. It is delineated that the proposed intelligent tire system can provide reliable information about the tire-road interactions even in the case of high slip angles. Besides, the lateral forces model based on GPR can predict forces with acceptable accuracy and provide level of uncertainties that can be very useful for designing vehicle control strategies.",Gaussian Process : METHOD; (GPR : RESEARCH_PROBLEM; GPR : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Understanding the dynamic behavior of tires and their interactions with road plays an important role in designing integrated vehicle control strategies. Accordingly, having access to reliable information about the tire-road interactions through tire embedded sensors is very demanding for developing enhanced vehicle control systems. Thus, the main objectives of the present research work are i. to analyze data from an experimental accelerometer-based intelligent tire acquired over a wide range of maneuvers, with different vertical loads, velocities, and high slip angles; and ii. to develop a lateral force predictor based on a machine learning tool, more specifically the Gaussian Process Regression (GPR ) technique. It is delineated that the proposed intelligent tire system can provide reliable information about the tire-road interactions even in the case of high slip angles. Besides, the lateral forces model based on GPR can predict forces with acceptable accuracy and provide level of uncertainties that can be very useful for designing vehicle control strategies. ### Response: Gaussian Process : METHOD; (GPR : RESEARCH_PROBLEM; GPR : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Neural Machine Translation (NMT) methodologies have burgeoned from using simple feed-forward architectures to the state of the art; viz. BERT model. The use cases of NMT models have been broadened from just language translations to conversational agents (chatbots), abstractive text summarization, image captioning, etc. which have proved to be a gem in their respective applications. This paper aims to study the major trends in Neural Machine Translation , the state of the art models in the domain and a high level comparison between them.",Machine Translation : RESEARCH_PROBLEM; BERT : METHOD; Machine Translation : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Neural Machine Translation (NMT) methodologies have burgeoned from using simple feed-forward architectures to the state of the art; viz. BERT model. The use cases of NMT models have been broadened from just language translations to conversational agents (chatbots), abstractive text summarization, image captioning, etc. which have proved to be a gem in their respective applications. This paper aims to study the major trends in Neural Machine Translation , the state of the art models in the domain and a high level comparison between them. ### Response: Machine Translation : RESEARCH_PROBLEM; BERT : METHOD; Machine Translation : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","As an emerging topic in face recognition, designing margin-based loss functions can increase the feature margin between different classes for enhanced discriminability. More recently, the idea of mining-based strategies is adopted to emphasize the misclassified samples, achieving promising results. However, during the entire training process, the prior methods either do not explicitly emphasize the sample based on its importance that renders the hard samples not fully exploited; or explicitly emphasize the effects of semi-hard/hard samples even at the early training stage that may lead to convergence issue. In this work, we propose a novel Adaptive Curriculum Learning loss (CurricularFace ) that embeds the idea of curriculum learning into the loss function to achieve a novel training strategy for deep face recognition, which mainly addresses easy samples in the early training stage and hard ones in the later stage. Specifically, our CurricularFace adaptively adjusts the relative importance of easy and hard samples during different training stages. In each stage, different samples are assigned with different importance according to their corresponding difficultness. Extensive experimental results on popular benchmarks demonstrate the superiority of our CurricularFace over the state-of-the-art competitors.",Curriculum Learning : RESEARCH_PROBLEM; (CurricularFace : METHOD; CurricularFace : METHOD; CurricularFace : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: As an emerging topic in face recognition, designing margin-based loss functions can increase the feature margin between different classes for enhanced discriminability. More recently, the idea of mining-based strategies is adopted to emphasize the misclassified samples, achieving promising results. However, during the entire training process, the prior methods either do not explicitly emphasize the sample based on its importance that renders the hard samples not fully exploited; or explicitly emphasize the effects of semi-hard/hard samples even at the early training stage that may lead to convergence issue. In this work, we propose a novel Adaptive Curriculum Learning loss (CurricularFace ) that embeds the idea of curriculum learning into the loss function to achieve a novel training strategy for deep face recognition, which mainly addresses easy samples in the early training stage and hard ones in the later stage. Specifically, our CurricularFace adaptively adjusts the relative importance of easy and hard samples during different training stages. In each stage, different samples are assigned with different importance according to their corresponding difficultness. Extensive experimental results on popular benchmarks demonstrate the superiority of our CurricularFace over the state-of-the-art competitors. ### Response: Curriculum Learning : RESEARCH_PROBLEM; (CurricularFace : METHOD; CurricularFace : METHOD; CurricularFace : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","The internet today has become an unrivalled source of information where people converse on content based websites such as Quora, Reddit, StackOverflow and Twitter asking doubts and sharing knowledge with the world. A major arising problem with such websites is the proliferation of toxic comments or instances of insincerity wherein the users instead of maintaining a sincere motive indulge in spreading toxic and divisive content. The straightforward course of action in confronting this situation is detecting such content beforehand and preventing it from subsisting online. In recent times Transfer Learning in Natural Language Processing has seen an unprecedented growth. Today with the existence of transformers and various state of the art innovations, a tremendous growth has been made in various NLP domains. The introduction of BERT has caused quite a stir in the NLP community. As mentioned, when published, BERT dominated performance benchmarks and thereby inspired many other authors to experiment with it and publish similar models. This led to the development of a whole BERT-family, each member being specialized on a different task. In this paper we solve the Insincere Questions Classification problem by fine tuning four cutting age models viz BERT, RoBERTa, DistilBERT and ALBERT.",Transfer Learning : RESEARCH_PROBLEM; DistilBERT : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: The internet today has become an unrivalled source of information where people converse on content based websites such as Quora, Reddit, StackOverflow and Twitter asking doubts and sharing knowledge with the world. A major arising problem with such websites is the proliferation of toxic comments or instances of insincerity wherein the users instead of maintaining a sincere motive indulge in spreading toxic and divisive content. The straightforward course of action in confronting this situation is detecting such content beforehand and preventing it from subsisting online. In recent times Transfer Learning in Natural Language Processing has seen an unprecedented growth. Today with the existence of transformers and various state of the art innovations, a tremendous growth has been made in various NLP domains. The introduction of BERT has caused quite a stir in the NLP community. As mentioned, when published, BERT dominated performance benchmarks and thereby inspired many other authors to experiment with it and publish similar models. This led to the development of a whole BERT-family, each member being specialized on a different task. In this paper we solve the Insincere Questions Classification problem by fine tuning four cutting age models viz BERT, RoBERTa, DistilBERT and ALBERT. ### Response: Transfer Learning : RESEARCH_PROBLEM; DistilBERT : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Urban ride-hailing demand prediction is a crucial but challenging task for intelligent transportation system construction. Predictable ride-hailing demand can facilitate more reasonable vehicle scheduling and online car-hailing platform dispatch. Conventional deep learning methods with no external structured data can be accomplished via hybrid models of CNNs and RNNs by meshing plentiful pixel-level labeled data, but spatial data sparsity and limited learning capabilities on temporal long-term dependencies are still two striking bottlenecks. To address these limitations, we propose a new virtual graph modeling method to focus on significant demand regions and a novel Deep Multi-View Spatiotemporal Virtual Graph Neural Network (DMVST-VGNN) to strengthen learning capabilities of spatial dynamics and temporal long-term dependencies. Specifically, DMVST-VGNN integrates the structures of 1D Convolutional Neural Network, Multi Graph Attention Neural Network and Transformer layer, which correspond to short-term temporal dynamics view, spatial dynamics view and long-term temporal dynamics view respectively. In this paper, experiments are conducted on two large-scale New York City datasets in fine-grained prediction scenes. And the experimental results demonstrate effectiveness and superiority of DMVST-VGNN framework in significant citywide ride-hailing demand prediction.",Graph Attention : RESEARCH_PROBLEM; Transformer : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Urban ride-hailing demand prediction is a crucial but challenging task for intelligent transportation system construction. Predictable ride-hailing demand can facilitate more reasonable vehicle scheduling and online car-hailing platform dispatch. Conventional deep learning methods with no external structured data can be accomplished via hybrid models of CNNs and RNNs by meshing plentiful pixel-level labeled data, but spatial data sparsity and limited learning capabilities on temporal long-term dependencies are still two striking bottlenecks. To address these limitations, we propose a new virtual graph modeling method to focus on significant demand regions and a novel Deep Multi-View Spatiotemporal Virtual Graph Neural Network (DMVST-VGNN) to strengthen learning capabilities of spatial dynamics and temporal long-term dependencies. Specifically, DMVST-VGNN integrates the structures of 1D Convolutional Neural Network, Multi Graph Attention Neural Network and Transformer layer, which correspond to short-term temporal dynamics view, spatial dynamics view and long-term temporal dynamics view respectively. In this paper, experiments are conducted on two large-scale New York City datasets in fine-grained prediction scenes. And the experimental results demonstrate effectiveness and superiority of DMVST-VGNN framework in significant citywide ride-hailing demand prediction. ### Response: Graph Attention : RESEARCH_PROBLEM; Transformer : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","A representation learning method is considered stable if it consistently generates similar representation of the given data across multiple runs. Word Embedding Methods (WEMs) are a class of representation learning methods that generate dense vector representation for each word in the given text data. The central idea of this paper is to explore the stability measurement of WEMs using intrinsic evaluation based on word similarity. We experiment with three popular WEMs: Word2Vec, GloVe , and fastText . For stability measurement, we investigate the effect of five parameters involved in training these models. We perform experiments using four real-world datasets from different domains: Wikipedia, News, Song lyrics, and European parliament proceedings. We also observe the effect of WEM stability on three downstream tasks: Clustering, POS tagging, and Fairness evaluation. Our experiments indicate that amongst the three WEMs, fastText is the most stable, followed by GloVe and Word2Vec.",GloVe : METHOD; fastText : METHOD; POS : RESEARCH_PROBLEM; Fairness : RESEARCH_PROBLEM; fastText : METHOD; GloVe : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: A representation learning method is considered stable if it consistently generates similar representation of the given data across multiple runs. Word Embedding Methods (WEMs) are a class of representation learning methods that generate dense vector representation for each word in the given text data. The central idea of this paper is to explore the stability measurement of WEMs using intrinsic evaluation based on word similarity. We experiment with three popular WEMs: Word2Vec, GloVe , and fastText . For stability measurement, we investigate the effect of five parameters involved in training these models. We perform experiments using four real-world datasets from different domains: Wikipedia, News, Song lyrics, and European parliament proceedings. We also observe the effect of WEM stability on three downstream tasks: Clustering, POS tagging, and Fairness evaluation. Our experiments indicate that amongst the three WEMs, fastText is the most stable, followed by GloVe and Word2Vec. ### Response: GloVe : METHOD; fastText : METHOD; POS : RESEARCH_PROBLEM; Fairness : RESEARCH_PROBLEM; fastText : METHOD; GloVe : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Topic models are one of the most popular methods for learning representationsof text, but a major challenge is that any change to the topic model requiresmathematically deriving a new inference algorithm. A promising approach toaddress this problem is autoencoding variational Bayes (AEVB), but it hasproven diffi- cult to apply to topic models in practice. We present what is toour knowledge the first effective AEVB based inference method for latentDirichlet allocation (LDA ), which we call Autoencoded Variational Inference ForTopic Model (AVITM). This model tackles the problems caused for AEVB by theDirichlet prior and by component collapsing. We find that AVITM matchestraditional methods in accuracy with much better inference time. Indeed,because of the inference network, we find that it is unnecessary to pay thecomputational cost of running variational optimization on test data. BecauseAVITM is black box, it is readily applied to new topic models. As a dramaticillustration of this, we present a new topic model called ProdLDA , thatreplaces the mixture model in LDA with a product of experts. By changing onlyone line of code from LDA , we find that ProdLDA yields much more interpretabletopics, even if LDA is trained via collapsed Gibbs sampling.",(LDA : METHOD; Variational Inference : RESEARCH_PROBLEM; ProdLDA : METHOD; LDA : METHOD; LDA : METHOD; ProdLDA : METHOD; LDA : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Topic models are one of the most popular methods for learning representationsof text, but a major challenge is that any change to the topic model requiresmathematically deriving a new inference algorithm. A promising approach toaddress this problem is autoencoding variational Bayes (AEVB), but it hasproven diffi- cult to apply to topic models in practice. We present what is toour knowledge the first effective AEVB based inference method for latentDirichlet allocation (LDA ), which we call Autoencoded Variational Inference ForTopic Model (AVITM). This model tackles the problems caused for AEVB by theDirichlet prior and by component collapsing. We find that AVITM matchestraditional methods in accuracy with much better inference time. Indeed,because of the inference network, we find that it is unnecessary to pay thecomputational cost of running variational optimization on test data. BecauseAVITM is black box, it is readily applied to new topic models. As a dramaticillustration of this, we present a new topic model called ProdLDA , thatreplaces the mixture model in LDA with a product of experts. By changing onlyone line of code from LDA , we find that ProdLDA yields much more interpretabletopics, even if LDA is trained via collapsed Gibbs sampling. ### Response: (LDA : METHOD; Variational Inference : RESEARCH_PROBLEM; ProdLDA : METHOD; LDA : METHOD; LDA : METHOD; ProdLDA : METHOD; LDA : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Multiple-choice Machine Reading Comprehension (MRC) is an important and challenging Natural Language Understanding (NLU) task, in which a machine must choose the answer to a question from a set of choices, with the question placed in context of text passages or dialog. In the last a couple of years the NLU field has been revolutionized with the advent of models based on the Transformer architecture, which are pretrained on massive amounts of unsupervised data and then fine-tuned for various supervised learning NLU tasks. Transformer models have come to dominate a wide variety of leader-boards in the NLU field; in the area of MRC, the current state-of-the-art model on the DREAM dataset (see[Sunet al., 2019]) fine tunes Albert, a large pretrained Transformer -based model, and addition-ally combines it with an extra layer of multi-head attention between context and question-answer[Zhuet al., 2020].The purpose of this note is to document a new state-of-the-art result in the DREAM task, which is accomplished by, additionally, performing multi-task learning on two MRC multi-choice reading comprehension tasks (RACE and DREAM).",Machine Reading Comprehension : RESEARCH_PROBLEM; Natural Language Understanding : RESEARCH_PROBLEM; Transformer : METHOD; Transformer : METHOD; Transformer : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Multiple-choice Machine Reading Comprehension (MRC) is an important and challenging Natural Language Understanding (NLU) task, in which a machine must choose the answer to a question from a set of choices, with the question placed in context of text passages or dialog. In the last a couple of years the NLU field has been revolutionized with the advent of models based on the Transformer architecture, which are pretrained on massive amounts of unsupervised data and then fine-tuned for various supervised learning NLU tasks. Transformer models have come to dominate a wide variety of leader-boards in the NLU field; in the area of MRC, the current state-of-the-art model on the DREAM dataset (see[Sunet al., 2019]) fine tunes Albert, a large pretrained Transformer -based model, and addition-ally combines it with an extra layer of multi-head attention between context and question-answer[Zhuet al., 2020].The purpose of this note is to document a new state-of-the-art result in the DREAM task, which is accomplished by, additionally, performing multi-task learning on two MRC multi-choice reading comprehension tasks (RACE and DREAM). ### Response: Machine Reading Comprehension : RESEARCH_PROBLEM; Natural Language Understanding : RESEARCH_PROBLEM; Transformer : METHOD; Transformer : METHOD; Transformer : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","State-of-the-art natural language processing systems rely on supervision inthe form of annotated data to learn competent models. These models aregenerally trained on data in a single language (usually English), and cannot bedirectly used beyond that language. Since collecting data in every language isnot realistic, there has been a growing interest in cross-lingual languageunderstanding (XLU) and low-resource cross-language transfer. In this work, weconstruct an evaluation set for XLU by extending the development and test setsof the Multi-Genre Natural Language Inference Corpus (MultiNLI) to 15languages, including low-resource languages such as Swahili and Urdu. We hopethat our dataset, dubbed XNLI, will catalyze research in cross-lingual sentenceunderstanding by providing an informative standard evaluation task. Inaddition, we provide several baselines for multilingual sentence understanding,including two based on machine translation systems, and two that use paralleldata to train aligned multilingual bag-of-words and LSTM encoders. We find thatXNLI represents a practical and challenging evaluation suite, and that directlytranslating the test data yields the best performance among availablebaselines.",Natural Language Inference : RESEARCH_PROBLEM; LSTM : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: State-of-the-art natural language processing systems rely on supervision inthe form of annotated data to learn competent models. These models aregenerally trained on data in a single language (usually English), and cannot bedirectly used beyond that language. Since collecting data in every language isnot realistic, there has been a growing interest in cross-lingual languageunderstanding (XLU) and low-resource cross-language transfer. In this work, weconstruct an evaluation set for XLU by extending the development and test setsof the Multi-Genre Natural Language Inference Corpus (MultiNLI) to 15languages, including low-resource languages such as Swahili and Urdu. We hopethat our dataset, dubbed XNLI, will catalyze research in cross-lingual sentenceunderstanding by providing an informative standard evaluation task. Inaddition, we provide several baselines for multilingual sentence understanding,including two based on machine translation systems, and two that use paralleldata to train aligned multilingual bag-of-words and LSTM encoders. We find thatXNLI represents a practical and challenging evaluation suite, and that directlytranslating the test data yields the best performance among availablebaselines. ### Response: Natural Language Inference : RESEARCH_PROBLEM; LSTM : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","We implement a differentiable Neural Architecture Search (NAS) method inspired by FBNet for discovering neural networks that are heavily optimized for a particular target device. The FBNet NAS method discovers a neural network from a given search space by optimizing over a loss function which accounts for accuracy and target device latency. We extend this loss function by adding an energy term. This will potentially enhance the ``hardware awareness"" and help us find a neural network architecture that is optimal in terms of accuracy, latency and energy consumption, given a target device (Raspberry Pi in our case). We name our trained child architecture obtained at the end of search process as Hardware Aware Neural Network Architecture (HANNA). We prove the efficacy of our approach by benchmarking HANNA against two other state-of-the-art neural networks designed for mobile/embedded applications, namely MobileNetv2 and CondenseNet for CIFAR-10 dataset. Our results show that HANNA provides a speedup of about 2.5x and 1.7x, and reduces energy consumption by 3.8x and 2x compared to MobileNetv2 and CondenseNet respectively. HANNA is able to provide such significant speedup and energy efficiency benefits over the state-of-the-art baselines at the cost of a tolerable 4-5% drop in accuracy.",Neural Architecture Search : RESEARCH_PROBLEM; FBNet : METHOD; FBNet : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: We implement a differentiable Neural Architecture Search (NAS) method inspired by FBNet for discovering neural networks that are heavily optimized for a particular target device. The FBNet NAS method discovers a neural network from a given search space by optimizing over a loss function which accounts for accuracy and target device latency. We extend this loss function by adding an energy term. This will potentially enhance the ``hardware awareness"" and help us find a neural network architecture that is optimal in terms of accuracy, latency and energy consumption, given a target device (Raspberry Pi in our case). We name our trained child architecture obtained at the end of search process as Hardware Aware Neural Network Architecture (HANNA). We prove the efficacy of our approach by benchmarking HANNA against two other state-of-the-art neural networks designed for mobile/embedded applications, namely MobileNetv2 and CondenseNet for CIFAR-10 dataset. Our results show that HANNA provides a speedup of about 2.5x and 1.7x, and reduces energy consumption by 3.8x and 2x compared to MobileNetv2 and CondenseNet respectively. HANNA is able to provide such significant speedup and energy efficiency benefits over the state-of-the-art baselines at the cost of a tolerable 4-5% drop in accuracy. ### Response: Neural Architecture Search : RESEARCH_PROBLEM; FBNet : METHOD; FBNet : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Recent advances in language representation using neural networks have made it viable to transfer the learned internal states of a trained model to downstream natural language processing tasks, such as named entity recognition (NER ) and question answering. It has been shown that the leverage of pre-trained language models improves the overall performance on many tasks and is highly beneficial when labeled data is scarce. In this work, we train Portuguese BERT models and employ a BERT -CRF architecture to the NER task on the Portuguese language, combining the transfer capabilities of BERT with the structured predictions of CRF. We explore feature-based and fine-tuning training strategies for the BERT model. Our fine-tuning approach obtains new state-of-the-art results on the HAREM I dataset, improving the F1-score by 1 point on the selective scenario (5 NE classes) and by 4 points on the total scenario (10 NE classes).",(NER : RESEARCH_PROBLEM; BERT : METHOD; BERT : METHOD; NER : RESEARCH_PROBLEM; BERT : METHOD; BERT : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Recent advances in language representation using neural networks have made it viable to transfer the learned internal states of a trained model to downstream natural language processing tasks, such as named entity recognition (NER ) and question answering. It has been shown that the leverage of pre-trained language models improves the overall performance on many tasks and is highly beneficial when labeled data is scarce. In this work, we train Portuguese BERT models and employ a BERT -CRF architecture to the NER task on the Portuguese language, combining the transfer capabilities of BERT with the structured predictions of CRF. We explore feature-based and fine-tuning training strategies for the BERT model. Our fine-tuning approach obtains new state-of-the-art results on the HAREM I dataset, improving the F1-score by 1 point on the selective scenario (5 NE classes) and by 4 points on the total scenario (10 NE classes). ### Response: (NER : RESEARCH_PROBLEM; BERT : METHOD; BERT : METHOD; NER : RESEARCH_PROBLEM; BERT : METHOD; BERT : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Fact checking is an important task for maintaining high quality posts and improving user experience in Community Question Answering forums. Therefore, the SemEval-2019 task 8 is aimed to identify factual question (subtask A) and detect true factual information from corresponding answers (subtask B). In order to address this task, we propose a system based on the BERT model with meta information of questions. For the subtask A, the outputs of fine-tuned BERT classification model are combined with the feature of length of questions to boost the performance. For the subtask B, the predictions of several variants of BERT model encoding the meta information are combined to create an ensemble model. Our system achieved competitive results with an accuracy of 0.82 in the subtask A and 0.83 in the subtask B. The experimental results validate the effectiveness of our system.",Community Question Answering : RESEARCH_PROBLEM; BERT : METHOD; BERT : METHOD; BERT : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Fact checking is an important task for maintaining high quality posts and improving user experience in Community Question Answering forums. Therefore, the SemEval-2019 task 8 is aimed to identify factual question (subtask A) and detect true factual information from corresponding answers (subtask B). In order to address this task, we propose a system based on the BERT model with meta information of questions. For the subtask A, the outputs of fine-tuned BERT classification model are combined with the feature of length of questions to boost the performance. For the subtask B, the predictions of several variants of BERT model encoding the meta information are combined to create an ensemble model. Our system achieved competitive results with an accuracy of 0.82 in the subtask A and 0.83 in the subtask B. The experimental results validate the effectiveness of our system. ### Response: Community Question Answering : RESEARCH_PROBLEM; BERT : METHOD; BERT : METHOD; BERT : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","In Federated Learning (FL), client devices collaboratively train a model without sharing the private data present on the devices. Federated Stochastic Gradient Descent (FedSGD ) is a recent generalisation of the popular Federated Averaging algorithm. Recent works show that when client data is distributed heterogeneously, the loss function minimised by FedSGD differs from the 'true' loss that would be minimised by centralised training. Previous works propose decaying the client learning rate, $\gamma$, to allow FedSGD to minimise the true loss. We propose instead decaying the number of local SGD steps, $K$, that clients perform during training rounds to allow minimisation of the true loss. Decaying $K$ has the added benefit of reducing the total computation that clients perform during FedSGD . Real-world applications of FL use large numbers of low-powered smartphone or Internet-of-Things clients, so reduction of computation would provide significant savings in terms of energy and time. In this work, we prove for quadratic objectives that annealing $K$ allows FedSGD to approach the true minimiser. We then perform thorough experimentation on three benchmark FL datasets to show that decaying $K$ can achieve the same generalisation performance as decaying $\gamma$, but with up to $3.8\times$ less total steps of SGD performed by clients.",Federated Learning : RESEARCH_PROBLEM; (FedSGD : METHOD; FedSGD : METHOD; FedSGD : METHOD; SGD : METHOD; FedSGD : METHOD; FedSGD : METHOD; SGD : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: In Federated Learning (FL), client devices collaboratively train a model without sharing the private data present on the devices. Federated Stochastic Gradient Descent (FedSGD ) is a recent generalisation of the popular Federated Averaging algorithm. Recent works show that when client data is distributed heterogeneously, the loss function minimised by FedSGD differs from the 'true' loss that would be minimised by centralised training. Previous works propose decaying the client learning rate, $\gamma$, to allow FedSGD to minimise the true loss. We propose instead decaying the number of local SGD steps, $K$, that clients perform during training rounds to allow minimisation of the true loss. Decaying $K$ has the added benefit of reducing the total computation that clients perform during FedSGD . Real-world applications of FL use large numbers of low-powered smartphone or Internet-of-Things clients, so reduction of computation would provide significant savings in terms of energy and time. In this work, we prove for quadratic objectives that annealing $K$ allows FedSGD to approach the true minimiser. We then perform thorough experimentation on three benchmark FL datasets to show that decaying $K$ can achieve the same generalisation performance as decaying $\gamma$, but with up to $3.8\times$ less total steps of SGD performed by clients. ### Response: Federated Learning : RESEARCH_PROBLEM; (FedSGD : METHOD; FedSGD : METHOD; FedSGD : METHOD; SGD : METHOD; FedSGD : METHOD; FedSGD : METHOD; SGD : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Syndromic surveillance detects and monitors individual and population healthindicators through sources such as emergency department records. Automatedclassification of these records can improve outbreak detection speed anddiagnosis accuracy. Current syndromic systems rely on hand-coded keyword-basedmethods to parse written fields and may benefit from the use of modernsupervised-learning classifier models. In this paper we implement two recurrentneural network models based on long short-term memory (LSTM) and gatedrecurrent unit (GRU ) cells and compare them to two traditional bag-of-wordsclassifiers: multinomial naive Bayes (MNB) and a support vector machine (SVM).The MNB classifier is one of only two machine learning algorithms currentlybeing used for syndromic surveillance. All four models are trained to predictdiagnostic code groups as defined by Clinical Classification Software, first topredict from discharge diagnosis, then from chief complaint fields. Theclassifiers are trained on 3.6 million de-identified emergency departmentrecords from a single United States jurisdiction. We compare performance ofthese models primarily using the F1 score. Using discharge diagnoses, the LSTMclassifier performs best, though all models exhibit an F1 score above 96.00.The GRU performs best on chief complaints (F1=47.38), and MNB with bigramsperforms worst (F1=39.40). Certain syndrome types are easier to detect thanothers. For examples, chief complaints using the GRU model predictsalcohol-related disorders well (F1=78.91) but predicts influenza poorly(F1=14.80). In all instances, the RNN models outperformed the bag-of-wordclassifiers, suggesting deep learning models could substantially improve theautomatic classification of unstructured text for syndromic surveillance.",(GRU : METHOD; Classification : RESEARCH_PROBLEM; GRU : METHOD; GRU : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Syndromic surveillance detects and monitors individual and population healthindicators through sources such as emergency department records. Automatedclassification of these records can improve outbreak detection speed anddiagnosis accuracy. Current syndromic systems rely on hand-coded keyword-basedmethods to parse written fields and may benefit from the use of modernsupervised-learning classifier models. In this paper we implement two recurrentneural network models based on long short-term memory (LSTM) and gatedrecurrent unit (GRU ) cells and compare them to two traditional bag-of-wordsclassifiers: multinomial naive Bayes (MNB) and a support vector machine (SVM).The MNB classifier is one of only two machine learning algorithms currentlybeing used for syndromic surveillance. All four models are trained to predictdiagnostic code groups as defined by Clinical Classification Software, first topredict from discharge diagnosis, then from chief complaint fields. Theclassifiers are trained on 3.6 million de-identified emergency departmentrecords from a single United States jurisdiction. We compare performance ofthese models primarily using the F1 score. Using discharge diagnoses, the LSTMclassifier performs best, though all models exhibit an F1 score above 96.00.The GRU performs best on chief complaints (F1=47.38), and MNB with bigramsperforms worst (F1=39.40). Certain syndrome types are easier to detect thanothers. For examples, chief complaints using the GRU model predictsalcohol-related disorders well (F1=78.91) but predicts influenza poorly(F1=14.80). In all instances, the RNN models outperformed the bag-of-wordclassifiers, suggesting deep learning models could substantially improve theautomatic classification of unstructured text for syndromic surveillance. ### Response: (GRU : METHOD; Classification : RESEARCH_PROBLEM; GRU : METHOD; GRU : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Recent research in self-supervised learning (SSL) has shown its capability in learning useful semantic representations from images for classification tasks. Through our work, we study the usefulness of SSL for Fine-Grained Visual Categorization (FGVC). FGVC aims to distinguish objects of visually similar sub categories within a general category. The small inter-class, but large intra-class variations within the dataset makes it a challenging task. The limited availability of annotated labels for such a fine-grained data encourages the need for SSL, where additional supervision can boost learning without the cost of extra annotations. Our baseline achieves $86.36\%$ top-1 classification accuracy on CUB-200-2011 dataset by utilizing random crop augmentation during training and center crop augmentation during testing. In this work, we explore the usefulness of various pretext tasks, specifically, rotation, pretext invariant representation learning (PIRL ), and deconstruction and construction learning (DCL) for FGVC. Rotation as an auxiliary task promotes the model to learn global features, and diverts it from focusing on the subtle details. PIRL that uses jigsaw patches attempts to focus on discriminative local regions, but struggles to accurately localize them. DCL helps in learning local discriminating features and outperforms the baseline by achieving $87.41\%$ top-1 accuracy. The deconstruction learning forces the model to focus on local object parts, while reconstruction learning helps in learning the correlation between the parts. We perform extensive experiments to reason our findings. Our code is available at https://github.com/mmaaz60/ssl_for_fgvc.",Fine-Grained Visual Categorization : RESEARCH_PROBLEM; (PIRL : METHOD; PIRL : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Recent research in self-supervised learning (SSL) has shown its capability in learning useful semantic representations from images for classification tasks. Through our work, we study the usefulness of SSL for Fine-Grained Visual Categorization (FGVC). FGVC aims to distinguish objects of visually similar sub categories within a general category. The small inter-class, but large intra-class variations within the dataset makes it a challenging task. The limited availability of annotated labels for such a fine-grained data encourages the need for SSL, where additional supervision can boost learning without the cost of extra annotations. Our baseline achieves $86.36\%$ top-1 classification accuracy on CUB-200-2011 dataset by utilizing random crop augmentation during training and center crop augmentation during testing. In this work, we explore the usefulness of various pretext tasks, specifically, rotation, pretext invariant representation learning (PIRL ), and deconstruction and construction learning (DCL) for FGVC. Rotation as an auxiliary task promotes the model to learn global features, and diverts it from focusing on the subtle details. PIRL that uses jigsaw patches attempts to focus on discriminative local regions, but struggles to accurately localize them. DCL helps in learning local discriminating features and outperforms the baseline by achieving $87.41\%$ top-1 accuracy. The deconstruction learning forces the model to focus on local object parts, while reconstruction learning helps in learning the correlation between the parts. We perform extensive experiments to reason our findings. Our code is available at https://github.com/mmaaz60/ssl_for_fgvc. ### Response: Fine-Grained Visual Categorization : RESEARCH_PROBLEM; (PIRL : METHOD; PIRL : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Sentiment Analysis for Indian Languages (SAIL)-Code Mixed tools contest aimedat identifying the sentence level sentiment polarity of the code-mixed datasetof Indian languages pairs (Hi-En, Ben-Hi-En). Hi-En dataset is henceforthreferred to as HI-EN and Ben-Hi-En dataset as BN-EN respectively. For this, wesubmitted four models for sentiment analysis of code-mixed HI-EN and BN-ENdatasets. The first model was an ensemble voting classifier consisting of threeclassifiers - linear SVM , logistic regression and random forests while thesecond one was a linear SVM . Both the models used TF-IDF feature vectors ofcharacter n-grams where n ranged from 2 to 6. We used scikit-learn (sklearn)machine learning library for implementing both the approaches. Run1 wasobtained from the voting classifier and Run2 used the linear SVM model forproducing the results. Out of the four submitted outputs Run2 outperformed Run1in both the datasets. We finished first in the contest for both HI-EN with anF-score of 0.569 and BN-EN with an F-score of 0.526.",Sentiment Analysis : RESEARCH_PROBLEM; SVM : METHOD; SVM : METHOD; SVM : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Sentiment Analysis for Indian Languages (SAIL)-Code Mixed tools contest aimedat identifying the sentence level sentiment polarity of the code-mixed datasetof Indian languages pairs (Hi-En, Ben-Hi-En). Hi-En dataset is henceforthreferred to as HI-EN and Ben-Hi-En dataset as BN-EN respectively. For this, wesubmitted four models for sentiment analysis of code-mixed HI-EN and BN-ENdatasets. The first model was an ensemble voting classifier consisting of threeclassifiers - linear SVM , logistic regression and random forests while thesecond one was a linear SVM . Both the models used TF-IDF feature vectors ofcharacter n-grams where n ranged from 2 to 6. We used scikit-learn (sklearn)machine learning library for implementing both the approaches. Run1 wasobtained from the voting classifier and Run2 used the linear SVM model forproducing the results. Out of the four submitted outputs Run2 outperformed Run1in both the datasets. We finished first in the contest for both HI-EN with anF-score of 0.569 and BN-EN with an F-score of 0.526. ### Response: Sentiment Analysis : RESEARCH_PROBLEM; SVM : METHOD; SVM : METHOD; SVM : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","In this paper, we present our approaches and results for SemEval-2020 Task 12, Multilingual Offensive Language Identification in Social Media (OffensEval 2020). The OffensEval 2020 had three subtasks: A) Identifying the tweets to be offensive (OFF) or non-offensive (NOT) for Arabic, Danish, English, Greek, and Turkish languages, B) Detecting if the offensive tweet is targeted (TIN) or untargeted (UNT) for the English language, and C) Categorizing the offensive targeted tweets into three classes, namely: individual (IND), Group (GRP), or Other (OTH) for the English language. We participate in all the subtasks A, B, and C. In our solution, first we use the pre-trained BERT model for all subtasks, A, B, and C and then we apply the BiLSTM model with attention mechanism (Attn-BiLSTM ) for the same. Our result demonstrates that the pre-trained model is not giving good results for all types of languages and is compute and memory intensive whereas the Attn-BiLSTM model is fast and gives good accuracy with fewer resources. The Attn-BiLSTM model is giving better accuracy for Arabic and Greek where the pre-trained model is not able to capture the complete context of these languages due to lower vocab-size.",Language Identification : RESEARCH_PROBLEM; BERT : METHOD; BiLSTM : METHOD; (Attn-BiLSTM : METHOD; Attn-BiLSTM : METHOD; Attn-BiLSTM : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: In this paper, we present our approaches and results for SemEval-2020 Task 12, Multilingual Offensive Language Identification in Social Media (OffensEval 2020). The OffensEval 2020 had three subtasks: A) Identifying the tweets to be offensive (OFF) or non-offensive (NOT) for Arabic, Danish, English, Greek, and Turkish languages, B) Detecting if the offensive tweet is targeted (TIN) or untargeted (UNT) for the English language, and C) Categorizing the offensive targeted tweets into three classes, namely: individual (IND), Group (GRP), or Other (OTH) for the English language. We participate in all the subtasks A, B, and C. In our solution, first we use the pre-trained BERT model for all subtasks, A, B, and C and then we apply the BiLSTM model with attention mechanism (Attn-BiLSTM ) for the same. Our result demonstrates that the pre-trained model is not giving good results for all types of languages and is compute and memory intensive whereas the Attn-BiLSTM model is fast and gives good accuracy with fewer resources. The Attn-BiLSTM model is giving better accuracy for Arabic and Greek where the pre-trained model is not able to capture the complete context of these languages due to lower vocab-size. ### Response: Language Identification : RESEARCH_PROBLEM; BERT : METHOD; BiLSTM : METHOD; (Attn-BiLSTM : METHOD; Attn-BiLSTM : METHOD; Attn-BiLSTM : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Question-answering plays an important role in e-commerce as it allows potential customers to actively seek crucial information about products or services to help their purchase decision making. Inspired by the recent success of machine reading comprehension (MRC) on formal documents, this paper explores the potential of turning customer reviews into a large source of knowledge that can be exploited to answer user questions.~We call this problem Review Reading Comprehension (RRC). To the best of our knowledge, no existing work has been done on RRC. In this work, we first build an RRC dataset called ReviewRC based on a popular benchmark for aspect-based sentiment analysis. Since ReviewRC has limited training examples for RRC (and also for aspect-based sentiment analysis), we then explore a novel post-training approach on the popular language model BERT to enhance the performance of fine-tuning of BERT for RRC. To show the generality of the approach, the proposed post-training is also applied to some other review-based tasks such as aspect extraction and aspect sentiment classification in aspect-based sentiment analysis. Experimental results demonstrate that the proposed post-training is highly effective. The datasets and code are available at https://www.cs.uic.edu/~hxu/.",Reading Comprehension : RESEARCH_PROBLEM; BERT : METHOD; BERT : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Question-answering plays an important role in e-commerce as it allows potential customers to actively seek crucial information about products or services to help their purchase decision making. Inspired by the recent success of machine reading comprehension (MRC) on formal documents, this paper explores the potential of turning customer reviews into a large source of knowledge that can be exploited to answer user questions.~We call this problem Review Reading Comprehension (RRC). To the best of our knowledge, no existing work has been done on RRC. In this work, we first build an RRC dataset called ReviewRC based on a popular benchmark for aspect-based sentiment analysis. Since ReviewRC has limited training examples for RRC (and also for aspect-based sentiment analysis), we then explore a novel post-training approach on the popular language model BERT to enhance the performance of fine-tuning of BERT for RRC. To show the generality of the approach, the proposed post-training is also applied to some other review-based tasks such as aspect extraction and aspect sentiment classification in aspect-based sentiment analysis. Experimental results demonstrate that the proposed post-training is highly effective. The datasets and code are available at https://www.cs.uic.edu/~hxu/. ### Response: Reading Comprehension : RESEARCH_PROBLEM; BERT : METHOD; BERT : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","In this paper, we consider the problem of Robust Matrix Completion (RMC) where the goal is to recover a low-rank matrix by observing a small number of its entries out of which a few can be arbitrarily corrupted. We propose a simple projected gradient descent-based method to estimate the low-rank matrix that alternately performs a projected gradient descent step and cleans up a few of the corrupted entries using hard-thresholding. Our algorithm solves RMC using nearly optimal number of observations while tolerating a nearly optimal number of corruptions. Our result also implies significant improvement over the existing time complexity bounds for the low-rank matrix completion problem. Finally, an application of our result to the robust PCA problem (low-rank+sparse matrix separation) leads to nearly linear time (in matrix dimensions) algorithm for the same; existing state-of-the-art methods require quadratic time. Our empirical results corroborate our theoretical results and show that even for moderate sized problems, our method for robust PCA is an order of magnitude faster than the existing methods.",Matrix Completion : RESEARCH_PROBLEM; PCA : METHOD; PCA : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: In this paper, we consider the problem of Robust Matrix Completion (RMC) where the goal is to recover a low-rank matrix by observing a small number of its entries out of which a few can be arbitrarily corrupted. We propose a simple projected gradient descent-based method to estimate the low-rank matrix that alternately performs a projected gradient descent step and cleans up a few of the corrupted entries using hard-thresholding. Our algorithm solves RMC using nearly optimal number of observations while tolerating a nearly optimal number of corruptions. Our result also implies significant improvement over the existing time complexity bounds for the low-rank matrix completion problem. Finally, an application of our result to the robust PCA problem (low-rank+sparse matrix separation) leads to nearly linear time (in matrix dimensions) algorithm for the same; existing state-of-the-art methods require quadratic time. Our empirical results corroborate our theoretical results and show that even for moderate sized problems, our method for robust PCA is an order of magnitude faster than the existing methods. ### Response: Matrix Completion : RESEARCH_PROBLEM; PCA : METHOD; PCA : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","This paper provides a report on our solution including model selection, tuning strategy and results obtained for Global Road Damage Detection Challenge. This Big Data Cup Challenge was held as a part of IEEE International Conference on Big Data 2020. We assess single and multi-stage network architectures for object detection and provide a benchmark using popular state-of-the-art open-source PyTorch frameworks like Detectron2 and Yolov5. Data preparation for provided Road Damage training dataset, captured using smartphone camera from Czech, India and Japan is discussed. We studied the effect of training on a per country basis with respect to a single generalizable model. We briefly describe the tuning strategy for the experiments conducted on two-stage Faster R-CNN with Deep Residual Network (Resnet) and Feature Pyramid Network (FPN) backbone. Additionally, we compare this to a one-stage Yolov5 model with Cross Stage Partial Network (CSPNet) backbone. We show a mean F1 score of 0.542 on Test2 and 0.536 on Test1 datasets using a multi-stage Faster R-CNN model, with Resnet-50 and Resnet-101 backbones respectively. This shows the generalizability of the Resnet-50 model when compared to its more complex counterparts. Experiments were conducted using Google Colab having K80 and a Linux PC with 1080Ti, NVIDIA consumer grade GPU. A PyTorch based Detectron2 code to preprocess, train, test and submit the Avg F1 score to is made available at https://github.com/vishwakarmarhl/rdd2020",Road Damage Detection : RESEARCH_PROBLEM; Faster R-CNN : METHOD; Faster R-CNN : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: This paper provides a report on our solution including model selection, tuning strategy and results obtained for Global Road Damage Detection Challenge. This Big Data Cup Challenge was held as a part of IEEE International Conference on Big Data 2020. We assess single and multi-stage network architectures for object detection and provide a benchmark using popular state-of-the-art open-source PyTorch frameworks like Detectron2 and Yolov5. Data preparation for provided Road Damage training dataset, captured using smartphone camera from Czech, India and Japan is discussed. We studied the effect of training on a per country basis with respect to a single generalizable model. We briefly describe the tuning strategy for the experiments conducted on two-stage Faster R-CNN with Deep Residual Network (Resnet) and Feature Pyramid Network (FPN) backbone. Additionally, we compare this to a one-stage Yolov5 model with Cross Stage Partial Network (CSPNet) backbone. We show a mean F1 score of 0.542 on Test2 and 0.536 on Test1 datasets using a multi-stage Faster R-CNN model, with Resnet-50 and Resnet-101 backbones respectively. This shows the generalizability of the Resnet-50 model when compared to its more complex counterparts. Experiments were conducted using Google Colab having K80 and a Linux PC with 1080Ti, NVIDIA consumer grade GPU. A PyTorch based Detectron2 code to preprocess, train, test and submit the Avg F1 score to is made available at https://github.com/vishwakarmarhl/rdd2020 ### Response: Road Damage Detection : RESEARCH_PROBLEM; Faster R-CNN : METHOD; Faster R-CNN : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","The CNN-based methods have achieved impressive results in medical image segmentation, but it failed to capture the long-range dependencies due to the inherent locality of convolution operation. Transformer -based methods are popular in vision tasks recently because of its capacity of long-range dependencies and get a promising performance. However, it lacks in modeling local context, although some works attempted to embed convolutional layer to overcome this problem and achieved some improvement, but it makes the feature inconsistent and fails to leverage the natural multi-scale features of hierarchical transformer, which limit the performance of models. In this paper, taking medical image segmentation as an example, we present MISSFormer, an effective and powerful Medical Image Segmentation tranSFormer. MISSFormer is a hierarchical encoder-decoder network and has two appealing designs: 1) A feed forward network is redesigned with the proposed Enhanced Transformer Block, which makes features aligned adaptively and enhances the long-range dependencies and local context. 2) We proposed Enhanced Transformer Context Bridge, a context bridge with the enhanced transformer block to model the long-range dependencies and local context of multi-scale features generated by our hierarchical transformer encoder. Driven by these two designs, the MISSFormer shows strong capacity to capture more valuable dependencies and context in medical image segmentation. The experiments on multi-organ and cardiac segmentation tasks demonstrate the superiority, effectiveness and robustness of our MISSFormer, the exprimental results of MISSFormer trained from scratch even outperforms state-of-the-art methods pretrained on ImageNet, and the core designs can be generalized to other visual segmentation tasks. The code will be released in Github.",Transformer : METHOD; Medical Image Segmentation : RESEARCH_PROBLEM; Transformer : METHOD; Transformer : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: The CNN-based methods have achieved impressive results in medical image segmentation, but it failed to capture the long-range dependencies due to the inherent locality of convolution operation. Transformer -based methods are popular in vision tasks recently because of its capacity of long-range dependencies and get a promising performance. However, it lacks in modeling local context, although some works attempted to embed convolutional layer to overcome this problem and achieved some improvement, but it makes the feature inconsistent and fails to leverage the natural multi-scale features of hierarchical transformer, which limit the performance of models. In this paper, taking medical image segmentation as an example, we present MISSFormer, an effective and powerful Medical Image Segmentation tranSFormer. MISSFormer is a hierarchical encoder-decoder network and has two appealing designs: 1) A feed forward network is redesigned with the proposed Enhanced Transformer Block, which makes features aligned adaptively and enhances the long-range dependencies and local context. 2) We proposed Enhanced Transformer Context Bridge, a context bridge with the enhanced transformer block to model the long-range dependencies and local context of multi-scale features generated by our hierarchical transformer encoder. Driven by these two designs, the MISSFormer shows strong capacity to capture more valuable dependencies and context in medical image segmentation. The experiments on multi-organ and cardiac segmentation tasks demonstrate the superiority, effectiveness and robustness of our MISSFormer, the exprimental results of MISSFormer trained from scratch even outperforms state-of-the-art methods pretrained on ImageNet, and the core designs can be generalized to other visual segmentation tasks. The code will be released in Github. ### Response: Transformer : METHOD; Medical Image Segmentation : RESEARCH_PROBLEM; Transformer : METHOD; Transformer : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Moving object detection has been a central topic of discussion in computer vision for its wide range of applications like in self-driving cars, video surveillance, security, and enforcement. Neuromorphic Vision Sensors (NVS) are bio-inspired sensors that mimic the working of the human eye. Unlike conventional frame-based cameras, these sensors capture a stream of asynchronous 'events' that pose multiple advantages over the former, like high dynamic range, low latency, low power consumption, and reduced motion blur. However, these advantages come at a high cost, as the event camera data typically contains more noise and has low resolution. Moreover, as event-based cameras can only capture the relative changes in brightness of a scene, event data do not contain usual visual information (like texture and color) as available in video data from normal cameras. So, moving object detection in event-based cameras becomes an extremely challenging task. In this paper, we present an unsupervised Graph Spectral Clustering technique for Moving Object Detection in Event-based data (GSCEventMOD). We additionally show how the optimum number of moving objects can be automatically determined. Experimental comparisons on publicly available datasets show that the proposed GSCEventMOD algorithm outperforms a number of state-of-the-art techniques by a maximum margin of 30%.",Spectral Clustering : METHOD; Moving Object Detection : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Moving object detection has been a central topic of discussion in computer vision for its wide range of applications like in self-driving cars, video surveillance, security, and enforcement. Neuromorphic Vision Sensors (NVS) are bio-inspired sensors that mimic the working of the human eye. Unlike conventional frame-based cameras, these sensors capture a stream of asynchronous 'events' that pose multiple advantages over the former, like high dynamic range, low latency, low power consumption, and reduced motion blur. However, these advantages come at a high cost, as the event camera data typically contains more noise and has low resolution. Moreover, as event-based cameras can only capture the relative changes in brightness of a scene, event data do not contain usual visual information (like texture and color) as available in video data from normal cameras. So, moving object detection in event-based cameras becomes an extremely challenging task. In this paper, we present an unsupervised Graph Spectral Clustering technique for Moving Object Detection in Event-based data (GSCEventMOD). We additionally show how the optimum number of moving objects can be automatically determined. Experimental comparisons on publicly available datasets show that the proposed GSCEventMOD algorithm outperforms a number of state-of-the-art techniques by a maximum margin of 30%. ### Response: Spectral Clustering : METHOD; Moving Object Detection : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Currently, deep learning approaches are superior in natural language processing due to their ability to extract informative features and patterns from languages. Two most successful neural architectures are LSTM and transformers, the latter mostly used in the form of large pretrained language models such as BERT . While cross-lingual approaches are on the rise, a vast majority of current natural language processing techniques is designed and applied to English, and less-resourced languages are lagging behind. In morphologically rich languages, plenty of information is conveyed through changes in morphology, e.g., through different prefixes and suffixes modifying stems of words. The existing neural approaches do not explicitly use the information on word morphology. We analyze the effect of adding morphological features to LSTM and BERT models. We use three tasks available in many less-resourced languages: named entity recognition (NER ), dependency parsing (DP), and comment filtering (CF). We construct sensible baselines involving LSTM and BERT models, which we adjust by adding additional input in the form of part of speech (POS) tags and universal features. We compare the obtained models across subsets of eight languages. Our results suggest that adding morphological features has mixed effects depending on the quality of features and the task. The features improve the performance of LSTM -based models on the NER and DP tasks, while they do not benefit the performance on the CF task. For BERT -based models, the added morphological features only improve the performance on DP when they are of high quality, while they do not show any practical improvement when they are predicted. As in NER and CF datasets manually checked features are not available, we only experiment with the predicted morphological features and find that they do not cause any practical improvement in performance.",LSTM : METHOD; BERT : METHOD; LSTM : METHOD; BERT : METHOD; (NER : RESEARCH_PROBLEM; LSTM : METHOD; BERT : METHOD; LSTM : METHOD; NER : RESEARCH_PROBLEM; BERT : METHOD; NER : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Currently, deep learning approaches are superior in natural language processing due to their ability to extract informative features and patterns from languages. Two most successful neural architectures are LSTM and transformers, the latter mostly used in the form of large pretrained language models such as BERT . While cross-lingual approaches are on the rise, a vast majority of current natural language processing techniques is designed and applied to English, and less-resourced languages are lagging behind. In morphologically rich languages, plenty of information is conveyed through changes in morphology, e.g., through different prefixes and suffixes modifying stems of words. The existing neural approaches do not explicitly use the information on word morphology. We analyze the effect of adding morphological features to LSTM and BERT models. We use three tasks available in many less-resourced languages: named entity recognition (NER ), dependency parsing (DP), and comment filtering (CF). We construct sensible baselines involving LSTM and BERT models, which we adjust by adding additional input in the form of part of speech (POS) tags and universal features. We compare the obtained models across subsets of eight languages. Our results suggest that adding morphological features has mixed effects depending on the quality of features and the task. The features improve the performance of LSTM -based models on the NER and DP tasks, while they do not benefit the performance on the CF task. For BERT -based models, the added morphological features only improve the performance on DP when they are of high quality, while they do not show any practical improvement when they are predicted. As in NER and CF datasets manually checked features are not available, we only experiment with the predicted morphological features and find that they do not cause any practical improvement in performance. ### Response: LSTM : METHOD; BERT : METHOD; LSTM : METHOD; BERT : METHOD; (NER : RESEARCH_PROBLEM; LSTM : METHOD; BERT : METHOD; LSTM : METHOD; NER : RESEARCH_PROBLEM; BERT : METHOD; NER : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Standard informativeness measures used to evaluate Automatic Text Summarization mostly rely on n-gram overlapping between the automatic summary and the reference summaries. These measures differ from the metric they use (cosine, ROUGE, Kullback-Leibler, Logarithm Similarity, etc.) and the bag of terms they consider (single words, word n-grams, entities, nuggets, etc.). Recent word embedding approaches offer a continuous alternative to discrete approaches based on the presence/absence of a text unit. Informativeness measures have been extended to Focus Information Retrieval evaluation involving a user's information need represented by short queries. In particular for the task of CLEF-INEX Tweet Contextualization, tweet contents have been considered as queries. In this paper we define the concept of Interestingness as a generalization of Informativeness, whereby the information need is diverse and formalized as an unknown set of implicit queries. We then study the ability of state of the art Informativeness measures to cope with this generalization. Lately we show that with this new framework, standard word embeddings outperforms discrete measures only on uni-grams, however bi-grams seems to be a key point of interestingness evaluation. Lastly we prove that the CLEF-INEX Tweet Contextualization 2012 Logarithm Similarity measure provides best results.",Text Summarization : RESEARCH_PROBLEM; Information Retrieval : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Standard informativeness measures used to evaluate Automatic Text Summarization mostly rely on n-gram overlapping between the automatic summary and the reference summaries. These measures differ from the metric they use (cosine, ROUGE, Kullback-Leibler, Logarithm Similarity, etc.) and the bag of terms they consider (single words, word n-grams, entities, nuggets, etc.). Recent word embedding approaches offer a continuous alternative to discrete approaches based on the presence/absence of a text unit. Informativeness measures have been extended to Focus Information Retrieval evaluation involving a user's information need represented by short queries. In particular for the task of CLEF-INEX Tweet Contextualization, tweet contents have been considered as queries. In this paper we define the concept of Interestingness as a generalization of Informativeness, whereby the information need is diverse and formalized as an unknown set of implicit queries. We then study the ability of state of the art Informativeness measures to cope with this generalization. Lately we show that with this new framework, standard word embeddings outperforms discrete measures only on uni-grams, however bi-grams seems to be a key point of interestingness evaluation. Lastly we prove that the CLEF-INEX Tweet Contextualization 2012 Logarithm Similarity measure provides best results. ### Response: Text Summarization : RESEARCH_PROBLEM; Information Retrieval : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Collaborative personalization, such as through learned user representations (embeddings), can improve the prediction accuracy of neural-network-based models significantly. We propose Federated User Representation Learning (FURL), a simple, scalable, privacy-preserving and resource-efficient way to utilize existing neural personalization techniques in the Federated Learning (FL) setting. FURL divides model parameters into federated and private parameters. Private parameters, such as private user embeddings, are trained locally, but unlike federated parameters, they are not transferred to or averaged on the server. We show theoretically that this parameter split does not affect training for most model personalization approaches. Storing user embeddings locally not only preserves user privacy, but also improves memory locality of personalization compared to on-server training. We evaluate FURL on two datasets, demonstrating a significant improvement in model quality with 8% and 51% performance increases, and approximately the same level of performance as centralized training with only 0% and 4% reductions. Furthermore, we show that user embeddings learned in FL and the centralized setting have a very similar structure, indicating that FURL can learn collaboratively through the shared parameters while preserving user privacy.",Representation Learning : RESEARCH_PROBLEM; Federated Learning : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Collaborative personalization, such as through learned user representations (embeddings), can improve the prediction accuracy of neural-network-based models significantly. We propose Federated User Representation Learning (FURL), a simple, scalable, privacy-preserving and resource-efficient way to utilize existing neural personalization techniques in the Federated Learning (FL) setting. FURL divides model parameters into federated and private parameters. Private parameters, such as private user embeddings, are trained locally, but unlike federated parameters, they are not transferred to or averaged on the server. We show theoretically that this parameter split does not affect training for most model personalization approaches. Storing user embeddings locally not only preserves user privacy, but also improves memory locality of personalization compared to on-server training. We evaluate FURL on two datasets, demonstrating a significant improvement in model quality with 8% and 51% performance increases, and approximately the same level of performance as centralized training with only 0% and 4% reductions. Furthermore, we show that user embeddings learned in FL and the centralized setting have a very similar structure, indicating that FURL can learn collaboratively through the shared parameters while preserving user privacy. ### Response: Representation Learning : RESEARCH_PROBLEM; Federated Learning : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Keyword Spotting (KWS) is a significant branch of Automatic Speech Recognition (ASR) and has been widely used in edge computing devices. The goal of KWS is to provide high accuracy with a low False Alarm Rate (FAR), while reducing the costs of memory, computation, and latency. However, limited resources are challenging for KWS applications on edge computing devices. Lightweight models and structures for deep learning have achieved good results in the KWS branch while maintaining efficient performances. In this paper, we present a new Convolutional Recurrent Neural Network (CRNN) architecture named EdgeCRNN for edge computing devices. EdgeCRNN, which is based on depthwise separable convolution and residual structure, uses a feature enhanced method. On the Google Speech Commands Dataset, the experimental results depict that EdgeCRNN can test 11.1 audio data per second on Raspberry Pi 3B+, which is 2.2 times than that of Tpool2. Compared with Tpool2, the accuracy of EdgeCRNN reaches 98.05% whilst its performance is also competitive.",Keyword Spotting : RESEARCH_PROBLEM; Speech Recognition : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Keyword Spotting (KWS) is a significant branch of Automatic Speech Recognition (ASR) and has been widely used in edge computing devices. The goal of KWS is to provide high accuracy with a low False Alarm Rate (FAR), while reducing the costs of memory, computation, and latency. However, limited resources are challenging for KWS applications on edge computing devices. Lightweight models and structures for deep learning have achieved good results in the KWS branch while maintaining efficient performances. In this paper, we present a new Convolutional Recurrent Neural Network (CRNN) architecture named EdgeCRNN for edge computing devices. EdgeCRNN, which is based on depthwise separable convolution and residual structure, uses a feature enhanced method. On the Google Speech Commands Dataset, the experimental results depict that EdgeCRNN can test 11.1 audio data per second on Raspberry Pi 3B+, which is 2.2 times than that of Tpool2. Compared with Tpool2, the accuracy of EdgeCRNN reaches 98.05% whilst its performance is also competitive. ### Response: Keyword Spotting : RESEARCH_PROBLEM; Speech Recognition : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Image compression is a widely used technique to reduce the spatial redundancy in images. Recently, learning based image compression has achieved significant progress by using the powerful representation ability from neural networks. However, the current state-of-the-art learning based image compression methods suffer from the huge computational cost, which limits their capacity for practical applications. In this paper, we propose a unified framework called Efficient Deep Image Compression (EDIC) based on three new technologies, including a channel attention module, a Gaussian mixture model and a decoder-side enhancement module. Specifically, we design an auto-encoder style network for learning based image compression. To improve the coding efficiency, we exploit the channel relationship between latent representations by using the channel attention module. Besides, the Gaussian mixture model is introduced for the entropy model and improves the accuracy for bitrate estimation. Furthermore, we introduce the decoder-side enhancement module to further improve image compression performance. Our EDIC method can also be readily incorporated with the Deep Video Compression (DVC) framework to further improve the video compression performance. Simultaneously, our EDIC method boosts the coding performance significantly while bringing slightly increased computational cost. More importantly, experimental results demonstrate that the proposed approach outperforms the current state-of-the-art image compression methods and is up to more than 150 times faster in terms of decoding speed when compared with Minnen's method. The proposed framework also successfully improves the performance of the recent deep video compression system DVC. Our code will be released at https://github.com/liujiaheng/compression.",Image Compression : RESEARCH_PROBLEM; Video Compression : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Image compression is a widely used technique to reduce the spatial redundancy in images. Recently, learning based image compression has achieved significant progress by using the powerful representation ability from neural networks. However, the current state-of-the-art learning based image compression methods suffer from the huge computational cost, which limits their capacity for practical applications. In this paper, we propose a unified framework called Efficient Deep Image Compression (EDIC) based on three new technologies, including a channel attention module, a Gaussian mixture model and a decoder-side enhancement module. Specifically, we design an auto-encoder style network for learning based image compression. To improve the coding efficiency, we exploit the channel relationship between latent representations by using the channel attention module. Besides, the Gaussian mixture model is introduced for the entropy model and improves the accuracy for bitrate estimation. Furthermore, we introduce the decoder-side enhancement module to further improve image compression performance. Our EDIC method can also be readily incorporated with the Deep Video Compression (DVC) framework to further improve the video compression performance. Simultaneously, our EDIC method boosts the coding performance significantly while bringing slightly increased computational cost. More importantly, experimental results demonstrate that the proposed approach outperforms the current state-of-the-art image compression methods and is up to more than 150 times faster in terms of decoding speed when compared with Minnen's method. The proposed framework also successfully improves the performance of the recent deep video compression system DVC. Our code will be released at https://github.com/liujiaheng/compression. ### Response: Image Compression : RESEARCH_PROBLEM; Video Compression : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","We present Neural Machine Translation (NMT) training using document-level metrics with batch-level documents. Previous sequence-objective approaches to NMT training focus exclusively on sentence-level metrics like sentence BLEU which do not correspond to the desired evaluation metric, typically document BLEU. Meanwhile research into document-level NMT training focuses on data or model architecture rather than training procedure. We find that each of these lines of research has a clear space in it for the other, and propose merging them with a scheme that allows a document-level evaluation metric to be used in the NMT training objective. We first sample pseudo-documents from sentence samples. We then approximate the expected document BLEU gradient with Monte Carlo sampling for use as a cost function in Minimum Risk Training (MRT). This two-level sampling procedure gives NMT performance gains over sequence MRT and maximum-likelihood training. We demonstrate that training is more robust for document-level metrics than with sequence metrics. We further demonstrate improvements on NMT with TER and Grammatical Error Correction (GEC) using GLEU, both metrics used at the document level for evaluations.",Machine Translation : RESEARCH_PROBLEM; Grammatical Error Correction : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: We present Neural Machine Translation (NMT) training using document-level metrics with batch-level documents. Previous sequence-objective approaches to NMT training focus exclusively on sentence-level metrics like sentence BLEU which do not correspond to the desired evaluation metric, typically document BLEU. Meanwhile research into document-level NMT training focuses on data or model architecture rather than training procedure. We find that each of these lines of research has a clear space in it for the other, and propose merging them with a scheme that allows a document-level evaluation metric to be used in the NMT training objective. We first sample pseudo-documents from sentence samples. We then approximate the expected document BLEU gradient with Monte Carlo sampling for use as a cost function in Minimum Risk Training (MRT). This two-level sampling procedure gives NMT performance gains over sequence MRT and maximum-likelihood training. We demonstrate that training is more robust for document-level metrics than with sequence metrics. We further demonstrate improvements on NMT with TER and Grammatical Error Correction (GEC) using GLEU, both metrics used at the document level for evaluations. ### Response: Machine Translation : RESEARCH_PROBLEM; Grammatical Error Correction : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Deep and large pre-trained language models are the state-of-the-art for various natural language processing tasks. However, the huge size of these models could be a deterrent to use them in practice. Some recent and concurrent works use knowledge distillation to compress these huge models into shallow ones. In this work we study knowledge distillation with a focus on multi-lingual Named Entity Recognition (NER ). In particular, we study several distillation strategies and propose a stage-wise optimization scheme leveraging teacher internal representations that is agnostic of teacher architecture and show that it outperforms strategies employed in prior works. Additionally, we investigate the role of several factors like the amount of unlabeled data, annotation resources, model architecture and inference latency to name a few. We show that our approach leads to massive compression of MBERT-like teacher models by upto 35x in terms of parameters and 51x in terms of latency for batch inference while retaining 95% of its F1-score for NER over 41 languages.",Named Entity Recognition : RESEARCH_PROBLEM; (NER : RESEARCH_PROBLEM; NER : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Deep and large pre-trained language models are the state-of-the-art for various natural language processing tasks. However, the huge size of these models could be a deterrent to use them in practice. Some recent and concurrent works use knowledge distillation to compress these huge models into shallow ones. In this work we study knowledge distillation with a focus on multi-lingual Named Entity Recognition (NER ). In particular, we study several distillation strategies and propose a stage-wise optimization scheme leveraging teacher internal representations that is agnostic of teacher architecture and show that it outperforms strategies employed in prior works. Additionally, we investigate the role of several factors like the amount of unlabeled data, annotation resources, model architecture and inference latency to name a few. We show that our approach leads to massive compression of MBERT-like teacher models by upto 35x in terms of parameters and 51x in terms of latency for batch inference while retaining 95% of its F1-score for NER over 41 languages. ### Response: Named Entity Recognition : RESEARCH_PROBLEM; (NER : RESEARCH_PROBLEM; NER : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","This paper presents the machine learning architecture of the Snips VoicePlatform, a software solution to perform Spoken Language Understanding onmicroprocessors typical of IoT devices. The embedded inference is fast andaccurate while enforcing privacy by design, as no personal user data is evercollected. Focusing on Automatic Speech Recognition and Natural LanguageUnderstanding, we detail our approach to training high-performance MachineLearning models that are small enough to run in real-time on small devices.Additionally, we describe a data generation procedure that provides sufficient,high-quality training data without compromising user privacy.",Spoken Language Understanding : RESEARCH_PROBLEM; Speech Recognition : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: This paper presents the machine learning architecture of the Snips VoicePlatform, a software solution to perform Spoken Language Understanding onmicroprocessors typical of IoT devices. The embedded inference is fast andaccurate while enforcing privacy by design, as no personal user data is evercollected. Focusing on Automatic Speech Recognition and Natural LanguageUnderstanding, we detail our approach to training high-performance MachineLearning models that are small enough to run in real-time on small devices.Additionally, we describe a data generation procedure that provides sufficient,high-quality training data without compromising user privacy. ### Response: Spoken Language Understanding : RESEARCH_PROBLEM; Speech Recognition : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Machine Translation is one of the research fields of ComputationalLinguistics. The objective of many MT Researchers is to develop an MT Systemthat produce good quality and high accuracy output translations and which alsocovers maximum language pairs. As internet and Globalization is increasing dayby day, we need a way that improves the quality of translation. For thisreason, we have developed a Classifier based Text Simplification Model forEnglish-Hindi Machine Translation Systems. We have used support vector machinesand Na\""ive Bayes Classifier to develop this model. We have also evaluated theperformance of these classifiers.",Machine Translation : RESEARCH_PROBLEM; Text Simplification : RESEARCH_PROBLEM; Machine Translation : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Machine Translation is one of the research fields of ComputationalLinguistics. The objective of many MT Researchers is to develop an MT Systemthat produce good quality and high accuracy output translations and which alsocovers maximum language pairs. As internet and Globalization is increasing dayby day, we need a way that improves the quality of translation. For thisreason, we have developed a Classifier based Text Simplification Model forEnglish-Hindi Machine Translation Systems. We have used support vector machinesand Na\""ive Bayes Classifier to develop this model. We have also evaluated theperformance of these classifiers. ### Response: Machine Translation : RESEARCH_PROBLEM; Text Simplification : RESEARCH_PROBLEM; Machine Translation : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Motif discovery is a fundamental step in data mining tasks for time-series data such as clustering, classification and anomaly detection. Even though many papers have addressed the problem of how to find motifs in time-series by proposing new motif discovery algorithms, not much work has been done on the exploration of the motifs extracted by these algorithms. In this paper, we argue that visually exploring time-series motifs computed by motif discovery algorithms can be useful to understand and debug results. To explore the output of motif discovery algorithms, we propose the use of an adapted Self-Organizing Map, the DTW-SOM, on the list of motif's centers. In short, DTW-SOM is a vanilla Self-Organizing Map with three main differences, namely (1) the use the Dynamic Time Warping distance instead of the Euclidean distance, (2) the adoption of two new network initialization routines (a random sample initialization and an anchor initialization) and (3) the adjustment of the Adaptation phase of the training to work with variable-length time-series sequences. We test DTW-SOM in a synthetic motif dataset and two real time-series datasets from the UCR Time Series Classification Archive. After an exploration of results, we conclude that DTW-SOM is capable of extracting relevant information from a set of motifs and display it in a visualization that is space-efficient.",Dynamic Time Warping : RESEARCH_PROBLEM; Time Series Classification : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Motif discovery is a fundamental step in data mining tasks for time-series data such as clustering, classification and anomaly detection. Even though many papers have addressed the problem of how to find motifs in time-series by proposing new motif discovery algorithms, not much work has been done on the exploration of the motifs extracted by these algorithms. In this paper, we argue that visually exploring time-series motifs computed by motif discovery algorithms can be useful to understand and debug results. To explore the output of motif discovery algorithms, we propose the use of an adapted Self-Organizing Map, the DTW-SOM, on the list of motif's centers. In short, DTW-SOM is a vanilla Self-Organizing Map with three main differences, namely (1) the use the Dynamic Time Warping distance instead of the Euclidean distance, (2) the adoption of two new network initialization routines (a random sample initialization and an anchor initialization) and (3) the adjustment of the Adaptation phase of the training to work with variable-length time-series sequences. We test DTW-SOM in a synthetic motif dataset and two real time-series datasets from the UCR Time Series Classification Archive. After an exploration of results, we conclude that DTW-SOM is capable of extracting relevant information from a set of motifs and display it in a visualization that is space-efficient. ### Response: Dynamic Time Warping : RESEARCH_PROBLEM; Time Series Classification : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","QTRAN is a multi-agent reinforcement learning (MARL) algorithm capable of learning the largest class of joint-action value functions up to date. However, despite its strong theoretical guarantee, it has shown poor empirical performance in complex environments, such as Starcraft Multi-Agent Challenge (SMAC ). In this paper, we identify the performance bottleneck of QTRAN and propose a substantially improved version, coined QTRAN++. Our gains come from (i) stabilizing the training objective of QTRAN, (ii) removing the strict role separation between the action-value estimators of QTRAN, and (iii) introducing a multi-head mixing network for value transformation. Through extensive evaluation, we confirm that our diagnosis is correct, and QTRAN++ successfully bridges the gap between empirical performance and theoretical guarantee. In particular, QTRAN++ newly achieves state-of-the-art performance in the SMAC environment. The code will be released.",Starcraft : RESEARCH_PROBLEM; (SMAC : RESEARCH_PROBLEM; SMAC : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: QTRAN is a multi-agent reinforcement learning (MARL) algorithm capable of learning the largest class of joint-action value functions up to date. However, despite its strong theoretical guarantee, it has shown poor empirical performance in complex environments, such as Starcraft Multi-Agent Challenge (SMAC ). In this paper, we identify the performance bottleneck of QTRAN and propose a substantially improved version, coined QTRAN++. Our gains come from (i) stabilizing the training objective of QTRAN, (ii) removing the strict role separation between the action-value estimators of QTRAN, and (iii) introducing a multi-head mixing network for value transformation. Through extensive evaluation, we confirm that our diagnosis is correct, and QTRAN++ successfully bridges the gap between empirical performance and theoretical guarantee. In particular, QTRAN++ newly achieves state-of-the-art performance in the SMAC environment. The code will be released. ### Response: Starcraft : RESEARCH_PROBLEM; (SMAC : RESEARCH_PROBLEM; SMAC : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Methods for Named Entity Recognition and Disambiguation (NER D) perform NER and NED in two separate stages. Therefore, NED may be penalized with respect to precision by NER false positives, and suffers in recall from NER false negatives. Conversely, NED does not fully exploit information computed by NER such as types of mentions. This paper presents J-NER D, a new approach to perform NER and NED jointly, by means of a probabilistic graphical model that captures mention spans, mention types, and the mapping of mentions to entities in a knowledge base. We present experiments with different kinds of texts from the CoNLL{'}03, ACE{'}05, and ClueWeb{'}09-FACC1 corpora. J-NER D consistently outperforms state-of-the-art competitors in end-to-end NER D precision, recall, and F1.",Named Entity Recognition : RESEARCH_PROBLEM; (NER : RESEARCH_PROBLEM; NER : RESEARCH_PROBLEM; NER : RESEARCH_PROBLEM; NER : RESEARCH_PROBLEM; NER : RESEARCH_PROBLEM; J-NER : RESEARCH_PROBLEM; NER : RESEARCH_PROBLEM; J-NER : RESEARCH_PROBLEM; NER : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Methods for Named Entity Recognition and Disambiguation (NER D) perform NER and NED in two separate stages. Therefore, NED may be penalized with respect to precision by NER false positives, and suffers in recall from NER false negatives. Conversely, NED does not fully exploit information computed by NER such as types of mentions. This paper presents J-NER D, a new approach to perform NER and NED jointly, by means of a probabilistic graphical model that captures mention spans, mention types, and the mapping of mentions to entities in a knowledge base. We present experiments with different kinds of texts from the CoNLL{'}03, ACE{'}05, and ClueWeb{'}09-FACC1 corpora. J-NER D consistently outperforms state-of-the-art competitors in end-to-end NER D precision, recall, and F1. ### Response: Named Entity Recognition : RESEARCH_PROBLEM; (NER : RESEARCH_PROBLEM; NER : RESEARCH_PROBLEM; NER : RESEARCH_PROBLEM; NER : RESEARCH_PROBLEM; NER : RESEARCH_PROBLEM; J-NER : RESEARCH_PROBLEM; NER : RESEARCH_PROBLEM; J-NER : RESEARCH_PROBLEM; NER : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Few-Shot Learning (FSL) algorithms are commonly trained through Meta-Learning (ML), which exposes models to batches of tasks sampled from a meta-dataset to mimic tasks seen during evaluation. However, the standard training procedures overlook the real-world dynamics where classes commonly occur at different frequencies. While it is generally understood that class imbalance harms the performance of supervised methods, limited research examines the impact of imbalance on the FSL evaluation task. Our analysis compares 10 state-of-the-art meta-learning and FSL methods on different imbalance distributions and rebalancing techniques. Our results reveal that 1) some FSL methods display a natural disposition against imbalance while most other approaches produce a performance drop by up to 17\% compared to the balanced task without the appropriate mitigation; 2) contrary to popular belief, many meta-learning algorithms will not automatically learn to balance from exposure to imbalanced training tasks; 3) classical rebalancing strategies, such as random oversampling, can still be very effective, leading to state-of-the-art performances and should not be overlooked; 4) FSL methods are more robust against meta-dataset imbalance than imbalance at the task-level with a similar imbalance ratio ($\rho<20$), with the effect holding even in long-tail datasets under a larger imbalance ($\rho=65$).",Few-Shot Learning : RESEARCH_PROBLEM; Meta-Learning : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Few-Shot Learning (FSL) algorithms are commonly trained through Meta-Learning (ML), which exposes models to batches of tasks sampled from a meta-dataset to mimic tasks seen during evaluation. However, the standard training procedures overlook the real-world dynamics where classes commonly occur at different frequencies. While it is generally understood that class imbalance harms the performance of supervised methods, limited research examines the impact of imbalance on the FSL evaluation task. Our analysis compares 10 state-of-the-art meta-learning and FSL methods on different imbalance distributions and rebalancing techniques. Our results reveal that 1) some FSL methods display a natural disposition against imbalance while most other approaches produce a performance drop by up to 17\% compared to the balanced task without the appropriate mitigation; 2) contrary to popular belief, many meta-learning algorithms will not automatically learn to balance from exposure to imbalanced training tasks; 3) classical rebalancing strategies, such as random oversampling, can still be very effective, leading to state-of-the-art performances and should not be overlooked; 4) FSL methods are more robust against meta-dataset imbalance than imbalance at the task-level with a similar imbalance ratio ($\rho<20$), with the effect holding even in long-tail datasets under a larger imbalance ($\rho=65$). ### Response: Few-Shot Learning : RESEARCH_PROBLEM; Meta-Learning : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","In order to answer semantically-complicated questions about an image, a Visual Question Answering (VQA) model needs to fully understand the visual scene in the image, especially the interactive dynamics between different objects. We propose a Relation-aware Graph Attention Network (ReGAT), which encodes each image into a graph and models multi-type inter-object relations via a graph attention mechanism, to learn question-adaptive relation representations. Two types of visual object relations are explored: (i) Explicit Relations that represent geometric positions and semantic interactions between objects; and (ii) Implicit Relations that capture the hidden dynamics between image regions. Experiments demonstrate that ReGAT outperforms prior state-of-the-art approaches on both VQA 2.0 and VQA-CP v2 datasets. We further show that ReGAT is compatible to existing VQA architectures, and can be used as a generic relation encoder to boost the model performance for VQA.",Visual Question Answering : RESEARCH_PROBLEM; Graph Attention : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: In order to answer semantically-complicated questions about an image, a Visual Question Answering (VQA) model needs to fully understand the visual scene in the image, especially the interactive dynamics between different objects. We propose a Relation-aware Graph Attention Network (ReGAT), which encodes each image into a graph and models multi-type inter-object relations via a graph attention mechanism, to learn question-adaptive relation representations. Two types of visual object relations are explored: (i) Explicit Relations that represent geometric positions and semantic interactions between objects; and (ii) Implicit Relations that capture the hidden dynamics between image regions. Experiments demonstrate that ReGAT outperforms prior state-of-the-art approaches on both VQA 2.0 and VQA-CP v2 datasets. We further show that ReGAT is compatible to existing VQA architectures, and can be used as a generic relation encoder to boost the model performance for VQA. ### Response: Visual Question Answering : RESEARCH_PROBLEM; Graph Attention : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Automatic Language Identification (LI) or Dialect Identification (DI) of short texts of closely related languages or dialects, is one of the primary steps in many natural language processing pipelines. Language identification is considered a solved task in many cases; however, in the case of very closely related languages, or in an unsupervised scenario (where the languages are not known in advance), performance is still poor. In this paper, we propose the Unsupervised Deep Language and Dialect Identification (UDLDI) method, which can simultaneously learn sentence embeddings and cluster assignments from short texts. The UDLDI model understands the sentence constructions of languages by applying attention to character relations which helps to optimize the clustering of languages. We have performed our experiments on three short-text datasets for different language families, each consisting of closely related languages or dialects, with very minimal training sets. Our experimental evaluations on these datasets have shown significant improvement over state-of-the-art unsupervised methods and our model has outperformed state-of-the-art LI and DI systems in supervised settings.",Language Identification : RESEARCH_PROBLEM; Dialect Identification : RESEARCH_PROBLEM; Dialect Identification : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Automatic Language Identification (LI) or Dialect Identification (DI) of short texts of closely related languages or dialects, is one of the primary steps in many natural language processing pipelines. Language identification is considered a solved task in many cases; however, in the case of very closely related languages, or in an unsupervised scenario (where the languages are not known in advance), performance is still poor. In this paper, we propose the Unsupervised Deep Language and Dialect Identification (UDLDI) method, which can simultaneously learn sentence embeddings and cluster assignments from short texts. The UDLDI model understands the sentence constructions of languages by applying attention to character relations which helps to optimize the clustering of languages. We have performed our experiments on three short-text datasets for different language families, each consisting of closely related languages or dialects, with very minimal training sets. Our experimental evaluations on these datasets have shown significant improvement over state-of-the-art unsupervised methods and our model has outperformed state-of-the-art LI and DI systems in supervised settings. ### Response: Language Identification : RESEARCH_PROBLEM; Dialect Identification : RESEARCH_PROBLEM; Dialect Identification : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Keyword Extraction is an important task in several text analysis endeavors.In this paper, we present a critical discussion of the issues and challengesingraph-based keyword extraction methods, along with comprehensive empiricalanalysis. We propose a parameterless method for constructing graph of text thatcaptures the contextual relation between words. A novel word scoring method isalso proposed based on the connection between concepts. We demonstrate thatboth proposals are individually superior to those followed by thestate-of-the-art graph-based keyword extraction algorithms. Combination of theproposed graph construction and scoring methods leads to a novel, parameterlesskeyword extraction method (sCAKE) based on semantic connectivity of words inthe document. Motivated by limited availability of NLP tools for several languages, we alsodesign and present a language-agnostic keyword extraction (LAKE) method. Weeliminate the need of NLP tools by using a statistical filter to identifycandidate keywords before constructing the graph. We show that the resultingmethod is a competent solution for extracting keywords from documentsoflanguages lacking sophisticated NLP support.",Keyword Extraction : RESEARCH_PROBLEM; graph construction : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Keyword Extraction is an important task in several text analysis endeavors.In this paper, we present a critical discussion of the issues and challengesingraph-based keyword extraction methods, along with comprehensive empiricalanalysis. We propose a parameterless method for constructing graph of text thatcaptures the contextual relation between words. A novel word scoring method isalso proposed based on the connection between concepts. We demonstrate thatboth proposals are individually superior to those followed by thestate-of-the-art graph-based keyword extraction algorithms. Combination of theproposed graph construction and scoring methods leads to a novel, parameterlesskeyword extraction method (sCAKE) based on semantic connectivity of words inthe document. Motivated by limited availability of NLP tools for several languages, we alsodesign and present a language-agnostic keyword extraction (LAKE) method. Weeliminate the need of NLP tools by using a statistical filter to identifycandidate keywords before constructing the graph. We show that the resultingmethod is a competent solution for extracting keywords from documentsoflanguages lacking sophisticated NLP support. ### Response: Keyword Extraction : RESEARCH_PROBLEM; graph construction : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Recent years have witnessed an upsurge of research interests and applications of machine learning on graphs. Automated machine learning (AutoML ) on graphs is on the horizon to automatically design the optimal machine learning algorithm for a given graph task. However, none of the existing libraries can fully support AutoML on graphs. To fill this gap, we present Automated Graph Learning (AutoGL), the first library for automated machine learning on graphs. AutoGL is open-source, easy to use, and flexible to be extended. Specifically, we propose an automated machine learning pipeline for graph data containing four modules: auto feature engineering, model training, hyper-parameter optimization, and auto ensemble. For each module, we provide numerous state-of-the-art methods and flexible base classes and APIs, which allow easy customization. We further provide experimental results to showcase the usage of our AutoGL library.",(AutoML : RESEARCH_PROBLEM; AutoML : RESEARCH_PROBLEM; Graph Learning : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Recent years have witnessed an upsurge of research interests and applications of machine learning on graphs. Automated machine learning (AutoML ) on graphs is on the horizon to automatically design the optimal machine learning algorithm for a given graph task. However, none of the existing libraries can fully support AutoML on graphs. To fill this gap, we present Automated Graph Learning (AutoGL), the first library for automated machine learning on graphs. AutoGL is open-source, easy to use, and flexible to be extended. Specifically, we propose an automated machine learning pipeline for graph data containing four modules: auto feature engineering, model training, hyper-parameter optimization, and auto ensemble. For each module, we provide numerous state-of-the-art methods and flexible base classes and APIs, which allow easy customization. We further provide experimental results to showcase the usage of our AutoGL library. ### Response: (AutoML : RESEARCH_PROBLEM; AutoML : RESEARCH_PROBLEM; Graph Learning : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","In recent literature, contextual pretrained Language Models (LMs) demonstrated their potential in generalizing the knowledge to several Natural Language Processing (NLP) tasks including supervised Word Sense Disambiguation (WSD), a challenging problem in the field of Natural Language Understanding (NLU). However, word representations from these models are still very dense, costly in terms of memory footprint, as well as minimally interpretable. In order to address such issues, we propose a new supervised biologically inspired technique for transferring large pre-trained language model representations into a compressed representation, for the case of WSD. Our produced representation contributes to increase the general interpretability of the framework and to decrease memory footprint, while enhancing performance.",Word Sense Disambiguation : RESEARCH_PROBLEM; Natural Language Understanding : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: In recent literature, contextual pretrained Language Models (LMs) demonstrated their potential in generalizing the knowledge to several Natural Language Processing (NLP) tasks including supervised Word Sense Disambiguation (WSD), a challenging problem in the field of Natural Language Understanding (NLU). However, word representations from these models are still very dense, costly in terms of memory footprint, as well as minimally interpretable. In order to address such issues, we propose a new supervised biologically inspired technique for transferring large pre-trained language model representations into a compressed representation, for the case of WSD. Our produced representation contributes to increase the general interpretability of the framework and to decrease memory footprint, while enhancing performance. ### Response: Word Sense Disambiguation : RESEARCH_PROBLEM; Natural Language Understanding : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Deformable Image Registration (DIR) can benefit from additional guidance using corresponding landmarks in the images. However, the benefits thereof are largely understudied, especially due to the lack of automatic detection methods for corresponding landmarks in three-dimensional (3D) medical images. In this work, we present a Deep Convolutional Neural Network (DCNN), called DCNN-Match, that learns to predict landmark correspondences in 3D images in a self-supervised manner. We explored five variants of DCNN-Match that use different loss functions and tested DCNN-Match separately as well as in combination with the open-source registration software Elastix to assess its impact on a common DIR approach. We employed lower-abdominal Computed Tomography (CT) scans from cervical cancer patients: 121 pelvic CT scan pairs containing simulated elastic transformations and 11 pairs demonstrating clinical deformations. Our results show significant improvement in DIR performance when landmark correspondences predicted by DCNN-Match were used in case of simulated as well as clinical deformations. We also observed that the spatial distribution of the automatically identified landmarks and the associated matching errors affect the extent of improvement in DIR. Finally, DCNN-Match was found to generalize well to Magnetic Resonance Imaging (MRI) scans without requiring retraining, indicating easy applicability to other datasets.",Image Registration : RESEARCH_PROBLEM; Computed Tomography (CT) : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Deformable Image Registration (DIR) can benefit from additional guidance using corresponding landmarks in the images. However, the benefits thereof are largely understudied, especially due to the lack of automatic detection methods for corresponding landmarks in three-dimensional (3D) medical images. In this work, we present a Deep Convolutional Neural Network (DCNN), called DCNN-Match, that learns to predict landmark correspondences in 3D images in a self-supervised manner. We explored five variants of DCNN-Match that use different loss functions and tested DCNN-Match separately as well as in combination with the open-source registration software Elastix to assess its impact on a common DIR approach. We employed lower-abdominal Computed Tomography (CT) scans from cervical cancer patients: 121 pelvic CT scan pairs containing simulated elastic transformations and 11 pairs demonstrating clinical deformations. Our results show significant improvement in DIR performance when landmark correspondences predicted by DCNN-Match were used in case of simulated as well as clinical deformations. We also observed that the spatial distribution of the automatically identified landmarks and the associated matching errors affect the extent of improvement in DIR. Finally, DCNN-Match was found to generalize well to Magnetic Resonance Imaging (MRI) scans without requiring retraining, indicating easy applicability to other datasets. ### Response: Image Registration : RESEARCH_PROBLEM; Computed Tomography (CT) : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Incorporating external knowledge into Named Entity Recognition (NER ) systems has been widely studied in the generic domain. In this paper, we focus on clinical domain where only limited data is accessible and interpretability is important. Recent advancement in technology and the acceleration of clinical trials has resulted in the discovery of new drugs, procedures as well as medical conditions. These factors motivate towards building robust zero-shot NER systems which can quickly adapt to new medical terminology. We propose an auxiliary gazetteer model and fuse it with an NER system, which results in better robustness and interpretability across different clinical datasets. Our gazetteer based fusion model is data efficient, achieving +1.7 micro-F1 gains on the i2b2 dataset using 20% training data, and brings + 4.7 micro-F1 gains on novel entity mentions never presented during training. Moreover, our fusion model is able to quickly adapt to new mentions in gazetteers without re-training and the gains from the proposed fusion model are transferable to related datasets.",Named Entity Recognition : RESEARCH_PROBLEM; (NER : RESEARCH_PROBLEM; NER : RESEARCH_PROBLEM; NER : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Incorporating external knowledge into Named Entity Recognition (NER ) systems has been widely studied in the generic domain. In this paper, we focus on clinical domain where only limited data is accessible and interpretability is important. Recent advancement in technology and the acceleration of clinical trials has resulted in the discovery of new drugs, procedures as well as medical conditions. These factors motivate towards building robust zero-shot NER systems which can quickly adapt to new medical terminology. We propose an auxiliary gazetteer model and fuse it with an NER system, which results in better robustness and interpretability across different clinical datasets. Our gazetteer based fusion model is data efficient, achieving +1.7 micro-F1 gains on the i2b2 dataset using 20% training data, and brings + 4.7 micro-F1 gains on novel entity mentions never presented during training. Moreover, our fusion model is able to quickly adapt to new mentions in gazetteers without re-training and the gains from the proposed fusion model are transferable to related datasets. ### Response: Named Entity Recognition : RESEARCH_PROBLEM; (NER : RESEARCH_PROBLEM; NER : RESEARCH_PROBLEM; NER : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Benefiting from the powerful expressive capability of graphs, graph-based approaches have achieved impressive performance in various biomedical applications. Most existing methods tend to define the adjacency matrix among samples manually based on meta-features, and then obtain the node embeddings for downstream tasks by Graph Representation Learning (GRL). However, it is not easy for these approaches to generalize to unseen samples. Meanwhile, the complex correlation between modalities is also ignored. As a result, these factors inevitably yield the inadequacy of providing valid information about the patient's condition for a reliable diagnosis. In this paper, we propose an end-to-end Multimodal Graph Learning framework (MMGL) for disease prediction. To effectively exploit the rich information across multi-modality associated with diseases, amodal-attentional multi-modal fusion is proposed to integrate the features of each modality by leveraging the correlation and complementarity between the modalities. Furthermore, instead of defining the adjacency matrix manually as existing methods, the latent graph structure can be captured through a novel way of adaptive graph learning. It could be jointly optimized with the prediction model, thus revealing the intrinsic connections among samples. Unlike the previous transductive methods, our model is also applicable to the scenario of inductive learning for those unseen data. An extensive group of experiments on two disease prediction problems is then carefully designed and presented, demonstrating that MMGL obtains more favorable performances. In addition, we also visualize and analyze the learned graph structure to provide more reliable decision support for doctors in real medical applications and inspiration for disease research.",Graph Representation Learning : RESEARCH_PROBLEM; Graph Learning : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Benefiting from the powerful expressive capability of graphs, graph-based approaches have achieved impressive performance in various biomedical applications. Most existing methods tend to define the adjacency matrix among samples manually based on meta-features, and then obtain the node embeddings for downstream tasks by Graph Representation Learning (GRL). However, it is not easy for these approaches to generalize to unseen samples. Meanwhile, the complex correlation between modalities is also ignored. As a result, these factors inevitably yield the inadequacy of providing valid information about the patient's condition for a reliable diagnosis. In this paper, we propose an end-to-end Multimodal Graph Learning framework (MMGL) for disease prediction. To effectively exploit the rich information across multi-modality associated with diseases, amodal-attentional multi-modal fusion is proposed to integrate the features of each modality by leveraging the correlation and complementarity between the modalities. Furthermore, instead of defining the adjacency matrix manually as existing methods, the latent graph structure can be captured through a novel way of adaptive graph learning. It could be jointly optimized with the prediction model, thus revealing the intrinsic connections among samples. Unlike the previous transductive methods, our model is also applicable to the scenario of inductive learning for those unseen data. An extensive group of experiments on two disease prediction problems is then carefully designed and presented, demonstrating that MMGL obtains more favorable performances. In addition, we also visualize and analyze the learned graph structure to provide more reliable decision support for doctors in real medical applications and inspiration for disease research. ### Response: Graph Representation Learning : RESEARCH_PROBLEM; Graph Learning : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Recent advances in Unsupervised Neural Machine Translation (UNMT) have minimized the gap between supervised and unsupervised machine translation performance for closely related language pairs. However, the situation is very different for distant language pairs. Lack of lexical overlap and low syntactic similarities such as between English and Indo-Aryan languages leads to poor translation quality in existing UNMT systems. In this paper, we show that initializing the embedding layer of UNMT models with cross-lingual embeddings shows significant improvements in BLEU score over existing approaches with embeddings randomly initialized. Further, static embeddings (freezing the embedding layer weights) lead to better gains compared to updating the embedding layer weights during training (non-static). We experimented using Masked Sequence to Sequence (MASS) and Denoising Autoencoder (DAE) UNMT approaches for three distant language pairs. The proposed cross-lingual embedding initialization yields BLEU score improvement of as much as ten times over the baseline for English-Hindi, English-Bengali, and English-Gujarati. Our analysis shows the importance of cross-lingual embedding, comparisons between approaches, and the scope of improvements in these systems.",Machine Translation : RESEARCH_PROBLEM; Denoising : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Recent advances in Unsupervised Neural Machine Translation (UNMT) have minimized the gap between supervised and unsupervised machine translation performance for closely related language pairs. However, the situation is very different for distant language pairs. Lack of lexical overlap and low syntactic similarities such as between English and Indo-Aryan languages leads to poor translation quality in existing UNMT systems. In this paper, we show that initializing the embedding layer of UNMT models with cross-lingual embeddings shows significant improvements in BLEU score over existing approaches with embeddings randomly initialized. Further, static embeddings (freezing the embedding layer weights) lead to better gains compared to updating the embedding layer weights during training (non-static). We experimented using Masked Sequence to Sequence (MASS) and Denoising Autoencoder (DAE) UNMT approaches for three distant language pairs. The proposed cross-lingual embedding initialization yields BLEU score improvement of as much as ten times over the baseline for English-Hindi, English-Bengali, and English-Gujarati. Our analysis shows the importance of cross-lingual embedding, comparisons between approaches, and the scope of improvements in these systems. ### Response: Machine Translation : RESEARCH_PROBLEM; Denoising : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","In the last years, there have been significant developments in the area of Question Answering over Knowledge Graphs (KGQA). Despite all the notable advancements, current KGQA datasets only provide the answers as the direct output result of the formal query, rather than full sentences incorporating question context. For achieving coherent answers sentence with the question's vocabulary, template-based verbalization so are usually employed for a better representation of answers, which in turn require extensive expert intervention. Thus, making way for machine learning approaches; however, there is a scarcity of datasets that empower machine learning models in this area. Hence, we provide the VANiLLa dataset which aims at reducing this gap by offering answers in natural language sentences. The answer sentences in this dataset are syntactically and semantically closer to the question than to the triple fact. Our dataset consists of over 100k simple questions adapted from the CSQA and SimpleQuestionsWikidata datasets and generated using a semi-automatic framework. We also present results of training our dataset on multiple baseline models adapted from current state-of-the-art Natural Language Generation (NLG) architectures. We believe that this dataset will allow researchers to focus on finding suitable methodologies and architectures for answer verbalization.",Question Answering : RESEARCH_PROBLEM; Knowledge Graphs : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: In the last years, there have been significant developments in the area of Question Answering over Knowledge Graphs (KGQA). Despite all the notable advancements, current KGQA datasets only provide the answers as the direct output result of the formal query, rather than full sentences incorporating question context. For achieving coherent answers sentence with the question's vocabulary, template-based verbalization so are usually employed for a better representation of answers, which in turn require extensive expert intervention. Thus, making way for machine learning approaches; however, there is a scarcity of datasets that empower machine learning models in this area. Hence, we provide the VANiLLa dataset which aims at reducing this gap by offering answers in natural language sentences. The answer sentences in this dataset are syntactically and semantically closer to the question than to the triple fact. Our dataset consists of over 100k simple questions adapted from the CSQA and SimpleQuestionsWikidata datasets and generated using a semi-automatic framework. We also present results of training our dataset on multiple baseline models adapted from current state-of-the-art Natural Language Generation (NLG) architectures. We believe that this dataset will allow researchers to focus on finding suitable methodologies and architectures for answer verbalization. ### Response: Question Answering : RESEARCH_PROBLEM; Knowledge Graphs : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Voice assistants provide users a new way of interacting with digital products, allowing them to retrieve information and complete tasks with an increased sense of control and flexibility. Such products are comprised of several machine learning models, like Speech-to-Text transcription, Named Entity Recognition and Resolution, and Text Classification. Building a voice assistant from scratch takes the prolonged efforts of several teams constructing numerous models and orchestrating between components. Alternatives such as using third-party vendors or re-purposing existing models may be considered to shorten time-to-market and development costs. However, each option has its benefits and drawbacks. We present key insights from building a voice search assistant for Booking.com search and recommendation system. Our paper compares the achieved performance and development efforts in dedicated tailor-made solutions against existing re-purposed models. We share and discuss our data-driven decisions about implementation trade-offs and their estimated outcomes in hindsight, showing that a fully functional machine learning product can be built from existing models.",Named Entity Recognition : RESEARCH_PROBLEM; voice assistant : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Voice assistants provide users a new way of interacting with digital products, allowing them to retrieve information and complete tasks with an increased sense of control and flexibility. Such products are comprised of several machine learning models, like Speech-to-Text transcription, Named Entity Recognition and Resolution, and Text Classification. Building a voice assistant from scratch takes the prolonged efforts of several teams constructing numerous models and orchestrating between components. Alternatives such as using third-party vendors or re-purposing existing models may be considered to shorten time-to-market and development costs. However, each option has its benefits and drawbacks. We present key insights from building a voice search assistant for Booking.com search and recommendation system. Our paper compares the achieved performance and development efforts in dedicated tailor-made solutions against existing re-purposed models. We share and discuss our data-driven decisions about implementation trade-offs and their estimated outcomes in hindsight, showing that a fully functional machine learning product can be built from existing models. ### Response: Named Entity Recognition : RESEARCH_PROBLEM; voice assistant : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Robots are becoming everyday devices, increasing their interaction with humans. To make human-machine interaction more natural, cognitive features like Visual Voice Activity Detection (VVAD), which can detect whether a person is speaking or not, given visual input of a camera, need to be implemented. Neural networks are state of the art for tasks in Image Processing, Time Series Prediction, Natural Language Processing and other domains. Those Networks require large quantities of labeled data. Currently there are not many datasets for the task of VVAD. In this work we created a large scale dataset called the VVAD-LRS3 dataset, derived by automatic annotations from the LRS3 dataset. The VVAD-LRS3 dataset contains over 44K samples, over three times the next competitive dataset (WildVVAD). We evaluate different baselines on four kinds of features: facial and lip images, and facial and lip landmark features. With a Convolutional Neural Network Long Short Term Memory (CNN LSTM) on facial images an accuracy of 92% was reached on the test set. A study with humans showed that they reach an accuracy of 87.93% on the test set.",Activity Detection : RESEARCH_PROBLEM; Time Series : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Robots are becoming everyday devices, increasing their interaction with humans. To make human-machine interaction more natural, cognitive features like Visual Voice Activity Detection (VVAD), which can detect whether a person is speaking or not, given visual input of a camera, need to be implemented. Neural networks are state of the art for tasks in Image Processing, Time Series Prediction, Natural Language Processing and other domains. Those Networks require large quantities of labeled data. Currently there are not many datasets for the task of VVAD. In this work we created a large scale dataset called the VVAD-LRS3 dataset, derived by automatic annotations from the LRS3 dataset. The VVAD-LRS3 dataset contains over 44K samples, over three times the next competitive dataset (WildVVAD). We evaluate different baselines on four kinds of features: facial and lip images, and facial and lip landmark features. With a Convolutional Neural Network Long Short Term Memory (CNN LSTM) on facial images an accuracy of 92% was reached on the test set. A study with humans showed that they reach an accuracy of 87.93% on the test set. ### Response: Activity Detection : RESEARCH_PROBLEM; Time Series : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Sound Event Detection and Audio Classification tasks are traditionally addressed through time-frequency representations of audio signals such as spectrograms. However, the emergence of deep neural networks as efficient feature extractors has enabled the direct use of audio signals for classification purposes. In this paper, we attempt to recognize musical instruments in polyphonic audio by only feeding their raw waveforms into deep learning models. Various recurrent and convolutional architectures incorporating residual connections are examined and parameterized in order to build end-to-end classi-fiers with low computational cost and only minimal preprocessing. We obtain competitive classification scores and useful instrument-wise insight through the IRMAS test set, utilizing a parallel CNN-BiGRU model with multiple residual connections, while maintaining a significantly reduced number of trainable parameters.",Sound Event Detection : RESEARCH_PROBLEM; Audio Classification : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Sound Event Detection and Audio Classification tasks are traditionally addressed through time-frequency representations of audio signals such as spectrograms. However, the emergence of deep neural networks as efficient feature extractors has enabled the direct use of audio signals for classification purposes. In this paper, we attempt to recognize musical instruments in polyphonic audio by only feeding their raw waveforms into deep learning models. Various recurrent and convolutional architectures incorporating residual connections are examined and parameterized in order to build end-to-end classi-fiers with low computational cost and only minimal preprocessing. We obtain competitive classification scores and useful instrument-wise insight through the IRMAS test set, utilizing a parallel CNN-BiGRU model with multiple residual connections, while maintaining a significantly reduced number of trainable parameters. ### Response: Sound Event Detection : RESEARCH_PROBLEM; Audio Classification : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","This paper describes Netmarble's submission to WMT21 Automatic Post-Editing (APE) Shared Task for the English-German language pair. First, we propose a Curriculum Training Strategy in training stages. Facebook Fair's WMT19 news translation model was chosen to engage the large and powerful pre-trained neural networks. Then, we post-train the translation model with different levels of data at each training stages. As the training stages go on, we make the system learn to solve multiple tasks by adding extra information at different training stages gradually. We also show a way to utilize the additional data in large volume for APE tasks. For further improvement, we apply Multi-Task Learning Strategy with the Dynamic Weight Average during the fine-tuning stage. To fine-tune the APE corpus with limited data, we add some related subtasks to learn a unified representation. Finally, for better performance, we leverage external translations as augmented machine translation (MT) during the post-training and fine-tuning. As experimental results show, our APE system significantly improves the translations of provided MT results by -2.848 and +3.74 on the development dataset in terms of TER and BLEU, respectively. It also demonstrates its effectiveness on the test dataset with higher quality than the development dataset.",Automatic Post-Editing : RESEARCH_PROBLEM; Multi-Task Learning : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: This paper describes Netmarble's submission to WMT21 Automatic Post-Editing (APE) Shared Task for the English-German language pair. First, we propose a Curriculum Training Strategy in training stages. Facebook Fair's WMT19 news translation model was chosen to engage the large and powerful pre-trained neural networks. Then, we post-train the translation model with different levels of data at each training stages. As the training stages go on, we make the system learn to solve multiple tasks by adding extra information at different training stages gradually. We also show a way to utilize the additional data in large volume for APE tasks. For further improvement, we apply Multi-Task Learning Strategy with the Dynamic Weight Average during the fine-tuning stage. To fine-tune the APE corpus with limited data, we add some related subtasks to learn a unified representation. Finally, for better performance, we leverage external translations as augmented machine translation (MT) during the post-training and fine-tuning. As experimental results show, our APE system significantly improves the translations of provided MT results by -2.848 and +3.74 on the development dataset in terms of TER and BLEU, respectively. It also demonstrates its effectiveness on the test dataset with higher quality than the development dataset. ### Response: Automatic Post-Editing : RESEARCH_PROBLEM; Multi-Task Learning : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","In this paper we propose a new approach to evaluate the informativeness oftranscriptions coming from Automatic Speech Recognition systems. This approach,based in the notion of informativeness, is focused on the framework ofAutomatic Text Summarization performed over these transcriptions. At a firstglance we estimate the informative content of the various automatictranscriptions, then we explore the capacity of Automatic Text Summarization toovercome the informative loss. To do this we use an automatic summaryevaluation protocol without reference (based on the informative content), whichcomputes the divergence between probability distributions of different textualrepresentations: manual and automatic transcriptions and their summaries. Aftera set of evaluations this analysis allowed us to judge both the quality of thetranscriptions in terms of informativeness and to assess the ability ofautomatic text summarization to compensate the problems raised during thetranscription phase.",Speech Recognition : RESEARCH_PROBLEM; Text Summarization : RESEARCH_PROBLEM; Text Summarization : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: In this paper we propose a new approach to evaluate the informativeness oftranscriptions coming from Automatic Speech Recognition systems. This approach,based in the notion of informativeness, is focused on the framework ofAutomatic Text Summarization performed over these transcriptions. At a firstglance we estimate the informative content of the various automatictranscriptions, then we explore the capacity of Automatic Text Summarization toovercome the informative loss. To do this we use an automatic summaryevaluation protocol without reference (based on the informative content), whichcomputes the divergence between probability distributions of different textualrepresentations: manual and automatic transcriptions and their summaries. Aftera set of evaluations this analysis allowed us to judge both the quality of thetranscriptions in terms of informativeness and to assess the ability ofautomatic text summarization to compensate the problems raised during thetranscription phase. ### Response: Speech Recognition : RESEARCH_PROBLEM; Text Summarization : RESEARCH_PROBLEM; Text Summarization : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Conventional spoken language translation (SLT) systems are pipeline based systems, where we have an Automatic Speech Recognition (ASR) system to convert the modality of source from speech to text and a Machine Translation (MT) systems to translate source text to text in target language. Recent progress in the sequence-sequence architectures have reduced the performance gap between the pipeline based SLT systems (cascaded ASR-MT) and End-to-End approaches. Though End-to-End and cascaded ASR-MT systems are reaching to the comparable levels of performances, we can see a large performance gap using the ASR hypothesis and oracle text w.r.t MT models. This performance gap indicates that the MT systems are prone to large performance degradation due to noisy ASR hypothesis as opposed to oracle text transcript. In this work this degradation in the performance is reduced by creating an end to-end differentiable pipeline between the ASR and MT systems. In this work, we train SLT systems with ASR objective as an auxiliary loss and both the networks are connected through the neural hidden representations. This train ing would have an End-to-End differentiable path w.r.t to the final objective function as well as utilize the ASR objective for better performance of the SLT systems. This architecture has improved from BLEU from 36.8 to 44.5. Due to the Multi-task training the model also generates the ASR hypothesis which are used by a pre-trained MT model. Combining the proposed systems with the MT model has increased the BLEU score by 1. All the experiments are reported on English-Portuguese speech translation task using How2 corpus. The final BLEU score is on-par with the best speech translation system on How2 dataset with no additional training data and language model and much less parameters.",Speech Recognition : RESEARCH_PROBLEM; Machine Translation : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Conventional spoken language translation (SLT) systems are pipeline based systems, where we have an Automatic Speech Recognition (ASR) system to convert the modality of source from speech to text and a Machine Translation (MT) systems to translate source text to text in target language. Recent progress in the sequence-sequence architectures have reduced the performance gap between the pipeline based SLT systems (cascaded ASR-MT) and End-to-End approaches. Though End-to-End and cascaded ASR-MT systems are reaching to the comparable levels of performances, we can see a large performance gap using the ASR hypothesis and oracle text w.r.t MT models. This performance gap indicates that the MT systems are prone to large performance degradation due to noisy ASR hypothesis as opposed to oracle text transcript. In this work this degradation in the performance is reduced by creating an end to-end differentiable pipeline between the ASR and MT systems. In this work, we train SLT systems with ASR objective as an auxiliary loss and both the networks are connected through the neural hidden representations. This train ing would have an End-to-End differentiable path w.r.t to the final objective function as well as utilize the ASR objective for better performance of the SLT systems. This architecture has improved from BLEU from 36.8 to 44.5. Due to the Multi-task training the model also generates the ASR hypothesis which are used by a pre-trained MT model. Combining the proposed systems with the MT model has increased the BLEU score by 1. All the experiments are reported on English-Portuguese speech translation task using How2 corpus. The final BLEU score is on-par with the best speech translation system on How2 dataset with no additional training data and language model and much less parameters. ### Response: Speech Recognition : RESEARCH_PROBLEM; Machine Translation : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","In this paper , we tackle Sentiment Analysis conditioned on a Topic inTwitter data using Deep Learning . We propose a 2-tier approach : In the firstphase we create our own Word Embeddings and see that they do perform betterthan state-of-the-art embeddings when used with standard classifiers. We thenperform inference on these embeddings to learn more about a word with respectto all the topics being considered, and also the top n-influencing words foreach topic. In the second phase we use these embeddings to predict thesentiment of the tweet with respect to a given topic, and all other topicsunder discussion.",Sentiment Analysis : RESEARCH_PROBLEM; Word Embeddings : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: In this paper , we tackle Sentiment Analysis conditioned on a Topic inTwitter data using Deep Learning . We propose a 2-tier approach : In the firstphase we create our own Word Embeddings and see that they do perform betterthan state-of-the-art embeddings when used with standard classifiers. We thenperform inference on these embeddings to learn more about a word with respectto all the topics being considered, and also the top n-influencing words foreach topic. In the second phase we use these embeddings to predict thesentiment of the tweet with respect to a given topic, and all other topicsunder discussion. ### Response: Sentiment Analysis : RESEARCH_PROBLEM; Word Embeddings : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Multilingual Neural Machine Translation (MNMT) trains a single NMT model that supports translation between multiple languages, rather than training separate models for different languages. Learning a single model can enhance the low-resource translation by leveraging data from multiple languages. However, the performance of an MNMT model is highly dependent on the type of languages used in training, as transferring knowledge from a diverse set of languages degrades the translation performance due to negative transfer. In this paper, we propose a Hierarchical Knowledge Distillation (HKD) approach for MNMT which capitalises on language groups generated according to typological features and phylogeny of languages to overcome the issue of negative transfer. HKD generates a set of multilingual teacher-assistant models via a selective knowledge distillation mechanism based on the language groups, and then distils the ultimate multilingual model from those assistants in an adaptive way. Experimental results derived from the TED dataset with 53 languages demonstrate the effectiveness of our approach in avoiding the negative transfer effect in MNMT, leading to an improved translation performance (about 1 BLEU score on average) compared to strong baselines.",Machine Translation : RESEARCH_PROBLEM; Knowledge Distillation : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Multilingual Neural Machine Translation (MNMT) trains a single NMT model that supports translation between multiple languages, rather than training separate models for different languages. Learning a single model can enhance the low-resource translation by leveraging data from multiple languages. However, the performance of an MNMT model is highly dependent on the type of languages used in training, as transferring knowledge from a diverse set of languages degrades the translation performance due to negative transfer. In this paper, we propose a Hierarchical Knowledge Distillation (HKD) approach for MNMT which capitalises on language groups generated according to typological features and phylogeny of languages to overcome the issue of negative transfer. HKD generates a set of multilingual teacher-assistant models via a selective knowledge distillation mechanism based on the language groups, and then distils the ultimate multilingual model from those assistants in an adaptive way. Experimental results derived from the TED dataset with 53 languages demonstrate the effectiveness of our approach in avoiding the negative transfer effect in MNMT, leading to an improved translation performance (about 1 BLEU score on average) compared to strong baselines. ### Response: Machine Translation : RESEARCH_PROBLEM; Knowledge Distillation : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Image classification with deep neural networks is typically restricted to images of small dimensionality such as 224 x 244 in Resnet models [24]. This limitation excludes the 4000 x 3000 dimensional images that are taken by modern smartphone cameras and smart devices. In this work, we aim to mitigate the prohibitive inferential and memory costs of operating in such large dimensional spaces. To sample from the high-resolution original input distribution, we propose using a smaller proxy distribution to learn the co-ordinates that correspond to regions of interest in the high-dimensional space. We introduce a new principled variational lower bound that captures the relationship of the proxy distribution's posterior and the original image's co-ordinate space in a way that maximizes the conditional classification likelihood. We empirically demonstrate on one synthetic benchmark and one real world large resolution DSLR camera image dataset that our method produces comparable results with ~10x faster inference and lower memory consumption than a model that utilizes the entire original input distribution. Finally, we experiment with a more complex setting using mini-maps from Starcraft II [56] to infer the number of characters in a complex 3d-rendered scene. Even in such complicated scenes our model provides strong localization: a feature missing from traditional classification models.",Starcraft II : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Image classification with deep neural networks is typically restricted to images of small dimensionality such as 224 x 244 in Resnet models [24]. This limitation excludes the 4000 x 3000 dimensional images that are taken by modern smartphone cameras and smart devices. In this work, we aim to mitigate the prohibitive inferential and memory costs of operating in such large dimensional spaces. To sample from the high-resolution original input distribution, we propose using a smaller proxy distribution to learn the co-ordinates that correspond to regions of interest in the high-dimensional space. We introduce a new principled variational lower bound that captures the relationship of the proxy distribution's posterior and the original image's co-ordinate space in a way that maximizes the conditional classification likelihood. We empirically demonstrate on one synthetic benchmark and one real world large resolution DSLR camera image dataset that our method produces comparable results with ~10x faster inference and lower memory consumption than a model that utilizes the entire original input distribution. Finally, we experiment with a more complex setting using mini-maps from Starcraft II [56] to infer the number of characters in a complex 3d-rendered scene. Even in such complicated scenes our model provides strong localization: a feature missing from traditional classification models. ### Response: Starcraft II : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Spoken Dialogue Systems (SDS) have great commercial potential as they promise to revolutionise the way in which humans interact with machines. The advent of deep learning led to substantial developments in this area of NLP research, and the goal of this tutorial is to familiarise the research community with the recent advances in what some call the most difficult problem in NLP. From a research perspective, the design of spoken dialogue systems provides a number of significant challenges, as these systems depend on: a) solving several difficult NLP and decision-making tasks; and b) combining these into a functional dialogue system pipeline. A key long-term goal of dialogue system research is to enable open-domain systems that can converse about arbitrary topics and assist humans with completing a wide range of tasks. Furthermore, such systems need to autonomously learn on-line to improve their performance and recover from errors using both signals from their environment and from implicit and explicit user feedback. While the design of such systems has traditionally been modular, domain and language-specific, advances in deep learning have alleviated many of the design problems. The main purpose of this tutorial is to encourage dialogue research in the NLP community by providing the research background, a survey of available resources, and giving key insights to application of state-of-the-art SDS methodology into industry-scale conversational AI systems. We plan to introduce researchers to the pipeline framework for modelling goal-oriented dialogue systems, which includes three key components: 1) Language Understanding; 2) Dialogue Management; and 3) Language Generation. The differences between goal-oriented dialogue systems and chat-bot style conversational agents will be explained in order to show the motivation behind the design of both, with the main focus on the pipeline SDS framework. For each key component, we will define the research problem, provide a brief literature review and introduce the current state-of-the-art approaches. Complementary resources (e.g. available datasets and toolkits) will also be discussed. Finally, future work, outstanding challenges, and current industry practices will be presented. All of the presented material will be made available online for future reference.",Spoken Dialogue Systems : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Spoken Dialogue Systems (SDS) have great commercial potential as they promise to revolutionise the way in which humans interact with machines. The advent of deep learning led to substantial developments in this area of NLP research, and the goal of this tutorial is to familiarise the research community with the recent advances in what some call the most difficult problem in NLP. From a research perspective, the design of spoken dialogue systems provides a number of significant challenges, as these systems depend on: a) solving several difficult NLP and decision-making tasks; and b) combining these into a functional dialogue system pipeline. A key long-term goal of dialogue system research is to enable open-domain systems that can converse about arbitrary topics and assist humans with completing a wide range of tasks. Furthermore, such systems need to autonomously learn on-line to improve their performance and recover from errors using both signals from their environment and from implicit and explicit user feedback. While the design of such systems has traditionally been modular, domain and language-specific, advances in deep learning have alleviated many of the design problems. The main purpose of this tutorial is to encourage dialogue research in the NLP community by providing the research background, a survey of available resources, and giving key insights to application of state-of-the-art SDS methodology into industry-scale conversational AI systems. We plan to introduce researchers to the pipeline framework for modelling goal-oriented dialogue systems, which includes three key components: 1) Language Understanding; 2) Dialogue Management; and 3) Language Generation. The differences between goal-oriented dialogue systems and chat-bot style conversational agents will be explained in order to show the motivation behind the design of both, with the main focus on the pipeline SDS framework. For each key component, we will define the research problem, provide a brief literature review and introduce the current state-of-the-art approaches. Complementary resources (e.g. available datasets and toolkits) will also be discussed. Finally, future work, outstanding challenges, and current industry practices will be presented. All of the presented material will be made available online for future reference. ### Response: Spoken Dialogue Systems : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","The use of the internet as a fast medium of spreading fake news reinforces the need for computational tools that combat it. Techniques that train fake news classifiers exist, but they all assume an abundance of resources including large labeled datasets and expert-curated corpora, which low-resource languages may not have. In this work, we make two main contributions: First, we alleviate resource scarcity by constructing the first expertly-curated benchmark dataset for fake news detection in Filipino, which we call ""Fake News Filipino."" Second, we benchmark Transfer Learning (TL) techniques and show that they can be used to train robust fake news classifiers from little data, achieving 91% accuracy on our fake news dataset, reducing the error by 14% compared to established few-shot baselines. Furthermore, lifting ideas from multitask learning, we show that augmenting transformer-based transfer techniques with auxiliary language modeling losses improves their performance by adapting to writing style. Using this, we improve TL performance by 4-6%, achieving an accuracy of 96% on our best model. Lastly, we show that our method generalizes well to different types of news articles, including political news, entertainment news, and opinion articles.",Transfer Learning : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: The use of the internet as a fast medium of spreading fake news reinforces the need for computational tools that combat it. Techniques that train fake news classifiers exist, but they all assume an abundance of resources including large labeled datasets and expert-curated corpora, which low-resource languages may not have. In this work, we make two main contributions: First, we alleviate resource scarcity by constructing the first expertly-curated benchmark dataset for fake news detection in Filipino, which we call ""Fake News Filipino."" Second, we benchmark Transfer Learning (TL) techniques and show that they can be used to train robust fake news classifiers from little data, achieving 91% accuracy on our fake news dataset, reducing the error by 14% compared to established few-shot baselines. Furthermore, lifting ideas from multitask learning, we show that augmenting transformer-based transfer techniques with auxiliary language modeling losses improves their performance by adapting to writing style. Using this, we improve TL performance by 4-6%, achieving an accuracy of 96% on our best model. Lastly, we show that our method generalizes well to different types of news articles, including political news, entertainment news, and opinion articles. ### Response: Transfer Learning : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Multimodal Sentiment Analysis (MuSe) 2021 is a challenge focusing on the tasks of sentiment and emotion, as well as physiological-emotion and emotion-based stress recognition through more comprehensively integrating the audio-visual, language, and biological signal modalities. The purpose of MuSe 2021 is to bring together communities from different disciplines; mainly, the audio-visual emotion recognition community (signal-based), the sentiment analysis community (symbol-based), and the health informatics community. We present four distinct sub-challenges: MuSe-Wilder and MuSe-Stress which focus on continuous emotion (valence and arousal) prediction; MuSe-Sent, in which participants recognise five classes each for valence and arousal; and MuSe-Physio, in which the novel aspect of `physiological-emotion' is to be predicted. For this years' challenge, we utilise the MuSe-CaR dataset focusing on user-generated reviews and introduce the Ulm-TSST dataset, which displays people in stressful depositions. This paper also provides detail on the state-of-the-art feature sets extracted from these datasets for utilisation by our baseline model, a Long Short-Term Memory-Recurrent Neural Network. For each sub-challenge, a competitive baseline for participants is set; namely, on test, we report a Concordance Correlation Coefficient (CCC) of .4616 CCC for MuSe-Wilder; .4717 CCC for MuSe-Stress, and .4606 CCC for MuSe-Physio. For MuSe-Sent an F1 score of 32.82 % is obtained.",Multimodal Sentiment Analysis : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Multimodal Sentiment Analysis (MuSe) 2021 is a challenge focusing on the tasks of sentiment and emotion, as well as physiological-emotion and emotion-based stress recognition through more comprehensively integrating the audio-visual, language, and biological signal modalities. The purpose of MuSe 2021 is to bring together communities from different disciplines; mainly, the audio-visual emotion recognition community (signal-based), the sentiment analysis community (symbol-based), and the health informatics community. We present four distinct sub-challenges: MuSe-Wilder and MuSe-Stress which focus on continuous emotion (valence and arousal) prediction; MuSe-Sent, in which participants recognise five classes each for valence and arousal; and MuSe-Physio, in which the novel aspect of `physiological-emotion' is to be predicted. For this years' challenge, we utilise the MuSe-CaR dataset focusing on user-generated reviews and introduce the Ulm-TSST dataset, which displays people in stressful depositions. This paper also provides detail on the state-of-the-art feature sets extracted from these datasets for utilisation by our baseline model, a Long Short-Term Memory-Recurrent Neural Network. For each sub-challenge, a competitive baseline for participants is set; namely, on test, we report a Concordance Correlation Coefficient (CCC) of .4616 CCC for MuSe-Wilder; .4717 CCC for MuSe-Stress, and .4606 CCC for MuSe-Physio. For MuSe-Sent an F1 score of 32.82 % is obtained. ### Response: Multimodal Sentiment Analysis : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Unsupervised and semi-supervised learning are important problems that are especially challenging with complex data like natural images. Progress on these problems would accelerate if we had access to appropriate generative models under which to pose the associated inference tasks. Inspired by the success of Convolutional Neural Networks (CNNs) for supervised prediction in images, we design the Neural Rendering Model (NRM), a new hierarchical probabilistic generative model whose inference calculations correspond to those in a CNN. The NRM introduces a small set of latent variables at each level of the model and enforces dependencies among all the latent variables via a conjugate prior distribution. The conjugate prior yields a new regularizer for learning based on the paths rendered in the generative model for training CNNs?the Rendering Path Normalization (RPN). We demonstrate that this regularizer improves generalization both in theory and in practice. Likelihood estimation in the NRM yields the new Max-Min cross entropy training loss, which suggests a new deep network architecture?the Max- Min network?which exceeds or matches the state-of-art for semi-supervised and supervised learning on SVHN, CIFAR10, and CIFAR100.",Neural Rendering : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Unsupervised and semi-supervised learning are important problems that are especially challenging with complex data like natural images. Progress on these problems would accelerate if we had access to appropriate generative models under which to pose the associated inference tasks. Inspired by the success of Convolutional Neural Networks (CNNs) for supervised prediction in images, we design the Neural Rendering Model (NRM), a new hierarchical probabilistic generative model whose inference calculations correspond to those in a CNN. The NRM introduces a small set of latent variables at each level of the model and enforces dependencies among all the latent variables via a conjugate prior distribution. The conjugate prior yields a new regularizer for learning based on the paths rendered in the generative model for training CNNs?the Rendering Path Normalization (RPN). We demonstrate that this regularizer improves generalization both in theory and in practice. Likelihood estimation in the NRM yields the new Max-Min cross entropy training loss, which suggests a new deep network architecture?the Max- Min network?which exceeds or matches the state-of-art for semi-supervised and supervised learning on SVHN, CIFAR10, and CIFAR100. ### Response: Neural Rendering : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET",In this paper we describe a non-expert setup for Vietnamese speech recognition system using Kaldi toolkit. We collected a speech corpus over fifteen hours from about fifty Vietnamese native speakers and using it to test the feasibility of our setup. The essential linguistic components for the Automatic Speech Recognition (ASR) system was prepared basing on the written form of the language instead of expertise knowledge on linguistic and phonology as commonly seen in rich resource languages like English. The modeling of tones by integrating them into the phoneme and using the phonetic decision tree is also discussed. Experimental results showed this setup for ASR systems does yield competitive results while still have potentials for further improvements.,Speech Recognition : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: In this paper we describe a non-expert setup for Vietnamese speech recognition system using Kaldi toolkit. We collected a speech corpus over fifteen hours from about fifty Vietnamese native speakers and using it to test the feasibility of our setup. The essential linguistic components for the Automatic Speech Recognition (ASR) system was prepared basing on the written form of the language instead of expertise knowledge on linguistic and phonology as commonly seen in rich resource languages like English. The modeling of tones by integrating them into the phoneme and using the phonetic decision tree is also discussed. Experimental results showed this setup for ASR systems does yield competitive results while still have potentials for further improvements. ### Response: Speech Recognition : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","This work attempts to tackle the problem of domain generalization (DG) via learning to reduce domain shift with an episodic training procedure. In particular, we measure the domain shift with $\mathcal{Y}$-discrepancy and learn to optimize $\mathcal{Y}$-discrepancy between the unseen target domain and source domains only using source-domain samples. Theoretically, we give a PAC-style generalization bound for discrepancy-optimal meta-learning and further make comparisons with other DG bounds including ERM and domain-invariant learning. The theoretical analyses show that there is a tradeoff between classification performance and computational complexity for discrepancy-optimal meta-learning. The theoretical results also shed light on a bilevel optimization algorithm for DG. Empirically, we evaluate the algorithm with DomainBed and achieves state-of-the-art results on two DG benchmarks.",bilevel optimization : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: This work attempts to tackle the problem of domain generalization (DG) via learning to reduce domain shift with an episodic training procedure. In particular, we measure the domain shift with $\mathcal{Y}$-discrepancy and learn to optimize $\mathcal{Y}$-discrepancy between the unseen target domain and source domains only using source-domain samples. Theoretically, we give a PAC-style generalization bound for discrepancy-optimal meta-learning and further make comparisons with other DG bounds including ERM and domain-invariant learning. The theoretical analyses show that there is a tradeoff between classification performance and computational complexity for discrepancy-optimal meta-learning. The theoretical results also shed light on a bilevel optimization algorithm for DG. Empirically, we evaluate the algorithm with DomainBed and achieves state-of-the-art results on two DG benchmarks. ### Response: bilevel optimization : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Automatic License Plate Recognition (ALPR) is a challenging area of researchdue to its importance to variety of commercial applications. The overallproblem may be subdivided into two key modules, firstly, localization oflicense plates from vehicle images, and secondly, optical character recognitionof extracted license plates. In the current work, we have concentrated on thefirst part of the problem, i.e., localization of license plate regions fromIndian commercial vehicles as a significant step towards development of acomplete ALPR system for Indian vehicles. The technique is based on color basedsegmentation of vehicle images and identification of potential license plateregions. True license plates are finally localized based on four spatial andhorizontal contrast features. The technique successfully localizes the actuallicense plates in 73.4% images.",License Plate Recognition : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Automatic License Plate Recognition (ALPR) is a challenging area of researchdue to its importance to variety of commercial applications. The overallproblem may be subdivided into two key modules, firstly, localization oflicense plates from vehicle images, and secondly, optical character recognitionof extracted license plates. In the current work, we have concentrated on thefirst part of the problem, i.e., localization of license plate regions fromIndian commercial vehicles as a significant step towards development of acomplete ALPR system for Indian vehicles. The technique is based on color basedsegmentation of vehicle images and identification of potential license plateregions. True license plates are finally localized based on four spatial andhorizontal contrast features. The technique successfully localizes the actuallicense plates in 73.4% images. ### Response: License Plate Recognition : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Accuracy predictor is a key component in Neural Architecture Search (NAS) for ranking architectures. Building a high-quality accuracy predictor usually costs enormous computation. To address this issue, instead of using an accuracy predictor, we propose a novel zero-shot index dubbed Zen-Score to rank the architectures. The Zen-Score represents the network expressivity and positively correlates with the model accuracy. The calculation of Zen-Score only takes a few forward inferences through a randomly initialized network, without training network parameters. Built upon the Zen-Score, we further propose a new NAS algorithm, termed as Zen-NAS, by maximizing the Zen-Score of the target network under given inference budgets. Within less than half GPU day, Zen-NAS is able to directly search high performance architectures in a data-free style. Comparing with previous NAS methods, the proposed Zen-NAS is magnitude times faster on multiple server-side and mobile-side GPU platforms with state-of-the-art accuracy on ImageNet. Searching and training code as well as pre-trained models are available from https://github.com/idstcv/ZenNAS.",Neural Architecture Search : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Accuracy predictor is a key component in Neural Architecture Search (NAS) for ranking architectures. Building a high-quality accuracy predictor usually costs enormous computation. To address this issue, instead of using an accuracy predictor, we propose a novel zero-shot index dubbed Zen-Score to rank the architectures. The Zen-Score represents the network expressivity and positively correlates with the model accuracy. The calculation of Zen-Score only takes a few forward inferences through a randomly initialized network, without training network parameters. Built upon the Zen-Score, we further propose a new NAS algorithm, termed as Zen-NAS, by maximizing the Zen-Score of the target network under given inference budgets. Within less than half GPU day, Zen-NAS is able to directly search high performance architectures in a data-free style. Comparing with previous NAS methods, the proposed Zen-NAS is magnitude times faster on multiple server-side and mobile-side GPU platforms with state-of-the-art accuracy on ImageNet. Searching and training code as well as pre-trained models are available from https://github.com/idstcv/ZenNAS. ### Response: Neural Architecture Search : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Recently, along with the rapid development of mobile communication technology, edge computing theory and techniques have been attracting more and more attentions from global researchers and engineers, which can significantly bridge the capacity of cloud and requirement of devices by the network edges, and thus can accelerate the content deliveries and improve the quality of mobile services. In order to bring more intelligence to the edge systems, compared to traditional optimization methodology, and driven by the current deep learning techniques, we propose to integrate the Deep Reinforcement Learning techniques and Federated Learning framework with the mobile edge systems, for optimizing the mobile edge computing, caching and communication. And thus, we design the ""In-Edge AI"" framework in order to intelligently utilize the collaboration among devices and edge nodes to exchange the learning parameters for a better training and inference of the models, and thus to carry out dynamic system-level optimization and application-level enhancement while reducing the unnecessary system communication load. ""In-Edge AI"" is evaluated and proved to have near-optimal performance but relatively low overhead of learning, while the system is cognitive and adaptive to the mobile communication systems. Finally, we discuss several related challenges and opportunities for unveiling a promising upcoming future of ""In-Edge AI"".",Federated Learning : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Recently, along with the rapid development of mobile communication technology, edge computing theory and techniques have been attracting more and more attentions from global researchers and engineers, which can significantly bridge the capacity of cloud and requirement of devices by the network edges, and thus can accelerate the content deliveries and improve the quality of mobile services. In order to bring more intelligence to the edge systems, compared to traditional optimization methodology, and driven by the current deep learning techniques, we propose to integrate the Deep Reinforcement Learning techniques and Federated Learning framework with the mobile edge systems, for optimizing the mobile edge computing, caching and communication. And thus, we design the ""In-Edge AI"" framework in order to intelligently utilize the collaboration among devices and edge nodes to exchange the learning parameters for a better training and inference of the models, and thus to carry out dynamic system-level optimization and application-level enhancement while reducing the unnecessary system communication load. ""In-Edge AI"" is evaluated and proved to have near-optimal performance but relatively low overhead of learning, while the system is cognitive and adaptive to the mobile communication systems. Finally, we discuss several related challenges and opportunities for unveiling a promising upcoming future of ""In-Edge AI"". ### Response: Federated Learning : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","We propose a framework for compressing state-of-the-art Single Shot MultiBoxDetector (SSD). The framework addresses compression in the following stages:Sparsity Induction, Filter Selection, and Filter Pruning. In the SparsityInduction stage, the object detector model is sparsified via an improved globalthreshold. In Filter Selection & Pruning stage, we select and remove filtersusing sparsity statistics of filter weights in two consecutive convolutionallayers. This results in the model with the size smaller than most existingcompact architectures. We evaluate the performance of our framework withmultiple datasets and compare over multiple methods. Experimental results showthat our method achieves state-of-the-art compression of 6.7X and 4.9X onPASCAL VOC dataset on models SSD300 and SSD512 respectively. We further showthat the method produces maximum compression of 26X with SSD512 on GermanTraffic Sign Detection Benchmark (GTSDB). Additionally, we also empiricallyshow our method's adaptability for classification based architecture VGG16 ondatasets CIFAR and German Traffic Sign Recognition Benchmark (GTSRB) achievinga compression rate of 125X and 200X with the reduction in flops by 90.50% and96.6% respectively with no loss of accuracy. In addition to this, our methoddoes not require any special libraries or hardware support for the resultingcompressed models.",Traffic Sign Recognition : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: We propose a framework for compressing state-of-the-art Single Shot MultiBoxDetector (SSD). The framework addresses compression in the following stages:Sparsity Induction, Filter Selection, and Filter Pruning. In the SparsityInduction stage, the object detector model is sparsified via an improved globalthreshold. In Filter Selection & Pruning stage, we select and remove filtersusing sparsity statistics of filter weights in two consecutive convolutionallayers. This results in the model with the size smaller than most existingcompact architectures. We evaluate the performance of our framework withmultiple datasets and compare over multiple methods. Experimental results showthat our method achieves state-of-the-art compression of 6.7X and 4.9X onPASCAL VOC dataset on models SSD300 and SSD512 respectively. We further showthat the method produces maximum compression of 26X with SSD512 on GermanTraffic Sign Detection Benchmark (GTSDB). Additionally, we also empiricallyshow our method's adaptability for classification based architecture VGG16 ondatasets CIFAR and German Traffic Sign Recognition Benchmark (GTSRB) achievinga compression rate of 125X and 200X with the reduction in flops by 90.50% and96.6% respectively with no loss of accuracy. In addition to this, our methoddoes not require any special libraries or hardware support for the resultingcompressed models. ### Response: Traffic Sign Recognition : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Models with transparent inner structure and high classification performance are required to reduce potential risk and provide trust for users in domains like health care, finance, security, etc. However, existing models are hard to simultaneously satisfy the above two properties. In this paper, we propose a new hierarchical rule-based model for classification tasks, named Concept Rule Sets (CRS), which has both a strong expressive ability and a transparent inner structure. To address the challenge of efficiently learning the non-differentiable CRS model, we propose a novel neural network architecture, Multilayer Logical Perceptron (MLLP), which is a continuous version of CRS. Using MLLP and the Random Binarization (RB) method we proposed, we can search the discrete solution of CRS in continuous space using gradient descent and ensure the discrete CRS acts almost the same as the corresponding continuous MLLP. Experiments on 12 public data sets show that CRS outperforms the state-of-the-art approaches and the complexity of the learned CRS is close to the simple decision tree. Source code is available at https://github.com/12wang3/mllp.",Binarization : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Models with transparent inner structure and high classification performance are required to reduce potential risk and provide trust for users in domains like health care, finance, security, etc. However, existing models are hard to simultaneously satisfy the above two properties. In this paper, we propose a new hierarchical rule-based model for classification tasks, named Concept Rule Sets (CRS), which has both a strong expressive ability and a transparent inner structure. To address the challenge of efficiently learning the non-differentiable CRS model, we propose a novel neural network architecture, Multilayer Logical Perceptron (MLLP), which is a continuous version of CRS. Using MLLP and the Random Binarization (RB) method we proposed, we can search the discrete solution of CRS in continuous space using gradient descent and ensure the discrete CRS acts almost the same as the corresponding continuous MLLP. Experiments on 12 public data sets show that CRS outperforms the state-of-the-art approaches and the complexity of the learned CRS is close to the simple decision tree. Source code is available at https://github.com/12wang3/mllp. ### Response: Binarization : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Federated Learning (FL) is a privacy-protected machine learning paradigm that allows model to be trained directly at the edge without uploading data. One of the biggest challenges faced by FL in practical applications is the heterogeneity of edge node data, which will slow down the convergence speed and degrade the performance of the model. For the above problems, a representative solution is to add additional constraints in the local training, such as FedProx, FedCurv and FedCL. However, the above algorithms still have room for improvement. We propose to use the aggregation of all models obtained in the past as new constraint target to further improve the performance of such algorithms. Experiments in various settings demonstrate that our method significantly improves the convergence speed and performance of the model.",Federated Learning : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Federated Learning (FL) is a privacy-protected machine learning paradigm that allows model to be trained directly at the edge without uploading data. One of the biggest challenges faced by FL in practical applications is the heterogeneity of edge node data, which will slow down the convergence speed and degrade the performance of the model. For the above problems, a representative solution is to add additional constraints in the local training, such as FedProx, FedCurv and FedCL. However, the above algorithms still have room for improvement. We propose to use the aggregation of all models obtained in the past as new constraint target to further improve the performance of such algorithms. Experiments in various settings demonstrate that our method significantly improves the convergence speed and performance of the model. ### Response: Federated Learning : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Ordinal Classification (OC) is an important classification task where the classes are ordinal. For example, an OC task for sentiment analysis could have the following classes: highly positive, positive, neutral, negative, highly negative. Clearly, evaluation measures for an OC task should penalise misclassifications by considering the ordinal nature of the classes. Ordinal Quantification (OQ) is a related task where the gold data is a distribution over ordinal classes, and the system is required to estimate this distribution. Evaluation measures for an OQ task should also take the ordinal nature of the classes into account. However, for both OC and OQ, there are only a small number of known evaluation measures that meet this basic requirement. In the present study, we utilise data from the SemEval and NTCIR communities to clarify the properties of nine evaluation measures in the context of OC tasks, and six measures in the context of OQ tasks.",Classification : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Ordinal Classification (OC) is an important classification task where the classes are ordinal. For example, an OC task for sentiment analysis could have the following classes: highly positive, positive, neutral, negative, highly negative. Clearly, evaluation measures for an OC task should penalise misclassifications by considering the ordinal nature of the classes. Ordinal Quantification (OQ) is a related task where the gold data is a distribution over ordinal classes, and the system is required to estimate this distribution. Evaluation measures for an OQ task should also take the ordinal nature of the classes into account. However, for both OC and OQ, there are only a small number of known evaluation measures that meet this basic requirement. In the present study, we utilise data from the SemEval and NTCIR communities to clarify the properties of nine evaluation measures in the context of OC tasks, and six measures in the context of OQ tasks. ### Response: Classification : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","With the aim of promoting and understanding the multilingual version of image search, we leverage visual object detection and propose a model with diverse multi-head attention to learn grounded multilingual multimodal representations. Specifically, our model attends to different types of textual semantics in two languages and visual objects for fine-grained alignments between sentences and images. We introduce a new objective function which explicitly encourages attention diversity to learn an improved visual-semantic embedding space. We evaluate our model in the German-Image and English-Image matching tasks on the Multi30K dataset, and in the Semantic Textual Similarity task with the English descriptions of visual content. Results show that our model yields a significant performance gain over other methods in all of the three tasks.",Semantic Textual Similarity : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: With the aim of promoting and understanding the multilingual version of image search, we leverage visual object detection and propose a model with diverse multi-head attention to learn grounded multilingual multimodal representations. Specifically, our model attends to different types of textual semantics in two languages and visual objects for fine-grained alignments between sentences and images. We introduce a new objective function which explicitly encourages attention diversity to learn an improved visual-semantic embedding space. We evaluate our model in the German-Image and English-Image matching tasks on the Multi30K dataset, and in the Semantic Textual Similarity task with the English descriptions of visual content. Results show that our model yields a significant performance gain over other methods in all of the three tasks. ### Response: Semantic Textual Similarity : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Supervised contour detection methods usually require many labeled trainingimages to obtain satisfactory performance. However, a large set of annotateddata might be unavailable or extremely labor intensive. In this paper, weinvestigate the usage of semi-supervised learning (SSL) to obtain competitivedetection accuracy with very limited training data (three labeled images).Specifically, we propose a semi-supervised structured ensemble learningapproach for contour detection built on structured random forests (SRF). Toallow SRF to be applicable to unlabeled data, we present an effective sparserepresentation approach to capture inherent structure in image patches byfinding a compact and discriminative low-dimensional subspace representation inan unsupervised manner, enabling the incorporation of abundant unlabeledpatches with their estimated structured labels to help SRF perform better nodesplitting. We re-examine the role of sparsity and propose a novel and fastsparse coding algorithm to boost the overall learning efficiency. To the bestof our knowledge, this is the first attempt to apply SSL for contour detection.Extensive experiments on the BSDS500 segmentation dataset and the NYU Depthdataset demonstrate the superiority of the proposed method.",BSDS500 : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Supervised contour detection methods usually require many labeled trainingimages to obtain satisfactory performance. However, a large set of annotateddata might be unavailable or extremely labor intensive. In this paper, weinvestigate the usage of semi-supervised learning (SSL) to obtain competitivedetection accuracy with very limited training data (three labeled images).Specifically, we propose a semi-supervised structured ensemble learningapproach for contour detection built on structured random forests (SRF). Toallow SRF to be applicable to unlabeled data, we present an effective sparserepresentation approach to capture inherent structure in image patches byfinding a compact and discriminative low-dimensional subspace representation inan unsupervised manner, enabling the incorporation of abundant unlabeledpatches with their estimated structured labels to help SRF perform better nodesplitting. We re-examine the role of sparsity and propose a novel and fastsparse coding algorithm to boost the overall learning efficiency. To the bestof our knowledge, this is the first attempt to apply SSL for contour detection.Extensive experiments on the BSDS500 segmentation dataset and the NYU Depthdataset demonstrate the superiority of the proposed method. ### Response: BSDS500 : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","We investigate the problem of recovering a partially observed high-rank matrix whose columns obey a nonlinear structure such as a union of subspaces, an algebraic variety or grouped in clusters. The recovery problem is formulated as the rank minimization of a nonlinear feature map applied to the original matrix, which is then further approximated by a constrained non-convex optimization problem involving the Grassmann manifold. We propose two sets of algorithms, one arising from Riemannian optimization and the other as an alternating minimization scheme, both of which include first- and second-order variants. Both sets of algorithms have theoretical guarantees. In particular, for the alternating minimization, we establish global convergence and worst-case complexity bounds. Additionally, using the Kurdyka-Lojasiewicz property, we show that the alternating minimization converges to a unique limit point. We provide extensive numerical results for the recovery of union of subspaces and clustering under entry sampling and dense Gaussian sampling. Our methods are competitive with existing approaches and, in particular, high accuracy is achieved in the recovery using Riemannian second-order methods.",Riemannian optimization : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: We investigate the problem of recovering a partially observed high-rank matrix whose columns obey a nonlinear structure such as a union of subspaces, an algebraic variety or grouped in clusters. The recovery problem is formulated as the rank minimization of a nonlinear feature map applied to the original matrix, which is then further approximated by a constrained non-convex optimization problem involving the Grassmann manifold. We propose two sets of algorithms, one arising from Riemannian optimization and the other as an alternating minimization scheme, both of which include first- and second-order variants. Both sets of algorithms have theoretical guarantees. In particular, for the alternating minimization, we establish global convergence and worst-case complexity bounds. Additionally, using the Kurdyka-Lojasiewicz property, we show that the alternating minimization converges to a unique limit point. We provide extensive numerical results for the recovery of union of subspaces and clustering under entry sampling and dense Gaussian sampling. Our methods are competitive with existing approaches and, in particular, high accuracy is achieved in the recovery using Riemannian second-order methods. ### Response: Riemannian optimization : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","There is mounting evidence of a link between the properties ofelectroencephalograms (EEG s) of depressive patients and the outcome ofpharmacotherapy. The goal of this study was to develop an EEG biomarker ofantidepressant treatment response which would require only a single EEG measurement. We recorded resting, 21-channel EEG in 17 inpatients sufferingfrom bipolar depression in eyes closed and eyes open conditions. The EEG measurement was performed at the end of the short washout period which followedpreviously unsuccessful pharmacotherapy. We calculated the normalized waveletpower of alpha rhythm using two referential montages and an average referencemontage. In particular, in the occipital (O1, O2, Oz) channels the waveletpower of responders was up to 84% higher than that of nonresponders. Using anovel classification algorithm we were able to correctly predict the outcome oftreatment with 90% sensitivity and 100% specificity. The proposed biomarkerrequires only a single EEG measurement and consequently is intrinsicallydifferent from biomarkers which exploit the changes in prefrontal EEG inducedby pharmacotherapy over a given time.",(EEG : RESEARCH_PROBLEM; EEG : RESEARCH_PROBLEM; EEG : RESEARCH_PROBLEM; EEG : RESEARCH_PROBLEM; EEG : RESEARCH_PROBLEM; EEG : RESEARCH_PROBLEM; EEG : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: There is mounting evidence of a link between the properties ofelectroencephalograms (EEG s) of depressive patients and the outcome ofpharmacotherapy. The goal of this study was to develop an EEG biomarker ofantidepressant treatment response which would require only a single EEG measurement. We recorded resting, 21-channel EEG in 17 inpatients sufferingfrom bipolar depression in eyes closed and eyes open conditions. The EEG measurement was performed at the end of the short washout period which followedpreviously unsuccessful pharmacotherapy. We calculated the normalized waveletpower of alpha rhythm using two referential montages and an average referencemontage. In particular, in the occipital (O1, O2, Oz) channels the waveletpower of responders was up to 84% higher than that of nonresponders. Using anovel classification algorithm we were able to correctly predict the outcome oftreatment with 90% sensitivity and 100% specificity. The proposed biomarkerrequires only a single EEG measurement and consequently is intrinsicallydifferent from biomarkers which exploit the changes in prefrontal EEG inducedby pharmacotherapy over a given time. ### Response: (EEG : RESEARCH_PROBLEM; EEG : RESEARCH_PROBLEM; EEG : RESEARCH_PROBLEM; EEG : RESEARCH_PROBLEM; EEG : RESEARCH_PROBLEM; EEG : RESEARCH_PROBLEM; EEG : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Classification of partially occluded images is a highly challenging computer vision problem even for the cutting edge deep learning technologies. To achieve a robust image classification for occluded images, this paper proposes a novel scheme using subspace decomposition based estimation (SDBE). The proposed SDBE-based classification scheme first employs a base convolutional neural network to extract the deep feature vector (DFV) and then utilizes the SDBE to compute the DFV of the original occlusion-free image for classification. The SDBE is performed by projecting the DFV of the occluded image onto the linear span of a class dictionary (CD) along the linear span of an occlusion error dictionary (OED). The CD and OED are constructed respectively by concatenating the DFVs of a training set and the occlusion error vectors of an extra set of image pairs. Two implementations of the SDBE are studied in this paper: the $l_1$-norm and the squared $l_2$-norm regularized least-squares estimates. By employing the ResNet-152, pre-trained on the ILSVRC2012 training set, as the base network, the proposed SBDE-based classification scheme is extensively evaluated on the Caltech-101 and ILSVRC2012 datasets. Extensive experimental results demonstrate that the proposed SDBE-based scheme dramatically boosts the classification accuracy for occluded images, and achieves around $22.25\%$ increase in classification accuracy under $20\%$ occlusion on the ILSVRC2012 dataset.",Classification : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Classification of partially occluded images is a highly challenging computer vision problem even for the cutting edge deep learning technologies. To achieve a robust image classification for occluded images, this paper proposes a novel scheme using subspace decomposition based estimation (SDBE). The proposed SDBE-based classification scheme first employs a base convolutional neural network to extract the deep feature vector (DFV) and then utilizes the SDBE to compute the DFV of the original occlusion-free image for classification. The SDBE is performed by projecting the DFV of the occluded image onto the linear span of a class dictionary (CD) along the linear span of an occlusion error dictionary (OED). The CD and OED are constructed respectively by concatenating the DFVs of a training set and the occlusion error vectors of an extra set of image pairs. Two implementations of the SDBE are studied in this paper: the $l_1$-norm and the squared $l_2$-norm regularized least-squares estimates. By employing the ResNet-152, pre-trained on the ILSVRC2012 training set, as the base network, the proposed SBDE-based classification scheme is extensively evaluated on the Caltech-101 and ILSVRC2012 datasets. Extensive experimental results demonstrate that the proposed SDBE-based scheme dramatically boosts the classification accuracy for occluded images, and achieves around $22.25\%$ increase in classification accuracy under $20\%$ occlusion on the ILSVRC2012 dataset. ### Response: Classification : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","In this study we estimate the heart rate from face videos for student assessment. This information could be very valuable to track their status along time and also to estimate other data such as their attention level or the presence of stress that may be caused by cheating attempts. The recent edBBplat, a platform for student behavior modelling in remote education, is considered in this study1. This platform permits to capture several signals from a set of sensors that capture biometric and behavioral data: RGB and near infrared cameras, microphone, EEG band, mouse, smartwatch, and keyboard, among others. In the experimental framework of this study, we focus on the RGB and near-infrared video sequences for performing heart rate estimation applying remote photoplethysmography techniques. The experiments include behavioral and physiological data from 25 different students completing a collection of tasks related to e-learning. Our proposed face heart rate estimation approach is compared with the heart rate provided by the smartwatch, achieving very promising results for its future deployment in e-learning applications.",EEG : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: In this study we estimate the heart rate from face videos for student assessment. This information could be very valuable to track their status along time and also to estimate other data such as their attention level or the presence of stress that may be caused by cheating attempts. The recent edBBplat, a platform for student behavior modelling in remote education, is considered in this study1. This platform permits to capture several signals from a set of sensors that capture biometric and behavioral data: RGB and near infrared cameras, microphone, EEG band, mouse, smartwatch, and keyboard, among others. In the experimental framework of this study, we focus on the RGB and near-infrared video sequences for performing heart rate estimation applying remote photoplethysmography techniques. The experiments include behavioral and physiological data from 25 different students completing a collection of tasks related to e-learning. Our proposed face heart rate estimation approach is compared with the heart rate provided by the smartwatch, achieving very promising results for its future deployment in e-learning applications. ### Response: EEG : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Communication complexity and privacy are the two key challenges in Federated Learning where the goal is to perform a distributed learning through a large volume of devices. In this work, we introduce FedSKETCH and FedSKETCHGATE algorithms to address both challenges in Federated learning jointly, where these algorithms are intended to be used for homogeneous and heterogeneous data distribution settings respectively. The key idea is to compress the accumulation of local gradients using count sketch, therefore, the server does not have access to the gradients themselves which provides privacy. Furthermore, due to the lower dimension of sketching used, our method exhibits communication-efficiency property as well. We provide, for the aforementioned schemes, sharp convergence guarantees. Finally, we back up our theory with various set of experiments.",Federated Learning : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Communication complexity and privacy are the two key challenges in Federated Learning where the goal is to perform a distributed learning through a large volume of devices. In this work, we introduce FedSKETCH and FedSKETCHGATE algorithms to address both challenges in Federated learning jointly, where these algorithms are intended to be used for homogeneous and heterogeneous data distribution settings respectively. The key idea is to compress the accumulation of local gradients using count sketch, therefore, the server does not have access to the gradients themselves which provides privacy. Furthermore, due to the lower dimension of sketching used, our method exhibits communication-efficiency property as well. We provide, for the aforementioned schemes, sharp convergence guarantees. Finally, we back up our theory with various set of experiments. ### Response: Federated Learning : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Predicting the future motion of vehicles has been studied using various techniques, including stochastic policies, generative models, and regression. Recent work has shown that classification over a trajectory set, which approximates possible motions, achieves state-of-the-art performance and avoids issues like mode collapse. However, map information and the physical relationships between nearby trajectories is not fully exploited in this formulation. We build on classification-based approaches to motion prediction by adding an auxiliary loss that penalizes off-road predictions. This auxiliary loss can easily be pretrained using only map information (e.g., off-road area), which significantly improves performance on small datasets. We also investigate weighted cross-entropy losses to capture spatial-temporal relationships among trajectories. Our final contribution is a detailed comparison of classification and ordinal regression on two public self-driving datasets.",motion prediction : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Predicting the future motion of vehicles has been studied using various techniques, including stochastic policies, generative models, and regression. Recent work has shown that classification over a trajectory set, which approximates possible motions, achieves state-of-the-art performance and avoids issues like mode collapse. However, map information and the physical relationships between nearby trajectories is not fully exploited in this formulation. We build on classification-based approaches to motion prediction by adding an auxiliary loss that penalizes off-road predictions. This auxiliary loss can easily be pretrained using only map information (e.g., off-road area), which significantly improves performance on small datasets. We also investigate weighted cross-entropy losses to capture spatial-temporal relationships among trajectories. Our final contribution is a detailed comparison of classification and ordinal regression on two public self-driving datasets. ### Response: motion prediction : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","We study the problem of named entity recognition (NER ) from electronicmedical records, which is one of the most fundamental and critical problems formedical text mining. Medical records which are written by clinicians fromdifferent specialties usually contain quite different terminologies and writingstyles. The difference of specialties and the cost of human annotation makes itparticularly difficult to train a universal medical NER system. In this paper,we propose a label-aware double transfer learning framework (La-DTL) forcross-specialty NER , so that a medical NER system designed for one specialtycould be conveniently applied to another one with minimal annotation efforts.The transferability is guaranteed by two components: (i) we propose label-awareMMD for feature representation transfer, and (ii) we perform parameter transferwith a theoretical upper bound which is also label aware. We conduct extensiveexperiments on 12 cross-specialty NER tasks. The experimental resultsdemonstrate that La-DTL provides consistent accuracy improvement over strongbaselines. Besides, the promising experimental results on non-medical NER scenarios indicate that La-DTL is potential to be seamlessly adapted to a widerange of NER tasks.",(NER : RESEARCH_PROBLEM; NER : RESEARCH_PROBLEM; NER : RESEARCH_PROBLEM; NER : RESEARCH_PROBLEM; NER : RESEARCH_PROBLEM; NER : RESEARCH_PROBLEM; NER : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: We study the problem of named entity recognition (NER ) from electronicmedical records, which is one of the most fundamental and critical problems formedical text mining. Medical records which are written by clinicians fromdifferent specialties usually contain quite different terminologies and writingstyles. The difference of specialties and the cost of human annotation makes itparticularly difficult to train a universal medical NER system. In this paper,we propose a label-aware double transfer learning framework (La-DTL) forcross-specialty NER , so that a medical NER system designed for one specialtycould be conveniently applied to another one with minimal annotation efforts.The transferability is guaranteed by two components: (i) we propose label-awareMMD for feature representation transfer, and (ii) we perform parameter transferwith a theoretical upper bound which is also label aware. We conduct extensiveexperiments on 12 cross-specialty NER tasks. The experimental resultsdemonstrate that La-DTL provides consistent accuracy improvement over strongbaselines. Besides, the promising experimental results on non-medical NER scenarios indicate that La-DTL is potential to be seamlessly adapted to a widerange of NER tasks. ### Response: (NER : RESEARCH_PROBLEM; NER : RESEARCH_PROBLEM; NER : RESEARCH_PROBLEM; NER : RESEARCH_PROBLEM; NER : RESEARCH_PROBLEM; NER : RESEARCH_PROBLEM; NER : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","In Autonomous Driving (AD) systems, perception is both security and safety critical. Despite various prior studies on its security issues, all of them only consider attacks on camera- or LiDAR-based AD perception alone. However, production AD systems today predominantly adopt a Multi-Sensor Fusion (MSF) based design, which in principle can be more robust against these attacks under the assumption that not all fusion sources are (or can be) attacked at the same time. In this paper, we present the first study of security issues of MSF-based perception in AD systems. We directly challenge the basic MSF design assumption above by exploring the possibility of attacking all fusion sources simultaneously. This allows us for the first time to understand how much security guarantee MSF can fundamentally provide as a general defense strategy for AD perception. We formulate the attack as an optimization problem to generate a physically-realizable, adversarial 3D-printed object that misleads an AD system to fail in detecting it and thus crash into it. We propose a novel attack pipeline that addresses two main design challenges: (1) non-differentiable target camera and LiDAR sensing systems, and (2) non-differentiable cell-level aggregated features popularly used in LiDAR-based AD perception. We evaluate our attack on MSF included in representative open-source industry-grade AD systems in real-world driving scenarios. Our results show that the attack achieves over 90% success rate across different object types and MSF. Our attack is also found stealthy, robust to victim positions, transferable across MSF algorithms, and physical-world realizable after being 3D-printed and captured by LiDAR and camera devices. To concretely assess the end-to-end safety impact, we further perform simulation evaluation and show that it can cause a 100% vehicle collision rate for an industry-grade AD system.",Autonomous Driving : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: In Autonomous Driving (AD) systems, perception is both security and safety critical. Despite various prior studies on its security issues, all of them only consider attacks on camera- or LiDAR-based AD perception alone. However, production AD systems today predominantly adopt a Multi-Sensor Fusion (MSF) based design, which in principle can be more robust against these attacks under the assumption that not all fusion sources are (or can be) attacked at the same time. In this paper, we present the first study of security issues of MSF-based perception in AD systems. We directly challenge the basic MSF design assumption above by exploring the possibility of attacking all fusion sources simultaneously. This allows us for the first time to understand how much security guarantee MSF can fundamentally provide as a general defense strategy for AD perception. We formulate the attack as an optimization problem to generate a physically-realizable, adversarial 3D-printed object that misleads an AD system to fail in detecting it and thus crash into it. We propose a novel attack pipeline that addresses two main design challenges: (1) non-differentiable target camera and LiDAR sensing systems, and (2) non-differentiable cell-level aggregated features popularly used in LiDAR-based AD perception. We evaluate our attack on MSF included in representative open-source industry-grade AD systems in real-world driving scenarios. Our results show that the attack achieves over 90% success rate across different object types and MSF. Our attack is also found stealthy, robust to victim positions, transferable across MSF algorithms, and physical-world realizable after being 3D-printed and captured by LiDAR and camera devices. To concretely assess the end-to-end safety impact, we further perform simulation evaluation and show that it can cause a 100% vehicle collision rate for an industry-grade AD system. ### Response: Autonomous Driving : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Ultrasound (US) is a non-invasive yet effective medical diagnostic imaging technique for the COVID-19 global pandemic. However, due to complex feature behaviors and expensive annotations of US images, it is difficult to apply Artificial Intelligence (AI) assisting approaches for lung's multi-symptom (multi-label) classification. To overcome these difficulties, we propose a novel semi-supervised Two-Stream Active Learning (TSAL) method to model complicated features and reduce labeling costs in an iterative procedure. The core component of TSAL is the multi-label learning mechanism, in which label correlations information is used to design multi-label margin (MLM) strategy and confidence validation for automatically selecting informative samples and confident labels. On this basis, a multi-symptom multi-label (MSML) classification network is proposed to learn discriminative features of lung symptoms, and a human-machine interaction is exploited to confirm the final annotations that are used to fine-tune MSML with progressively labeled data. Moreover, a novel lung US dataset named COVID19-LUSMS is built, currently containing 71 clinical patients with 6,836 images sampled from 678 videos. Experimental evaluations show that TSAL using only 20% data can achieve superior performance to the baseline and the state-of-the-art. Qualitatively, visualization of both attention map and sample distribution confirms the good consistency with the clinic knowledge.",Active Learning : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Ultrasound (US) is a non-invasive yet effective medical diagnostic imaging technique for the COVID-19 global pandemic. However, due to complex feature behaviors and expensive annotations of US images, it is difficult to apply Artificial Intelligence (AI) assisting approaches for lung's multi-symptom (multi-label) classification. To overcome these difficulties, we propose a novel semi-supervised Two-Stream Active Learning (TSAL) method to model complicated features and reduce labeling costs in an iterative procedure. The core component of TSAL is the multi-label learning mechanism, in which label correlations information is used to design multi-label margin (MLM) strategy and confidence validation for automatically selecting informative samples and confident labels. On this basis, a multi-symptom multi-label (MSML) classification network is proposed to learn discriminative features of lung symptoms, and a human-machine interaction is exploited to confirm the final annotations that are used to fine-tune MSML with progressively labeled data. Moreover, a novel lung US dataset named COVID19-LUSMS is built, currently containing 71 clinical patients with 6,836 images sampled from 678 videos. Experimental evaluations show that TSAL using only 20% data can achieve superior performance to the baseline and the state-of-the-art. Qualitatively, visualization of both attention map and sample distribution confirms the good consistency with the clinic knowledge. ### Response: Active Learning : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Envisioning a new imaginative idea together is a popular human need. Imagining together as a team can often lead to breakthrough ideas, but the collaboration effort can also be challenging, especially when the team members are separated by time and space. What if there is a AI that can assist the team to collaboratively envision new ideas?. Is it possible to develop a working model of such an AI? This paper aims to design such an intelligence. This paper proposes a approach to design a creative and collaborative intelligence by employing a form of distributed machine learning approach called Federated Learning along with fusion on Generative Adversarial Networks, GAN. This collaborative creative AI presents a new paradigm in AI, one that lets a team of two or more to come together to imagine and envision ideas that synergies well with interests of all members of the team. In short, this paper explores the design of a novel type of AI paradigm, called Federated AI Imagination, one that lets geographically distributed teams to collaboratively imagine.",Federated Learning : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Envisioning a new imaginative idea together is a popular human need. Imagining together as a team can often lead to breakthrough ideas, but the collaboration effort can also be challenging, especially when the team members are separated by time and space. What if there is a AI that can assist the team to collaboratively envision new ideas?. Is it possible to develop a working model of such an AI? This paper aims to design such an intelligence. This paper proposes a approach to design a creative and collaborative intelligence by employing a form of distributed machine learning approach called Federated Learning along with fusion on Generative Adversarial Networks, GAN. This collaborative creative AI presents a new paradigm in AI, one that lets a team of two or more to come together to imagine and envision ideas that synergies well with interests of all members of the team. In short, this paper explores the design of a novel type of AI paradigm, called Federated AI Imagination, one that lets geographically distributed teams to collaboratively imagine. ### Response: Federated Learning : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Latest insights from biology show that intelligence does not only emerge from the connections between the neurons, but that individual neurons shoulder more computational responsibility. Current Neural Network architecture design and search are biased on fixed activation functions. Using more advanced learnable activation functions provide Neural Networks with higher learning capacity. However, general guidance for building such networks is still missing. In this work, we first explain why rationals offer an optimal choice for activation functions. We then show that they are closed under residual connections, and inspired by recurrence for residual networks we derive a self-regularized version of Rationals: Recurrent Rationals. We demonstrate that (Recurrent) Rational Networks lead to high performance improvements on Image Classification and Deep Reinforcement Learning.",Image Classification : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Latest insights from biology show that intelligence does not only emerge from the connections between the neurons, but that individual neurons shoulder more computational responsibility. Current Neural Network architecture design and search are biased on fixed activation functions. Using more advanced learnable activation functions provide Neural Networks with higher learning capacity. However, general guidance for building such networks is still missing. In this work, we first explain why rationals offer an optimal choice for activation functions. We then show that they are closed under residual connections, and inspired by recurrence for residual networks we derive a self-regularized version of Rationals: Recurrent Rationals. We demonstrate that (Recurrent) Rational Networks lead to high performance improvements on Image Classification and Deep Reinforcement Learning. ### Response: Image Classification : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Quantization techniques can reduce the size of Deep Neural Networks and improve inference latency and throughput by taking advantage of high throughput integer instructions. In this paper we review the mathematical aspects of quantization parameters and evaluate their choices on a wide range of neural network models for different application domains, including vision, speech, and language. We focus on quantization techniques that are amenable to acceleration by processors with high-throughput integer math pipelines. We also present a workflow for 8-bit quantization that is able to maintain accuracy within 1% of the floating-point baseline on all networks studied, including models that are more difficult to quantize, such as MobileNets and BERT-large.",Quantization : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Quantization techniques can reduce the size of Deep Neural Networks and improve inference latency and throughput by taking advantage of high throughput integer instructions. In this paper we review the mathematical aspects of quantization parameters and evaluate their choices on a wide range of neural network models for different application domains, including vision, speech, and language. We focus on quantization techniques that are amenable to acceleration by processors with high-throughput integer math pipelines. We also present a workflow for 8-bit quantization that is able to maintain accuracy within 1% of the floating-point baseline on all networks studied, including models that are more difficult to quantize, such as MobileNets and BERT-large. ### Response: Quantization : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Causal discovery, i.e., inferring underlying cause-effect relationships from observations of a scene or system, is an inherent mechanism in human cognition, but has been shown to be highly challenging to automate. The majority of approaches in the literature aiming for this task consider constrained scenarios with fully observed variables or data from stationary time-series. In this work we aim for causal discovery in a more general class of scenarios, scenes with non-stationary behavior over time. For our purposes we here regard a scene as a composition objects interacting with each other over time. Non-stationarity is modeled as stationarity conditioned on an underlying variable, a state, which can be of varying dimension, more or less hidden given observations of the scene, and also depend more or less directly on these observations. We propose a probabilistic deep learning approach called State-Dependent Causal Inference (SDCI) for causal discovery in such conditionally stationary time-series data. Results in two different synthetic scenarios show that this method is able to recover the underlying causal dependencies with high accuracy even in cases with hidden states.",Causal Inference : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Causal discovery, i.e., inferring underlying cause-effect relationships from observations of a scene or system, is an inherent mechanism in human cognition, but has been shown to be highly challenging to automate. The majority of approaches in the literature aiming for this task consider constrained scenarios with fully observed variables or data from stationary time-series. In this work we aim for causal discovery in a more general class of scenarios, scenes with non-stationary behavior over time. For our purposes we here regard a scene as a composition objects interacting with each other over time. Non-stationarity is modeled as stationarity conditioned on an underlying variable, a state, which can be of varying dimension, more or less hidden given observations of the scene, and also depend more or less directly on these observations. We propose a probabilistic deep learning approach called State-Dependent Causal Inference (SDCI) for causal discovery in such conditionally stationary time-series data. Results in two different synthetic scenarios show that this method is able to recover the underlying causal dependencies with high accuracy even in cases with hidden states. ### Response: Causal Inference : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","In various cases of decision analysis we use two popular methods: Analytical Hierarchical Process (AHP) and Fuzzy based AHP or Fuzzy AHP. Both the methods deal with stochastic data and can determine decision result through Multi Criteria Decision Making (MCDM) process. Obviously resulting values of the two methods are not same though same set of data is fed into them. In this research work, we have tried to observe similarities and dissimilarities between two methods outputs. Almost same trend or fluctuations in outputs have been seen for both methods for same set of input data which are not consistent. Both method outputs ups and down fluctuations are same for fifty percent cases.",Decision Making : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: In various cases of decision analysis we use two popular methods: Analytical Hierarchical Process (AHP) and Fuzzy based AHP or Fuzzy AHP. Both the methods deal with stochastic data and can determine decision result through Multi Criteria Decision Making (MCDM) process. Obviously resulting values of the two methods are not same though same set of data is fed into them. In this research work, we have tried to observe similarities and dissimilarities between two methods outputs. Almost same trend or fluctuations in outputs have been seen for both methods for same set of input data which are not consistent. Both method outputs ups and down fluctuations are same for fifty percent cases. ### Response: Decision Making : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Deep Gaussian Processes (DGPs) were proposed as an expressive Bayesian model capable of a mathematically grounded estimation of uncertainty. The expressivity of DPGs results from not only the compositional character but the distribution propagation within the hierarchy. Recently, [1] pointed out that the hierarchical structure of DGP well suited modeling the multi-fidelity regression, in which one is provided sparse observations with high precision and plenty of low fidelity observations. We propose the conditional DGP model in which the latent GPs are directly supported by the fixed lower fidelity data. Then the moment matching method in [2] is applied to approximate the marginal prior of conditional DGP with a GP. The obtained effective kernels are implicit functions of the lower-fidelity data, manifesting the expressivity contributed by distribution propagation within the hierarchy. The hyperparameters are learned via optimizing the approximate marginal likelihood. Experiments with synthetic and high dimensional data show comparable performance against other multi-fidelity regression methods, variational inference, and multi-output GP. We conclude that, with the low fidelity data and the hierarchical DGP structure, the effective kernel encodes the inductive bias for true function allowing the compositional freedom discussed in [3,4].",Gaussian Processes : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Deep Gaussian Processes (DGPs) were proposed as an expressive Bayesian model capable of a mathematically grounded estimation of uncertainty. The expressivity of DPGs results from not only the compositional character but the distribution propagation within the hierarchy. Recently, [1] pointed out that the hierarchical structure of DGP well suited modeling the multi-fidelity regression, in which one is provided sparse observations with high precision and plenty of low fidelity observations. We propose the conditional DGP model in which the latent GPs are directly supported by the fixed lower fidelity data. Then the moment matching method in [2] is applied to approximate the marginal prior of conditional DGP with a GP. The obtained effective kernels are implicit functions of the lower-fidelity data, manifesting the expressivity contributed by distribution propagation within the hierarchy. The hyperparameters are learned via optimizing the approximate marginal likelihood. Experiments with synthetic and high dimensional data show comparable performance against other multi-fidelity regression methods, variational inference, and multi-output GP. We conclude that, with the low fidelity data and the hierarchical DGP structure, the effective kernel encodes the inductive bias for true function allowing the compositional freedom discussed in [3,4]. ### Response: Gaussian Processes : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Translation is a central biological process by which proteins are synthesizedfrom genetic information contained within mRNAs. Here we study the kinetics oftranslation at molecular level through a stochastic simulation model. The modelexplicitly include RNA sequences, ribosome dynamics, tRNA pool and biochemicalreactions in the translation elongation. The results show that the translationefficiency is mainly limited by the available ribosome number, translationinitiation and the translation elongation time. The elongation time islog-normal distribution with mean and variance determined by both the codonsaturation and the process of aa-tRNA selection at each codon binding.Moreover, our simulations show that the translation accuracy exponentiallydecreases with the sequence length. These results suggest that aa-tRNAcompetition is crucial for both translation elongation, translation efficiencyand the accuracy, which in turn determined the effective protein productionrate of correct proteins. Our results improve the dynamical equation of proteinproduction with a delay differential equation which is dependent on sequenceinformations through both the effective production rate and the distribution ofelongation time.",Translation : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Translation is a central biological process by which proteins are synthesizedfrom genetic information contained within mRNAs. Here we study the kinetics oftranslation at molecular level through a stochastic simulation model. The modelexplicitly include RNA sequences, ribosome dynamics, tRNA pool and biochemicalreactions in the translation elongation. The results show that the translationefficiency is mainly limited by the available ribosome number, translationinitiation and the translation elongation time. The elongation time islog-normal distribution with mean and variance determined by both the codonsaturation and the process of aa-tRNA selection at each codon binding.Moreover, our simulations show that the translation accuracy exponentiallydecreases with the sequence length. These results suggest that aa-tRNAcompetition is crucial for both translation elongation, translation efficiencyand the accuracy, which in turn determined the effective protein productionrate of correct proteins. Our results improve the dynamical equation of proteinproduction with a delay differential equation which is dependent on sequenceinformations through both the effective production rate and the distribution ofelongation time. ### Response: Translation : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Image classification has always been a hot and challenging task. This paper is a brief report to our submission to the VIPriors Image Classification Challenge. In this challenge, the difficulty is how to train the model from scratch without any pretrained weight. In our method, several strong backbones and multiple loss functions are used to learn more representative features. To improve the models' generalization and robustness, efficient image augmentation strategies are utilized, like autoaugment and cutmix. Finally, ensemble learning is used to increase the performance of the models. The final Top-1 accuracy of our team DeepBlueAI is 0.7015, ranking second in the leaderboard.",Image Classification : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Image classification has always been a hot and challenging task. This paper is a brief report to our submission to the VIPriors Image Classification Challenge. In this challenge, the difficulty is how to train the model from scratch without any pretrained weight. In our method, several strong backbones and multiple loss functions are used to learn more representative features. To improve the models' generalization and robustness, efficient image augmentation strategies are utilized, like autoaugment and cutmix. Finally, ensemble learning is used to increase the performance of the models. The final Top-1 accuracy of our team DeepBlueAI is 0.7015, ranking second in the leaderboard. ### Response: Image Classification : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Weakly Supervised Object Detection (WSOD) has emerged as an effective tool to train object detectors using only the image-level category labels. However, without object-level labels, WSOD detectors are prone to detect bounding boxes on salient objects, clustered objects and discriminative object parts. Moreover, the image-level category labels do not enforce consistent object detection across different transformations of the same images. To address the above issues, we propose a Comprehensive Attention Self-Distillation (CASD) training approach for WSOD. To balance feature learning among all object instances, CASD computes the comprehensive attention aggregated from multiple transformations and feature layers of the same images. To enforce consistent spatial supervision on objects, CASD conducts self-distillation on the WSOD networks, such that the comprehensive attention is approximated simultaneously by multiple transformations and feature layers of the same images. CASD produces new state-of-the-art WSOD results on standard benchmarks such as PASCAL VOC 2007/2012 and MS-COCO.",Weakly Supervised Object Detection : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Weakly Supervised Object Detection (WSOD) has emerged as an effective tool to train object detectors using only the image-level category labels. However, without object-level labels, WSOD detectors are prone to detect bounding boxes on salient objects, clustered objects and discriminative object parts. Moreover, the image-level category labels do not enforce consistent object detection across different transformations of the same images. To address the above issues, we propose a Comprehensive Attention Self-Distillation (CASD) training approach for WSOD. To balance feature learning among all object instances, CASD computes the comprehensive attention aggregated from multiple transformations and feature layers of the same images. To enforce consistent spatial supervision on objects, CASD conducts self-distillation on the WSOD networks, such that the comprehensive attention is approximated simultaneously by multiple transformations and feature layers of the same images. CASD produces new state-of-the-art WSOD results on standard benchmarks such as PASCAL VOC 2007/2012 and MS-COCO. ### Response: Weakly Supervised Object Detection : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","This paper describes SalamNET, an Arabic offensive language detection system that has been submitted to SemEval 2020 shared task 12: Multilingual Offensive Language Identification in Social Media. Our approach focuses on applying multiple deep learning models and conducting in depth error analysis of results to provide system implications for future development considerations. To pursue our goal, a Recurrent Neural Network (RNN), a Gated Recurrent Unit (GRU), and Long-Short Term Memory (LSTM) models with different design architectures have been developed and evaluated. The SalamNET, a Bi-directional Gated Recurrent Unit (Bi-GRU) based model, reports a macro-F1 score of 0.83.",Language Identification : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: This paper describes SalamNET, an Arabic offensive language detection system that has been submitted to SemEval 2020 shared task 12: Multilingual Offensive Language Identification in Social Media. Our approach focuses on applying multiple deep learning models and conducting in depth error analysis of results to provide system implications for future development considerations. To pursue our goal, a Recurrent Neural Network (RNN), a Gated Recurrent Unit (GRU), and Long-Short Term Memory (LSTM) models with different design architectures have been developed and evaluated. The SalamNET, a Bi-directional Gated Recurrent Unit (Bi-GRU) based model, reports a macro-F1 score of 0.83. ### Response: Language Identification : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Deep Convolutional Neural Network (CNN) is a special type of Neural Networks, which has shown exemplary performance on several competitions related to Computer Vision and Image Processing. Some of the exciting application areas of CNN include Image Classification and Segmentation, Object Detection, Video Processing, Natural Language Processing, and Speech Recognition. The powerful learning ability of deep CNN is primarily due to the use of multiple feature extraction stages that can automatically learn representations from the data. The availability of a large amount of data and improvement in the hardware technology has accelerated the research in CNNs, and recently interesting deep CNN architectures have been reported. Several inspiring ideas to bring advancements in CNNs have been explored, such as the use of different activation and loss functions, parameter optimization, regularization, and architectural innovations. However, the significant improvement in the representational capacity of the deep CNN is achieved through architectural innovations. Notably, the ideas of exploiting spatial and channel information, depth and width of architecture, and multi-path information processing have gained substantial attention. Similarly, the idea of using a block of layers as a structural unit is also gaining popularity. This survey thus focuses on the intrinsic taxonomy present in the recently reported deep CNN architectures and, consequently, classifies the recent innovations in CNN architectures into seven different categories. These seven categories are based on spatial exploitation, depth, multi-path, width, feature-map exploitation, channel boosting, and attention. Additionally, the elementary understanding of CNN components, current challenges, and applications of CNN are also provided.",Image Classification : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Deep Convolutional Neural Network (CNN) is a special type of Neural Networks, which has shown exemplary performance on several competitions related to Computer Vision and Image Processing. Some of the exciting application areas of CNN include Image Classification and Segmentation, Object Detection, Video Processing, Natural Language Processing, and Speech Recognition. The powerful learning ability of deep CNN is primarily due to the use of multiple feature extraction stages that can automatically learn representations from the data. The availability of a large amount of data and improvement in the hardware technology has accelerated the research in CNNs, and recently interesting deep CNN architectures have been reported. Several inspiring ideas to bring advancements in CNNs have been explored, such as the use of different activation and loss functions, parameter optimization, regularization, and architectural innovations. However, the significant improvement in the representational capacity of the deep CNN is achieved through architectural innovations. Notably, the ideas of exploiting spatial and channel information, depth and width of architecture, and multi-path information processing have gained substantial attention. Similarly, the idea of using a block of layers as a structural unit is also gaining popularity. This survey thus focuses on the intrinsic taxonomy present in the recently reported deep CNN architectures and, consequently, classifies the recent innovations in CNN architectures into seven different categories. These seven categories are based on spatial exploitation, depth, multi-path, width, feature-map exploitation, channel boosting, and attention. Additionally, the elementary understanding of CNN components, current challenges, and applications of CNN are also provided. ### Response: Image Classification : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Neural network models are resource hungry. It is difficult to deploy such deep networks on devices with limited resources, like smart wearables, cellphones, drones, and autonomous vehicles. Low bit quantization such as binary and ternary quantization is a common approach to alleviate this resource requirements. Ternary quantization provides a more flexible model and outperforms binary quantization in terms of accuracy, however doubles the memory footprint and increases the computational cost. Contrary to these approaches, mixed quantized models allow a trade-off between accuracy and memory footprint. In such models, quantization depth is often chosen manually, or is tuned using a separate optimization routine. The latter requires training a quantized network multiple times. Here, we propose an adaptive combination of binary and ternary quantization, namely Smart Quantization (SQ), in which the quantization depth is modified directly via a regularization function, so that the model is trained only once. Our experimental results show that the proposed method adapts quantization depth successfully while keeping the model accuracy high on MNIST and CIFAR10 benchmarks.",Quantization : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Neural network models are resource hungry. It is difficult to deploy such deep networks on devices with limited resources, like smart wearables, cellphones, drones, and autonomous vehicles. Low bit quantization such as binary and ternary quantization is a common approach to alleviate this resource requirements. Ternary quantization provides a more flexible model and outperforms binary quantization in terms of accuracy, however doubles the memory footprint and increases the computational cost. Contrary to these approaches, mixed quantized models allow a trade-off between accuracy and memory footprint. In such models, quantization depth is often chosen manually, or is tuned using a separate optimization routine. The latter requires training a quantized network multiple times. Here, we propose an adaptive combination of binary and ternary quantization, namely Smart Quantization (SQ), in which the quantization depth is modified directly via a regularization function, so that the model is trained only once. Our experimental results show that the proposed method adapts quantization depth successfully while keeping the model accuracy high on MNIST and CIFAR10 benchmarks. ### Response: Quantization : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","We review three recently-proposed classifier quality metrics and consider their suitability for large-scale classification challenges such as applying convolutional neural networks to the 1000-class ImageNet dataset. These metrics, referred to as the ""geometric accuracy,"" ""decisiveness,"" and ""robustness,"" are based on the generalized mean ($\rho$ equals 0, 1, and -2/3, respectively) of the classifier's self-reported and measured probabilities of correct classification. We also propose some minor clarifications to standardize the metric definitions. With these updates, we show some examples of calculating the metrics using deep convolutional neural networks (AlexNet and DenseNet) acting on large datasets (the German Traffic Sign Recognition Benchmark and ImageNet).",Traffic Sign Recognition : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: We review three recently-proposed classifier quality metrics and consider their suitability for large-scale classification challenges such as applying convolutional neural networks to the 1000-class ImageNet dataset. These metrics, referred to as the ""geometric accuracy,"" ""decisiveness,"" and ""robustness,"" are based on the generalized mean ($\rho$ equals 0, 1, and -2/3, respectively) of the classifier's self-reported and measured probabilities of correct classification. We also propose some minor clarifications to standardize the metric definitions. With these updates, we show some examples of calculating the metrics using deep convolutional neural networks (AlexNet and DenseNet) acting on large datasets (the German Traffic Sign Recognition Benchmark and ImageNet). ### Response: Traffic Sign Recognition : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","High-level synthesis (HLS) shortens the development time of hardware designs and enables faster design space exploration at a higher abstraction level. Optimization of complex applications in HLS is challenging due to the effects of implementation issues such as routing congestion. Routing congestion estimation is absent or inaccurate in existing HLS design methods and tools. Early and accurate congestion estimation is of great benefit to guide the optimization in HLS and improve the efficiency of implementation. However, routability, a serious concern in FPGA designs, has been difficult to evaluate in HLS without analyzing post-implementation details after Place and Route. To this end, we propose a novel method to predict routing congestion in HLS using machine learning and map the expected congested regions in the design to the relevant high-level source code. This is greatly beneficial in early identification of routability oriented bottlenecks in the high-level source code without running time-consuming register-transfer level (RTL) implementation flow. Experiments demonstrate that our approach accurately estimates vertical and horizontal routing congestion with errors of 6.71% and 10.05% respectively. By presenting Face Detection application as a case study, we show that by discovering the bottlenecks in high-level source code, routing congestion can be easily and quickly resolved compared to the efforts involved in RTL implementation and design feedback.",Face Detection : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: High-level synthesis (HLS) shortens the development time of hardware designs and enables faster design space exploration at a higher abstraction level. Optimization of complex applications in HLS is challenging due to the effects of implementation issues such as routing congestion. Routing congestion estimation is absent or inaccurate in existing HLS design methods and tools. Early and accurate congestion estimation is of great benefit to guide the optimization in HLS and improve the efficiency of implementation. However, routability, a serious concern in FPGA designs, has been difficult to evaluate in HLS without analyzing post-implementation details after Place and Route. To this end, we propose a novel method to predict routing congestion in HLS using machine learning and map the expected congested regions in the design to the relevant high-level source code. This is greatly beneficial in early identification of routability oriented bottlenecks in the high-level source code without running time-consuming register-transfer level (RTL) implementation flow. Experiments demonstrate that our approach accurately estimates vertical and horizontal routing congestion with errors of 6.71% and 10.05% respectively. By presenting Face Detection application as a case study, we show that by discovering the bottlenecks in high-level source code, routing congestion can be easily and quickly resolved compared to the efforts involved in RTL implementation and design feedback. ### Response: Face Detection : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","In this work, we address the problem of Named Entity Recognition (NER) in code-switched tweets as a part of the Workshop on Computational Approaches to Linguistic Code-switching (CALCS) at ACL{'}18. Code-switching is the phenomenon where a speaker switches between two languages or variants of the same language within or across utterances, known as intra-sentential or inter-sentential code-switching, respectively. Processing such data is challenging using state of the art methods since such technology is generally geared towards processing monolingual text. In this paper we explored ways to use language identification and translation to recognize named entities in such data, however, utilizing simple features (sans multi-lingual features) with Conditional Random Field (CRF) classifier achieved the best results. Our experiments were mainly aimed at the (ENG-SPA) English-Spanish dataset but we submitted a language-independent version of our system to the (MSA-EGY) Arabic-Egyptian dataset as well and achieved good results.",Named Entity Recognition : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: In this work, we address the problem of Named Entity Recognition (NER) in code-switched tweets as a part of the Workshop on Computational Approaches to Linguistic Code-switching (CALCS) at ACL{'}18. Code-switching is the phenomenon where a speaker switches between two languages or variants of the same language within or across utterances, known as intra-sentential or inter-sentential code-switching, respectively. Processing such data is challenging using state of the art methods since such technology is generally geared towards processing monolingual text. In this paper we explored ways to use language identification and translation to recognize named entities in such data, however, utilizing simple features (sans multi-lingual features) with Conditional Random Field (CRF) classifier achieved the best results. Our experiments were mainly aimed at the (ENG-SPA) English-Spanish dataset but we submitted a language-independent version of our system to the (MSA-EGY) Arabic-Egyptian dataset as well and achieved good results. ### Response: Named Entity Recognition : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Artificial Intelligence agents are required to learn from their surroundings and to reason about the knowledge that has been learned in order to make decisions. While state-of-the-art learning from data typically uses sub-symbolic distributed representations, reasoning is normally useful at a higher level of abstraction with the use of a first-order logic language for knowledge representation. As a result, attempts at combining symbolic AI and neural computation into neural-symbolic systems have been on the increase. In this paper, we present Logic Tensor Networks (LTN), a neurosymbolic formalism and computational model that supports learning and reasoning through the introduction of a many-valued, end-to-end differentiable first-order logic called Real Logic as a representation language for deep learning. We show that LTN provides a uniform language for the specification and the computation of several AI tasks such as data clustering, multi-label classification, relational learning, query answering, semi-supervised learning, regression and embedding learning. We implement and illustrate each of the above tasks with a number of simple explanatory examples using TensorFlow 2. Keywords: Neurosymbolic AI, Deep Learning and Reasoning, Many-valued Logic.",Tensor Networks : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Artificial Intelligence agents are required to learn from their surroundings and to reason about the knowledge that has been learned in order to make decisions. While state-of-the-art learning from data typically uses sub-symbolic distributed representations, reasoning is normally useful at a higher level of abstraction with the use of a first-order logic language for knowledge representation. As a result, attempts at combining symbolic AI and neural computation into neural-symbolic systems have been on the increase. In this paper, we present Logic Tensor Networks (LTN), a neurosymbolic formalism and computational model that supports learning and reasoning through the introduction of a many-valued, end-to-end differentiable first-order logic called Real Logic as a representation language for deep learning. We show that LTN provides a uniform language for the specification and the computation of several AI tasks such as data clustering, multi-label classification, relational learning, query answering, semi-supervised learning, regression and embedding learning. We implement and illustrate each of the above tasks with a number of simple explanatory examples using TensorFlow 2. Keywords: Neurosymbolic AI, Deep Learning and Reasoning, Many-valued Logic. ### Response: Tensor Networks : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","In Machine Learning scenarios, privacy is a crucial concern when models have to be trained with private data coming from users of a service, such as a recommender system, a location-based mobile service, a mobile phone text messaging service providing next word prediction, or a face image classification system. The main issue is that, often, data are collected, transferred, and processed by third parties. These transactions violate new regulations, such as GDPR. Furthermore, users usually are not willing to share private data such as their visited locations, the text messages they wrote, or the photo they took with a third party. On the other hand, users appreciate services that work based on their behaviors and preferences. In order to address these issues, Federated Learning (FL) has been recently proposed as a means to build ML models based on private datasets distributed over a large number of clients, while preventing data leakage. A federation of users is asked to train a same global model on their private data, while a central coordinating server receives locally computed updates by clients and aggregate them to obtain a better global model, without the need to use clients' actual data. In this work, we extend the FL approach by pushing forward the state-of-the-art approaches in the aggregation step of FL, which we deem crucial for building a high-quality global model. Specifically, we propose an approach that takes into account a suite of client-specific criteria that constitute the basis for assigning a score to each client based on a priority of criteria defined by the service provider. Extensive experiments on two publicly available datasets indicate the merits of the proposed approach compared to standard FL baseline.",Federated Learning : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: In Machine Learning scenarios, privacy is a crucial concern when models have to be trained with private data coming from users of a service, such as a recommender system, a location-based mobile service, a mobile phone text messaging service providing next word prediction, or a face image classification system. The main issue is that, often, data are collected, transferred, and processed by third parties. These transactions violate new regulations, such as GDPR. Furthermore, users usually are not willing to share private data such as their visited locations, the text messages they wrote, or the photo they took with a third party. On the other hand, users appreciate services that work based on their behaviors and preferences. In order to address these issues, Federated Learning (FL) has been recently proposed as a means to build ML models based on private datasets distributed over a large number of clients, while preventing data leakage. A federation of users is asked to train a same global model on their private data, while a central coordinating server receives locally computed updates by clients and aggregate them to obtain a better global model, without the need to use clients' actual data. In this work, we extend the FL approach by pushing forward the state-of-the-art approaches in the aggregation step of FL, which we deem crucial for building a high-quality global model. Specifically, we propose an approach that takes into account a suite of client-specific criteria that constitute the basis for assigning a score to each client based on a priority of criteria defined by the service provider. Extensive experiments on two publicly available datasets indicate the merits of the proposed approach compared to standard FL baseline. ### Response: Federated Learning : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","This paper studies how to apply differential privacy to constrained optimization problems whose inputs are sensitive. This task raises significant challenges since random perturbations of the input data often render the constrained optimization problem infeasible or change significantly the nature of its optimal solutions. To address this difficulty, this paper proposes a bilevel optimization model that can be used as a post-processing step: It redistributes the noise introduced by a differentially private mechanism optimally while restoring feasibility and near-optimality. The paper shows that, under a natural assumption, this bilevel model can be solved efficiently for real-life large-scale nonlinear nonconvex optimization problems with sensitive customer data. The experimental results demonstrate the accuracy of the privacy-preserving mechanism and showcases significant benefits compared to standard approaches.",bilevel optimization : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: This paper studies how to apply differential privacy to constrained optimization problems whose inputs are sensitive. This task raises significant challenges since random perturbations of the input data often render the constrained optimization problem infeasible or change significantly the nature of its optimal solutions. To address this difficulty, this paper proposes a bilevel optimization model that can be used as a post-processing step: It redistributes the noise introduced by a differentially private mechanism optimally while restoring feasibility and near-optimality. The paper shows that, under a natural assumption, this bilevel model can be solved efficiently for real-life large-scale nonlinear nonconvex optimization problems with sensitive customer data. The experimental results demonstrate the accuracy of the privacy-preserving mechanism and showcases significant benefits compared to standard approaches. ### Response: bilevel optimization : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Human Activity Recognition (HAR), based on machine and deep learning algorithms is considered one of the most promising technologies to monitor professional and daily life activities for different categories of people (e.g., athletes, elderly, kids, employers) in order to provide a variety of services related, for example to well-being, empowering of technical performances, prevention of risky situation, and educational purposes. However, the analysis of the effectiveness and the efficiency of HAR methodologies suffers from the lack of a standard workflow, which might represent the baseline for the estimation of the quality of the developed pattern recognition models. This makes the comparison among different approaches a challenging task. In addition, researchers can make mistakes that, when not detected, definitely affect the achieved results. To mitigate such issues, this paper proposes an open-source automatic and highly configurable framework, named B-HAR, for the definition, standardization, and development of a baseline framework in order to evaluate and compare HAR methodologies. It implements the most popular data processing methods for data preparation and the most commonly used machine and deep learning pattern recognition models.",Activity Recognition : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Human Activity Recognition (HAR), based on machine and deep learning algorithms is considered one of the most promising technologies to monitor professional and daily life activities for different categories of people (e.g., athletes, elderly, kids, employers) in order to provide a variety of services related, for example to well-being, empowering of technical performances, prevention of risky situation, and educational purposes. However, the analysis of the effectiveness and the efficiency of HAR methodologies suffers from the lack of a standard workflow, which might represent the baseline for the estimation of the quality of the developed pattern recognition models. This makes the comparison among different approaches a challenging task. In addition, researchers can make mistakes that, when not detected, definitely affect the achieved results. To mitigate such issues, this paper proposes an open-source automatic and highly configurable framework, named B-HAR, for the definition, standardization, and development of a baseline framework in order to evaluate and compare HAR methodologies. It implements the most popular data processing methods for data preparation and the most commonly used machine and deep learning pattern recognition models. ### Response: Activity Recognition : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Efficient similarity retrieval from large-scale multimodal database ispervasive in modern search engines and social networks. To support queriesacross content modalities, the system should enable cross-modal correlation andcomputation-efficient indexing. While hashing methods have shown greatpotential in achieving this goal, current attempts generally fail to learnisomorphic hash codes in a seamless scheme, that is, they embed multiplemodalities in a continuous isomorphic space and separately threshold embeddingsinto binary codes, which incurs substantial loss of retrieval accuracy. In thispaper, we approach seamless multimodal hashing by proposing a novel CompositeCorrelation Quantization (CCQ) model. Specifically, CCQ jointly findscorrelation-maximal mappings that transform different modalities intoisomorphic latent space, and learns composite quantizers that convert theisomorphic latent features into compact binary codes. An optimization frameworkis devised to preserve both intra-modal similarity and inter-modal correlationthrough minimizing both reconstruction and quantization errors, which can betrained from both paired and partially paired data in linear time. Acomprehensive set of experiments clearly show the superior effectiveness andefficiency of CCQ against the state of the art hashing methods for bothunimodal and cross-modal retrieval.",Quantization : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Efficient similarity retrieval from large-scale multimodal database ispervasive in modern search engines and social networks. To support queriesacross content modalities, the system should enable cross-modal correlation andcomputation-efficient indexing. While hashing methods have shown greatpotential in achieving this goal, current attempts generally fail to learnisomorphic hash codes in a seamless scheme, that is, they embed multiplemodalities in a continuous isomorphic space and separately threshold embeddingsinto binary codes, which incurs substantial loss of retrieval accuracy. In thispaper, we approach seamless multimodal hashing by proposing a novel CompositeCorrelation Quantization (CCQ) model. Specifically, CCQ jointly findscorrelation-maximal mappings that transform different modalities intoisomorphic latent space, and learns composite quantizers that convert theisomorphic latent features into compact binary codes. An optimization frameworkis devised to preserve both intra-modal similarity and inter-modal correlationthrough minimizing both reconstruction and quantization errors, which can betrained from both paired and partially paired data in linear time. Acomprehensive set of experiments clearly show the superior effectiveness andefficiency of CCQ against the state of the art hashing methods for bothunimodal and cross-modal retrieval. ### Response: Quantization : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Automated Theorem Proving (ATP) is an established branch of ArtificialIntelligence. The purpose of ATP is to design a system which can automaticallyfigure out an algorithm either to prove or disprove a mathematical claim, onthe basis of a set of given premises, using a set of fundamental postulates andfollowing the method of logical inference. In this paper, we propose GraATP, ageneralized framework for automated theorem proving in plane geometry. Ourproposed method translates the geometric entities into nodes of a graph and therelations between them as edges of that graph. The automated system searchesfor different ways to reach the conclusion for a claim via graph traversal bywhich the validity of the geometric theorem is examined.",Automated Theorem Proving : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Automated Theorem Proving (ATP) is an established branch of ArtificialIntelligence. The purpose of ATP is to design a system which can automaticallyfigure out an algorithm either to prove or disprove a mathematical claim, onthe basis of a set of given premises, using a set of fundamental postulates andfollowing the method of logical inference. In this paper, we propose GraATP, ageneralized framework for automated theorem proving in plane geometry. Ourproposed method translates the geometric entities into nodes of a graph and therelations between them as edges of that graph. The automated system searchesfor different ways to reach the conclusion for a claim via graph traversal bywhich the validity of the geometric theorem is examined. ### Response: Automated Theorem Proving : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Image Super-Resolution (SR) provides a promising technique to enhance the image quality of low-resolution optical sensors, facilitating better-performing target detection and autonomous navigation in a wide range of robotics applications. It is noted that the state-of-the-art SR methods are typically trained and tested using single-channel inputs, neglecting the fact that the cost of capturing high-resolution images in different spectral domains varies significantly. In this paper, we attempt to leverage complementary information from a low-cost channel (visible/depth) to boost image quality of an expensive channel (thermal) using fewer parameters. To this end, we first present an effective method to virtually generate pixel-wise aligned visible and thermal images based on real-time 3D reconstruction of multi-modal data captured at various viewpoints. Then, we design a feature-level multispectral fusion residual network model to perform high-accuracy SR of thermal images by adaptively integrating co-occurrence features presented in multispectral images. Experimental results demonstrate that this new approach can effectively alleviate the ill-posed inverse problem of image SR by taking into account complementary information from an additional low-cost channel, significantly outperforming state-of-the-art SR approaches in terms of both accuracy and efficiency.",Image Super-Resolution : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Image Super-Resolution (SR) provides a promising technique to enhance the image quality of low-resolution optical sensors, facilitating better-performing target detection and autonomous navigation in a wide range of robotics applications. It is noted that the state-of-the-art SR methods are typically trained and tested using single-channel inputs, neglecting the fact that the cost of capturing high-resolution images in different spectral domains varies significantly. In this paper, we attempt to leverage complementary information from a low-cost channel (visible/depth) to boost image quality of an expensive channel (thermal) using fewer parameters. To this end, we first present an effective method to virtually generate pixel-wise aligned visible and thermal images based on real-time 3D reconstruction of multi-modal data captured at various viewpoints. Then, we design a feature-level multispectral fusion residual network model to perform high-accuracy SR of thermal images by adaptively integrating co-occurrence features presented in multispectral images. Experimental results demonstrate that this new approach can effectively alleviate the ill-posed inverse problem of image SR by taking into account complementary information from an additional low-cost channel, significantly outperforming state-of-the-art SR approaches in terms of both accuracy and efficiency. ### Response: Image Super-Resolution : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Differentiable ARchiTecture Search (DARTS) is one of the most trending Neural Architecture Search (NAS) methods, drastically reducing search cost by resorting to Stochastic Gradient Descent (SGD) and weight-sharing. However, it also greatly reduces the search space, thus excluding potential promising architectures from being discovered. In this paper, we propose D-DARTS, a novel solution that addresses this problem by nesting several neural networks at cell-level instead of using weight-sharing to produce more diversified and specialized architectures. Moreover, we introduce a novel algorithm which can derive deeper architectures from a few trained cells, increasing performance and saving computation time. Our solution is able to provide state-of-the-art results on CIFAR-10, CIFAR-100 and ImageNet while using significantly less parameters than previous baselines, resulting in more hardware-efficient neural networks.",Neural Architecture Search : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Differentiable ARchiTecture Search (DARTS) is one of the most trending Neural Architecture Search (NAS) methods, drastically reducing search cost by resorting to Stochastic Gradient Descent (SGD) and weight-sharing. However, it also greatly reduces the search space, thus excluding potential promising architectures from being discovered. In this paper, we propose D-DARTS, a novel solution that addresses this problem by nesting several neural networks at cell-level instead of using weight-sharing to produce more diversified and specialized architectures. Moreover, we introduce a novel algorithm which can derive deeper architectures from a few trained cells, increasing performance and saving computation time. Our solution is able to provide state-of-the-art results on CIFAR-10, CIFAR-100 and ImageNet while using significantly less parameters than previous baselines, resulting in more hardware-efficient neural networks. ### Response: Neural Architecture Search : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","We consider the task of incorporating real-world commonsense knowledge into deep Natural Language Inference (NLI) models. Existing external knowledge incorporation methods are limited to lexical level knowledge and lack generalization across NLI models, datasets, and commonsense knowledge sources. To address these issues, we propose a novel NLI model-independent neural framework, BiCAM. BiCAM incorporates real-world commonsense knowledge into NLI models. Combined with convolutional feature detectors and bilinear feature fusion, BiCAM provides a conceptually simple mechanism that generalizes well. Quantitative evaluations with two state-of-the-art NLI baselines on SNLI and SciTail datasets in conjunction with ConceptNet and Aristo Tuple KGs show that BiCAM considerably improves the accuracy the incorporated NLI baselines. For example, our BiECAM model, an instance of BiCAM, on the challenging SciTail dataset, improves the accuracy of incorporated baselines by 7.0% with ConceptNet, and 8.0% with Aristo Tuple KG.",Natural Language Inference : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: We consider the task of incorporating real-world commonsense knowledge into deep Natural Language Inference (NLI) models. Existing external knowledge incorporation methods are limited to lexical level knowledge and lack generalization across NLI models, datasets, and commonsense knowledge sources. To address these issues, we propose a novel NLI model-independent neural framework, BiCAM. BiCAM incorporates real-world commonsense knowledge into NLI models. Combined with convolutional feature detectors and bilinear feature fusion, BiCAM provides a conceptually simple mechanism that generalizes well. Quantitative evaluations with two state-of-the-art NLI baselines on SNLI and SciTail datasets in conjunction with ConceptNet and Aristo Tuple KGs show that BiCAM considerably improves the accuracy the incorporated NLI baselines. For example, our BiECAM model, an instance of BiCAM, on the challenging SciTail dataset, improves the accuracy of incorporated baselines by 7.0% with ConceptNet, and 8.0% with Aristo Tuple KG. ### Response: Natural Language Inference : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","This paper describes the POSTECH{'}s submission to the WMT 2018 shared task on Automatic Post-Editing (APE). We propose a new neural end-to-end post-editing model based on the transformer network. We modified the encoder-decoder attention to reflect the relation between the machine translation output, the source and the post-edited translation in APE problem. Experiments on WMT17 English-German APE data set show an improvement in both TER and BLEU score over the best result of WMT17 APE shared task. Our primary submission achieves -4.52 TER and +6.81 BLEU score on PBSMT task and -0.13 TER and +0.40 BLEU score for NMT task compare to the baseline.",Automatic Post-Editing : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: This paper describes the POSTECH{'}s submission to the WMT 2018 shared task on Automatic Post-Editing (APE). We propose a new neural end-to-end post-editing model based on the transformer network. We modified the encoder-decoder attention to reflect the relation between the machine translation output, the source and the post-edited translation in APE problem. Experiments on WMT17 English-German APE data set show an improvement in both TER and BLEU score over the best result of WMT17 APE shared task. Our primary submission achieves -4.52 TER and +6.81 BLEU score on PBSMT task and -0.13 TER and +0.40 BLEU score for NMT task compare to the baseline. ### Response: Automatic Post-Editing : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","The multi-scale defect detection for photovoltaic (PV) cell electroluminescence (EL) images is a challenging task, due to the feature vanishing as network deepens. To address this problem, an attention-based top-down and bottom-up architecture is developed to accomplish multi-scale feature fusion. This architecture, called Bidirectional Attention Feature Pyramid Network (BAFPN), can make all layers of the pyramid share similar semantic features. In BAFPN, cosine similarity is employed to measure the importance of each pixel in the fused features. Furthermore, a novel object detector is proposed, called BAF-Detector, which embeds BAFPN into Region Proposal Network (RPN) in Faster RCNN+FPN. BAFPN improves the robustness of the network to scales, thus the proposed detector achieves a good performance in multi-scale defects detection task. Finally, the experimental results on a large-scale EL dataset including 3629 images, 2129 of which are defective, show that the proposed method achieves 98.70% (F-measure), 88.07% (mAP), and 73.29% (IoU) in terms of multi-scale defects classification and detection results in raw PV cell EL images.",Region Proposal : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: The multi-scale defect detection for photovoltaic (PV) cell electroluminescence (EL) images is a challenging task, due to the feature vanishing as network deepens. To address this problem, an attention-based top-down and bottom-up architecture is developed to accomplish multi-scale feature fusion. This architecture, called Bidirectional Attention Feature Pyramid Network (BAFPN), can make all layers of the pyramid share similar semantic features. In BAFPN, cosine similarity is employed to measure the importance of each pixel in the fused features. Furthermore, a novel object detector is proposed, called BAF-Detector, which embeds BAFPN into Region Proposal Network (RPN) in Faster RCNN+FPN. BAFPN improves the robustness of the network to scales, thus the proposed detector achieves a good performance in multi-scale defects detection task. Finally, the experimental results on a large-scale EL dataset including 3629 images, 2129 of which are defective, show that the proposed method achieves 98.70% (F-measure), 88.07% (mAP), and 73.29% (IoU) in terms of multi-scale defects classification and detection results in raw PV cell EL images. ### Response: Region Proposal : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Visual Question Answering (VQA) models have achieved significant success in recent times. Despite the success of VQA models, they are mostly black-box models providing no reasoning about the predicted answer, thus raising questions for their applicability in safety-critical such as autonomous systems and cyber-security. Current state of the art fail to better complex questions and thus are unable to exploit compositionality. To minimize the black-box effect of these models and also to make them better exploit compositionality, we propose a Dynamic Neural Network (DMN), which can understand a particular question and then dynamically assemble various relatively shallow deep learning modules from a pool of modules to form a network. We incorporate compositional temporal attention to these deep learning based modules to increase compositionality exploitation. This results in achieving better understanding of complex questions and also provides reasoning as to why the module predicts a particular answer. Experimental analysis on the two benchmark datasets, VQA2.0 and CLEVR, depicts that our model outperforms the previous approaches for Visual Question Answering task as well as provides better reasoning, thus making it reliable for mission critical applications like safety and security.",Visual Question Answering : RESEARCH_PROBLEM; Visual Question Answering : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Visual Question Answering (VQA) models have achieved significant success in recent times. Despite the success of VQA models, they are mostly black-box models providing no reasoning about the predicted answer, thus raising questions for their applicability in safety-critical such as autonomous systems and cyber-security. Current state of the art fail to better complex questions and thus are unable to exploit compositionality. To minimize the black-box effect of these models and also to make them better exploit compositionality, we propose a Dynamic Neural Network (DMN), which can understand a particular question and then dynamically assemble various relatively shallow deep learning modules from a pool of modules to form a network. We incorporate compositional temporal attention to these deep learning based modules to increase compositionality exploitation. This results in achieving better understanding of complex questions and also provides reasoning as to why the module predicts a particular answer. Experimental analysis on the two benchmark datasets, VQA2.0 and CLEVR, depicts that our model outperforms the previous approaches for Visual Question Answering task as well as provides better reasoning, thus making it reliable for mission critical applications like safety and security. ### Response: Visual Question Answering : RESEARCH_PROBLEM; Visual Question Answering : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Circular cone-beam (CCB) Computed Tomography (CT) has become an integral part of industrial quality control, materials science and medical imaging. The need to acquire and process each scan in a short time naturally leads to trade-offs between speed and reconstruction quality, creating a need for fast reconstruction algorithms capable of creating accurate reconstructions from limited data. In this paper we introduce the Neural Network Feldkamp-Davis-Kress (NN-FDK) algorithm. This algorithm adds a machine learning component to the FDK algorithm to improve its reconstruction accuracy while maintaining its computational efficiency. Moreover, the NN-FDK algorithm is designed such that it has low training data requirements and is fast to train. This ensures that the proposed algorithm can be used to improve image quality in high throughput CT scanning settings, where FDK is currently used to keep pace with the acquisition speed using readily available computational resources. We compare the NN-FDK algorithm to two standard CT reconstruction algorithms and to two popular deep neural networks trained to remove reconstruction artifacts from the 2D slices of an FDK reconstruction. We show that the NN-FDK reconstruction algorithm is substantially faster in computing a reconstruction than all the tested alternative methods except for the standard FDK algorithm and we show it can compute accurate CCB CT reconstructions in cases of high noise, a low number of projection angles or large cone angles. Moreover, we show that the training time of an NN-FDK network is orders of magnitude lower than the considered deep neural networks, with only a slight reduction in reconstruction accuracy.",Computed Tomography (CT) : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Circular cone-beam (CCB) Computed Tomography (CT) has become an integral part of industrial quality control, materials science and medical imaging. The need to acquire and process each scan in a short time naturally leads to trade-offs between speed and reconstruction quality, creating a need for fast reconstruction algorithms capable of creating accurate reconstructions from limited data. In this paper we introduce the Neural Network Feldkamp-Davis-Kress (NN-FDK) algorithm. This algorithm adds a machine learning component to the FDK algorithm to improve its reconstruction accuracy while maintaining its computational efficiency. Moreover, the NN-FDK algorithm is designed such that it has low training data requirements and is fast to train. This ensures that the proposed algorithm can be used to improve image quality in high throughput CT scanning settings, where FDK is currently used to keep pace with the acquisition speed using readily available computational resources. We compare the NN-FDK algorithm to two standard CT reconstruction algorithms and to two popular deep neural networks trained to remove reconstruction artifacts from the 2D slices of an FDK reconstruction. We show that the NN-FDK reconstruction algorithm is substantially faster in computing a reconstruction than all the tested alternative methods except for the standard FDK algorithm and we show it can compute accurate CCB CT reconstructions in cases of high noise, a low number of projection angles or large cone angles. Moreover, we show that the training time of an NN-FDK network is orders of magnitude lower than the considered deep neural networks, with only a slight reduction in reconstruction accuracy. ### Response: Computed Tomography (CT) : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Despite the significant progress achieved in image de-raining by training an encoder-decoder network within the image-to-image translation formulation, blurry results with missing details indicate the deficiency of the existing models. By interpreting the de-raining encoder-decoder network as a conditional generator, within which the decoder acts as a generator conditioned on the embedding learned by the encoder, the unsatisfactory output can be attributed to the low-quality embedding learned by the encoder. In this paper, we hypothesize that there exists an inherent mapping between the low-quality embedding to a latent optimal one, with which the generator (decoder) can produce much better results. To improve the de-raining results significantly over existing models, we propose to learn this mapping by formulating a residual learning branch, that is capable of adaptively adding residuals to the original low-quality embedding in a representation entanglement manner. Using an embedding learned this way, the decoder is able to generate much more satisfactory de-raining results with better detail recovery and rain artefacts removal, providing new state-of-the-art results on four benchmark datasets with considerable improvement (i.e., on the challenging Rain100H data, an improvement of 4.19dB on PSNR and 5% on SSIM is obtained). The entanglement can be easily adopted into any encoder-decoder based image restoration networks. Besides, we propose a series of evaluation metrics to investigate the specific contribution of the proposed entangled representation learning mechanism. Codes are available at .",SSIM : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Despite the significant progress achieved in image de-raining by training an encoder-decoder network within the image-to-image translation formulation, blurry results with missing details indicate the deficiency of the existing models. By interpreting the de-raining encoder-decoder network as a conditional generator, within which the decoder acts as a generator conditioned on the embedding learned by the encoder, the unsatisfactory output can be attributed to the low-quality embedding learned by the encoder. In this paper, we hypothesize that there exists an inherent mapping between the low-quality embedding to a latent optimal one, with which the generator (decoder) can produce much better results. To improve the de-raining results significantly over existing models, we propose to learn this mapping by formulating a residual learning branch, that is capable of adaptively adding residuals to the original low-quality embedding in a representation entanglement manner. Using an embedding learned this way, the decoder is able to generate much more satisfactory de-raining results with better detail recovery and rain artefacts removal, providing new state-of-the-art results on four benchmark datasets with considerable improvement (i.e., on the challenging Rain100H data, an improvement of 4.19dB on PSNR and 5% on SSIM is obtained). The entanglement can be easily adopted into any encoder-decoder based image restoration networks. Besides, we propose a series of evaluation metrics to investigate the specific contribution of the proposed entangled representation learning mechanism. Codes are available at . ### Response: SSIM : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Training semantic segmentation models requires a large amount of finely annotated data, making it hard to quickly adapt to novel classes not satisfying this condition. Few-Shot Segmentation (FS-Seg) tackles this problem with many constraints. In this paper, we introduce a new benchmark, called Generalized Few-Shot Semantic Segmentation (GFS-Seg), to analyze the generalization ability of segmentation models to simultaneously recognize novel categories with very few examples as well as base categories with sufficient examples. Previous state-of-the-art FS-Seg methods fall short in GFS-Seg and the performance discrepancy mainly comes from the constrained training setting of FS-Seg. To make GFS-Seg tractable, we set up a GFS-Seg baseline that achieves decent performance without structural change on the original model. Then, as context is the key for boosting performance on semantic segmentation, we propose the Context-Aware Prototype Learning (CAPL) that significantly improves performance by leveraging the contextual information to update class prototypes with aligned features. Extensive experiments on Pascal-VOC and COCO manifest the effectiveness of CAPL, and CAPL also generalizes well to FS-Seg.",Few-Shot Semantic Segmentation : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Training semantic segmentation models requires a large amount of finely annotated data, making it hard to quickly adapt to novel classes not satisfying this condition. Few-Shot Segmentation (FS-Seg) tackles this problem with many constraints. In this paper, we introduce a new benchmark, called Generalized Few-Shot Semantic Segmentation (GFS-Seg), to analyze the generalization ability of segmentation models to simultaneously recognize novel categories with very few examples as well as base categories with sufficient examples. Previous state-of-the-art FS-Seg methods fall short in GFS-Seg and the performance discrepancy mainly comes from the constrained training setting of FS-Seg. To make GFS-Seg tractable, we set up a GFS-Seg baseline that achieves decent performance without structural change on the original model. Then, as context is the key for boosting performance on semantic segmentation, we propose the Context-Aware Prototype Learning (CAPL) that significantly improves performance by leveraging the contextual information to update class prototypes with aligned features. Extensive experiments on Pascal-VOC and COCO manifest the effectiveness of CAPL, and CAPL also generalizes well to FS-Seg. ### Response: Few-Shot Semantic Segmentation : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","The standard ML methodology assumes that the test samples are derived from a set of pre-observed classes used in the training phase. Where the model extracts and learns useful patterns to detect new data samples belonging to the same data classes. However, in certain applications such as Network Intrusion Detection Systems, it is challenging to obtain data samples for all attack classes that the model will most likely observe in production. ML-based NIDSs face new attack traffic known as zero-day attacks, that are not used in the training of the learning models due to their non-existence at the time. In this paper, a zero-shot learning methodology has been proposed to evaluate the ML model performance in the detection of zero-day attack scenarios. In the attribute learning stage, the ML models map the network data features to distinguish semantic attributes from known attack (seen) classes. In the inference stage, the models are evaluated in the detection of zero-day attack (unseen) classes by constructing the relationships between known attacks and zero-day attacks. A new metric is defined as Zero-day Detection Rate, which measures the effectiveness of the learning model in the inference stage. The results demonstrate that while the majority of the attack classes do not represent significant risks to organisations adopting an ML-based NIDS in a zero-day attack scenario. However, for certain attack groups identified in this paper, such systems are not effective in applying the learnt attributes of attack behaviour to detect them as malicious. Further Analysis was conducted using the Wasserstein Distance technique to measure how different such attacks are from other attack types used in the training of the ML model. The results demonstrate that sophisticated attacks with a low zero-day detection rate have a significantly distinct feature distribution compared to the other attack classes.",Network Intrusion Detection : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: The standard ML methodology assumes that the test samples are derived from a set of pre-observed classes used in the training phase. Where the model extracts and learns useful patterns to detect new data samples belonging to the same data classes. However, in certain applications such as Network Intrusion Detection Systems, it is challenging to obtain data samples for all attack classes that the model will most likely observe in production. ML-based NIDSs face new attack traffic known as zero-day attacks, that are not used in the training of the learning models due to their non-existence at the time. In this paper, a zero-shot learning methodology has been proposed to evaluate the ML model performance in the detection of zero-day attack scenarios. In the attribute learning stage, the ML models map the network data features to distinguish semantic attributes from known attack (seen) classes. In the inference stage, the models are evaluated in the detection of zero-day attack (unseen) classes by constructing the relationships between known attacks and zero-day attacks. A new metric is defined as Zero-day Detection Rate, which measures the effectiveness of the learning model in the inference stage. The results demonstrate that while the majority of the attack classes do not represent significant risks to organisations adopting an ML-based NIDS in a zero-day attack scenario. However, for certain attack groups identified in this paper, such systems are not effective in applying the learnt attributes of attack behaviour to detect them as malicious. Further Analysis was conducted using the Wasserstein Distance technique to measure how different such attacks are from other attack types used in the training of the ML model. The results demonstrate that sophisticated attacks with a low zero-day detection rate have a significantly distinct feature distribution compared to the other attack classes. ### Response: Network Intrusion Detection : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","We ascertain and compare the performances of AutoML tools on large, highly imbalanced healthcare datasets. We generated a large dataset using historical administrative claims including demographic information and flags for disease codes in four different time windows prior to 2019. We then trained three AutoML tools on this dataset to predict six different disease outcomes in 2019 and evaluated model performances on several metrics. The AutoML tools showed improvement from the baseline random forest model but did not differ significantly from each other. All models recorded low area under the precision-recall curve and failed to predict true positives while keeping the true negative rate high. Model performance was not directly related to prevalence. We provide a specific use-case to illustrate how to select a threshold that gives the best balance between true and false positive rates, as this is an important consideration in medical applications. Healthcare datasets present several challenges for AutoML tools, including large sample size, high imbalance, and limitations in the available features types. Improvements in scalability, combinations of imbalance-learning resampling and ensemble approaches, and curated feature selection are possible next steps to achieve better performance. Among the three explored, no AutoML tool consistently outperforms the rest in terms of predictive performance. The performances of the models in this study suggest that there may be room for improvement in handling medical claims data. Finally, selection of the optimal prediction threshold should be guided by the specific practical application.",AutoML : RESEARCH_PROBLEM; AutoML : RESEARCH_PROBLEM; AutoML : RESEARCH_PROBLEM; AutoML : RESEARCH_PROBLEM; AutoML : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: We ascertain and compare the performances of AutoML tools on large, highly imbalanced healthcare datasets. We generated a large dataset using historical administrative claims including demographic information and flags for disease codes in four different time windows prior to 2019. We then trained three AutoML tools on this dataset to predict six different disease outcomes in 2019 and evaluated model performances on several metrics. The AutoML tools showed improvement from the baseline random forest model but did not differ significantly from each other. All models recorded low area under the precision-recall curve and failed to predict true positives while keeping the true negative rate high. Model performance was not directly related to prevalence. We provide a specific use-case to illustrate how to select a threshold that gives the best balance between true and false positive rates, as this is an important consideration in medical applications. Healthcare datasets present several challenges for AutoML tools, including large sample size, high imbalance, and limitations in the available features types. Improvements in scalability, combinations of imbalance-learning resampling and ensemble approaches, and curated feature selection are possible next steps to achieve better performance. Among the three explored, no AutoML tool consistently outperforms the rest in terms of predictive performance. The performances of the models in this study suggest that there may be room for improvement in handling medical claims data. Finally, selection of the optimal prediction threshold should be guided by the specific practical application. ### Response: AutoML : RESEARCH_PROBLEM; AutoML : RESEARCH_PROBLEM; AutoML : RESEARCH_PROBLEM; AutoML : RESEARCH_PROBLEM; AutoML : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Pathological slowing in the electroencephalogram (EEG ) is widely investigated for the diagnosis of neurological disorders. Currently, the gold standard for slowing detection is the visual inspection of the EEG by experts, which is time-consuming and subjective. To address those issues, we propose three automated approaches to detect slowing in EEG : Threshold-based Detecting System (TDS), Shallow Learning-based Detecting System (SLDS), and Deep Learning-based Detecting System (DLDS). These systems are evaluated on channel-, segment- and EEG -level. The TDS, SLDS, and DLDS performs prediction via detecting slowing at individual channels, and those detections are arranged in histograms for detection of slowing at the segment- and EEG -level. We evaluate the systems through Leave-One-Subject-Out (LOSO) cross-validation (CV) and Leave-One-Institution-Out (LOIO) CV on four datasets from the US, Singapore, and India. The DLDS achieved the best overall results: LOIO CV mean balanced accuracy (BAC) of 71.9%, 75.5%, and 82.0% at channel-, segment- and EEG -level, and LOSO CV mean BAC of 73.6%, 77.2%, and 81.8% at channel-, segment-, and EEG -level. The channel- and segment-level performance is comparable to the intra-rater agreement (IRA) of an expert of 72.4% and 82%. The DLDS can process a 30-minutes EEG in 4 seconds and can be deployed to assist clinicians in interpreting EEG s.",(EEG : RESEARCH_PROBLEM; EEG : RESEARCH_PROBLEM; EEG : RESEARCH_PROBLEM; EEG : RESEARCH_PROBLEM; EEG : RESEARCH_PROBLEM; EEG : RESEARCH_PROBLEM; EEG : RESEARCH_PROBLEM; EEG : RESEARCH_PROBLEM; EEG : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Pathological slowing in the electroencephalogram (EEG ) is widely investigated for the diagnosis of neurological disorders. Currently, the gold standard for slowing detection is the visual inspection of the EEG by experts, which is time-consuming and subjective. To address those issues, we propose three automated approaches to detect slowing in EEG : Threshold-based Detecting System (TDS), Shallow Learning-based Detecting System (SLDS), and Deep Learning-based Detecting System (DLDS). These systems are evaluated on channel-, segment- and EEG -level. The TDS, SLDS, and DLDS performs prediction via detecting slowing at individual channels, and those detections are arranged in histograms for detection of slowing at the segment- and EEG -level. We evaluate the systems through Leave-One-Subject-Out (LOSO) cross-validation (CV) and Leave-One-Institution-Out (LOIO) CV on four datasets from the US, Singapore, and India. The DLDS achieved the best overall results: LOIO CV mean balanced accuracy (BAC) of 71.9%, 75.5%, and 82.0% at channel-, segment- and EEG -level, and LOSO CV mean BAC of 73.6%, 77.2%, and 81.8% at channel-, segment-, and EEG -level. The channel- and segment-level performance is comparable to the intra-rater agreement (IRA) of an expert of 72.4% and 82%. The DLDS can process a 30-minutes EEG in 4 seconds and can be deployed to assist clinicians in interpreting EEG s. ### Response: (EEG : RESEARCH_PROBLEM; EEG : RESEARCH_PROBLEM; EEG : RESEARCH_PROBLEM; EEG : RESEARCH_PROBLEM; EEG : RESEARCH_PROBLEM; EEG : RESEARCH_PROBLEM; EEG : RESEARCH_PROBLEM; EEG : RESEARCH_PROBLEM; EEG : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","In this paper we present the dataset of Himachali low resource endangered language, Kangri (ISO 639-3xnr) listed in the United Nations Educational, Scientific and Cultural Organization (UNESCO). The compilation of kangri corpus has been a challenging task due to the non-availability of the digitalized resources. The corpus contains 1,81,552 Monolingual and 27,362 Hindi-Kangri Parallel corpora. We shared pre-trained kangri word embeddings. We also reported the Bilingual Evaluation Understudy (BLEU) score and Metric for Evaluation of Translation with Explicit ORdering (METEOR) score of Statistical Machine Translation (SMT) and Neural Machine Translation (NMT) results for the corpus. The corpus is freely available for non-commercial usages and research. To the best of our knowledge, this is the first Himachali low resource endangered language corpus. The resources are available at (https://github.com/chauhanshweta/Kangri_corpus)",Machine Translation : RESEARCH_PROBLEM; Machine Translation : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: In this paper we present the dataset of Himachali low resource endangered language, Kangri (ISO 639-3xnr) listed in the United Nations Educational, Scientific and Cultural Organization (UNESCO). The compilation of kangri corpus has been a challenging task due to the non-availability of the digitalized resources. The corpus contains 1,81,552 Monolingual and 27,362 Hindi-Kangri Parallel corpora. We shared pre-trained kangri word embeddings. We also reported the Bilingual Evaluation Understudy (BLEU) score and Metric for Evaluation of Translation with Explicit ORdering (METEOR) score of Statistical Machine Translation (SMT) and Neural Machine Translation (NMT) results for the corpus. The corpus is freely available for non-commercial usages and research. To the best of our knowledge, this is the first Himachali low resource endangered language corpus. The resources are available at (https://github.com/chauhanshweta/Kangri_corpus) ### Response: Machine Translation : RESEARCH_PROBLEM; Machine Translation : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET",The Pre-training for Video Captioning Challenge 2020 Summary: results and challenge participants' technical reports.,Video Captioning : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: The Pre-training for Video Captioning Challenge 2020 Summary: results and challenge participants' technical reports. ### Response: Video Captioning : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Manual count of mitotic figures, which is determined in the tumor region with the highest mitotic activity, is a key parameter of most tumor grading schemes. It can be, however, strongly dependent on the area selection due to uneven mitotic figure distribution in the tumor section.We aimed to assess the question, how significantly the area selection could impact the mitotic count, which has a known high inter-rater disagreement. On a data set of 32 whole slide images of H&E-stained canine cutaneous mast cell tumor, fully annotated for mitotic figures, we asked eight veterinary pathologists (five board-certified, three in training) to select a field of interest for the mitotic count. To assess the potential difference on the mitotic count, we compared the mitotic count of the selected regions to the overall distribution on the slide.Additionally, we evaluated three deep learning-based methods for the assessment of highest mitotic density: In one approach, the model would directly try to predict the mitotic count for the presented image patches as a regression task. The second method aims at deriving a segmentation mask for mitotic figures, which is then used to obtain a mitotic density. Finally, we evaluated a two-stage object-detection pipeline based on state-of-the-art architectures to identify individual mitotic figures. We found that the predictions by all models were, on average, better than those of the experts. The two-stage object detector performed best and outperformed most of the human pathologists on the majority of tumor cases. The correlation between the predicted and the ground truth mitotic count was also best for this approach (0.963 to 0.979). Further, we found considerable differences in position selection between pathologists, which could partially explain the high variance that has been reported for the manual mitotic count.",whole slide images : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Manual count of mitotic figures, which is determined in the tumor region with the highest mitotic activity, is a key parameter of most tumor grading schemes. It can be, however, strongly dependent on the area selection due to uneven mitotic figure distribution in the tumor section.We aimed to assess the question, how significantly the area selection could impact the mitotic count, which has a known high inter-rater disagreement. On a data set of 32 whole slide images of H&E-stained canine cutaneous mast cell tumor, fully annotated for mitotic figures, we asked eight veterinary pathologists (five board-certified, three in training) to select a field of interest for the mitotic count. To assess the potential difference on the mitotic count, we compared the mitotic count of the selected regions to the overall distribution on the slide.Additionally, we evaluated three deep learning-based methods for the assessment of highest mitotic density: In one approach, the model would directly try to predict the mitotic count for the presented image patches as a regression task. The second method aims at deriving a segmentation mask for mitotic figures, which is then used to obtain a mitotic density. Finally, we evaluated a two-stage object-detection pipeline based on state-of-the-art architectures to identify individual mitotic figures. We found that the predictions by all models were, on average, better than those of the experts. The two-stage object detector performed best and outperformed most of the human pathologists on the majority of tumor cases. The correlation between the predicted and the ground truth mitotic count was also best for this approach (0.963 to 0.979). Further, we found considerable differences in position selection between pathologists, which could partially explain the high variance that has been reported for the manual mitotic count. ### Response: whole slide images : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Incremental Learning (IL) is an interesting AI problem when the algorithm isassumed to work on a budget. This is especially true when IL is modeled using adeep learning approach, where two com- plex challenges arise due to limitedmemory, which induces catastrophic forgetting and delays related to theretraining needed in order to incorpo- rate new classes. Here we introduceDeeSIL, an adaptation of a known transfer learning scheme that combines a fixeddeep representation used as feature extractor and learning independent shallowclassifiers to in- crease recognition capacity. This scheme tackles the twoaforementioned challenges since it works well with a limited memory budget andeach new concept can be added within a minute. Moreover, since no deep re-training is needed when the model is incremented, DeeSIL can integrate largeramounts of initial data that provide more transferable features. Performance isevaluated on ImageNet LSVRC 2012 against three state of the art algorithms.Results show that, at scale, DeeSIL performance is 23 and 33 points higher thanthe best baseline when using the same and more initial data respectively.",Incremental Learning : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Incremental Learning (IL) is an interesting AI problem when the algorithm isassumed to work on a budget. This is especially true when IL is modeled using adeep learning approach, where two com- plex challenges arise due to limitedmemory, which induces catastrophic forgetting and delays related to theretraining needed in order to incorpo- rate new classes. Here we introduceDeeSIL, an adaptation of a known transfer learning scheme that combines a fixeddeep representation used as feature extractor and learning independent shallowclassifiers to in- crease recognition capacity. This scheme tackles the twoaforementioned challenges since it works well with a limited memory budget andeach new concept can be added within a minute. Moreover, since no deep re-training is needed when the model is incremented, DeeSIL can integrate largeramounts of initial data that provide more transferable features. Performance isevaluated on ImageNet LSVRC 2012 against three state of the art algorithms.Results show that, at scale, DeeSIL performance is 23 and 33 points higher thanthe best baseline when using the same and more initial data respectively. ### Response: Incremental Learning : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Anomalies in images occur in various scales from a small hole on a carpet to a large stain. However, anomaly detection based on sparse coding, one of the widely used anomaly detection methods, has an issue in dealing with anomalies that are out of the patch size employed to sparsely represent images. A large anomaly can be considered normal if seen in a small scale, but it is not easy to determine a single scale (patch size) that works well for all images. Then, we propose to incorporate multi-scale features to sparse coding and improve the performance of anomaly detection. The proposed method, multi-layer feature sparse coding (MLF-SC), employs a neural network for feature extraction, and feature maps from intermediate layers of the network are given to sparse coding, whereas the standard sparse-coding-based anomaly detection method directly works on given images. We show that MLF-SC outperforms state-of-the-art anomaly detection methods including those employing deep learning. Our target data are the texture categories of the MVTec Anomaly Detection (MVTec AD) dataset, which is a modern benchmark dataset consisting of images from the real world. Our idea can be a simple and practical option to deal with practical data.",Anomaly Detection : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Anomalies in images occur in various scales from a small hole on a carpet to a large stain. However, anomaly detection based on sparse coding, one of the widely used anomaly detection methods, has an issue in dealing with anomalies that are out of the patch size employed to sparsely represent images. A large anomaly can be considered normal if seen in a small scale, but it is not easy to determine a single scale (patch size) that works well for all images. Then, we propose to incorporate multi-scale features to sparse coding and improve the performance of anomaly detection. The proposed method, multi-layer feature sparse coding (MLF-SC), employs a neural network for feature extraction, and feature maps from intermediate layers of the network are given to sparse coding, whereas the standard sparse-coding-based anomaly detection method directly works on given images. We show that MLF-SC outperforms state-of-the-art anomaly detection methods including those employing deep learning. Our target data are the texture categories of the MVTec Anomaly Detection (MVTec AD) dataset, which is a modern benchmark dataset consisting of images from the real world. Our idea can be a simple and practical option to deal with practical data. ### Response: Anomaly Detection : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Selfie-based biometrics has great potential for a wide range of applications from marketing to higher security environments like online banking. This is now especially relevant since e.g. periocular verification is contactless, and thereby safe to use in pandemics such as COVID-19. However, selfie-based biometrics faces some challenges since there is limited control over the data acquisition conditions. Therefore, super-resolution has to be used to increase the quality of the captured images. Most of the state of the art super-resolution methods use deep networks with large filters, thereby needing to train and store a correspondingly large number of parameters, and making their use difficult for mobile devices commonly used for selfie-based. In order to achieve an efficient super-resolution method, we propose an Efficient Single Image Super-Resolution (ESISR) algorithm, which takes into account a trade-off between the efficiency of the deep neural network and the size of its filters. To that end, the method implements a novel loss function based on the Sharpness metric. This metric turns out to be more suitable for increasing the quality of the eye images. Our method drastically reduces the number of parameters when compared with Deep CNNs with Skip Connection and Network (DCSCN): from 2,170,142 to 28,654 parameters when the image size is increased by a factor of x3. Furthermore, the proposed method keeps the sharp quality of the images, which is highly relevant for biometric recognition purposes. The results on remote verification systems with raw images reached an Equal Error Rate (EER) of 8.7% for FaceNet and 10.05% for VGGFace. Where embedding vectors were used from periocular images the best results reached an EER of 8.9% (x3) for FaceNet and 9.90% (x4) for VGGFace.",Image Super-Resolution : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Selfie-based biometrics has great potential for a wide range of applications from marketing to higher security environments like online banking. This is now especially relevant since e.g. periocular verification is contactless, and thereby safe to use in pandemics such as COVID-19. However, selfie-based biometrics faces some challenges since there is limited control over the data acquisition conditions. Therefore, super-resolution has to be used to increase the quality of the captured images. Most of the state of the art super-resolution methods use deep networks with large filters, thereby needing to train and store a correspondingly large number of parameters, and making their use difficult for mobile devices commonly used for selfie-based. In order to achieve an efficient super-resolution method, we propose an Efficient Single Image Super-Resolution (ESISR) algorithm, which takes into account a trade-off between the efficiency of the deep neural network and the size of its filters. To that end, the method implements a novel loss function based on the Sharpness metric. This metric turns out to be more suitable for increasing the quality of the eye images. Our method drastically reduces the number of parameters when compared with Deep CNNs with Skip Connection and Network (DCSCN): from 2,170,142 to 28,654 parameters when the image size is increased by a factor of x3. Furthermore, the proposed method keeps the sharp quality of the images, which is highly relevant for biometric recognition purposes. The results on remote verification systems with raw images reached an Equal Error Rate (EER) of 8.7% for FaceNet and 10.05% for VGGFace. Where embedding vectors were used from periocular images the best results reached an EER of 8.9% (x3) for FaceNet and 9.90% (x4) for VGGFace. ### Response: Image Super-Resolution : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Deep learning methods have proven extremely effective at performing a variety of medical image analysis tasks. With their potential use in clinical routine, their lack of transparency has however been one of their few weak points, raising concerns regarding their behavior and failure modes. While most research to infer model behavior has focused on indirect strategies that estimate prediction uncertainties and visualize model support in the input image space, the ability to explicitly query a prediction model regarding its image content offers a more direct way to determine the behavior of trained models. To this end, we present a novel Visual Question Answering approach that allows an image to be queried by means of a written question. Experiments on a variety of medical and natural image datasets show that by fusing image and question features in a novel way, the proposed approach achieves an equal or higher accuracy compared to current methods.",Visual Question Answering : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Deep learning methods have proven extremely effective at performing a variety of medical image analysis tasks. With their potential use in clinical routine, their lack of transparency has however been one of their few weak points, raising concerns regarding their behavior and failure modes. While most research to infer model behavior has focused on indirect strategies that estimate prediction uncertainties and visualize model support in the input image space, the ability to explicitly query a prediction model regarding its image content offers a more direct way to determine the behavior of trained models. To this end, we present a novel Visual Question Answering approach that allows an image to be queried by means of a written question. Experiments on a variety of medical and natural image datasets show that by fusing image and question features in a novel way, the proposed approach achieves an equal or higher accuracy compared to current methods. ### Response: Visual Question Answering : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Semantic Segmentation is a crucial component in the perception systems of many applications, such as robotics and autonomous driving that rely on accurate environmental perception and understanding. In literature, several approaches are introduced to attempt LiDAR semantic segmentation task, such as projection-based (range-view or birds-eye-view), and voxel-based approaches. However, they either abandon the valuable 3D topology and geometric relations and suffer from information loss introduced in the projection process or are inefficient. Therefore, there is a need for accurate models capable of processing the 3D driving-scene point cloud in 3D space. In this paper, we propose S3Net, a novel convolutional neural network for LiDAR point cloud semantic segmentation. It adopts an encoder-decoder backbone that consists of Sparse Intra-channel Attention Module (SIntraAM), and Sparse Inter-channel Attention Module (SInterAM) to emphasize the fine details of both within each feature map and among nearby feature maps. To extract the global contexts in deeper layers, we introduce Sparse Residual Tower based upon sparse convolution that suits varying sparsity of LiDAR point cloud. In addition, geo-aware anisotrophic loss is leveraged to emphasize the semantic boundaries and penalize the noise within each predicted regions, leading to a robust prediction. Our experimental results show that the proposed method leads to a large improvement (12\%) compared to its baseline counterpart (MinkNet42 \cite{choy20194d}) on SemanticKITTI \cite{DBLP:conf/iccv/BehleyGMQBSG19} test set and achieves state-of-the-art mIoU accuracy of semantic segmentation approaches.",Semantic Segmentation : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Semantic Segmentation is a crucial component in the perception systems of many applications, such as robotics and autonomous driving that rely on accurate environmental perception and understanding. In literature, several approaches are introduced to attempt LiDAR semantic segmentation task, such as projection-based (range-view or birds-eye-view), and voxel-based approaches. However, they either abandon the valuable 3D topology and geometric relations and suffer from information loss introduced in the projection process or are inefficient. Therefore, there is a need for accurate models capable of processing the 3D driving-scene point cloud in 3D space. In this paper, we propose S3Net, a novel convolutional neural network for LiDAR point cloud semantic segmentation. It adopts an encoder-decoder backbone that consists of Sparse Intra-channel Attention Module (SIntraAM), and Sparse Inter-channel Attention Module (SInterAM) to emphasize the fine details of both within each feature map and among nearby feature maps. To extract the global contexts in deeper layers, we introduce Sparse Residual Tower based upon sparse convolution that suits varying sparsity of LiDAR point cloud. In addition, geo-aware anisotrophic loss is leveraged to emphasize the semantic boundaries and penalize the noise within each predicted regions, leading to a robust prediction. Our experimental results show that the proposed method leads to a large improvement (12\%) compared to its baseline counterpart (MinkNet42 \cite{choy20194d}) on SemanticKITTI \cite{DBLP:conf/iccv/BehleyGMQBSG19} test set and achieves state-of-the-art mIoU accuracy of semantic segmentation approaches. ### Response: Semantic Segmentation : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","This paper describes the submission to the IWSLT 2021 Low-Resource Speech Translation Shared Task by IMS team. We utilize state-of-the-art models combined with several data augmentation, multi-task and transfer learning approaches for the automatic speech recognition (ASR) and machine translation (MT) steps of our cascaded system. Moreover, we also explore the feasibility of a full end-to-end speech translation (ST) model in the case of very constrained amount of ground truth labeled data. Our best system achieves the best performance among all submitted systems for Congolese Swahili to English and French with BLEU scores 7.7 and 13.7 respectively, and the second best result for Coastal Swahili to English with BLEU score 14.9.",Translation : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: This paper describes the submission to the IWSLT 2021 Low-Resource Speech Translation Shared Task by IMS team. We utilize state-of-the-art models combined with several data augmentation, multi-task and transfer learning approaches for the automatic speech recognition (ASR) and machine translation (MT) steps of our cascaded system. Moreover, we also explore the feasibility of a full end-to-end speech translation (ST) model in the case of very constrained amount of ground truth labeled data. Our best system achieves the best performance among all submitted systems for Congolese Swahili to English and French with BLEU scores 7.7 and 13.7 respectively, and the second best result for Coastal Swahili to English with BLEU score 14.9. ### Response: Translation : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","In machine translation it is common phenomenon that machine-readabledictionaries and standard parsing rules are not enough to ensure accuracy inparsing and translating English phrases into Korean language, which is revealedin misleading translation results due to consequent structural and semanticambiguities. This paper aims to suggest a solution to structural and semanticambiguities due to the idiomaticity and non-grammaticalness of phrases commonlyused in English language by applying bilingual phrase database inEnglish-Korean Machine Translation (EKMT). This paper firstly clarifies whatthe phrase unit in EKMT is based on the definition of the English phrase,secondly clarifies what kind of language unit can be the target of the phrasedatabase for EKMT, thirdly suggests a way to build the phrase database bypresenting the format of the phrase database with examples, and finallydiscusses briefly the method to apply this bilingual phrase database to theEKMT for structural and semantic disambiguation.",Machine Translation : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: In machine translation it is common phenomenon that machine-readabledictionaries and standard parsing rules are not enough to ensure accuracy inparsing and translating English phrases into Korean language, which is revealedin misleading translation results due to consequent structural and semanticambiguities. This paper aims to suggest a solution to structural and semanticambiguities due to the idiomaticity and non-grammaticalness of phrases commonlyused in English language by applying bilingual phrase database inEnglish-Korean Machine Translation (EKMT). This paper firstly clarifies whatthe phrase unit in EKMT is based on the definition of the English phrase,secondly clarifies what kind of language unit can be the target of the phrasedatabase for EKMT, thirdly suggests a way to build the phrase database bypresenting the format of the phrase database with examples, and finallydiscusses briefly the method to apply this bilingual phrase database to theEKMT for structural and semantic disambiguation. ### Response: Machine Translation : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Fine-Grained Visual Categorization (FGVC) is a challenging topic in computer vision. It is a problem characterized by large intra-class differences and subtle inter-class differences. In this paper, we tackle this problem in a weakly supervised manner, where neural network models are getting fed with additional data using a data augmentation technique through a visual attention mechanism. We perform domain adaptive knowledge transfer via fine-tuning on our base network model. We perform our experiment on six challenging and commonly used FGVC datasets, and we show competitive improvement on accuracies by using attention-aware data augmentation techniques with features derived from deep learning model InceptionV3, pre-trained on large scale datasets. Our method outperforms competitor methods on multiple FGVC datasets and showed competitive results on other datasets. Experimental studies show that transfer learning from large scale datasets can be utilized effectively with visual attention based data augmentation, which can obtain state-of-the-art results on several FGVC datasets. We present a comprehensive analysis of our experiments. Our method achieves state-of-the-art results in multiple fine-grained classification datasets including challenging CUB200-2011 bird, Flowers-102, and FGVC-Aircrafts datasets.",Fine-Grained Visual Categorization : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Fine-Grained Visual Categorization (FGVC) is a challenging topic in computer vision. It is a problem characterized by large intra-class differences and subtle inter-class differences. In this paper, we tackle this problem in a weakly supervised manner, where neural network models are getting fed with additional data using a data augmentation technique through a visual attention mechanism. We perform domain adaptive knowledge transfer via fine-tuning on our base network model. We perform our experiment on six challenging and commonly used FGVC datasets, and we show competitive improvement on accuracies by using attention-aware data augmentation techniques with features derived from deep learning model InceptionV3, pre-trained on large scale datasets. Our method outperforms competitor methods on multiple FGVC datasets and showed competitive results on other datasets. Experimental studies show that transfer learning from large scale datasets can be utilized effectively with visual attention based data augmentation, which can obtain state-of-the-art results on several FGVC datasets. We present a comprehensive analysis of our experiments. Our method achieves state-of-the-art results in multiple fine-grained classification datasets including challenging CUB200-2011 bird, Flowers-102, and FGVC-Aircrafts datasets. ### Response: Fine-Grained Visual Categorization : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Although Generative Adversarial Networks have shown remarkable performance in image generation, there are some challenges in image realism and convergence speed. The results of some models display the imbalances of quality within a generated image, in which some defective parts appear compared with other regions. Different from general single global optimization methods, we introduce an adaptive global and local bilevel optimization model(GL-GAN). The model achieves the generation of high-resolution images in a complementary and promoting way, where global optimization is to optimize the whole images and local is only to optimize the low-quality areas. With a simple network structure, GL-GAN is allowed to effectively avoid the nature of imbalance by local bilevel optimization , which is accomplished by first locating low-quality areas and then optimizing them. Moreover, by using feature map cues from discriminator output, we propose the adaptive local and global optimization method(Ada-OP) for specific implementation and find that it boosts the convergence speed. Compared with the current GAN methods, our model has shown impressive performance on CelebA, CelebA-HQ and LSUN datasets.",bilevel optimization : RESEARCH_PROBLEM; bilevel optimization : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Although Generative Adversarial Networks have shown remarkable performance in image generation, there are some challenges in image realism and convergence speed. The results of some models display the imbalances of quality within a generated image, in which some defective parts appear compared with other regions. Different from general single global optimization methods, we introduce an adaptive global and local bilevel optimization model(GL-GAN). The model achieves the generation of high-resolution images in a complementary and promoting way, where global optimization is to optimize the whole images and local is only to optimize the low-quality areas. With a simple network structure, GL-GAN is allowed to effectively avoid the nature of imbalance by local bilevel optimization , which is accomplished by first locating low-quality areas and then optimizing them. Moreover, by using feature map cues from discriminator output, we propose the adaptive local and global optimization method(Ada-OP) for specific implementation and find that it boosts the convergence speed. Compared with the current GAN methods, our model has shown impressive performance on CelebA, CelebA-HQ and LSUN datasets. ### Response: bilevel optimization : RESEARCH_PROBLEM; bilevel optimization : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","This paper describes our results at the NLI shared task 2017. We participated in essays, speech, and fusion task that uses text, speech, and i-vectors for the task of identifying the native language of the given input. In the essay track, a linear SVM system using word bigrams and character 7-grams performed the best. In the speech track, an LDA classifier based only on i-vectors performed better than a combination system using text features from speech transcriptions and i-vectors. In the fusion task, we experimented with systems that used combination of i-vectors with higher order n-grams features, combination of i-vectors with word unigrams, a mean probability ensemble, and a stacked ensemble system. Our finding is that word unigrams in combination with i-vectors achieve higher score than systems trained with larger number of $n$-gram features. Our best-performing systems achieved F1-scores of 87.16{\%}, 83.33{\%} and 91.75{\%} on the essay track, the speech track and the fusion track respectively.",SVM : METHOD; LDA : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: This paper describes our results at the NLI shared task 2017. We participated in essays, speech, and fusion task that uses text, speech, and i-vectors for the task of identifying the native language of the given input. In the essay track, a linear SVM system using word bigrams and character 7-grams performed the best. In the speech track, an LDA classifier based only on i-vectors performed better than a combination system using text features from speech transcriptions and i-vectors. In the fusion task, we experimented with systems that used combination of i-vectors with higher order n-grams features, combination of i-vectors with word unigrams, a mean probability ensemble, and a stacked ensemble system. Our finding is that word unigrams in combination with i-vectors achieve higher score than systems trained with larger number of $n$-gram features. Our best-performing systems achieved F1-scores of 87.16{\%}, 83.33{\%} and 91.75{\%} on the essay track, the speech track and the fusion track respectively. ### Response: SVM : METHOD; LDA : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Contextual word embedding models such as ELMo (Peters et al., 2018) and BERT (Devlin et al., 2018) have dramatically improved performance for many natural language processing (NLP) tasks in recent months. However, these models have been minimally explored on specialty corpora, such as clinical text; moreover, in the clinical domain, no publicly-available pre-trained BERT models yet exist. In this work, we address this need by exploring and releasing BERT models for clinical text: one for generic clinical text and another for discharge summaries specifically. We demonstrate that using a domain-specific model yields performance improvements on three common clinical NLP tasks as compared to nonspecific embeddings. These domain-specific models are not as performant on two clinical de-identification tasks, and argue that this is a natural consequence of the differences between de-identified source text and synthetically non de-identified task text.",ELMo : METHOD; BERT : METHOD; BERT : METHOD; BERT : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Contextual word embedding models such as ELMo (Peters et al., 2018) and BERT (Devlin et al., 2018) have dramatically improved performance for many natural language processing (NLP) tasks in recent months. However, these models have been minimally explored on specialty corpora, such as clinical text; moreover, in the clinical domain, no publicly-available pre-trained BERT models yet exist. In this work, we address this need by exploring and releasing BERT models for clinical text: one for generic clinical text and another for discharge summaries specifically. We demonstrate that using a domain-specific model yields performance improvements on three common clinical NLP tasks as compared to nonspecific embeddings. These domain-specific models are not as performant on two clinical de-identification tasks, and argue that this is a natural consequence of the differences between de-identified source text and synthetically non de-identified task text. ### Response: ELMo : METHOD; BERT : METHOD; BERT : METHOD; BERT : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Generative Adversarial Nets (GAN s) represent an important milestone foreffective generative models, which has inspired numerous variants seeminglydifferent from each other. One of the main contributions of this paper is toreveal a unified geometric structure in GAN and its variants. Specifically, weshow that the adversarial generative model training can be decomposed intothree geometric steps: separating hyperplane search, discriminator parameterupdate away from the separating hyperplane, and the generator update along thenormal vector direction of the separating hyperplane. This geometric intuitionreveals the limitations of the existing approaches and leads us to propose anew formulation called geometric GAN using SVM separating hyperplane thatmaximizes the margin. Our theoretical analysis shows that the geometric GAN converges to a Nash equilibrium between the discriminator and generator. Inaddition, extensive numerical results show that the superior performance ofgeometric GAN .",(GAN : METHOD; GAN : METHOD; GAN : METHOD; SVM : METHOD; GAN : METHOD; GAN : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Generative Adversarial Nets (GAN s) represent an important milestone foreffective generative models, which has inspired numerous variants seeminglydifferent from each other. One of the main contributions of this paper is toreveal a unified geometric structure in GAN and its variants. Specifically, weshow that the adversarial generative model training can be decomposed intothree geometric steps: separating hyperplane search, discriminator parameterupdate away from the separating hyperplane, and the generator update along thenormal vector direction of the separating hyperplane. This geometric intuitionreveals the limitations of the existing approaches and leads us to propose anew formulation called geometric GAN using SVM separating hyperplane thatmaximizes the margin. Our theoretical analysis shows that the geometric GAN converges to a Nash equilibrium between the discriminator and generator. Inaddition, extensive numerical results show that the superior performance ofgeometric GAN . ### Response: (GAN : METHOD; GAN : METHOD; GAN : METHOD; SVM : METHOD; GAN : METHOD; GAN : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","In recent years, there has been a surge of interest in automatically describing images or videos in a natural language. These descriptions are useful for image/video search, etc. In this paper, we focus on procedure execution videos, in which a human makes or repairs something and propose a method for generating procedural texts from them. Since video/text pairs available are limited in size, the direct application of end-to-end deep learning is not feasible. Thus we propose to train Faster R-CNN network for object recognition and LSTM for text generation and combine them at run time. We took pairs of recipe and cooking video, generated a recipe from a video, and compared it with the original recipe. The experimental results showed that our method can produce a recipe as accurate as the state-of-the-art scene descriptions.",Faster R-CNN : METHOD; LSTM : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: In recent years, there has been a surge of interest in automatically describing images or videos in a natural language. These descriptions are useful for image/video search, etc. In this paper, we focus on procedure execution videos, in which a human makes or repairs something and propose a method for generating procedural texts from them. Since video/text pairs available are limited in size, the direct application of end-to-end deep learning is not feasible. Thus we propose to train Faster R-CNN network for object recognition and LSTM for text generation and combine them at run time. We took pairs of recipe and cooking video, generated a recipe from a video, and compared it with the original recipe. The experimental results showed that our method can produce a recipe as accurate as the state-of-the-art scene descriptions. ### Response: Faster R-CNN : METHOD; LSTM : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","This research tested the following well known strategies to deal with binaryimbalanced data on 82 different real life data sets (sampled to imbalance ratesof 5%, 3%, 1%, and 0.1%): class weight, SMOTE , Underbagging, and a baseline(just the base classifier). As base classifiers we used SVM with RBF kernel,random forests, and gradient boosting machines and we measured the quality ofthe resulting classifier using 6 different metrics (Area under the curve,Accuracy, F-measure, G-mean, Matthew's correlation coefficient and Balancedaccuracy). The best strategy strongly depends on the metric used to measure thequality of the classifier. For AUC and accuracy class weight and the baselineperform better; for F-measure and MCC, SMOTE performs better; and for G-meanand balanced accuracy, underbagging.",SMOTE : METHOD; SVM : METHOD; SMOTE : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: This research tested the following well known strategies to deal with binaryimbalanced data on 82 different real life data sets (sampled to imbalance ratesof 5%, 3%, 1%, and 0.1%): class weight, SMOTE , Underbagging, and a baseline(just the base classifier). As base classifiers we used SVM with RBF kernel,random forests, and gradient boosting machines and we measured the quality ofthe resulting classifier using 6 different metrics (Area under the curve,Accuracy, F-measure, G-mean, Matthew's correlation coefficient and Balancedaccuracy). The best strategy strongly depends on the metric used to measure thequality of the classifier. For AUC and accuracy class weight and the baselineperform better; for F-measure and MCC, SMOTE performs better; and for G-meanand balanced accuracy, underbagging. ### Response: SMOTE : METHOD; SVM : METHOD; SMOTE : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","3D object detection plays a crucial role in environmental perception for autonomous vehicles, which is the prerequisite of decision and control. This paper analyses partition-based methods' inherent drawbacks. In the partition operation, a single instance such as a pedestrian is sliced into several pieces, which we call it the partition effect. We propose the Spatial-Attention Graph Convolution (S-AT GCN ), forming the Feature Enhancement (FE) layers to overcome this drawback. The S-AT GCN utilizes the graph convolution and the spatial attention mechanism to extract local geometrical structure features. This allows the network to have more meaningful features for the foreground. Our experiments on the KITTI 3D object and bird's eye view detection show that S-AT Conv and FE layers are effective, especially for small objects. FE layers boost the pedestrian class performance by 3.62\% and cyclist class by 4.21\% 3D mAP. The time cost of these extra FE layers are limited. PointPillars with FE layers can achieve 48 PFS, satisfying the real-time requirement.",Convolution : METHOD; GCN : METHOD; GCN : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: 3D object detection plays a crucial role in environmental perception for autonomous vehicles, which is the prerequisite of decision and control. This paper analyses partition-based methods' inherent drawbacks. In the partition operation, a single instance such as a pedestrian is sliced into several pieces, which we call it the partition effect. We propose the Spatial-Attention Graph Convolution (S-AT GCN ), forming the Feature Enhancement (FE) layers to overcome this drawback. The S-AT GCN utilizes the graph convolution and the spatial attention mechanism to extract local geometrical structure features. This allows the network to have more meaningful features for the foreground. Our experiments on the KITTI 3D object and bird's eye view detection show that S-AT Conv and FE layers are effective, especially for small objects. FE layers boost the pedestrian class performance by 3.62\% and cyclist class by 4.21\% 3D mAP. The time cost of these extra FE layers are limited. PointPillars with FE layers can achieve 48 PFS, satisfying the real-time requirement. ### Response: Convolution : METHOD; GCN : METHOD; GCN : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Student dropout prediction provides an opportunity to improve student engagement, which maximizes the overall effectiveness of learning experiences. However, researches on student dropout were mainly conducted on school dropout or course dropout, and study session dropout in a mobile learning environment has not been considered thoroughly. In this paper, we investigate the study session dropout prediction problem in a mobile learning environment. First, we define the concept of the study session, study session dropout and study session dropout prediction task in a mobile learning environment. Based on the definitions, we propose a novel Transformer based model for predicting study session dropout, DAS: Deep Attentive Study Session Dropout Prediction in Mobile Learning Environment. DAS has an encoder-decoder structure which is composed of stacked multi-head attention and point-wise feed-forward networks. The deep attentive computations in DAS are capable of capturing complex relations among dynamic student interactions. To the best of our knowledge, this is the first attempt to investigate study session dropout in a mobile learning environment. Empirical evaluations on a large-scale dataset show that DAS achieves the best performance with a significant improvement in area under the receiver operating characteristic curve compared to baseline models.",Transformer : METHOD; Dropout : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Student dropout prediction provides an opportunity to improve student engagement, which maximizes the overall effectiveness of learning experiences. However, researches on student dropout were mainly conducted on school dropout or course dropout, and study session dropout in a mobile learning environment has not been considered thoroughly. In this paper, we investigate the study session dropout prediction problem in a mobile learning environment. First, we define the concept of the study session, study session dropout and study session dropout prediction task in a mobile learning environment. Based on the definitions, we propose a novel Transformer based model for predicting study session dropout, DAS: Deep Attentive Study Session Dropout Prediction in Mobile Learning Environment. DAS has an encoder-decoder structure which is composed of stacked multi-head attention and point-wise feed-forward networks. The deep attentive computations in DAS are capable of capturing complex relations among dynamic student interactions. To the best of our knowledge, this is the first attempt to investigate study session dropout in a mobile learning environment. Empirical evaluations on a large-scale dataset show that DAS achieves the best performance with a significant improvement in area under the receiver operating characteristic curve compared to baseline models. ### Response: Transformer : METHOD; Dropout : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Convolution neural network demonstrates great capability for multiple tasks, such as image classification and many others. However, much resource is required to train a network. Hence much effort has been made to accelerate neural network by reducing precision of weights, activation, and gradient. However, these filter-wise quantification methods exist a natural upper limit, caused by the size of the kernel. Meanwhile, with the popularity of small kernel, the natural limit further decrease. To address this issue, we propose a new cross-filter compression method that can provide $\sim32\times$ memory savings and $122\times$ speed up in convolution operations. In our method, all convolution filters are quantized to given bits and spatially adjacent filters share the same scaling factor. Our compression method, based on Binary-Weight and XNOR-Net separately, is evaluated on CIFAR-10 and ImageNet dataset with widely used network structures, such as ResNet and VGG, and witness tolerable accuracy loss compared to state-of-the-art quantification methods.",Convolution : METHOD; ResNet : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Convolution neural network demonstrates great capability for multiple tasks, such as image classification and many others. However, much resource is required to train a network. Hence much effort has been made to accelerate neural network by reducing precision of weights, activation, and gradient. However, these filter-wise quantification methods exist a natural upper limit, caused by the size of the kernel. Meanwhile, with the popularity of small kernel, the natural limit further decrease. To address this issue, we propose a new cross-filter compression method that can provide $\sim32\times$ memory savings and $122\times$ speed up in convolution operations. In our method, all convolution filters are quantized to given bits and spatially adjacent filters share the same scaling factor. Our compression method, based on Binary-Weight and XNOR-Net separately, is evaluated on CIFAR-10 and ImageNet dataset with widely used network structures, such as ResNet and VGG, and witness tolerable accuracy loss compared to state-of-the-art quantification methods. ### Response: Convolution : METHOD; ResNet : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","This paper describes the winning system for SemEval-2017 Task 6: {\#}HashtagWars: Learning a Sense of Humor. Humor detection has up until now been predominantly addressed using feature-based approaches. Our system utilizes recurrent deep learning methods with dense embeddings to predict humorous tweets from the @midnight show {\#}HashtagWars. In order to include both meaning and sound in the analysis, GloVe embeddings are combined with a novel phonetic representation to serve as input to an LSTM component. The output is combined with a character-based CNN model, and an XGBoost component in an ensemble model which achieves 0.675 accuracy on the evaluation data.",GloVe : METHOD; LSTM : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: This paper describes the winning system for SemEval-2017 Task 6: {\#}HashtagWars: Learning a Sense of Humor. Humor detection has up until now been predominantly addressed using feature-based approaches. Our system utilizes recurrent deep learning methods with dense embeddings to predict humorous tweets from the @midnight show {\#}HashtagWars. In order to include both meaning and sound in the analysis, GloVe embeddings are combined with a novel phonetic representation to serve as input to an LSTM component. The output is combined with a character-based CNN model, and an XGBoost component in an ensemble model which achieves 0.675 accuracy on the evaluation data. ### Response: GloVe : METHOD; LSTM : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","BERT has recently attracted a lot of attention in natural language understanding (NLU) and achieved state-of-the-art results in various NLU tasks. However, its success requires large deep neural networks and huge amount of data, which result in long training time and impede development progress. Using stochastic gradient methods with large mini-batch has been advocated as an efficient tool to reduce the training time. Along this line of research, LAMB is a prominent example that reduces the training time of BERT from 3 days to 76 minutes on a TPUv3 Pod. In this paper, we propose an accelerated gradient method called LANS to improve the efficiency of using large mini-batches for training. As the learning rate is theoretically upper bounded by the inverse of the Lipschitz constant of the function, one cannot always reduce the number of optimization iterations by selecting a larger learning rate. In order to use larger mini-batch size without accuracy loss, we develop a new learning rate scheduler that overcomes the difficulty of using large learning rate. Using the proposed LANS method and the learning rate scheme, we scaled up the mini-batch sizes to 96K and 33K in phases 1 and 2 of BERT pretraining, respectively. It takes 54 minutes on 192 AWS EC2 P3dn.24xlarge instances to achieve a target F1 score of 90.5 or higher on SQuAD v1.1, achieving the fastest BERT training time in the cloud.",BERT : METHOD; LAMB : METHOD; BERT : METHOD; BERT : METHOD; BERT : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: BERT has recently attracted a lot of attention in natural language understanding (NLU) and achieved state-of-the-art results in various NLU tasks. However, its success requires large deep neural networks and huge amount of data, which result in long training time and impede development progress. Using stochastic gradient methods with large mini-batch has been advocated as an efficient tool to reduce the training time. Along this line of research, LAMB is a prominent example that reduces the training time of BERT from 3 days to 76 minutes on a TPUv3 Pod. In this paper, we propose an accelerated gradient method called LANS to improve the efficiency of using large mini-batches for training. As the learning rate is theoretically upper bounded by the inverse of the Lipschitz constant of the function, one cannot always reduce the number of optimization iterations by selecting a larger learning rate. In order to use larger mini-batch size without accuracy loss, we develop a new learning rate scheduler that overcomes the difficulty of using large learning rate. Using the proposed LANS method and the learning rate scheme, we scaled up the mini-batch sizes to 96K and 33K in phases 1 and 2 of BERT pretraining, respectively. It takes 54 minutes on 192 AWS EC2 P3dn.24xlarge instances to achieve a target F1 score of 90.5 or higher on SQuAD v1.1, achieving the fastest BERT training time in the cloud. ### Response: BERT : METHOD; LAMB : METHOD; BERT : METHOD; BERT : METHOD; BERT : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","DETR has been recently proposed to eliminate the need for many hand-designed components in object detection while demonstrating good performance. However, it suffers from slow convergence and limited feature spatial resolution, due to the limitation of Transformer attention modules in processing image feature maps. To mitigate these issues, we proposed Deformable DETR , whose attention modules only attend to a small set of key sampling points around a reference. Deformable DETR can achieve better performance than DETR (especially on small objects) with 10 times less training epochs. Extensive experiments on the COCO benchmark demonstrate the effectiveness of our approach. Code is released at https://github.com/fundamentalvision/Deformable-DETR.",Transformer : METHOD; Deformable DETR : METHOD; Deformable DETR : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: DETR has been recently proposed to eliminate the need for many hand-designed components in object detection while demonstrating good performance. However, it suffers from slow convergence and limited feature spatial resolution, due to the limitation of Transformer attention modules in processing image feature maps. To mitigate these issues, we proposed Deformable DETR , whose attention modules only attend to a small set of key sampling points around a reference. Deformable DETR can achieve better performance than DETR (especially on small objects) with 10 times less training epochs. Extensive experiments on the COCO benchmark demonstrate the effectiveness of our approach. Code is released at https://github.com/fundamentalvision/Deformable-DETR. ### Response: Transformer : METHOD; Deformable DETR : METHOD; Deformable DETR : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Decentralized Parallel SGD (D-PSGD ) and its asynchronous variant Asynchronous Parallel SGD (AD-PSGD ) is a family of distributed learning algorithms that have been demonstrated to perform well for large-scale deep learning tasks. One drawback of (A)D-PSGD is that the spectral gap of the mixing matrix decreases when the number of learners in the system increases, which hampers convergence. In this paper, we investigate techniques to accelerate (A)D-PSGD based training by improving the spectral gap while minimizing the communication cost. We demonstrate the effectiveness of our proposed techniques by running experiments on the 2000-hour Switchboard speech recognition task and the ImageNet computer vision task. On an IBM P9 supercomputer, our system is able to train an LSTM acoustic model in 2.28 hours with 7.5% WER on the Hub5-2000 Switchboard (SWB) test set and 13.3% WER on the CallHome (CH) test set using 64 V100 GPUs and in 1.98 hours with 7.7% WER on SWB and 13.3% WER on CH using 128 V100 GPUs, the fastest training time reported to date.",SGD : METHOD; (D-PSGD : METHOD; SGD : METHOD; (AD-PSGD : METHOD; (A)D-PSGD : METHOD; (A)D-PSGD : METHOD; LSTM : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Decentralized Parallel SGD (D-PSGD ) and its asynchronous variant Asynchronous Parallel SGD (AD-PSGD ) is a family of distributed learning algorithms that have been demonstrated to perform well for large-scale deep learning tasks. One drawback of (A)D-PSGD is that the spectral gap of the mixing matrix decreases when the number of learners in the system increases, which hampers convergence. In this paper, we investigate techniques to accelerate (A)D-PSGD based training by improving the spectral gap while minimizing the communication cost. We demonstrate the effectiveness of our proposed techniques by running experiments on the 2000-hour Switchboard speech recognition task and the ImageNet computer vision task. On an IBM P9 supercomputer, our system is able to train an LSTM acoustic model in 2.28 hours with 7.5% WER on the Hub5-2000 Switchboard (SWB) test set and 13.3% WER on the CallHome (CH) test set using 64 V100 GPUs and in 1.98 hours with 7.7% WER on SWB and 13.3% WER on CH using 128 V100 GPUs, the fastest training time reported to date. ### Response: SGD : METHOD; (D-PSGD : METHOD; SGD : METHOD; (AD-PSGD : METHOD; (A)D-PSGD : METHOD; (A)D-PSGD : METHOD; LSTM : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Effective models of social dialog must understand a broad range of rhetoricaland figurative devices. Rhetorical questions (RQs) are a type of figurativelanguage whose aim is to achieve a pragmatic goal, such as structuring anargument, being persuasive, emphasizing a point, or being ironic. While thereare computational models for other forms of figurative language, rhetoricalquestions have received little attention to date. We expand a small datasetfrom previous work, presenting a corpus of 10,270 RQs from debate forums andTwitter that represent different discourse functions. We show that we canclearly distinguish between RQs and sincere questions (0.76 F1). We then showthat RQs can be used both sarcastically and non-sarcastically, observing thatnon-sarcastic (other) uses of RQs are frequently argumentative in forums, andpersuasive in tweets. We present experiments to distinguish between these usesof RQs using SVM and LSTM models that represent linguistic features andpost-level context, achieving results as high as 0.76 F1 for ""sarcastic"" and0.77 F1 for ""other"" in forums, and 0.83 F1 for both ""sarcastic"" and ""other"" intweets. We supplement our quantitative experiments with an in-depthcharacterization of the linguistic variation in RQs.",SVM : METHOD; LSTM : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Effective models of social dialog must understand a broad range of rhetoricaland figurative devices. Rhetorical questions (RQs) are a type of figurativelanguage whose aim is to achieve a pragmatic goal, such as structuring anargument, being persuasive, emphasizing a point, or being ironic. While thereare computational models for other forms of figurative language, rhetoricalquestions have received little attention to date. We expand a small datasetfrom previous work, presenting a corpus of 10,270 RQs from debate forums andTwitter that represent different discourse functions. We show that we canclearly distinguish between RQs and sincere questions (0.76 F1). We then showthat RQs can be used both sarcastically and non-sarcastically, observing thatnon-sarcastic (other) uses of RQs are frequently argumentative in forums, andpersuasive in tweets. We present experiments to distinguish between these usesof RQs using SVM and LSTM models that represent linguistic features andpost-level context, achieving results as high as 0.76 F1 for ""sarcastic"" and0.77 F1 for ""other"" in forums, and 0.83 F1 for both ""sarcastic"" and ""other"" intweets. We supplement our quantitative experiments with an in-depthcharacterization of the linguistic variation in RQs. ### Response: SVM : METHOD; LSTM : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Stateful optimizers maintain gradient statistics over time, e.g., the exponentially smoothed sum (SGD with momentum) or squared sum (Adam) of past gradient values. This state can be used to accelerate optimization significantly, compared to plain stochastic gradient descent, but uses memory that might otherwise be allocated to model parameters, thereby limiting the maximum size of models trained in practice. In this paper, we develop the first optimizers that use 8-bit statistics while maintaining the performance levels of using 32-bit optimizer states. To overcome the resulting computational, quantization, and stability challenges, we develop block-wise dynamic quantization. Block-wise quantization divides input tensors into smaller blocks that are independently quantized. Each block is processed in parallel across cores, yielding faster optimization and high precision quantization. To maintain stability and performance, we combine block-wise quantization with two additional changes: (1) dynamic quantization, a form of non-linear optimization that is precise for both large and small magnitude values, and (2) a stable embedding layer to reduce gradient variance that comes from the highly non-uniform distribution of input tokens in language models. As a result, our 8-bit optimizers maintain 32-bit performance with a small fraction of the memory footprint on a range of tasks, including 1.5B parameter language modeling, GLUE finetuning, ImageNet classification, WMT'14 machine translation, MoCo v2 contrastive ImageNet pretraining+finetuning, and RoBERTa pretraining, without changes to the original optimizer hyperparameters. We open-source our 8-bit optimizers as a drop-in replacement that only requires a two-line code change.",MoCo v2 : METHOD; RoBERTa : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Stateful optimizers maintain gradient statistics over time, e.g., the exponentially smoothed sum (SGD with momentum) or squared sum (Adam) of past gradient values. This state can be used to accelerate optimization significantly, compared to plain stochastic gradient descent, but uses memory that might otherwise be allocated to model parameters, thereby limiting the maximum size of models trained in practice. In this paper, we develop the first optimizers that use 8-bit statistics while maintaining the performance levels of using 32-bit optimizer states. To overcome the resulting computational, quantization, and stability challenges, we develop block-wise dynamic quantization. Block-wise quantization divides input tensors into smaller blocks that are independently quantized. Each block is processed in parallel across cores, yielding faster optimization and high precision quantization. To maintain stability and performance, we combine block-wise quantization with two additional changes: (1) dynamic quantization, a form of non-linear optimization that is precise for both large and small magnitude values, and (2) a stable embedding layer to reduce gradient variance that comes from the highly non-uniform distribution of input tokens in language models. As a result, our 8-bit optimizers maintain 32-bit performance with a small fraction of the memory footprint on a range of tasks, including 1.5B parameter language modeling, GLUE finetuning, ImageNet classification, WMT'14 machine translation, MoCo v2 contrastive ImageNet pretraining+finetuning, and RoBERTa pretraining, without changes to the original optimizer hyperparameters. We open-source our 8-bit optimizers as a drop-in replacement that only requires a two-line code change. ### Response: MoCo v2 : METHOD; RoBERTa : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","We consider the problem of learning distance-based Graph Convolutional Networks (GCN s) for relational data. Specifically, we first embed the original graph into the Euclidean space $\mathbb{R}^m$ using a relational density estimation technique thereby constructing a secondary Euclidean graph. The graph vertices correspond to the target triples and edges denote the Euclidean distances between the target triples. We emphasize the importance of learning the secondary Euclidean graph and the advantages of employing a distance matrix over the typically used adjacency matrix. Our comprehensive empirical evaluation demonstrates the superiority of our approach over $12$ different GCN models, relational embedding techniques and rule learning techniques.",Graph Convolutional Networks : METHOD; (GCN : METHOD; GCN : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: We consider the problem of learning distance-based Graph Convolutional Networks (GCN s) for relational data. Specifically, we first embed the original graph into the Euclidean space $\mathbb{R}^m$ using a relational density estimation technique thereby constructing a secondary Euclidean graph. The graph vertices correspond to the target triples and edges denote the Euclidean distances between the target triples. We emphasize the importance of learning the secondary Euclidean graph and the advantages of employing a distance matrix over the typically used adjacency matrix. Our comprehensive empirical evaluation demonstrates the superiority of our approach over $12$ different GCN models, relational embedding techniques and rule learning techniques. ### Response: Graph Convolutional Networks : METHOD; (GCN : METHOD; GCN : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","This paper introduces Click to Move (C2M), a novel framework for video generation where the user can control the motion of the synthesized video through mouse clicks specifying simple object trajectories of the key objects in the scene. Our model receives as input an initial frame, its corresponding segmentation map and the sparse motion vectors encoding the input provided by the user. It outputs a plausible video sequence starting from the given frame and with a motion that is consistent with user input. Notably, our proposed deep architecture incorporates a Graph Convolution Network (GCN ) modelling the movements of all the objects in the scene in a holistic manner and effectively combining the sparse user motion information and image features. Experimental results show that C2M outperforms existing methods on two publicly available datasets, thus demonstrating the effectiveness of our GCN framework at modelling object interactions. The source code is publicly available at https://github.com/PierfrancescoArdino/C2M.",Convolution : METHOD; (GCN : METHOD; GCN : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: This paper introduces Click to Move (C2M), a novel framework for video generation where the user can control the motion of the synthesized video through mouse clicks specifying simple object trajectories of the key objects in the scene. Our model receives as input an initial frame, its corresponding segmentation map and the sparse motion vectors encoding the input provided by the user. It outputs a plausible video sequence starting from the given frame and with a motion that is consistent with user input. Notably, our proposed deep architecture incorporates a Graph Convolution Network (GCN ) modelling the movements of all the objects in the scene in a holistic manner and effectively combining the sparse user motion information and image features. Experimental results show that C2M outperforms existing methods on two publicly available datasets, thus demonstrating the effectiveness of our GCN framework at modelling object interactions. The source code is publicly available at https://github.com/PierfrancescoArdino/C2M. ### Response: Convolution : METHOD; (GCN : METHOD; GCN : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Masked language model and autoregressive language model are two types of language models. While pretrained masked language models such as BERT overwhelm the line of natural language understanding (NLU) tasks, autoregressive language models such as GPT are especially capable in natural language generation (NLG). In this paper, we propose a probabilistic masking scheme for the masked language model, which we call probabilistically masked language model (PMLM ). We implement a specific PMLM with a uniform prior distribution on the masking ratio named u-PMLM . We prove that u-PMLM is equivalent to an autoregressive permutated language model. One main advantage of the model is that it supports text generation in arbitrary order with surprisingly good quality, which could potentially enable new applications over traditional unidirectional generation. Besides, the pretrained u-PMLM also outperforms BERT on a set of downstream NLU tasks.",BERT : METHOD; (PMLM : METHOD; PMLM : METHOD; u-PMLM : METHOD; u-PMLM : METHOD; u-PMLM : METHOD; BERT : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Masked language model and autoregressive language model are two types of language models. While pretrained masked language models such as BERT overwhelm the line of natural language understanding (NLU) tasks, autoregressive language models such as GPT are especially capable in natural language generation (NLG). In this paper, we propose a probabilistic masking scheme for the masked language model, which we call probabilistically masked language model (PMLM ). We implement a specific PMLM with a uniform prior distribution on the masking ratio named u-PMLM . We prove that u-PMLM is equivalent to an autoregressive permutated language model. One main advantage of the model is that it supports text generation in arbitrary order with surprisingly good quality, which could potentially enable new applications over traditional unidirectional generation. Besides, the pretrained u-PMLM also outperforms BERT on a set of downstream NLU tasks. ### Response: BERT : METHOD; (PMLM : METHOD; PMLM : METHOD; u-PMLM : METHOD; u-PMLM : METHOD; u-PMLM : METHOD; BERT : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","State-of-the-art neural networks are getting deeper and wider. While theirperformance increases with the increasing number of layers and neurons, it iscrucial to design an efficient deep architecture in order to reducecomputational and memory costs. Designing an efficient neural network, however,is labor intensive requiring many experiments, and fine-tunings. In this paper,we introduce network trimming which iteratively optimizes the network bypruning unimportant neurons based on analysis of their outputs on a largedataset. Our algorithm is inspired by an observation that the outputs of asignificant portion of neurons in a large network are mostly zero, regardlessof what inputs the network received. These zero activation neurons areredundant, and can be removed without affecting the overall accuracy of thenetwork. After pruning the zero activation neurons, we retrain the networkusing the weights before pruning as initialization. We alternate the pruningand retraining to further reduce zero activations in a network. Our experimentson the LeNet and VGG-16 show that we can achieve high compression ratio ofparameters without losing or even achieving higher accuracy than the originalnetwork.",LeNet : METHOD; VGG-16 : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: State-of-the-art neural networks are getting deeper and wider. While theirperformance increases with the increasing number of layers and neurons, it iscrucial to design an efficient deep architecture in order to reducecomputational and memory costs. Designing an efficient neural network, however,is labor intensive requiring many experiments, and fine-tunings. In this paper,we introduce network trimming which iteratively optimizes the network bypruning unimportant neurons based on analysis of their outputs on a largedataset. Our algorithm is inspired by an observation that the outputs of asignificant portion of neurons in a large network are mostly zero, regardlessof what inputs the network received. These zero activation neurons areredundant, and can be removed without affecting the overall accuracy of thenetwork. After pruning the zero activation neurons, we retrain the networkusing the weights before pruning as initialization. We alternate the pruningand retraining to further reduce zero activations in a network. Our experimentson the LeNet and VGG-16 show that we can achieve high compression ratio ofparameters without losing or even achieving higher accuracy than the originalnetwork. ### Response: LeNet : METHOD; VGG-16 : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Adaptive gradient algorithm (AdaGrad) and its variants, such as RMSProp, Adam , AMSGrad, etc, have been widely used in deep learning. Although these algorithms are faster in the early phase of training, their generalization performance is often not as good as stochastic gradient descent (SGD ). Hence, a trade-off method of transforming Adam to SGD after a certain iteration to gain the merits of both algorithms is theoretically and practically significant. To that end, we propose a decreasing scaling transition scheme to achieve a smooth and stable transition from Adam to SGD , which is called DSTAdam . The convergence of the proposed DSTAdam is also proved in an online convex setting. Finally, the effectiveness of the DSTAdam is verified on the CIFAR-10/100 datasets. Our implementation is available at: https://github.com/kunzeng/DSTAdam .",Adam : METHOD; (SGD : METHOD; Adam : METHOD; SGD : METHOD; Adam : METHOD; SGD : METHOD; DSTAdam : METHOD; DSTAdam : METHOD; DSTAdam : METHOD; https://github.com/kunzeng/DSTAdam : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Adaptive gradient algorithm (AdaGrad) and its variants, such as RMSProp, Adam , AMSGrad, etc, have been widely used in deep learning. Although these algorithms are faster in the early phase of training, their generalization performance is often not as good as stochastic gradient descent (SGD ). Hence, a trade-off method of transforming Adam to SGD after a certain iteration to gain the merits of both algorithms is theoretically and practically significant. To that end, we propose a decreasing scaling transition scheme to achieve a smooth and stable transition from Adam to SGD , which is called DSTAdam . The convergence of the proposed DSTAdam is also proved in an online convex setting. Finally, the effectiveness of the DSTAdam is verified on the CIFAR-10/100 datasets. Our implementation is available at: https://github.com/kunzeng/DSTAdam . ### Response: Adam : METHOD; (SGD : METHOD; Adam : METHOD; SGD : METHOD; Adam : METHOD; SGD : METHOD; DSTAdam : METHOD; DSTAdam : METHOD; DSTAdam : METHOD; https://github.com/kunzeng/DSTAdam : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Dropout as a regularizer in deep neural networks has been less effective in convolutional layers than in fully connected layers. This is due to the fact that dropout drops features randomly. When features are spatially correlated as in the case of convolutional layers, information about the dropped pixels can still propagate to the next layers via neighboring pixels. In order to address this problem, more structured forms of dropout have been proposed. A drawback of these methods is that they do not adapt to the data. In this work, we introduce a novel structured regularization for convolutional layers, which we call DropCluster. Our regularizer relies on data-driven structure. It finds clusters of correlated features in convolutional layer outputs and drops the clusters randomly at each iteration. The clusters are learned and updated during model training so that they adapt both to the data and to the model weights. Our experiments on the ResNet-50 architecture demonstrate that our approach achieves better performance than DropBlock or other existing structured dropout variants. We also demonstrate the robustness of our approach when the size of training data is limited and when there is corruption in the data at test time.",Dropout : METHOD; DropBlock : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Dropout as a regularizer in deep neural networks has been less effective in convolutional layers than in fully connected layers. This is due to the fact that dropout drops features randomly. When features are spatially correlated as in the case of convolutional layers, information about the dropped pixels can still propagate to the next layers via neighboring pixels. In order to address this problem, more structured forms of dropout have been proposed. A drawback of these methods is that they do not adapt to the data. In this work, we introduce a novel structured regularization for convolutional layers, which we call DropCluster. Our regularizer relies on data-driven structure. It finds clusters of correlated features in convolutional layer outputs and drops the clusters randomly at each iteration. The clusters are learned and updated during model training so that they adapt both to the data and to the model weights. Our experiments on the ResNet-50 architecture demonstrate that our approach achieves better performance than DropBlock or other existing structured dropout variants. We also demonstrate the robustness of our approach when the size of training data is limited and when there is corruption in the data at test time. ### Response: Dropout : METHOD; DropBlock : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Training deep Convolutional Neural Networks (CNN) is a time consuming taskthat may take weeks to complete. In this article we propose a novel,theoretically founded method for reducing CNN training time without incurringany loss in accuracy. The basic idea is to begin training with a pre-trainnetwork using lower-resolution kernels and input images, and then refine theresults at the full resolution by exploiting the spatial scaling property ofconvolutions. We apply our method to the ImageNet winner OverFeat and to themore recent ResNet architecture and show a reduction in training time of nearly20% while test set accuracy is preserved in both cases.",OverFeat : METHOD; ResNet : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Training deep Convolutional Neural Networks (CNN) is a time consuming taskthat may take weeks to complete. In this article we propose a novel,theoretically founded method for reducing CNN training time without incurringany loss in accuracy. The basic idea is to begin training with a pre-trainnetwork using lower-resolution kernels and input images, and then refine theresults at the full resolution by exploiting the spatial scaling property ofconvolutions. We apply our method to the ImageNet winner OverFeat and to themore recent ResNet architecture and show a reduction in training time of nearly20% while test set accuracy is preserved in both cases. ### Response: OverFeat : METHOD; ResNet : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","We introduce Dirichlet pruning, a novel post-processing technique to transform a large neural network model into a compressed one. Dirichlet pruning is a form of structured pruning that assigns the Dirichlet distribution over each layer's channels in convolutional layers (or neurons in fully-connected layers) and estimates the parameters of the distribution over these units using variational inference. The learned distribution allows us to remove unimportant units, resulting in a compact architecture containing only crucial features for a task at hand. The number of newly introduced Dirichlet parameters is only linear in the number of channels, which allows for rapid training, requiring as little as one epoch to converge. We perform extensive experiments, in particular on larger architectures such as VGG and ResNet (45% and 58% compression rate, respectively) where our method achieves the state-of-the-art compression performance and provides interpretable features as a by-product.",VGG : METHOD; ResNet : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: We introduce Dirichlet pruning, a novel post-processing technique to transform a large neural network model into a compressed one. Dirichlet pruning is a form of structured pruning that assigns the Dirichlet distribution over each layer's channels in convolutional layers (or neurons in fully-connected layers) and estimates the parameters of the distribution over these units using variational inference. The learned distribution allows us to remove unimportant units, resulting in a compact architecture containing only crucial features for a task at hand. The number of newly introduced Dirichlet parameters is only linear in the number of channels, which allows for rapid training, requiring as little as one epoch to converge. We perform extensive experiments, in particular on larger architectures such as VGG and ResNet (45% and 58% compression rate, respectively) where our method achieves the state-of-the-art compression performance and provides interpretable features as a by-product. ### Response: VGG : METHOD; ResNet : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Artificial Intelligence (AI) has created the single biggest technology revolution the world has ever seen. For the finance sector, it provides great opportunities to enhance customer experience, democratize financial services, ensure consumer protection and significantly improve risk management. While it is easier than ever to run state-of-the-art machine learning models, designing and implementing systems that support real-world finance applications have been challenging. In large part because they lack transparency and explainability which are important factors in establishing reliable technology and the research on this topic with a specific focus on applications in credit risk management. In this paper, we implement two advanced post-hoc model agnostic explainability techniques called Local Interpretable Model Agnostic Explanations (LIME ) and SHapley Additive exPlanations (SHAP ) to machine learning (ML)-based credit scoring models applied to the open-access data set offered by the US-based P2P Lending Platform, Lending Club. Specifically, we use LIME to explain instances locally and SHAP to get both local and global explanations. We discuss the results in detail and present multiple comparison scenarios by using various kernels available for explaining graphs generated using SHAP values. We also discuss the practical challenges associated with the implementation of these state-of-art eXplainabale AI (XAI) methods and document them for future reference. We have made an effort to document every technical aspect of this research, while at the same time providing a general summary of the conclusions.",(LIME : METHOD; (SHAP : METHOD; LIME : METHOD; SHAP : METHOD; SHAP : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Artificial Intelligence (AI) has created the single biggest technology revolution the world has ever seen. For the finance sector, it provides great opportunities to enhance customer experience, democratize financial services, ensure consumer protection and significantly improve risk management. While it is easier than ever to run state-of-the-art machine learning models, designing and implementing systems that support real-world finance applications have been challenging. In large part because they lack transparency and explainability which are important factors in establishing reliable technology and the research on this topic with a specific focus on applications in credit risk management. In this paper, we implement two advanced post-hoc model agnostic explainability techniques called Local Interpretable Model Agnostic Explanations (LIME ) and SHapley Additive exPlanations (SHAP ) to machine learning (ML)-based credit scoring models applied to the open-access data set offered by the US-based P2P Lending Platform, Lending Club. Specifically, we use LIME to explain instances locally and SHAP to get both local and global explanations. We discuss the results in detail and present multiple comparison scenarios by using various kernels available for explaining graphs generated using SHAP values. We also discuss the practical challenges associated with the implementation of these state-of-art eXplainabale AI (XAI) methods and document them for future reference. We have made an effort to document every technical aspect of this research, while at the same time providing a general summary of the conclusions. ### Response: (LIME : METHOD; (SHAP : METHOD; LIME : METHOD; SHAP : METHOD; SHAP : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","In this work we consider the problem of learning a classifier from noisy labels when a few clean labeled examples are given. The structure of clean and noisy data is modeled by a graph per class and Graph Convolutional Networks (GCN ) are used to predict class relevance of noisy examples. For each class, the GCN is treated as a binary classifier, which learns to discriminate clean from noisy examples using a weighted binary cross-entropy loss function. The GCN -inferred ""clean"" probability is then exploited as a relevance measure. Each noisy example is weighted by its relevance when learning a classifier for the end task. We evaluate our method on an extended version of a few-shot learning problem, where the few clean examples of novel classes are supplemented with additional noisy data. Experimental results show that our GCN -based cleaning process significantly improves the classification accuracy over not cleaning the noisy data, as well as standard few-shot classification where only few clean examples are used.",Graph Convolutional Networks : METHOD; (GCN : METHOD; GCN : METHOD; GCN : METHOD; GCN : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: In this work we consider the problem of learning a classifier from noisy labels when a few clean labeled examples are given. The structure of clean and noisy data is modeled by a graph per class and Graph Convolutional Networks (GCN ) are used to predict class relevance of noisy examples. For each class, the GCN is treated as a binary classifier, which learns to discriminate clean from noisy examples using a weighted binary cross-entropy loss function. The GCN -inferred ""clean"" probability is then exploited as a relevance measure. Each noisy example is weighted by its relevance when learning a classifier for the end task. We evaluate our method on an extended version of a few-shot learning problem, where the few clean examples of novel classes are supplemented with additional noisy data. Experimental results show that our GCN -based cleaning process significantly improves the classification accuracy over not cleaning the noisy data, as well as standard few-shot classification where only few clean examples are used. ### Response: Graph Convolutional Networks : METHOD; (GCN : METHOD; GCN : METHOD; GCN : METHOD; GCN : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","We motivate and propose a suite of simple but effective improvements for concept-to-text generation called SAPPHIRE: Set Augmentation and Post-hoc PHrase Infilling and REcombination. We demonstrate their effectiveness on generative commonsense reasoning, a.k.a. the CommonGen task, through experiments using both BART and T5 models. Through extensive automatic and human evaluation, we show that SAPPHIRE noticeably improves model performance. An in-depth qualitative analysis illustrates that SAPPHIRE effectively addresses many issues of the baseline model generations, including lack of commonsense, insufficient specificity, and poor fluency.",BART : METHOD; T5 : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: We motivate and propose a suite of simple but effective improvements for concept-to-text generation called SAPPHIRE: Set Augmentation and Post-hoc PHrase Infilling and REcombination. We demonstrate their effectiveness on generative commonsense reasoning, a.k.a. the CommonGen task, through experiments using both BART and T5 models. Through extensive automatic and human evaluation, we show that SAPPHIRE noticeably improves model performance. An in-depth qualitative analysis illustrates that SAPPHIRE effectively addresses many issues of the baseline model generations, including lack of commonsense, insufficient specificity, and poor fluency. ### Response: BART : METHOD; T5 : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Natural Language inference is the task of identifying relation between two sentences as entailment, contradiction or neutrality. MedNLI is a biomedical flavour of NLI for clinical domain. This paper explores the use of Bidirectional Encoder Representation from Transformer (BERT ) for solving MedNLI. The proposed model, BERT pre-trained on PMC, PubMed and fine-tuned on MIMICIII v1.4, achieves state of the art results on MedNLI (83.45{\%}) and an accuracy of 78.5{\%} in MEDIQA challenge. The authors present an analysis of the attention patterns that emerged as a result of training BERT on MedNLI using a visualization tool, bertviz.",Transformer : METHOD; (BERT : METHOD; BERT : METHOD; BERT : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Natural Language inference is the task of identifying relation between two sentences as entailment, contradiction or neutrality. MedNLI is a biomedical flavour of NLI for clinical domain. This paper explores the use of Bidirectional Encoder Representation from Transformer (BERT ) for solving MedNLI. The proposed model, BERT pre-trained on PMC, PubMed and fine-tuned on MIMICIII v1.4, achieves state of the art results on MedNLI (83.45{\%}) and an accuracy of 78.5{\%} in MEDIQA challenge. The authors present an analysis of the attention patterns that emerged as a result of training BERT on MedNLI using a visualization tool, bertviz. ### Response: Transformer : METHOD; (BERT : METHOD; BERT : METHOD; BERT : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Although ordinary differential equations (ODEs) provide insights for designing network architectures, its relationship with the non-residual convolutional neural networks (CNNs) is still unclear. In this paper, we present a novel ODE model by adding a damping term. It can be shown that the proposed model can recover both a ResNet and a CNN by adjusting an interpolation coefficient. Therefore, the damped ODE model provides a unified framework for the interpretation of residual and non-residual networks. The Lyapunov analysis reveals better stability of the proposed model, and thus yields robustness improvement of the learned networks. Experiments on a number of image classification benchmarks show that the proposed model substantially improves the accuracy of ResNet and ResNeXt over the perturbed inputs from both stochastic noise and adversarial attack methods. Moreover, the loss landscape analysis demonstrates the improved robustness of our method along the attack direction.",ResNet : METHOD; ResNet : METHOD; ResNeXt : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Although ordinary differential equations (ODEs) provide insights for designing network architectures, its relationship with the non-residual convolutional neural networks (CNNs) is still unclear. In this paper, we present a novel ODE model by adding a damping term. It can be shown that the proposed model can recover both a ResNet and a CNN by adjusting an interpolation coefficient. Therefore, the damped ODE model provides a unified framework for the interpretation of residual and non-residual networks. The Lyapunov analysis reveals better stability of the proposed model, and thus yields robustness improvement of the learned networks. Experiments on a number of image classification benchmarks show that the proposed model substantially improves the accuracy of ResNet and ResNeXt over the perturbed inputs from both stochastic noise and adversarial attack methods. Moreover, the loss landscape analysis demonstrates the improved robustness of our method along the attack direction. ### Response: ResNet : METHOD; ResNet : METHOD; ResNeXt : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Multi-label image recognition is a task that predicts a set of object labels in an image. As the objects co-occur in the physical world, it is desirable to model label dependencies. Previous existing methods resort to either recurrent networks or pre-defined label correlation graphs for this purpose. In this paper, instead of using a pre-defined graph which is inflexible and may be sub-optimal for multi-label classification, we propose the A-GCN , which leverages the popular Graph Convolutional Networks with an Adaptive label correlation graph to model label dependencies. Specifically, we introduce a plug-and-play Label Graph (LG) module to learn label correlations with word embeddings, and then utilize traditional GCN to map this graph into label-dependent object classifiers which are further applied to image features. The basic LG module incorporates two 1x1 convolutional layers and uses the dot product to generate label graphs. In addition, we propose a sparse correlation constraint to enhance the LG module and also explore different LG architectures. We validate our method on two diverse multi-label datasets: MS-COCO and Fashion550K. Experimental results show that our A-GCN significantly improves baseline methods and achieves performance superior or comparable to the state of the art.",A-GCN : METHOD; Graph Convolutional Networks : METHOD; GCN : METHOD; A-GCN : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Multi-label image recognition is a task that predicts a set of object labels in an image. As the objects co-occur in the physical world, it is desirable to model label dependencies. Previous existing methods resort to either recurrent networks or pre-defined label correlation graphs for this purpose. In this paper, instead of using a pre-defined graph which is inflexible and may be sub-optimal for multi-label classification, we propose the A-GCN , which leverages the popular Graph Convolutional Networks with an Adaptive label correlation graph to model label dependencies. Specifically, we introduce a plug-and-play Label Graph (LG) module to learn label correlations with word embeddings, and then utilize traditional GCN to map this graph into label-dependent object classifiers which are further applied to image features. The basic LG module incorporates two 1x1 convolutional layers and uses the dot product to generate label graphs. In addition, we propose a sparse correlation constraint to enhance the LG module and also explore different LG architectures. We validate our method on two diverse multi-label datasets: MS-COCO and Fashion550K. Experimental results show that our A-GCN significantly improves baseline methods and achieves performance superior or comparable to the state of the art. ### Response: A-GCN : METHOD; Graph Convolutional Networks : METHOD; GCN : METHOD; A-GCN : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","The recently proposed Sharpness-Aware Minimization (SAM) improves generalization by minimizing a perturbed loss defined as the maximum loss within a neighborhood in the parameter space. However, we show that both sharp and flat minima can have a low perturbed loss, implying that SAM does not always prefer flat minima. Instead, we define a surrogate gap, a measure equivalent to the dominant eigenvalue of Hessian at a local minimum when the radius of neighborhood (to derive the perturbed loss) is small. The surrogate gap is easy to compute and feasible for direct minimization during training. Based on the above observations, we propose Surrogate Gap Guided Sharpness-Aware Minimization (GSAM), a novel improvement over SAM with negligible computation overhead. Conceptually, GSAM consists of two steps: 1) a gradient descent like SAM to minimize the perturbed loss, and 2) an ascent step in the orthogonal direction (after gradient decomposition) to minimize the surrogate gap and yet not affect the perturbed loss. GSAM seeks a region with both small loss (by step 1) and low sharpness (by step 2), giving rise to a model with high generalization capabilities. Theoretically, we show the convergence of GSAM and provably better generalization than SAM.Empirically, GSAM consistently improves generalization (e.g., +3.2% over SAM and +5.4% over AdamW on ImageNet top-1 accuracy for ViT-B/32).",Sharpness-Aware Minimization : METHOD; Sharpness-Aware Minimization : METHOD; AdamW : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: The recently proposed Sharpness-Aware Minimization (SAM) improves generalization by minimizing a perturbed loss defined as the maximum loss within a neighborhood in the parameter space. However, we show that both sharp and flat minima can have a low perturbed loss, implying that SAM does not always prefer flat minima. Instead, we define a surrogate gap, a measure equivalent to the dominant eigenvalue of Hessian at a local minimum when the radius of neighborhood (to derive the perturbed loss) is small. The surrogate gap is easy to compute and feasible for direct minimization during training. Based on the above observations, we propose Surrogate Gap Guided Sharpness-Aware Minimization (GSAM), a novel improvement over SAM with negligible computation overhead. Conceptually, GSAM consists of two steps: 1) a gradient descent like SAM to minimize the perturbed loss, and 2) an ascent step in the orthogonal direction (after gradient decomposition) to minimize the surrogate gap and yet not affect the perturbed loss. GSAM seeks a region with both small loss (by step 1) and low sharpness (by step 2), giving rise to a model with high generalization capabilities. Theoretically, we show the convergence of GSAM and provably better generalization than SAM.Empirically, GSAM consistently improves generalization (e.g., +3.2% over SAM and +5.4% over AdamW on ImageNet top-1 accuracy for ViT-B/32). ### Response: Sharpness-Aware Minimization : METHOD; Sharpness-Aware Minimization : METHOD; AdamW : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","We study in this paper the rate of convergence for learning densities underthe Generative Adversarial Networks (GAN ) framework, borrowing insights fromnonparametric statistics. We introduce an improved GAN estimator that achievesa faster rate, through simultaneously leveraging the level of smoothness in thetarget density and the evaluation metric, which in theory remedies the modecollapse problem reported in the literature. A minimax lower bound isconstructed to show that when the dimension is large, the exponent in the ratefor the new GAN estimator is near optimal. One can view our results asanswering in a quantitative way how well GAN learns a wide range of densitieswith different smoothness properties, under a hierarchy of evaluation metrics.As a byproduct, we also obtain improved generalization bounds for GAN withdeeper ReLU discriminator network.",(GAN : METHOD; GAN : METHOD; GAN : METHOD; GAN : METHOD; GAN : METHOD; ReLU : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: We study in this paper the rate of convergence for learning densities underthe Generative Adversarial Networks (GAN ) framework, borrowing insights fromnonparametric statistics. We introduce an improved GAN estimator that achievesa faster rate, through simultaneously leveraging the level of smoothness in thetarget density and the evaluation metric, which in theory remedies the modecollapse problem reported in the literature. A minimax lower bound isconstructed to show that when the dimension is large, the exponent in the ratefor the new GAN estimator is near optimal. One can view our results asanswering in a quantitative way how well GAN learns a wide range of densitieswith different smoothness properties, under a hierarchy of evaluation metrics.As a byproduct, we also obtain improved generalization bounds for GAN withdeeper ReLU discriminator network. ### Response: (GAN : METHOD; GAN : METHOD; GAN : METHOD; GAN : METHOD; GAN : METHOD; ReLU : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","This paper presents a memory-optimized metadata-based data structure for implementation of binary chromosome in Genetic Algorithm. In GA different types of genotypes are used depending on the problem domain. Among these, binary genotype is the most popular one for non-enumerated encoding owing to its representational and computational simplicity. This paper proposes a memory-optimized implementation approach of binary genotype. The approach improves the memory utilization as well as capacity of retaining alleles. Mathematical proof has been provided to establish the same.",GA : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: This paper presents a memory-optimized metadata-based data structure for implementation of binary chromosome in Genetic Algorithm. In GA different types of genotypes are used depending on the problem domain. Among these, binary genotype is the most popular one for non-enumerated encoding owing to its representational and computational simplicity. This paper proposes a memory-optimized implementation approach of binary genotype. The approach improves the memory utilization as well as capacity of retaining alleles. Mathematical proof has been provided to establish the same. ### Response: GA : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Point clouds acquired from range scans are often sparse, noisy, and non-uniform. This paper presents a new point cloud upsampling network called PU-GAN , which is formulated based on a generative adversarial network (GAN ), to learn a rich variety of point distributions from the latent space and upsample points over patches on object surfaces. To realize a working GAN network, we construct an up-down-up expansion unit in the generator for upsampling point features with error feedback and self-correction, and formulate a self-attention unit to enhance the feature integration. Further, we design a compound loss with adversarial, uniform and reconstruction terms, to encourage the discriminator to learn more latent patterns and enhance the output point distribution uniformity. Qualitative and quantitative evaluations demonstrate the quality of our results over the state-of-the-arts in terms of distribution uniformity, proximity-to-surface, and 3D reconstruction quality.",PU-GAN : METHOD; (GAN : METHOD; GAN : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Point clouds acquired from range scans are often sparse, noisy, and non-uniform. This paper presents a new point cloud upsampling network called PU-GAN , which is formulated based on a generative adversarial network (GAN ), to learn a rich variety of point distributions from the latent space and upsample points over patches on object surfaces. To realize a working GAN network, we construct an up-down-up expansion unit in the generator for upsampling point features with error feedback and self-correction, and formulate a self-attention unit to enhance the feature integration. Further, we design a compound loss with adversarial, uniform and reconstruction terms, to encourage the discriminator to learn more latent patterns and enhance the output point distribution uniformity. Qualitative and quantitative evaluations demonstrate the quality of our results over the state-of-the-arts in terms of distribution uniformity, proximity-to-surface, and 3D reconstruction quality. ### Response: PU-GAN : METHOD; (GAN : METHOD; GAN : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","In this paper, we present a state-of-the-art reinforcement learning method for autonomous driving. Our approach employs temporal difference learning in a Bayesian framework to learn vehicle control signals from sensor data. The agent has access to images from a forward facing camera, which are preprocessed to generate semantic segmentation maps. We trained our system using both ground truth and estimated semantic segmentation input. Based on our observations from a large set of experiments, we conclude that training the system on ground truth input data leads to better performance than training the system on estimated input even if estimated input is used for evaluation. The system is trained and evaluated in a realistic simulated urban environment using the CARLA simulator. The simulator also contains a benchmark that allows for comparing to other systems and methods. The required training time of the system is shown to be lower and the performance on the benchmark superior to competing approaches.",CARLA : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: In this paper, we present a state-of-the-art reinforcement learning method for autonomous driving. Our approach employs temporal difference learning in a Bayesian framework to learn vehicle control signals from sensor data. The agent has access to images from a forward facing camera, which are preprocessed to generate semantic segmentation maps. We trained our system using both ground truth and estimated semantic segmentation input. Based on our observations from a large set of experiments, we conclude that training the system on ground truth input data leads to better performance than training the system on estimated input even if estimated input is used for evaluation. The system is trained and evaluated in a realistic simulated urban environment using the CARLA simulator. The simulator also contains a benchmark that allows for comparing to other systems and methods. The required training time of the system is shown to be lower and the performance on the benchmark superior to competing approaches. ### Response: CARLA : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","We propose a rejection sampling scheme using the discriminator of a GAN toapproximately correct errors in the GAN generator distribution. We show thatunder quite strict assumptions, this will allow us to recover the datadistribution exactly. We then examine where those strict assumptions break downand design a practical algorithm - called Discriminator Rejection Sampling(DRS) - that can be used on real data-sets. Finally, we demonstrate theefficacy of DRS on a mixture of Gaussians and on the SAGAN model,state-of-the-art in the image generation task at the time of developing thiswork. On ImageNet, we train an improved baseline that increases the InceptionScore from 52.52 to 62.36 and reduces the Frechet Inception Distance from 18.65to 14.79. We then use DRS to further improve on this baseline, improving theInception Score to 76.08 and the FID to 13.75.",SAGAN : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: We propose a rejection sampling scheme using the discriminator of a GAN toapproximately correct errors in the GAN generator distribution. We show thatunder quite strict assumptions, this will allow us to recover the datadistribution exactly. We then examine where those strict assumptions break downand design a practical algorithm - called Discriminator Rejection Sampling(DRS) - that can be used on real data-sets. Finally, we demonstrate theefficacy of DRS on a mixture of Gaussians and on the SAGAN model,state-of-the-art in the image generation task at the time of developing thiswork. On ImageNet, we train an improved baseline that increases the InceptionScore from 52.52 to 62.36 and reduces the Frechet Inception Distance from 18.65to 14.79. We then use DRS to further improve on this baseline, improving theInception Score to 76.08 and the FID to 13.75. ### Response: SAGAN : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Given an incomplete image without additional constraint, image inpainting natively allows for multiple solutions as long as they appear plausible. Recently, multiplesolution inpainting methods have been proposed and shown the potential of generating diverse results. However, these methods have difficulty in ensuring the quality of each solution, e.g. they produce distorted structure and/or blurry texture. We propose a two-stage model for diverse inpainting, where the first stage generates multiple coarse results each of which has a different structure, and the second stage refines each coarse result separately by augmenting texture. The proposed model is inspired by the hierarchical vector quantized variational auto-encoder (VQ-VAE ), whose hierarchical architecture isentangles structural and textural information. In addition, the vector quantization in VQVAE enables autoregressive modeling of the discrete distribution over the structural information. Sampling from the distribution can easily generate diverse and high-quality structures, making up the first stage of our model. In the second stage, we propose a structural attention module inside the texture generation network, where the module utilizes the structural information to capture distant correlations. We further reuse the VQ-VAE to calculate two feature losses, which help improve structure coherence and texture realism, respectively. Experimental results on CelebA-HQ, Places2, and ImageNet datasets show that our method not only enhances the diversity of the inpainting solutions but also improves the visual quality of the generated multiple images. Code and models are available at: https://github.com/USTC-JialunPeng/Diverse-Structure-Inpainting.",(VQ-VAE : METHOD; VQ-VAE : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Given an incomplete image without additional constraint, image inpainting natively allows for multiple solutions as long as they appear plausible. Recently, multiplesolution inpainting methods have been proposed and shown the potential of generating diverse results. However, these methods have difficulty in ensuring the quality of each solution, e.g. they produce distorted structure and/or blurry texture. We propose a two-stage model for diverse inpainting, where the first stage generates multiple coarse results each of which has a different structure, and the second stage refines each coarse result separately by augmenting texture. The proposed model is inspired by the hierarchical vector quantized variational auto-encoder (VQ-VAE ), whose hierarchical architecture isentangles structural and textural information. In addition, the vector quantization in VQVAE enables autoregressive modeling of the discrete distribution over the structural information. Sampling from the distribution can easily generate diverse and high-quality structures, making up the first stage of our model. In the second stage, we propose a structural attention module inside the texture generation network, where the module utilizes the structural information to capture distant correlations. We further reuse the VQ-VAE to calculate two feature losses, which help improve structure coherence and texture realism, respectively. Experimental results on CelebA-HQ, Places2, and ImageNet datasets show that our method not only enhances the diversity of the inpainting solutions but also improves the visual quality of the generated multiple images. Code and models are available at: https://github.com/USTC-JialunPeng/Diverse-Structure-Inpainting. ### Response: (VQ-VAE : METHOD; VQ-VAE : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Depth is one of the key factors behind the success of convolutional neural networks (CNNs). Since ResNet , we are able to train very deep CNNs as the gradient vanishing issue has been largely addressed by the introduction of skip connections. However, we observe that, when the depth is very large, the intermediate layers (especially shallow layers) may fail to receive sufficient supervision from the loss due to the severe transformation through a long backpropagation path. As a result, the representation power of intermediate layers can be very weak and the model becomes very redundant with limited performance. In this paper, we first investigate the supervision vanishing issue in existing backpropagation (BP) methods. And then, we propose to address it via an effective method, called Multi-way BP (MW-BP), which relies on multiple auxiliary losses added to the intermediate layers of the network. The proposed MW-BP method can be applied to most deep architectures with slight modifications, such as ResNet and MobileNet. Our method often gives rise to much more compact models (denoted by ""Mw+Architecture"") than existing methods. For example, MwResNet -44 with 44 layers performs better than ResNet -110 with 110 layers on CIFAR-10 and CIFAR-100. More critically, the resultant models even outperform the light models obtained by state-of-the-art model compression methods. Last, our method inherently produces multiple compact models with different depths at the same time, which is helpful for model selection.",ResNet : METHOD; ResNet : METHOD; MwResNet : METHOD; ResNet : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Depth is one of the key factors behind the success of convolutional neural networks (CNNs). Since ResNet , we are able to train very deep CNNs as the gradient vanishing issue has been largely addressed by the introduction of skip connections. However, we observe that, when the depth is very large, the intermediate layers (especially shallow layers) may fail to receive sufficient supervision from the loss due to the severe transformation through a long backpropagation path. As a result, the representation power of intermediate layers can be very weak and the model becomes very redundant with limited performance. In this paper, we first investigate the supervision vanishing issue in existing backpropagation (BP) methods. And then, we propose to address it via an effective method, called Multi-way BP (MW-BP), which relies on multiple auxiliary losses added to the intermediate layers of the network. The proposed MW-BP method can be applied to most deep architectures with slight modifications, such as ResNet and MobileNet. Our method often gives rise to much more compact models (denoted by ""Mw+Architecture"") than existing methods. For example, MwResNet -44 with 44 layers performs better than ResNet -110 with 110 layers on CIFAR-10 and CIFAR-100. More critically, the resultant models even outperform the light models obtained by state-of-the-art model compression methods. Last, our method inherently produces multiple compact models with different depths at the same time, which is helpful for model selection. ### Response: ResNet : METHOD; ResNet : METHOD; MwResNet : METHOD; ResNet : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Fine-grained facial expression manipulation is a challenging problem, as fine-grained expression details are difficult to be captured. Most existing expression manipulation methods resort to discrete expression labels, which mainly edit global expressions and ignore the manipulation of fine details. To tackle this limitation, we propose an end-to-end expression-guided generative adversarial network (EGGAN ), which utilizes structured latent codes and continuous expression labels as input to generate images with expected expressions. Specifically, we adopt an adversarial autoencoder to map a source image into a structured latent space. Then, given the source latent code and the target expression label, we employ a conditional GAN to generate a new image with the target expression. Moreover, we introduce a perceptual loss and a multi-scale structural similarity loss to preserve identity and global shape during generation. Extensive experiments show that our method can manipulate fine-grained expressions, and generate continuous intermediate expressions between source and target expressions.",(EGGAN : METHOD; GAN : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Fine-grained facial expression manipulation is a challenging problem, as fine-grained expression details are difficult to be captured. Most existing expression manipulation methods resort to discrete expression labels, which mainly edit global expressions and ignore the manipulation of fine details. To tackle this limitation, we propose an end-to-end expression-guided generative adversarial network (EGGAN ), which utilizes structured latent codes and continuous expression labels as input to generate images with expected expressions. Specifically, we adopt an adversarial autoencoder to map a source image into a structured latent space. Then, given the source latent code and the target expression label, we employ a conditional GAN to generate a new image with the target expression. Moreover, we introduce a perceptual loss and a multi-scale structural similarity loss to preserve identity and global shape during generation. Extensive experiments show that our method can manipulate fine-grained expressions, and generate continuous intermediate expressions between source and target expressions. ### Response: (EGGAN : METHOD; GAN : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","In this paper, we apply Classification Restricted Boltzmann Machine(ClassRBM) to the problem of predicting breast cancer recurrence. According tothe Polish National Cancer Registry, in 2010 only, the breast cancer causedalmost 25% of all diagnosed cases of cancer in Poland. We propose how to useClassRBM for predicting breast cancer return and discovering relevant inputs(symptoms) in illness reappearance. Next, we outline a general probabilisticframework for learning Boltzmann machines with masks, which we refer to asDropping. The fashion of generating masks leads to different learning methods,i.e., DropOut, DropConnect . We propose a new method called DropPart which is ageneralization of DropConnect . In DropPart the Beta distribution instead ofBernoulli distribution in DropConnect is used. At the end, we carry out anexperiment using real-life dataset consisting of 949 cases, provided by theInstitute of Oncology Ljubljana.",DropConnect : METHOD; DropConnect : METHOD; DropConnect : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: In this paper, we apply Classification Restricted Boltzmann Machine(ClassRBM) to the problem of predicting breast cancer recurrence. According tothe Polish National Cancer Registry, in 2010 only, the breast cancer causedalmost 25% of all diagnosed cases of cancer in Poland. We propose how to useClassRBM for predicting breast cancer return and discovering relevant inputs(symptoms) in illness reappearance. Next, we outline a general probabilisticframework for learning Boltzmann machines with masks, which we refer to asDropping. The fashion of generating masks leads to different learning methods,i.e., DropOut, DropConnect . We propose a new method called DropPart which is ageneralization of DropConnect . In DropPart the Beta distribution instead ofBernoulli distribution in DropConnect is used. At the end, we carry out anexperiment using real-life dataset consisting of 949 cases, provided by theInstitute of Oncology Ljubljana. ### Response: DropConnect : METHOD; DropConnect : METHOD; DropConnect : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","There is a longstanding debate whether the Kolmogorov-Arnold representation theorem can explain the use of more than one hidden layer in neural networks. The Kolmogorov-Arnold representation decomposes a multivariate function into an interior and an outer function and therefore has indeed a similar structure as a neural network with two hidden layers. But there are distinctive differences. One of the main obstacles is that the outer function depends on the represented function and can be wildly varying even if the represented function is smooth. We derive modifications of the Kolmogorov-Arnold representation that transfer smoothness properties of the represented function to the outer function and can be well approximated by ReLU networks. It appears that instead of two hidden layers, a more natural interpretation of the Kolmogorov-Arnold representation is that of a deep neural network where most of the layers are required to approximate the interior function.",ReLU : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: There is a longstanding debate whether the Kolmogorov-Arnold representation theorem can explain the use of more than one hidden layer in neural networks. The Kolmogorov-Arnold representation decomposes a multivariate function into an interior and an outer function and therefore has indeed a similar structure as a neural network with two hidden layers. But there are distinctive differences. One of the main obstacles is that the outer function depends on the represented function and can be wildly varying even if the represented function is smooth. We derive modifications of the Kolmogorov-Arnold representation that transfer smoothness properties of the represented function to the outer function and can be well approximated by ReLU networks. It appears that instead of two hidden layers, a more natural interpretation of the Kolmogorov-Arnold representation is that of a deep neural network where most of the layers are required to approximate the interior function. ### Response: ReLU : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Convolutional Neural Network (CNN) is the state-of-the-art for image classification task. Here we have briefly discussed different components of CNN. In this paper, We have explained different CNN architectures for image classification. Through this paper, we have shown advancements in CNN from LeNet-5 to latest SENet model. We have discussed the model description and training details of each model. We have also drawn a comparison among those models.",SENet : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Convolutional Neural Network (CNN) is the state-of-the-art for image classification task. Here we have briefly discussed different components of CNN. In this paper, We have explained different CNN architectures for image classification. Through this paper, we have shown advancements in CNN from LeNet-5 to latest SENet model. We have discussed the model description and training details of each model. We have also drawn a comparison among those models. ### Response: SENet : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Machine learning plays an ever-bigger part in online recruitment, powering intelligent matchmaking and job recommendations across many of the world's largest job platforms. However, the main text is rarely enough to fully understand a job posting: more often than not, much of the required information is condensed into the job title. Several organised efforts have been made to map job titles onto a hand-made knowledge base as to provide this information, but these only cover around 60\% of online vacancies. We introduce a novel, purely data-driven approach towards the detection of new job titles. Our method is conceptually simple, extremely efficient and competitive with traditional NER-based approaches. Although the standalone application of our method does not outperform a finetuned BERT model, it can be applied as a preprocessing step as well, substantially boosting accuracy across several architectures.",BERT : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Machine learning plays an ever-bigger part in online recruitment, powering intelligent matchmaking and job recommendations across many of the world's largest job platforms. However, the main text is rarely enough to fully understand a job posting: more often than not, much of the required information is condensed into the job title. Several organised efforts have been made to map job titles onto a hand-made knowledge base as to provide this information, but these only cover around 60\% of online vacancies. We introduce a novel, purely data-driven approach towards the detection of new job titles. Our method is conceptually simple, extremely efficient and competitive with traditional NER-based approaches. Although the standalone application of our method does not outperform a finetuned BERT model, it can be applied as a preprocessing step as well, substantially boosting accuracy across several architectures. ### Response: BERT : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","We present Deep Voice, a production-quality text-to-speech system constructedentirely from deep neural networks. Deep Voice lays the groundwork for trulyend-to-end neural speech synthesis. The system comprises five major buildingblocks: a segmentation model for locating phoneme boundaries, agrapheme-to-phoneme conversion model, a phoneme duration prediction model, afundamental frequency prediction model, and an audio synthesis model. For thesegmentation model, we propose a novel way of performing phoneme boundarydetection with deep neural networks using connectionist temporal classification(CTC) loss. For the audio synthesis model, we implement a variant of WaveNet that requires fewer parameters and trains faster than the original. By using aneural network for each component, our system is simpler and more flexible thantraditional text-to-speech systems, where each component requires laboriousfeature engineering and extensive domain expertise. Finally, we show thatinference with our system can be performed faster than real time and describeoptimized WaveNet inference kernels on both CPU and GPU that achieve up to 400xspeedups over existing implementations.",WaveNet : METHOD; WaveNet : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: We present Deep Voice, a production-quality text-to-speech system constructedentirely from deep neural networks. Deep Voice lays the groundwork for trulyend-to-end neural speech synthesis. The system comprises five major buildingblocks: a segmentation model for locating phoneme boundaries, agrapheme-to-phoneme conversion model, a phoneme duration prediction model, afundamental frequency prediction model, and an audio synthesis model. For thesegmentation model, we propose a novel way of performing phoneme boundarydetection with deep neural networks using connectionist temporal classification(CTC) loss. For the audio synthesis model, we implement a variant of WaveNet that requires fewer parameters and trains faster than the original. By using aneural network for each component, our system is simpler and more flexible thantraditional text-to-speech systems, where each component requires laboriousfeature engineering and extensive domain expertise. Finally, we show thatinference with our system can be performed faster than real time and describeoptimized WaveNet inference kernels on both CPU and GPU that achieve up to 400xspeedups over existing implementations. ### Response: WaveNet : METHOD; WaveNet : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","In recent years, social media platforms have hosted an explosion of hate speech and objectionable content. The urgent need for effective automatic hate speech detection models have drawn remarkable investment from companies and researchers. Social media posts are generally short and their semantics could drastically be altered by even a single token. Thus, it is crucial for this task to learn context-aware input representations, and consider relevancy scores between input embeddings and class representations as an additional signal. To accommodate these needs, this paper introduces CRAB (Class Representation Attentive BERT ), a neural model for detecting hate speech in social media. The model benefits from two semantic representations: (i) trainable token-wise and sentence-wise class representations, and (ii) contextualized input embeddings from state-of-the-art BERT encoder. To investigate effectiveness of CRAB, we train our model on Twitter data and compare it against strong baselines. Our results show that CRAB achieves 1.89% relative improved Macro-averaged F1 over state-of-the-art baseline. The results of this research open an opportunity for the future research on automated abusive behavior detection in social media",BERT : METHOD; BERT : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: In recent years, social media platforms have hosted an explosion of hate speech and objectionable content. The urgent need for effective automatic hate speech detection models have drawn remarkable investment from companies and researchers. Social media posts are generally short and their semantics could drastically be altered by even a single token. Thus, it is crucial for this task to learn context-aware input representations, and consider relevancy scores between input embeddings and class representations as an additional signal. To accommodate these needs, this paper introduces CRAB (Class Representation Attentive BERT ), a neural model for detecting hate speech in social media. The model benefits from two semantic representations: (i) trainable token-wise and sentence-wise class representations, and (ii) contextualized input embeddings from state-of-the-art BERT encoder. To investigate effectiveness of CRAB, we train our model on Twitter data and compare it against strong baselines. Our results show that CRAB achieves 1.89% relative improved Macro-averaged F1 over state-of-the-art baseline. The results of this research open an opportunity for the future research on automated abusive behavior detection in social media ### Response: BERT : METHOD; BERT : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Understanding the shopping motivations behind market baskets has high commercial value in the grocery retail industry. Analyzing shopping transactions demands techniques that can cope with the volume and dimensionality of grocery transactional data while keeping interpretable outcomes. Latent Dirichlet Allocation (LDA ) provides a suitable framework to process grocery transactions and to discover a broad representation of customers' shopping motivations. However, summarizing the posterior distribution of an LDA model is challenging, while individual LDA draws may not be coherent and cannot capture topic uncertainty. Moreover, the evaluation of LDA models is dominated by model-fit measures which may not adequately capture the qualitative aspects such as interpretability and stability of topics. In this paper, we introduce clustering methodology that post-processes posterior LDA draws to summarise the entire posterior distribution and identify semantic modes represented as recurrent topics. Our approach is an alternative to standard label-switching techniques and provides a single posterior summary set of topics, as well as associated measures of uncertainty. Furthermore, we establish a more holistic definition for model evaluation, which assesses topic models based not only on their likelihood but also on their coherence, distinctiveness and stability. By means of a survey, we set thresholds for the interpretation of topic coherence and topic similarity in the domain of grocery retail data. We demonstrate that the selection of recurrent topics through our clustering methodology not only improves model likelihood but also outperforms the qualitative aspects of LDA such as interpretability and stability. We illustrate our methods on an example from a large UK supermarket chain.",(LDA : METHOD; LDA : METHOD; LDA : METHOD; LDA : METHOD; LDA : METHOD; LDA : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Understanding the shopping motivations behind market baskets has high commercial value in the grocery retail industry. Analyzing shopping transactions demands techniques that can cope with the volume and dimensionality of grocery transactional data while keeping interpretable outcomes. Latent Dirichlet Allocation (LDA ) provides a suitable framework to process grocery transactions and to discover a broad representation of customers' shopping motivations. However, summarizing the posterior distribution of an LDA model is challenging, while individual LDA draws may not be coherent and cannot capture topic uncertainty. Moreover, the evaluation of LDA models is dominated by model-fit measures which may not adequately capture the qualitative aspects such as interpretability and stability of topics. In this paper, we introduce clustering methodology that post-processes posterior LDA draws to summarise the entire posterior distribution and identify semantic modes represented as recurrent topics. Our approach is an alternative to standard label-switching techniques and provides a single posterior summary set of topics, as well as associated measures of uncertainty. Furthermore, we establish a more holistic definition for model evaluation, which assesses topic models based not only on their likelihood but also on their coherence, distinctiveness and stability. By means of a survey, we set thresholds for the interpretation of topic coherence and topic similarity in the domain of grocery retail data. We demonstrate that the selection of recurrent topics through our clustering methodology not only improves model likelihood but also outperforms the qualitative aspects of LDA such as interpretability and stability. We illustrate our methods on an example from a large UK supermarket chain. ### Response: (LDA : METHOD; LDA : METHOD; LDA : METHOD; LDA : METHOD; LDA : METHOD; LDA : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Neural network models for many NLP tasks have grown increasingly complex in recent years, making training and deployment more difficult. A number of recent papers have questioned the necessity of such architectures and found that well-executed, simpler models are quite effective. We show that this is also the case for document classification: in a large-scale reproducibility study of several recent neural models, we find that a simple BiLSTM architecture with appropriate regularization yields accuracy and F1 that are either competitive or exceed the state of the art on four standard benchmark datasets. Surprisingly, our simple model is able to achieve these results without attention mechanisms. While these regularization techniques, borrowed from language modeling, are not novel, to our knowledge we are the first to apply them in this context. Our work provides an open-source platform and the foundation for future work in document classification.",BiLSTM : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Neural network models for many NLP tasks have grown increasingly complex in recent years, making training and deployment more difficult. A number of recent papers have questioned the necessity of such architectures and found that well-executed, simpler models are quite effective. We show that this is also the case for document classification: in a large-scale reproducibility study of several recent neural models, we find that a simple BiLSTM architecture with appropriate regularization yields accuracy and F1 that are either competitive or exceed the state of the art on four standard benchmark datasets. Surprisingly, our simple model is able to achieve these results without attention mechanisms. While these regularization techniques, borrowed from language modeling, are not novel, to our knowledge we are the first to apply them in this context. Our work provides an open-source platform and the foundation for future work in document classification. ### Response: BiLSTM : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Microstructures of a material form the bridge linking processing conditions - which can be controlled, to the material property - which is the primary interest in engineering applications. Thus a critical task in material design is establishing the processing-structure relationship, which requires domain expertise and techniques that can model the high-dimensional material microstructure. This work proposes a deep learning based approach that models the processing-structure relationship as a conditional image synthesis problem. In particular, we develop an auxiliary classifier Wasserstein GAN with gradient penalty (ACWGAN -GP) to synthesize microstructures under a given processing condition. This approach is free of feature engineering, requires modest domain knowledge and is applicable to a wide range of material systems. We demonstrate this approach using the ultra high carbon steel (UHCS) database, where each microstructure is annotated with a label describing the cooling method it was subjected to. Our results show that ACWGAN -GP can synthesize high-quality multiphase microstructures for a given cooling method.",GAN : METHOD; (ACWGAN : METHOD; ACWGAN : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Microstructures of a material form the bridge linking processing conditions - which can be controlled, to the material property - which is the primary interest in engineering applications. Thus a critical task in material design is establishing the processing-structure relationship, which requires domain expertise and techniques that can model the high-dimensional material microstructure. This work proposes a deep learning based approach that models the processing-structure relationship as a conditional image synthesis problem. In particular, we develop an auxiliary classifier Wasserstein GAN with gradient penalty (ACWGAN -GP) to synthesize microstructures under a given processing condition. This approach is free of feature engineering, requires modest domain knowledge and is applicable to a wide range of material systems. We demonstrate this approach using the ultra high carbon steel (UHCS) database, where each microstructure is annotated with a label describing the cooling method it was subjected to. Our results show that ACWGAN -GP can synthesize high-quality multiphase microstructures for a given cooling method. ### Response: GAN : METHOD; (ACWGAN : METHOD; ACWGAN : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Deep neural networks are learning models with a very high capacity andtherefore prone to over-fitting. Many regularization techniques such asDropout , DropConnect, and weight decay all attempt to solve the problem ofover-fitting by reducing the capacity of their respective models (Srivastava etal., 2014), (Wan et al., 2013), (Krogh & Hertz, 1992). In this paper weintroduce a new form of regularization that guides the learning problem in away that reduces over-fitting without sacrificing the capacity of the model.The mistakes that models make in early stages of training carry informationabout the learning problem. By adjusting the labels of the current epoch oftraining through a weighted average of the real labels, and an exponentialaverage of the past soft-targets we achieved a regularization scheme aspowerful as Dropout without necessarily reducing the capacity of the model, andsimplified the complexity of the learning problem. SoftTarget regularizationproved to be an effective tool in various neural network architectures.",asDropout : METHOD; Dropout : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Deep neural networks are learning models with a very high capacity andtherefore prone to over-fitting. Many regularization techniques such asDropout , DropConnect, and weight decay all attempt to solve the problem ofover-fitting by reducing the capacity of their respective models (Srivastava etal., 2014), (Wan et al., 2013), (Krogh & Hertz, 1992). In this paper weintroduce a new form of regularization that guides the learning problem in away that reduces over-fitting without sacrificing the capacity of the model.The mistakes that models make in early stages of training carry informationabout the learning problem. By adjusting the labels of the current epoch oftraining through a weighted average of the real labels, and an exponentialaverage of the past soft-targets we achieved a regularization scheme aspowerful as Dropout without necessarily reducing the capacity of the model, andsimplified the complexity of the learning problem. SoftTarget regularizationproved to be an effective tool in various neural network architectures. ### Response: asDropout : METHOD; Dropout : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Structural equation models (SEMs) are widely used in sciences, ranging from economics to psychology, to uncover causal relationships underlying a complex system under consideration and estimate structural parameters of interest. We study estimation in a class of generalized SEMs where the object of interest is defined as the solution to a linear operator equation. We formulate the linear operator equation as a min-max game, where both players are parameterized by neural networks (NNs), and learn the parameters of these neural networks using the stochastic gradient descent. We consider both 2-layer and multi-layer NNs with ReLU activation functions and prove global convergence in an overparametrized regime, where the number of neurons is diverging. The results are established using techniques from online learning and local linearization of NNs, and improve in several aspects the current state-of-the-art. For the first time we provide a tractable estimation procedure for SEMs based on NNs with provable convergence and without the need for sample splitting.",ReLU : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Structural equation models (SEMs) are widely used in sciences, ranging from economics to psychology, to uncover causal relationships underlying a complex system under consideration and estimate structural parameters of interest. We study estimation in a class of generalized SEMs where the object of interest is defined as the solution to a linear operator equation. We formulate the linear operator equation as a min-max game, where both players are parameterized by neural networks (NNs), and learn the parameters of these neural networks using the stochastic gradient descent. We consider both 2-layer and multi-layer NNs with ReLU activation functions and prove global convergence in an overparametrized regime, where the number of neurons is diverging. The results are established using techniques from online learning and local linearization of NNs, and improve in several aspects the current state-of-the-art. For the first time we provide a tractable estimation procedure for SEMs based on NNs with provable convergence and without the need for sample splitting. ### Response: ReLU : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","In this paper we are concerned with the approximation of functions by single hidden layer neural networks with ReLU activation functions on the unit circle. In particular, we are interested in the case when the number of data-points exceeds the number of nodes. We first study the convergence to equilibrium of the stochastic gradient flow associated with the cost function with a quadratic penalization. Specifically, we prove a Poincar\'e inequality for a penalized version of the cost function with explicit constants that are independent of the data and of the number of nodes. As our penalization biases the weights to be bounded, this leads us to study how well a network with bounded weights can approximate a given function of bounded variation (BV). Our main contribution concerning approximation of BV functions, is a result which we call the localization theorem. Specifically, it states that the expected error of the constrained problem, where the length of the weights are less than $R$, is of order $R^{-1/9}$ with respect to the unconstrained problem (the global optimum). The proof is novel in this topic and is inspired by techniques from regularity theory of elliptic partial differential equations. Finally we quantify the expected value of the global optimum by proving a quantitative version of the universal approximation theorem.",ReLU : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: In this paper we are concerned with the approximation of functions by single hidden layer neural networks with ReLU activation functions on the unit circle. In particular, we are interested in the case when the number of data-points exceeds the number of nodes. We first study the convergence to equilibrium of the stochastic gradient flow associated with the cost function with a quadratic penalization. Specifically, we prove a Poincar\'e inequality for a penalized version of the cost function with explicit constants that are independent of the data and of the number of nodes. As our penalization biases the weights to be bounded, this leads us to study how well a network with bounded weights can approximate a given function of bounded variation (BV). Our main contribution concerning approximation of BV functions, is a result which we call the localization theorem. Specifically, it states that the expected error of the constrained problem, where the length of the weights are less than $R$, is of order $R^{-1/9}$ with respect to the unconstrained problem (the global optimum). The proof is novel in this topic and is inspired by techniques from regularity theory of elliptic partial differential equations. Finally we quantify the expected value of the global optimum by proving a quantitative version of the universal approximation theorem. ### Response: ReLU : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Image captioning is an important but challenging task, applicable to virtualassistants, editing tools, image indexing, and support of the disabled. Itschallenges are due to the variability and ambiguity of possible imagedescriptions. In recent years significant progress has been made in imagecaptioning, using Recurrent Neural Networks powered by long-short-term-memory(LSTM ) units. Despite mitigating the vanishing gradient problem, and despitetheir compelling ability to memorize dependencies, LSTM units are complex andinherently sequential across time. To address this issue, recent work has shownbenefits of convolutional networks for machine translation and conditionalimage generation. Inspired by their success, in this paper, we develop aconvolutional image captioning technique. We demonstrate its efficacy on thechallenging MSCOCO dataset and demonstrate performance on par with thebaseline, while having a faster training time per number of parameters. We alsoperform a detailed analysis, providing compelling reasons in favor ofconvolutional language generation approaches.",long-short-term-memory(LSTM : METHOD; LSTM : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Image captioning is an important but challenging task, applicable to virtualassistants, editing tools, image indexing, and support of the disabled. Itschallenges are due to the variability and ambiguity of possible imagedescriptions. In recent years significant progress has been made in imagecaptioning, using Recurrent Neural Networks powered by long-short-term-memory(LSTM ) units. Despite mitigating the vanishing gradient problem, and despitetheir compelling ability to memorize dependencies, LSTM units are complex andinherently sequential across time. To address this issue, recent work has shownbenefits of convolutional networks for machine translation and conditionalimage generation. Inspired by their success, in this paper, we develop aconvolutional image captioning technique. We demonstrate its efficacy on thechallenging MSCOCO dataset and demonstrate performance on par with thebaseline, while having a faster training time per number of parameters. We alsoperform a detailed analysis, providing compelling reasons in favor ofconvolutional language generation approaches. ### Response: long-short-term-memory(LSTM : METHOD; LSTM : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","In this paper, we propose a novel learning-based polygonal point set tracking method. Compared to existing video object segmentation~(VOS ) methods that propagate pixel-wise object mask information, we propagate a polygonal point set over frames. Specifically, the set is defined as a subset of points in the target contour, and our goal is to track corresponding points on the target contour. Those outputs enable us to apply various visual effects such as motion tracking, part deformation, and texture mapping. To this end, we propose a new method to track the corresponding points between frames by the global-local alignment with delicately designed losses and regularization terms. We also introduce a novel learning strategy using synthetic and VOS datasets that makes it possible to tackle the problem without developing the point correspondence dataset. Since the existing datasets are not suitable to validate our method, we build a new polygonal point set tracking dataset and demonstrate the superior performance of our method over the baselines and existing contour-based VOS methods. In addition, we present visual-effects applications of our method on part distortion and text mapping.",segmentation~(VOS : METHOD; VOS : METHOD; VOS : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: In this paper, we propose a novel learning-based polygonal point set tracking method. Compared to existing video object segmentation~(VOS ) methods that propagate pixel-wise object mask information, we propagate a polygonal point set over frames. Specifically, the set is defined as a subset of points in the target contour, and our goal is to track corresponding points on the target contour. Those outputs enable us to apply various visual effects such as motion tracking, part deformation, and texture mapping. To this end, we propose a new method to track the corresponding points between frames by the global-local alignment with delicately designed losses and regularization terms. We also introduce a novel learning strategy using synthetic and VOS datasets that makes it possible to tackle the problem without developing the point correspondence dataset. Since the existing datasets are not suitable to validate our method, we build a new polygonal point set tracking dataset and demonstrate the superior performance of our method over the baselines and existing contour-based VOS methods. In addition, we present visual-effects applications of our method on part distortion and text mapping. ### Response: segmentation~(VOS : METHOD; VOS : METHOD; VOS : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","This paper analyzes some speed and performance improvement methods of Transformer architecture in recent years, mainly its application in dedicated model training. The dedicated model studied here refers to the open domain persona-aware dialogue generation model, and the dataset is multi turn short dialogue, The total length of a single input sequence is no more than 105 tokens. Therefore, many improvements in the architecture and attention mechanism of transformer architecture for long sequence processing are not discussed in this paper. The source code of the experiments has been open sourced: https://github.com/ghosthamlet/persona",Transformer : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: This paper analyzes some speed and performance improvement methods of Transformer architecture in recent years, mainly its application in dedicated model training. The dedicated model studied here refers to the open domain persona-aware dialogue generation model, and the dataset is multi turn short dialogue, The total length of a single input sequence is no more than 105 tokens. Therefore, many improvements in the architecture and attention mechanism of transformer architecture for long sequence processing are not discussed in this paper. The source code of the experiments has been open sourced: https://github.com/ghosthamlet/persona ### Response: Transformer : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","In this paper we describe the submission of the UniBuc-NLP team for the Discriminating between Similar Languages Shared Task, DSL 2016. We present and analyze the results we obtained in the closed track of sub-task 1 (Similar languages and language varieties) and sub-task 2 (Arabic dialects). For sub-task 1 we used a logistic regression classifier with tf-idf feature weighting and for sub-task 2 a character-based string kernel with an SVM classifier. Our results show that good accuracy scores can be obtained with limited feature and model engineering. While certain limitations are to be acknowledged, our approach worked surprisingly well for out-of-domain, social media data, with 0.898 accuracy (3rd place) for dataset B1 and 0.838 accuracy (4th place) for dataset B2.",SVM : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: In this paper we describe the submission of the UniBuc-NLP team for the Discriminating between Similar Languages Shared Task, DSL 2016. We present and analyze the results we obtained in the closed track of sub-task 1 (Similar languages and language varieties) and sub-task 2 (Arabic dialects). For sub-task 1 we used a logistic regression classifier with tf-idf feature weighting and for sub-task 2 a character-based string kernel with an SVM classifier. Our results show that good accuracy scores can be obtained with limited feature and model engineering. While certain limitations are to be acknowledged, our approach worked surprisingly well for out-of-domain, social media data, with 0.898 accuracy (3rd place) for dataset B1 and 0.838 accuracy (4th place) for dataset B2. ### Response: SVM : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","The mini-batch stochastic gradient descent (SGD ) algorithm is widely used in training machine learning models, in particular deep learning models. We study SGD dynamics under linear regression and two-layer linear networks, with an easy extension to deeper linear networks, by focusing on the variance of the gradients, which is the first study of this nature. In the linear regression case, we show that in each iteration the norm of the gradient is a decreasing function of the mini-batch size $b$ and thus the variance of the stochastic gradient estimator is a decreasing function of $b$. For deep neural networks with $L_2$ loss we show that the variance of the gradient is a polynomial in $1/b$. The results back the important intuition that smaller batch sizes yield lower loss function values which is a common believe among the researchers. The proof techniques exhibit a relationship between stochastic gradient estimators and initial weights, which is useful for further research on the dynamics of SGD . We empirically provide further insights to our results on various datasets and commonly used deep network structures.",(SGD : METHOD; SGD : METHOD; SGD : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: The mini-batch stochastic gradient descent (SGD ) algorithm is widely used in training machine learning models, in particular deep learning models. We study SGD dynamics under linear regression and two-layer linear networks, with an easy extension to deeper linear networks, by focusing on the variance of the gradients, which is the first study of this nature. In the linear regression case, we show that in each iteration the norm of the gradient is a decreasing function of the mini-batch size $b$ and thus the variance of the stochastic gradient estimator is a decreasing function of $b$. For deep neural networks with $L_2$ loss we show that the variance of the gradient is a polynomial in $1/b$. The results back the important intuition that smaller batch sizes yield lower loss function values which is a common believe among the researchers. The proof techniques exhibit a relationship between stochastic gradient estimators and initial weights, which is useful for further research on the dynamics of SGD . We empirically provide further insights to our results on various datasets and commonly used deep network structures. ### Response: (SGD : METHOD; SGD : METHOD; SGD : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Data augmentation is a widely used technique in many machine learning tasks,such as image classification, to virtually enlarge the training dataset sizeand avoid overfitting. Traditional data augmentation techniques for imageclassification tasks create new samples from the original training data by, forexample, flipping, distorting, adding a small amount of noise to, or cropping apatch from an original image. In this paper, we introduce a simple butsurprisingly effective data augmentation technique for image classificationtasks. With our technique, named SamplePairing, we synthesize a new sample fromone image by overlaying another image randomly chosen from the training data(i.e., taking an average of two images for each pixel). By using two imagesrandomly selected from the training set, we can generate $N^2$ new samples from$N$ training samples. This simple data augmentation technique significantlyimproved classification accuracy for all the tested datasets; for example, thetop-1 error rate was reduced from 33.5% to 29.0% for the ILSVRC 2012 datasetwith GoogLeNet and from 8.22% to 6.93% in the CIFAR-10 dataset. We also showthat our SamplePairing technique largely improved accuracy when the number ofsamples in the training set was very small. Therefore, our technique is morevaluable for tasks with a limited amount of training data, such as medicalimaging tasks.",GoogLeNet : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Data augmentation is a widely used technique in many machine learning tasks,such as image classification, to virtually enlarge the training dataset sizeand avoid overfitting. Traditional data augmentation techniques for imageclassification tasks create new samples from the original training data by, forexample, flipping, distorting, adding a small amount of noise to, or cropping apatch from an original image. In this paper, we introduce a simple butsurprisingly effective data augmentation technique for image classificationtasks. With our technique, named SamplePairing, we synthesize a new sample fromone image by overlaying another image randomly chosen from the training data(i.e., taking an average of two images for each pixel). By using two imagesrandomly selected from the training set, we can generate $N^2$ new samples from$N$ training samples. This simple data augmentation technique significantlyimproved classification accuracy for all the tested datasets; for example, thetop-1 error rate was reduced from 33.5% to 29.0% for the ILSVRC 2012 datasetwith GoogLeNet and from 8.22% to 6.93% in the CIFAR-10 dataset. We also showthat our SamplePairing technique largely improved accuracy when the number ofsamples in the training set was very small. Therefore, our technique is morevaluable for tasks with a limited amount of training data, such as medicalimaging tasks. ### Response: GoogLeNet : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Pre-trained Transformers are now ubiquitous in natural language processing, but despite their high end-task performance, little is known empirically about whether they are calibrated. Specifically, do these models' posterior probabilities provide an accurate empirical measure of how likely the model is to be correct on a given example? We focus on BERT and RoBERTa in this work, and analyze their calibration across three tasks: natural language inference, paraphrase detection, and commonsense reasoning. For each task, we consider in-domain as well as challenging out-of-domain settings, where models face more examples they should be uncertain about. We show that: (1) when used out-of-the-box, pre-trained models are calibrated in-domain, and compared to baselines, their calibration error out-of-domain can be as much as 3.5x lower; (2) temperature scaling is effective at further reducing calibration error in-domain, and using label smoothing to deliberately increase empirical uncertainty helps calibrate posteriors out-of-domain.",RoBERTa : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Pre-trained Transformers are now ubiquitous in natural language processing, but despite their high end-task performance, little is known empirically about whether they are calibrated. Specifically, do these models' posterior probabilities provide an accurate empirical measure of how likely the model is to be correct on a given example? We focus on BERT and RoBERTa in this work, and analyze their calibration across three tasks: natural language inference, paraphrase detection, and commonsense reasoning. For each task, we consider in-domain as well as challenging out-of-domain settings, where models face more examples they should be uncertain about. We show that: (1) when used out-of-the-box, pre-trained models are calibrated in-domain, and compared to baselines, their calibration error out-of-domain can be as much as 3.5x lower; (2) temperature scaling is effective at further reducing calibration error in-domain, and using label smoothing to deliberately increase empirical uncertainty helps calibrate posteriors out-of-domain. ### Response: RoBERTa : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Spatio-temporal prediction plays an important role in many application areasespecially in traffic domain. However, due to complicated spatio-temporaldependency and high non-linear dynamics in road networks, traffic predictiontask is still challenging. Existing works either exhibit heavy training cost orfail to accurately capture the spatio-temporal patterns, also ignore thecorrelation between distant roads that share the similar patterns. In thispaper, we propose a novel deep learning framework to overcome these issues: 3DTemporal Graph Convolutional Networks (3D-TGCN). Two novel components of ourmodel are introduced. (1) Instead of constructing the road graph based onspatial information, we learn it by comparing the similarity between timeseries for each road, thus providing a spatial information free framework. (2)We propose an original 3D graph convolution model to model the spatio-temporaldata more accurately. Empirical results show that 3D-TGCN could outperformstate-of-the-art baselines.",Graph Convolutional Networks : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Spatio-temporal prediction plays an important role in many application areasespecially in traffic domain. However, due to complicated spatio-temporaldependency and high non-linear dynamics in road networks, traffic predictiontask is still challenging. Existing works either exhibit heavy training cost orfail to accurately capture the spatio-temporal patterns, also ignore thecorrelation between distant roads that share the similar patterns. In thispaper, we propose a novel deep learning framework to overcome these issues: 3DTemporal Graph Convolutional Networks (3D-TGCN). Two novel components of ourmodel are introduced. (1) Instead of constructing the road graph based onspatial information, we learn it by comparing the similarity between timeseries for each road, thus providing a spatial information free framework. (2)We propose an original 3D graph convolution model to model the spatio-temporaldata more accurately. Empirical results show that 3D-TGCN could outperformstate-of-the-art baselines. ### Response: Graph Convolutional Networks : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Cell event detection in cell videos is essential for monitoring of cellular behavior over extended time periods. Deep learning methods have shown great success in the detection of cell events for their ability to capture more discriminative features of cellular processes compared to traditional methods. In particular, convolutional long short-term memory (LSTM ) models, which exploits the changes in cell events observable in video sequences, is the state-of-the-art for mitosis detection in cell videos. However, their limitations are the determination of the input sequence length, which is often performed empirically, and the need for a large annotated training dataset which is expensive to prepare. We propose a novel semi-supervised method of optimal length detection for mitosis detection with two key contributions: (i) an unsupervised step for learning the spatial and temporal locations of cells in their normal stage and approximating the distribution of temporal lengths of cell events and, (ii) a step of inferring, from that distribution, an optimal input sequence length and a minimal number of annotated frames for training a LSTM model for each particular video. We evaluated our method in detecting mitosis in densely packed stem cells in a phase-contrast microscopy videos. Our experimental data prove that increasing the input sequence length of LSTM can lead to a decrease in performance. Our results also show that by approximating the optimal input sequence length of the tested video, a model trained with only 18 annotated frames achieved F1-scores of 0.880-0.907, which are 10% higher than those of other published methods with a full set of 110 training annotated frames.",(LSTM : METHOD; LSTM : METHOD; LSTM : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Cell event detection in cell videos is essential for monitoring of cellular behavior over extended time periods. Deep learning methods have shown great success in the detection of cell events for their ability to capture more discriminative features of cellular processes compared to traditional methods. In particular, convolutional long short-term memory (LSTM ) models, which exploits the changes in cell events observable in video sequences, is the state-of-the-art for mitosis detection in cell videos. However, their limitations are the determination of the input sequence length, which is often performed empirically, and the need for a large annotated training dataset which is expensive to prepare. We propose a novel semi-supervised method of optimal length detection for mitosis detection with two key contributions: (i) an unsupervised step for learning the spatial and temporal locations of cells in their normal stage and approximating the distribution of temporal lengths of cell events and, (ii) a step of inferring, from that distribution, an optimal input sequence length and a minimal number of annotated frames for training a LSTM model for each particular video. We evaluated our method in detecting mitosis in densely packed stem cells in a phase-contrast microscopy videos. Our experimental data prove that increasing the input sequence length of LSTM can lead to a decrease in performance. Our results also show that by approximating the optimal input sequence length of the tested video, a model trained with only 18 annotated frames achieved F1-scores of 0.880-0.907, which are 10% higher than those of other published methods with a full set of 110 training annotated frames. ### Response: (LSTM : METHOD; LSTM : METHOD; LSTM : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Textual representation learners trained on large amounts of data have achieved notable success on downstream tasks; intriguingly, they have also performed well on challenging tests of syntactic competence. Given this success, it remains an open question whether scalable learners like BERT can become fully proficient in the syntax of natural language by virtue of data scale alone, or whether they still benefit from more explicit syntactic biases. To answer this question, we introduce a knowledge distillation strategy for injecting syntactic biases into BERT pretraining, by distilling the syntactically informative predictions of a hierarchical---albeit harder to scale---syntactic language model. Since BERT models masked words in bidirectional context, we propose to distill the approximate marginal distribution over words in context from the syntactic LM. Our approach reduces relative error by 2-21% on a diverse set of structured prediction tasks, although we obtain mixed results on the GLUE benchmark. Our findings demonstrate the benefits of syntactic biases, even in representation learners that exploit large amounts of data, and contribute to a better understanding of where syntactic biases are most helpful in benchmarks of natural language understanding.",BERT : METHOD; BERT : METHOD; BERT : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Textual representation learners trained on large amounts of data have achieved notable success on downstream tasks; intriguingly, they have also performed well on challenging tests of syntactic competence. Given this success, it remains an open question whether scalable learners like BERT can become fully proficient in the syntax of natural language by virtue of data scale alone, or whether they still benefit from more explicit syntactic biases. To answer this question, we introduce a knowledge distillation strategy for injecting syntactic biases into BERT pretraining, by distilling the syntactically informative predictions of a hierarchical---albeit harder to scale---syntactic language model. Since BERT models masked words in bidirectional context, we propose to distill the approximate marginal distribution over words in context from the syntactic LM. Our approach reduces relative error by 2-21% on a diverse set of structured prediction tasks, although we obtain mixed results on the GLUE benchmark. Our findings demonstrate the benefits of syntactic biases, even in representation learners that exploit large amounts of data, and contribute to a better understanding of where syntactic biases are most helpful in benchmarks of natural language understanding. ### Response: BERT : METHOD; BERT : METHOD; BERT : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Improving the aesthetic quality of images is challenging and eager for the public. To address this problem, most existing algorithms are based on supervised learning methods to learn an automatic photo enhancer for paired data, which consists of low-quality photos and corresponding expert-retouched versions. However, the style and characteristics of photos retouched by experts may not meet the needs or preferences of general users. In this paper, we present an unsupervised image enhancement generative adversarial network (UEGAN), which learns the corresponding image-to-image mapping from a set of images with desired characteristics in an unsupervised manner, rather than learning on a large number of paired images. The proposed model is based on single deep GAN which embeds the modulation and attention mechanisms to capture richer global and local features. Based on the proposed model, we introduce two losses to deal with the unsupervised image enhancement: (1) fidelity loss, which is defined as a L2 regularization in the feature domain of a pre-trained VGG network to ensure the content between the enhanced image and the input image is the same, and (2) quality loss that is formulated as a relativistic hinge adversarial loss to endow the input image the desired characteristics. Both quantitative and qualitative results show that the proposed model effectively improves the aesthetic quality of images. Our code is available at: https://github.com/eezkni/UEGAN.",VGG : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Improving the aesthetic quality of images is challenging and eager for the public. To address this problem, most existing algorithms are based on supervised learning methods to learn an automatic photo enhancer for paired data, which consists of low-quality photos and corresponding expert-retouched versions. However, the style and characteristics of photos retouched by experts may not meet the needs or preferences of general users. In this paper, we present an unsupervised image enhancement generative adversarial network (UEGAN), which learns the corresponding image-to-image mapping from a set of images with desired characteristics in an unsupervised manner, rather than learning on a large number of paired images. The proposed model is based on single deep GAN which embeds the modulation and attention mechanisms to capture richer global and local features. Based on the proposed model, we introduce two losses to deal with the unsupervised image enhancement: (1) fidelity loss, which is defined as a L2 regularization in the feature domain of a pre-trained VGG network to ensure the content between the enhanced image and the input image is the same, and (2) quality loss that is formulated as a relativistic hinge adversarial loss to endow the input image the desired characteristics. Both quantitative and qualitative results show that the proposed model effectively improves the aesthetic quality of images. Our code is available at: https://github.com/eezkni/UEGAN. ### Response: VGG : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Graph Neural Networks (GNNs) have emerged as a powerful and flexible framework for representation learning on irregular data. As they generalize the operations of classical CNNs on grids to arbitrary topologies, GNNs also bring much of the implementation challenges of their Euclidean counterparts. Model size, memory footprint, and energy consumption are common concerns for many real-world applications. Network binarization allocates a single bit to parameters and activations, thus dramatically reducing the memory requirements (up to 32x compared to single-precision floating-point numbers) and maximizing the benefits of fast SIMD instructions on modern hardware for measurable speedups. However, in spite of the large body of work on binarization for classical CNNs, this area remains largely unexplored in geometric deep learning. In this paper, we present and evaluate different strategies for the binarization of graph neural networks. We show that through careful design of the models, and control of the training process, binary graph neural networks can be trained at only a moderate cost in accuracy on challenging benchmarks. In particular, we present the first dynamic graph neural network in Hamming space, able to leverage efficient k-NN search on binary vectors to speed-up the construction of the dynamic graph. We further verify that the binary models offer significant savings on embedded devices. Our code is publicly available on Github.",k-NN : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Graph Neural Networks (GNNs) have emerged as a powerful and flexible framework for representation learning on irregular data. As they generalize the operations of classical CNNs on grids to arbitrary topologies, GNNs also bring much of the implementation challenges of their Euclidean counterparts. Model size, memory footprint, and energy consumption are common concerns for many real-world applications. Network binarization allocates a single bit to parameters and activations, thus dramatically reducing the memory requirements (up to 32x compared to single-precision floating-point numbers) and maximizing the benefits of fast SIMD instructions on modern hardware for measurable speedups. However, in spite of the large body of work on binarization for classical CNNs, this area remains largely unexplored in geometric deep learning. In this paper, we present and evaluate different strategies for the binarization of graph neural networks. We show that through careful design of the models, and control of the training process, binary graph neural networks can be trained at only a moderate cost in accuracy on challenging benchmarks. In particular, we present the first dynamic graph neural network in Hamming space, able to leverage efficient k-NN search on binary vectors to speed-up the construction of the dynamic graph. We further verify that the binary models offer significant savings on embedded devices. Our code is publicly available on Github. ### Response: k-NN : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Deep model-based Reinforcement Learning (RL) has the potential to substantially improve the sample-efficiency of deep RL. While various challenges have long held it back, a number of papers have recently come out reporting success with deep model-based methods. This is a great development, but the lack of a consistent metric to evaluate such methods makes it difficult to compare various approaches. For example, the common single-task sample-efficiency metric conflates improvements due to model-based learning with various other aspects, such as representation learning, making it difficult to assess true progress on model-based RL. To address this, we introduce an experimental setup to evaluate model-based behavior of RL methods, inspired by work from neuroscience on detecting model-based behavior in humans and animals. Our metric based on this setup, the Local Change Adaptation (LoCA) regret, measures how quickly an RL method adapts to a local change in the environment. Our metric can identify model-based behavior, even if the method uses a poor representation and provides insight in how close a method's behavior is from optimal model-based behavior. We use our setup to evaluate the model-based behavior of MuZero on a variation of the classic Mountain Car task.",MuZero : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Deep model-based Reinforcement Learning (RL) has the potential to substantially improve the sample-efficiency of deep RL. While various challenges have long held it back, a number of papers have recently come out reporting success with deep model-based methods. This is a great development, but the lack of a consistent metric to evaluate such methods makes it difficult to compare various approaches. For example, the common single-task sample-efficiency metric conflates improvements due to model-based learning with various other aspects, such as representation learning, making it difficult to assess true progress on model-based RL. To address this, we introduce an experimental setup to evaluate model-based behavior of RL methods, inspired by work from neuroscience on detecting model-based behavior in humans and animals. Our metric based on this setup, the Local Change Adaptation (LoCA) regret, measures how quickly an RL method adapts to a local change in the environment. Our metric can identify model-based behavior, even if the method uses a poor representation and provides insight in how close a method's behavior is from optimal model-based behavior. We use our setup to evaluate the model-based behavior of MuZero on a variation of the classic Mountain Car task. ### Response: MuZero : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","With ever increasing number of vehicles, vehicular tracking is one of the major challenges faced by urban areas. In this paper we try to develop a model that can locate a particular vehicle that the user is looking for depending on two factors 1. the Type of vehicle and the 2. License plate number of the car. The proposed system uses a unique mixture consisting of Mask R-CNN model for vehicle type detection, WpodNet and pytesseract for License Plate detection and Prediction of letters in it.",Mask R-CNN : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: With ever increasing number of vehicles, vehicular tracking is one of the major challenges faced by urban areas. In this paper we try to develop a model that can locate a particular vehicle that the user is looking for depending on two factors 1. the Type of vehicle and the 2. License plate number of the car. The proposed system uses a unique mixture consisting of Mask R-CNN model for vehicle type detection, WpodNet and pytesseract for License Plate detection and Prediction of letters in it. ### Response: Mask R-CNN : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Thanks to their improved data efficiency, equivariant neural networks have gained increased interest in the deep learning community. They have been successfully applied in the medical domain where symmetries in the data can be effectively exploited to build more accurate and robust models. To be able to reach a much larger body of patients, mobile, on-device implementations of deep learning solutions have been developed for medical applications. However, equivariant models are commonly implemented using large and computationally expensive architectures, not suitable to run on mobile devices. In this work, we design and test an equivariant version of MobileNetV2 and further optimize it with model quantization to enable more efficient inference. We achieve close-to state of the art performance on the Patch Camelyon (PCam) medical dataset while being more computationally efficient.",MobileNetV2 : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Thanks to their improved data efficiency, equivariant neural networks have gained increased interest in the deep learning community. They have been successfully applied in the medical domain where symmetries in the data can be effectively exploited to build more accurate and robust models. To be able to reach a much larger body of patients, mobile, on-device implementations of deep learning solutions have been developed for medical applications. However, equivariant models are commonly implemented using large and computationally expensive architectures, not suitable to run on mobile devices. In this work, we design and test an equivariant version of MobileNetV2 and further optimize it with model quantization to enable more efficient inference. We achieve close-to state of the art performance on the Patch Camelyon (PCam) medical dataset while being more computationally efficient. ### Response: MobileNetV2 : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","In spite of the many advantages of aerial imagery for crowd monitoring and management at mass events, datasets of aerial images of crowds are still lacking in the field. As a remedy, in this work we introduce a novel crowd dataset, the DLR Aerial Crowd Dataset (DLR-ACD), which is composed of 33 large aerial images acquired from 16 flight campaigns over mass events with 226,291 persons annotated. To the best of our knowledge, DLR-ACD is the first aerial crowd dataset and will be released publicly. To tackle the problem of accurate crowd counting and density map estimation in aerial images of crowds, this work also proposes a new encoder-decoder convolutional neural network, the so-called Multi-Resolution Crowd Network MRCNet. The encoder is based on the VGG-16 network and the decoder is composed of a set of bilinear upsampling and convolutional layers. Using two losses, one at an earlier level and another at the last level of the decoder, MRCNet estimates crowd counts and high-resolution crowd density maps as two different but interrelated tasks. In addition, MRCNet utilizes contextual and detailed local information by combining high- and low-level features through a number of lateral connections inspired by the Feature Pyramid Network (FPN) technique. We evaluated MRCNet on the proposed DLR-ACD dataset as well as on the ShanghaiTech dataset, a CCTV-based crowd counting benchmark. The results demonstrate that MRCNet outperforms the state-of-the-art crowd counting methods in estimating the crowd counts and density maps for both aerial and CCTV-based images.",VGG-16 : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: In spite of the many advantages of aerial imagery for crowd monitoring and management at mass events, datasets of aerial images of crowds are still lacking in the field. As a remedy, in this work we introduce a novel crowd dataset, the DLR Aerial Crowd Dataset (DLR-ACD), which is composed of 33 large aerial images acquired from 16 flight campaigns over mass events with 226,291 persons annotated. To the best of our knowledge, DLR-ACD is the first aerial crowd dataset and will be released publicly. To tackle the problem of accurate crowd counting and density map estimation in aerial images of crowds, this work also proposes a new encoder-decoder convolutional neural network, the so-called Multi-Resolution Crowd Network MRCNet. The encoder is based on the VGG-16 network and the decoder is composed of a set of bilinear upsampling and convolutional layers. Using two losses, one at an earlier level and another at the last level of the decoder, MRCNet estimates crowd counts and high-resolution crowd density maps as two different but interrelated tasks. In addition, MRCNet utilizes contextual and detailed local information by combining high- and low-level features through a number of lateral connections inspired by the Feature Pyramid Network (FPN) technique. We evaluated MRCNet on the proposed DLR-ACD dataset as well as on the ShanghaiTech dataset, a CCTV-based crowd counting benchmark. The results demonstrate that MRCNet outperforms the state-of-the-art crowd counting methods in estimating the crowd counts and density maps for both aerial and CCTV-based images. ### Response: VGG-16 : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Recent work has found evidence that Multilingual BERT (mBERT ), a transformer-based multilingual masked language model, is capable of zero-shot cross-lingual transfer, suggesting that some aspects of its representations are shared cross-lingually. To better understand this overlap, we extend recent work on finding syntactic trees in neural networks' internal representations to the multilingual setting. We show that subspaces of mBERT representations recover syntactic tree distances in languages other than English, and that these subspaces are approximately shared across languages. Motivated by these results, we present an unsupervised analysis method that provides evidence mBERT learns representations of syntactic dependency labels, in the form of clusters which largely agree with the Universal Dependencies taxonomy. This evidence suggests that even without explicit supervision, multilingual masked language models learn certain linguistic universals.",BERT : METHOD; (mBERT : METHOD; mBERT : METHOD; mBERT : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Recent work has found evidence that Multilingual BERT (mBERT ), a transformer-based multilingual masked language model, is capable of zero-shot cross-lingual transfer, suggesting that some aspects of its representations are shared cross-lingually. To better understand this overlap, we extend recent work on finding syntactic trees in neural networks' internal representations to the multilingual setting. We show that subspaces of mBERT representations recover syntactic tree distances in languages other than English, and that these subspaces are approximately shared across languages. Motivated by these results, we present an unsupervised analysis method that provides evidence mBERT learns representations of syntactic dependency labels, in the form of clusters which largely agree with the Universal Dependencies taxonomy. This evidence suggests that even without explicit supervision, multilingual masked language models learn certain linguistic universals. ### Response: BERT : METHOD; (mBERT : METHOD; mBERT : METHOD; mBERT : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Principal component analysis (PCA ) has well-documented merits for dataextraction and dimensionality reduction. PCA deals with a single dataset at atime, and it is challenged when it comes to analyzing multiple datasets. Yet incertain setups, one wishes to extract the most significant information of onedataset relative to other datasets. Specifically, the interest may be onidentifying, namely extracting features that are specific to a single targetdataset but not the others. This paper develops a novel approach for suchso-termed discriminative data analysis, and establishes its optimality in theleast-squares (LS) sense under suitable data modeling assumptions. Thecriterion reveals linear combinations of variables by maximizing the ratio ofthe variance of the target data to that of the remainders. The novel approachsolves a generalized eigenvalue problem by performing SVD just once. Numericaltests using synthetic and real datasets showcase the merits of the proposedapproach relative to its competing alternatives.",(PCA : METHOD; PCA : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Principal component analysis (PCA ) has well-documented merits for dataextraction and dimensionality reduction. PCA deals with a single dataset at atime, and it is challenged when it comes to analyzing multiple datasets. Yet incertain setups, one wishes to extract the most significant information of onedataset relative to other datasets. Specifically, the interest may be onidentifying, namely extracting features that are specific to a single targetdataset but not the others. This paper develops a novel approach for suchso-termed discriminative data analysis, and establishes its optimality in theleast-squares (LS) sense under suitable data modeling assumptions. Thecriterion reveals linear combinations of variables by maximizing the ratio ofthe variance of the target data to that of the remainders. The novel approachsolves a generalized eigenvalue problem by performing SVD just once. Numericaltests using synthetic and real datasets showcase the merits of the proposedapproach relative to its competing alternatives. ### Response: (PCA : METHOD; PCA : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Geo-localizing static objects from street images is challenging but also very important for road asset mapping and autonomous driving. In this paper we present a two-stage framework that detects and geolocalizes traffic signs from low frame rate street videos. Our proposed system uses a modified version of RetinaNet (GPS-RetinaNet ), which predicts a positional offset for each sign relative to the camera, in addition to performing the standard classification and bounding box regression. Candidate sign detections from GPS-RetinaNet are condensed into geolocalized signs by our custom tracker, which consists of a learned metric network and a variant of the Hungarian Algorithm. Our metric network estimates the similarity between pairs of detections, then the Hungarian Algorithm matches detections across images using the similarity scores provided by the metric network. Our models were trained using an updated version of the ARTS dataset, which contains 25,544 images and 47.589 sign annotations ~\cite{arts}. The proposed dataset covers a diverse set of environments gathered from a broad selection of roads. Each annotaiton contains a sign class label, its geospatial location, an assembly label, a side of road indicator, and unique identifiers that aid in the evaluation. This dataset will support future progress in the field, and the proposed system demonstrates how to take advantage of some of the unique characteristics of a realistic geolocalization dataset.",RetinaNet : METHOD; (GPS-RetinaNet : METHOD; GPS-RetinaNet : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Geo-localizing static objects from street images is challenging but also very important for road asset mapping and autonomous driving. In this paper we present a two-stage framework that detects and geolocalizes traffic signs from low frame rate street videos. Our proposed system uses a modified version of RetinaNet (GPS-RetinaNet ), which predicts a positional offset for each sign relative to the camera, in addition to performing the standard classification and bounding box regression. Candidate sign detections from GPS-RetinaNet are condensed into geolocalized signs by our custom tracker, which consists of a learned metric network and a variant of the Hungarian Algorithm. Our metric network estimates the similarity between pairs of detections, then the Hungarian Algorithm matches detections across images using the similarity scores provided by the metric network. Our models were trained using an updated version of the ARTS dataset, which contains 25,544 images and 47.589 sign annotations ~\cite{arts}. The proposed dataset covers a diverse set of environments gathered from a broad selection of roads. Each annotaiton contains a sign class label, its geospatial location, an assembly label, a side of road indicator, and unique identifiers that aid in the evaluation. This dataset will support future progress in the field, and the proposed system demonstrates how to take advantage of some of the unique characteristics of a realistic geolocalization dataset. ### Response: RetinaNet : METHOD; (GPS-RetinaNet : METHOD; GPS-RetinaNet : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","There is an increasing realization that algorithmic inductive biases are central in preventing overfitting; empirically, we often see a benign overfitting phenomenon in overparameterized settings for natural learning algorithms, such as stochastic gradient descent (SGD ), where little to no explicit regularization has been employed. This work considers this issue in arguably the most basic setting: constant-stepsize SGD (with iterate averaging or tail averaging) for linear regression in the overparameterized regime. Our main result provides a sharp excess risk bound, stated in terms of the full eigenspectrum of the data covariance matrix, that reveals a bias-variance decomposition characterizing when generalization is possible: (i) the variance bound is characterized in terms of an effective dimension (specific for SGD ) and (ii) the bias bound provides a sharp geometric characterization in terms of the location of the initial iterate (and how it aligns with the data covariance matrix). More specifically, for SGD with iterate averaging, we demonstrate the sharpness of the established excess risk bound by proving a matching lower bound (up to constant factors). For SGD with tail averaging, we show its advantage over SGD with iterate averaging by proving a better excess risk bound together with a nearly matching lower bound. Moreover, we reflect on a number of notable differences between the algorithmic regularization afforded by (unregularized) SGD in comparison to ordinary least squares (minimum-norm interpolation) and ridge regression. Experimental results on synthetic data corroborate our theoretical findings.",(SGD : METHOD; SGD : METHOD; SGD : METHOD; SGD : METHOD; SGD : METHOD; SGD : METHOD; SGD : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: There is an increasing realization that algorithmic inductive biases are central in preventing overfitting; empirically, we often see a benign overfitting phenomenon in overparameterized settings for natural learning algorithms, such as stochastic gradient descent (SGD ), where little to no explicit regularization has been employed. This work considers this issue in arguably the most basic setting: constant-stepsize SGD (with iterate averaging or tail averaging) for linear regression in the overparameterized regime. Our main result provides a sharp excess risk bound, stated in terms of the full eigenspectrum of the data covariance matrix, that reveals a bias-variance decomposition characterizing when generalization is possible: (i) the variance bound is characterized in terms of an effective dimension (specific for SGD ) and (ii) the bias bound provides a sharp geometric characterization in terms of the location of the initial iterate (and how it aligns with the data covariance matrix). More specifically, for SGD with iterate averaging, we demonstrate the sharpness of the established excess risk bound by proving a matching lower bound (up to constant factors). For SGD with tail averaging, we show its advantage over SGD with iterate averaging by proving a better excess risk bound together with a nearly matching lower bound. Moreover, we reflect on a number of notable differences between the algorithmic regularization afforded by (unregularized) SGD in comparison to ordinary least squares (minimum-norm interpolation) and ridge regression. Experimental results on synthetic data corroborate our theoretical findings. ### Response: (SGD : METHOD; SGD : METHOD; SGD : METHOD; SGD : METHOD; SGD : METHOD; SGD : METHOD; SGD : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","We present the work-in-progress of automating the classification of doctor-patient questions in the context of a simulated consultation with a virtual patient. We classify questions according to the computational strategy (rule-based or other) needed for looking up data in the clinical record. We compare {`}traditional{'} machine learning methods (Gaussian and Multinomial Naive Bayes, and Support Vector Machines) and a neural network classifier (FastText). We obtained the best results with the SVM using semantic annotations, whereas the neural classifier achieved promising results without it.",SVM : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: We present the work-in-progress of automating the classification of doctor-patient questions in the context of a simulated consultation with a virtual patient. We classify questions according to the computational strategy (rule-based or other) needed for looking up data in the clinical record. We compare {`}traditional{'} machine learning methods (Gaussian and Multinomial Naive Bayes, and Support Vector Machines) and a neural network classifier (FastText). We obtained the best results with the SVM using semantic annotations, whereas the neural classifier achieved promising results without it. ### Response: SVM : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","This paper presents a constrained policy gradient algorithm. We introduce constraints for safe learning with the following steps. First, learning is slowed down (lazy learning) so that the episodic policy change can be computed with the help of the policy gradient theorem and the neural tangent kernel. Then, this enables us the evaluation of the policy at arbitrary states too. In the same spirit, learning can be guided, ensuring safety via augmenting episode batches with states where the desired action probabilities are prescribed. Finally, exogenous discounted sum of future rewards (returns) can be computed at these specific state-action pairs such that the policy network satisfies constraints. Computing the returns is based on solving a system of linear equations (equality constraints) or a constrained quadratic program (inequality constraints). Simulation results suggest that adding constraints (external information) to the learning can improve learning in terms of speed and safety reasonably if constraints are appropriately selected. The efficiency of the constrained learning was demonstrated with a shallow and wide ReLU network in the Cartpole and Lunar Lander OpenAI gym environments. The main novelty of the paper is giving a practical use of the neural tangent kernel in reinforcement learning.",ReLU : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: This paper presents a constrained policy gradient algorithm. We introduce constraints for safe learning with the following steps. First, learning is slowed down (lazy learning) so that the episodic policy change can be computed with the help of the policy gradient theorem and the neural tangent kernel. Then, this enables us the evaluation of the policy at arbitrary states too. In the same spirit, learning can be guided, ensuring safety via augmenting episode batches with states where the desired action probabilities are prescribed. Finally, exogenous discounted sum of future rewards (returns) can be computed at these specific state-action pairs such that the policy network satisfies constraints. Computing the returns is based on solving a system of linear equations (equality constraints) or a constrained quadratic program (inequality constraints). Simulation results suggest that adding constraints (external information) to the learning can improve learning in terms of speed and safety reasonably if constraints are appropriately selected. The efficiency of the constrained learning was demonstrated with a shallow and wide ReLU network in the Cartpole and Lunar Lander OpenAI gym environments. The main novelty of the paper is giving a practical use of the neural tangent kernel in reinforcement learning. ### Response: ReLU : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","A major challenge in reinforcement learning (RL) is the design of agents that are able to generalize across tasks that share common dynamics. A viable solution is meta-reinforcement learning, which identifies common structures among past tasks to be then generalized to new tasks (meta-test). In meta-training, the RL agent learns state representations that encode prior information from a set of tasks, used to generalize the value function approximation. This has been proposed in the literature as successor representation approximators. While promising, these methods do not generalize well across optimal policies, leading to sampling-inefficiency during meta-test phases. In this paper, we propose state2vec, an efficient and low-complexity framework for learning successor features which (i) generalize across policies, (ii) ensure sample-efficiency during meta-test. We extend the well known node2vec framework to learn state embeddings that account for the discounted future state transitions in RL. The proposed off-policy state2vec captures the geometry of the underlying state space, making good basis functions for linear value function approximation.",node2vec : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: A major challenge in reinforcement learning (RL) is the design of agents that are able to generalize across tasks that share common dynamics. A viable solution is meta-reinforcement learning, which identifies common structures among past tasks to be then generalized to new tasks (meta-test). In meta-training, the RL agent learns state representations that encode prior information from a set of tasks, used to generalize the value function approximation. This has been proposed in the literature as successor representation approximators. While promising, these methods do not generalize well across optimal policies, leading to sampling-inefficiency during meta-test phases. In this paper, we propose state2vec, an efficient and low-complexity framework for learning successor features which (i) generalize across policies, (ii) ensure sample-efficiency during meta-test. We extend the well known node2vec framework to learn state embeddings that account for the discounted future state transitions in RL. The proposed off-policy state2vec captures the geometry of the underlying state space, making good basis functions for linear value function approximation. ### Response: node2vec : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Although substantial efforts have been made to learn disentangled representations under the variational autoencoder (VAE ) framework, the fundamental properties to the dynamics of learning of most VAE models still remain unknown and under-investigated. In this work, we first propose a novel learning objective, termed the principle-of-relevant-information variational autoencoder (PRI-VAE ), to learn disentangled representations. We then present an information-theoretic perspective to analyze existing VAE models by inspecting the evolution of some critical information-theoretic quantities across training epochs. Our observations unveil some fundamental properties associated with VAE s. Empirical results also demonstrate the effectiveness of PRI-VAE on four benchmark data sets.",(VAE : METHOD; VAE : METHOD; (PRI-VAE : METHOD; VAE : METHOD; VAE : METHOD; PRI-VAE : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Although substantial efforts have been made to learn disentangled representations under the variational autoencoder (VAE ) framework, the fundamental properties to the dynamics of learning of most VAE models still remain unknown and under-investigated. In this work, we first propose a novel learning objective, termed the principle-of-relevant-information variational autoencoder (PRI-VAE ), to learn disentangled representations. We then present an information-theoretic perspective to analyze existing VAE models by inspecting the evolution of some critical information-theoretic quantities across training epochs. Our observations unveil some fundamental properties associated with VAE s. Empirical results also demonstrate the effectiveness of PRI-VAE on four benchmark data sets. ### Response: (VAE : METHOD; VAE : METHOD; (PRI-VAE : METHOD; VAE : METHOD; VAE : METHOD; PRI-VAE : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Linear discriminant analysis (LDA ) based classifiers tend to falter in many practical settings where the training data size is smaller than, or comparable to, the number of features. As a remedy, different regularized LDA (RLDA ) methods have been proposed. These methods may still perform poorly depending on the size and quality of the available training data. In particular, the test data deviation from the training data model, for example, due to noise contamination, can cause severe performance degradation. Moreover, these methods commit further to the Gaussian assumption (upon which LDA is established) to tune their regularization parameters, which may compromise accuracy when dealing with real data. To address these issues, we propose a doubly regularized LDA classifier that we denote as R2LDA . In the proposed R2LDA approach, the RLDA score function is converted into an inner product of two vectors. By substituting the expressions of the regularized estimators of these vectors, we obtain the R2LDA score function that involves two regularization parameters. To set the values of these parameters, we adopt three existing regularization techniques; the constrained perturbation regularization approach (COPRA), the bounded perturbation regularization (BPR) algorithm, and the generalized cross-validation (GCV) method. These methods are used to tune the regularization parameters based on linear estimation models, with the sample covariance matrix's square root being the linear operator. Results obtained from both synthetic and real data demonstrate the consistency and effectiveness of the proposed R2LDA approach, especially in scenarios involving test data contaminated with noise that is not observed during the training phase.",(LDA : METHOD; LDA : METHOD; (RLDA : METHOD; LDA : METHOD; LDA : METHOD; R2LDA : METHOD; R2LDA : METHOD; RLDA : METHOD; R2LDA : METHOD; R2LDA : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Linear discriminant analysis (LDA ) based classifiers tend to falter in many practical settings where the training data size is smaller than, or comparable to, the number of features. As a remedy, different regularized LDA (RLDA ) methods have been proposed. These methods may still perform poorly depending on the size and quality of the available training data. In particular, the test data deviation from the training data model, for example, due to noise contamination, can cause severe performance degradation. Moreover, these methods commit further to the Gaussian assumption (upon which LDA is established) to tune their regularization parameters, which may compromise accuracy when dealing with real data. To address these issues, we propose a doubly regularized LDA classifier that we denote as R2LDA . In the proposed R2LDA approach, the RLDA score function is converted into an inner product of two vectors. By substituting the expressions of the regularized estimators of these vectors, we obtain the R2LDA score function that involves two regularization parameters. To set the values of these parameters, we adopt three existing regularization techniques; the constrained perturbation regularization approach (COPRA), the bounded perturbation regularization (BPR) algorithm, and the generalized cross-validation (GCV) method. These methods are used to tune the regularization parameters based on linear estimation models, with the sample covariance matrix's square root being the linear operator. Results obtained from both synthetic and real data demonstrate the consistency and effectiveness of the proposed R2LDA approach, especially in scenarios involving test data contaminated with noise that is not observed during the training phase. ### Response: (LDA : METHOD; LDA : METHOD; (RLDA : METHOD; LDA : METHOD; LDA : METHOD; R2LDA : METHOD; R2LDA : METHOD; RLDA : METHOD; R2LDA : METHOD; R2LDA : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Ultrasound imaging makes use of backscattering of waves during theirinteraction with scatterers present in biological tissues. Simulation ofsynthetic ultrasound images is a challenging problem on account of inability toaccurately model various factors of which some include intra-/inter scanlineinterference, transducer to surface coupling, artifacts on transducer elements,inhomogeneous shadowing and nonlinear attenuation. Current approaches typicallysolve wave space equations making them computationally expensive and slow tooperate. We propose a generative adversarial network (GAN ) inspired approachfor fast simulation of patho-realistic ultrasound images. We apply theframework to intravascular ultrasound (IVUS) simulation. A stage 0 simulationperformed using pseudo B-mode ultrasound image simulator yields speckle mappingof a digitally defined phantom. The stage I GAN subsequently refines them topreserve tissue specific speckle intensities. The stage II GAN further refinesthem to generate high resolution images with patho-realistic speckle profiles.We evaluate patho-realism of simulated images with a visual Turing testindicating an equivocal confusion in discriminating simulated from real. Wealso quantify the shift in tissue specific intensity distributions of the realand simulated images to prove their similarity.",(GAN : METHOD; GAN : METHOD; GAN : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Ultrasound imaging makes use of backscattering of waves during theirinteraction with scatterers present in biological tissues. Simulation ofsynthetic ultrasound images is a challenging problem on account of inability toaccurately model various factors of which some include intra-/inter scanlineinterference, transducer to surface coupling, artifacts on transducer elements,inhomogeneous shadowing and nonlinear attenuation. Current approaches typicallysolve wave space equations making them computationally expensive and slow tooperate. We propose a generative adversarial network (GAN ) inspired approachfor fast simulation of patho-realistic ultrasound images. We apply theframework to intravascular ultrasound (IVUS) simulation. A stage 0 simulationperformed using pseudo B-mode ultrasound image simulator yields speckle mappingof a digitally defined phantom. The stage I GAN subsequently refines them topreserve tissue specific speckle intensities. The stage II GAN further refinesthem to generate high resolution images with patho-realistic speckle profiles.We evaluate patho-realism of simulated images with a visual Turing testindicating an equivocal confusion in discriminating simulated from real. Wealso quantify the shift in tissue specific intensity distributions of the realand simulated images to prove their similarity. ### Response: (GAN : METHOD; GAN : METHOD; GAN : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Target-oriented opinion words extraction (TOWE) (Fan et al., 2019b) is a new subtask of target-oriented sentiment analysis that aims to extract opinion words for a given aspect in text. Current state-of-the-art methods leverage position embeddings to capture the relative position of a word to the target. However, the performance of these methods depends on the ability to incorporate this information into word representations. In this paper, we explore a variety of text encoders based on pretrained word embeddings or language models that leverage part-of-speech and position embeddings, aiming to examine the actual contribution of each component in TOWE. We also adapt a graph convolutional network (GCN ) to enhance word representations by incorporating syntactic information. Our experimental results demonstrate that BiLSTM-based models can effectively encode position information into word representations while using a GCN only achieves marginal gains. Interestingly, our simple methods outperform several state-of-the-art complex neural structures.",(GCN : METHOD; GCN : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Target-oriented opinion words extraction (TOWE) (Fan et al., 2019b) is a new subtask of target-oriented sentiment analysis that aims to extract opinion words for a given aspect in text. Current state-of-the-art methods leverage position embeddings to capture the relative position of a word to the target. However, the performance of these methods depends on the ability to incorporate this information into word representations. In this paper, we explore a variety of text encoders based on pretrained word embeddings or language models that leverage part-of-speech and position embeddings, aiming to examine the actual contribution of each component in TOWE. We also adapt a graph convolutional network (GCN ) to enhance word representations by incorporating syntactic information. Our experimental results demonstrate that BiLSTM-based models can effectively encode position information into word representations while using a GCN only achieves marginal gains. Interestingly, our simple methods outperform several state-of-the-art complex neural structures. ### Response: (GCN : METHOD; GCN : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Logical reasoning tasks over symbols, such as learning arithmetic operations and computer program evaluations, have become challenges to deep learning. In particular, even state-of-the-art neural networks fail to achieve \textit{out-of-distribution} (OOD) generalization of symbolic reasoning tasks, whereas humans can easily extend learned symbolic rules. To resolve this difficulty, we propose a neural sequence-to-grid (seq2grid) module, an input preprocessor that automatically segments and aligns an input sequence into a grid. As our module outputs a grid via a novel differentiable mapping, any neural network structure taking a grid input, such as ResNet or TextCNN, can be jointly trained with our module in an end-to-end fashion. Extensive experiments show that neural networks having our module as an input preprocessor achieve OOD generalization on various arithmetic and algorithmic problems including number sequence prediction problems, algebraic word problems, and computer program evaluation problems while other state-of-the-art sequence transduction models cannot. Moreover, we verify that our module enhances TextCNN to solve the bAbI QA tasks without external memory.",ResNet : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Logical reasoning tasks over symbols, such as learning arithmetic operations and computer program evaluations, have become challenges to deep learning. In particular, even state-of-the-art neural networks fail to achieve \textit{out-of-distribution} (OOD) generalization of symbolic reasoning tasks, whereas humans can easily extend learned symbolic rules. To resolve this difficulty, we propose a neural sequence-to-grid (seq2grid) module, an input preprocessor that automatically segments and aligns an input sequence into a grid. As our module outputs a grid via a novel differentiable mapping, any neural network structure taking a grid input, such as ResNet or TextCNN, can be jointly trained with our module in an end-to-end fashion. Extensive experiments show that neural networks having our module as an input preprocessor achieve OOD generalization on various arithmetic and algorithmic problems including number sequence prediction problems, algebraic word problems, and computer program evaluation problems while other state-of-the-art sequence transduction models cannot. Moreover, we verify that our module enhances TextCNN to solve the bAbI QA tasks without external memory. ### Response: ResNet : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Adaptive gradient methods for stochastic optimization adjust the learningrate for each parameter locally. However, there is also a global learning ratewhich must be tuned in order to get the best performance. In this paper, wepresent a new algorithm that adapts the learning rate locally for eachparameter separately, and also globally for all parameters together.Specifically, we modify Adam , a popular method for training deep learningmodels, with a coefficient that captures properties of the objective function.Empirically, we show that our method, which we call Eve, outperforms Adam andother popular methods in training deep neural networks, like convolutionalneural networks for image classification, and recurrent neural networks forlanguage tasks.",Adam : METHOD; Adam : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Adaptive gradient methods for stochastic optimization adjust the learningrate for each parameter locally. However, there is also a global learning ratewhich must be tuned in order to get the best performance. In this paper, wepresent a new algorithm that adapts the learning rate locally for eachparameter separately, and also globally for all parameters together.Specifically, we modify Adam , a popular method for training deep learningmodels, with a coefficient that captures properties of the objective function.Empirically, we show that our method, which we call Eve, outperforms Adam andother popular methods in training deep neural networks, like convolutionalneural networks for image classification, and recurrent neural networks forlanguage tasks. ### Response: Adam : METHOD; Adam : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Many automatic machine learning models developed for focal pathology (e.g. lesions, tumours) detection and segmentation perform well, but do not generalize as well to new patient cohorts, impeding their widespread adoption into real clinical contexts. One strategy to create a more diverse, generalizable training set is to naively pool datasets from different cohorts. Surprisingly, training on this \it{big data} does not necessarily increase, and may even reduce, overall performance and model generalizability, due to the existence of cohort biases that affect label distributions. In this paper, we propose a generalized affine conditioning framework to learn and account for cohort biases across multi-source datasets, which we call Source-Conditioned Instance Normalization (SCIN). Through extensive experimentation on three different, large scale, multi-scanner, multi-centre Multiple Sclerosis (MS) clinical trial MRI datasets, we show that our cohort bias adaptation method (1) improves performance of the network on pooled datasets relative to naively pooling datasets and (2) can quickly adapt to a new cohort by fine-tuning the instance normalization parameters, thus learning the new cohort bias with only 10 labelled samples.",Instance Normalization : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Many automatic machine learning models developed for focal pathology (e.g. lesions, tumours) detection and segmentation perform well, but do not generalize as well to new patient cohorts, impeding their widespread adoption into real clinical contexts. One strategy to create a more diverse, generalizable training set is to naively pool datasets from different cohorts. Surprisingly, training on this \it{big data} does not necessarily increase, and may even reduce, overall performance and model generalizability, due to the existence of cohort biases that affect label distributions. In this paper, we propose a generalized affine conditioning framework to learn and account for cohort biases across multi-source datasets, which we call Source-Conditioned Instance Normalization (SCIN). Through extensive experimentation on three different, large scale, multi-scanner, multi-centre Multiple Sclerosis (MS) clinical trial MRI datasets, we show that our cohort bias adaptation method (1) improves performance of the network on pooled datasets relative to naively pooling datasets and (2) can quickly adapt to a new cohort by fine-tuning the instance normalization parameters, thus learning the new cohort bias with only 10 labelled samples. ### Response: Instance Normalization : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Dropout is a very effective method in preventing overfitting and has becomethe go-to regularizer for multi-layer neural networks in recent years.Hierarchical mixture of experts is a hierarchically gated model that defines asoft decision tree where leaves correspond to experts and decision nodescorrespond to gating models that softly choose between its children, and assuch, the model defines a soft hierarchical partitioning of the input space. Inthis work, we propose a variant of dropout for hierarchical mixture of expertsthat is faithful to the tree hierarchy defined by the model, as opposed tohaving a flat, unitwise independent application of dropout as one has withmulti-layer perceptrons. We show that on a synthetic regression data and onMNIST and CIFAR-10 datasets, our proposed dropout mechanism preventsoverfitting on trees with many levels improving generalization and providingsmoother fits.",Dropout : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Dropout is a very effective method in preventing overfitting and has becomethe go-to regularizer for multi-layer neural networks in recent years.Hierarchical mixture of experts is a hierarchically gated model that defines asoft decision tree where leaves correspond to experts and decision nodescorrespond to gating models that softly choose between its children, and assuch, the model defines a soft hierarchical partitioning of the input space. Inthis work, we propose a variant of dropout for hierarchical mixture of expertsthat is faithful to the tree hierarchy defined by the model, as opposed tohaving a flat, unitwise independent application of dropout as one has withmulti-layer perceptrons. We show that on a synthetic regression data and onMNIST and CIFAR-10 datasets, our proposed dropout mechanism preventsoverfitting on trees with many levels improving generalization and providingsmoother fits. ### Response: Dropout : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","In recent times, BERT based transformer models have become an inseparable part of the 'tech stack' of text processing models. Similar progress is being observed in the speech domain with a multitude of models observing state-of-the-art results by using audio transformer models to encode speech. This begs the question of what are these audio transformer models learning. Moreover, although the standard methodology is to choose the last layer embedding for any downstream task, but is it the optimal choice? We try to answer these questions for the two recent audio transformer models, Mockingjay and wave2vec2.0. We compare them on a comprehensive set of language delivery and structure features including audio, fluency and pronunciation features. Additionally, we probe the audio models' understanding of textual surface, syntax, and semantic features and compare them to BERT . We do this over exhaustive settings for native, non-native, synthetic, read and spontaneous speech datasets",BERT : METHOD; BERT : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: In recent times, BERT based transformer models have become an inseparable part of the 'tech stack' of text processing models. Similar progress is being observed in the speech domain with a multitude of models observing state-of-the-art results by using audio transformer models to encode speech. This begs the question of what are these audio transformer models learning. Moreover, although the standard methodology is to choose the last layer embedding for any downstream task, but is it the optimal choice? We try to answer these questions for the two recent audio transformer models, Mockingjay and wave2vec2.0. We compare them on a comprehensive set of language delivery and structure features including audio, fluency and pronunciation features. Additionally, we probe the audio models' understanding of textual surface, syntax, and semantic features and compare them to BERT . We do this over exhaustive settings for native, non-native, synthetic, read and spontaneous speech datasets ### Response: BERT : METHOD; BERT : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Physical and cloud storage services are well-served by functioning and reliable high-volume storage systems. Recent observations point to hard disk reliability as one of the most pressing reliability issues in data centers containing massive volumes of storage devices such as HDDs. In this regard, early detection of impending failure at the disk level aids in reducing system downtime and reduces operational loss making proactive health monitoring a priority for AIOps in such settings. In this work, we introduce methods of extracting meaningful attributes associated with operational failure and of pre-processing the highly imbalanced health statistics data for subsequent prediction tasks using data-driven approaches. We use a Bidirectional LSTM with a multi-day look back period to learn the temporal progression of health indicators and baseline them against vanilla LSTM and Random Forest models to come up with several key metrics that establish the usefulness of and superiority of our model under some tightly defined operational constraints. For example, using a 15 day look back period, our approach can predict the occurrence of disk failure with an accuracy of 96.4% considering test data 60 days before failure. This helps to alert operations maintenance well in-advance about potential mitigation needs. In addition, our model reports a mean absolute error of 0.12 for predicting failure up to 60 days in advance, placing it among the state-of-the-art in recent literature.",LSTM : METHOD; LSTM : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Physical and cloud storage services are well-served by functioning and reliable high-volume storage systems. Recent observations point to hard disk reliability as one of the most pressing reliability issues in data centers containing massive volumes of storage devices such as HDDs. In this regard, early detection of impending failure at the disk level aids in reducing system downtime and reduces operational loss making proactive health monitoring a priority for AIOps in such settings. In this work, we introduce methods of extracting meaningful attributes associated with operational failure and of pre-processing the highly imbalanced health statistics data for subsequent prediction tasks using data-driven approaches. We use a Bidirectional LSTM with a multi-day look back period to learn the temporal progression of health indicators and baseline them against vanilla LSTM and Random Forest models to come up with several key metrics that establish the usefulness of and superiority of our model under some tightly defined operational constraints. For example, using a 15 day look back period, our approach can predict the occurrence of disk failure with an accuracy of 96.4% considering test data 60 days before failure. This helps to alert operations maintenance well in-advance about potential mitigation needs. In addition, our model reports a mean absolute error of 0.12 for predicting failure up to 60 days in advance, placing it among the state-of-the-art in recent literature. ### Response: LSTM : METHOD; LSTM : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Despite their performance, Artificial Neural Networks are not reliable enough for most of industrial applications. They are sensitive to noises, rotations, blurs and adversarial examples. There is a need to build defenses that protect against a wide range of perturbations, covering the most traditional common corruptions and adversarial examples. We propose a new data augmentation strategy called M-TLAT and designed to address robustness in a broad sense. Our approach combines the Mixup augmentation and a new adversarial training algorithm called Targeted Labeling Adversarial Training (TLAT). The idea of TLAT is to interpolate the target labels of adversarial examples with the ground-truth labels. We show that M-TLAT can increase the robustness of image classifiers towards nineteen common corruptions and five adversarial attacks, without reducing the accuracy on clean samples.",Mixup : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Despite their performance, Artificial Neural Networks are not reliable enough for most of industrial applications. They are sensitive to noises, rotations, blurs and adversarial examples. There is a need to build defenses that protect against a wide range of perturbations, covering the most traditional common corruptions and adversarial examples. We propose a new data augmentation strategy called M-TLAT and designed to address robustness in a broad sense. Our approach combines the Mixup augmentation and a new adversarial training algorithm called Targeted Labeling Adversarial Training (TLAT). The idea of TLAT is to interpolate the target labels of adversarial examples with the ground-truth labels. We show that M-TLAT can increase the robustness of image classifiers towards nineteen common corruptions and five adversarial attacks, without reducing the accuracy on clean samples. ### Response: Mixup : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","When applying principal component analysis (PCA ) for dimension reduction, the most varying projections are usually used in order to retain most of the information. For the purpose of anomaly and change detection, however, the least varying projections are often the most important ones. In this article, we present a novel method that automatically tailors the choice of projections to monitor for sparse changes in the mean and/or covariance matrix of high-dimensional data. A subset of the least varying projections is almost always selected based on a criteria of the projection's sensitivity to changes. Our focus is on online/sequential change detection, where the aim is to detect changes as quickly as possible, while controlling false alarms at a specified level. A combination of tailored PCA and a generalized log-likelihood monitoring procedure displays high efficiency in detecting even very sparse changes in the mean, variance and correlation. We demonstrate on real data that tailored PCA monitoring is efficient for sparse change detection also when the data streams are highly auto-correlated and non-normal. Notably, error control is achieved without a large validation set, which is needed in most existing methods.",(PCA : METHOD; PCA : METHOD; PCA : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: When applying principal component analysis (PCA ) for dimension reduction, the most varying projections are usually used in order to retain most of the information. For the purpose of anomaly and change detection, however, the least varying projections are often the most important ones. In this article, we present a novel method that automatically tailors the choice of projections to monitor for sparse changes in the mean and/or covariance matrix of high-dimensional data. A subset of the least varying projections is almost always selected based on a criteria of the projection's sensitivity to changes. Our focus is on online/sequential change detection, where the aim is to detect changes as quickly as possible, while controlling false alarms at a specified level. A combination of tailored PCA and a generalized log-likelihood monitoring procedure displays high efficiency in detecting even very sparse changes in the mean, variance and correlation. We demonstrate on real data that tailored PCA monitoring is efficient for sparse change detection also when the data streams are highly auto-correlated and non-normal. Notably, error control is achieved without a large validation set, which is needed in most existing methods. ### Response: (PCA : METHOD; PCA : METHOD; PCA : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","PixelCNN achieves state-of-the-art results in density estimation for naturalimages. Although training is fast, inference is costly, requiring one networkevaluation per pixel; O(N) for N pixels. This can be sped up by cachingactivations, but still involves generating each pixel sequentially. In thiswork, we propose a parallelized PixelCNN that allows more efficient inferenceby modeling certain pixel groups as conditionally independent. Our new PixelCNN model achieves competitive density estimation and orders of magnitude speedup -O(log N) sampling instead of O(N) - enabling the practical generation of512x512 images. We evaluate the model on class-conditional image generation,text-to-image synthesis, and action-conditional video generation, showing thatour model achieves the best results among non-pixel-autoregressive densitymodels that allow efficient sampling.",PixelCNN : METHOD; PixelCNN : METHOD; PixelCNN : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: PixelCNN achieves state-of-the-art results in density estimation for naturalimages. Although training is fast, inference is costly, requiring one networkevaluation per pixel; O(N) for N pixels. This can be sped up by cachingactivations, but still involves generating each pixel sequentially. In thiswork, we propose a parallelized PixelCNN that allows more efficient inferenceby modeling certain pixel groups as conditionally independent. Our new PixelCNN model achieves competitive density estimation and orders of magnitude speedup -O(log N) sampling instead of O(N) - enabling the practical generation of512x512 images. We evaluate the model on class-conditional image generation,text-to-image synthesis, and action-conditional video generation, showing thatour model achieves the best results among non-pixel-autoregressive densitymodels that allow efficient sampling. ### Response: PixelCNN : METHOD; PixelCNN : METHOD; PixelCNN : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Visual speech recognition models traditionally consist of two stages, feature extraction and classification. Several deep learning approaches have been recently presented aiming to replace the feature extraction stage by automatically extracting features from mouth images. However, research on joint learning of features and classification remains limited. In addition, most of the existing methods require large amounts of data in order to achieve state-of-the-art performance, otherwise they under-perform. In this work, we present an end-to-end visual speech recognition system based on fully-connected layers and Long-Short Memory (LSTM ) networks which is suitable for small-scale datasets. The model consists of two streams which extract features directly from the mouth and difference images, respectively. The temporal dynamics in each stream are modelled by a Bidirectional LSTM (BLSTM ) and the fusion of the two streams takes place via another BLSTM . An absolute improvement of 0.6%, 3.4%, 3.9%, 11.4% over the state-of-the-art is reported on the OuluVS2, CUAVE, AVLetters and AVLetters2 databases, respectively.",(LSTM : METHOD; LSTM : METHOD; (BLSTM : METHOD; BLSTM : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Visual speech recognition models traditionally consist of two stages, feature extraction and classification. Several deep learning approaches have been recently presented aiming to replace the feature extraction stage by automatically extracting features from mouth images. However, research on joint learning of features and classification remains limited. In addition, most of the existing methods require large amounts of data in order to achieve state-of-the-art performance, otherwise they under-perform. In this work, we present an end-to-end visual speech recognition system based on fully-connected layers and Long-Short Memory (LSTM ) networks which is suitable for small-scale datasets. The model consists of two streams which extract features directly from the mouth and difference images, respectively. The temporal dynamics in each stream are modelled by a Bidirectional LSTM (BLSTM ) and the fusion of the two streams takes place via another BLSTM . An absolute improvement of 0.6%, 3.4%, 3.9%, 11.4% over the state-of-the-art is reported on the OuluVS2, CUAVE, AVLetters and AVLetters2 databases, respectively. ### Response: (LSTM : METHOD; LSTM : METHOD; (BLSTM : METHOD; BLSTM : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Detecting prohibited items in X-ray security imagery is pivotal in maintaining border and transport security against a wide range of threat profiles. Convolutional Neural Networks (CNN) with the support of a significant volume of data have brought advancement in such automated prohibited object detection and classification. However, collating such large volumes of X-ray security imagery remains a significant challenge. This work opens up the possibility of using synthetically composed imagery, avoiding the need to collate such large volumes of hand-annotated real-world imagery. Here we investigate the difference in detection performance achieved using real and synthetic X-ray training imagery for CNN architecture detecting three exemplar prohibited items, {Firearm, Firearm Parts, Knives}, within cluttered and complex X-ray security baggage imagery. We achieve 0.88 of mean average precision (mAP) with a Faster R-CNN and ResNet-101 CNN architecture for this 3-class object detection using real X-ray imagery. While the performance is comparable with synthetically composited X-ray imagery (0.78 mAP), our extended evaluation demonstrates both challenge and promise of using synthetically composed images to diversify the X-ray security training imagery for automated detection algorithm training.",Faster R-CNN : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Detecting prohibited items in X-ray security imagery is pivotal in maintaining border and transport security against a wide range of threat profiles. Convolutional Neural Networks (CNN) with the support of a significant volume of data have brought advancement in such automated prohibited object detection and classification. However, collating such large volumes of X-ray security imagery remains a significant challenge. This work opens up the possibility of using synthetically composed imagery, avoiding the need to collate such large volumes of hand-annotated real-world imagery. Here we investigate the difference in detection performance achieved using real and synthetic X-ray training imagery for CNN architecture detecting three exemplar prohibited items, {Firearm, Firearm Parts, Knives}, within cluttered and complex X-ray security baggage imagery. We achieve 0.88 of mean average precision (mAP) with a Faster R-CNN and ResNet-101 CNN architecture for this 3-class object detection using real X-ray imagery. While the performance is comparable with synthetically composited X-ray imagery (0.78 mAP), our extended evaluation demonstrates both challenge and promise of using synthetically composed images to diversify the X-ray security training imagery for automated detection algorithm training. ### Response: Faster R-CNN : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","This paper introduces two recurrent neural network structures called SimpleGated Unit (SGU) and Deep Simple Gated Unit (DSGU), which are generalstructures for learning long term dependencies. Compared to traditional LongShort-Term Memory (LSTM) and Gated Recurrent Unit (GRU ), both structuresrequire fewer parameters and less computation time in sequence classificationtasks. Unlike GRU and LSTM, which require more than one gates to controlinformation flow in the network, SGU and DSGU only use one multiplicative gateto control the flow of information. We show that this difference can acceleratethe learning speed in tasks that require long dependency information. We alsoshow that DSGU is more numerically stable than SGU. In addition, we alsopropose a standard way of representing inner structure of RNN called RNNConventional Graph (RCG), which helps analyzing the relationship between inputunits and hidden units of RNN.",(GRU : METHOD; GRU : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: This paper introduces two recurrent neural network structures called SimpleGated Unit (SGU) and Deep Simple Gated Unit (DSGU), which are generalstructures for learning long term dependencies. Compared to traditional LongShort-Term Memory (LSTM) and Gated Recurrent Unit (GRU ), both structuresrequire fewer parameters and less computation time in sequence classificationtasks. Unlike GRU and LSTM, which require more than one gates to controlinformation flow in the network, SGU and DSGU only use one multiplicative gateto control the flow of information. We show that this difference can acceleratethe learning speed in tasks that require long dependency information. We alsoshow that DSGU is more numerically stable than SGU. In addition, we alsopropose a standard way of representing inner structure of RNN called RNNConventional Graph (RCG), which helps analyzing the relationship between inputunits and hidden units of RNN. ### Response: (GRU : METHOD; GRU : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Tremendous amounts of multimedia associated with speech information are driving an urgent need to develop efficient and effective automatic summarization methods. To this end, we have seen rapid progress in applying supervised deep neural network-based methods to extractive speech summarization. More recently, the Bidirectional Encoder Representations from Transformers (BERT ) model was proposed and has achieved record-breaking success on many natural language processing (NLP) tasks such as question answering and language understanding. In view of this, we in this paper contextualize and enhance the state-of-the-art BERT -based model for speech summarization, while its contributions are at least three-fold. First, we explore the incorporation of confidence scores into sentence representations to see if such an attempt could help alleviate the negative effects caused by imperfect automatic speech recognition (ASR). Secondly, we also augment the sentence embeddings obtained from BERT with extra structural and linguistic features, such as sentence position and inverse document frequency (IDF) statistics. Finally, we validate the effectiveness of our proposed method on a benchmark dataset, in comparison to several classic and celebrated speech summarization methods.",(BERT : METHOD; BERT : METHOD; BERT : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Tremendous amounts of multimedia associated with speech information are driving an urgent need to develop efficient and effective automatic summarization methods. To this end, we have seen rapid progress in applying supervised deep neural network-based methods to extractive speech summarization. More recently, the Bidirectional Encoder Representations from Transformers (BERT ) model was proposed and has achieved record-breaking success on many natural language processing (NLP) tasks such as question answering and language understanding. In view of this, we in this paper contextualize and enhance the state-of-the-art BERT -based model for speech summarization, while its contributions are at least three-fold. First, we explore the incorporation of confidence scores into sentence representations to see if such an attempt could help alleviate the negative effects caused by imperfect automatic speech recognition (ASR). Secondly, we also augment the sentence embeddings obtained from BERT with extra structural and linguistic features, such as sentence position and inverse document frequency (IDF) statistics. Finally, we validate the effectiveness of our proposed method on a benchmark dataset, in comparison to several classic and celebrated speech summarization methods. ### Response: (BERT : METHOD; BERT : METHOD; BERT : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Distributed machine learning has been widely studied in order to handle exploding amount of data. In this paper, we study an important yet less visited distributed learning problem where features are inherently distributed or vertically partitioned among multiple parties, and sharing of raw data or model parameters among parties is prohibited due to privacy concerns. We propose an ADMM sharing framework to approach risk minimization over distributed features, where each party only needs to share a single value for each sample in the training process, thus minimizing the data leakage risk. We establish convergence and iteration complexity results for the proposed parallel ADMM algorithm under non-convex loss. We further introduce a novel differentially private ADMM sharing algorithm and bound the privacy guarantee with carefully designed noise perturbation. The experiments based on a prototype system shows that the proposed ADMM algorithms converge efficiently in a robust fashion, demonstrating advantage over gradient based methods especially for data set with high dimensional feature spaces.",ADMM : METHOD; ADMM : METHOD; ADMM : METHOD; ADMM : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Distributed machine learning has been widely studied in order to handle exploding amount of data. In this paper, we study an important yet less visited distributed learning problem where features are inherently distributed or vertically partitioned among multiple parties, and sharing of raw data or model parameters among parties is prohibited due to privacy concerns. We propose an ADMM sharing framework to approach risk minimization over distributed features, where each party only needs to share a single value for each sample in the training process, thus minimizing the data leakage risk. We establish convergence and iteration complexity results for the proposed parallel ADMM algorithm under non-convex loss. We further introduce a novel differentially private ADMM sharing algorithm and bound the privacy guarantee with carefully designed noise perturbation. The experiments based on a prototype system shows that the proposed ADMM algorithms converge efficiently in a robust fashion, demonstrating advantage over gradient based methods especially for data set with high dimensional feature spaces. ### Response: ADMM : METHOD; ADMM : METHOD; ADMM : METHOD; ADMM : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Monocular face reconstruction is a challenging task in computer vision, which aims to recover 3D face geometry from a single RGB face image. Recently, deep learning based methods have achieved great improvements on monocular face reconstruction. However, for deep learning-based methods to reach optimal performance, it is paramount to have large-scale training images with ground-truth 3D face geometry, which is generally difficult for human to annotate. To tackle this problem, we propose a semi-supervised monocular reconstruction method, which jointly optimizes a shape-preserved domain-transfer CycleGAN and a shape estimation network. The framework is semi-supervised trained with 3D rendered images with ground-truth shapes and in-the-wild face images without any extra annotation. The CycleGAN network transforms all realistic images to have the rendered style and is end-to-end trained within the overall framework. This is the key difference compared with existing CycleGAN -based learning methods, which just used CycleGAN as a separate training sample generator. Novel landmark consistency loss and edge-aware shape estimation loss are proposed for our two networks to jointly solve the challenging face reconstruction problem. Extensive experiments on public face reconstruction datasets demonstrate the effectiveness of our overall method as well as the individual components.",CycleGAN : METHOD; CycleGAN : METHOD; CycleGAN : METHOD; CycleGAN : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Monocular face reconstruction is a challenging task in computer vision, which aims to recover 3D face geometry from a single RGB face image. Recently, deep learning based methods have achieved great improvements on monocular face reconstruction. However, for deep learning-based methods to reach optimal performance, it is paramount to have large-scale training images with ground-truth 3D face geometry, which is generally difficult for human to annotate. To tackle this problem, we propose a semi-supervised monocular reconstruction method, which jointly optimizes a shape-preserved domain-transfer CycleGAN and a shape estimation network. The framework is semi-supervised trained with 3D rendered images with ground-truth shapes and in-the-wild face images without any extra annotation. The CycleGAN network transforms all realistic images to have the rendered style and is end-to-end trained within the overall framework. This is the key difference compared with existing CycleGAN -based learning methods, which just used CycleGAN as a separate training sample generator. Novel landmark consistency loss and edge-aware shape estimation loss are proposed for our two networks to jointly solve the challenging face reconstruction problem. Extensive experiments on public face reconstruction datasets demonstrate the effectiveness of our overall method as well as the individual components. ### Response: CycleGAN : METHOD; CycleGAN : METHOD; CycleGAN : METHOD; CycleGAN : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Hateful and Toxic content has become a significant concern in today's world due to an exponential rise in social media. The increase in hate speech and harmful content motivated researchers to dedicate substantial efforts to the challenging direction of hateful content identification. In this task, we propose an approach to automatically classify hate speech and offensive content. We have used the datasets obtained from FIRE 2019 and 2020 shared tasks. We perform experiments by taking advantage of transfer learning models. We observed that the pre-trained BERT model and the multilingual-BERT model gave the best results. The code is made publically available at https://github.com/suman101112/hasoc-fire-2020.",BERT : METHOD; multilingual-BERT : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Hateful and Toxic content has become a significant concern in today's world due to an exponential rise in social media. The increase in hate speech and harmful content motivated researchers to dedicate substantial efforts to the challenging direction of hateful content identification. In this task, we propose an approach to automatically classify hate speech and offensive content. We have used the datasets obtained from FIRE 2019 and 2020 shared tasks. We perform experiments by taking advantage of transfer learning models. We observed that the pre-trained BERT model and the multilingual-BERT model gave the best results. The code is made publically available at https://github.com/suman101112/hasoc-fire-2020. ### Response: BERT : METHOD; multilingual-BERT : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","We explore the phase diagram of approximation rates for deep neural networks and prove several new theoretical results. In particular, we generalize the existing result on the existence of deep discontinuous phase in ReLU networks to functional classes of arbitrary positive smoothness, and identify the boundary between the feasible and infeasible rates. Moreover, we show that all networks with a piecewise polynomial activation function have the same phase diagram. Next, we demonstrate that standard fully-connected architectures with a fixed width independent of smoothness can adapt to smoothness and achieve almost optimal rates. Finally, we consider deep networks with periodic activations (""deep Fourier expansion"") and prove that they have very fast, nearly exponential approximation rates, thanks to the emerging capability of the network to implement efficient lookup operations.",ReLU : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: We explore the phase diagram of approximation rates for deep neural networks and prove several new theoretical results. In particular, we generalize the existing result on the existence of deep discontinuous phase in ReLU networks to functional classes of arbitrary positive smoothness, and identify the boundary between the feasible and infeasible rates. Moreover, we show that all networks with a piecewise polynomial activation function have the same phase diagram. Next, we demonstrate that standard fully-connected architectures with a fixed width independent of smoothness can adapt to smoothness and achieve almost optimal rates. Finally, we consider deep networks with periodic activations (""deep Fourier expansion"") and prove that they have very fast, nearly exponential approximation rates, thanks to the emerging capability of the network to implement efficient lookup operations. ### Response: ReLU : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","In order to further overcome the difficulties of the existing models in dealing with the non-stationary and nonlinear characteristics of high-frequency financial time series data, especially its weak generalization ability, this paper proposes an ensemble method based on data denoising methods, including the wavelet transform (WT) and singular spectrum analysis (SSA), and long-term short-term memory neural network (LSTM ) to build a data prediction model, The financial time series is decomposed and reconstructed by WT and SSA to denoise. Under the condition of denoising, the smooth sequence with effective information is reconstructed. The smoothing sequence is introduced into LSTM and the predicted value is obtained. With the Dow Jones industrial average index (DJIA) as the research object, the closing price of the DJIA every five minutes is divided into short-term (1 hour), medium-term (3 hours) and long-term (6 hours) respectively. . Based on root mean square error (RMSE), mean absolute error (MAE), mean absolute percentage error (MAPE) and absolute percentage error standard deviation (SDAPE), the experimental results show that in the short-term, medium-term and long-term, data denoising can greatly improve the accuracy and stability of the prediction, and can effectively improve the generalization ability of LSTM prediction model. As WT and SSA can extract useful information from the original sequence and avoid overfitting, the hybrid model can better grasp the sequence pattern of the closing price of the DJIA. And the WT-LSTM model is better than the benchmark LSTM model and SSA-LSTM model.",(LSTM : METHOD; LSTM : METHOD; LSTM : METHOD; WT-LSTM : METHOD; LSTM : METHOD; SSA-LSTM : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: In order to further overcome the difficulties of the existing models in dealing with the non-stationary and nonlinear characteristics of high-frequency financial time series data, especially its weak generalization ability, this paper proposes an ensemble method based on data denoising methods, including the wavelet transform (WT) and singular spectrum analysis (SSA), and long-term short-term memory neural network (LSTM ) to build a data prediction model, The financial time series is decomposed and reconstructed by WT and SSA to denoise. Under the condition of denoising, the smooth sequence with effective information is reconstructed. The smoothing sequence is introduced into LSTM and the predicted value is obtained. With the Dow Jones industrial average index (DJIA) as the research object, the closing price of the DJIA every five minutes is divided into short-term (1 hour), medium-term (3 hours) and long-term (6 hours) respectively. . Based on root mean square error (RMSE), mean absolute error (MAE), mean absolute percentage error (MAPE) and absolute percentage error standard deviation (SDAPE), the experimental results show that in the short-term, medium-term and long-term, data denoising can greatly improve the accuracy and stability of the prediction, and can effectively improve the generalization ability of LSTM prediction model. As WT and SSA can extract useful information from the original sequence and avoid overfitting, the hybrid model can better grasp the sequence pattern of the closing price of the DJIA. And the WT-LSTM model is better than the benchmark LSTM model and SSA-LSTM model. ### Response: (LSTM : METHOD; LSTM : METHOD; LSTM : METHOD; WT-LSTM : METHOD; LSTM : METHOD; SSA-LSTM : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","An ensemble of neural networks is known to be more robust and accurate thanan individual network, however usually with linearly-increased cost in bothtraining and testing. In this work, we propose a two-stage method to learnSparse Structured Ensembles (SSEs) for neural networks. In the first stage, werun SG-MCMC with group sparse priors to draw an ensemble of samples from theposterior distribution of network parameters. In the second stage, we applyweight-pruning to each sampled network and then perform retraining over theremained connections. In this way of learning SSEs with SG-MCMC and pruning, wenot only achieve high prediction accuracy since SG-MCMC enhances exploration ofthe model-parameter space, but also reduce memory and computation costsignificantly in both training and testing of NN ensembles. This is thoroughlyevaluated in the experiments of learning SSE ensembles of both FNNs and LSTM s.For example, in LSTM based language modeling (LM), we obtain 21% relativereduction in LM perplexity by learning a SSE of 4 large LSTM models, which hasonly 30% of model parameters and 70% of computations in total, as compared tothe baseline large LSTM LM. To the best of our knowledge, this work representsthe first methodology and empirical study of integrating SG-MCMC, group sparseprior and network pruning together for learning NN ensembles.",LSTM : METHOD; LSTM : METHOD; LSTM : METHOD; LSTM : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: An ensemble of neural networks is known to be more robust and accurate thanan individual network, however usually with linearly-increased cost in bothtraining and testing. In this work, we propose a two-stage method to learnSparse Structured Ensembles (SSEs) for neural networks. In the first stage, werun SG-MCMC with group sparse priors to draw an ensemble of samples from theposterior distribution of network parameters. In the second stage, we applyweight-pruning to each sampled network and then perform retraining over theremained connections. In this way of learning SSEs with SG-MCMC and pruning, wenot only achieve high prediction accuracy since SG-MCMC enhances exploration ofthe model-parameter space, but also reduce memory and computation costsignificantly in both training and testing of NN ensembles. This is thoroughlyevaluated in the experiments of learning SSE ensembles of both FNNs and LSTM s.For example, in LSTM based language modeling (LM), we obtain 21% relativereduction in LM perplexity by learning a SSE of 4 large LSTM models, which hasonly 30% of model parameters and 70% of computations in total, as compared tothe baseline large LSTM LM. To the best of our knowledge, this work representsthe first methodology and empirical study of integrating SG-MCMC, group sparseprior and network pruning together for learning NN ensembles. ### Response: LSTM : METHOD; LSTM : METHOD; LSTM : METHOD; LSTM : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Physical construction---the ability to compose objects, subject to physical dynamics, to serve some function---is fundamental to human intelligence. We introduce a suite of challenging physical construction tasks inspired by how children play with blocks, such as matching a target configuration, stacking blocks to connect objects together, and creating shelter-like structures over target objects. We examine how a range of deep reinforcement learning agents fare on these challenges, and introduce several new approaches which provide superior performance. Our results show that agents which use structured representations (e.g., objects and scene graphs) and structured policies (e.g., object-centric actions) outperform those which use less structured representations, and generalize better beyond their training when asked to reason about larger scenes. Model-based agents which use Monte-Carlo Tree Search also outperform strictly model-free agents in our most challenging construction problems. We conclude that approaches which combine structured representations and reasoning with powerful learning are a key path toward agents that possess rich intuitive physics, scene understanding, and planning.",Monte-Carlo Tree Search : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Physical construction---the ability to compose objects, subject to physical dynamics, to serve some function---is fundamental to human intelligence. We introduce a suite of challenging physical construction tasks inspired by how children play with blocks, such as matching a target configuration, stacking blocks to connect objects together, and creating shelter-like structures over target objects. We examine how a range of deep reinforcement learning agents fare on these challenges, and introduce several new approaches which provide superior performance. Our results show that agents which use structured representations (e.g., objects and scene graphs) and structured policies (e.g., object-centric actions) outperform those which use less structured representations, and generalize better beyond their training when asked to reason about larger scenes. Model-based agents which use Monte-Carlo Tree Search also outperform strictly model-free agents in our most challenging construction problems. We conclude that approaches which combine structured representations and reasoning with powerful learning are a key path toward agents that possess rich intuitive physics, scene understanding, and planning. ### Response: Monte-Carlo Tree Search : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","This paper introduces a novel method to fine-tune handwriting recognition systems based on Recurrent Neural Networks (RNN). Long Short-Term Memory (LSTM) networks are good at modeling long sequences but they tend to overfit over time. To improve the system's ability to model sequences, we propose to drop information at random positions in the sequence. We call our approach Temporal Dropout (TD). We apply TD at the image level as well to internal network representation. We show that TD improves the results on two different datasets. Our method outperforms previous state-of-the-art on Rodrigo dataset.",Dropout : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: This paper introduces a novel method to fine-tune handwriting recognition systems based on Recurrent Neural Networks (RNN). Long Short-Term Memory (LSTM) networks are good at modeling long sequences but they tend to overfit over time. To improve the system's ability to model sequences, we propose to drop information at random positions in the sequence. We call our approach Temporal Dropout (TD). We apply TD at the image level as well to internal network representation. We show that TD improves the results on two different datasets. Our method outperforms previous state-of-the-art on Rodrigo dataset. ### Response: Dropout : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","In contrast to their word- or sentence-level counterparts, character embeddings are still poorly understood. We aim at closing this gap with an in-depth study of English character embeddings. For this, we use resources from research on grapheme-color synesthesia -- a neuropsychological phenomenon where letters are associated with colors, which give us insight into which characters are similar for synesthetes and how characters are organized in color space. Comparing 10 different character embeddings, we ask: How similar are character embeddings to a synesthete's perception of characters? And how similar are character embeddings extracted from different models? We find that LSTMs agree with humans more than transformers. Comparing across tasks, grapheme-to-phoneme conversion results in the most human-like character embeddings. Finally, ELMo embeddings differ from both humans and other models.",ELMo : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: In contrast to their word- or sentence-level counterparts, character embeddings are still poorly understood. We aim at closing this gap with an in-depth study of English character embeddings. For this, we use resources from research on grapheme-color synesthesia -- a neuropsychological phenomenon where letters are associated with colors, which give us insight into which characters are similar for synesthetes and how characters are organized in color space. Comparing 10 different character embeddings, we ask: How similar are character embeddings to a synesthete's perception of characters? And how similar are character embeddings extracted from different models? We find that LSTMs agree with humans more than transformers. Comparing across tasks, grapheme-to-phoneme conversion results in the most human-like character embeddings. Finally, ELMo embeddings differ from both humans and other models. ### Response: ELMo : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","High throughput and low latency inference of deep neural networks arecritical for the deployment of deep learning applications. This paper presentsthe efficient inference techniques of IntelCaffe, the first Intel optimizeddeep learning framework that supports efficient 8-bit low precision inferenceand model optimization techniques of convolutional neural networks on IntelXeon Scalable Processors. The 8-bit optimized model is automatically generatedwith a calibration process from FP32 model without the need of fine-tuning orretraining. We show that the inference throughput and latency with ResNet-50,Inception-v3 and SSD are improved by 1.38X-2.9X and 1.35X-3X respectively withneglectable accuracy loss from IntelCaffe FP32 baseline and by 56X-75X and26X-37X from BVLC Caffe. All these techniques have been open-sourced onIntelCaffe GitHub1, and the artifact is provided to reproduce the result onAmazon AWS Cloud.",SSD : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: High throughput and low latency inference of deep neural networks arecritical for the deployment of deep learning applications. This paper presentsthe efficient inference techniques of IntelCaffe, the first Intel optimizeddeep learning framework that supports efficient 8-bit low precision inferenceand model optimization techniques of convolutional neural networks on IntelXeon Scalable Processors. The 8-bit optimized model is automatically generatedwith a calibration process from FP32 model without the need of fine-tuning orretraining. We show that the inference throughput and latency with ResNet-50,Inception-v3 and SSD are improved by 1.38X-2.9X and 1.35X-3X respectively withneglectable accuracy loss from IntelCaffe FP32 baseline and by 56X-75X and26X-37X from BVLC Caffe. All these techniques have been open-sourced onIntelCaffe GitHub1, and the artifact is provided to reproduce the result onAmazon AWS Cloud. ### Response: SSD : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","The 2nd edition of the Montreal AI Ethics Institute's The State of AI Ethics captures the most relevant developments in the field of AI Ethics since July 2020. This report aims to help anyone, from machine learning experts to human rights activists and policymakers, quickly digest and understand the ever-changing developments in the field. Through research and article summaries, as well as expert commentary, this report distills the research and reporting surrounding various domains related to the ethics of AI, including: AI and society, bias and algorithmic justice, disinformation, humans and AI, labor impacts, privacy, risk, and future of AI ethics. In addition, The State of AI Ethics includes exclusive content written by world-class AI Ethics experts from universities, research institutes, consulting firms, and governments. These experts include: Danit Gal (Tech Advisor, United Nations), Amba Kak (Director of Global Policy and Programs, NYU's AI Now Institute), Rumman Chowdhury (Global Lead for Responsible AI, Accenture), Brent Barron (Director of Strategic Projects and Knowledge Management, CIFAR), Adam Murray (U.S. Diplomat working on tech policy, Chair of the OECD Network on AI), Thomas Kochan (Professor, MIT Sloan School of Management), and Katya Klinova (AI and Economy Program Lead, Partnership on AI). This report should be used not only as a point of reference and insight on the latest thinking in the field of AI Ethics, but should also be used as a tool for introspection as we aim to foster a more nuanced conversation regarding the impacts of AI on the world.",Adam : METHOD,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: The 2nd edition of the Montreal AI Ethics Institute's The State of AI Ethics captures the most relevant developments in the field of AI Ethics since July 2020. This report aims to help anyone, from machine learning experts to human rights activists and policymakers, quickly digest and understand the ever-changing developments in the field. Through research and article summaries, as well as expert commentary, this report distills the research and reporting surrounding various domains related to the ethics of AI, including: AI and society, bias and algorithmic justice, disinformation, humans and AI, labor impacts, privacy, risk, and future of AI ethics. In addition, The State of AI Ethics includes exclusive content written by world-class AI Ethics experts from universities, research institutes, consulting firms, and governments. These experts include: Danit Gal (Tech Advisor, United Nations), Amba Kak (Director of Global Policy and Programs, NYU's AI Now Institute), Rumman Chowdhury (Global Lead for Responsible AI, Accenture), Brent Barron (Director of Strategic Projects and Knowledge Management, CIFAR), Adam Murray (U.S. Diplomat working on tech policy, Chair of the OECD Network on AI), Thomas Kochan (Professor, MIT Sloan School of Management), and Katya Klinova (AI and Economy Program Lead, Partnership on AI). This report should be used not only as a point of reference and insight on the latest thinking in the field of AI Ethics, but should also be used as a tool for introspection as we aim to foster a more nuanced conversation regarding the impacts of AI on the world. ### Response: Adam : METHOD"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Manual acquisition of semantic constraints in broad domains is very expensive. This paper presents an automatic scheme for collecting statistics on cooccurrence patterns in a large corpus . To a large extent, these statistics reflect semantic constraints and thus are used to disambiguate anaphora references and syntactic ambiguities . The scheme was implemented by gathering statistics on the output of other linguistic tools. An experiment was performed to resolve references of the pronoun ""it"" in sentences that were randomly selected from the corpus . The results of the experiment show that in most of the cases the cooccurrence statistics indeed reflect the semantic constraints and thus provide a basis for a useful disambiguation tool .",Manual acquisition of semantic constraints : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Manual acquisition of semantic constraints in broad domains is very expensive. This paper presents an automatic scheme for collecting statistics on cooccurrence patterns in a large corpus . To a large extent, these statistics reflect semantic constraints and thus are used to disambiguate anaphora references and syntactic ambiguities . The scheme was implemented by gathering statistics on the output of other linguistic tools. An experiment was performed to resolve references of the pronoun ""it"" in sentences that were randomly selected from the corpus . The results of the experiment show that in most of the cases the cooccurrence statistics indeed reflect the semantic constraints and thus provide a basis for a useful disambiguation tool . ### Response: Manual acquisition of semantic constraints : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","The compact description of a video sequence through a single image map and a dominant motion has applications in several domains, including video browsing and retrieval , compression , mosaicing , and visual summarization . Building such a representation requires the capability to register all the frames with respect to the dominant object in the scene, a task which has been, in the past, addressed through temporally localized motion estimates. In this paper, we show how the lack of temporal consistency associated with such estimates can undermine the validity of the dominant motion assumption, leading to oscillation between different scene interpretations and poor registration. To avoid this oscillation, we augment the motion model with a generic temporal constraint which increases the robustness against competing interpretations, leading to more meaningful content summarization .",compact description of a video sequence : RESEARCH_PROBLEM; video browsing and retrieval : RESEARCH_PROBLEM; compression : RESEARCH_PROBLEM; mosaicing : RESEARCH_PROBLEM; visual summarization : RESEARCH_PROBLEM; content summarization : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: The compact description of a video sequence through a single image map and a dominant motion has applications in several domains, including video browsing and retrieval , compression , mosaicing , and visual summarization . Building such a representation requires the capability to register all the frames with respect to the dominant object in the scene, a task which has been, in the past, addressed through temporally localized motion estimates. In this paper, we show how the lack of temporal consistency associated with such estimates can undermine the validity of the dominant motion assumption, leading to oscillation between different scene interpretations and poor registration. To avoid this oscillation, we augment the motion model with a generic temporal constraint which increases the robustness against competing interpretations, leading to more meaningful content summarization . ### Response: compact description of a video sequence : RESEARCH_PROBLEM; video browsing and retrieval : RESEARCH_PROBLEM; compression : RESEARCH_PROBLEM; mosaicing : RESEARCH_PROBLEM; visual summarization : RESEARCH_PROBLEM; content summarization : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","This work presents a real-time system for multiple object tracking in dynamic scenes . A unique characteristic of the system is its ability to cope with long-duration and complete occlusion without a prior knowledge about the shape or motion of objects. The system produces good segment and tracking results at a frame rate of 15-20 fps for image size of 320x240, as demonstrated by extensive experiments performed using video sequences under different conditions indoor and outdoor with long-duration and complete occlusions in changing background.",multiple object tracking in dynamic scenes : RESEARCH_PROBLEM; tracking : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: This work presents a real-time system for multiple object tracking in dynamic scenes . A unique characteristic of the system is its ability to cope with long-duration and complete occlusion without a prior knowledge about the shape or motion of objects. The system produces good segment and tracking results at a frame rate of 15-20 fps for image size of 320x240, as demonstrated by extensive experiments performed using video sequences under different conditions indoor and outdoor with long-duration and complete occlusions in changing background. ### Response: multiple object tracking in dynamic scenes : RESEARCH_PROBLEM; tracking : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","A recognition scheme that scales efficiently to a large number of objects is presented. The efficiency and quality is exhibited in a live demonstration that recognizes CD-covers from a database of 40000 images of popular music CD's. The scheme builds upon popular techniques of indexing descriptors extracted from local regions, and is robust to background clutter and occlusion. The local region descriptors are hierarchically quantized in a vocabulary tree. The vocabulary tree allows a larger and more discriminatory vocabulary to be used efficiently, which we show experimentally leads to a dramatic improvement in retrieval quality. The most significant property of the scheme is that the tree directly defines the quantization. The quantization and the indexing are therefore fully integrated, essentially being one and the same. The recognition quality is evaluated through retrieval on a database with ground truth, showing the power of the vocabulary tree approach, going as high as 1 million images.",retrieval : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: A recognition scheme that scales efficiently to a large number of objects is presented. The efficiency and quality is exhibited in a live demonstration that recognizes CD-covers from a database of 40000 images of popular music CD's. The scheme builds upon popular techniques of indexing descriptors extracted from local regions, and is robust to background clutter and occlusion. The local region descriptors are hierarchically quantized in a vocabulary tree. The vocabulary tree allows a larger and more discriminatory vocabulary to be used efficiently, which we show experimentally leads to a dramatic improvement in retrieval quality. The most significant property of the scheme is that the tree directly defines the quantization. The quantization and the indexing are therefore fully integrated, essentially being one and the same. The recognition quality is evaluated through retrieval on a database with ground truth, showing the power of the vocabulary tree approach, going as high as 1 million images. ### Response: retrieval : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","We present a new approach for building an efficient and robust classifier for the two class problem , that localizes objects that may appear in the image under different orien-tations. In contrast to other works that address this problem using multiple classifiers, each one specialized for a specific orientation, we propose a simple two-step approach with an estimation stage and a classification stage. The estimator yields an initial set of potential object poses that are then validated by the classifier. This methodology allows reducing the time complexity of the algorithm while classification results remain high. The classifier we use in both stages is based on a boosted combination of Random Ferns over local histograms of oriented gradients (HOGs), which we compute during a pre-processing step. Both the use of supervised learning and working on the gradient space makes our approach robust while being efficient at run-time. We show these properties by thorough testing on standard databases and on a new database made of motorbikes under planar rotations, and with challenging conditions such as cluttered backgrounds, changing illumination conditions and partial occlusions.",class problem : RESEARCH_PROBLEM; classification : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: We present a new approach for building an efficient and robust classifier for the two class problem , that localizes objects that may appear in the image under different orien-tations. In contrast to other works that address this problem using multiple classifiers, each one specialized for a specific orientation, we propose a simple two-step approach with an estimation stage and a classification stage. The estimator yields an initial set of potential object poses that are then validated by the classifier. This methodology allows reducing the time complexity of the algorithm while classification results remain high. The classifier we use in both stages is based on a boosted combination of Random Ferns over local histograms of oriented gradients (HOGs), which we compute during a pre-processing step. Both the use of supervised learning and working on the gradient space makes our approach robust while being efficient at run-time. We show these properties by thorough testing on standard databases and on a new database made of motorbikes under planar rotations, and with challenging conditions such as cluttered backgrounds, changing illumination conditions and partial occlusions. ### Response: class problem : RESEARCH_PROBLEM; classification : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","We describe an implementation of data-driven selection of emphatic facial displays for an embodied conversational agent in a dialogue system . A corpus of sentences in the domain of the target dialogue system was recorded, and the facial displays used by the speaker were annotated. The data from those recordings was used in a range of models for generating facial displays, each model making use of a different amount of context or choosing displays differently within a context . The models were evaluated in two ways: by cross-validation against the corpus , and by asking users to rate the output. The predictions of the cross-validation study differed from the actual user ratings. While the cross-validation gave the highest scores to models making a majority choice within a context, the user study showed a significant preference for models that produced more variation. This preference was especially strong among the female subjects.",data-driven selection : RESEARCH_PROBLEM; embodied conversational agent : RESEARCH_PROBLEM; dialogue system : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: We describe an implementation of data-driven selection of emphatic facial displays for an embodied conversational agent in a dialogue system . A corpus of sentences in the domain of the target dialogue system was recorded, and the facial displays used by the speaker were annotated. The data from those recordings was used in a range of models for generating facial displays, each model making use of a different amount of context or choosing displays differently within a context . The models were evaluated in two ways: by cross-validation against the corpus , and by asking users to rate the output. The predictions of the cross-validation study differed from the actual user ratings. While the cross-validation gave the highest scores to models making a majority choice within a context, the user study showed a significant preference for models that produced more variation. This preference was especially strong among the female subjects. ### Response: data-driven selection : RESEARCH_PROBLEM; embodied conversational agent : RESEARCH_PROBLEM; dialogue system : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","In this paper we compare two competing approaches to part-of-speech tagging , statistical and constraint-based disambiguation , using French as our test language . We imposed a time limit on our experiment: the amount of time spent on the design of our constraint system was about the same as the time we used to train and test the easy-to-implement statistical model . We describe the two systems and compare the results. The accuracy of the statistical method is reasonably good, comparable to taggers for English . But the constraint-based tagger seems to be superior even with the limited time we allowed ourselves for rule development .",part-of-speech tagging : RESEARCH_PROBLEM; statistical and constraint-based disambiguation : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: In this paper we compare two competing approaches to part-of-speech tagging , statistical and constraint-based disambiguation , using French as our test language . We imposed a time limit on our experiment: the amount of time spent on the design of our constraint system was about the same as the time we used to train and test the easy-to-implement statistical model . We describe the two systems and compare the results. The accuracy of the statistical method is reasonably good, comparable to taggers for English . But the constraint-based tagger seems to be superior even with the limited time we allowed ourselves for rule development . ### Response: part-of-speech tagging : RESEARCH_PROBLEM; statistical and constraint-based disambiguation : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET",Our goal is to learn a Mahalanobis distance by minimizing a loss defined on the weighted sum of the precision at different ranks. Our core motivation is that minimizing a weighted rank loss is a natural criterion for many problems in computer vision such as person re-identification . We propose a novel metric learning formulation called Weighted Approximate Rank Component Analysis (WARCA). We then derive a scalable stochastic gradient descent algorithm for the resulting learning problem. We also derive an efficient non-linear extension of WARCA by using the kernel trick. Kernel space embedding decouples the training and prediction costs from the data dimension and enables us to plug inarbitrary distance measures which are more natural for the features. We also address a more general problem of matrix rank degeneration & non-isolated minima in the low-rank matrix optimization by using new type of regularizer which approximately enforces the or-thonormality of the learned matrix very efficiently. We validate this new method on nine standard person re-identification datasets including two large scale Market-1501 and CUHK03 datasets and show that we improve upon the current state-of-the-art methods on all of them.,Mahalanobis distance : RESEARCH_PROBLEM; computer vision : RESEARCH_PROBLEM; person re-identification : RESEARCH_PROBLEM; low-rank matrix optimization : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Our goal is to learn a Mahalanobis distance by minimizing a loss defined on the weighted sum of the precision at different ranks. Our core motivation is that minimizing a weighted rank loss is a natural criterion for many problems in computer vision such as person re-identification . We propose a novel metric learning formulation called Weighted Approximate Rank Component Analysis (WARCA). We then derive a scalable stochastic gradient descent algorithm for the resulting learning problem. We also derive an efficient non-linear extension of WARCA by using the kernel trick. Kernel space embedding decouples the training and prediction costs from the data dimension and enables us to plug inarbitrary distance measures which are more natural for the features. We also address a more general problem of matrix rank degeneration & non-isolated minima in the low-rank matrix optimization by using new type of regularizer which approximately enforces the or-thonormality of the learned matrix very efficiently. We validate this new method on nine standard person re-identification datasets including two large scale Market-1501 and CUHK03 datasets and show that we improve upon the current state-of-the-art methods on all of them. ### Response: Mahalanobis distance : RESEARCH_PROBLEM; computer vision : RESEARCH_PROBLEM; person re-identification : RESEARCH_PROBLEM; low-rank matrix optimization : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","In this paper, we use the information redundancy in multilingual input to correct errors in machine translation and thus improve the quality of multilingual summaries . We consider the case of multi-document summarization , where the input documents are in Arabic , and the output summary is in English . Typically, information that makes it to a summary appears in many different lexical-syntactic forms in the input documents . Further, the use of multiple machine translation systems provides yet more redundancy , yielding different ways to realize that information in English . We demonstrate how errors in the machine translations of the input Arabic documents can be corrected by identifying and generating from such redundancy , focusing on noun phrases .",machine translation : RESEARCH_PROBLEM; multilingual summaries : RESEARCH_PROBLEM; multi-document summarization : RESEARCH_PROBLEM; machine translations : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: In this paper, we use the information redundancy in multilingual input to correct errors in machine translation and thus improve the quality of multilingual summaries . We consider the case of multi-document summarization , where the input documents are in Arabic , and the output summary is in English . Typically, information that makes it to a summary appears in many different lexical-syntactic forms in the input documents . Further, the use of multiple machine translation systems provides yet more redundancy , yielding different ways to realize that information in English . We demonstrate how errors in the machine translations of the input Arabic documents can be corrected by identifying and generating from such redundancy , focusing on noun phrases . ### Response: machine translation : RESEARCH_PROBLEM; multilingual summaries : RESEARCH_PROBLEM; multi-document summarization : RESEARCH_PROBLEM; machine translations : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","This paper presents a word segmentation system in France Telecom R&D Beijing, which uses a unified approach to word breaking and OOV identification . The output can be customized to meet different segmentation standards through the application of an ordered list of transformation. The system participated in all the tracks of the segmentation bakeoff -- PK-open , PK-closed , AS-open , AS-closed , HK-open , HK-closed , MSR-open and MSR- closed -- and achieved the state-of-the-art performance in MSR-open , MSR-close and PK-open tracks. Analysis of the results shows that each component of the system contributed to the scores .",word breaking : RESEARCH_PROBLEM; OOV identification : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: This paper presents a word segmentation system in France Telecom R&D Beijing, which uses a unified approach to word breaking and OOV identification . The output can be customized to meet different segmentation standards through the application of an ordered list of transformation. The system participated in all the tracks of the segmentation bakeoff -- PK-open , PK-closed , AS-open , AS-closed , HK-open , HK-closed , MSR-open and MSR- closed -- and achieved the state-of-the-art performance in MSR-open , MSR-close and PK-open tracks. Analysis of the results shows that each component of the system contributed to the scores . ### Response: word breaking : RESEARCH_PROBLEM; OOV identification : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","In this paper, we propose a novel algorithm to detect/compensate on-line interference effects when integrating Global Navigation Satellite System (GNSS) and Inertial Navigation System (INS) . The GNSS/INS coupling is usually performed by an Extended Kalman Filter (EKF) which yields an accurate and robust localization . However , interference cause the GNSS measurement noise to increase unexpectedly, hence degrade the positioning accuracy. In this context , our contribution is twofold. We first study the impact of the GNSS noise inflation on the covariance of the EKF outputs so as to compute a least square estimate of the potential variance jumps. Then, this estimation is used in a Bayesian test which decides whether interference are corrupting the GNSS signal or not. It allows us to estimate their times of occurrence as well. In this way, the impaired measurements can be discarded while their impact on the navigation solution can be compensated. The results show the performance of the proposed approach on simulated data.",on-line interference effects : RESEARCH_PROBLEM; Global Navigation Satellite System (GNSS) : RESEARCH_PROBLEM; Inertial Navigation System (INS) : RESEARCH_PROBLEM; GNSS/INS coupling : RESEARCH_PROBLEM; accurate and robust localization : RESEARCH_PROBLEM; navigation solution : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: In this paper, we propose a novel algorithm to detect/compensate on-line interference effects when integrating Global Navigation Satellite System (GNSS) and Inertial Navigation System (INS) . The GNSS/INS coupling is usually performed by an Extended Kalman Filter (EKF) which yields an accurate and robust localization . However , interference cause the GNSS measurement noise to increase unexpectedly, hence degrade the positioning accuracy. In this context , our contribution is twofold. We first study the impact of the GNSS noise inflation on the covariance of the EKF outputs so as to compute a least square estimate of the potential variance jumps. Then, this estimation is used in a Bayesian test which decides whether interference are corrupting the GNSS signal or not. It allows us to estimate their times of occurrence as well. In this way, the impaired measurements can be discarded while their impact on the navigation solution can be compensated. The results show the performance of the proposed approach on simulated data. ### Response: on-line interference effects : RESEARCH_PROBLEM; Global Navigation Satellite System (GNSS) : RESEARCH_PROBLEM; Inertial Navigation System (INS) : RESEARCH_PROBLEM; GNSS/INS coupling : RESEARCH_PROBLEM; accurate and robust localization : RESEARCH_PROBLEM; navigation solution : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","We present a single-image highlight removal method that incorporates illumination-based constraints into image in-painting . Unlike occluded image regions filled by traditional inpainting , highlight pixels contain some useful information for guiding the inpainting process . Constraints provided by observed pixel colors, highlight color analysis and illumination color uniformity are employed in our method to improve estimation of the underlying diffuse color. The inclusion of these illumination constraints allows for better recovery of shading and textures by inpainting. Experimental results are given to demonstrate the performance of our method.",image in-painting : RESEARCH_PROBLEM; inpainting : RESEARCH_PROBLEM; inpainting process : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: We present a single-image highlight removal method that incorporates illumination-based constraints into image in-painting . Unlike occluded image regions filled by traditional inpainting , highlight pixels contain some useful information for guiding the inpainting process . Constraints provided by observed pixel colors, highlight color analysis and illumination color uniformity are employed in our method to improve estimation of the underlying diffuse color. The inclusion of these illumination constraints allows for better recovery of shading and textures by inpainting. Experimental results are given to demonstrate the performance of our method. ### Response: image in-painting : RESEARCH_PROBLEM; inpainting : RESEARCH_PROBLEM; inpainting process : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","This paper presents an approach to localizing functional objects in surveillance videos without domain knowledge about semantic object classes that may appear in the scene. Functional objects do not have discriminative appearance and shape, but they affect behavior of people in the scene. For example, they "" attract "" people to approach them for satisfying certain needs (e.g., vending machines could quench thirst), or "" repel "" people to avoid them (e.g., grass lawns). Therefore, functional objects can be viewed as "" dark matter "" , emanating "" dark energy "" that affects people's trajectories in the video. To detect "" dark matter "" and infer their "" dark energy "" field, we extend the La-grangian mechanics. People are treated as particle-agents with latent intents to approach "" dark matter "" and thus satisfy their needs, where their motions are subject to a composite "" dark energy "" field of all functional objects in the scene. We make the assumption that people take globally optimal paths toward the intended "" dark matter "" while avoiding latent obstacles. A Bayesian framework is used to probabilistically model: people's trajectories and intents, constraint map of the scene, and locations of functional objects. A data-driven Markov Chain Monte Carlo (MCMC) process is used for inference . Our evaluation on videos of public squares and courtyards demonstrates our effectiveness in localizing functional objects and predicting people's trajectories in unobserved parts of the video footage.",localizing functional objects : RESEARCH_PROBLEM; inference : RESEARCH_PROBLEM; localizing functional objects : RESEARCH_PROBLEM; predicting people's trajectories : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: This paper presents an approach to localizing functional objects in surveillance videos without domain knowledge about semantic object classes that may appear in the scene. Functional objects do not have discriminative appearance and shape, but they affect behavior of people in the scene. For example, they "" attract "" people to approach them for satisfying certain needs (e.g., vending machines could quench thirst), or "" repel "" people to avoid them (e.g., grass lawns). Therefore, functional objects can be viewed as "" dark matter "" , emanating "" dark energy "" that affects people's trajectories in the video. To detect "" dark matter "" and infer their "" dark energy "" field, we extend the La-grangian mechanics. People are treated as particle-agents with latent intents to approach "" dark matter "" and thus satisfy their needs, where their motions are subject to a composite "" dark energy "" field of all functional objects in the scene. We make the assumption that people take globally optimal paths toward the intended "" dark matter "" while avoiding latent obstacles. A Bayesian framework is used to probabilistically model: people's trajectories and intents, constraint map of the scene, and locations of functional objects. A data-driven Markov Chain Monte Carlo (MCMC) process is used for inference . Our evaluation on videos of public squares and courtyards demonstrates our effectiveness in localizing functional objects and predicting people's trajectories in unobserved parts of the video footage. ### Response: localizing functional objects : RESEARCH_PROBLEM; inference : RESEARCH_PROBLEM; localizing functional objects : RESEARCH_PROBLEM; predicting people's trajectories : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Is it possible to use out-of-domain acoustic training data to improve a speech recognizer's performance on a speciic, independent application? In our experiments, we use Wallstreet Journal (WSJ) data to train a recognizer, which is adapted and evaluated in the Phonebook domain. Apart from their common language (US English), the two corpora diier in many important respects: microphone vs. telephone channel, continuous speech vs. isolated words, mismatch i n s p e a k i n g r a t e. This paper deals with two questions. First, starting from the WSJ-trained recognizer, how much adaptation data (taken from the Phonebook training corpus) is necessary to achieve a reasonable recognition performance in spite of the high degree of mismatch? Second, is it possible to improve the recognition performance of a Phonebook-trained baseline acoustic model by using additional out-of-domain training data? The paper describes the adaptation and normalization techniques used to bridge the mismatch b e-tween the two corpora.",recognition : RESEARCH_PROBLEM; recognition : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Is it possible to use out-of-domain acoustic training data to improve a speech recognizer's performance on a speciic, independent application? In our experiments, we use Wallstreet Journal (WSJ) data to train a recognizer, which is adapted and evaluated in the Phonebook domain. Apart from their common language (US English), the two corpora diier in many important respects: microphone vs. telephone channel, continuous speech vs. isolated words, mismatch i n s p e a k i n g r a t e. This paper deals with two questions. First, starting from the WSJ-trained recognizer, how much adaptation data (taken from the Phonebook training corpus) is necessary to achieve a reasonable recognition performance in spite of the high degree of mismatch? Second, is it possible to improve the recognition performance of a Phonebook-trained baseline acoustic model by using additional out-of-domain training data? The paper describes the adaptation and normalization techniques used to bridge the mismatch b e-tween the two corpora. ### Response: recognition : RESEARCH_PROBLEM; recognition : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","This paper develops a new approach for extremely fast detection in domains where the distribution of positive and negative examples is highly skewed (e.g. face detection or database retrieval ). In such domains a cascade of simple classifiers each trained to achieve high detection rates and modest false positive rates can yield a final detector with many desirable features: including high detection rates, very low false positive rates, and fast performance. Achieving extremely high detection rates, rather than low error, is not a task typically addressed by machine learning algorithms. We propose a new variant of AdaBoost as a mechanism for training the simple classifiers used in the cascade. Experimental results in the domain of face detection show the training algorithm yields significant improvements in performance over conventional AdaBoost. The final face detection system can process 15 frames per second, achieves over 90% detection, and a false positive rate of 1 in a 1,000,000.",fast detection : RESEARCH_PROBLEM; face detection : RESEARCH_PROBLEM; database retrieval : RESEARCH_PROBLEM; face detection : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: This paper develops a new approach for extremely fast detection in domains where the distribution of positive and negative examples is highly skewed (e.g. face detection or database retrieval ). In such domains a cascade of simple classifiers each trained to achieve high detection rates and modest false positive rates can yield a final detector with many desirable features: including high detection rates, very low false positive rates, and fast performance. Achieving extremely high detection rates, rather than low error, is not a task typically addressed by machine learning algorithms. We propose a new variant of AdaBoost as a mechanism for training the simple classifiers used in the cascade. Experimental results in the domain of face detection show the training algorithm yields significant improvements in performance over conventional AdaBoost. The final face detection system can process 15 frames per second, achieves over 90% detection, and a false positive rate of 1 in a 1,000,000. ### Response: fast detection : RESEARCH_PROBLEM; face detection : RESEARCH_PROBLEM; database retrieval : RESEARCH_PROBLEM; face detection : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","Previous research has demonstrated the utility of clustering in inducing semantic verb classes from undisambiguated corpus data . We describe a new approach which involves clustering subcategorization frame (SCF) distributions using the Information Bottleneck and nearest neighbour methods. In contrast to previous work, we particularly focus on clustering polysemic verbs . A novel evaluation scheme is proposed which accounts for the effect of polysemy on the clusters , offering us a good insight into the potential and limitations of semantically classifying undisambiguated SCF data .",inducing semantic verb classes : RESEARCH_PROBLEM; clustering subcategorization frame (SCF) distributions : RESEARCH_PROBLEM; clustering polysemic verbs : RESEARCH_PROBLEM; semantically classifying undisambiguated SCF data : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Previous research has demonstrated the utility of clustering in inducing semantic verb classes from undisambiguated corpus data . We describe a new approach which involves clustering subcategorization frame (SCF) distributions using the Information Bottleneck and nearest neighbour methods. In contrast to previous work, we particularly focus on clustering polysemic verbs . A novel evaluation scheme is proposed which accounts for the effect of polysemy on the clusters , offering us a good insight into the potential and limitations of semantically classifying undisambiguated SCF data . ### Response: inducing semantic verb classes : RESEARCH_PROBLEM; clustering subcategorization frame (SCF) distributions : RESEARCH_PROBLEM; clustering polysemic verbs : RESEARCH_PROBLEM; semantically classifying undisambiguated SCF data : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","This paper concerns the discourse understanding process in spoken dialogue systems . This process enables the system to understand user utterances based on the context of a dialogue . Since multiple candidates for the understanding result can be obtained for a user utterance due to the ambiguity of speech understanding , it is not appropriate to decide on a single understanding result after each user utterance . By holding multiple candidates for understanding results and resolving the ambiguity as the dialogue progresses, the discourse understanding accuracy can be improved. This paper proposes a method for resolving this ambiguity based on statistical information obtained from dialogue corpora . Unlike conventional methods that use hand-crafted rules , the proposed method enables easy design of the discourse understanding process . Experiment results have shown that a system that exploits the proposed method performs sufficiently and that holding multiple candidates for understanding results is effective.",discourse understanding process : RESEARCH_PROBLEM; discourse understanding process : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: This paper concerns the discourse understanding process in spoken dialogue systems . This process enables the system to understand user utterances based on the context of a dialogue . Since multiple candidates for the understanding result can be obtained for a user utterance due to the ambiguity of speech understanding , it is not appropriate to decide on a single understanding result after each user utterance . By holding multiple candidates for understanding results and resolving the ambiguity as the dialogue progresses, the discourse understanding accuracy can be improved. This paper proposes a method for resolving this ambiguity based on statistical information obtained from dialogue corpora . Unlike conventional methods that use hand-crafted rules , the proposed method enables easy design of the discourse understanding process . Experiment results have shown that a system that exploits the proposed method performs sufficiently and that holding multiple candidates for understanding results is effective. ### Response: discourse understanding process : RESEARCH_PROBLEM; discourse understanding process : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET",In this paper we describe a novel data structure for phrase-based statistical machine translation which allows for the retrieval of arbitrarily long phrases while simultaneously using less memory than is required by current decoder implementations. We detail the computational complexity and average retrieval times for looking up phrase translations in our suffix array-based data structure . We show how sampling can be used to reduce the retrieval time by orders of magnitude with no loss in translation quality .,phrase-based statistical machine translation : RESEARCH_PROBLEM; retrieval of arbitrarily long phrases : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: In this paper we describe a novel data structure for phrase-based statistical machine translation which allows for the retrieval of arbitrarily long phrases while simultaneously using less memory than is required by current decoder implementations. We detail the computational complexity and average retrieval times for looking up phrase translations in our suffix array-based data structure . We show how sampling can be used to reduce the retrieval time by orders of magnitude with no loss in translation quality . ### Response: phrase-based statistical machine translation : RESEARCH_PROBLEM; retrieval of arbitrarily long phrases : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET",Topical blog post retrieval is the task of ranking blog posts with respect to their relevance for a given topic . To improve topical blog post retrieval we incorporate textual credibility indicators in the retrieval process . We consider two groups of indicators : post level (determined using information about individual blog posts only) and blog level (determined using information from the underlying blogs ). We describe how to estimate these indicators and how to integrate them into a retrieval approach based on language models . Experiments on the TREC Blog track test set show that both groups of credibility indicators significantly improve retrieval effectiveness ; the best performance is achieved when combining them.,Topical blog post retrieval : RESEARCH_PROBLEM; ranking blog posts : RESEARCH_PROBLEM; topical blog post retrieval : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: Topical blog post retrieval is the task of ranking blog posts with respect to their relevance for a given topic . To improve topical blog post retrieval we incorporate textual credibility indicators in the retrieval process . We consider two groups of indicators : post level (determined using information about individual blog posts only) and blog level (determined using information from the underlying blogs ). We describe how to estimate these indicators and how to integrate them into a retrieval approach based on language models . Experiments on the TREC Blog track test set show that both groups of credibility indicators significantly improve retrieval effectiveness ; the best performance is achieved when combining them. ### Response: Topical blog post retrieval : RESEARCH_PROBLEM; ranking blog posts : RESEARCH_PROBLEM; topical blog post retrieval : RESEARCH_PROBLEM"
"In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET","The TIPSTER Architecture has been designed to enable a variety of different text applications to use a set of common text processing modules . Since user interfaces work best when customized for particular applications , it is appropriator that no particular user interface styles or conventions are described in the TIPSTER Architecture specification . However, the Computing Research Laboratory (CRL) has constructed several TIPSTER applications that use a common set of configurable Graphical User Interface (GUI) functions . These GUIs were constructed using CRL's TIPSTER User Interface Toolkit (TUIT) . TUIT is a software library that can be used to construct multilingual TIPSTER user interfaces for a set of common user tasks. CRL developed TUIT to support their work to integrate TIPSTER modules for the 6 and 12 month TIPSTER II demonstrations as well as their Oleada and Temple demonstration projects. This paper briefly describes TUIT and its capabilities.",text applications : RESEARCH_PROBLEM; TIPSTER applications : RESEARCH_PROBLEM,"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: In the given sentence, find the entities of possible types - SOLUTION, RESEARCH_PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET ### Input: The TIPSTER Architecture has been designed to enable a variety of different text applications to use a set of common text processing modules . Since user interfaces work best when customized for particular applications , it is appropriator that no particular user interface styles or conventions are described in the TIPSTER Architecture specification . However, the Computing Research Laboratory (CRL) has constructed several TIPSTER applications that use a common set of configurable Graphical User Interface (GUI) functions . These GUIs were constructed using CRL's TIPSTER User Interface Toolkit (TUIT) . TUIT is a software library that can be used to construct multilingual TIPSTER user interfaces for a set of common user tasks. CRL developed TUIT to support their work to integrate TIPSTER modules for the 6 and 12 month TIPSTER II demonstrations as well as their Oleada and Temple demonstration projects. This paper briefly describes TUIT and its capabilities. ### Response: text applications : RESEARCH_PROBLEM; TIPSTER applications : RESEARCH_PROBLEM"
