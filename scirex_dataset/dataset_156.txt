document O
: O
Learning O
a O
Discriminative Method
Null Method
Space Method
for O
Person Task
Re Task
- Task
identification Task
Most O
existing O
person Task
re Task
- Task
identification Task
( O
re Task
- Task
i Task
d Task
) O
methods O
focus O
on O
learning O
the O
optimal Metric
distance Metric
metrics Metric
across O
camera O
views O
. O
Typically O
a O
person O
’s O
appearance O
is O
represented O
using O
features O
of O
thousands O
of O
dimensions O
, O
whilst O
only O
hundreds O
of O
training O
samples O
are O
available O
due O
to O
the O
difficulties O
in O
collecting O
matched O
training O
images O
. O
With O
the O
number O
of O
training O
samples O
much O
smaller O
than O
the O
feature O
dimension O
, O
the O
existing O
methods O
thus O
face O
the O
classic O
small Task
sample Task
size Task
( O
SSS Task
) Task
problem Task
and O
have O
to O
resort O
to O
dimensionality Method
reduction Method
techniques O
and O
/ O
or O
matrix Method
regularisation Method
, O
which O
lead O
to O
loss O
of O
discriminative O
power O
. O
In O
this O
work O
, O
we O
propose O
to O
overcome O
the O
SSS Task
problem Task
in O
re Task
- Task
i Task
d Task
distance O
metric O
learning O
by O
matching O
people O
in O
a O
discriminative O
null O
space O
of O
the O
training O
data O
. O
In O
this O
null O
space O
, O
images O
of O
the O
same O
person O
are O
collapsed O
into O
a O
single O
point O
thus O
minimising O
the O
within O
- O
class O
scatter O
to O
the O
extreme O
and O
maximising O
the O
relative O
between O
- O
class O
separation O
simultaneously O
. O
Importantly O
, O
it O
has O
a O
fixed O
dimension O
, O
a O
closed Method
- Method
form Method
solution Method
and O
is O
very O
efficient O
to O
compute O
. O
Extensive O
experiments O
carried O
out O
on O
five O
person Task
re Task
- Task
identification Task
benchmarks O
including O
VIPeR Material
, O
PRID2011 Material
, O
CUHK01 Material
, O
CUHK03 Material
and O
Market1501 Material
show O
that O
such O
a O
simple O
approach O
beats O
the O
state O
- O
of O
- O
the O
- O
art O
alternatives O
, O
often O
by O
a O
big O
margin O
. O
section O
: O
Introduction O
The O
problem O
of O
person Task
re Task
- Task
identification Task
( O
re Task
- Task
i Task
d Task
) O
has O
attracted O
great O
attention O
in O
the O
past O
five O
years O
. O
When O
a O
person O
is O
captured O
by O
multiple O
non O
- O
overlapping O
views O
, O
the O
objective O
is O
to O
match O
him O
/ O
her O
across O
views O
among O
a O
large O
number O
of O
imposters O
. O
Despite O
the O
best O
efforts O
from O
the O
computer Task
vision Task
researchers Task
, O
re Task
- Task
i Task
d Task
remains O
a O
largely O
unsolved O
problem O
. O
This O
is O
because O
that O
a O
person O
’s O
appearance O
often O
undergoes O
dramatic O
changes O
across O
camera O
views O
due O
to O
changes O
in O
view O
angle O
, O
body O
pose O
, O
illumination O
and O
background O
clutter O
. O
Furthermore O
, O
since O
people O
are O
mainly O
distinguishable O
by O
their O
clothing O
under O
a O
surveillance O
setting O
, O
many O
passers O
- O
by O
can O
be O
easily O
confused O
with O
the O
target O
person O
because O
they O
wear O
similar O
clothes O
. O
Existing O
approaches O
focus O
on O
developing O
discriminative Method
feature Method
representations Method
that O
are O
robust O
against O
the O
view O
/ O
pose O
/ O
illumination O
/ O
background O
changes O
, O
or O
learning O
a O
distance O
metric O
, O
or O
both O
jointly O
. O
Among O
them O
, O
the O
distance Method
metric Method
learning Method
methods Method
are O
most O
popular O
and O
are O
the O
focus O
of O
this O
paper O
. O
Given O
any O
feature Method
representation Method
and O
a O
set O
of O
training O
data O
consisting O
of O
matching O
image O
pairs O
across O
camera O
views O
, O
the O
objective O
is O
to O
learn O
the O
optimal Metric
distance Metric
metric Metric
that O
gives O
small O
values O
to O
images O
of O
the O
same O
person O
and O
large O
values O
for O
those O
of O
different O
people O
. O
Distance Method
metric Method
learning Method
has O
been O
extensively O
studied O
in O
machine Task
learning Task
, O
and O
existing O
metric Method
learning Method
methods Method
employed O
for O
re Task
- Task
i Task
d Task
are O
either O
originated O
elsewhere O
or O
extensions O
of O
existing O
methods O
with O
modifications O
to O
address O
the O
additional O
challenges O
arising O
from O
the O
re Task
- Task
i Task
d Task
task Task
. O
Although O
they O
have O
been O
shown O
to O
be O
effective O
in O
improving O
the O
existing O
re Task
- Task
i Task
d Task
benchmarks O
over O
the O
past O
five O
years O
, O
all O
these O
models O
are O
still O
limited O
by O
some O
of O
classical O
problems O
in O
model Task
learning Task
. O
Specifically O
, O
a O
key O
challenge O
for O
distance Task
metric Task
learning Task
when O
applied O
to O
person Task
re Task
- Task
i Task
d Task
is O
the O
small Task
sample Task
size Task
( O
SSS Task
) Task
problem Task
. O
Specifically O
, O
to O
capture O
rich O
person O
appearance O
whilst O
being O
robust O
against O
those O
condition O
changes O
mentioned O
above O
, O
the O
feature Method
representations Method
used O
by O
most O
recent O
re Task
- Task
i Task
d Task
works O
are O
of O
high O
dimension O
– O
typically O
in O
the O
order O
of O
thousands O
or O
tens O
of O
thousands O
. O
In O
contrast O
, O
the O
number O
of O
training O
samples O
is O
typically O
small O
, O
normally O
in O
hundreds O
. O
This O
is O
because O
that O
collecting O
training O
samples O
of O
matched O
person O
pairs O
across O
views O
is O
labour O
intensive O
and O
tedious O
. O
As O
a O
result O
the O
sample O
size O
is O
much O
smaller O
( O
often O
in O
an O
order O
of O
magnitude O
) O
than O
the O
feature O
dimension O
, O
a O
problem O
known O
as O
the O
SSS Task
problem Task
. O
Metric Method
learning Method
methods Method
suffer O
from O
the O
SSS Task
problem Task
because O
they O
essentially O
aim O
to O
minimise O
the O
within O
- O
class O
( O
intra O
- O
person O
) O
variance O
( O
distance Metric
) O
, O
whilst O
maximising O
the O
inter O
- O
class O
( O
inter Metric
- Metric
person Metric
) Metric
variance Metric
( O
distance Metric
) O
. O
With O
a O
small O
sample O
size O
, O
the O
within O
- O
class O
scatter O
matrix O
becomes O
singular O
; O
to O
avoid O
it O
, O
unsupervised O
dimensionality Method
reduction Method
or O
regularisation Method
are O
required O
. O
This O
in O
turn O
makes O
the O
learned O
distance Metric
metric Metric
sub O
- O
optimal O
and O
less O
discriminative O
. O
In O
this O
paper O
, O
we O
argue O
that O
the O
SSS Task
problem Task
in O
person O
re Task
- Task
i Task
d Task
distance O
metric O
learning O
can O
be O
best O
solved O
by O
learning O
a O
discriminative O
null O
space O
of O
the O
training O
data O
. O
In O
particular O
, O
instead O
of O
minimising O
the O
within O
- O
class O
variance O
, O
data O
points O
of O
the O
same O
classes O
are O
collapsed O
, O
by O
a O
transform O
, O
into O
a O
single O
point O
in O
a O
new O
space O
( O
see O
Fig O
. O
[ O
reference O
] O
) O
. O
By O
keeping O
the O
between O
- O
class O
variance O
non O
- O
zero O
, O
this O
automatically O
maximises O
the O
Fisher Metric
discriminative Metric
criterion Metric
and O
results O
in O
a O
discriminative O
subspace O
. O
The O
null Method
space Method
method Method
, O
also O
known O
as O
the O
null Method
Foley Method
- Method
Sammon Method
transfer Method
( O
NFST Method
) O
is O
specifically O
designed O
for O
the O
small Task
sample Task
case Task
, O
with O
rigorous O
theoretical O
proof O
on O
the O
resulting O
subspace Metric
dimension Metric
. O
Importantly O
, O
it O
has O
a O
closed O
- O
form O
solution O
, O
no O
parameter O
to O
tune O
, O
requires O
no O
pre O
- O
precessing O
steps O
to O
reduce O
the O
feature O
dimension O
, O
and O
can O
be O
computed O
efficiently O
. O
Furthermore O
, O
to O
deal O
with O
the O
non O
- O
linearity O
of O
the O
person O
’s O
appearance O
, O
a O
kernel Method
version Method
can O
be O
developed O
easily O
to O
further O
boost O
the O
matching Task
performance O
within O
the O
null O
space O
. O
It O
therefore O
offers O
a O
perfect O
solution O
to O
the O
challenging O
person Task
re Task
- Task
i Task
d Task
problem Task
. O
In O
addition O
to O
formulating O
the O
NSFT Method
model Method
as O
a O
fully Method
supervised Method
model Method
to O
solve O
the O
person Task
re Task
- Task
i Task
d Task
problem Task
, O
we O
also O
extend O
it O
to O
the O
semi Task
- Task
supervised Task
setting Task
to O
further O
alleviate O
the O
effects O
of O
the O
SSS Task
problem Task
by O
exploiting O
unlabelled Material
data Material
abundant O
in O
re Task
- Task
i Task
d Task
applications O
. O
The O
contributions O
of O
this O
work O
are O
as O
follows O
: O
( O
1 O
) O
We O
identify O
the O
small Metric
sample Metric
size Metric
( O
SSS Task
) Task
problem Task
suffered O
by O
all O
existing O
metric O
learning O
based O
re Task
- Task
i Task
d Task
methods O
and O
argue O
that O
their O
solutions O
to O
this O
problem O
is O
suboptimal O
. O
( O
2 O
) O
For O
the O
first O
time O
, O
we O
propose O
to O
overcome O
the O
SSS Task
problem Task
in O
person Task
re Task
- Task
i Task
d Task
by O
learning O
a O
discriminative O
null O
space O
of O
the O
training O
data O
. O
( O
3 O
) O
We O
develop O
a O
novel O
semi Method
- Method
supervised Method
learning Method
method Method
in O
the O
null O
space O
to O
exploit O
the O
abundant O
unlabelled O
data O
to O
further O
alleviate O
the O
effects O
of O
the O
SSS Task
problem Task
. O
Extensive O
experiments O
carried O
out O
on O
five O
person Task
re Task
- Task
identification Task
benchmarks O
including O
VIPeR Material
, O
PRID2011 Material
, O
CUHK01 Material
, O
CUHK03 Material
and O
Market1501 Material
show O
that O
such O
a O
simple O
and O
computationally O
very O
efficient O
approach O
beats O
all O
state O
- O
of O
- O
the O
- O
art O
methods O
presented O
to O
date O
, O
often O
by O
a O
large O
margin O
. O
section O
: O
Related O
Work O
Existing O
works O
on O
person Task
re Task
- Task
i Task
d Task
can O
be O
roughly O
categorised O
into O
three O
groups O
. O
The O
first O
group O
of O
methods O
design O
invariant O
and O
discriminant O
features O
. O
The O
general O
trend O
is O
that O
the O
dimensions O
of O
the O
proposed O
features O
are O
getting O
higher O
. O
For O
instance O
the O
dimensions O
of O
two O
representations O
, O
recently O
proposed O
in O
and O
and O
used O
in O
our O
experiments O
, O
are O
5 O
, O
138 O
and O
26 O
, O
960 O
respectively O
. O
However O
, O
no O
matter O
how O
robust O
the O
designed O
features O
are O
, O
they O
are O
unlikely O
to O
be O
completely O
invariant O
to O
the O
often O
drastic O
cross O
- O
view O
pose O
/ O
illumination O
/ O
background O
changes O
. O
Therefore O
, O
the O
second O
group O
of O
methods O
focus O
on O
learning O
robust Metric
and Metric
discriminative Metric
distance Metric
metrics Metric
or O
subspaces O
for O
matching O
people O
across O
views O
. O
Recently O
, O
the O
third O
group O
of O
methods O
start O
to O
appear O
which O
are O
based O
on O
deep Method
learning Method
. O
However O
, O
person Task
re Task
- Task
i Task
d Task
seems O
to O
be O
one O
of O
the O
few O
vision Task
problems Task
that O
deep Method
learning Method
has O
not O
been O
able O
to O
shine O
due O
to O
the O
small O
training O
sample O
size O
problem O
addressed O
in O
this O
work O
. O
Apart O
from O
a O
few O
exceptions O
based O
on O
ranking Task
or O
boosting Method
, O
the O
second O
groups O
of O
methods O
can O
be O
further O
divided O
into O
two O
major O
sub O
- O
groups O
: O
those O
on O
learning Metric
distance Metric
metrics Metric
and O
those O
on O
learning O
discriminative O
subspaces O
. O
Seemingly O
different O
, O
these O
two O
sub O
- O
groups O
are O
closely O
related O
. O
Specifically O
, O
most O
metric Method
learning Method
methods Method
focus O
on O
Mahalanobis Metric
form Metric
metrics Metric
. O
If O
the O
linear Method
projection Method
of O
a O
feature O
vector O
in O
a O
learned O
discriminative O
subspace O
is O
denoted O
as O
, O
we O
have O
. O
The O
Euclidean O
distance O
between O
and O
is O
exactly O
a O
Mahalanobis Method
distance Method
where O
is O
a O
positive O
semidefinite O
matrix O
. O
In O
other O
words O
, O
learning O
a O
discriminative O
subspace O
followed O
by O
computing O
Euclidean O
distance O
is O
equivalent O
to O
computing O
a O
discriminative O
Mahalanobis O
distance O
over O
feature O
vectors O
in O
the O
original O
space O
. O
By O
making O
this O
connection O
, O
it O
is O
not O
difficult O
to O
see O
why O
both O
methods O
suffer O
from O
the O
same O
SSS Task
problem Task
typically O
associated O
with O
the O
subspace Method
learning Method
methods Method
. O
Most O
existing O
methods O
need O
to O
work O
with O
a O
reduced O
dimensionality O
, O
achieved O
typically O
by O
PCA Method
whose O
dimension O
has O
to O
be O
carefully O
tuned O
for O
each O
dataset O
. O
Some O
works O
additionally O
require O
introducing O
matrix O
regularisation O
term O
if O
the O
intra O
- O
class O
scatter O
matrix O
is O
used O
in O
the O
formulation O
, O
in O
order O
to O
prevent O
matrix O
singularity O
, O
again O
with O
free O
parameters O
to O
tune O
. O
Critically O
, O
they O
suffer O
from O
the O
degenerate Task
eigenvalue Task
problem Task
( O
i.e. O
several O
eigenvectors O
share O
the O
same O
eigenvalue O
) O
, O
which O
makes O
the O
solution O
sub O
- O
optimal O
resulting O
in O
loss O
of O
discriminant Metric
ability Metric
. O
In O
contrast O
, O
for O
our O
discriminative Method
null Method
space Method
based Method
approach Method
, O
neither O
dimensionality Method
reduction Method
before O
model Method
learning Method
nor O
regularisation Method
term Method
is O
required O
, O
and O
it O
has O
no O
parameters O
to O
tune O
. O
As O
a O
solution O
proposed O
specifically O
to O
address O
the O
SSS Task
problem Task
, O
the O
null Method
Foley Method
- Method
Sammon Method
transfer Method
( O
NFST Method
) O
method O
has O
been O
around O
for O
a O
long O
time O
, O
but O
received O
very O
little O
attention O
apart O
from O
a O
recent O
application O
to O
the O
novelty Task
detection Task
problem Task
. O
A O
possible O
reason O
is O
that O
by O
restricting O
the O
learned O
discriminative O
projecting O
directions O
to O
the O
null O
projecting O
directions O
( O
NPDs O
) O
, O
on O
which O
within O
- O
class O
distance O
is O
always O
zero O
and O
between O
- O
class O
distance O
is O
positive O
, O
the O
model O
is O
extreme O
, O
leaving O
little O
space O
for O
further O
extension O
with O
clear O
added O
- O
value O
. O
For O
example O
, O
the O
more O
relaxed O
Fisher Method
discriminative Method
analysis Method
( O
FDA Method
) O
can O
be O
extended O
, O
gaining O
notable O
advantage O
, O
by O
exploit O
graph Method
laplacian Method
to O
preserve O
local O
data O
structure O
, O
known O
as O
LFDA Method
, O
which O
has O
been O
successfully O
applied O
to O
re Task
- Task
i Task
d Task
. O
However O
, O
a O
similar O
graph Method
laplacian Method
extension Method
to O
NFST Method
does O
not O
apply O
due O
to O
its O
single O
point O
per O
class O
nature O
. O
Despite O
the O
restrictions O
, O
given O
the O
acute O
SSS Task
problem Task
in O
re Task
- Task
i Task
d Task
distance O
metric O
learning O
, O
the O
basic O
idea O
of O
learning O
a O
null O
space O
for O
overcoming O
this O
problem O
becomes O
very O
attractive O
. O
The O
general O
concept O
of O
collapsing O
same O
- O
class O
data O
points O
to O
a O
single O
point O
has O
been O
exploited O
in O
a O
Mahalanobis Method
distance Method
learning Method
framework Method
, O
known O
as O
maximally Method
collapsing Method
metric Method
learning Method
( O
MCML Method
) O
. O
However O
, O
MCML Method
does O
not O
exploit O
a O
null O
space O
. O
Instead O
, O
the O
MCML Method
model Method
must O
make O
approximations O
with O
plenty O
of O
free O
parameters O
to O
tune O
and O
no O
closed Method
- Method
form Method
solution Method
. O
In O
this O
work O
, O
we O
exploit O
the O
original O
null Method
Foley Method
- Method
Sammon Method
transfer Method
( O
NFST Method
) O
method O
with O
its O
conventional O
supervised Method
learning Method
approach Method
, O
benefiting O
from O
its O
attractive O
closed Method
- Method
form Method
solution Method
and O
no O
parameters Method
tuning Method
required O
. O
Moreover O
, O
we O
extend O
the O
original O
fully Method
supervised Method
null Method
space Method
model Method
to O
a O
semi Task
- Task
supervised Task
learning Task
setting Task
. O
This O
is O
to O
explore O
, O
in O
addition O
to O
a O
few O
labelled O
data O
, O
a O
larger O
quantities O
of O
unlabelled O
data O
typically O
available O
in O
person O
re Task
- Task
i Task
d Task
scenarios O
for O
model Task
learning Task
. O
The O
problem O
of O
semi O
- O
supervised O
re Task
- Task
i Task
d Task
has O
attracted O
interest O
lately O
due O
to O
its O
potential O
to O
overcome O
the O
lack O
of O
training O
data O
problem O
. O
One O
approach O
is O
by O
dictionary Method
learning Method
for O
sparse Task
coding Task
, O
which O
has O
an O
unsupervised O
nature O
, O
thus O
can O
be O
learned O
with O
both O
labelled O
and O
unlabelled O
data O
. O
In O
this O
work O
, O
we O
compare O
the O
new O
semi Method
- Method
supervised Method
null Method
space Method
model Method
against O
dictionary Method
learning Method
based Method
methods Method
and O
demonstrate O
the O
superior O
performance O
from O
the O
new O
model O
. O
section O
: O
Methodology O
subsection O
: O
Problem O
Definition O
Given O
a O
set O
of O
training O
data O
denoted O
as O
. O
Each O
column O
of O
the O
data Method
descriptor Method
matrix Method
, O
is O
a O
feature O
vector O
representing O
the O
- O
th O
training O
sample O
. O
In O
the O
case O
of O
person Task
re Task
- Task
i Task
d Task
, O
this O
feature O
vector O
is O
extracted O
from O
a O
person O
detection O
box O
and O
contains O
appearance O
information O
about O
the O
person O
, O
and O
its O
dimension O
is O
typically O
very O
high O
. O
We O
assume O
that O
each O
data O
point O
belongs O
to O
one O
of O
classes O
, O
i.e. O
different O
identities O
. O
The O
objective O
of O
learning O
a O
discriminative Task
null Task
space Task
is O
to O
learn O
a O
projection O
matrix O
to O
project O
the O
original O
high O
- O
dimensional O
feature O
vector O
into O
a O
lower O
- O
dimensional O
one O
with O
. O
Person Task
re Task
- Task
i Task
d Task
can O
then O
be O
performed O
by O
computing O
the O
Euclidean O
distance O
between O
two O
projected O
vectors O
in O
the O
learned O
discriminative O
null O
space O
. O
subsection O
: O
Foley Method
- Method
Sammon Method
Transform Method
The O
learned O
null Method
Foley Method
- Method
Sammon Method
transform Method
( O
NFST Method
) O
space O
is O
closely O
related O
to O
linear Method
discriminant Method
analysis Method
( O
LDA Method
) O
, O
also O
known O
as O
Foley Method
- Method
Sammon Method
transform Method
( O
FST Method
) O
. O
So O
before O
we O
formulate O
NFST Method
, O
let O
us O
first O
briefly O
revisit O
FST Method
. O
The O
objective O
of O
FST Task
is O
to O
learn O
a O
projection O
matrix O
so O
that O
each O
column O
, O
denoted O
as O
, O
is O
an O
optimal O
discriminant O
direction O
that O
maximises O
the O
Fisher Metric
discriminant Metric
criterion Metric
: O
where O
is O
the O
between O
- O
class O
scatter O
matrix O
and O
is O
the O
within O
- O
class O
scatter O
matrix O
. O
The O
optimisation Task
of Task
Eq Task
. O
( O
[ O
reference O
] O
) O
can O
be O
done O
by O
solving O
the O
following O
generalised Method
eigen Method
- Method
problem Method
: O
If O
is O
non O
- O
singular O
, O
eigenvectors O
can O
be O
computed O
corresponding O
to O
the O
largest O
eigenvalues O
of O
. O
Using O
them O
as O
the O
columns O
, O
the O
projection Method
matrix Method
can O
project O
the O
original O
data O
into O
a O
dimensional O
discriminative O
subspace O
where O
the O
classes O
become O
maximally O
separable O
. O
However O
, O
in O
the O
small O
sample O
size O
case O
, O
we O
have O
; O
as O
a O
result O
, O
is O
singular O
. O
FST Method
thus O
runs O
in O
numerical Task
problems Task
and O
common O
solutions O
include O
reducing O
by O
PCA Method
or O
adding O
a O
regularisation Method
term Method
to O
. O
In O
, O
a O
more O
principled O
way O
to O
overcome O
the O
SSS Task
problem Task
in O
FST Task
is O
proposed O
, O
termed O
as O
Null Method
Foley Method
- Method
Sammon Method
transform Method
( O
NFST Method
) O
. O
subsection O
: O
Null Method
Foley Method
- Method
Sammon Method
transform Method
NFST Method
aims O
to O
learn O
a O
discriminative O
subspace O
where O
the O
training O
data O
points O
of O
each O
of O
the O
classes O
are O
collapsed O
to O
a O
single O
point O
, O
resulting O
in O
points O
in O
the O
space O
. O
In O
order O
to O
make O
this O
subspace O
discriminative O
, O
these O
points O
should O
not O
further O
collapse O
to O
a O
single O
point O
. O
Formally O
, O
we O
aim O
to O
learn O
the O
optimal O
projection O
matrix O
so O
that O
each O
of O
its O
column O
satisfies O
the O
following O
two O
conditions O
: O
That O
is O
, O
it O
satisfies O
zero O
within O
- O
class O
scatter O
and O
positive O
between O
- O
class O
scatter O
. O
This O
guarantees O
the O
best O
separability O
of O
the O
training O
data O
in O
the O
sense O
of O
Fisher Metric
discriminant Metric
criterion Metric
. O
Such O
a O
linear O
projecting O
direction O
is O
called O
Null O
Projecting O
Direction O
( O
NPD O
) O
. O
Next O
, O
we O
show O
that O
a O
NPD O
must O
lie O
in O
the O
null O
space O
of O
. O
In O
particular O
, O
we O
have O
the O
following O
Lemma O
: O
Lemma O
1 O
. O
Let O
W O
be O
a O
projection Method
matrix Method
which O
maps O
a O
sample O
x O
into O
the O
null O
space O
of O
Sw O
, O
where O
the O
null O
space O
is O
spanned O
by O
the O
orthonormal O
set O
of O
W O
, O
that O
is O
, O
= O
⁢SwW0 O
. O
If O
all O
samples O
are O
mapped O
into O
the O
null O
space O
of O
Sw O
through O
W O
, O
the O
within O
- O
class O
scatter O
matrix O
^Sw O
of O
the O
mapped O
samples O
is O
a O
complete O
zero O
matrix O
. O
Proof O
. O
Let O
be O
the O
sample O
of O
the O
class O
which O
has O
samples O
in O
total O
. O
denote O
the O
mapped O
feature O
vector O
through O
. O
We O
have O
: O
where O
, O
, O
, O
is O
the O
number O
of O
samples O
in O
class O
, O
and O
is O
the O
mean O
vector O
of O
all O
data O
belonging O
to O
the O
class O
. O
Now O
with O
Lemma O
1 O
, O
we O
know O
that O
Eq O
. O
( O
[ O
reference O
] O
) O
holds O
as O
long O
as O
is O
from O
the O
null O
space O
of O
. O
Next O
we O
take O
a O
look O
the O
condition O
in O
the O
inequality O
( O
[ O
reference O
] O
) O
. O
It O
is O
easy O
to O
see O
that O
when O
Eq O
. O
( O
[ O
reference O
] O
) O
holds O
, O
( O
[ O
reference O
] O
) O
also O
holds O
if O
: O
where O
is O
the O
total O
scatter O
matrix O
. O
We O
now O
denote O
the O
null O
space O
of O
the O
and O
as O
: O
and O
their O
orthogonal O
complements O
as O
and O
respectively O
. O
Now O
since O
is O
non O
- O
negative O
definite O
, O
we O
can O
see O
that O
in O
order O
for O
the O
NPDs O
to O
satisfy O
both O
Eqs O
. O
( O
[ O
reference O
] O
) O
and O
( O
[ O
reference O
] O
) O
simultaneously O
, O
they O
must O
lie O
in O
the O
shared O
space O
between O
and O
, O
that O
is O
: O
It O
has O
been O
proved O
in O
that O
there O
are O
precisely O
NPDs O
that O
satisfy O
both O
Eq O
. O
( O
[ O
reference O
] O
) O
and O
( O
[ O
reference O
] O
) O
. O
In O
other O
words O
, O
the O
discriminative O
null O
space O
we O
are O
looking O
for O
has O
dimensions O
. O
subsection O
: O
Learning O
the O
Discriminative Method
Null Method
Space Method
Let O
be O
the O
matrix O
consisting O
of O
vectors O
. O
be O
the O
matrix O
consisting O
of O
vectors O
with O
. O
We O
then O
have O
, O
Now O
we O
know O
where O
to O
look O
for O
the O
NPDs O
– O
the O
shared O
space O
between O
and O
. O
Next O
, O
we O
shall O
see O
how O
to O
compute O
them O
. O
Let O
us O
first O
take O
a O
look O
at O
how O
to O
compute O
that O
satisfies O
. O
First O
we O
notice O
that O
: O
Hence O
, O
is O
the O
subspace O
spanned O
by O
zero O
- O
mean O
data O
. O
We O
can O
obtain O
the O
orthonormal O
basis O
of O
the O
zero O
- O
mean O
data O
using O
Gram Method
- Method
Schmidt Method
orthonormalisation Method
, O
then O
represent O
each O
solution O
as O
: O
Note O
that O
there O
are O
basis O
vectors O
because O
the O
rank O
of O
is O
. O
So O
now O
after O
expressing O
using O
Eq O
. O
( O
[ O
reference O
] O
) O
, O
it O
must O
satisfy O
. O
The O
next O
step O
is O
the O
make O
it O
also O
satisfy O
. O
This O
can O
be O
achieved O
by O
substituting O
Eq O
. O
( O
[ O
reference O
] O
) O
into O
Eq O
. O
( O
[ O
reference O
] O
) O
and O
solve O
the O
following O
eigen Task
- Task
problem Task
: O
for O
which O
we O
know O
that O
solutions O
exist O
, O
giving O
NPDs O
, O
. O
In O
summary O
, O
the O
problem O
of O
learning O
the O
discriminative Task
null Task
space Task
boils O
down O
to O
solving O
an O
eigen Task
- Task
problem Task
which O
has O
a O
closed O
- O
form O
solution O
and O
can O
be O
solved O
very O
efficiently O
. O
Importantly O
, O
the O
whole O
optimisation Method
algorithm Method
has O
no O
free O
parameter O
to O
tune O
. O
subsection O
: O
Kernelisation O
The O
NFST Method
model O
is O
a O
linear Method
model Method
. O
It O
has O
been O
demonstrated O
that O
many O
distance Method
metric Method
learning Method
or O
discriminative Method
subspace Method
based Method
methods Method
for O
person Task
re Task
- Task
i Task
d Task
benefit O
from O
kernelisation Method
because O
of O
the O
non O
- O
linearity O
in O
person O
’s O
appearance O
. O
In O
the O
following O
we O
describe O
how O
the O
discriminative O
null O
space O
can O
be O
kernelised O
. O
Given O
a O
kernel Method
function Method
, O
where O
maps O
to O
an O
implicit O
higher O
dimensional O
space O
, O
we O
can O
compute O
the O
data O
kernel O
matrix O
for O
training O
data O
as O
. O
Now O
the O
within O
- O
class O
scatter O
matrix O
and O
total Method
- Method
class Method
scatter Method
matrix Method
can O
be O
kernelised O
as O
: O
where O
is O
a O
identity O
matrix O
, O
is O
a O
block Method
diagonal Method
matrix Method
with O
block O
sizes O
equal O
to O
the O
number O
of O
data O
points O
for O
each O
class O
and O
is O
a O
matrix O
with O
all O
entries O
equal O
to O
. O
Now O
to O
write O
Eq O
. O
( O
[ O
reference O
] O
) O
in O
its O
kernelised O
form O
, O
we O
need O
to O
replace O
with O
, O
and O
compute O
the O
orthonormal O
basis O
of O
to O
replace O
. O
The O
orthonormal O
basis O
of O
can O
be O
computed O
using O
kernel Method
PCA Method
. O
First O
, O
we O
compute O
the O
centred Method
kernel Method
matrix Method
. O
Second O
, O
the O
eigendecomposition Method
of Method
is O
written O
as O
with O
being O
the O
diagonal O
matrix O
containing O
non O
- O
zero O
eigenvalues O
and O
containing O
the O
corresponding O
eigenvectors O
in O
its O
columns O
. O
Now O
the O
scaled O
eigenvectors O
contain O
coefficients O
for O
the O
kernelised O
orthonormal O
basis O
used O
to O
replace O
in O
Eq O
. O
( O
[ O
reference O
] O
) O
. O
Let O
and O
with O
Eq O
. O
( O
[ O
reference O
] O
) O
, O
we O
can O
rewrite O
Eq O
. O
( O
[ O
reference O
] O
) O
as O
: O
By O
solving O
the O
eigen Task
- Task
problem Task
Eq Task
. O
( O
[ O
reference O
] O
) O
, O
we O
obtain O
the O
final O
null O
projection O
directions O
( O
NPDs O
) O
as O
: O
subsection O
: O
Semi Task
- Task
supervised Task
Learning Task
The O
NFST Method
method O
is O
a O
fully Method
supervised Method
method Method
. O
When O
applied O
to O
the O
problem O
of O
re Task
- Task
i Task
d Task
, O
the O
labelled O
training O
set O
is O
used O
to O
learn O
the O
projection O
. O
The O
test O
data O
are O
then O
projected O
into O
the O
same O
subspace O
and O
matched O
by O
computing O
the O
Euclidean O
distance O
between O
a O
query O
sample O
and O
a O
set O
of O
gallery O
samples O
. O
In O
a O
real Task
- Task
world Task
application Task
scenario Task
, O
the O
labelled O
training O
data O
are O
scarce O
but O
there O
are O
often O
plenty O
of O
unlabelled O
data O
( O
person O
images O
collected O
from O
different O
views O
) O
that O
can O
be O
used O
to O
alleviate O
the O
small Task
sample Task
size Task
problem Task
. O
To O
this O
end O
, O
the O
NFST Method
method O
is O
extended O
to O
the O
semi Task
- Task
supervised Task
setting Task
. O
More O
specifically O
, O
given O
a O
training O
set O
contains O
a O
labelled O
subset O
of O
samples O
and O
an O
unlabelled O
subset O
of O
samples O
. O
Using O
the O
NFST Method
method O
described O
above O
, O
we O
can O
first O
learn O
an O
initial O
projection O
matrix O
using O
only O
. O
Then O
is O
projected O
to O
the O
lower O
- O
dimensional O
subspace O
through O
and O
becomes O
. O
To O
utilise O
the O
unlabelled O
data O
, O
we O
use O
their O
projections O
to O
build O
a O
cross Method
- Method
view Method
correspondence Method
matrix Method
which O
captures O
the O
identity O
relationship O
for O
the O
unlabelled O
people O
across O
views O
. O
Note O
, O
since O
the O
data O
are O
unlabelled O
, O
the O
true O
cross O
- O
view O
correspondence O
relationship O
is O
unknown O
. O
We O
therefore O
use O
to O
represent O
a O
soft O
cross O
- O
view O
correspondence O
relationship O
. O
That O
is O
, O
each O
person O
in O
one O
view O
can O
correspond O
to O
multiple O
people O
in O
another O
view O
depending O
on O
their O
visual O
similarity O
in O
the O
learned O
discriminative O
subspace O
parameterised O
by O
. O
To O
this O
end O
, O
we O
first O
construct O
a O
- Method
nearest Method
- Method
neighbour Method
( O
- Method
nn Method
) O
graph O
across O
camera O
views O
with O
vertices O
, O
where O
each O
vertex O
represents O
a O
unlabelled O
data O
point O
. O
is O
then O
computed O
as O
the O
weight O
matrix O
of O
using O
a O
heat Method
kernel Method
. O
With O
this O
- Method
nn Method
graph O
, O
we O
then O
create O
pseudo O
- O
classes O
, O
each O
consisting O
one O
vertex O
from O
one O
view O
and O
its O
- O
nearest O
- O
neighbours O
from O
the O
other O
view O
. O
Next O
these O
pseudo O
- O
classes O
are O
augmented O
with O
the O
labelled O
classes O
in O
to O
create O
a O
new O
training O
set O
, O
denoted O
, O
on O
which O
a O
new O
project O
matrix O
is O
computed O
using O
NFST Method
. O
Re O
- O
learning O
the O
projection O
matrix O
runs O
iteratively O
till O
the O
average Metric
distance Metric
for O
the O
- O
nearest O
- O
neighbours O
stop O
decreasing O
. O
In O
our O
experiments O
, O
we O
found O
that O
the O
algorithm O
converges O
rapidly O
. O
This O
semi Method
- Method
supervised Method
learning Method
is O
essentially O
based O
on O
self Method
- Method
training Method
, O
a O
popular O
strategy O
taken O
by O
many O
semi Method
- Method
supervised Method
learning Method
methods Method
. O
For O
any O
self Method
- Method
training Method
based Method
methods Method
, O
preventing O
model Task
drift Task
is O
of O
paramount O
importance O
. O
Apart O
from O
examining O
the O
average Metric
distance Metric
for O
the O
- O
nearest O
- O
neighbours O
, O
another O
measure O
taken O
is O
to O
rank O
the O
- O
nearest O
- O
neighbours O
and O
take O
only O
the O
top O
percent O
with O
the O
smallest O
distance O
to O
create O
the O
pseudo O
- O
classes O
. O
The O
complete O
semi Method
- Method
supervised Method
null Method
space Method
learning Method
algorithm Method
is O
summarised O
in O
Alg O
. O
[ O
reference O
] O
. O
[ O
! O
t O
] O
Semi Task
- Task
supervised Task
null Task
space Task
learning Task
[ O
1 O
] O
, O
, O
, O
. O
The O
learned Method
projection Method
. O
Estimate O
using O
; O
; O
not O
converged O
project O
through O
to O
obtain O
build O
- Method
nn Method
graph O
with O
take O
top O
percent O
to O
create O
the O
pseudo O
- O
classes O
learn O
with O
section O
: O
Experiments O
subsection O
: O
Datasets O
and O
Settings O
Datasets O
Five O
widely O
used O
datasets O
are O
selected O
for O
experiments O
, O
including O
the O
three O
largest O
benchmarks O
available O
( O
CUHK01 Material
, O
CUHK03 Material
, O
and O
Market1501 Material
) O
. O
VIPeR Material
contains O
632 O
identities O
and O
each O
has O
two O
images O
captured O
outdoor O
from O
two O
views O
with O
distinct O
view O
angles O
. O
All O
images O
are O
scaled O
to O
128 O
48 O
pixels O
. O
The O
632 O
people O
’s O
images O
are O
randomly O
divided O
into O
two O
equal O
halves O
, O
one O
for O
training O
and O
the O
other O
for O
testing O
. O
This O
is O
repeated O
for O
10 O
times O
and O
the O
averaged O
performance O
is O
reported O
. O
PRID2011 Material
consists O
of O
person O
images O
recorded O
from O
two O
cameras O
. O
Specifically O
, O
it O
has O
two O
camera O
views O
. O
View Material
captures O
385 O
people O
, O
whilst O
View Material
contains O
749 O
people O
. O
Only O
200 O
people O
appear O
in O
both O
views O
. O
The O
single O
shot O
version O
of O
the O
dataset O
is O
used O
in O
our O
experiments O
as O
in O
: O
In O
each O
data O
split O
, O
100 O
people O
with O
one O
image O
from O
each O
view O
are O
randomly O
chosen O
from O
the O
200 O
present O
in O
both O
camera O
views O
for O
the O
training O
set O
, O
while O
the O
remaining O
100 O
of O
View Material
are O
used O
as O
the O
probe O
set O
, O
and O
the O
remaining O
649 O
of O
View Material
are O
used O
as O
gallery O
. O
Experiments O
are O
repeated O
over O
the O
10 O
splits O
provided O
in O
. O
CUHK01 Material
contains O
971 O
identities O
with O
each O
person O
having O
two O
images O
in O
each O
camera O
view O
. O
All O
the O
images O
are O
normalised O
to O
160 O
60 O
pixels O
. O
Following O
the O
standard O
setting O
, O
images O
from O
camera O
A O
are O
used O
as O
probe O
and O
those O
from O
camera O
B O
as O
gallery O
. O
We O
randomly O
partition O
the O
dataset O
into O
485 O
people O
for O
training O
and O
486 O
for O
testing O
( O
multi Task
- Task
shot Task
) Task
following Task
, O
again O
over O
10 O
trials O
. O
CUHK03 Material
contains O
13 O
, O
164 O
images O
of O
1 O
, O
360 O
identities O
, O
captured O
by O
six O
surveillance O
cameras O
with O
each O
person O
only O
appearing O
in O
two O
views O
. O
It O
provides O
both O
manually O
labelled O
pedestrian O
bounding O
boxes O
and O
bounding O
boxes O
automatically O
detected O
by O
the O
deformable Method
- Method
part Method
- Method
model Method
( O
DPM Method
) O
detector O
. O
A O
real O
- O
world O
re Task
- Task
i Task
d Task
system O
has O
to O
rely O
on O
a O
person Method
detector Method
; O
the O
latter O
version O
of O
the O
data O
is O
thus O
ideal O
for O
testing O
performance O
given O
detector Metric
errors Metric
. O
We O
report O
results O
on O
both O
of O
the O
manually O
labelled O
and O
detected O
person O
images O
. O
The O
20 O
training O
/ O
test O
splits O
provided O
in O
is O
used O
under O
and O
the O
single O
- O
shot O
setting O
as O
in O
– O
two O
images O
are O
randomly O
chosen O
for O
testing O
; O
one O
is O
for O
probe O
and O
the O
other O
for O
gallery Task
. O
Market1501 Material
is O
the O
biggest O
re Task
- Task
i Task
d Task
benchmark O
dataset O
to O
date O
, O
containing O
32 O
, O
668 O
detected O
person O
bounding O
boxes O
of O
1 O
, O
501 O
identities O
. O
Each O
identity O
is O
captured O
by O
six O
cameras O
at O
most O
, O
and O
two O
cameras O
at O
least O
. O
During O
testing O
, O
for O
each O
identity O
, O
one O
query O
image O
in O
each O
camera O
is O
selected O
, O
therefore O
multiple O
queries O
are O
used O
for O
each O
identity O
. O
Note O
that O
, O
the O
selected O
3 O
, O
368 O
queries O
in O
are O
hand O
- O
drawn O
, O
instead O
of O
DPM Method
- O
detected O
as O
in O
the O
gallery O
. O
Each O
identity O
may O
have O
multiple O
images O
under O
each O
camera O
. O
We O
use O
the O
provided O
fixed O
training O
and O
test O
set O
, O
under O
both O
the O
single O
- O
query O
and O
multi Task
- Task
query Task
evaluation Task
settings Task
. O
Feature Method
Representations Method
By O
default O
the O
recently O
proposed O
Local Method
Maximal Method
Occurrence Method
( O
LOMO Method
) O
features O
are O
used O
for O
person Task
representation Task
. O
The O
descriptor O
has O
26 O
, O
960 O
dimensions O
. O
To O
test O
our O
method O
’s O
ability O
to O
fuse O
different O
representations O
, O
we O
also O
consider O
another O
histogram Method
- Method
based Method
image Method
descriptor Method
proposed O
in O
. O
These O
include O
colour O
histogram O
, O
HOG Method
and O
LBP Method
which O
are O
concatenated O
resulting O
in O
5138 O
dimensions O
. O
Evaluation Metric
metrics Metric
We O
use O
Cumulated Metric
Matching Metric
Characteristics Metric
( O
CMC Metric
) O
curve O
to O
evaluate O
the O
performance O
of O
person Method
re Method
- Method
identification Method
methods Method
for O
all O
datasets O
in O
this O
paper O
. O
Due O
to O
space O
limitation O
and O
for O
easier O
comparison O
with O
published O
results O
, O
we O
only O
report O
the O
cumulated Metric
matching Metric
accuracy Metric
at O
selected O
ranks O
in O
tables O
rather O
than O
plotting O
the O
actual O
curves O
. O
Note O
that O
for O
the O
Market1501 Material
dataset O
, O
since O
there O
are O
on O
average O
14.8 O
cross O
- O
camera O
ground O
truth O
matches O
for O
each O
query O
, O
we O
additionally O
use O
mean Metric
average Metric
precision Metric
( O
mAP Metric
) O
as O
in O
to O
evaluate O
the O
performance O
. O
Parameter Task
setting Task
There O
is O
no O
free O
parameter O
to O
tune O
for O
our O
model O
. O
However O
, O
with O
the O
kernelisation Method
, O
kernel Method
selection Method
is O
necessary O
. O
Unless O
stated O
otherwise O
, O
RBF Method
kernel Method
is O
used O
with O
the O
kernel O
width O
determined O
automatically O
using O
the O
mean O
pairwise O
distance O
of O
samples O
. O
For O
other O
compared O
methods O
, O
different O
model O
specific O
parameters O
have O
to O
be O
tuned O
carefully O
to O
report O
the O
highest O
results O
. O
Note O
that O
under O
the O
semi Method
- Method
supervised Method
null Method
space Method
learning Method
algorithm Method
, O
there O
are O
free O
parameters O
: O
the O
value O
of O
in O
the O
- Method
nn Method
graph O
is O
fixed O
to O
3 O
for O
all O
experiments O
. O
The O
percentage O
of O
neighbours O
kept O
for O
creating O
pseudo O
classes O
are O
fixed O
at O
40 O
% O
. O
We O
found O
that O
the O
results O
are O
not O
sensitive O
to O
the O
values O
of O
these O
parameters O
. O
subsection O
: O
Fully Task
Supervised Task
Learning Task
Results O
For O
the O
fully Task
supervised Task
setting Task
, O
all O
the O
labels O
of O
the O
training O
data O
are O
used O
for O
model Task
learning Task
. O
For O
different O
datasets O
, O
we O
select O
different O
most O
representative O
and O
competitive O
alternative O
methods O
for O
comparison O
. O
Results O
on O
VIPeR Material
We O
first O
evaluate O
our O
method O
against O
the O
state O
- O
of O
- O
the O
- O
art O
on O
VIPeR. Task
We O
compare O
with O
17 O
existing O
methods O
. O
Among O
them O
, O
the O
distance Method
metric Method
learning Method
based Method
methods Method
are O
RPLM Method
, O
MtMCML Method
, O
Mid Method
- Method
level Method
Filter Method
, O
SCNCD Method
, O
Similarity Method
Learning Method
, O
LADF Method
, O
ITML Method
, O
LMNN Method
, O
KISSME Method
, O
and O
MCML Method
, O
whilst O
the O
others O
are O
discriminative Method
subspace Method
learning Method
based Method
methods Method
including O
kCCA Method
, O
MFA Method
, O
kLFDA Method
, O
and O
XQDA Method
. O
Note O
that O
XQDA Method
can O
be O
considered O
as O
hybrid Method
between Method
metric Method
learning Method
and O
subspace Method
learning Method
. O
In O
addition O
, O
deep Method
learning Method
based Method
model Method
is O
also O
compared O
. O
For O
fair O
comparison O
, O
whenever O
possible O
( O
i.e. O
code O
is O
available O
and O
features O
can O
be O
replaced O
) O
, O
we O
compare O
with O
these O
methods O
using O
the O
same O
LOMO Method
features O
. O
Otherwise O
, O
the O
reported O
results O
are O
presented O
. O
From O
the O
results O
shown O
in O
Table O
[ O
reference O
] O
, O
we O
can O
make O
the O
following O
observations O
: O
( O
1 O
) O
Our O
method O
achieves O
the O
highest O
performance O
when O
a O
single O
type O
of O
features O
are O
used O
( O
Rank O
1 O
of O
42.28 O
% O
compared O
to O
the O
closest O
competitor O
XQDA Method
which O
gives O
40.00 O
% O
) O
. O
( O
2 O
) O
For O
fair O
comparison O
against O
methods O
which O
fuse O
more O
than O
one O
types O
of O
features O
or O
more O
than O
one O
models O
, O
we O
also O
present O
our O
method O
’s O
result O
obtained O
by O
a O
simple O
score Method
- Method
level Method
fusion Method
using O
the O
two O
types O
of O
features O
described O
earlier O
. O
Our O
method O
( O
Ours O
( O
Fusion Method
) O
) O
beats O
the O
nearest Method
rival Method
by O
over O
5 O
% O
on O
Rank O
1 O
. O
( O
3 O
) O
The O
discriminative Method
subspace Method
learning Method
based Method
methods Method
seem O
to O
be O
more O
competitive O
compared O
with O
the O
distance Method
metric Method
learning Method
based Method
methods Method
. O
Note O
that O
all O
of O
them O
have O
been O
kernelised O
and O
we O
observe O
a O
significant O
drop O
in O
performance O
without O
kernelisation Method
. O
This O
confirms O
the O
conclusion O
drawn O
in O
that O
kernelisation Method
is O
critical O
for O
addressing O
the O
non O
- O
linearity O
problem O
in O
re Task
- Task
i Task
d Task
. O
( O
4 O
) O
The O
most O
related O
methods O
MCML Method
and O
MtMCML Method
yeild O
much O
poorer O
results O
, O
indicating O
that O
the O
principle O
of O
collapsing O
same O
- O
class O
samples O
is O
better O
realised O
in O
a O
subspace Method
learning Method
framework Method
which O
provides O
an O
exact O
and O
closed O
- O
form Method
solution Method
. O
( O
5 O
) O
The O
deep Method
learning Method
based Method
method Method
does O
not O
fare O
well O
on O
this O
small O
dataset O
despite O
the O
fact O
that O
the O
model O
has O
been O
pre O
- O
trained O
on O
the O
far O
- O
larger O
CUHK01 Material
+ O
CUHK03 Material
datasets Material
. O
This O
suggests O
that O
the O
model O
learned O
from O
other O
datasets O
are O
not O
transferable O
by O
the O
simple O
model Method
fine Method
- Method
tuning Method
strategy Method
and O
small O
sample O
size O
remains O
a O
bottle O
- O
neck O
for O
applying O
deep Method
learning Method
to O
re Task
- Task
i Task
d Task
. O
Results O
on O
PRID2011 Material
We O
compare O
the O
state O
- O
of O
- O
the O
- O
art O
results O
reported O
on O
PRID2011 Material
in O
Table O
[ O
reference O
] O
. O
With O
access O
to O
the O
implementation O
codes O
, O
we O
also O
compare O
with O
the O
methods O
in O
using O
the O
same O
LOMO Method
features O
. O
The O
results O
show O
clearly O
with O
a O
single O
feature O
type O
, O
our O
method O
is O
the O
state O
- O
of O
- O
the O
- O
art O
; O
when O
fusing O
two O
types O
of O
features O
, O
the O
result O
is O
improved O
dramatically O
( O
over O
10 O
% O
increase O
on O
both O
Rank O
1 O
and O
5 O
) O
, O
and O
significantly O
higher O
than O
the O
reported O
results O
of O
the O
feature Method
fusion Method
method Method
in O
, O
which O
fuses O
four O
different O
types O
of O
features O
including O
the O
deep Method
convolutional Method
neural Method
network Method
( O
CNN Method
) O
features O
. O
Results O
on O
CUHK01 Material
& O
CUHK03 Material
Compared O
with O
VIPeR Material
and O
PRID2011 Material
, O
these O
two O
datasets O
are O
much O
bigger O
with O
thousands O
of O
training O
samples O
. O
However O
, O
the O
sample O
size O
is O
still O
much O
smaller O
than O
the O
feature O
dimension O
, O
i.e. O
the O
SSS Task
problem Task
still O
exists O
. O
Table O
[ O
reference O
] O
shows O
that O
on O
CUHK01 Material
, O
our O
method O
beats O
all O
compared O
existing O
methods O
at O
low O
ranks O
and O
when O
two O
types O
of O
features O
are O
fused O
, O
the O
margin O
is O
significant O
. O
As O
for O
CUHK03 Material
, O
there O
are O
two O
versions O
: O
the O
one O
with O
manually O
cropped O
person O
images O
, O
and O
the O
one O
with O
bounding O
boxes O
produced O
by O
a O
detector Method
. O
The O
latter O
obviously O
is O
harder O
as O
reflected O
by O
the O
decrease O
of O
matching Metric
accuracy Metric
for O
all O
compared O
methods O
. O
But O
it O
is O
also O
a O
better O
indicator O
of O
real O
- O
world O
performance O
. O
It O
can O
be O
seen O
from O
Table O
[ O
reference O
] O
that O
, O
as O
expected O
, O
on O
this O
much O
larger O
dataset O
, O
the O
deep Method
learning Method
based Method
model Method
with O
its O
millions O
of O
parameters O
becomes O
much O
more O
competitive O
– O
with O
manually O
cropped O
images O
, O
our O
result O
with O
single O
feature O
type O
is O
higher O
on O
Rank O
1 O
but O
lower O
on O
other O
ranks O
. O
However O
, O
with O
the O
detector O
boxes O
, O
our O
method O
is O
less O
affected O
and O
outperforms O
the O
deep Method
model Method
in O
by O
a O
big O
margin O
. O
In O
addition O
, O
our O
performance O
is O
further O
boosted O
by O
fusing O
two O
types O
of O
features O
. O
Results O
on O
Market1501 Material
This O
dataset O
is O
the O
largest O
and O
most O
realistic O
dataset O
with O
natural O
detector O
errors O
abundant O
in O
the O
provided O
data O
as O
they O
were O
collected O
in O
front O
of O
a O
busy O
supermarket O
. O
Since O
it O
is O
new O
, O
few O
reported O
results O
are O
available O
. O
The O
baseline O
presented O
in O
is O
not O
competitive O
because O
it O
is O
based O
on O
a O
weaker O
BoW O
features O
and O
L2 O
- O
Norm O
distance O
. O
We O
compare O
our O
method O
with O
four O
alternatives O
with O
the O
same O
LOMO Method
features O
. O
The O
results O
in O
Table O
[ O
reference O
] O
again O
show O
that O
our O
method O
significantly O
outperforms O
the O
alternatives O
, O
under O
both O
the O
single O
query O
and O
multi Task
- Task
query Task
settings Task
and O
with O
both O
evaluation Metric
metrics Metric
. O
This O
is O
despite O
the O
fact O
that O
with O
12 O
, O
936 O
training O
samples O
, O
the O
SSS Task
problem Task
is O
the O
least O
severe O
in O
this O
dataset O
. O
subsection O
: O
Semi Task
- Task
supervised Task
Learning Task
Results O
For O
semi Task
- Task
supervised Task
setting Task
, O
we O
use O
the O
VIPeR Material
and O
PRID2011 Material
datasets Material
. O
The O
same O
data O
splits O
are O
used O
as O
in O
the O
fully Task
- Task
supervised Task
setting Task
. O
The O
difference O
is O
that O
only O
one O
third O
of O
the O
training O
data O
are O
labelled O
following O
the O
setting O
in O
. O
For O
comparison O
, O
apart O
from O
the O
state O
- O
of O
- O
the O
- O
art O
methods O
in O
, O
we O
also O
choose O
three O
subspace Method
learning Method
based Method
methods Method
trained O
on O
the O
labelled O
data O
only O
. O
The O
results O
in O
Table O
[ O
reference O
] O
show O
that O
the O
performance O
of O
our O
method O
is O
clearly O
superior O
to O
that O
of O
the O
compared O
alternatives O
. O
The O
advantage O
is O
more O
significant O
on O
PRID2011 Material
. O
This O
dataset O
has O
only O
100 O
pairs O
or O
200 O
training O
samples O
; O
with O
only O
one O
third O
of O
them O
labelled O
, O
the O
SSS Task
problem Task
becomes O
the O
most O
acute O
than O
any O
experiment O
we O
conducted O
before O
. O
Comparing O
Table O
[ O
reference O
] O
with O
Table O
[ O
reference O
] O
, O
it O
is O
apparent O
that O
the O
performance O
of O
all O
three O
compared O
subspace Method
learning Method
methods Method
, O
kCCA Method
, O
kLFDA Method
, O
and O
XQDA Method
degrades O
drastically O
. O
In O
contrast O
, O
the O
performance O
of O
our O
method O
decrease O
much O
more O
gracefully O
from O
29.80 O
% O
to O
24.70 O
% O
on O
Rank O
1 O
. O
This O
is O
partly O
because O
our O
self Method
- Method
training Method
based Method
method Method
can O
exploit O
the O
unlabelled O
data O
. O
It O
also O
shows O
that O
it O
can O
better O
cope O
with O
the O
SSS Task
problem Task
in O
its O
extreme O
. O
subsection O
: O
Running Metric
Cost Metric
We O
compare O
the O
run Metric
time Metric
of O
our O
method O
with O
XQDA Method
, O
kLFDA Method
and O
MFA Method
on O
Market1501 Material
. O
We O
calculate O
the O
overall O
training Metric
time Metric
over O
12 O
, O
936 O
samples O
and O
test O
time O
over O
3 O
, O
368 O
queries O
. O
All O
algorithms O
are O
implemented O
in O
Matlab Method
and O
run O
on O
a O
server O
with O
2.6GHz O
CPU O
cores O
and O
384 O
GB O
memory O
. O
Table O
[ O
reference O
] O
shows O
that O
for O
training Task
, O
our O
method O
is O
the O
most O
efficiently O
, O
whilst O
on O
testing O
it O
is O
much O
slower O
than O
XQDA Method
, O
but O
faster O
than O
kLFDA Method
and O
MFA Method
. O
Considering O
the O
test Metric
time Metric
is O
over O
3 O
, O
368 O
queries O
, O
it O
is O
more O
than O
adequate O
for O
real Task
- Task
time Task
applications Task
. O
section O
: O
Conclusion O
We O
proposed O
to O
solve O
the O
person Task
re Task
- Task
i Task
d Task
problem Task
by O
learning O
a O
discriminative O
null O
space O
of O
the O
training O
samples O
. O
Compared O
with O
existing O
re Task
- Task
i Task
d Task
models O
, O
the O
employed O
NFST Method
model O
is O
much O
simpler O
, O
with O
a O
closed O
- O
form O
solution O
and O
no O
parameters O
to O
tune O
. O
Yet O
, O
it O
is O
very O
effective O
in O
dealing O
with O
the O
SSS Task
problem Task
faced O
by O
the O
re Task
- Task
i Task
d Task
methods O
. O
Extensive O
experiments O
on O
five O
benchmarks O
show O
that O
our O
method O
achieves O
the O
state O
- O
of O
- O
the O
- O
art O
performance O
on O
all O
of O
them O
under O
both O
fully Task
supervised Task
and Task
semi Task
- Task
supervised Task
settings Task
. O
section O
: O
Acknowledgement O
This O
work O
was O
funded O
in O
part O
by O
the O
European O
FP7 O
Project O
SUNNY O
( O
grant O
agreement O
no O
. O
313243 O
) O
. O
bibliography O
: O
References O
