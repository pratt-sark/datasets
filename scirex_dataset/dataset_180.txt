3DMatch	Method
:	O
Learning	O
Local	Method
Geometric	Method
Descriptors	Method
from	O
RGB	Method
-	Method
D	Method
Reconstructions	Method
section	O
:	O
Abstract	O
Matching	Task
local	Task
geometric	Task
features	Task
on	O
real	O
-	O
world	O
depth	O
images	O
is	O
a	O
challenging	O
task	O
due	O
to	O
the	O
noisy	O
,	O
lowresolution	O
,	O
and	O
incomplete	O
nature	O
of	O
3D	O
scan	O
data	O
.	O
These	O
difficulties	O
limit	O
the	O
performance	O
of	O
current	O
state	O
-	O
of	O
-	O
art	O
methods	O
,	O
which	O
are	O
typically	O
based	O
on	O
histograms	O
over	O
geometric	O
properties	O
.	O
In	O
this	O
paper	O
,	O
we	O
present	O
3DMatch	Method
,	O
a	O
data	Method
-	Method
driven	Method
model	Method
that	O
learns	O
a	O
local	Method
volumetric	Method
patch	Method
descriptor	Method
for	O
establishing	Task
correspondences	Task
between	O
partial	O
3D	O
data	O
.	O
To	O
amass	O
training	O
data	O
for	O
our	O
model	O
,	O
we	O
propose	O
a	O
self	Method
-	Method
supervised	Method
feature	Method
learning	Method
method	Method
that	O
leverages	O
the	O
millions	O
of	O
correspondence	O
labels	O
found	O
in	O
existing	O
RGB	Material
-	Material
D	Material
reconstructions	Material
.	O
Experiments	O
show	O
that	O
our	O
descriptor	O
is	O
not	O
only	O
able	O
to	O
match	O
local	O
geometry	O
in	O
new	O
scenes	O
for	O
reconstruction	Task
,	O
but	O
also	O
generalize	O
to	O
different	O
tasks	O
and	O
spatial	O
scales	O
(	O
e.g.	O
instance	Task
-	Task
level	Task
object	Task
model	Task
alignment	Task
for	O
the	O
Amazon	Task
Picking	Task
Challenge	Task
,	O
and	O
mesh	Task
surface	Task
correspondence	Task
)	O
.	O
Results	O
show	O
that	O
3DMatch	Method
consistently	O
outperforms	O
other	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
approaches	O
by	O
a	O
significant	O
margin	O
.	O
Code	O
,	O
data	O
,	O
benchmarks	O
,	O
and	O
pre	O
-	O
trained	Method
models	Method
are	O
available	O
online	O
at	O
http:	O
//	O
3dmatch.cs.princeton.edu	O
.	O
section	O
:	O
Introduction	O
Matching	Task
3D	Task
geometry	Task
has	O
a	O
long	O
history	O
starting	O
in	O
the	O
early	O
days	O
of	O
computer	Task
graphics	Task
and	Task
vision	Task
.	O
With	O
the	O
rise	O
of	O
commodity	Method
range	Method
sensing	Method
technologies	Method
,	O
this	O
research	O
has	O
become	O
paramount	O
to	O
many	O
applications	O
including	O
object	Task
pose	Task
estimation	Task
,	O
object	Task
retrieval	Task
,	O
3D	Task
reconstruction	Task
,	O
and	O
camera	Task
localization	Task
.	O
However	O
,	O
matching	Task
local	Task
geometric	Task
features	Task
in	O
lowresolution	O
,	O
noisy	O
,	O
and	O
partial	O
3D	O
data	O
is	O
still	O
a	O
challenging	O
task	O
as	O
shown	O
in	O
Fig	O
.	O
1	O
.	O
While	O
there	O
is	O
a	O
wide	O
range	O
of	O
low	O
-	O
level	O
hand	O
-	O
crafted	O
geometric	Method
feature	Method
descriptors	Method
that	O
can	O
be	O
used	O
for	O
this	O
task	O
,	O
they	O
are	O
mostly	O
based	O
on	O
signatures	O
derived	O
from	O
histograms	O
over	O
static	O
geometric	O
properties	O
[	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
.	O
They	O
work	O
well	O
for	O
3D	Task
models	Task
with	O
complete	O
surfaces	O
,	O
but	O
are	O
often	O
unstable	O
or	O
inconsistent	O
in	O
real	O
-	O
world	O
partial	O
surfaces	O
from	O
3D	O
scanning	O
data	O
and	O
difficult	O
to	O
adapt	O
to	O
new	O
datasets	O
.	O
As	O
a	O
result	O
,	O
state	O
-	O
of	O
-	O
the	O
-	O
Figure	O
1	O
.	O
In	O
this	O
work	O
,	O
we	O
present	O
a	O
data	O
-	O
driven	O
local	O
descriptor	O
3DMatch	Method
that	O
establishes	O
correspondences	O
(	O
green	O
)	O
to	O
match	O
geometric	O
features	O
in	O
noisy	O
and	O
partial	O
3D	O
scanning	O
data	O
.	O
This	O
figure	O
illustrates	O
an	O
example	O
of	O
bringing	O
two	O
RGB	Task
-	Task
D	Task
scans	Task
into	O
alignment	Task
using	O
3DMatch	Method
on	O
depth	O
information	O
only	O
.	O
Color	O
images	O
are	O
for	O
visualization	Task
only	O
.	O
art	O
3D	Task
reconstruction	Task
methods	O
using	O
these	O
descriptors	O
for	O
matching	Task
geometry	Task
require	O
significant	O
algorithmic	O
effort	O
to	O
handle	O
outliers	O
and	O
establish	O
global	O
correspondences	O
[	O
reference	O
]	O
.	O
In	O
response	O
to	O
these	O
difficulties	O
,	O
and	O
inspired	O
by	O
the	O
recent	O
success	O
of	O
neural	Method
networks	Method
,	O
we	O
formulate	O
a	O
data	Method
-	Method
driven	Method
method	Method
to	O
learn	O
a	O
local	Method
geometric	Method
descriptor	Method
for	O
establishing	Task
correspondences	Task
between	O
partial	O
3D	O
data	O
.	O
The	O
idea	O
is	O
that	O
by	O
learning	O
from	O
example	O
,	O
data	Method
-	Method
driven	Method
models	Method
can	O
sufficiently	O
address	O
the	O
difficulties	O
of	O
establishing	Task
correspondences	Task
between	Task
partial	Task
surfaces	Task
in	O
3D	O
scanning	O
data	O
.	O
To	O
this	O
end	O
,	O
we	O
present	O
a	O
3D	Method
convolutional	Method
neural	Method
network	Method
(	Method
ConvNet	Method
)	Method
,	O
called	O
3DMatch	Method
,	O
that	O
takes	O
in	O
the	O
local	O
volumetric	O
region	O
(	O
or	O
3D	O
patch	O
)	O
around	O
an	O
arbitrary	O
interest	O
point	O
on	O
a	O
3D	O
surface	O
and	O
computes	O
a	O
feature	Method
descriptor	Method
for	O
that	O
point	O
,	O
where	O
a	O
smaller	O
distance	O
between	O
two	O
descriptors	O
indicates	O
a	O
higher	O
likelihood	O
of	O
correspondence	O
.	O
However	O
,	O
optimizing	O
a	O
3D	Method
ConvNet	Method
-	Method
based	Method
descriptor	Method
for	O
this	O
task	O
requires	O
massive	O
amounts	O
of	O
training	O
data	O
(	O
i.e.	O
,	O
1	O
Figure	O
2	O
.	O
Learning	O
3DMatch	Method
from	O
reconstructions	O
.	O
From	O
existing	O
RGB	Material
-	Material
D	Material
reconstructions	Material
(	O
a	O
)	O
,	O
we	O
extract	O
local	O
3D	O
patches	O
and	O
correspondence	O
labels	O
from	O
scans	O
of	O
different	O
views	O
(	O
b	O
)	O
.	O
We	O
collect	O
pairs	O
of	O
matching	O
and	O
non	O
-	O
matching	O
local	O
3D	O
patches	O
and	O
convert	O
into	O
a	O
volumetric	Method
representation	Method
(	O
c	O
)	O
to	O
train	O
a	O
3D	Method
ConvNet	Method
-	Method
based	Method
descriptor	Method
(	O
d	O
)	O
.	O
This	O
geometric	Method
descriptor	Method
can	O
be	O
used	O
to	O
establish	O
correspondences	O
for	O
matching	Task
3D	Task
geometry	Task
in	O
various	O
applications	O
(	O
e	O
)	O
such	O
as	O
reconstruction	Task
,	O
model	Task
alignment	Task
,	O
and	O
surface	Task
correspondence	Task
.	O
ground	O
truth	O
matches	O
between	O
local	O
3D	O
patches	O
)	O
.	O
Obtaining	O
this	O
training	O
data	O
with	O
manual	O
annotations	O
is	O
a	O
challenging	O
endeavor	O
.	O
Unlike	O
2D	Task
image	Task
labels	Task
,	O
which	O
can	O
be	O
effectively	O
crowd	O
-	O
sourced	O
or	O
parsed	O
from	O
the	O
web	O
,	O
acquiring	O
ground	O
truth	O
correspondences	O
by	O
manually	O
clicking	O
keypoint	O
pairs	O
on	O
3D	O
partial	O
data	O
is	O
not	O
only	O
time	O
consuming	O
but	O
also	O
prone	O
to	O
errors	O
.	O
Our	O
key	O
idea	O
is	O
to	O
amass	O
training	O
data	O
by	O
leveraging	O
correspondence	O
labels	O
found	O
in	O
existing	O
RGB	Material
-	Material
D	Material
scene	Material
reconstructions	Material
.	O
Due	O
to	O
the	O
importance	O
of	O
3D	Task
reconstructions	Task
,	O
there	O
has	O
been	O
much	O
research	O
on	O
designing	O
algorithms	O
and	O
systems	O
that	O
can	O
build	O
high	Task
-	Task
fidelity	Task
reconstructions	Task
from	O
RGB	Material
-	Material
D	Material
data	Material
[	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
.	O
Although	O
these	O
reconstructions	O
have	O
been	O
used	O
for	O
high	Task
-	Task
level	Task
reasoning	Task
about	Task
the	Task
environment	Task
[	O
reference	O
][	O
reference	O
]	O
,	O
it	O
is	O
often	O
overlooked	O
that	O
they	O
can	O
also	O
serve	O
as	O
a	O
massive	O
source	O
of	O
labeled	O
correspondences	O
between	O
surfaces	O
points	O
of	O
aligned	O
frames	O
.	O
By	O
training	O
on	O
correspondences	O
from	O
multiple	O
existing	O
RGB	Material
-	Material
D	Material
reconstruction	Material
datasets	Material
,	O
each	O
with	O
its	O
own	O
properties	O
of	O
sensor	O
noise	O
,	O
occlusion	O
patterns	O
,	O
variance	O
of	O
geometric	O
structures	O
,	O
and	O
variety	O
of	O
camera	O
viewpoints	O
,	O
we	O
can	O
optimize	O
3DMatch	Method
to	O
generalize	O
and	O
robustly	O
match	O
local	O
geometry	O
in	O
real	O
-	O
world	O
partial	O
3D	O
data	O
.	O
In	O
this	O
paper	O
,	O
we	O
train	O
3DMatch	Method
over	O
8	O
million	O
correspondences	O
from	O
a	O
collection	O
of	O
62	O
RGB	Material
-	Material
D	Material
scene	Material
reconstructions	Material
[	O
37	O
,	O
[	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
and	O
demonstrate	O
its	O
ability	O
to	O
match	O
3D	O
data	O
in	O
several	O
applications	O
.	O
Results	O
show	O
that	O
3DMatch	Method
is	O
considerably	O
better	O
than	O
state	O
-	O
ofthe	O
-	O
art	O
methods	O
at	O
matching	Task
keypoints	Task
,	O
and	O
outperforms	O
other	O
algorithms	O
for	O
geometric	Task
registration	Task
when	O
combined	O
with	O
standard	O
RANSAC	Material
.	O
Furthermore	O
,	O
we	O
demonstrate	O
that	O
3DMatch	Method
can	O
also	O
generalize	O
to	O
different	O
tasks	O
and	O
spatial	O
resolutions	O
.	O
For	O
example	O
,	O
we	O
utilize	O
3DMatch	Method
to	O
obtain	O
instance	Task
-	Task
level	Task
model	Task
alignments	Task
for	O
6D	Task
object	Task
pose	Task
estimation	Task
as	O
well	O
as	O
to	O
find	O
surface	Task
correspondences	Task
in	Task
3D	Task
meshes	Task
.	O
To	O
facilitate	O
further	O
research	O
in	O
the	O
area	O
of	O
3D	Task
keypoint	Task
matching	Task
and	O
geometric	Task
registration	Task
,	O
we	O
provide	O
a	O
correspondence	Task
matching	Task
benchmark	Task
as	O
well	O
as	O
a	O
surface	Method
registration	Method
benchmark	Method
similar	O
to	O
[	O
reference	O
]	O
,	O
but	O
with	O
real	O
-	O
world	O
scan	O
data	O
.	O
section	O
:	O
Related	O
Work	O
Learning	Task
local	Task
geometric	Task
descriptors	Task
for	O
matching	Task
3D	Task
data	Task
lies	O
at	O
the	O
intersection	O
of	O
computer	Task
vision	Task
and	Task
graphics	Task
.	O
We	O
briefly	O
review	O
the	O
related	O
work	O
in	O
both	O
domains	O
.	O
Hand	O
-	O
crafted	O
3D	Method
Local	Method
Descriptors	Method
.	O
Many	O
geometric	Method
descriptors	Method
have	O
been	O
proposed	O
including	O
Spin	Material
Images	Material
[	O
reference	O
]	O
,	O
Geometry	O
Histograms	O
[	O
reference	O
]	O
,	O
and	O
Signatures	Method
of	Method
Histograms	Method
[	O
reference	O
]	O
,	O
Feature	Method
Histograms	Method
[	O
reference	O
]	O
.	O
Many	O
of	O
these	O
descriptors	O
are	O
now	O
available	O
in	O
the	O
Point	Material
Cloud	Material
Library	Material
[	O
reference	O
]	O
.	O
While	O
these	O
methods	O
have	O
made	O
significant	O
progress	O
,	O
they	O
still	O
struggle	O
to	O
handle	O
noisy	O
,	O
low	O
-	O
resolution	O
,	O
and	O
incomplete	O
real	O
-	O
world	O
data	O
from	O
commodity	O
range	O
sensors	O
.	O
Furthermore	O
,	O
since	O
they	O
are	O
manually	O
designed	O
for	O
specific	O
applications	O
or	O
3D	O
data	O
types	O
,	O
it	O
is	O
often	O
difficult	O
for	O
them	O
to	O
generalize	O
to	O
new	O
data	O
modalities	O
.	O
The	O
goal	O
of	O
our	O
work	O
is	O
to	O
provide	O
a	O
new	O
local	Method
3D	Method
descriptor	Method
that	O
directly	O
learns	O
from	O
data	O
to	O
provide	O
more	O
robust	O
and	O
accurate	O
geometric	Task
feature	Task
matching	Task
results	O
in	O
a	O
variety	O
of	O
settings	O
.	O
Learned	O
2D	Method
Local	Method
Descriptors	Method
.	O
The	O
recent	O
availability	O
of	O
large	O
-	O
scale	O
labeled	O
image	O
data	O
has	O
opened	O
up	O
new	O
opportunities	O
to	O
use	O
data	Method
-	Method
driven	Method
approaches	Method
for	O
designing	O
2D	Task
local	Task
image	Task
patch	Task
descriptors	Task
.	O
For	O
instance	O
,	O
various	O
works	O
[	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
learn	O
non	O
-	O
linear	O
mappings	O
from	O
local	O
image	O
patches	O
to	O
feature	Method
descriptors	Method
.	O
Many	O
of	O
these	O
prior	O
works	O
are	O
trained	O
on	O
data	O
generated	O
from	O
multi	O
-	O
view	O
stereo	O
datasets	O
[	O
reference	O
]	O
.	O
However	O
,	O
in	O
addition	O
to	O
being	O
limited	O
to	O
2D	O
correspondences	O
on	O
images	O
,	O
multi	Task
-	Task
view	Task
stereo	Task
is	O
difficult	O
to	O
scale	O
up	O
in	O
practice	O
and	O
is	O
prone	O
to	O
error	Metric
from	O
missing	O
correspondences	O
on	O
textureless	O
or	O
non	O
-	O
Lambertian	O
surfaces	O
,	O
so	O
it	O
is	O
not	O
suitable	O
for	O
learning	O
a	O
3D	Method
surface	Method
descriptor	Method
.	O
A	O
more	O
recent	O
work	O
[	O
reference	O
]	O
uses	O
RGB	Material
-	Material
D	Material
reconstructions	Material
to	O
train	O
a	O
2D	Method
descriptor	Method
,	O
while	O
we	O
train	O
a	O
3D	Method
geometric	Method
descriptor	Method
.	O
Learned	O
3D	Method
Global	Method
Descriptors	Method
.	O
There	O
has	O
also	O
been	O
rapid	O
progress	O
in	O
learning	O
geometric	Task
representations	Task
on	O
3D	O
data	O
.	O
3D	Material
ShapeNets	Material
[	O
reference	O
]	O
introduced	O
3D	Method
deep	Method
learning	Method
for	O
modeling	Task
3D	Task
shapes	Task
,	O
and	O
several	O
recent	O
works	O
[	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
also	O
compute	O
deep	O
features	O
from	O
3D	O
data	O
for	O
the	O
task	O
of	O
object	Task
retrieval	Task
and	Task
classification	Task
.	O
While	O
these	O
works	O
are	O
inspiring	O
,	O
their	O
focus	O
is	O
centered	O
on	O
extracting	O
features	O
from	O
complete	O
3D	Method
object	Method
models	Method
at	O
a	O
global	O
level	O
.	O
In	O
contrast	O
,	O
our	O
descriptor	O
focuses	O
on	O
learning	O
geometric	O
features	O
for	O
real	O
-	O
world	O
RGB	Material
-	Material
D	Material
scanning	Material
data	Material
at	O
a	O
local	O
level	O
,	O
to	O
provide	O
more	O
robustness	O
when	O
dealing	O
with	O
partial	O
data	O
suffering	O
from	O
various	O
occlusion	O
patterns	O
and	O
viewpoint	O
differences	O
.	O
Learned	O
3D	Method
Local	Method
Descriptors	Method
.	O
More	O
closely	O
related	O
to	O
this	O
work	O
is	O
Guo	O
et	O
al	O
.	O
[	O
reference	O
]	O
,	O
which	O
uses	O
a	O
2D	Method
ConvNet	Method
descriptor	Method
to	O
match	O
local	O
geometric	O
features	O
for	O
mesh	Task
labeling	Task
.	O
However	O
,	O
their	O
approach	O
operates	O
only	O
on	O
synthetic	Task
and	Task
complete	Task
3D	Task
models	Task
,	O
while	O
using	O
ConvNets	Method
over	O
input	O
patches	O
of	O
concatenated	O
feature	O
vectors	O
that	O
do	O
not	O
have	O
any	O
kind	O
of	O
spatial	O
correlation	O
.	O
In	O
contrast	O
,	O
our	O
work	O
not	O
only	O
tackles	O
the	O
harder	O
problem	O
of	O
matching	Task
real	Task
-	Task
world	Task
partial	Task
3D	Task
data	Task
,	O
but	O
also	O
properly	O
leverages	O
3D	Method
ConvNets	Method
on	O
volumetric	O
data	O
in	O
a	O
spatially	O
coherent	O
way	O
.	O
Self	Method
-	Method
supervised	Method
Deep	Method
Learning	Method
.	O
Recently	O
,	O
there	O
has	O
been	O
significant	O
interest	O
in	O
learning	O
powerful	O
deep	Method
models	Method
using	O
automatically	O
-	O
obtained	O
labels	O
.	O
For	O
example	O
,	O
recent	O
works	O
show	O
that	O
the	O
temporal	O
information	O
from	O
videos	O
can	O
be	O
used	O
as	O
a	O
plentiful	O
source	O
of	O
supervision	O
to	O
learn	O
embeddings	Task
that	O
are	O
useful	O
for	O
various	O
tasks	O
[	O
reference	O
][	O
reference	O
]	O
.	O
Other	O
works	O
show	O
that	O
deep	O
features	O
learned	O
from	O
egomotion	O
supervision	O
perform	O
better	O
than	O
features	O
using	O
class	O
-	O
labels	O
as	O
supervision	O
for	O
many	O
tasks	O
[	O
reference	O
]	O
.	O
Analogous	O
to	O
these	O
recent	O
works	O
in	O
self	Method
-	Method
supervised	Method
learning	Method
,	O
our	O
method	O
of	O
extracting	Task
training	Task
data	Task
and	O
correspondence	O
labels	O
from	O
existing	O
RGB	Material
-	Material
D	Material
reconstructions	Material
online	O
is	O
fully	O
automatic	O
,	O
and	O
does	O
not	O
require	O
any	O
manual	O
labor	O
or	O
human	O
supervision	O
.	O
section	O
:	O
Learning	Task
From	Task
Reconstructions	Task
In	O
this	O
paper	O
,	O
our	O
goal	O
is	O
to	O
create	O
a	O
function	Method
ψ	Method
that	O
maps	O
the	O
local	O
volumetric	O
region	O
(	O
or	O
3D	O
patch	O
)	O
around	O
a	O
point	O
on	O
a	O
3D	O
surface	O
to	O
a	O
descriptor	O
vector	O
.	O
Given	O
any	O
two	O
points	O
,	O
an	O
ideal	Method
function	Method
ψ	Method
maps	O
their	O
local	O
3D	O
patches	O
to	O
two	O
descriptors	O
,	O
where	O
a	O
smaller	O
2	O
distance	O
between	O
the	O
descriptors	O
indicates	O
a	O
higher	O
likelihood	O
of	O
correspondence	O
.	O
We	O
learn	O
the	O
function	Method
ψ	Method
by	O
making	O
use	O
of	O
data	O
from	O
existing	O
high	O
quality	O
RGB	Material
-	Material
D	Material
scene	Material
reconstructions	Material
.	O
The	O
advantage	O
of	O
this	O
approach	O
is	O
threefold	O
:	O
First	O
,	O
reconstruction	O
datasets	O
can	O
provide	O
large	O
amounts	O
of	O
training	O
correspondences	O
since	O
each	O
reconstruction	O
contains	O
millions	O
of	O
points	O
that	O
are	O
observed	O
from	O
multiple	O
different	O
scanning	O
views	O
.	O
Each	O
observation	O
pair	O
provides	O
a	O
training	O
example	O
for	O
matching	Task
local	Task
geometry	Task
.	O
Between	O
different	O
observations	O
of	O
the	O
same	O
interest	O
point	O
,	O
its	O
local	O
3D	O
patches	O
can	O
look	O
very	O
different	O
due	O
to	O
sensor	O
noise	O
,	O
viewpoint	O
variance	O
,	O
and	O
occlusion	O
patterns	O
.	O
This	O
helps	O
to	O
provide	O
a	O
large	O
and	O
diverse	O
correspondence	O
training	O
set	O
.	O
Second	O
,	O
reconstructions	Method
can	O
leverage	O
domain	O
knowledge	O
such	O
as	O
temporal	O
information	O
and	O
well	O
-	O
engineered	O
global	Method
optimization	Method
methods	Method
,	O
which	O
can	O
facilitate	O
wide	Task
baseline	Task
registrations	Task
(	O
loop	O
closures	O
)	O
.	O
We	O
can	O
use	O
the	O
correspondences	O
from	O
these	O
challenging	O
registrations	Task
to	O
train	O
a	O
powerful	O
descriptor	Method
that	O
can	O
be	O
used	O
for	O
other	O
tasks	O
where	O
the	O
aforementioned	O
domain	O
knowledge	O
is	O
unavailable	O
.	O
Third	O
,	O
by	O
learning	O
from	O
multiple	O
reconstruction	O
datasets	O
,	O
we	O
can	O
optimize	O
3DMatch	Method
to	O
generalize	O
and	O
robustly	O
match	O
local	O
geometry	O
in	O
real	O
-	O
world	O
partial	O
3D	O
data	O
under	O
a	O
variety	O
of	O
conditions	O
.	O
Specifically	O
,	O
we	O
use	O
a	O
total	O
of	O
over	O
200	O
K	O
RGB	Material
-	Material
D	Material
images	Material
of	O
62	O
different	O
scenes	O
collected	O
from	O
Analysis	Material
-	Material
by	Material
-	Material
Synthesis	Material
[	O
37	O
]	O
,	O
7	Material
-	Material
Scenes	Material
[	O
reference	O
]	O
,	O
SUN3D	Material
[	O
reference	O
]	O
,	O
RGB	Material
-	Material
D	Material
Scenes	Material
v.2	O
[	O
reference	O
]	O
,	O
and	O
Halber	O
et	O
al	O
.	O
[	O
reference	O
]	O
.	O
54	O
scenes	O
are	O
used	O
for	O
training	O
and	O
8	O
scenes	O
for	O
testing	O
.	O
Each	O
of	O
the	O
reconstruction	O
datasets	O
are	O
captured	O
in	O
different	O
environments	O
with	O
different	O
local	O
geometries	O
at	O
varying	O
scales	O
and	O
built	O
with	O
different	O
reconstruction	Method
algorithms	Method
.	O
section	O
:	O
Generating	Task
Training	Task
Correspondences	Task
To	O
obtain	O
training	O
3D	O
patches	O
and	O
their	O
ground	O
truth	O
correspondence	O
labels	O
(	O
match	O
or	O
non	O
-	O
match	O
)	O
,	O
we	O
extract	O
local	O
3D	O
patches	O
from	O
different	O
scanning	O
views	O
around	O
interest	O
points	O
randomly	O
sampled	O
from	O
reconstructions	O
.	O
To	O
find	O
correspondences	O
for	O
an	O
interest	O
point	O
,	O
we	O
map	O
its	O
3D	O
position	O
in	O
the	O
reconstruction	O
into	O
all	O
RGB	Material
-	Material
D	Material
frames	Material
for	O
which	O
the	O
3D	O
point	O
lies	O
within	O
the	O
frame	O
's	O
camera	O
view	O
frustum	O
and	O
is	O
not	O
occluded	O
.	O
The	O
locations	O
of	O
the	O
cameras	O
from	O
which	O
the	O
RGB	Material
-	Material
D	Material
frames	Material
are	O
taken	O
are	O
enforced	O
to	O
be	O
at	O
least	O
1	O
m	O
apart	O
,	O
so	O
that	O
the	O
views	O
between	O
observation	O
pairs	O
are	O
sufficiently	O
wide	O
-	O
baselined	O
.	O
We	O
then	O
extract	O
two	O
local	O
3D	O
patches	O
around	O
the	O
interest	O
point	O
from	O
two	O
of	O
these	O
RGB	Material
-	Material
D	Material
frames	Material
,	O
and	O
use	O
them	O
as	O
a	O
matching	O
pair	O
.	O
To	O
obtain	O
nonmatching	O
pairs	O
,	O
we	O
extract	O
local	O
3D	O
patches	O
from	O
randomly	O
picked	O
depth	O
frames	O
of	O
two	O
interest	O
points	O
(	O
at	O
least	O
0.1	O
m	O
apart	O
)	O
randomly	O
sampled	O
from	O
the	O
surface	O
of	O
the	O
reconstruction	O
.	O
Each	O
local	Method
3D	Method
patch	Method
is	O
converted	O
into	O
a	O
volumetric	Method
representation	Method
as	O
described	O
in	O
Sec	O
.	O
4.1	O
.	O
Due	O
to	O
perturbations	O
from	O
depth	O
sensor	O
noise	O
and	O
imperfections	O
in	O
reconstruction	O
results	O
,	O
the	O
sampled	O
interest	O
points	O
and	O
their	O
surrounding	O
local	O
3D	O
patches	O
can	O
experience	O
some	O
minor	O
amounts	O
of	O
drift	O
.	O
We	O
see	O
this	O
jitter	O
as	O
an	O
opportunity	O
for	O
our	O
local	Method
descriptor	Method
to	O
learn	O
small	O
amounts	O
of	O
translation	O
invariance	O
.	O
Since	O
we	O
are	O
learning	O
from	O
RGB	Material
-	Material
D	Material
reconstruction	Material
datasets	Material
using	O
different	O
sensors	O
and	O
algorithms	O
,	O
the	O
jitter	O
is	O
not	O
consistent	O
,	O
which	O
enables	O
the	O
descriptor	O
to	O
generalize	O
and	O
be	O
more	O
robust	O
to	O
it	O
.	O
section	O
:	O
Learning	O
A	O
Local	Method
Geometric	Method
Descriptor	Method
We	O
use	O
a	O
3D	Method
ConvNet	Method
to	O
learn	O
the	O
mapping	O
from	O
a	O
volumetric	O
3D	O
patch	O
to	O
an	O
512	Method
-	Method
dimensional	Method
feature	Method
representation	Method
that	O
serves	O
as	O
the	O
descriptor	O
for	O
that	O
local	O
region	O
.	O
During	O
training	O
,	O
we	O
optimize	O
this	O
mapping	O
(	O
i.e.	O
,	O
updating	O
the	O
weights	O
of	O
the	O
ConvNet	Method
)	O
by	O
minimizing	O
the	O
2	O
distance	O
between	O
descriptors	O
generated	O
from	O
corresponding	O
interest	O
points	O
(	O
matches	O
)	O
,	O
and	O
maximize	O
the	O
2	O
distance	O
between	O
descriptors	O
generated	O
from	O
non	O
-	O
corresponding	O
interest	O
points	O
(	O
non	O
-	O
matches	O
)	O
.	O
This	O
is	O
equivalent	O
to	O
training	O
a	O
ConvNet	Method
with	O
two	O
streams	O
(	O
i.e.	O
,	O
Siamese	Method
Style	Method
ConvNets	Method
[	O
reference	O
]	O
)	O
that	O
takes	O
in	O
two	O
local	O
3D	O
patches	O
and	O
predicts	O
whether	O
or	O
not	O
they	O
correspond	O
to	O
each	O
other	O
.	O
section	O
:	O
3D	Method
Data	Method
Representation	Method
For	O
each	O
interest	O
point	O
,	O
we	O
first	O
extract	O
a	O
3D	Method
volumetric	Method
representation	Method
for	O
the	O
local	O
region	O
surrounding	O
it	O
.	O
Each	O
3D	O
region	O
is	O
converted	O
from	O
its	O
original	O
representation	O
(	O
surface	O
mesh	O
,	O
point	O
cloud	O
,	O
or	O
depth	O
map	O
)	O
into	O
a	O
volumetric	O
30	O
×	O
30	O
×	O
30	O
voxel	O
grid	O
of	O
Truncated	O
Distance	O
Function	O
(	O
TDF	O
)	O
values	O
.	O
Analogous	O
to	O
2D	O
pixel	O
image	O
patches	O
,	O
we	O
refer	O
to	O
these	O
TDF	Method
voxel	Method
grids	Method
as	O
local	O
3D	O
patches	O
.	O
In	O
our	O
experiments	O
,	O
these	O
local	O
3D	O
patches	O
spatially	O
span	O
0.3	O
m	O
[	O
reference	O
]	O
,	O
where	O
voxel	O
size	O
is	O
0.01	O
m	O
[	O
reference	O
]	O
.	O
The	O
voxel	O
grid	O
is	O
aligned	O
with	O
respect	O
to	O
the	O
camera	O
view	O
.	O
If	O
camera	O
information	O
is	O
unavailable	O
(	O
i.e.	O
for	O
pre	O
-	O
scanned	O
3D	O
models	O
)	O
,	O
the	O
voxel	O
grid	O
is	O
aligned	O
to	O
the	O
object	O
coordinates	O
.	O
The	O
TDF	O
value	O
of	O
each	O
voxel	O
indicates	O
the	O
distance	O
between	O
the	O
center	O
of	O
that	O
voxel	O
to	O
the	O
nearest	O
3D	O
surface	O
.	O
These	O
TDF	O
values	O
are	O
truncated	O
,	O
normalized	O
and	O
then	O
flipped	O
to	O
be	O
between	O
1	O
(	O
on	O
surface	O
)	O
and	O
0	O
(	O
far	O
from	O
surface	O
)	O
.	O
This	O
form	O
of	O
3D	Method
representation	Method
is	O
cross	O
-	O
compatible	O
with	O
3D	O
meshes	O
,	O
point	O
-	O
clouds	O
,	O
and	O
depth	O
maps	O
.	O
Analogous	O
to	O
2D	O
RGB	O
pixel	O
matrices	O
for	O
color	O
images	O
,	O
3D	O
TDF	O
voxel	O
grids	O
also	O
provide	O
a	O
natural	O
volumetric	O
encoding	O
of	O
3D	O
space	O
that	O
is	O
suitable	O
as	O
input	O
to	O
a	O
3D	Task
ConvNet	Task
.	O
The	O
TDF	Method
representation	Method
holds	O
several	O
advantages	O
over	O
its	O
signed	O
alternative	O
TSDF	Method
[	O
reference	O
]	O
,	O
which	O
encodes	O
occluded	O
space	O
(	O
values	O
near	O
-	O
1	O
)	O
in	O
addition	O
to	O
the	O
surface	O
(	O
values	O
near	O
0	O
)	O
and	O
free	O
space	O
(	O
values	O
near	O
1	O
)	O
.	O
By	O
removing	O
the	O
sign	O
,	O
the	O
TDF	Method
loses	O
the	O
distinction	O
between	O
free	O
space	O
and	O
occluded	O
space	O
,	O
but	O
gains	O
a	O
new	O
property	O
that	O
is	O
crucial	O
to	O
the	O
robustness	Metric
of	O
our	O
descriptor	O
on	O
partial	O
data	O
:	O
the	O
largest	O
gradients	O
between	O
voxel	O
values	O
are	O
concentrated	O
around	O
the	O
surfaces	O
rather	O
than	O
in	O
the	O
shadow	O
boundaries	O
between	O
free	O
space	O
and	O
occluded	O
space	O
.	O
Furthermore	O
,	O
the	O
TDF	Method
representation	Method
reduces	O
the	O
ambiguity	O
of	O
determining	O
what	O
is	O
occluded	O
space	O
on	O
3D	O
data	O
where	O
camera	O
view	O
is	O
unavailable	O
.	O
Figure	O
3	O
.	O
t	O
-	O
SNE	O
embedding	O
of	O
3DMatch	Method
descriptors	O
for	O
local	O
3D	O
patches	O
from	O
the	O
RedKitchen	O
test	O
scene	O
of	O
7	Material
-	Material
Scenes	Material
[	O
reference	O
]	O
.	O
This	O
embedding	O
suggests	O
that	O
our	O
3DMatch	Method
ConvNet	O
is	O
able	O
to	O
cluster	O
local	O
3D	O
patches	O
based	O
on	O
local	O
geometric	O
features	O
such	O
as	O
edges	O
(	O
a	O
,	O
f	O
)	O
,	O
planes	O
(	O
e	O
)	O
,	O
corners	O
(	O
c	O
,	O
d	O
)	O
,	O
and	O
other	O
geometric	O
structures	O
(	O
g	O
,	O
b	O
,	O
h	O
)	O
in	O
the	O
face	O
of	O
noisy	O
and	O
partial	O
data	O
.	O
section	O
:	O
Network	Method
Architecture	Method
3DMatch	Method
is	O
a	O
standard	O
3D	Method
ConvNet	Method
,	O
inspired	O
by	O
AlexNet	Method
[	O
reference	O
]	O
.	O
Given	O
a	O
30×30×30	O
TDF	O
voxel	O
grid	O
of	O
a	O
local	O
3D	O
patch	O
around	O
an	O
interest	O
point	O
,	O
we	O
use	O
eight	O
convolutional	Method
layers	Method
(	O
each	O
with	O
a	O
rectified	O
linear	O
unit	O
activation	O
function	O
for	O
nonlinearity	O
)	O
and	O
a	O
pooling	Method
layer	Method
to	O
compute	O
a	O
512	Method
-	Method
dimensional	Method
feature	Method
representation	Method
,	O
which	O
serves	O
as	O
the	O
feature	Method
descriptor	Method
.	O
Since	O
the	O
dimensions	O
of	O
the	O
initial	O
input	O
voxel	O
grid	O
are	O
small	O
,	O
we	O
only	O
include	O
one	O
layer	O
of	O
pooling	Method
to	O
avoid	O
a	O
substantial	O
loss	O
of	O
information	O
.	O
Convolution	O
parameters	O
are	O
shown	O
in	O
Fig	O
.	O
2	O
as	O
(	O
kernel	O
size	O
,	O
number	O
of	O
filters	O
)	O
.	O
section	O
:	O
Network	Method
Training	Method
During	O
training	Task
,	O
our	O
objective	O
is	O
to	O
optimize	O
the	O
local	O
descriptors	O
generated	O
by	O
the	O
ConvNet	Method
such	O
that	O
they	O
are	O
similar	O
for	O
3D	O
patches	O
corresponding	O
to	O
the	O
same	O
point	O
,	O
and	O
dissimilar	O
otherwise	O
.	O
To	O
this	O
end	O
,	O
we	O
train	O
our	O
ConvNet	Method
with	O
two	O
streams	O
in	O
a	O
Siamese	Method
fashion	Method
where	O
each	O
stream	O
independently	O
computes	O
a	O
descriptor	O
for	O
a	O
different	O
local	O
3D	O
patch	O
.	O
The	O
first	O
stream	O
takes	O
in	O
the	O
local	O
3D	O
patch	O
around	O
a	O
surface	O
point	O
p	O
1	O
,	O
while	O
the	O
second	O
stream	O
takes	O
in	O
a	O
second	O
local	O
3D	O
patch	O
around	O
a	O
surface	O
point	O
p	O
2	O
.	O
Both	O
streams	O
share	O
the	O
same	O
architecture	O
and	O
underlying	O
weights	O
.	O
We	O
use	O
the	O
2	O
norm	O
as	O
a	O
similarity	Metric
metric	Metric
between	O
descriptors	O
,	O
modeled	O
during	O
training	Method
with	O
the	O
contrastive	O
loss	O
function	O
[	O
reference	O
]	O
.	O
This	O
loss	O
minimizes	O
the	O
2	O
distance	O
between	O
descriptors	O
of	O
corresponding	O
3D	O
point	O
pairs	O
(	O
matches	O
)	O
,	O
while	O
pulling	O
apart	O
the	O
2	O
distance	O
between	O
descriptors	O
of	O
noncorresponding	O
3D	O
point	O
pairs	O
.	O
During	O
training	O
,	O
we	O
feed	O
the	O
network	O
with	O
a	O
balanced	O
1:1	O
ratio	O
of	O
matches	O
to	O
nonmatches	O
.	O
This	O
strategy	O
of	O
balancing	O
positives	O
and	O
negatives	O
has	O
shown	O
to	O
be	O
effective	O
for	O
efficiently	O
learning	O
discriminative	Task
descriptors	Task
[	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
.	O
Fig.3	O
shows	O
a	O
t	Method
-	Method
SNE	Method
embedding	Method
[	O
reference	O
]	O
of	O
local	O
3D	O
patches	O
based	O
on	O
their	O
3DMatch	Method
descriptors	O
,	O
which	O
demonstrates	O
the	O
ConvNet	Method
's	O
ability	O
to	O
clus	O
-	O
ter	O
local	O
3D	O
patches	O
based	O
on	O
their	O
geometric	O
structure	O
as	O
well	O
as	O
local	O
context	O
.	O
section	O
:	O
Evaluation	O
In	O
this	O
section	O
,	O
we	O
first	O
evaluate	O
how	O
well	O
our	O
learned	O
local	Method
3D	Method
descriptor	Method
(	O
3DMatch	Method
)	O
can	O
match	O
local	O
3D	O
patches	O
of	O
interest	O
point	O
pairs	O
(	O
Sec	O
.	O
5.1	O
)	O
.	O
We	O
then	O
evaluate	O
its	O
practical	O
use	O
as	O
part	O
of	O
geometric	Task
registration	Task
for	O
matching	Task
3D	Task
data	Task
in	O
several	O
applications	O
,	O
such	O
as	O
scene	Task
reconstruction	Task
(	O
Sec	O
.	O
5.2	O
)	O
and	O
6D	Task
object	Task
pose	Task
estimation	Task
(	O
Sec	O
.	O
5.3	O
)	O
.	O
section	O
:	O
Keypoint	Method
Matching	Method
Our	O
first	O
set	O
of	O
experiments	O
measure	O
the	O
quality	Metric
of	O
a	O
3D	Method
local	Method
descriptor	Method
by	O
testing	O
its	O
ability	O
to	O
distinguish	O
between	O
matching	O
and	O
non	O
-	O
matching	O
local	O
3D	O
patches	O
of	O
keypoint	O
pairs	O
.	O
Using	O
the	O
sampling	Method
algorithm	Method
described	O
in	O
Sec	O
.	O
3	O
,	O
we	O
construct	O
a	O
correspondence	Task
benchmark	Task
,	O
similar	O
to	O
the	O
Photo	Material
Tourism	Material
dataset	Material
[	O
reference	O
]	O
but	O
with	O
local	O
3D	O
patches	O
extracted	O
from	O
depth	O
frames	O
.	O
The	O
benchmark	O
contains	O
a	O
collection	O
of	O
30	O
,	O
000	O
3D	O
patches	O
,	O
with	O
a	O
1:1	O
ratio	O
between	O
matches	O
and	O
non	O
-	O
matches	O
.	O
As	O
in	O
[	O
reference	O
][	O
reference	O
]	O
,	O
our	O
evaluation	Metric
metric	Metric
is	O
the	O
false	Metric
-	Metric
positive	Metric
rate	Metric
(	O
error	Metric
)	O
at	O
95	O
%	O
recall	Metric
,	O
the	O
lower	O
the	O
better	O
.	O
What	O
's	O
the	O
benefit	O
of	O
3D	O
volumes	O
vs.	O
2D	Task
depth	Task
patches	Task
?	O
We	O
use	O
TDF	Method
voxel	Method
grids	Method
to	O
represent	O
3D	O
data	O
,	O
not	O
only	O
because	O
it	O
is	O
an	O
intermediate	Method
representation	Method
that	O
can	O
be	O
easily	O
converted	O
from	O
meshes	O
or	O
point	O
clouds	O
,	O
but	O
also	O
because	O
this	O
3D	Method
representation	Method
allows	O
reasoning	O
over	O
real	O
-	O
world	O
spatial	O
scale	O
and	O
occluded	O
regions	O
,	O
which	O
can	O
not	O
be	O
directly	O
encoded	O
in	O
2D	O
depth	O
patches	O
.	O
To	O
evaluate	O
the	O
advantages	O
of	O
this	O
3D	Method
TDF	Method
encoding	Method
over	O
2D	O
depth	O
,	O
we	O
train	O
a	O
variant	O
of	O
our	O
method	O
using	O
a	O
2D	Method
ConvNet	Method
on	O
depth	O
patches	O
.	O
The	O
depth	O
patches	O
are	O
extracted	O
from	O
a	O
0.3	O
m	O
3	O
crop	O
and	O
resized	O
to	O
64x64	O
patches	O
.	O
For	O
a	O
fair	O
comparison	O
,	O
the	O
architecture	O
of	O
the	O
2D	Method
ConvNet	Method
is	O
similar	O
to	O
our	O
3D	Method
ConvNet	Method
with	O
two	O
extra	O
convolution	O
layers	O
to	O
achieve	O
a	O
similar	O
number	O
of	O
parameters	O
as	O
the	O
3D	Method
ConvNet	Method
.	O
As	O
shown	O
in	O
Table	O
1	O
,	O
this	O
2D	Method
ConvNet	Method
yields	O
a	O
higher	O
error	Metric
rate	O
(	O
38.5	O
vs.	O
[	O
reference	O
]	O
section	O
:	O
.3	O
)	O
.	O
Should	O
we	O
use	O
a	O
metric	Method
network	Method
?	O
Recent	O
work	O
[	O
reference	O
]	O
proposes	O
the	O
joint	Method
learning	Method
of	O
a	O
descriptor	Method
and	Method
similarity	Method
metric	Method
with	O
ConvNets	Method
to	O
optimize	O
matching	Metric
accuracy	Metric
.	O
To	O
explore	O
this	O
idea	O
,	O
we	O
replace	O
our	O
contrastive	Method
loss	Method
layer	Method
with	O
three	O
fully	Method
connected	Method
layers	Method
,	O
followed	O
by	O
a	O
Softmax	Method
layer	Method
for	O
binary	Task
classification	Task
of	O
"	O
match	O
"	O
vs	O
"	O
non	O
-	O
match	O
"	O
.	O
We	O
evaluate	O
the	O
performance	O
of	O
this	O
network	O
on	O
our	O
keypoint	Task
matching	Task
benchmark	Task
,	O
where	O
we	O
see	O
an	O
error	Metric
of	O
33.1	O
%	O
(	O
2.2	O
%	O
improvement	O
)	O
.	O
However	O
,	O
as	O
noted	O
by	O
Yi	O
et	O
al	O
.	O
[	O
reference	O
]	O
,	O
descriptors	O
that	O
require	O
a	O
learned	O
metric	O
have	O
a	O
limited	O
range	O
of	O
applicability	O
due	O
to	O
the	O
O	O
(	O
n	O
2	O
)	O
comparison	Metric
behaviour	Metric
at	O
test	O
time	O
since	O
they	O
can	O
not	O
be	O
directly	O
combined	O
with	O
metric	Method
-	Method
based	Method
acceleration	Method
structures	Method
such	O
as	O
KD	Method
-	Method
trees	Method
.	O
To	O
maintain	O
runtime	O
within	O
practical	O
limits	O
,	O
we	O
use	O
the	O
version	O
of	O
3DMatch	Method
trained	O
with	O
an	O
2	O
metric	O
in	O
the	O
following	O
sections	O
.	O
section	O
:	O
Geometric	Task
Registration	Task
To	O
evaluate	O
the	O
practical	O
use	O
of	O
our	O
descriptor	O
,	O
we	O
combine	O
3DMatch	Method
with	O
a	O
RANSAC	Material
search	O
algorithm	O
for	O
geometric	Task
registration	Task
,	O
and	O
measure	O
its	O
performance	O
on	O
standard	O
benchmarks	O
.	O
More	O
specifically	O
,	O
given	O
two	O
3D	O
point	O
[	O
reference	O
]	O
.	O
Challenging	O
cases	O
of	O
loop	O
closures	O
from	O
test	O
scenes	O
of	O
SUN3D	Material
[	O
reference	O
]	O
.	O
In	O
these	O
instances	O
,	O
color	O
features	O
in	O
the	O
RGB	Material
images	Material
(	O
top	O
row	O
)	O
are	O
insufficient	O
for	O
registering	O
the	O
scan	O
pairs	O
due	O
to	O
drastic	O
viewpoint	O
differences	O
.	O
While	O
Rusu	O
et	O
al	O
.	O
[	O
reference	O
]	O
fails	O
at	O
aligning	O
the	O
pairs	O
(	O
middle	O
row	O
)	O
,	O
3DMatch	Method
is	O
able	O
to	O
successfully	O
align	O
each	O
pair	O
of	O
scans	O
(	O
bottom	O
row	O
)	O
by	O
matching	O
local	O
geometric	O
features	O
.	O
clouds	O
from	O
scanning	O
data	O
,	O
we	O
first	O
randomly	O
sample	O
n	O
keypoints	O
from	O
each	O
point	O
cloud	O
.	O
Using	O
the	O
local	O
3D	O
30	O
×	O
30	O
×	O
30	O
TDF	O
patches	O
around	O
each	O
keypoint	O
(	O
aligned	O
to	O
the	O
camera	O
axes	O
,	O
which	O
may	O
be	O
different	O
per	O
point	O
cloud	O
)	O
,	O
we	O
compute	O
3DMatch	Method
descriptors	O
for	O
all	O
2n	O
keypoints	O
.	O
We	O
find	O
keypoints	O
whose	O
descriptors	O
are	O
mutually	O
closest	O
to	O
each	O
other	O
in	O
Euclidean	O
space	O
,	O
and	O
use	O
RANSAC	Material
over	O
the	O
3D	O
positions	O
of	O
these	O
keypoint	O
matches	O
to	O
estimate	O
a	O
rigid	O
transformation	O
between	O
the	O
two	O
point	O
clouds	O
.	O
section	O
:	O
Matching	Task
Local	Task
Geometry	Task
in	Task
Scenes	Task
We	O
evaluate	O
our	O
3DMatch	Method
-	O
based	O
geometric	O
registration	O
algorithm	O
(	O
i.e.	O
,	O
3DMatch	Method
+	O
RANSAC	Material
)	O
on	O
both	O
real	O
and	O
synthetic	O
datasets	O
.	O
For	O
synthetic	O
,	O
we	O
use	O
the	O
benchmark	O
from	O
Choi	O
et	O
al	O
.	O
[	O
reference	O
]	O
which	O
contains	O
207	O
fragments	O
(	O
each	O
fused	O
from	O
50	O
depth	O
frames	O
)	O
of	O
four	O
scenes	O
from	O
the	O
ICL	Material
-	Material
NUIM	Material
dataset	Material
[	O
reference	O
]	O
.	O
However	O
,	O
the	O
duplicated	O
and	O
over	O
-	O
simplified	O
geometry	O
in	O
this	O
ICL	Material
-	Material
NUIM	Material
dataset	Material
is	O
very	O
different	O
from	O
that	O
of	O
real	O
-	O
world	O
scenes	O
.	O
Therefore	O
,	O
we	O
create	O
a	O
separate	O
benchmark	O
with	O
fragments	O
formed	O
from	O
the	O
testing	O
split	O
of	O
our	O
real	O
-	O
world	O
reconstruction	O
datasets	O
.	O
We	O
use	O
the	O
same	O
evaluation	O
scheme	O
introduced	O
by	O
Choi	O
et	O
al	O
.	O
[	O
reference	O
]	O
,	O
measuring	O
the	O
recall	Metric
and	O
precision	Metric
of	O
a	O
method	O
based	O
on	O
two	O
factors	O
:	O
(	O
1	O
)	O
how	O
well	O
it	O
finds	O
loop	O
closures	O
,	O
and	O
(	O
2	O
)	O
how	O
well	O
it	O
estimates	O
rigid	O
transformation	O
matrices	O
.	O
Given	O
two	O
nonconsecutive	O
scene	O
fragments	O
(	O
P	O
i	O
,	O
P	O
j	O
)	O
,	O
the	O
predicted	O
relative	O
rigid	O
transformation	O
T	O
ij	O
is	O
a	O
true	O
positive	O
if	O
(	O
1	O
)	O
over	O
30	O
%	O
of	O
T	O
ij	O
P	O
i	O
overlaps	O
with	O
P	O
j	O
and	O
if	O
(	O
2	O
)	O
T	O
ij	O
is	O
sufficiently	O
close	O
to	O
the	O
ground	O
-	O
truth	O
transformation	O
T	O
*	O
ij	O
.	O
T	O
ij	O
is	O
correct	O
if	O
it	O
brings	O
the	O
RMSE	O
of	O
the	O
ground	O
truth	O
correspondences	O
K	O
*	O
ij	O
between	O
P	O
i	O
and	O
P	O
j	O
below	O
a	O
threshold	O
τ	O
=	O
0.2	O
where	O
p	O
*	O
q	O
*	O
are	O
the	O
ground	O
truth	O
correspondences	O
.	O
Since	O
the	O
benchmark	O
from	O
Choi	O
et	O
al	O
.	O
[	O
reference	O
]	O
uses	O
fragments	O
fused	O
from	O
multiple	O
depth	O
frames	O
,	O
we	O
fine	O
-	O
tune	O
our	O
3DMatch	Method
ConvNet	O
on	O
correspondences	O
over	O
a	O
set	O
of	O
fragments	O
constructed	O
in	O
the	O
same	O
way	O
using	O
the	O
7	Material
-	Material
scenes	Material
training	Material
set	Material
.	O
We	O
then	O
run	O
pairwise	Method
geometric	Method
registration	Method
with	O
3DMatch	Method
+	O
RANSAC	Material
on	O
every	O
pair	O
of	O
fragments	O
from	O
the	O
benchmarks	O
.	O
We	O
compare	O
the	O
performance	O
of	O
our	O
3DMatch	Method
-	O
based	O
registration	O
approach	O
versus	O
other	O
state	O
-	O
ofthe	O
-	O
art	O
geometric	Method
registration	Method
methods	Method
on	O
the	O
synthetic	O
data	O
benchmark	O
in	O
Table	O
2	O
[	O
reference	O
]	O
,	O
and	O
the	O
real	O
data	O
benchmark	O
in	O
Table	O
3	O
.	O
We	O
also	O
compare	O
with	O
Rusu	O
et	O
al	O
.	O
[	O
reference	O
]	O
and	O
Johnson	O
et	O
al	O
.	O
[	O
reference	O
]	O
using	O
the	O
same	O
RANSAC	Material
-	O
based	O
pipeline	O
.	O
Overall	O
,	O
our	O
descriptor	O
with	O
RANSAC	Material
outperforms	O
other	O
methods	O
by	O
a	O
significant	O
margin	O
on	O
both	O
datasets	O
.	O
section	O
:	O
Method	Metric
Recall	Metric
(	O
%	O
)	O
Precision	Metric
(	O
%	O
)	O
Drost	O
et	O
al	O
.	O
[	O
reference	O
]	O
5.3	O
1.6	O
Mellado	O
et	O
al	O
.	O
[	O
reference	O
]	O
17.8	O
10.4	O
Rusu	O
et	O
al	O
.	O
[	O
reference	O
]	O
44.9	O
14.0	O
Choi	O
et	O
al	O
.	O
[	O
reference	O
]	O
59	O
Table	O
3	O
.	O
Performance	O
of	O
geometric	Method
registration	Method
algorithms	Method
between	O
fused	O
fragments	O
of	O
real	O
-	O
world	O
scans	O
.	O
Figure	O
6	O
.	O
3DMatch	Method
for	O
reconstructions	Task
.	O
On	O
the	O
left	O
,	O
we	O
show	O
a	O
complete	O
reconstruction	O
of	O
an	O
apartment	O
from	O
SUN3D	Material
[	O
reference	O
]	O
using	O
only	O
3DMatch	Method
.	O
On	O
the	O
right	O
,	O
we	O
show	O
two	O
reconstructions	O
using	O
only	O
SIFT	O
to	O
match	O
color	O
features	O
(	O
top	O
)	O
,	O
using	O
only	O
3DMatch	Method
to	O
match	O
geometric	O
features	O
(	O
middle	O
)	O
,	O
and	O
using	O
both	O
SIFT	Method
and	O
3DMatch	Method
(	O
bottom	O
)	O
.	O
The	O
red	O
boxes	O
highlight	O
areas	O
with	O
poor	O
reconstruction	Metric
quality	Metric
,	O
while	O
the	O
green	O
boxes	O
highlight	O
areas	O
with	O
improved	O
quality	O
.	O
These	O
examples	O
show	O
that	O
3DMatch	Method
provides	O
strong	O
geometric	O
feature	O
correspondences	O
that	O
are	O
complementary	O
to	O
color	O
features	O
and	O
can	O
help	O
to	O
improve	O
the	O
quality	O
of	O
reconstructions	Task
.	O
section	O
:	O
Integrate	O
3DMatch	Method
in	O
Reconstruction	Task
Pipeline	Task
.	O
In	O
this	O
section	O
,	O
we	O
show	O
that	O
3DMatch	Method
is	O
not	O
only	O
capable	O
of	O
detecting	Task
challenging	Task
cases	Task
of	Task
loop	Task
closure	Task
,	O
but	O
also	O
can	O
be	O
used	O
in	O
a	O
standard	O
reconstruction	Method
pipeline	Method
to	O
generate	O
highquality	Task
reconstructions	Task
of	Task
new	Task
scenes	Task
.	O
We	O
use	O
our	O
3DMatch	Method
descriptor	O
as	O
part	O
of	O
a	O
standard	O
sparse	Method
bundle	Method
adjustment	Method
formulation	Method
for	O
scene	Task
reconstruction	Task
[	O
reference	O
][	O
reference	O
]	O
.	O
Traditionally	O
,	O
sparse	O
RGB	O
features	O
,	O
such	O
as	O
SIFT	Method
or	O
SURF	Method
,	O
are	O
used	O
to	O
establish	O
feature	O
matches	O
between	O
frames	O
.	O
With	O
3DMatch	Method
,	O
we	O
are	O
able	O
to	O
establish	O
keypoint	O
matches	O
from	O
geometric	O
information	O
and	O
add	O
to	O
the	O
bundle	Method
adjustment	Method
step	Method
.	O
With	O
this	O
simple	O
pipeline	O
we	O
are	O
able	O
to	O
generate	O
globally	Task
-	Task
consistent	Task
alignments	Task
in	Task
challenging	Task
scenes	Task
using	O
only	O
geometric	O
information	O
as	O
shown	O
in	O
Fig	O
.	O
6	O
.	O
We	O
also	O
find	O
that	O
color	O
and	O
depth	O
provide	O
complementary	O
information	O
for	O
RGB	Material
-	Material
D	Material
reconstructions	Material
.	O
For	O
example	O
,	O
sparse	O
RGB	O
features	O
can	O
provide	O
correspondences	O
where	O
there	O
is	O
insufficient	O
geometric	O
information	O
in	O
the	O
scans	O
,	O
while	O
geometric	O
signals	O
are	O
helpful	O
where	O
there	O
are	O
drastic	O
viewpoint	O
or	O
lighting	O
changes	O
that	O
cause	O
traditional	O
RGB	O
features	O
to	O
fail	O
.	O
Fig	O
.	O
5	O
shows	O
challenging	O
cases	O
of	O
loop	O
closure	O
from	O
the	O
testing	O
split	O
of	O
the	O
SUN3D	Material
datasets	Material
that	O
are	O
difficult	O
for	O
color	Method
-	Method
based	Method
descriptors	Method
to	O
find	O
correspondences	O
due	O
to	O
drastic	O
viewpoint	O
differences	O
.	O
Our	O
3DMatch	Method
-	O
based	O
registration	O
algorithm	O
is	O
capable	O
of	O
matching	O
the	O
local	O
geometry	O
to	O
find	O
correspondences	O
and	O
bring	O
the	O
scans	O
into	O
alignment	O
.	O
In	O
Fig	O
.	O
6	O
,	O
we	O
show	O
several	O
reconstruction	Task
results	O
where	O
combining	O
correspondences	O
from	O
both	O
SIFT	O
(	O
color	O
)	O
and	O
3DMatch	Method
(	O
geometry	O
)	O
improves	O
alignment	Metric
quality	Metric
as	O
a	O
whole	O
.	O
section	O
:	O
Can	O
3DMatch	Method
generalize	O
to	O
new	O
domains	O
?	O
As	O
a	O
final	O
test	O
,	O
we	O
evaluate	O
the	O
ability	O
of	O
our	O
3DMatch	Method
descriptor	O
,	O
which	O
is	O
trained	O
from	O
3D	Task
reconstructions	Task
,	O
to	O
generalize	O
to	O
completely	O
different	O
tasks	O
and	O
spatial	O
scales	O
;	O
namely	O
,	O
6D	Task
object	Task
pose	Task
estimation	Task
by	O
model	Task
alignment	Task
and	O
correspondence	Task
labeling	Task
for	O
3D	Task
meshes	Task
.	O
section	O
:	O
6D	O
Object	Task
Pose	Task
Estimation	Task
by	O
model	Task
alignment	Task
.	O
In	O
our	O
first	O
experiment	O
,	O
the	O
task	O
is	O
to	O
register	O
pre	O
-	O
scanned	O
object	Method
models	Method
to	O
RGB	Material
-	Material
D	Material
scanning	Material
data	Material
for	O
the	O
Shelf	Material
&	Material
Tote	Material
benchmark	Material
in	O
the	O
Amazon	Material
Picking	Material
Challenge	Material
(	O
APC	O
)	O
setting	O
[	O
reference	O
]	O
,	O
as	O
illustrated	O
in	O
Fig	O
.	O
7	O
.	O
This	O
scenario	O
is	O
different	O
from	O
scene	Task
level	Task
reconstruction	Task
in	O
the	O
following	O
two	O
aspects	O
:	O
(	O
1	O
)	O
object	O
sizes	O
and	O
their	O
geometric	O
features	O
are	O
much	O
smaller	O
in	O
scale	O
and	O
(	O
2	O
)	O
the	O
alignment	Task
here	O
is	O
from	O
full	Method
pre	Method
-	Method
scanned	Method
models	Method
to	O
partial	O
scan	O
data	O
,	O
instead	O
of	O
partial	O
scans	O
to	O
partial	O
scans	O
.	O
section	O
:	O
Method	O
Rotation	O
(	O
%	O
)	O
Translation	O
(	O
%	O
)	O
Baseline	O
[	O
reference	O
]	O
49.0	O
67	O
.	O
To	O
account	O
for	O
spatial	O
scale	O
differences	O
,	O
we	O
reduce	O
the	O
size	O
of	O
each	O
voxel	O
to	O
0.005	O
m	O
3	O
within	O
the	O
local	O
3D	O
patches	O
.	O
The	O
voxel	O
grids	O
from	O
the	O
object	Method
models	Method
are	O
aligned	O
with	O
respect	O
to	O
the	O
object	O
model	O
's	O
coordinates	O
axes	O
,	O
while	O
the	O
voxel	O
grids	O
from	O
the	O
scans	O
are	O
aligned	O
to	O
the	O
camera	O
axes	O
.	O
We	O
use	O
the	O
3DMatch	Method
network	O
pre	O
-	O
trained	O
on	O
reconstructions	Method
,	O
and	O
fine	O
-	O
tune	O
it	O
on	O
a	O
50	O
%	O
training	O
split	O
of	O
the	O
Shelf	Material
&	Material
Tote	Material
data	Material
.	O
Similar	O
to	O
how	O
we	O
align	O
scene	O
fragments	O
to	O
each	O
other	O
in	O
Sec	O
.	O
5.2	O
,	O
we	O
use	O
a	O
RANSAC	Material
based	O
geometric	O
registration	O
approach	O
to	O
align	O
the	O
object	Method
models	Method
to	O
scans	O
.	O
The	O
predicted	O
rigid	O
transformation	O
is	O
used	O
as	O
object	O
pose	O
.	O
Similar	O
to	O
the	O
baseline	O
approach	O
,	O
we	O
perform	O
model	Method
alignment	Method
between	O
object	Method
models	Method
to	O
segmentation	Task
results	O
from	O
[	O
reference	O
]	O
.	O
We	O
evaluate	O
on	O
the	O
testing	O
split	O
of	O
the	O
Shelf	Material
&	Material
Tote	Material
dataset	Material
using	O
the	O
error	Metric
metric	O
from	O
[	O
reference	O
]	O
,	O
where	O
we	O
report	O
the	O
percentage	O
of	O
pose	O
predictions	O
with	O
error	Metric
in	O
orientation	O
smaller	O
than	O
15	O
•	O
and	O
translations	O
smaller	O
than	O
5	O
cm	O
.	O
We	O
compare	O
to	O
the	O
baseline	O
approach	O
for	O
the	O
Shelf	Task
&	Task
Tote	Task
benchmark	Task
,	O
as	O
well	O
as	O
to	O
other	O
approaches	O
in	O
Table	O
4	O
.	O
Several	O
of	O
our	O
predictions	O
are	O
illustrated	O
in	O
Fig	O
.	O
8	O
.	O
Our	O
descriptor	O
significantly	O
outperforms	O
the	O
baseline	O
approach	O
with	O
over	O
10	O
%	O
improvement	O
in	O
rotation	Metric
prediction	Metric
accuracy	Metric
and	O
other	O
registration	Metric
variants	Metric
.	O
The	O
3DMatch	Method
model	O
without	O
pre	Method
-	Method
training	Method
on	O
reconstructions	Method
yields	O
a	O
lower	O
performance	O
,	O
demonstrating	O
the	O
importance	O
of	O
pre	O
-	O
training	O
on	O
reconstruction	O
data	O
.	O
Surface	Task
Correspondence	Task
on	O
3D	Material
meshes	Material
.	O
In	O
our	O
final	O
experiment	O
,	O
we	O
test	O
3DMatch	Method
's	O
ability	O
to	O
generalize	O
even	O
further	O
to	O
other	O
modalities	O
.	O
We	O
take	O
a	O
3DMatch	Method
model	O
trained	O
on	O
RGB	Material
-	Material
D	Material
reconstruction	Material
data	Material
,	O
and	O
directly	O
test	O
it	O
on	O
3D	Method
mesh	Method
models	Method
without	O
any	O
fine	O
-	O
tuning	O
to	O
see	O
whether	O
[	O
reference	O
]	O
.	O
Surface	O
correspondences	O
on	O
3D	O
meshes	O
.	O
The	O
first	O
column	O
shows	O
the	O
input	O
mesh	O
and	O
query	O
points	O
(	O
red	O
and	O
blue	O
)	O
.	O
The	O
other	O
columns	O
show	O
the	O
respective	O
correspondences	O
found	O
in	O
other	O
meshes	O
of	O
the	O
same	O
object	O
category	O
(	O
top	O
and	O
middle	O
row	O
)	O
and	O
across	O
different	O
object	O
categories	O
(	O
bottom	O
row	O
)	O
.	O
3DMatch	Method
is	O
able	O
to	O
find	O
surface	Task
correspondences	Task
based	O
on	O
local	O
geometry	O
.	O
Given	O
a	O
query	O
point	O
on	O
the	O
surface	O
of	O
a	O
3D	O
mesh	O
,	O
the	O
goal	O
is	O
to	O
find	O
geometrically	O
similar	O
points	O
on	O
a	O
second	O
mesh	O
(	O
e.g.	O
for	O
transferring	O
annotations	O
about	O
human	O
contact	O
points	O
[	O
reference	O
]	O
)	O
.	O
We	O
do	O
this	O
by	O
first	O
encoding	O
the	O
local	O
volumetric	O
regions	O
(	O
with	O
size	O
0.3	O
m	O
3	O
)	O
of	O
the	O
query	O
point	O
from	O
the	O
first	O
mesh	O
and	O
all	O
surface	O
points	O
from	O
the	O
second	O
mesh	O
into	O
TDF	O
volume	O
aligned	O
to	O
object	O
coordinate	O
,	O
and	O
compute	O
their	O
3DMatch	Method
descriptors	O
.	O
For	O
every	O
surface	O
point	O
on	O
the	O
second	O
mesh	O
,	O
we	O
color	O
it	O
with	O
intensity	O
based	O
on	O
its	O
descriptor	O
's	O
2	O
distance	O
to	O
the	O
descriptor	O
of	O
the	O
query	O
point	O
.	O
Fig	O
.	O
9	O
shows	O
results	O
on	O
meshes	O
from	O
the	O
Shape2Pose	Material
dataset	Material
[	O
reference	O
]	O
.	O
The	O
results	O
demonstrate	O
that	O
without	O
any	O
fine	O
-	O
tuning	O
on	O
the	O
mesh	O
data	O
,	O
3DMatch	Method
can	O
be	O
used	O
as	O
a	O
general	O
3D	Method
shape	Method
descriptor	Method
to	O
find	O
correspondences	O
with	O
similar	O
local	O
geometry	O
between	O
meshes	O
.	O
Interestingly	O
3DMatch	Method
is	O
also	O
able	O
to	O
find	O
geometric	O
correspondences	O
across	O
different	O
object	O
categories	O
.	O
For	O
example	O
in	O
the	O
third	O
row	O
of	O
Fig	O
.	O
9	O
,	O
3DMatch	Method
is	O
able	O
to	O
match	O
the	O
handles	O
in	O
very	O
different	O
meshes	O
.	O
section	O
:	O
Conclusion	O
In	O
this	O
work	O
,	O
we	O
presented	O
3DMatch	Method
,	O
a	O
3D	Method
ConvNetbased	Method
local	Method
geometric	Method
descriptor	Method
that	O
can	O
be	O
used	O
to	O
match	O
partial	Material
3D	Material
data	Material
for	O
a	O
variety	O
of	O
applications	O
.	O
We	O
demonstrated	O
that	O
by	O
leveraging	O
the	O
vast	O
amounts	O
of	O
correspondences	O
automatically	O
obtained	O
from	O
RGB	Material
-	Material
D	Material
reconstructions	Material
,	O
we	O
can	O
train	O
a	O
powerful	O
descriptor	O
that	O
outperforms	O
existing	O
geometric	Method
descriptors	Method
by	O
a	O
significant	O
margin	O
.	O
We	O
make	O
all	O
code	O
and	O
pre	O
-	O
trained	Method
models	Method
available	O
for	O
easy	O
use	O
and	O
integration	O
.	O
To	O
encourage	O
further	O
research	O
,	O
we	O
also	O
provide	O
a	O
correspondence	Task
matching	Task
benchmark	Task
and	O
a	O
surface	Task
registration	Task
benchmark	Task
,	O
both	O
with	O
real	O
-	O
world	O
3D	O
data	O
.	O
section	O
:	O
A.	O
Appendix	O
In	O
this	O
section	O
,	O
we	O
present	O
several	O
statistics	O
of	O
the	O
RGB	Material
-	Material
D	Material
reconstruction	Material
datasets	Material
used	O
to	O
generate	O
training	O
correspondences	O
for	O
3DMatch	Method
,	O
the	O
implementation	O
details	O
of	O
our	O
network	O
,	O
and	O
run	Metric
-	Metric
time	Metric
statistics	Metric
relevant	O
to	O
the	O
experiments	O
discussed	O
in	O
the	O
main	O
paper	O
.	O
section	O
:	O
A.1	O
.	O
RGB	Material
-	Material
D	Material
Reconstruction	Material
Datasets	Material
As	O
mentioned	O
in	O
Sec	O
.	O
3	O
of	O
the	O
main	O
paper	O
,	O
we	O
use	O
registered	O
depth	O
frames	O
of	O
62	O
different	O
real	O
-	O
world	O
scenes	O
collected	O
from	O
Analysis	Material
-	Material
by	Material
-	Material
Synthesis	Material
[	O
37	O
]	O
,	O
7	Material
-	Material
Scenes	Material
[	O
reference	O
]	O
,	O
SUN3D	Material
[	O
reference	O
]	O
,	O
RGB	Material
-	Material
D	Material
Scenes	Material
v.2	O
[	O
reference	O
]	O
,	O
and	O
Halber	O
et	O
al	O
.	O
[	O
reference	O
]	O
,	O
with	O
54	O
scenes	O
for	O
training	O
and	O
8	O
scenes	O
for	O
testing	O
.	O
For	O
selected	O
scenes	O
of	O
the	O
SUN3D	Material
dataset	Material
,	O
we	O
use	O
the	O
method	O
from	O
Halber	O
et	O
al	O
.	O
to	O
estimate	O
camera	O
poses	O
.	O
For	O
the	O
precise	O
train	O
/	O
test	O
scene	O
splits	O
,	O
see	O
our	O
project	O
webpage	O
.	O
In	O
Fig	O
.	O
11	O
,	O
we	O
show	O
top	O
-	O
down	O
views	O
of	O
the	O
completed	O
reconstructions	O
.	O
They	O
are	O
diverse	O
in	O
the	O
environments	O
they	O
capture	O
,	O
with	O
local	O
geometries	O
at	O
varying	O
scales	O
,	O
which	O
provide	O
a	O
diverse	O
surface	O
correspondence	O
training	O
set	O
for	O
3DMatch	Method
.	O
In	O
total	O
,	O
there	O
are	O
214	O
,	O
569	O
depth	O
frames	O
over	O
the	O
54	O
training	O
scenes	O
,	O
most	O
of	O
which	O
are	O
made	O
up	O
of	O
indoor	O
bedrooms	O
,	O
offices	O
,	O
living	O
rooms	O
,	O
tabletops	O
,	O
and	O
restrooms	O
.	O
The	O
depth	O
sensors	O
used	O
for	O
scanning	Task
include	O
the	O
Microsoft	O
Kinect	O
,	O
Structure	Method
Sensor	Method
,	O
Asus	Method
Xtion	Method
Pro	Method
Live	Method
,	O
and	O
Intel	Method
RealSense	Method
.	O
The	O
size	O
of	O
the	O
correspondence	Metric
training	Metric
set	Metric
correlates	O
with	O
the	O
amount	O
of	O
overlap	O
between	O
visible	O
surfaces	O
from	O
different	O
scanning	O
views	O
.	O
In	O
Fig	O
.	O
10	O
,	O
we	O
show	O
the	O
average	O
distribution	O
of	O
volumetric	O
voxels	O
(	O
size	O
0.02	O
3	O
m	O
)	O
on	O
the	O
surface	O
vs.	O
the	O
number	O
of	O
frames	O
in	O
which	O
the	O
voxels	O
were	O
seen	O
by	O
the	O
depth	O
sensor	O
.	O
We	O
plot	O
this	O
distribution	O
averaged	O
over	O
the	O
54	O
training	O
scenes	O
(	O
left	O
)	O
and	O
illustrate	O
a	O
heat	O
map	O
of	O
over	O
two	O
example	O
reconstructions	O
(	O
right	O
)	O
,	O
where	O
a	O
warmer	O
region	O
implies	O
that	O
the	O
area	O
has	O
been	O
seen	O
more	O
times	O
.	O
The	O
camera	O
trajectories	O
are	O
plotted	O
with	O
a	O
red	O
line	O
.	O
section	O
:	O
A.2	O
.	O
Implementation	O
Details	O
We	O
implement	O
the	O
3DMatch	Method
network	O
architecture	O
in	O
Marvin	Method
[	O
reference	O
]	O
,	O
a	O
lightweight	Method
GPU	Method
deep	Method
learning	Method
framework	Method
that	O
supports	O
3D	Method
convolutional	Method
neural	Method
networks	Method
.	O
Weights	O
of	O
the	O
network	O
are	O
initialized	O
with	O
the	O
Xavier	Method
algorithm	Method
[	O
reference	O
]	O
,	O
and	O
biases	O
are	O
initialized	O
to	O
0	O
.	O
We	O
train	O
by	O
SGD	Method
with	O
momentum	Method
using	O
a	O
fixed	O
learning	Metric
rate	Metric
of	O
10	O
-	O
3	O
,	O
a	O
momentum	O
of	O
0.99	O
,	O
and	O
weight	O
decay	O
of	O
5	O
[	O
reference	O
]	O
.	O
Random	Method
sampling	Method
matching	Method
and	O
non	Method
-	Method
matching	Method
3D	Method
training	Method
patches	Method
from	O
reconstructions	O
(	O
refer	O
to	O
Sec	O
.	O
3	O
)	O
is	O
performed	O
on	O
-	O
the	O
-	O
go	O
during	O
network	Method
training	Method
.	O
We	O
used	O
a	O
batch	Method
size	O
of	O
128	O
,	O
contrastive	O
margin	O
of	O
1	O
,	O
no	O
batch	Method
or	O
patch	Method
normalization	Method
.	O
Our	O
reference	O
model	O
was	O
trained	O
for	O
approximately	O
eight	O
days	O
on	O
a	O
single	O
NVIDIA	Material
Tesla	Material
K40c	Material
,	O
over	O
16	O
million	O
3D	Material
patch	Material
pairs	Material
,	O
which	O
includes	O
8	O
million	O
correspondences	O
and	O
8	O
million	O
non	O
-	O
correspondences	O
.	O
section	O
:	O
A.3	O
.	O
Run	Metric
-	Metric
time	Metric
Information	Metric
The	O
following	O
run	Metric
-	Metric
times	Metric
are	O
reported	O
from	O
the	O
implementations	O
used	O
in	O
our	O
experiments	O
.	O
We	O
did	O
not	O
optimize	O
for	O
speed	O
.	O
TDF	Method
Conversion	Method
.	O
As	O
mentioned	O
in	O
Sec	O
4.1	O
,	O
a	O
local	O
3D	O
patch	O
around	O
an	O
interest	O
point	O
is	O
represented	O
as	O
a	O
30×30×30	O
voxel	O
grid	O
of	O
TDF	O
values	O
(	O
in	O
all	O
of	O
our	O
experiments	O
,	O
truncation	O
margin	O
is	O
5	O
voxels	O
)	O
.	O
Converting	O
a	O
point	O
cloud	O
spanning	O
0.3	O
m	O
3	O
of	O
a	O
depth	O
frame	O
into	O
a	O
TDF	Method
voxel	Method
grid	Method
(	O
using	O
CUDAenabled	Method
GPU	Method
acceleration	Method
)	O
takes	O
anywhere	O
from	O
3	O
-	O
20	O
milliseconds	O
,	O
depending	O
on	O
the	O
density	O
of	O
the	O
point	O
cloud	O
.	O
We	O
observe	O
an	O
average	Metric
conversion	Metric
time	Metric
of	O
8.9	O
milliseconds	O
per	O
patch	O
from	O
the	O
keypoint	Task
matching	Task
benchmark	Task
in	O
Sec	O
.	O
5.1	O
on	O
an	O
NVIDIA	Material
Tesla	Material
K40c	Material
.	O
3DMatch	Method
Descriptor	O
.	O
Computing	O
a	O
3DMatch	Method
descriptor	O
(	O
e.g.	O
ConvNet	Method
forward	Method
pass	Method
)	O
for	O
a	O
single	O
30	O
×	O
30	O
×	O
30	O
TDF	O
voxel	O
grid	O
takes	O
an	O
average	O
of	O
3.2	O
milliseconds	O
with	O
Marvin	Method
.	O
Geometric	Task
Registration	Task
.	O
To	O
register	O
two	O
surfaces	O
,	O
we	O
randomly	O
sample	O
n	O
keypoints	O
per	O
surface	O
.	O
n	O
=	O
5000	O
for	O
scene	Task
fragment	Task
surface	Task
registration	Task
(	O
Sec	O
.	O
5.2.1	O
-	O
Sec	O
.	O
5.2.2	O
)	O
and	O
n	O
=	O
1000	O
for	O
model	Task
alignment	Task
in	O
the	O
Amazon	Task
Picking	Task
Challenge	Task
(	O
Sec	O
.	O
5.3	O
)	O
.	O
Finding	Task
keypoints	Task
with	O
mutually	O
closest	O
3DMatch	Method
descriptors	O
takes	O
2	O
seconds	O
or	O
less	O
,	O
while	O
RANSAC	Material
for	O
estimating	Task
rigid	Task
transformation	Task
can	O
take	O
anywhere	O
from	O
2	O
seconds	O
up	O
to	O
a	O
minute	O
depending	O
on	O
the	O
number	O
of	O
RANSAC	Material
iterations	O
and	O
rate	Metric
of	Metric
convergence	Metric
.	O
These	O
numbers	O
are	O
reported	O
using	O
a	O
single	O
CPU	O
thread	O
on	O
an	O
Intel	O
Core	O
i7	O
-	O
3770	O
K	O
clocked	O
at	O
3.5	O
GHz	O
.	O
Figure	O
11	O
.	O
Visualizing	O
several	O
RGB	Material
-	Material
D	Material
reconstructions	Material
of	O
the	O
datasets	O
used	O
to	O
train	O
3DMatch	Method
in	O
our	O
experiments	O
.	O
Each	O
dataset	O
contains	O
depth	O
scans	O
of	O
different	O
environments	O
with	O
different	O
local	O
geometries	O
at	O
varying	O
scales	O
,	O
registered	O
together	O
by	O
different	O
reconstruction	Method
algorithms	Method
.	O
These	O
datasets	O
provide	O
a	O
diverse	O
surface	O
correspondence	O
training	O
set	O
with	O
varying	O
levels	O
of	O
sensor	O
noise	O
,	O
viewpoint	O
variance	O
,	O
and	O
occlusion	O
patterns	O
.	O
Color	O
for	O
visualization	Task
only	O
.	O
section	O
:	O
section	O
:	O
section	O
:	O
