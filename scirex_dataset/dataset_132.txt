document	O
:	O
Natural	Task
TTS	Task
Synthesis	Task
By	O
Conditioning	O
WaveNet	Method
On	O
Mel	Method
Spectrogram	Method
Predictions	Method
This	O
paper	O
describes	O
Tacotron	Method
2	Method
,	O
a	O
neural	Method
network	Method
architecture	Method
for	O
speech	Task
synthesis	Task
directly	O
from	O
text	O
.	O
The	O
system	O
is	O
composed	O
of	O
a	O
recurrent	Method
sequence	Method
-	Method
to	Method
-	Method
sequence	Method
feature	Method
prediction	Method
network	Method
that	O
maps	O
character	O
embeddings	O
to	O
mel	O
-	O
scale	O
spectrograms	O
,	O
followed	O
by	O
a	O
modified	O
WaveNet	Method
model	O
acting	O
as	O
a	O
vocoder	Method
to	O
synthesize	O
time	O
-	O
domain	O
waveforms	O
from	O
those	O
spectrograms	O
.	O
Our	O
model	O
achieves	O
a	O
mean	Metric
opinion	Metric
score	Metric
(	O
MOS	Metric
)	O
of	O
comparable	O
to	O
a	O
MOS	Metric
of	O
for	O
professionally	O
recorded	O
speech	O
.	O
To	O
validate	O
our	O
design	O
choices	O
,	O
we	O
present	O
ablation	O
studies	O
of	O
key	O
components	O
of	O
our	O
system	O
and	O
evaluate	O
the	O
impact	O
of	O
using	O
mel	O
spectrograms	O
as	O
the	O
conditioning	O
input	O
to	O
WaveNet	Method
instead	O
of	O
linguistic	O
,	O
duration	O
,	O
and	O
features	O
.	O
We	O
further	O
show	O
that	O
using	O
this	O
compact	O
acoustic	Method
intermediate	Method
representation	Method
allows	O
for	O
a	O
significant	O
reduction	O
in	O
the	O
size	O
of	O
the	O
WaveNet	Method
architecture	Method
.	O
1	O
]	O
JonathanShen1	O
]	O
RuomingPang1	O
]	O
RonJ.Weiss1	O
]	O
MikeSchuster1	O
]	O
NavdeepJaitly2	O
]	O
ZonghengYang	O
1	O
]	O
ZhifengChen1	O
]	O
YuZhang	O
1	O
]	O
YuxuanWang1	O
]	O
RJSkerry	O
-	O
Ryan1	O
]	O
RifA.Saurous1	O
]	O
YannisAgiomyrgiannakis1	O
]	O
YonghuiWu	O
[	O
1	O
]	O
Google	O
,	O
Inc	O
.	O
[	O
2	O
]	O
UniversityofCalifornia	O
,	O
Berkeley	O
[	O
]	O
{	O
jonathanasdf	O
,	O
rpang	O
,	O
yonghui	O
}	O
@google.com	O
Tacotron	Method
2	Method
,	O
WaveNet	Method
,	O
text	Task
-	Task
to	Task
-	Task
speech	Task
section	O
:	O
Introduction	O
Generating	Task
natural	Task
speech	Task
from	O
text	O
(	O
text	O
-	O
to	O
-	O
speech	Task
synthesis	Task
,	O
TTS	Task
)	O
remains	O
a	O
challenging	O
task	O
despite	O
decades	O
of	O
investigation	O
.	O
Over	O
time	O
,	O
different	O
techniques	O
have	O
dominated	O
the	O
field	O
.	O
Concatenative	Method
synthesis	Method
with	O
unit	Method
selection	Method
,	O
the	O
process	O
of	O
stitching	O
small	O
units	O
of	O
pre	O
-	O
recorded	O
waveforms	O
together	O
was	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
for	O
many	O
years	O
.	O
Statistical	O
parametric	O
speech	Task
synthesis	Task
,	O
which	O
directly	O
generates	O
smooth	O
trajectories	O
of	O
speech	O
features	O
to	O
be	O
synthesized	O
by	O
a	O
vocoder	Method
,	O
followed	O
,	O
solving	O
many	O
of	O
the	O
issues	O
that	O
concatenative	Task
synthesis	Task
had	O
with	O
boundary	O
artifacts	O
.	O
However	O
,	O
the	O
audio	O
produced	O
by	O
these	O
systems	O
often	O
sounds	O
muffled	O
and	O
unnatural	O
compared	O
to	O
human	O
speech	O
.	O
WaveNet	Method
,	O
a	O
generative	Method
model	Method
of	Method
time	Method
domain	Method
waveforms	Method
,	O
produces	O
audio	Metric
quality	Metric
that	O
begins	O
to	O
rival	O
that	O
of	O
real	O
human	O
speech	O
and	O
is	O
already	O
used	O
in	O
some	O
complete	O
TTS	Method
systems	Method
.	O
The	O
inputs	O
to	O
WaveNet	Method
(	O
linguistic	O
features	O
,	O
predicted	O
log	O
fundamental	O
frequency	O
(	O
)	O
,	O
and	O
phoneme	O
durations	O
)	O
,	O
however	O
,	O
require	O
significant	O
domain	O
expertise	O
to	O
produce	O
,	O
involving	O
elaborate	O
text	Method
-	Method
analysis	Method
systems	Method
as	O
well	O
as	O
a	O
robust	O
lexicon	O
(	O
pronunciation	O
guide	O
)	O
.	O
Tacotron	Method
,	O
a	O
sequence	Method
-	Method
to	Method
-	Method
sequence	Method
architecture	Method
for	O
producing	O
magnitude	O
spectrograms	O
from	O
a	O
sequence	O
of	O
characters	O
,	O
simplifies	O
the	O
traditional	O
speech	Task
synthesis	Task
pipeline	O
by	O
replacing	O
the	O
production	O
of	O
these	O
linguistic	O
and	O
acoustic	O
features	O
with	O
a	O
single	O
neural	Method
network	Method
trained	O
from	O
data	O
alone	O
.	O
To	O
vocode	O
the	O
resulting	O
magnitude	O
spectrograms	O
,	O
Tacotron	Method
uses	O
the	O
Griffin	Method
-	Method
Lim	Method
algorithm	Method
for	O
phase	Task
estimation	Task
,	O
followed	O
by	O
an	O
inverse	O
short	Method
-	Method
time	Method
Fourier	Method
transform	Method
.	O
As	O
the	O
authors	O
note	O
,	O
this	O
was	O
simply	O
a	O
placeholder	O
for	O
future	O
neural	Method
vocoder	Method
approaches	Method
,	O
as	O
Griffin	O
-	O
Lim	O
produces	O
characteristic	O
artifacts	O
and	O
lower	O
audio	Metric
quality	Metric
than	O
approaches	O
like	O
WaveNet	Method
.	O
In	O
this	O
paper	O
,	O
we	O
describe	O
a	O
unified	O
,	O
entirely	Method
neural	Method
approach	Method
to	O
speech	Task
synthesis	Task
that	O
combines	O
the	O
best	O
of	O
the	O
previous	O
approaches	O
:	O
a	O
sequence	O
-	O
to	O
-	O
sequence	O
Tacotron	Method
-	O
style	O
model	O
that	O
generates	O
mel	O
spectrograms	O
,	O
followed	O
by	O
a	O
modified	O
WaveNet	Method
vocoder	O
.	O
Trained	O
directly	O
on	O
normalized	O
character	O
sequences	O
and	O
corresponding	O
speech	O
waveforms	O
,	O
our	O
model	O
learns	O
to	O
synthesize	O
natural	O
sounding	O
speech	O
that	O
is	O
difficult	O
to	O
distinguish	O
from	O
real	O
human	O
speech	O
.	O
Deep	O
Voice	O
3	O
describes	O
a	O
similar	O
approach	O
.	O
However	O
,	O
unlike	O
our	O
system	O
,	O
its	O
naturalness	O
has	O
not	O
been	O
shown	O
to	O
rival	O
that	O
of	O
human	O
speech	O
.	O
Char2Wav	Method
describes	O
yet	O
another	O
similar	O
approach	O
to	O
end	Task
-	Task
to	Task
-	Task
end	Task
TTS	Task
using	O
a	O
neural	Method
vocoder	Method
.	O
However	O
,	O
they	O
use	O
different	O
intermediate	Method
representations	Method
(	O
traditional	O
vocoder	O
features	O
)	O
and	O
their	O
model	Method
architecture	Method
differs	O
significantly	O
.	O
section	O
:	O
Model	O
Architecture	O
Our	O
proposed	O
system	O
consists	O
of	O
two	O
components	O
,	O
shown	O
in	O
Figure	O
[	O
reference	O
]	O
:	O
subsection	O
:	O
Intermediate	Method
Feature	Method
Representation	Method
In	O
this	O
work	O
we	O
choose	O
a	O
low	Method
-	Method
level	Method
acoustic	Method
representation	Method
:	O
mel	Method
-	Method
frequency	Method
spectrograms	Method
,	O
to	O
bridge	O
the	O
two	O
components	O
.	O
Using	O
a	O
representation	O
that	O
is	O
easily	O
computed	O
from	O
time	O
-	O
domain	O
waveforms	O
allows	O
us	O
to	O
train	O
the	O
two	O
components	O
separately	O
.	O
This	O
representation	O
is	O
also	O
smoother	O
than	O
waveform	O
samples	O
and	O
is	O
easier	O
to	O
train	O
using	O
a	O
squared	Metric
error	Metric
loss	Metric
because	O
it	O
is	O
invariant	O
to	O
phase	O
within	O
each	O
frame	O
.	O
A	O
mel	O
-	O
frequency	O
spectrogram	O
is	O
related	O
to	O
the	O
linear	Method
-	Method
frequency	Method
spectrogram	Method
,	O
i.e.	O
,	O
the	O
short	Method
-	Method
time	Method
Fourier	Method
transform	Method
(	O
STFT	Method
)	O
magnitude	O
.	O
It	O
is	O
obtained	O
by	O
applying	O
a	O
nonlinear	Method
transform	Method
to	O
the	O
frequency	O
axis	O
of	O
the	O
STFT	Method
,	O
inspired	O
by	O
measured	O
responses	O
from	O
the	O
human	O
auditory	O
system	O
,	O
and	O
summarizes	O
the	O
frequency	O
content	O
with	O
fewer	O
dimensions	O
.	O
Using	O
such	O
an	O
auditory	O
frequency	O
scale	O
has	O
the	O
effect	O
of	O
emphasizing	O
details	O
in	O
lower	O
frequencies	O
,	O
which	O
are	O
critical	O
to	O
speech	O
intelligibility	O
,	O
while	O
de	O
-	O
emphasizing	O
high	O
frequency	O
details	O
,	O
which	O
are	O
dominated	O
by	O
fricatives	O
and	O
other	O
noise	O
bursts	O
and	O
generally	O
do	O
not	O
need	O
to	O
be	O
modeled	O
with	O
high	O
fidelity	O
.	O
Because	O
of	O
these	O
properties	O
,	O
features	O
derived	O
from	O
the	O
mel	O
scale	O
have	O
been	O
used	O
as	O
an	O
underlying	O
representation	O
for	O
speech	Task
recognition	Task
for	O
many	O
decades	O
.	O
While	O
linear	O
spectrograms	O
discard	O
phase	O
information	O
(	O
and	O
are	O
therefore	O
lossy	O
)	O
,	O
algorithms	O
such	O
as	O
Griffin	Method
-	Method
Lim	Method
are	O
capable	O
of	O
estimating	O
this	O
discarded	O
information	O
,	O
which	O
enables	O
time	Method
-	Method
domain	Method
conversion	Method
via	O
the	O
inverse	O
short	Method
-	Method
time	Method
Fourier	Method
transform	Method
.	O
Mel	O
spectrograms	O
discard	O
even	O
more	O
information	O
,	O
presenting	O
a	O
challenging	O
inverse	Task
problem	Task
.	O
However	O
,	O
in	O
comparison	O
to	O
the	O
linguistic	O
and	O
acoustic	O
features	O
used	O
in	O
WaveNet	Method
,	O
the	O
mel	Method
spectrogram	Method
is	O
a	O
simpler	O
,	O
lower	O
-	O
level	Method
acoustic	Method
representation	Method
of	Method
audio	Method
signals	Method
.	O
It	O
should	O
therefore	O
be	O
straightforward	O
for	O
a	O
similar	O
WaveNet	Method
model	O
conditioned	O
on	O
mel	O
spectrograms	O
to	O
generate	O
audio	O
,	O
essentially	O
as	O
a	O
neural	Method
vocoder	Method
.	O
Indeed	O
,	O
we	O
will	O
show	O
that	O
it	O
is	O
possible	O
to	O
generate	O
high	O
quality	O
audio	O
from	O
mel	O
spectrograms	O
using	O
a	O
modified	O
WaveNet	Method
architecture	Method
.	O
subsection	O
:	O
Spectrogram	Method
Prediction	Method
Network	Method
As	O
in	O
Tacotron	Method
,	O
mel	O
spectrograms	O
are	O
computed	O
through	O
a	O
short	Method
-	Method
time	Method
Fourier	Method
transform	Method
(	O
STFT	Method
)	O
using	O
a	O
50	O
ms	O
frame	O
size	O
,	O
12.5	O
ms	O
frame	O
hop	O
,	O
and	O
a	O
Hann	O
window	O
function	O
.	O
We	O
experimented	O
with	O
a	O
5	O
ms	O
frame	O
hop	O
to	O
match	O
the	O
frequency	O
of	O
the	O
conditioning	O
inputs	O
in	O
the	O
original	O
WaveNet	Method
,	O
but	O
the	O
corresponding	O
increase	O
in	O
temporal	Metric
resolution	Metric
resulted	O
in	O
significantly	O
more	O
pronunciation	O
issues	O
.	O
We	O
transform	O
the	O
STFT	Method
magnitude	O
to	O
the	O
mel	O
scale	O
using	O
an	O
80	Method
channel	Method
mel	Method
filterbank	Method
spanning	O
125	O
Hz	O
to	O
7.6	O
kHz	O
,	O
followed	O
by	O
log	Method
dynamic	Method
range	Method
compression	Method
.	O
Prior	O
to	O
log	Task
compression	Task
,	O
the	O
filterbank	O
output	O
magnitudes	O
are	O
clipped	O
to	O
a	O
minimum	O
value	O
of	O
0.01	O
in	O
order	O
to	O
limit	O
dynamic	O
range	O
in	O
the	O
logarithmic	O
domain	O
.	O
The	O
network	O
is	O
composed	O
of	O
an	O
encoder	Method
and	O
a	O
decoder	Method
with	O
attention	Method
.	O
The	O
encoder	O
converts	O
a	O
character	O
sequence	O
into	O
a	O
hidden	Method
feature	Method
representation	Method
which	O
the	O
decoder	Method
consumes	O
to	O
predict	O
a	O
spectrogram	O
.	O
Input	O
characters	O
are	O
represented	O
using	O
a	O
learned	O
512	Method
-	Method
dimensional	Method
character	Method
embedding	Method
,	O
which	O
are	O
passed	O
through	O
a	O
stack	O
of	O
3	O
convolutional	Method
layers	Method
each	O
containing	O
512	O
filters	O
with	O
shape	O
,	O
i.e.	O
,	O
where	O
each	O
filter	O
spans	O
5	O
characters	O
,	O
followed	O
by	O
batch	Method
normalization	Method
and	O
ReLU	Method
activations	Method
.	O
As	O
in	O
Tacotron	Method
,	O
these	O
convolutional	Method
layers	Method
model	O
longer	O
-	O
term	O
context	O
(	O
e.g.	O
,	O
-	O
grams	O
)	O
in	O
the	O
input	O
character	O
sequence	O
.	O
The	O
output	O
of	O
the	O
final	O
convolutional	Method
layer	Method
is	O
passed	O
into	O
a	O
single	O
bi	Method
-	Method
directional	Method
LSTM	Method
layer	Method
containing	O
512	O
units	O
(	O
256	O
in	O
each	O
direction	O
)	O
to	O
generate	O
the	O
encoded	O
features	O
.	O
The	O
encoder	O
output	O
is	O
consumed	O
by	O
an	O
attention	Method
network	Method
which	O
summarizes	O
the	O
full	O
encoded	O
sequence	O
as	O
a	O
fixed	O
-	O
length	O
context	O
vector	O
for	O
each	O
decoder	O
output	O
step	O
.	O
We	O
use	O
the	O
location	O
-	O
sensitive	O
attention	O
from	O
,	O
which	O
extends	O
the	O
additive	Method
attention	Method
mechanism	Method
to	O
use	O
cumulative	O
attention	O
weights	O
from	O
previous	O
decoder	O
time	O
steps	O
as	O
an	O
additional	O
feature	O
.	O
This	O
encourages	O
the	O
model	O
to	O
move	O
forward	O
consistently	O
through	O
the	O
input	O
,	O
mitigating	O
potential	O
failure	O
modes	O
where	O
some	O
subsequences	O
are	O
repeated	O
or	O
ignored	O
by	O
the	O
decoder	Method
.	O
Attention	O
probabilities	O
are	O
computed	O
after	O
projecting	O
inputs	O
and	O
location	O
features	O
to	O
128	Method
-	Method
dimensional	Method
hidden	Method
representations	Method
.	O
Location	O
features	O
are	O
computed	O
using	O
32	O
1	Method
-	Method
D	Method
convolution	Method
filters	Method
of	O
length	O
31	O
.	O
The	O
decoder	Method
is	O
an	O
autoregressive	Method
recurrent	Method
neural	Method
network	Method
which	O
predicts	O
a	O
mel	O
spectrogram	O
from	O
the	O
encoded	O
input	O
sequence	O
one	O
frame	O
at	O
a	O
time	O
.	O
The	O
prediction	O
from	O
the	O
previous	O
time	O
step	O
is	O
first	O
passed	O
through	O
a	O
small	O
pre	Method
-	Method
net	Method
containing	O
2	O
fully	Method
connected	Method
layers	Method
of	O
256	O
hidden	Method
ReLU	Method
units	Method
.	O
We	O
found	O
that	O
the	O
pre	O
-	O
net	O
acting	O
as	O
an	O
information	O
bottleneck	O
was	O
essential	O
for	O
learning	Task
attention	Task
.	O
The	O
pre	O
-	O
net	O
output	O
and	O
attention	O
context	O
vector	O
are	O
concatenated	O
and	O
passed	O
through	O
a	O
stack	O
of	O
2	O
uni	Method
-	Method
directional	Method
LSTM	Method
layers	Method
with	O
1024	O
units	O
.	O
The	O
concatenation	O
of	O
the	O
LSTM	O
output	O
and	O
the	O
attention	O
context	O
vector	O
is	O
projected	O
through	O
a	O
linear	Method
transform	Method
to	O
predict	O
the	O
target	O
spectrogram	O
frame	O
.	O
Finally	O
,	O
the	O
predicted	O
mel	O
spectrogram	O
is	O
passed	O
through	O
a	O
5	Method
-	Method
layer	Method
convolutional	Method
post	Method
-	Method
net	Method
which	O
predicts	O
a	O
residual	O
to	O
add	O
to	O
the	O
prediction	O
to	O
improve	O
the	O
overall	O
reconstruction	Task
.	O
Each	O
post	Method
-	Method
net	Method
layer	Method
is	O
comprised	O
of	O
512	Method
filters	Method
with	O
shape	O
with	O
batch	Method
normalization	Method
,	O
followed	O
by	O
activations	O
on	O
all	O
but	O
the	O
final	O
layer	O
.	O
We	O
minimize	O
the	O
summed	Metric
mean	Metric
squared	Metric
error	Metric
(	O
MSE	Metric
)	O
from	O
before	O
and	O
after	O
the	O
post	O
-	O
net	O
to	O
aid	O
convergence	O
.	O
We	O
also	O
experimented	O
with	O
a	O
log	Method
-	Method
likelihood	Method
loss	Method
by	O
modeling	O
the	O
output	O
distribution	O
with	O
a	O
Mixture	Method
Density	Method
Network	Method
to	O
avoid	O
assuming	O
a	O
constant	O
variance	O
over	O
time	O
,	O
but	O
found	O
that	O
these	O
were	O
more	O
difficult	O
to	O
train	O
and	O
they	O
did	O
not	O
lead	O
to	O
better	O
sounding	O
samples	O
.	O
In	O
parallel	O
to	O
spectrogram	Task
frame	Task
prediction	Task
,	O
the	O
concatenation	O
of	O
decoder	O
LSTM	O
output	O
and	O
the	O
attention	O
context	O
is	O
projected	O
down	O
to	O
a	O
scalar	O
and	O
passed	O
through	O
a	O
sigmoid	Method
activation	Method
to	O
predict	O
the	O
probability	O
that	O
the	O
output	O
sequence	O
has	O
completed	O
.	O
This	O
“	O
stop	O
token	O
”	O
prediction	O
is	O
used	O
during	O
inference	Task
to	O
allow	O
the	O
model	O
to	O
dynamically	O
determine	O
when	O
to	O
terminate	Task
generation	Task
instead	O
of	O
always	O
generating	O
for	O
a	O
fixed	O
duration	O
.	O
Specifically	O
,	O
generation	Task
completes	O
at	O
the	O
first	O
frame	O
for	O
which	O
this	O
probability	O
exceeds	O
a	O
threshold	O
of	O
0.5	O
.	O
The	O
convolutional	Method
layers	Method
in	O
the	O
network	O
are	O
regularized	O
using	O
dropout	Method
with	O
probability	O
0.5	O
,	O
and	O
LSTM	Method
layers	Method
are	O
regularized	O
using	O
zoneout	Method
with	O
probability	O
0.1	O
.	O
In	O
order	O
to	O
introduce	O
output	O
variation	O
at	O
inference	O
time	O
,	O
dropout	O
with	O
probability	O
0.5	O
is	O
applied	O
only	O
to	O
layers	O
in	O
the	O
pre	O
-	O
net	O
of	O
the	O
autoregressive	Method
decoder	Method
.	O
In	O
contrast	O
to	O
the	O
original	O
Tacotron	Method
,	O
our	O
model	O
uses	O
simpler	O
building	Method
blocks	Method
,	O
using	O
vanilla	Method
LSTM	Method
and	Method
convolutional	Method
layers	Method
in	O
the	O
encoder	Method
and	Method
decoder	Method
instead	O
of	O
“	O
CBHG	Method
”	Method
stacks	Method
and	O
GRU	Method
recurrent	Method
layers	Method
.	O
We	O
do	O
not	O
use	O
a	O
“	O
reduction	O
factor	O
”	O
,	O
i.e.	O
,	O
each	O
decoder	Method
step	Method
corresponds	O
to	O
a	O
single	O
spectrogram	O
frame	O
.	O
subsection	O
:	O
WaveNet	Method
Vocoder	O
We	O
use	O
a	O
modified	O
version	O
of	O
the	O
WaveNet	Method
architecture	Method
from	O
to	O
invert	O
the	O
mel	Method
spectrogram	Method
feature	Method
representation	Method
into	O
time	O
-	O
domain	O
waveform	O
samples	O
.	O
As	O
in	O
the	O
original	O
architecture	O
,	O
there	O
are	O
30	O
dilated	O
convolution	O
layers	O
,	O
grouped	O
into	O
3	O
dilation	O
cycles	O
,	O
i.e.	O
,	O
the	O
dilation	O
rate	O
of	O
layer	O
k	O
(	O
)	O
is	O
.	O
To	O
work	O
with	O
the	O
12.5	O
ms	O
frame	O
hop	O
of	O
the	O
spectrogram	O
frames	O
,	O
only	O
2	O
upsampling	O
layers	O
are	O
used	O
in	O
the	O
conditioning	Method
stack	Method
instead	O
of	O
3	O
layers	O
.	O
Instead	O
of	O
predicting	O
discretized	O
buckets	O
with	O
a	O
softmax	Method
layer	Method
,	O
we	O
follow	O
PixelCNN	Method
++	Method
and	O
Parallel	O
WaveNet	Method
and	O
use	O
a	O
10	Method
-	Method
component	Method
mixture	Method
of	Method
logistic	Method
distributions	Method
(	O
MoL	Method
)	O
to	O
generate	O
16	O
-	O
bit	O
samples	O
at	O
24	O
kHz	O
.	O
To	O
compute	O
the	O
logistic	O
mixture	O
distribution	O
,	O
the	O
WaveNet	Method
stack	O
output	O
is	O
passed	O
through	O
a	O
ReLU	Method
activation	Method
followed	O
by	O
a	O
linear	Method
projection	Method
to	O
predict	O
parameters	O
(	O
mean	O
,	O
log	O
scale	O
,	O
mixture	O
weight	O
)	O
for	O
each	O
mixture	Method
component	Method
.	O
The	O
loss	Metric
is	O
computed	O
as	O
the	O
negative	O
log	O
-	O
likelihood	O
of	O
the	O
ground	O
truth	O
sample	O
.	O
section	O
:	O
Experiments	O
&	O
Results	O
subsection	O
:	O
Training	O
Setup	O
Our	O
training	O
process	O
involves	O
first	O
training	O
the	O
feature	Method
prediction	Method
network	Method
on	O
its	O
own	O
,	O
followed	O
by	O
training	O
a	O
modified	O
WaveNet	Method
independently	O
on	O
the	O
outputs	O
generated	O
by	O
the	O
first	O
network	O
.	O
To	O
train	O
the	O
feature	Method
prediction	Method
network	Method
,	O
we	O
apply	O
the	O
standard	O
maximum	Method
-	Method
likelihood	Method
training	Method
procedure	Method
(	O
feeding	O
in	O
the	O
correct	O
output	O
instead	O
of	O
the	O
predicted	O
output	O
on	O
the	O
decoder	O
side	O
,	O
also	O
referred	O
to	O
as	O
teacher	O
-	O
forcing	O
)	O
with	O
a	O
batch	O
size	O
of	O
64	O
on	O
a	O
single	O
GPU	O
.	O
We	O
use	O
the	O
Adam	Method
optimizer	Method
with	O
and	O
a	O
learning	Metric
rate	Metric
of	O
exponentially	O
decaying	O
to	O
starting	O
after	O
50	O
,	O
000	O
iterations	O
.	O
We	O
also	O
apply	O
regularization	Method
with	Method
weight	Method
.	O
We	O
then	O
train	O
our	O
modified	O
WaveNet	Method
on	O
the	O
ground	O
truth	O
-	O
aligned	O
predictions	O
of	O
the	O
feature	Method
prediction	Method
network	Method
.	O
That	O
is	O
,	O
the	O
prediction	Method
network	Method
is	O
run	O
in	O
teacher	O
-	O
forcing	O
mode	O
,	O
where	O
each	O
predicted	O
frame	O
is	O
conditioned	O
on	O
the	O
encoded	O
input	O
sequence	O
and	O
the	O
corresponding	O
previous	O
frame	O
in	O
the	O
ground	O
truth	O
spectrogram	O
.	O
This	O
ensures	O
that	O
each	O
predicted	O
frame	O
exactly	O
aligns	O
with	O
the	O
target	O
waveform	O
samples	O
.	O
We	O
train	O
with	O
a	O
batch	O
size	O
of	O
128	O
distributed	O
across	O
32	O
GPUs	Method
with	O
synchronous	O
updates	O
,	O
using	O
the	O
Adam	Method
optimizer	Method
with	O
and	O
a	O
fixed	O
learning	Metric
rate	Metric
of	O
.	O
It	O
helps	O
quality	O
to	O
average	O
model	O
weights	O
over	O
recent	O
updates	O
.	O
Therefore	O
we	O
maintain	O
an	O
exponentially	Method
-	Method
weighted	Method
moving	Method
average	Method
of	Method
the	Method
network	Method
parameters	Method
over	O
update	O
steps	O
with	O
a	O
decay	O
of	O
0.9999	O
–	O
this	O
version	O
is	O
used	O
for	O
inference	Task
(	O
see	O
also	O
)	O
.	O
To	O
speed	O
up	O
convergence	Metric
,	O
we	O
scale	O
the	O
waveform	O
targets	O
by	O
a	O
factor	O
of	O
which	O
brings	O
the	O
initial	O
outputs	O
of	O
the	O
mixture	Method
of	Method
logistics	Method
layer	Method
closer	O
to	O
the	O
eventual	O
distributions	O
.	O
We	O
train	O
all	O
models	O
on	O
an	O
internal	Material
US	Material
English	Material
dataset	Material
,	O
which	O
contains	O
24.6	O
hours	O
of	O
speech	O
from	O
a	O
single	O
professional	O
female	O
speaker	O
.	O
All	O
text	O
in	O
our	O
datasets	O
is	O
spelled	O
out	O
.	O
e.g.	O
,	O
“	O
16	O
”	O
is	O
written	O
as	O
“	O
sixteen	O
”	O
,	O
i.e.	O
,	O
our	O
models	O
are	O
all	O
trained	O
on	O
normalized	O
text	O
.	O
subsection	O
:	O
Evaluation	O
When	O
generating	O
speech	O
in	O
inference	Task
mode	Task
,	O
the	O
ground	O
truth	O
targets	O
are	O
not	O
known	O
.	O
Therefore	O
,	O
the	O
predicted	O
outputs	O
from	O
the	O
previous	O
step	O
are	O
fed	O
in	O
during	O
decoding	Task
,	O
in	O
contrast	O
to	O
the	O
teacher	Method
-	Method
forcing	Method
configuration	Method
used	O
for	O
training	Task
.	O
We	O
randomly	O
selected	O
100	O
fixed	O
examples	O
from	O
the	O
test	O
set	O
of	O
our	O
internal	O
dataset	O
as	O
the	O
evaluation	O
set	O
.	O
Audio	O
generated	O
on	O
this	O
set	O
are	O
sent	O
to	O
a	O
human	Method
rating	Method
service	Method
similar	O
to	O
Amazon	O
’s	O
Mechanical	O
Turk	O
where	O
each	O
sample	O
is	O
rated	O
by	O
at	O
least	O
8	O
raters	O
on	O
a	O
scale	O
from	O
1	O
to	O
5	O
with	O
0.5	O
point	O
increments	O
,	O
from	O
which	O
a	O
subjective	O
mean	Metric
opinion	Metric
score	Metric
(	O
MOS	Metric
)	O
is	O
calculated	O
.	O
Each	O
evaluation	O
is	O
conducted	O
independently	O
from	O
each	O
other	O
,	O
so	O
the	O
outputs	O
of	O
two	O
different	O
models	O
are	O
not	O
directly	O
compared	O
when	O
raters	O
assign	O
a	O
score	O
to	O
them	O
.	O
Note	O
that	O
while	O
instances	O
in	O
the	O
evaluation	O
set	O
never	O
appear	O
in	O
the	O
training	O
set	O
,	O
there	O
are	O
some	O
recurring	O
patterns	O
and	O
common	O
words	O
between	O
the	O
two	O
sets	O
.	O
While	O
this	O
could	O
potentially	O
result	O
in	O
an	O
inflated	O
MOS	Metric
compared	O
to	O
an	O
evaluation	O
set	O
consisting	O
of	O
sentences	O
generated	O
from	O
random	O
words	O
,	O
using	O
this	O
set	O
allows	O
us	O
to	O
compare	O
to	O
the	O
ground	O
truth	O
.	O
Since	O
all	O
the	O
systems	O
we	O
compare	O
are	O
trained	O
on	O
the	O
same	O
data	O
,	O
relative	O
comparisons	O
are	O
still	O
meaningful	O
.	O
Table	O
[	O
reference	O
]	O
shows	O
a	O
comparison	O
of	O
our	O
method	O
against	O
various	O
prior	O
systems	O
.	O
In	O
order	O
to	O
better	O
isolate	O
the	O
effect	O
of	O
using	O
mel	O
spectrograms	O
as	O
features	O
,	O
we	O
compare	O
to	O
a	O
WaveNet	Method
conditioned	O
on	O
linguistic	O
features	O
with	O
similar	O
modifications	O
to	O
the	O
WaveNet	Method
architecture	Method
as	O
introduced	O
above	O
.	O
We	O
also	O
compare	O
to	O
the	O
original	O
Tacotron	Method
that	O
predicts	O
linear	O
spectrograms	O
and	O
uses	O
Griffin	Method
-	Method
Lim	Method
to	O
synthesize	O
audio	O
,	O
as	O
well	O
as	O
concatenative	Method
and	Method
parametric	Method
baseline	Method
systems	Method
,	O
both	O
of	O
which	O
have	O
been	O
used	O
in	O
production	Task
at	O
Google	O
.	O
We	O
find	O
that	O
the	O
proposed	O
system	O
significantly	O
outpeforms	O
all	O
other	O
TTS	Method
systems	Method
,	O
and	O
results	O
in	O
an	O
MOS	Metric
comparable	O
to	O
that	O
of	O
the	O
ground	O
truth	O
audio	O
.	O
We	O
also	O
conduct	O
a	O
side	O
-	O
by	O
-	O
side	Metric
evaluation	Metric
between	O
audio	O
synthesized	O
by	O
our	O
system	O
and	O
the	O
ground	O
truth	O
.	O
For	O
each	O
pair	O
of	O
utterances	O
,	O
raters	O
are	O
asked	O
to	O
give	O
a	O
score	O
ranging	O
from	O
-	O
3	O
(	O
synthesized	O
much	O
worse	O
than	O
ground	O
truth	O
)	O
to	O
3	O
(	O
synthesized	O
much	O
better	O
than	O
ground	O
truth	O
)	O
.	O
The	O
overall	O
mean	O
score	O
of	O
shows	O
that	O
raters	O
have	O
a	O
small	O
but	O
statistically	O
significant	O
preference	O
towards	O
ground	O
truth	O
over	O
our	O
results	O
.	O
See	O
Figure	O
[	O
reference	O
]	O
for	O
a	O
detailed	O
breakdown	O
.	O
The	O
comments	O
from	O
raters	O
indicate	O
that	O
occasional	O
mispronunciation	O
by	O
our	O
system	O
is	O
the	O
primary	O
reason	O
for	O
this	O
preference	O
.	O
We	O
ran	O
a	O
separate	O
rating	O
experiment	O
on	O
the	O
custom	O
100	O
-	O
sentence	O
test	O
set	O
from	O
Appendix	O
E	O
of	O
,	O
obtaining	O
a	O
MOS	Metric
of	O
4.354	O
.	O
In	O
a	O
manual	O
analysis	O
of	O
the	O
error	Metric
modes	Metric
of	O
our	O
system	O
,	O
counting	O
errors	O
in	O
each	O
category	O
independently	O
,	O
0	O
sentences	O
contained	O
repeated	O
words	O
,	O
6	O
contained	O
mispronunciations	O
,	O
1	O
contained	O
skipped	O
words	O
,	O
and	O
23	O
were	O
subjectively	O
decided	O
to	O
contain	O
unnatural	O
prosody	O
,	O
such	O
as	O
emphasis	O
on	O
the	O
wrong	O
syllables	O
or	O
words	O
,	O
or	O
unnatural	O
pitch	O
.	O
End	Task
-	Task
point	Task
prediction	Task
failed	O
in	O
a	O
single	O
case	O
,	O
on	O
the	O
input	O
sentence	O
containing	O
the	O
most	O
characters	O
.	O
These	O
results	O
show	O
that	O
while	O
our	O
system	O
is	O
able	O
to	O
reliably	O
attend	O
to	O
the	O
entire	O
input	O
,	O
there	O
is	O
still	O
room	O
for	O
improvement	O
in	O
prosody	Task
modeling	Task
.	O
Finally	O
,	O
we	O
evaluate	O
samples	O
generated	O
from	O
37	O
news	O
headlines	O
to	O
test	O
the	O
generalization	Metric
ability	Metric
of	O
our	O
system	O
to	O
out	O
-	O
of	O
-	O
domain	O
text	O
.	O
On	O
this	O
task	O
,	O
our	O
model	O
receives	O
a	O
MOS	Metric
of	O
while	O
WaveNet	Method
conditioned	O
on	O
linguistic	O
features	O
receives	O
a	O
MOS	O
of	O
.	O
A	O
side	O
-	O
by	O
-	O
side	O
evaluation	O
comparing	O
the	O
output	O
of	O
these	O
systems	O
also	O
shows	O
a	O
virtual	O
tie	O
–	O
a	O
statistically	O
insignificant	O
preference	O
towards	O
our	O
results	O
by	O
.	O
Examination	O
of	O
rater	O
comments	O
shows	O
that	O
our	O
neural	Method
system	Method
tends	O
to	O
generate	O
speech	O
that	O
feels	O
more	O
natural	O
and	O
human	O
-	O
like	O
,	O
but	O
it	O
sometimes	O
runs	O
into	O
pronunciation	O
difficulties	O
,	O
e.g.	O
,	O
when	O
handling	O
names	O
.	O
This	O
result	O
points	O
to	O
a	O
challenge	O
for	O
end	O
-	O
to	O
-	O
end	O
approaches	O
–	O
they	O
require	O
training	O
on	O
data	O
that	O
cover	O
intended	O
usage	O
.	O
subsection	O
:	O
Ablation	Task
Studies	Task
subsubsection	O
:	O
Predicted	O
Features	O
versus	O
Ground	O
Truth	O
While	O
the	O
two	O
components	O
of	O
our	O
model	O
were	O
trained	O
separately	O
,	O
the	O
WaveNet	Method
component	O
depends	O
on	O
the	O
predicted	O
features	O
for	O
training	O
.	O
An	O
alternative	O
is	O
to	O
train	O
WaveNet	Method
independently	O
on	O
mel	O
spectrograms	O
extracted	O
from	O
ground	O
truth	O
audio	O
.	O
We	O
explore	O
this	O
in	O
Table	O
[	O
reference	O
]	O
.	O
As	O
expected	O
,	O
the	O
best	O
performance	O
is	O
obtained	O
when	O
the	O
features	O
used	O
for	O
training	O
match	O
those	O
used	O
for	O
inference	Task
.	O
However	O
,	O
when	O
trained	O
on	O
ground	O
truth	O
features	O
and	O
made	O
to	O
synthesize	O
from	O
predicted	O
features	O
,	O
the	O
result	O
is	O
worse	O
than	O
the	O
opposite	O
.	O
This	O
is	O
due	O
to	O
the	O
tendency	O
of	O
the	O
predicted	O
spectrograms	O
to	O
be	O
oversmoothed	O
and	O
less	O
detailed	O
than	O
the	O
ground	O
truth	O
–	O
a	O
consequence	O
of	O
the	O
squared	Metric
error	Metric
loss	Metric
optimized	O
by	O
the	O
feature	Method
prediction	Method
network	Method
.	O
When	O
trained	O
on	O
ground	O
truth	O
spectrograms	O
,	O
the	O
network	O
does	O
not	O
learn	O
to	O
generate	O
high	O
quality	O
speech	O
waveforms	O
from	O
oversmoothed	O
features	O
.	O
subsubsection	O
:	O
Linear	Method
Spectrograms	Method
Instead	O
of	O
predicting	O
mel	O
spectrograms	O
,	O
we	O
experiment	O
with	O
training	O
to	O
predict	O
linear	O
-	O
frequency	O
spectrograms	O
instead	O
,	O
making	O
it	O
possible	O
to	O
invert	O
the	O
spectrogram	O
using	O
Griffin	Method
-	Method
Lim	Method
.	O
As	O
noted	O
in	O
,	O
WaveNet	Method
produces	O
much	O
higher	O
quality	O
audio	O
compared	O
to	O
Griffin	O
-	O
Lim	Method
.	O
However	O
,	O
there	O
is	O
not	O
much	O
difference	O
between	O
the	O
use	O
of	O
linear	O
-	O
scale	O
or	O
mel	Method
-	Method
scale	Method
spectrograms	Method
.	O
As	O
such	O
,	O
the	O
use	O
of	O
mel	O
spectrograms	O
seems	O
to	O
be	O
a	O
strictly	O
better	O
choice	O
since	O
it	O
is	O
a	O
more	O
compact	O
representation	O
.	O
It	O
would	O
be	O
interesting	O
to	O
explore	O
the	O
trade	O
-	O
off	O
between	O
the	O
number	O
of	O
mel	O
frequency	O
bins	O
versus	O
audio	Metric
quality	Metric
in	O
future	O
work	O
.	O
subsubsection	O
:	O
Post	Method
-	Method
Processing	Method
Network	Method
Since	O
it	O
is	O
not	O
possible	O
to	O
use	O
the	O
information	O
of	O
predicted	O
future	O
frames	O
before	O
they	O
have	O
been	O
decoded	O
,	O
we	O
use	O
a	O
convolutional	Method
post	Method
-	Method
processing	Method
network	Method
to	O
incorporate	O
past	O
and	O
future	O
frames	O
after	O
decoding	O
to	O
improve	O
the	O
feature	Task
predictions	Task
.	O
However	O
,	O
because	O
WaveNet	Method
already	O
contains	O
convolutional	O
layers	O
,	O
one	O
may	O
wonder	O
if	O
the	O
post	Method
-	Method
net	Method
is	O
still	O
necessary	O
when	O
WaveNet	Method
is	O
used	O
as	O
the	O
vocoder	Method
.	O
To	O
answer	O
this	O
question	O
,	O
we	O
compared	O
our	O
model	O
with	O
and	O
without	O
the	O
post	O
-	O
net	O
,	O
and	O
found	O
that	O
without	O
it	O
,	O
our	O
model	O
only	O
obtains	O
a	O
MOS	Metric
score	Metric
of	O
,	O
compared	O
to	O
with	O
it	O
,	O
meaning	O
that	O
empirically	O
the	O
post	Method
-	Method
net	Method
is	O
still	O
an	O
important	O
part	O
of	O
the	O
network	Task
design	Task
.	O
subsubsection	O
:	O
Simplifying	O
WaveNet	Method
A	O
defining	O
feature	O
of	O
WaveNet	Method
is	O
its	O
use	O
of	O
dilated	Method
convolution	Method
to	O
increase	O
the	O
receptive	O
field	O
exponentially	O
with	O
the	O
number	O
of	O
layers	O
.	O
We	O
evaluate	O
models	O
with	O
varying	O
receptive	O
field	O
sizes	O
and	O
number	O
of	O
layers	O
to	O
test	O
our	O
hypothesis	O
that	O
a	O
shallow	Method
network	Method
with	O
a	O
small	O
receptive	O
field	O
may	O
solve	O
the	O
problem	O
satisfactorily	O
since	O
mel	O
spectrograms	O
are	O
a	O
much	O
closer	O
representation	O
of	O
the	O
waveform	O
than	O
linguistic	O
features	O
and	O
already	O
capture	O
long	O
-	O
term	O
dependencies	O
across	O
frames	O
.	O
As	O
shown	O
in	O
Table	O
[	O
reference	O
]	O
,	O
we	O
find	O
that	O
our	O
model	O
can	O
generate	O
high	O
-	O
quality	O
audio	O
using	O
as	O
few	O
as	O
12	O
layers	O
with	O
a	O
receptive	O
field	O
of	O
10.5	O
ms	O
,	O
compared	O
to	O
30	O
layers	O
and	O
256	O
ms	O
in	O
the	O
baseline	O
model	O
.	O
These	O
results	O
confirm	O
the	O
observations	O
in	O
that	O
a	O
large	O
receptive	O
field	O
size	O
is	O
not	O
an	O
essential	O
factor	O
for	O
audio	Metric
quality	Metric
.	O
However	O
,	O
we	O
hypothesize	O
that	O
it	O
is	O
the	O
choice	O
to	O
condition	O
on	O
mel	O
spectrograms	O
that	O
allows	O
this	O
reduction	O
in	O
complexity	Metric
.	O
On	O
the	O
other	O
hand	O
,	O
if	O
we	O
eliminate	O
dilated	O
convolutions	O
altogether	O
,	O
the	O
receptive	O
field	O
becomes	O
two	O
orders	O
of	O
magnitude	O
smaller	O
than	O
the	O
baseline	O
and	O
the	O
quality	Metric
degrades	O
significantly	O
even	O
though	O
the	O
stack	Method
is	O
as	O
deep	O
as	O
the	O
baseline	O
model	O
.	O
This	O
indicates	O
that	O
the	O
model	O
requires	O
sufficient	O
context	O
at	O
the	O
time	O
scale	O
of	O
waveform	O
samples	O
in	O
order	O
to	O
generate	O
high	O
quality	O
sound	O
.	O
section	O
:	O
Conclusion	O
This	O
paper	O
describes	O
Tacotron	Method
2	Method
,	O
a	O
fully	Method
neural	Method
TTS	Method
system	Method
that	O
combines	O
a	O
sequence	Method
-	Method
to	Method
-	Method
sequence	Method
recurrent	Method
network	Method
with	O
attention	Method
to	O
predicts	O
mel	O
spectrograms	O
with	O
a	O
modified	O
WaveNet	Method
vocoder	O
.	O
The	O
resulting	O
system	O
synthesizes	O
speech	O
with	O
Tacotron	Method
-	O
level	O
prosody	O
and	O
WaveNet	Method
-	O
level	O
audio	O
quality	O
.	O
This	O
system	O
can	O
be	O
trained	O
directly	O
from	O
data	O
without	O
relying	O
on	O
complex	O
feature	Method
engineering	Method
,	O
and	O
achieves	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
sound	Metric
quality	Metric
close	O
to	O
that	O
of	O
natural	O
human	O
speech	O
.	O
section	O
:	O
Acknowledgments	O
The	O
authors	O
thank	O
Jan	O
Chorowski	O
,	O
Samy	O
Bengio	O
,	O
Aäron	O
van	O
den	O
Oord	O
,	O
and	O
the	O
WaveNet	Method
and	O
Machine	O
Hearing	O
teams	O
for	O
their	O
helpful	O
discussions	O
and	O
advice	O
,	O
as	O
well	O
as	O
Heiga	O
Zen	O
and	O
the	O
Google	Method
TTS	Method
team	O
for	O
their	O
feedback	O
and	O
assistance	O
with	O
running	O
evaluations	O
.	O
The	O
authors	O
are	O
also	O
grateful	O
to	O
the	O
very	O
thorough	O
reviewers	O
.	O
bibliography	O
:	O
References	O
