document O
: O
Neural Method
Ranking Method
Models Method
with O
Weak Method
Supervision Method
Despite O
the O
impressive O
improvements O
achieved O
by O
unsupervised Method
deep Method
neural Method
networks Method
in O
computer Task
vision Task
and O
NLP Task
tasks Task
, O
such O
improvements O
have O
not O
yet O
been O
observed O
in O
ranking Task
for O
information Task
retrieval Task
. O
The O
reason O
may O
be O
the O
complexity O
of O
the O
ranking Task
problem Task
, O
as O
it O
is O
not O
obvious O
how O
to O
learn O
from O
queries O
and O
documents O
when O
no O
supervised O
signal O
is O
available O
. O
Hence O
, O
in O
this O
paper O
, O
we O
propose O
to O
train O
a O
neural Method
ranking Method
model Method
using O
weak O
supervision O
, O
where O
labels O
are O
obtained O
automatically O
without O
human O
annotators O
or O
any O
external O
resources O
( O
e.g. O
, O
click O
data O
) O
. O
To O
this O
aim O
, O
we O
use O
the O
output O
of O
an O
unsupervised Method
ranking Method
model Method
, O
such O
as O
BM25 Method
, O
as O
a O
weak O
supervision O
signal O
. O
We O
further O
train O
a O
set O
of O
simple O
yet O
effective O
ranking Method
models Method
based O
on O
feed Method
- Method
forward Method
neural Method
networks Method
. O
We O
study O
their O
effectiveness O
under O
various O
learning Task
scenarios Task
( O
point Method
- Method
wise Method
and Method
pair Method
- Method
wise Method
models Method
) O
and O
using O
different O
input O
representations O
( O
i.e. O
, O
from O
encoding O
query O
- O
document O
pairs O
into O
dense O
/ O
sparse O
vectors O
to O
using O
word Method
embedding Method
representation Method
) O
. O
We O
train O
our O
networks O
using O
tens O
of O
millions O
of O
training Metric
instances O
and O
evaluate O
it O
on O
two O
standard O
collections O
: O
a O
homogeneous Material
news Material
collection Material
( O
Robust Material
) O
and O
a O
heterogeneous O
large O
- O
scale O
web O
collection O
( O
ClueWeb O
) O
. O
Our O
experiments O
indicate O
that O
employing O
proper O
objective O
functions O
and O
letting O
the O
networks O
to O
learn O
the O
input Method
representation Method
based O
on O
weakly O
supervised O
data O
leads O
to O
impressive O
performance O
, O
with O
over O
13 O
% O
and O
35 O
% O
MAP Metric
improvements O
over O
the O
BM25 Method
model Method
on O
the O
Robust Material
and O
the O
ClueWeb O
collections O
. O
Our O
findings O
also O
suggest O
that O
supervised Method
neural Method
ranking Method
models Method
can O
greatly O
benefit O
from O
pre O
- O
training Metric
on O
large O
amounts O
of O
weakly O
labeled O
data O
that O
can O
be O
easily O
obtained O
from O
unsupervised O
IR Task
models O
. O
KEYWORDS O
Ranking Method
model Method
, O
weak Method
supervision Method
, O
deep Method
neural Method
network Method
, O
deep Method
learning Method
, O
ad Task
- Task
hoc Task
retrieval O
compat=1.11 O
ternary O
compat O
= O
newest O
0.98 O
perpHTMLA411CC O
cyanHTML307D7E O
2017 O
2017 O
rightsretained O
SIGIR’17August07 O
- O
11 O
, O
2017Shinjuku O
, O
Tokyo O
, O
Japan O
10.1145 O
/ O
3077136.3080832 O
978 O
- O
1 O
- O
4503 O
- O
5022 O
- O
8 O
/ O
17 O
/ O
08 O
Work O
done O
while O
interning O
at O
Google O
Research O
. O
section O
: O
Introduction O
Learning O
state O
- O
of O
- O
the O
- O
art O
deep Method
neural Method
network Method
models Method
requires O
a O
large O
amounts O
of O
labeled O
data O
, O
which O
is O
not O
always O
readily O
available O
and O
can O
be O
expensive O
to O
obtain O
. O
To O
circumvent O
the O
lack O
of O
human O
- O
labeled O
training Metric
examples O
, O
unsupervised Method
learning Method
methods Method
aim O
to O
model O
the O
underlying O
data O
distribution O
, O
thus O
learning O
powerful O
feature Method
representations Method
of O
the O
input O
data O
, O
which O
can O
be O
helpful O
for O
building O
more O
accurate O
discriminative Method
models Method
especially O
when O
little O
or O
even O
no O
supervised O
data O
is O
available O
. O
A O
large O
group O
of O
unsupervised Method
neural Method
models Method
seeks O
to O
exploit O
the O
implicit O
internal O
structure O
of O
the O
input O
data O
, O
which O
in O
turn O
requires O
customized O
formulation O
of O
the O
training Metric
objective O
( O
loss O
function O
) O
, O
targeted Method
network Method
architectures Method
and O
often O
non O
- O
trivial O
training Metric
setups O
. O
For O
example O
in O
NLP Task
, O
various O
methods O
for O
learning O
distributed Method
word Method
representations Method
, O
e.g. O
, O
word2vec O
Mikolov:2013 O
, O
GloVe O
Pennington:2014 O
, O
and O
sentence Method
representations Method
, O
e.g. O
, O
paragraph O
vectors O
Le:2014 O
and O
skip Method
- Method
thought Method
Kiros:2015 O
have O
been O
shown O
very O
useful O
to O
pre O
- O
train O
word Method
embeddings Method
that O
are O
then O
used O
for O
other O
tasks O
such O
as O
sentence Task
classification Task
, O
sentiment Task
analysis Task
, O
etc O
. O
Other O
generative Method
approaches Method
such O
as O
language Method
modeling Method
in O
NLP Method
, O
and O
, O
more O
recently O
, O
various O
flavors O
of O
auto Method
- Method
encoders Method
Baldi:2012 Method
and O
generative Method
adversarial Method
networks Method
Goodfellow:2014 O
in O
computer Task
vision Task
have O
shown O
a O
promise O
in O
building O
more O
accurate O
models O
. O
Despite O
the O
advances O
in O
computer Task
vision Task
, O
speech Task
recognition Task
, O
and O
NLP Task
tasks Task
using O
unsupervised Method
deep Method
neural Method
networks Method
, O
such O
advances O
have O
not O
been O
observed O
in O
core Task
information Task
retrieval Task
( O
IR Task
) O
problems O
, O
such O
as O
ranking Task
. O
A O
plausible O
explanation O
is O
the O
complexity O
of O
the O
ranking Task
problem Task
in O
IR Task
, O
in O
the O
sense O
that O
it O
is O
not O
obvious O
how O
to O
learn O
a O
ranking Method
model Method
from O
queries O
and O
documents O
when O
no O
supervision O
in O
form O
of O
the O
relevance O
information O
is O
available O
. O
To O
overcome O
this O
issue O
, O
in O
this O
paper O
, O
we O
propose O
to O
leverage O
large O
amounts O
of O
unsupervised O
data O
to O
infer O
“ O
noisy O
” O
or O
“ O
weak O
” O
labels O
and O
use O
that O
signal O
for O
learning O
supervised Method
models Method
as O
if O
we O
had O
the O
ground O
truth O
labels O
. O
In O
particular O
, O
we O
use O
classic O
unsupervised O
IR Task
models O
as O
a O
weak O
supervision O
signal O
for O
training Metric
deep Method
neural Method
ranking Method
models Method
. O
Weak Task
supervision Task
here O
refers O
to O
a O
learning Method
approach Method
that O
creates O
its O
own O
training Metric
data O
by O
heuristically O
retrieving O
documents O
for O
a O
large O
query O
set O
. O
This O
training Metric
data O
is O
created O
automatically O
, O
and O
thus O
it O
is O
possible O
to O
generate O
billions O
of O
training Metric
instances O
with O
almost O
no O
cost O
. O
As O
training Metric
deep Method
neural Method
networks Method
is O
an O
exceptionally O
data Task
hungry Task
process Task
, O
the O
idea O
of O
pre O
- O
training Metric
on O
massive O
amount O
of O
weakly O
supervised O
data O
and O
then O
fine O
- O
tuning O
the O
model O
using O
a O
small O
amount O
of O
supervised O
data O
could O
improve O
the O
performance O
Rrhan:2010 O
. O
The O
main O
aim O
of O
this O
paper O
is O
to O
study O
the O
impact O
of O
weak O
supervision O
on O
neural Method
ranking Method
models Method
, O
which O
we O
break O
down O
into O
the O
following O
concrete O
research O
questions O
: O
Can O
labels O
from O
an O
unsupervised O
IR Task
model O
such O
as O
BM25 Method
be O
used O
as O
weak O
supervision O
signal O
to O
train O
an O
effective O
neural Method
ranker Method
? O
What O
input O
representation O
and O
learning Metric
objective Metric
is O
most O
suitable O
for O
learning Task
in O
such O
a O
setting O
? O
Can O
a O
supervised Method
learning Method
model Method
benefit O
from O
a O
weak O
supervision O
step O
, O
especially O
in O
cases O
when O
labeled O
data O
is O
limited O
? O
We O
examine O
various O
neural Method
ranking Method
models Method
with O
different O
ranking Method
architectures Method
and O
objectives O
, O
i.e. O
, O
point O
- O
wise O
and O
pair O
- O
wise O
, O
as O
well O
as O
different O
input O
representations O
, O
from O
encoding O
query O
- O
document O
pairs O
into O
dense O
/ O
sparse O
vectors O
to O
learning O
query Method
/ Method
document Method
embedding Method
representations Method
. O
The O
models O
are O
trained O
on O
billions O
of O
training Metric
examples O
that O
are O
annotated O
by O
BM25 Method
, O
as O
the O
weak O
supervision O
signal O
. O
Interestingly O
, O
we O
observe O
that O
using O
just O
training Metric
data O
that O
are O
annotated O
by O
BM25 Method
as O
the O
weak O
annotator O
, O
we O
can O
outperform O
BM25 Method
itself O
on O
the O
test O
data O
. O
Based O
on O
our O
analysis O
, O
the O
achieved O
performance O
is O
generally O
indebted O
to O
three O
main O
factors O
: O
First O
, O
defining O
an O
objective Method
function Method
that O
aims O
to O
learn O
the O
ranking Task
instead O
of O
calibrated O
scoring O
to O
relax O
the O
network O
from O
fitting O
to O
the O
imperfections O
in O
the O
weakly O
supervised O
training Metric
data O
. O
Second O
, O
letting O
the O
neural Method
networks Method
learn O
optimal O
query Method
/ Method
document Method
representations Method
instead O
of O
feeding O
them O
with O
a O
representation O
based O
on O
predefined O
features O
. O
This O
is O
a O
key O
requirement O
to O
maximize O
the O
benefits O
from O
deep Method
learning Method
models Method
with O
weak O
supervision O
as O
it O
enables O
them O
to O
generalize O
better O
. O
Third O
and O
last O
, O
the O
weak Method
supervision Method
setting Method
makes O
it O
possible O
to O
train O
the O
network O
on O
a O
massive O
amount O
of O
training Metric
data O
. O
We O
further O
thoroughly O
analyse O
the O
behavior O
of O
models O
to O
understand O
what O
they O
learn O
, O
what O
is O
the O
relationship O
among O
different O
models O
, O
and O
how O
much O
training Metric
data O
is O
needed O
to O
go O
beyond O
the O
weak O
supervision O
signal O
. O
We O
also O
study O
if O
employing O
deep Method
neural Method
networks Method
may O
help O
in O
different O
situations O
. O
Finally O
, O
we O
examine O
the O
scenario O
of O
using O
the O
network O
trained O
on O
a O
weak O
supervision O
signal O
as O
a O
pre O
- O
training Metric
step O
. O
We O
demonstrate O
that O
, O
in O
the O
ranking Task
problem Task
, O
the O
performance O
of O
deep Method
neural Method
networks Method
trained O
on O
a O
limited O
amount O
of O
supervised O
data O
significantly O
improves O
when O
they O
are O
initialized O
from O
a O
model O
pre O
- O
trained O
on O
weakly O
labeled O
data O
. O
Our O
results O
have O
broad O
impact O
as O
the O
proposal O
to O
use O
unsupervised Method
traditional Method
methods Method
as O
weak O
supervision O
signals O
is O
applicable O
to O
variety O
of O
IR Task
tasks Task
, O
such O
as O
filtering Task
or O
classification Task
, O
without O
the O
need O
for O
supervised O
data O
. O
More O
generally O
, O
our O
approach O
unifies O
the O
classic O
IR Task
models O
with O
currently O
emerging O
data Method
- Method
driven Method
approaches Method
in O
an O
elegant O
way O
. O
section O
: O
Related O
Work O
Deep Method
neural Method
networks Method
have O
shown O
impressive O
performance O
in O
many O
computer Task
vision Task
, O
natural Task
language Task
processing Task
, O
and O
speech Task
recognition Task
tasks Task
Lecun:2015 O
. O
Recently O
, O
several O
attempts O
have O
been O
made O
to O
study O
deep Method
neural Method
networks Method
in O
IR Task
applications O
, O
which O
can O
be O
generally O
partitioned O
into O
two O
categories O
Onal:2016 O
, O
Zhang:2016 O
. O
The O
first O
category O
includes O
approaches O
that O
use O
the O
results O
of O
trained O
( O
deep Method
) Method
neural Method
networks Method
in O
order O
to O
improve O
the O
performance O
in O
IR Task
applications O
. O
Among O
these O
, O
distributed Method
word Method
representations Method
or O
embeddings Method
Mikolov:2013 O
, O
Pennington:2014 O
have O
attracted O
a O
lot O
of O
attention O
. O
Word Method
embedding Method
vectors Method
have O
been O
applied O
to O
term Task
re Task
- Task
weighting Task
in O
IR Task
models O
Zheng:2015 O
, O
Rekabsaz:2017 O
, O
query Task
expansion Task
Diaz:2016 O
, O
Zamani:2016a O
, O
Rekabsaz:2016 O
, O
query Task
classification Task
Liu:2015 O
, O
Zamani:2016b O
, O
etc O
. O
The O
main O
shortcoming O
of O
most O
of O
the O
approaches O
in O
this O
category O
is O
that O
the O
objective O
of O
the O
trained O
neural Method
network Method
differs O
from O
the O
objective O
of O
these O
tasks O
. O
For O
instance O
, O
the O
word Method
embedding Method
vectors Method
proposed O
in O
Mikolov:2013 O
, O
Pennington:2014 O
are O
trained O
based O
on O
term O
proximity O
in O
a O
large O
corpus O
, O
which O
is O
different O
from O
the O
objective O
in O
most O
IR Task
tasks Task
. O
To O
overcome O
this O
issue O
, O
some O
approaches O
try O
to O
learn O
representations O
in O
an O
end Method
- Method
to Method
- Method
end Method
neural Method
model Method
for O
learning O
a O
specific O
task O
like O
entity Task
ranking Task
for O
expert Task
finding Task
VanGysel:2016:www O
or O
product Task
search Task
VanGysel:2016:cikm O
. O
Zamani:2017 O
recently O
proposed O
relevance Method
- Method
based Method
word Method
embedding Method
models Method
for O
learning Task
word Task
representations Task
based O
on O
the O
objectives O
that O
matter O
for O
IR Task
applications O
. O
The O
second O
category O
, O
which O
this O
paper O
belongs O
to O
, O
consists O
of O
the O
approaches O
that O
design O
and O
train O
a O
( O
deep Method
) Method
neural Method
network Method
for O
a O
specific O
task O
, O
e.g. O
, O
question Task
answering Task
Cohen:2016 O
, O
Yang:2016 O
, O
click Method
models Method
Borisov:2016 O
, O
context Task
- Task
aware Task
ranking Task
Zamani:2017b O
, O
etc O
. O
A O
number O
of O
the O
approaches O
in O
this O
category O
have O
been O
proposed O
for O
ranking Task
documents Task
in O
response O
to O
a O
given O
query O
. O
These O
approaches O
can O
be O
generally O
divided O
into O
two O
groups O
: O
late Method
combination Method
models Method
and O
early Method
combination Method
models Method
( O
or O
representation Method
- Method
focused Method
and Method
interaction Method
- Method
focused Method
models Method
according O
to O
Guo:2016 O
) O
. O
The O
late Method
combination Method
models Method
, O
following O
the O
idea O
of O
Siamese Method
networks Method
Bromley:1993 O
, O
independently O
learn O
a O
representation O
for O
each O
query O
and O
candidate O
document O
and O
then O
calculate O
the O
similarity O
between O
the O
two O
estimated O
representations O
via O
a O
similarity Method
function Method
. O
For O
example O
, O
Huang:2013 O
proposed O
DSSM Method
, O
which O
is O
a O
feed Method
forward Method
neural Method
network Method
with O
a O
word Method
hashing Method
phase Method
as O
the O
first O
layer O
to O
predict O
the O
click O
probability O
given O
a O
query O
string O
and O
a O
document O
title O
. O
The O
DSSM Method
model Method
was O
further O
improved O
by O
incorporating O
convolutional Method
neural Method
networks Method
Shen:2014 O
. O
On O
the O
other O
hand O
, O
the O
early Method
combination Method
models Method
are O
designed O
based O
on O
the O
interactions O
between O
the O
query O
and O
the O
candidate O
document O
as O
the O
input O
of O
network O
. O
For O
instance O
, O
DeepMatch Method
Lu:2013 Method
maps O
each O
text O
to O
a O
sequence O
of O
terms O
and O
trains O
a O
feed Method
- Method
forward Method
network Method
for O
computing O
the O
matching Metric
score Metric
. O
The O
deep Method
relevance Method
matching Method
model Method
for O
ad Task
- Task
hoc Task
retrieval O
Guo:2016 O
is O
another O
example O
of O
an O
early Method
combination Method
model Method
that O
feeds O
a O
neural Method
network Method
with O
the O
histogram O
- O
based O
features O
representing O
interactions O
between O
the O
query O
and O
document O
. O
Early Method
combining Method
enables O
the O
model O
to O
have O
an O
opportunity O
to O
capture O
various O
interactions O
between O
query O
and O
document O
( O
s O
) O
, O
while O
with O
late Method
combination Method
approach Method
, O
the O
model O
has O
only O
the O
chance O
of O
isolated O
observation O
of O
input O
elements O
. O
Recently O
, O
Mitra O
et O
al O
. O
Mitra:2016 O
proposed O
to O
simultaneously O
learn O
local Method
and Method
distributional Method
representations Method
, O
which O
are O
early Method
and Method
late Method
combination Method
models Method
respectively O
, O
to O
capture O
both O
exact Task
term Task
matching Task
and O
semantic Task
term Task
matching Task
. O
Until O
now O
, O
all O
the O
proposed O
neural Method
models Method
for O
ranking Task
are O
trained O
on O
either O
explicit O
relevance O
judgements O
or O
clickthrough O
logs O
. O
However O
, O
a O
massive O
amount O
of O
such O
training Metric
data O
is O
not O
always O
available O
. O
In O
this O
paper O
, O
we O
propose O
to O
train O
neural Method
ranking Method
models Method
using O
weak Method
supervision Method
, O
which O
is O
the O
most O
natural O
way O
to O
reuse O
the O
existing O
supervised Method
learning Method
models Method
where O
the O
imperfect O
labels O
are O
treated O
as O
the O
ground O
truth O
. O
The O
basic O
assumption O
is O
that O
we O
can O
cheaply O
obtain O
labels O
( O
that O
are O
of O
lower O
quality O
than O
human O
- O
provided O
labels O
) O
by O
expressing O
the O
prior O
knowledge O
we O
have O
about O
the O
task O
at O
hand O
by O
specifying O
a O
set O
of O
heuristics O
, O
adapting O
existing O
ground O
truth O
data O
for O
a O
different O
but O
related O
task O
( O
this O
is O
often O
referred O
to O
distant Task
supervision Task
) O
, O
extracting O
supervision O
signal O
from O
external O
knowledge O
- O
bases O
or O
ontologies O
, O
crowd O
- O
sourcing O
partial O
annotations O
that O
are O
cheaper O
to O
get O
, O
etc O
. O
Weak Method
supervision Method
is O
a O
natural O
way O
to O
benefit O
from O
unsupervised O
data O
and O
it O
has O
been O
applied O
in O
NLP Task
for O
various O
tasks O
including O
relation Task
extraction Task
Bing:2015 O
, O
Han:2016 O
, O
knowledge Task
- Task
base Task
completion Task
Hoffmann:2011 O
, O
sentiment Task
analysis Task
Severyn:2015 O
, O
etc O
. O
There O
are O
also O
similar O
attempts O
in O
IR Task
for O
automatically Task
constructing Task
test Task
collections Task
Asadi:2011 O
and O
learning O
to O
rank O
using O
labeled O
features O
, O
i.e. O
features O
that O
an O
expert O
believes O
they O
are O
correlated O
with O
relevance O
Diaz:2016:ictir O
. O
In O
this O
paper O
, O
we O
make O
use O
of O
traditional O
IR Task
models O
as O
the O
weak O
supervision O
signal O
to O
generate O
a O
large O
amount O
of O
training Metric
data O
and O
train O
effective O
neural Method
ranking Method
models Method
that O
outperform O
the O
baseline O
methods O
by O
a O
significant O
margin O
. O
section O
: O
Weak Task
Supervision Task
for O
Ranking Task
Deep Method
learning Method
techniques Method
have O
taken O
off O
in O
many O
fields O
, O
as O
they O
automate O
the O
onerous Task
task Task
of O
input Task
representation Task
and O
feature Task
engineering Task
. O
On O
the O
other O
hand O
, O
the O
more O
the O
neural Method
networks Method
become O
deep O
and O
complex O
, O
the O
more O
it O
is O
crucial O
for O
them O
to O
be O
trained O
on O
massive O
amounts O
of O
training Metric
data O
. O
In O
many O
applications O
, O
rich O
annotations O
are O
costly O
to O
obtain O
and O
task O
- O
specific O
training Metric
data O
is O
now O
a O
critical O
bottleneck O
. O
Hence O
, O
unsupervised Method
learning Method
is O
considered O
as O
a O
long O
standing O
goal O
for O
several O
applications O
. O
However O
, O
in O
a O
number O
of O
information Task
retrieval Task
tasks O
, O
such O
as O
ranking Task
, O
it O
is O
not O
obvious O
how O
to O
train O
a O
model O
with O
large O
numbers O
of O
queries O
and O
documents O
with O
no O
relevance O
signal O
. O
To O
address O
this O
problem O
in O
an O
unsupervised Task
fashion Task
, O
we O
use O
the O
idea O
of O
“ O
Pseudo Task
- Task
Labeling Task
” O
by O
taking O
advantage O
of O
existing O
unsupervised Method
methods Method
for O
creating O
a O
weakly O
annotated O
set O
of O
training Metric
data O
and O
we O
propose O
to O
train O
a O
neural Method
retrieval Method
model Method
with O
weak O
supervision O
signals O
we O
have O
generated O
. O
In O
general O
, O
weak Task
supervision Task
refers O
to O
learning O
from O
training Metric
data O
in O
which O
the O
labels O
are O
imprecise O
. O
In O
this O
paper O
, O
we O
refer O
to O
weak Task
supervision Task
as O
a O
learning Method
approach Method
that O
automatically O
creates O
its O
own O
training Metric
data O
using O
an O
existing O
unsupervised Method
approach Method
, O
which O
differs O
from O
imprecise O
data O
coming O
from O
external O
observations O
( O
e.g. O
, O
click O
- O
through O
data O
) O
or O
noisy O
human O
- O
labeled O
data O
. O
We O
focus O
on O
query Task
- Task
dependent Task
ranking Task
as O
a O
core O
IR Task
task Task
. O
To O
this O
aim O
, O
we O
take O
a O
well O
- O
performing O
existing O
unsupervised Method
retrieval Method
model Method
, O
such O
as O
BM25 Method
. O
This O
model O
plays O
the O
role O
of O
“ O
pseudo O
- O
labeler O
” O
in O
our O
learning Task
scenario Task
. O
In O
more O
detail O
, O
given O
a O
target O
collection O
and O
a O
large O
set O
of O
training Metric
queries O
( O
without O
relevance O
judgments O
) O
, O
we O
make O
use O
of O
the O
pseudo Method
- Method
labeler Method
to O
rank O
/ O
score O
the O
documents O
for O
each O
query O
in O
the O
training Metric
query O
set O
. O
Note O
that O
we O
can O
generate O
as O
much O
as O
training Metric
data O
as O
we O
need O
with O
almost O
no O
cost O
. O
The O
goal O
is O
to O
train O
a O
ranking Method
model Method
given O
the O
scores O
/ O
ranking O
generated O
by O
the O
pseudo Method
- Method
labeler Method
as O
a O
weak O
supervision O
signal O
. O
In O
the O
following O
section O
, O
we O
formally O
present O
a O
set O
of O
neural Method
network Method
- Method
based Method
ranking Method
models Method
that O
can O
leverage O
the O
given O
weak O
supervision O
signal O
in O
order O
to O
learn O
accurate O
representations Task
and O
ranking Task
for O
the O
ad Task
- Task
hoc Task
retrieval O
task O
. O
section O
: O
Neural Method
Ranking Method
Models Method
In O
this O
section O
, O
we O
first O
introduce O
our O
ranking Method
models Method
. O
Then O
, O
we O
describe O
the O
architecture O
of O
the O
base Method
neural Method
network Method
model Method
shared O
by O
different O
ranking Method
models Method
. O
Finally O
, O
we O
discuss O
the O
three O
input Method
layer Method
architectures Method
used O
in O
our O
neural Method
rankers Method
to O
encode O
( O
query O
, O
candidate O
document O
) O
pairs O
. O
[ O
t O
] O
0.23 O
[ O
t O
] O
0.40 O
[ O
t O
] O
0.37 O
subsection O
: O
Ranking Method
Architectures Method
We O
define O
three O
different O
ranking Method
models Method
: O
one O
point Method
- Method
wise Method
and O
two O
pair Method
- Method
wise Method
models Method
. O
We O
introduce O
the O
architecture O
of O
these O
models O
and O
explain O
how O
we O
train O
them O
using O
weak O
supervision O
signals O
. O
Score Method
model Method
: O
This O
architecture O
models O
a O
point Method
- Method
wise Method
ranking Method
model Method
that O
learns O
to O
predict O
retrieval O
scores O
for O
query O
- O
document O
pairs O
. O
More O
formally O
, O
the O
goal O
in O
this O
architecture O
is O
to O
learn O
a O
scoring O
function O
that O
determines O
the O
retrieval Metric
score Metric
of O
document O
for O
query O
, O
given O
a O
set O
of O
model O
parameters O
. O
In O
the O
training Metric
stage O
, O
we O
are O
given O
a O
training Metric
set O
comprising O
of O
training Metric
instances O
each O
a O
triple O
, O
where O
is O
a O
query O
from O
training Metric
query O
set O
, O
represents O
a O
retrieved O
document O
for O
the O
query O
, O
and O
is O
the O
relevance O
score O
( O
calculated O
by O
a O
weak Method
supervisor Method
) O
, O
which O
is O
acquired O
using O
a O
retrieval Method
scoring Method
function Method
in O
our O
setup O
. O
We O
consider O
the O
mean Metric
squared Metric
error Metric
as O
the O
loss Metric
function Metric
for O
a O
given O
batch O
of O
training Metric
instances O
: O
where O
denotes O
the O
query O
and O
the O
corresponding O
retrieved O
document O
in O
the O
training Metric
instance O
, O
i.e. O
in O
the O
batch O
. O
The O
conceptual Method
architecture Method
of O
the O
model O
is O
illustrated O
in O
Figure O
[ O
reference O
] O
. O
Rank Method
model Method
: O
In O
this O
model O
, O
similar O
to O
the O
previous O
one O
, O
the O
goal O
is O
to O
learn O
a O
scoring O
function O
for O
a O
given O
pair O
of O
query O
and O
document O
with O
the O
set O
of O
model O
parameters O
. O
However O
, O
unlike O
the O
previous O
model O
, O
we O
do O
not O
aim O
to O
learn O
a O
calibrated O
scoring O
function O
. O
In O
this O
model O
, O
as O
it O
is O
depicted O
in O
Figure O
[ O
reference O
] O
, O
we O
use O
a O
pair O
- O
wise O
scenario O
during O
training Metric
in O
which O
we O
have O
two O
point O
- O
wise Method
networks Method
that O
share O
parameters O
and O
we O
update O
their O
parameters O
to O
minimize O
a O
pair Metric
- Metric
wise Metric
loss Metric
. O
In O
this O
model O
, O
each O
training Metric
instance O
has O
five O
elements O
: O
. O
During O
the O
inference Task
, O
we O
treat O
the O
trained O
model O
as O
a O
point Method
- Method
wise Method
scoring Method
function Method
to O
score O
query O
- O
document O
pairs O
. O
We O
have O
tried O
different O
pair O
- O
wise Metric
loss Metric
functions Metric
and O
empirically O
found O
that O
the O
model O
learned O
based O
on O
the O
hinge Method
loss Method
( O
max Method
- Method
margin Method
loss Method
function Method
) O
performs O
better O
than O
the O
others O
. O
Hinge Method
loss Method
is O
a O
linear Method
loss Method
that O
penalizes O
examples O
that O
violate O
the O
margin O
constraint O
. O
It O
is O
widely O
used O
in O
various O
learning Task
to Task
rank Task
algorithms Task
, O
such O
as O
Ranking Task
SVM Task
Herbrich:1999 O
. O
The O
hinge Method
loss Method
function Method
for O
a O
batch O
of O
training Metric
instances O
is O
defined O
as O
follows O
: O
where O
is O
the O
parameter O
determining O
the O
margin O
of O
hinge O
loss O
. O
We O
found O
that O
as O
we O
compress O
the O
outputs O
to O
the O
range O
of O
, O
works O
well O
as O
the O
margin O
for O
the O
hinge O
loss O
function O
. O
RankProb Method
model Method
: O
The O
third O
architecture O
is O
based O
on O
a O
pair Method
- Method
wise Method
scenario Method
during O
both O
training Metric
and O
inference Task
( O
Figure O
[ O
reference O
] O
) O
. O
This O
model O
learns O
a O
ranking Method
function Method
which O
predicts O
the O
probability O
of O
document O
to O
be O
ranked O
higher O
than O
given O
. O
Similar O
to O
the O
rank Method
model Method
, O
each O
training Metric
instance O
has O
five O
elements O
: O
. O
For O
a O
given O
batch O
of O
training Metric
instances O
, O
we O
define O
our O
loss O
function O
based O
on O
cross Metric
- Metric
entropy Metric
as O
follows O
: O
L O
( O
b O
; O
) O
= O
- O
_ O
i=1^—b— O
P_{q O
, O
d_1 O
, O
d_2}_i O
( O
R O
( O
{ O
q O
, O
d_1 O
, O
d_2}_i O
; O
) O
) O
+ O
( O
1 O
- O
P_{q O
, O
d_1 O
, O
d_2}_i O
) O
( O
1 O
- O
R O
( O
{ O
q O
, O
d_1 O
, O
d_2}_i O
; O
) O
) O
where O
is O
the O
probability O
of O
document O
being O
ranked O
higher O
than O
, O
based O
on O
the O
scores O
obtained O
from O
training Metric
instance O
: O
It O
is O
notable O
that O
at O
inference Task
time Task
, O
we O
need O
a O
scalar O
score O
for O
each O
document O
. O
Therefore O
, O
we O
need O
to O
turn O
the O
model O
’s O
pair O
- O
wise O
predictions O
into O
a O
score O
per O
document O
. O
To O
do O
so O
, O
for O
each O
document O
, O
we O
calculate O
the O
average O
of O
predictions O
against O
all O
other O
candidate O
documents O
, O
which O
has O
time Metric
complexity Metric
and O
is O
not O
practical O
in O
real Task
- Task
world Task
applications Task
. O
There O
are O
some O
approximations O
could O
be O
applicable O
to O
decrease O
the O
time Metric
complexity Metric
at O
inference O
time O
Wauthier:2013 O
. O
subsection O
: O
Neural Method
Network Method
Architecture Method
As O
shown O
in O
Figure O
[ O
reference O
] O
, O
all O
the O
described O
ranking Method
architectures Method
share O
a O
neural Method
network Method
module Method
. O
We O
opted O
for O
a O
simple O
feed Method
- Method
forward Method
neural Method
network Method
which O
is O
composed O
of O
: O
input O
layer O
, O
hidden O
layers O
, O
and O
the O
output O
layer O
. O
The O
input O
layer O
provides O
a O
mapping O
to O
encode O
the O
input O
query O
and O
document O
( O
s O
) O
into O
a O
fixed O
- O
length O
vector O
. O
The O
exact O
specification O
of O
the O
input O
representation O
feature O
function O
is O
given O
in O
the O
next O
subsection O
. O
Each O
hidden Method
layer Method
is O
a O
fully Method
- Method
connected Method
layer Method
that O
computes O
the O
following O
transformation O
: O
where O
and O
respectively O
denote O
the O
weight O
matrix O
and O
the O
bias O
term O
corresponding O
to O
the O
hidden O
layer O
, O
and O
is O
the O
activation O
function O
. O
We O
use O
the O
rectifier Method
linear Method
unit Method
as O
the O
activation O
function O
, O
which O
is O
a O
common O
choice O
in O
the O
deep Task
learning Task
literature Task
Lecun:2015 O
. O
The O
output Method
layer Method
is O
a O
fully Method
- Method
connected Method
layer Method
with O
a O
single O
continuous O
output O
. O
The O
activation O
function O
for O
the O
output Method
layer Method
depends O
on O
the O
ranking Method
architecture Method
that O
we O
use O
. O
For O
the O
score Method
model Method
architecture Method
, O
we O
empirically O
found O
that O
a O
linear O
activation O
function O
works O
best O
, O
while O
and O
the O
sigmoid Method
functions Method
are O
used O
for O
the O
rank Method
model Method
and O
rankprob Method
model Method
respectively O
. O
Furthermore O
, O
to O
prevent O
feature Task
co Task
- Task
adaptation Task
, O
we O
use O
dropout Method
Srivastava:2014 Method
as O
the O
regularization Method
technique Method
in O
all O
the O
models O
. O
Dropout Method
sets O
a O
portion O
of O
hidden O
units O
to O
zero O
during O
the O
forward O
phase O
when O
computing O
the O
activations O
which O
prevents O
overfitting O
. O
subsection O
: O
Input Method
Representations Method
We O
explore O
three O
definitions O
of O
the O
input Method
layer Method
representation Method
captured O
by O
a O
feature Method
function Method
that O
maps O
the O
input O
into O
a O
fixed O
- O
size O
vector O
which O
is O
further O
fed O
into O
the O
fully Method
connected Method
layers Method
: O
( O
i O
) O
a O
conventional O
dense Method
feature Method
vector Method
representation Method
that O
contains O
various O
statistics O
describing O
the O
input O
query O
- O
document O
pair O
, O
( O
ii O
) O
a O
sparse Method
vector Method
containing O
bag Method
- Method
of Method
- Method
words Method
representation Method
, O
and O
( O
iii O
) O
bag Method
- Method
of Method
- Method
embeddings Method
averaged O
with O
learned O
weights O
. O
These O
input O
representations O
define O
how O
much O
capacity O
is O
given O
to O
the O
network O
to O
extract O
discriminative O
signal O
from O
the O
training Metric
data O
and O
thus O
result O
in O
different O
generalization O
behavior O
of O
the O
networks O
. O
It O
is O
noteworthy O
that O
input O
representation O
of O
the O
networks O
in O
the O
score Method
model Method
and O
rank Method
model Method
is O
defined O
for O
a O
pair O
of O
the O
query O
and O
the O
document O
, O
while O
the O
network O
in O
the O
rankprob Method
model Method
needs O
to O
be O
fed O
by O
a O
triple O
of O
the O
query O
, O
the O
first O
document O
, O
and O
the O
second O
document O
. O
Dense Method
vector Method
representation Method
( O
Dense Method
) O
: O
In O
this O
setting O
, O
we O
build O
a O
dense O
feature O
vector O
composed O
of O
features O
used O
by O
traditional O
IR Task
methods O
, O
e.g. O
, O
BM25 Method
. O
The O
goal O
here O
is O
to O
let O
the O
network O
fit O
the O
function O
described O
by O
the O
BM25 Method
formula Method
when O
it O
receives O
exactly O
the O
same O
inputs O
. O
In O
more O
detail O
, O
our O
input O
vector O
is O
a O
concatenation O
( O
) O
of O
the O
following O
inputs O
: O
total O
number O
of O
documents O
in O
the O
collection O
( O
i.e. O
, O
) O
, O
average O
length O
of O
documents O
in O
the O
collection O
( O
i.e. O
, O
) O
, O
document O
length O
( O
i.e. O
, O
) O
, O
frequency O
of O
each O
query O
term O
in O
the O
document O
( O
i.e. O
, O
) O
, O
and O
document O
frequency O
of O
each O
query O
term O
( O
i.e. O
, O
) O
. O
Therefore O
, O
for O
the O
point Task
- Task
wise Task
setting Task
, O
we O
have O
the O
following O
input O
vector O
: O
where O
is O
set O
to O
a O
fixed O
value O
( O
in O
our O
experiments O
) O
. O
We O
truncate O
longer O
queries O
and O
do O
zero Method
padding Method
for O
shorter O
queries O
. O
For O
the O
networks O
in O
the O
rankprob Method
model Method
, O
we O
consider O
a O
similar O
function O
with O
additional O
elements O
: O
the O
length O
of O
the O
second O
document O
and O
the O
frequency O
of O
query O
terms O
in O
the O
second O
document O
. O
Sparse Method
vector Method
representation Method
( O
Sparse Method
) O
: O
Next O
, O
we O
move O
away O
from O
a O
fully Method
featurized Method
representation Method
that O
contains O
only O
aggregated O
statistics O
and O
let O
the O
network O
performs O
feature Task
extraction Task
for O
us O
. O
In O
particular O
, O
we O
build O
a O
bag Method
- Method
of Method
- Method
words Method
representation Method
by O
extracting O
term O
frequency O
vectors O
of O
query O
( O
) O
, O
document O
( O
) O
, O
and O
the O
collection O
( O
) O
and O
feed O
the O
network O
with O
concatenation O
of O
these O
three O
vectors O
. O
For O
the O
point Task
- Task
wise Task
setting Task
, O
we O
have O
the O
following O
input O
vector O
: O
For O
the O
network O
in O
rankprob Method
model Method
, O
we O
have O
a O
similar O
input O
vector O
with O
both O
and O
. O
Hence O
, O
the O
size O
of O
the O
input O
layer O
is O
in O
the O
point O
- O
wise O
setting O
, O
and O
in O
the O
pair Task
- Task
wise Task
setting Task
. O
Embedding Method
vector Method
representation Method
( O
Embed Method
) O
: O
The O
major O
weakness O
of O
the O
previous O
input Method
representation Method
is O
that O
words O
are O
treated O
as O
discrete O
units O
, O
hence O
prohibiting O
the O
network O
from O
performing O
soft Task
matching Task
between O
semantically O
similar O
words O
in O
queries O
and O
documents O
. O
In O
this O
input Method
representation Method
paradigm Method
, O
we O
rely O
on O
word Method
embeddings Method
to O
obtain O
more O
powerful O
representation O
of O
queries O
and O
documents O
that O
could O
bridge O
the O
lexical O
chasm O
. O
The O
representation Method
function Method
consists O
of O
three O
components O
: O
an O
embedding Method
function Method
( O
where O
denotes O
the O
vocabulary O
set O
and O
is O
the O
embedding O
dimension O
) O
, O
a O
weighting Method
function Method
, O
and O
a O
compositionality Method
function Method
. O
More O
formally O
, O
the O
function O
for O
the O
point Task
- Task
wise Task
setting Task
is O
defined O
as O
: O
where O
and O
denote O
the O
term O
in O
query O
and O
document O
, O
respectively O
. O
For O
the O
network O
of O
the O
rankprob Method
model Method
, O
another O
similar O
term O
is O
concatenated O
with O
the O
above O
vector O
for O
the O
second O
document O
. O
The O
embedding Method
function Method
transforms O
each O
term O
to O
a O
dense O
- O
dimensional O
float O
vector O
as O
its O
representation O
, O
which O
is O
learned O
during O
the O
training Metric
phase O
. O
The O
weighting Method
function Method
assigns O
a O
weight O
to O
each O
term O
in O
the O
vocabulary O
set O
, O
which O
is O
supposed O
to O
learn O
term O
global O
importance O
for O
the O
retrieval Task
task Task
. O
The O
compositionality Method
function Method
projects O
a O
set O
of O
embedding O
and O
weighting O
pairs O
to O
an O
- Method
dimensional Method
representation Method
, O
independent O
from O
the O
value O
of O
. O
The O
compositionality O
function O
is O
given O
by O
: O
which O
is O
the O
weighted O
element O
- O
wise O
sum O
of O
the O
terms O
’ O
embedding O
vectors O
. O
is O
the O
normalized O
weight O
that O
is O
learned O
for O
each O
term O
, O
given O
as O
follows O
: O
All O
combinations O
of O
different O
ranking Method
architectures Method
and O
different O
input O
representations O
presented O
in O
this O
section O
can O
be O
considered O
for O
developing O
ranking Method
models Method
. O
section O
: O
Experimental O
Design O
In O
this O
section O
, O
we O
describe O
the O
train Metric
and Metric
evaluation Metric
data Metric
, O
metrics O
we O
report O
, O
and O
detailed O
experimental O
setup O
. O
Then O
we O
discuss O
the O
results O
. O
subsection O
: O
Data O
Collections O
. O
In O
our O
experiments O
, O
we O
used O
two O
standard O
TREC Material
collections Material
: O
The O
first O
collection O
( O
called O
Robust04 Material
) O
consists O
of O
over O
500k O
news O
articles O
from O
different O
news O
agencies O
, O
that O
is O
available O
in O
TREC Material
Disks Material
4 O
and O
5 O
( O
excluding O
Congressional O
Records O
) O
. O
This O
collection O
, O
which O
was O
used O
in O
TREC O
Robust Material
Track O
2004 O
, O
is O
considered O
as O
a O
homogeneous O
collection O
, O
because O
of O
the O
nature O
and O
the O
quality O
of O
documents O
. O
The O
second O
collection O
( O
called O
ClueWeb O
) O
that O
we O
used O
is O
ClueWeb09 O
Category O
B O
, O
a O
large O
- O
scale O
web O
collection O
with O
over O
50 O
million O
English O
documents O
, O
which O
is O
considered O
as O
a O
heterogeneous O
collection O
. O
This O
collection O
has O
been O
used O
in O
TREC Material
Web Material
Track Material
, O
for O
several O
years O
. O
In O
our O
experiments O
with O
this O
collection O
, O
we O
filtered O
out O
the O
spam O
documents O
using O
the O
Waterloo Method
spam Method
scorer Method
Cormack:2011 Method
with O
the O
default O
threshold O
. O
The O
statistics O
of O
these O
collections O
are O
reported O
in O
Table O
[ O
reference O
] O
. O
Training O
query O
set O
. O
To O
train O
our O
neural Method
ranking Method
models Method
, O
we O
used O
the O
unique O
queries O
( O
only O
the O
query O
string O
) O
appearing O
in O
the O
AOL O
query O
logs O
Pass:2006 O
. O
This O
query O
set O
contains O
web O
queries O
initiated O
by O
real O
users O
in O
the O
AOL Method
search Method
engine Method
that O
were O
sampled O
from O
a O
three O
- O
month O
period O
from O
March O
1 O
, O
2006 O
to O
May O
31 O
, O
2006 O
. O
We O
filtered O
out O
a O
large O
volume O
of O
navigational O
queries O
containing O
URL O
substrings O
( O
“ O
http O
” O
, O
“ O
www O
. O
” O
, O
“ O
.com O
” O
, O
“ O
.net O
” O
, O
“ O
.org O
” O
, O
“ O
.edu O
” O
) O
. O
We O
also O
removed O
all O
non O
- O
alphanumeric O
characters O
from O
the O
queries O
. O
We O
made O
sure O
that O
no O
queries O
from O
the O
training Metric
set O
appear O
in O
our O
evaluation O
sets O
. O
For O
each O
dataset O
, O
we O
took O
queries O
that O
have O
at O
least O
ten O
hits O
in O
the O
target O
corpus O
using O
the O
pseudo Method
- Method
labeler Method
method Method
. O
Applying O
all O
these O
processes O
, O
we O
ended O
up O
with O
6.15 O
million O
queries O
for O
the O
Robust04 Material
dataset O
and O
6.87 O
million O
queries O
for O
the O
ClueWeb O
dataset O
. O
In O
our O
experiments O
, O
we O
randomly O
selected O
of O
the O
training Metric
queries O
as O
training Metric
set O
and O
the O
remaining O
of O
the O
queries O
were O
chosen O
as O
validation O
set O
for O
hyper Method
- Method
parameter Method
tuning Method
. O
As O
the O
“ O
pseudo O
- O
labeler O
” O
in O
our O
training Metric
data O
, O
we O
have O
used O
BM25 Method
to O
score O
/ O
rank O
documents O
in O
the O
collections O
given O
the O
queries O
in O
the O
training Metric
query O
set O
. O
Evaluation O
query O
sets O
. O
We O
use O
the O
following O
query O
sets O
for O
evaluation Task
that O
contain O
human O
- O
labeled O
judgements O
: O
a O
set O
of O
250 O
queries O
( O
TREC Material
topics Material
301–450 O
and O
601–700 O
) O
for O
the O
Robust04 Material
collection O
that O
were O
previously O
used O
in O
TREC O
Robust Material
Track O
2004 O
. O
A O
set O
of O
200 O
queries O
( O
topics O
1 O
- O
200 O
) O
were O
used O
for O
the O
experiments O
on O
the O
ClueWeb O
collection O
. O
These O
queries O
were O
used O
in O
TREC O
Web O
Track O
2009–2012 O
. O
We O
only O
used O
the O
title O
of O
topics O
as O
queries O
. O
subsection O
: O
Evaluation Metric
Metrics Metric
. O
To O
evaluate O
retrieval Metric
effectiveness Metric
, O
we O
report O
three O
standard O
evaluation Metric
metrics Metric
: O
mean Metric
average Metric
precision Metric
( O
MAP Metric
) O
of O
the O
top O
- O
ranked O
documents O
, O
precision Metric
of O
the O
top O
retrieved O
documents O
( O
P@20 Metric
) O
, O
and O
normalized Metric
discounted Metric
cumulative Metric
gain Metric
( O
nDCG Metric
) O
Jarvelin:2002 O
calculated O
for O
the O
top O
retrieved O
documents O
( O
nDCG@20 O
) O
. O
Statistically O
significant O
differences O
of O
MAP Metric
, O
P@20 O
, O
and O
nDCG@20 O
values O
are O
determined O
using O
the O
two O
- O
tailed O
paired O
t O
- O
test O
with O
, O
with O
Bonferroni Method
correction Method
. O
max O
width=0.9 O
subsection O
: O
Experimental O
Setup O
All O
models O
described O
in O
Section O
[ O
reference O
] O
are O
implemented O
using O
TensorFlow Method
tang2016:tflearn O
, O
tensorflow2015 Method
- Method
whitepaper Method
. O
In O
all O
experiments O
, O
the O
parameters O
of O
the O
network O
are O
optimized O
employing O
the O
Adam Method
optimizer Method
Kingma:2014 O
and O
using O
the O
computed O
gradient O
of O
the O
loss O
to O
perform O
the O
back Method
- Method
propagation Method
algorithm Method
. O
All O
model O
hyper O
- O
parameters O
were O
tuned O
on O
the O
respective O
validation O
set O
( O
see O
Section O
[ O
reference O
] O
for O
more O
detail O
) O
using O
batched Method
GP Method
bandits Method
with O
an O
expected O
improvement O
acquisition O
function O
Desautels:2014 O
. O
For O
each O
model O
, O
the O
size O
of O
hidden O
layers O
and O
the O
number O
of O
hidden O
layers O
were O
selected O
from O
and O
, O
respectively O
. O
The O
initial O
learning Metric
rate Metric
and O
the O
dropout O
parameter O
were O
selected O
from O
and O
, O
respectively O
. O
For O
models O
with O
embedding Method
vector Method
representation Method
, O
we O
considered O
embedding O
sizes O
of O
. O
As O
the O
training Metric
data O
, O
we O
take O
the O
top O
retrieved O
documents O
for O
each O
query O
from O
training Metric
query O
set O
, O
to O
prepare O
the O
training Metric
data O
. O
In O
total O
, O
we O
have O
( O
examples O
in O
our O
data O
) O
point O
- O
wise O
example O
and O
( O
examples O
in O
our O
data O
) O
pair O
- O
wise O
examples O
. O
The O
batch O
size O
in O
our O
experiments O
was O
selected O
from O
. O
At O
inference O
time O
, O
for O
each O
query O
, O
we O
take O
the O
top O
retrieved O
documents O
using O
BM25 Method
as O
candidate O
documents O
and O
re O
- O
rank O
them O
by O
the O
trained O
models O
. O
In O
our O
experiments O
, O
we O
use O
the O
Indri Method
implementation Method
of O
BM25 Method
with O
the O
default O
parameters O
( O
i.e. O
, O
, O
, O
and O
) O
. O
section O
: O
Results O
and O
Discussion O
In O
the O
following O
, O
we O
evaluate O
our O
neural Method
rankers Method
trained O
with O
different O
learning Method
approaches Method
( O
Section O
[ O
reference O
] O
) O
and O
different O
input O
representations O
( O
Section O
[ O
reference O
] O
) O
. O
We O
attempt O
to O
break O
down O
our O
research O
questions O
to O
several O
subquestions O
, O
and O
provide O
empirical O
answers O
along O
with O
the O
intuition O
and O
analysis O
behind O
each O
question O
: O
How O
do O
the O
neural Method
models Method
with O
different O
training Metric
objectives O
and O
input O
representations O
compare O
? O
Table O
[ O
reference O
] O
presents O
the O
performance O
of O
all O
model O
combinations O
. O
Interestingly O
, O
combinations O
of O
the O
rank Method
model Method
and O
the O
rankprob Method
model Method
with O
embedding Method
vector Method
representation Method
outperform O
BM25 Method
by O
significant O
margins O
in O
both O
collections O
. O
For O
instance O
, O
the O
rankprob Method
model Method
with O
embedding Method
vector Method
representation Method
that O
shows O
the O
best O
performance O
among O
the O
other O
methods O
, O
surprisingly O
, O
improves O
BM25 Method
by O
over O
and O
in O
Robust04 Material
and O
ClueWeb O
collections O
respectively O
, O
in O
terms O
of O
MAP Metric
. O
Similar O
improvements O
can O
be O
observed O
for O
the O
other O
evaluation Metric
metrics Metric
. O
Regarding O
the O
modeling Method
architecture Method
, O
in O
the O
rank Method
model Method
and O
the O
rankprob Method
model Method
, O
compared O
to O
the O
score Method
model Method
, O
we O
define O
objective O
functions O
that O
target O
to O
learn O
ranking Task
instead O
of O
scoring Task
. O
This O
is O
particularly O
important O
in O
weak Task
supervision Task
, O
as O
the O
scores O
are O
imperfect O
values O
— O
using O
the O
ranking O
objective O
alleviates O
this O
issue O
by O
forcing O
the O
model O
to O
learn O
a O
preference O
function O
rather O
than O
reproduce O
absolute O
scores O
. O
In O
other O
words O
, O
using O
the O
ranking O
objective O
instead O
of O
learning O
to O
predict O
calibrated O
scores O
allows O
the O
rank Method
model Method
and O
the O
rankprob Method
model Method
to O
learn O
to O
distinguish O
between O
examples O
whose O
scores O
are O
close O
. O
This O
way O
, O
some O
small O
amount O
of O
noise O
, O
which O
is O
a O
common O
problem O
in O
weak Task
supervision Task
, O
would O
not O
perturb O
the O
ranking Task
as O
easily O
. O
Regarding O
the O
input O
representations O
, O
embedding Method
vector Method
representation Method
leads O
to O
better O
performance O
compared O
to O
the O
other O
ones O
in O
all O
models O
. O
Using O
embedding Method
vector Method
representation Method
not O
only O
provides O
the O
network O
with O
more O
information O
, O
but O
also O
lets O
the O
network O
to O
learn O
proper O
representation O
capturing O
the O
needed O
elements O
for O
the O
next O
layers O
with O
better O
understanding O
of O
the O
interactions O
between O
query O
and O
documents O
. O
Providing O
the O
network O
with O
already O
engineered O
features O
would O
block O
it O
from O
going O
beyond O
the O
weak O
supervision O
signal O
and O
limit O
the O
ability O
of O
the O
models O
to O
learn O
latent O
features O
that O
are O
unattainable O
through O
feature Method
engineering Method
. O
Note O
that O
although O
the O
rankprob Method
model Method
is O
more O
precise O
in O
terms O
of O
MAP Metric
, O
the O
rank Method
model Method
is O
much O
faster O
in O
the O
inference Metric
time Metric
( O
compared O
to O
) O
, O
which O
is O
a O
desirable O
property O
in O
real Task
- Task
life Task
applications Task
. O
[ O
t O
] O
0.3 O
[ O
t O
] O
0.3 O
[ O
t O
] O
0.3 O
[ O
t O
] O
0.3 O
[ O
t O
] O
0.3 O
[ O
t O
] O
0.3 O
[ O
t O
] O
0.3 O
[ O
t O
] O
0.3 O
[ O
t O
] O
0.3 O
ticks O
= O
none O
[ O
width= O
9 O
cm O
, O
height=5.5 O
cm O
, O
grid O
= O
both O
, O
nodes O
near O
coords O
, O
scatter O
/ O
classes= O
BM25=mark Method
= O
otimes Method
* O
, O
mark O
size=3pt O
, O
yellow O
, O
draw O
= O
black O
, O
m1f1=mark O
= O
halfcircle O
* O
, O
mark O
size=3pt O
, O
blue O
, O
, O
m1f2=mark O
= O
halfcircle O
* O
, O
mark O
size=3pt O
, O
red O
, O
m1f3=mark O
= O
halfcircle O
* O
, O
mark O
size=3pt O
, O
black O
, O
m2f1=mark O
= O
halfsquare O
* O
, O
mark O
size=3pt O
, O
blue O
, O
m2f2=mark O
= O
halfsquare O
* O
, O
mark O
size=3pt O
, O
red O
, O
m2f3=mark O
= O
halfsquare O
* O
, O
mark O
size=3pt O
, O
black O
, O
m3f1=mark O
= O
pentagon O
* O
, O
mark O
size=3pt O
, O
blue O
, O
m3f2=mark O
= O
pentagon O
* O
, O
mark O
size=3pt O
, O
red O
, O
m3f3=mark O
= O
pentagon O
* O
, O
mark O
size=3pt O
, O
black O
, O
legend O
style= O
at= O
( O
1.2 O
, O
0.85 O
) O
, O
font= O
, O
, O
] O
[ O
scatter O
, O
only O
marks O
, O
scatter O
src O
= O
explicit O
symbolic O
] O
coordinates O
( O
0.403 O
, O
0.801 O
) O
[ O
BM25 O
] O
( O
0.341 O
, O
0.749 O
) O
[ O
m1f1 O
] O
( O
0.232 O
, O
0.240 O
) O
[ O
m1f2 O
] O
( O
0.570 O
, O
0.412 O
) O
[ O
m1f3 O
] O
( O
0.091 O
, O
0.718 O
) O
[ O
m2f1 O
] O
( O
0.265 O
, O
0.369 O
) O
[ O
m2f2 O
] O
( O
0.808 O
, O
0.101 O
) O
[ O
m2f3 O
] O
( O
0.246 O
, O
0.601 O
) O
[ O
m3f1 O
] O
( O
0.371 O
, O
0.600 O
) O
[ O
m3f2 O
] O
( O
0.730 O
, O
0.305 O
) O
[ O
m3f3 O
] O
; O
[ O
right O
] O
at O
( O
0.413 O
, O
0.801 O
) O
BM25 Method
; O
[ O
left O
] O
at O
( O
0.381 O
, O
0.800 O
) O
Score O
+ O
Dense O
; O
[ O
below O
] O
at O
( O
0.232 O
, O
0.230 O
) O
Score O
+ O
Sparse O
; O
[ O
above O
] O
at O
( O
0.570 O
, O
0.422 O
) O
Score O
+ O
Embed Method
; O
[ O
below O
] O
at O
( O
0.121 O
, O
0.708 O
) O
Rank O
+ O
Dense O
; O
[ O
above O
] O
at O
( O
0.265 O
, O
0.379 O
) O
Rank O
+ O
Sparse O
; O
[ O
above O
] O
at O
( O
0.758 O
, O
0.121 O
) O
Rank O
+ O
Embed Method
; O
[ O
below O
] O
at O
( O
0.226 O
, O
0.591 O
) O
RankProb O
+ O
Dense O
; O
[ O
right O
] O
at O
( O
0.381 O
, O
0.600 O
) O
RankProb Method
+ Method
Sparse Method
; O
[ O
above O
] O
at O
( O
0.730 O
, O
0.315 O
) O
RankProb O
+ O
Embed Method
; O
Why O
do O
dense Method
vector Method
representation Method
and O
sparse Method
vector Method
representation Method
fail O
to O
replicate O
the O
performance O
of O
BM25 Method
? O
Although O
neural Method
networks Method
are O
capable O
of O
approximating O
arbitrarily O
complex O
non O
- O
linear O
functions O
, O
we O
observe O
that O
the O
models O
with O
dense Method
vector Method
representation Method
fail O
to O
replicate O
the O
BM25 Method
performance O
, O
while O
they O
are O
given O
the O
same O
feature O
inputs O
as O
the O
BM25 Method
components Method
( O
e.g. O
, O
TF O
, O
IDF Method
, O
average Metric
document Metric
length Metric
, O
etc O
) O
. O
To O
ensure O
that O
the O
training Metric
converges O
and O
there O
is O
no O
overfitting O
, O
we O
have O
looked O
into O
the O
training Metric
and O
validation Metric
loss Metric
values Metric
of O
different O
models O
during O
the O
training Metric
time O
. O
Figure O
[ O
reference O
] O
illustrates O
the O
loss Metric
curves Metric
for O
the O
training Metric
and O
validation O
sets O
( O
see O
Section O
[ O
reference O
] O
) O
per O
training Metric
step O
for O
different O
models O
. O
As O
shown O
, O
in O
models O
with O
dense Method
vector Method
representation Method
, O
the O
training Metric
losses O
drop O
quickly O
to O
values O
close O
to O
zero O
while O
this O
is O
not O
the O
case O
for O
the O
validation Metric
losses Metric
, O
which O
is O
an O
indicator O
of O
over Task
- Task
fitting Task
on O
the O
training Metric
data O
. O
Although O
we O
have O
tried O
different O
regularization Method
techniques Method
, O
like O
- O
regularization O
and O
dropout Method
with O
various O
parameters O
, O
there O
is O
less O
chance O
for O
generalization Task
when O
the O
networks O
are O
fed O
with O
the O
fully O
featurized O
input O
. O
Note O
that O
over Task
- Task
fitting Task
would O
lead O
to O
poor O
performance O
, O
especially O
in O
weak Task
supervision Task
scenarios Task
as O
the O
network O
learns O
to O
model O
imperfections O
from O
weak O
annotations O
. O
This O
phenomenon O
is O
also O
the O
case O
for O
models O
with O
the O
sparse Method
vector Method
representation Method
, O
but O
with O
less O
impact O
. O
However O
, O
in O
the O
models O
with O
the O
embedding Method
vector Method
representation Method
, O
the O
networks O
do O
not O
overfit O
, O
which O
helps O
it O
to O
go O
beyond O
the O
weak O
supervision O
signals O
in O
the O
training Metric
data O
. O
How O
are O
the O
models O
related O
? O
To O
better O
understand O
the O
relationship O
of O
different O
neural Method
models Method
described O
above O
, O
we O
compare O
their O
performance O
across O
the O
query O
dimension O
following O
the O
approach O
in O
Mitra:2016 O
. O
We O
assume O
that O
similar O
models O
should O
perform O
similarly O
for O
the O
same O
queries O
. O
Hence O
, O
we O
represent O
each O
model O
by O
a O
vector O
, O
called O
the O
performance O
vector O
, O
whose O
elements O
correspond O
to O
per O
query O
performance O
of O
the O
model O
, O
in O
terms O
of O
nDCG@20 Task
. O
The O
closer O
the O
performance O
vectors O
are O
, O
the O
more O
similar O
the O
models O
are O
in O
terms O
of O
query Metric
by Metric
query Metric
performance Metric
. O
For O
the O
sake O
of O
visualization Task
, O
we O
reduce O
the O
vectors O
dimension O
by O
projecting O
them O
to O
a O
two O
- O
dimensional O
space O
, O
using O
t Method
- Method
Distributed Method
Stochastic Method
Neighbor Method
Embedding Method
( O
t Method
- Method
SNE Method
) O
. O
Figure O
[ O
reference O
] O
illustrates O
the O
proximity O
of O
different O
models O
in O
the O
Robust04 Material
collection O
. O
Based O
on O
this O
plot O
, O
models O
with O
similar O
input O
representations O
( O
same O
color O
) O
have O
quite O
close O
performance O
vectors O
, O
which O
means O
that O
they O
perform O
similarly O
for O
same O
queries O
. O
This O
is O
not O
necessarily O
the O
case O
for O
models O
with O
similar O
architecture O
( O
same O
shape O
) O
. O
This O
suggests O
that O
the O
amount O
and O
the O
way O
that O
we O
provide O
information O
to O
the O
networks O
are O
the O
key O
factors O
in O
the O
ranking Task
performance O
. O
We O
also O
observe O
that O
the O
score Method
model Method
with O
dense Method
vector Method
representation Method
is O
the O
closest O
to O
BM25 Method
which O
is O
expected O
. O
It O
is O
also O
interesting O
that O
models O
with O
embedding Method
vector Method
representation Method
are O
placed O
far O
away O
from O
other O
models O
which O
shows O
they O
perform O
differently O
compared O
to O
the O
other O
input O
representations O
. O
How O
meaningful O
are O
the O
compositionality O
weights O
learned O
in O
the O
embedding Method
vector Method
representation Method
? O
In O
this O
experiment O
, O
we O
focus O
on O
the O
best O
performing O
combination O
, O
i.e. O
, O
the O
rankprob Method
model Method
with O
embedding Method
vector Method
representation Method
. O
To O
analyze O
what O
the O
network O
learns O
, O
we O
look O
into O
the O
weights O
( O
see O
Section O
[ O
reference O
] O
) O
learned O
by O
the O
network O
. O
Note O
that O
the O
weighting Method
function Method
learns O
a O
global O
weight O
for O
each O
vocabulary O
term O
. O
We O
notice O
that O
in O
both O
collections O
there O
is O
a O
strong O
linear O
correlation O
between O
the O
learned O
weights O
and O
the O
inverse O
document O
frequency O
of O
terms O
. O
max O
width=0.9 O
[ O
t O
] O
0.24 O
( O
Pearson Metric
Correlation Metric
: O
0.8243 O
) O
[ O
t O
] O
0.24 O
( O
Pearson Metric
Correlation Metric
: O
0.7014 O
) O
Figure O
[ O
reference O
] O
illustrates O
the O
scatter O
plots O
of O
the O
learned O
weight O
for O
each O
vocabulary O
term O
and O
its O
IDF Method
, O
in O
both O
collections O
. O
This O
is O
an O
interesting O
observation O
as O
we O
do O
not O
provide O
any O
global O
corpus O
information O
to O
the O
network O
in O
training Metric
and O
the O
network O
is O
able O
to O
infer O
such O
a O
global O
information O
by O
only O
observing O
individual O
training Metric
instances O
. O
How O
well O
do O
other O
alternatives O
for O
the O
embedding Method
and Method
weighting Method
functions Method
in O
the O
embedding Method
vector Method
representation Method
perform O
? O
Considering O
embedding Method
vector Method
representation Method
as O
the O
input O
representation O
, O
we O
have O
examined O
different O
alternatives O
for O
the O
embedding Method
function Method
: O
( O
1 O
) O
employing O
pre Method
- Method
trained Method
word Method
embeddings Method
learned O
from O
an O
external O
corpus O
( O
we O
used O
Google O
News O
) O
, O
( O
2 O
) O
employing O
pre Method
- Method
trained Method
word Method
embeddings Method
learned O
from O
the O
target O
corpus O
( O
using O
the O
skip Method
- Method
gram Method
model Method
) O
, O
and O
( O
3 O
) O
learning O
embeddings O
during O
the O
network O
training Metric
as O
it O
is O
explained O
in O
Section O
[ O
reference O
] O
. O
Furthermore O
, O
for O
the O
compositionality O
function O
, O
we O
tried O
different O
alternatives O
: O
( O
1 O
) O
uniform Method
weighting Method
( O
simple O
averaging Method
which O
is O
a O
common O
approach O
in O
compositionality O
function O
) O
, O
( O
2 O
) O
using O
IDF Method
as O
fixed O
weights O
instead O
of O
learning O
the O
weighting Method
function Method
, O
and O
( O
3 O
) O
learning O
weights O
during O
the O
training Metric
as O
described O
in O
Section O
[ O
reference O
] O
. O
Table O
[ O
reference O
] O
presents O
the O
performance O
of O
all O
these O
combinations O
on O
both O
collections O
. O
We O
note O
that O
learning O
both O
embedding Method
and Method
weighting Method
functions Method
leads O
to O
the O
highest O
performance O
in O
both O
collections O
. O
These O
improvements O
are O
statistically O
significant O
. O
According O
to O
the O
results O
, O
regardless O
of O
the O
weighting Method
approach Method
, O
learning O
embeddings Method
during O
training Metric
outperforms O
the O
models O
with O
fixed O
pre O
- O
trained O
embeddings O
. O
This O
supports O
the O
hypothesis O
that O
with O
the O
embedding Method
vector Method
representation Method
the O
neural Method
networks Method
learn O
an O
embedding Method
that O
is O
based O
on O
the O
interactions O
of O
query O
and O
documents O
that O
tends O
to O
be O
tuned O
better O
to O
the O
corresponding O
ranking Task
task Task
. O
Also O
, O
regardless O
of O
the O
embedding Method
method Method
, O
learning O
weights O
helps O
models O
to O
get O
better O
performance O
compared O
to O
the O
fixed O
weightings O
, O
with O
either O
IDF Method
or O
uniform Method
weights Method
. O
Although O
weight Method
learning Method
can O
significantly O
affect O
the O
performance O
, O
it O
has O
less O
impact O
than O
learning Task
embeddings Task
. O
Note O
that O
in O
the O
models O
with O
pre O
- O
trained O
word Method
embeddings Method
, O
employing O
word Method
embeddings Method
trained O
on O
the O
target O
collection O
outperforms O
those O
trained O
on O
the O
external O
corpus O
in O
the O
ClueWeb O
collection O
; O
while O
this O
is O
not O
the O
case O
for O
the O
Robust04 Material
collection O
. O
The O
reason O
could O
be O
related O
to O
the O
collection Metric
size Metric
, O
since O
the O
ClueWeb Method
is O
approximately O
times O
larger O
than O
the O
Robust04 Material
. O
[ O
t O
] O
0.24 O
[ O
t O
] O
0.24 O
max O
width=0.8 O
max O
width=0.8 O
In O
addition O
to O
the O
aforementioned O
experiments O
, O
we O
have O
also O
tried O
initializing O
the O
embedding O
matrix O
with O
a O
pre Method
- Method
trained Method
word Method
embedding Method
trained O
on O
the O
Google O
News O
corpus O
, O
instead O
of O
random Method
initialization Method
. O
Figure O
[ O
reference O
] O
presents O
the O
learning O
curve O
of O
the O
models O
. O
According O
to O
this O
figure O
, O
the O
model O
initialized O
by O
a O
pre Method
- Method
trained Method
embedding Method
performs O
better O
than O
random Method
initialization Method
when O
a O
limited O
amount O
of O
training Metric
data O
is O
available O
. O
When O
enough O
training Metric
data O
is O
fed O
to O
the O
network O
, O
initializing O
with O
pre O
- O
trained O
embedding O
and O
random O
values O
converge O
to O
the O
same O
performance O
. O
An O
interesting O
observation O
here O
is O
that O
in O
both O
collections O
, O
these O
two O
initializations O
converge O
when O
the O
models O
exceed O
the O
performance O
of O
the O
weak Method
supervision Method
source Method
, O
which O
is O
BM25 Method
in O
our O
experiments O
. O
This O
suggests O
that O
the O
convergence O
occurs O
when O
accurate O
representations O
are O
learned O
by O
the O
networks O
, O
regardless O
of O
the O
initialization O
. O
Are O
deep Method
neural Method
networks Method
a O
good O
choice O
for O
learning Task
to Task
rank Task
with O
weak O
supervision O
? O
To O
see O
if O
there O
is O
a O
real O
benefit O
from O
using O
a O
non Method
- Method
linear Method
neural Method
network Method
in O
different O
settings O
, O
we O
examined O
RankSVM Method
Joachims:2002 O
as O
a O
strong O
- O
performing O
pair Method
- Method
wise Method
learning Method
to Method
rank Method
method Method
with O
linear Method
kernel Method
that O
is O
fed O
with O
different O
inputs O
: O
dense Method
vector Method
representation Method
, O
sparse Method
vector Method
representation Method
, O
and O
embedding Method
vector Method
representation Method
. O
Considering O
that O
off O
- O
the O
- O
shelf O
RankSVM Method
is O
not O
able O
to O
learn O
embedding Method
representations Method
during O
training Metric
, O
for O
embedding Task
vector Task
representation Task
, O
instead O
of O
learning Task
embeddings Task
we O
use O
a O
pre O
- O
trained O
embedding Method
matrix Method
trained O
on O
Google O
News O
and O
fixed O
IDF Method
weights O
. O
The O
results O
are O
reported O
in O
Table O
[ O
reference O
] O
. O
As O
BM25 Method
is O
not O
a O
linear O
function O
, O
RankSVM Method
with O
linear Method
kernel Method
is O
not O
able O
to O
completely O
approximate O
it O
. O
However O
, O
surprisingly O
, O
for O
both O
dense Task
vector Task
representation Task
and O
sparse Task
vector Task
representation Task
, O
RankSVM Method
works O
as O
well O
as O
neural Method
networks Method
( O
see O
Table O
[ O
reference O
] O
) O
. O
Also O
, O
compared O
to O
the O
corresponding O
experiment O
in O
Table O
[ O
reference O
] O
, O
the O
performance O
of O
the O
neural Method
network Method
with O
an O
external Method
pre Method
- Method
trained Method
embedding Method
and O
IDF Method
weighting O
is O
not O
considerably O
better O
than O
RankSVM Method
. O
This O
shows O
that O
having O
non O
- O
linearity O
in O
neural Method
networks Method
does O
not O
help O
that O
much O
when O
we O
do O
not O
have O
representation Method
learning Method
as O
part O
of O
the O
model O
. O
Note O
that O
all O
of O
these O
results O
are O
still O
lower O
than O
BM25 Method
, O
which O
shows O
that O
they O
are O
not O
good O
at O
learning O
from O
weak O
supervision O
signals O
for O
ranking Task
. O
We O
have O
also O
examined O
the O
score Method
model Method
with O
a O
network O
with O
a O
single O
linear Method
hidden Method
layer Method
, O
with O
the O
embedding Method
vector Method
representation Method
, O
which O
is O
equivalent O
to O
a O
linear Method
regression Method
model Method
with O
the O
ability O
of O
representation Method
learning Method
. O
Comparing O
the O
results O
of O
this O
experiment O
with O
Score O
- O
Embed Method
in O
Table O
[ O
reference O
] O
, O
we O
can O
see O
that O
with O
a O
single O
- O
linear Method
network Method
we O
are O
not O
able O
to O
achieve O
a O
performance O
that O
is O
as O
good O
as O
a O
deep Method
neural Method
network Method
with O
non Method
- Method
linearity Method
. O
This O
shows O
that O
the O
most O
important O
superiority O
of O
deep Method
neural Method
networks Method
over O
other O
machine Method
learning Method
methods Method
is O
their O
ability O
to O
learn O
an O
effective O
representation O
and O
take O
all O
the O
interactions O
between O
query O
and O
document O
( O
s O
) O
into O
consideration O
for O
approximating O
an O
effective O
ranking Metric
/ Metric
scoring Metric
function Metric
. O
This O
can O
be O
achieved O
when O
we O
have O
a O
deep Method
enough Method
network Method
with O
non O
- O
linear O
activations O
. O
How O
useful O
is O
learning O
with O
weak O
supervision O
for O
supervised Task
ranking Task
? O
In O
this O
set O
of O
experiments O
, O
we O
investigate O
whether O
employing O
weak O
supervision O
as O
a O
pre O
- O
training Metric
step O
helps O
to O
improve O
the O
performance O
of O
supervised Task
ranking Task
, O
when O
a O
small O
amount O
of O
training Metric
data O
is O
available O
. O
Table O
[ O
reference O
] O
shows O
the O
performance O
of O
the O
rankprob Method
model Method
with O
the O
embedding Method
vector Method
representation Method
in O
three O
situations O
: O
( O
1 O
) O
when O
it O
is O
only O
trained O
on O
weakly O
supervised O
data O
( O
similar O
to O
the O
previous O
experiments O
) O
, O
( O
2 O
) O
when O
it O
is O
only O
trained O
on O
supervised O
data O
, O
i.e. O
, O
relevance O
judgments O
, O
and O
( O
3 O
) O
when O
the O
parameters O
of O
the O
network O
is O
pre O
- O
trained O
using O
the O
weakly O
supervised O
data O
and O
then O
fine O
tuned O
using O
relevance O
judgments O
. O
In O
all O
the O
supervised Task
scenarios Task
, O
we O
performed O
5 Metric
- Metric
fold Metric
cross Metric
- Metric
validation Metric
over O
the O
queries O
of O
each O
collection O
and O
in O
each O
step O
, O
we O
used O
the O
TREC O
relevance O
judgements O
of O
the O
training Metric
set O
as O
supervised O
signal O
. O
For O
each O
query O
with O
relevant O
documents O
, O
we O
also O
randomly O
sampled O
non O
- O
relevant O
documents O
as O
negative O
instances O
. O
Binary O
labels O
are O
used O
in O
the O
experiments O
: O
for O
relevant O
documents O
and O
for O
non O
- O
relevant O
ones O
. O
The O
results O
in O
Table O
[ O
reference O
] O
suggest O
that O
pre O
- O
training Metric
the O
network O
with O
a O
weak O
supervision O
signal O
, O
significantly O
improves O
the O
performance O
of O
supervised Task
ranking Task
. O
The O
reason O
for O
the O
poor O
performance O
of O
the O
supervised Method
model Method
compared O
to O
the O
conventional O
learning Method
to Method
rank Method
models Method
is O
that O
the O
number O
of O
parameters O
are O
much O
larger O
, O
hence O
it O
needs O
much O
more O
data O
for O
training Metric
. O
In O
situations O
when O
little O
supervised O
data O
is O
available O
, O
it O
is O
especially O
helpful O
to O
use O
unsupervised O
pre O
- O
training Metric
which O
acts O
as O
a O
network Method
pre Method
- Method
conditioning Method
that O
puts O
the O
parameter O
values O
in O
the O
appropriate O
range O
that O
renders O
the O
optimization Method
process Method
more O
effective O
for O
further O
supervised O
training Metric
Rrhan:2010 O
. O
With O
this O
experiment O
, O
we O
indicate O
that O
the O
idea O
of O
learning O
from O
weak O
supervision O
signals O
for O
neural Method
ranking Method
models Method
, O
which O
is O
presented O
in O
this O
paper O
, O
not O
only O
enables O
us O
to O
learn O
neural Method
ranking Method
models Method
when O
no O
supervised O
signal O
is O
available O
, O
but O
also O
has O
substantial O
positive O
effects O
on O
the O
supervised Method
ranking Method
models Method
with O
limited O
amount O
of O
training Metric
data O
. O
section O
: O
Conclusions O
In O
this O
paper O
, O
we O
proposed O
to O
use O
traditional O
IR Task
models O
such O
as O
BM25 Method
as O
a O
weak O
supervision O
signal O
in O
order O
to O
generate O
large O
amounts O
of O
training Metric
data O
to O
train O
effective O
neural Method
ranking Method
models Method
. O
We O
examine O
various O
neural Method
ranking Method
models Method
with O
different O
ranking O
architectures O
and O
objectives O
, O
and O
different O
input O
representations O
. O
We O
used O
over O
six O
million O
queries O
to O
train O
our O
models O
and O
evaluated O
them O
on O
Robust04 Material
and O
ClueWeb O
09 O
- O
Category O
B O
collections O
, O
in O
an O
ad Task
- Task
hoc Task
retrieval O
setting O
. O
The O
experiments O
showed O
that O
our O
best O
performing O
model O
significantly O
outperforms O
the O
BM25 Method
model Method
( O
our O
weak Method
supervision Method
signal Method
) O
by O
over O
and O
MAP Metric
improvements O
in O
the O
Robust04 Material
and O
ClueWeb O
collections O
, O
respectively O
. O
We O
also O
demonstrated O
that O
in O
the O
case O
of O
having O
a O
small O
amount O
of O
training Metric
data O
, O
we O
can O
improve O
the O
performance O
of O
supervised Method
learning Method
by O
pre O
- O
training Metric
the O
network O
on O
weakly O
supervised O
data O
. O
Based O
on O
our O
results O
, O
there O
are O
three O
key O
ingredients O
in O
neural Method
ranking Method
models Method
that O
lead O
to O
good O
performance O
with O
weak O
supervision O
: O
The O
first O
is O
the O
proper O
input Method
representation Method
. O
Providing O
the O
network O
with O
raw O
data O
and O
letting O
the O
network O
to O
learn O
the O
features O
that O
matter O
, O
gives O
the O
network O
a O
chance O
of O
learning O
how O
to O
ignore O
imperfection O
in O
the O
training Metric
data O
. O
The O
second O
ingredient O
is O
to O
target O
the O
right O
goal O
and O
define O
a O
proper O
objective Metric
function Metric
. O
In O
the O
case O
of O
having O
weakly O
annotated O
training Metric
data O
, O
by O
targeting O
some O
explicit O
labels O
from O
the O
data O
, O
we O
may O
end O
up O
with O
a O
model O
that O
learned O
to O
express O
the O
data O
very O
well O
, O
but O
is O
incapable O
of O
going O
beyond O
it O
. O
This O
is O
especially O
the O
case O
with O
deep Method
neural Method
networks Method
where O
there O
are O
many O
parameters O
and O
it O
is O
easy O
to O
learn O
a O
model O
that O
overfits O
the O
data O
. O
The O
third O
ingredient O
is O
providing O
the O
network O
with O
a O
considerable O
amount O
of O
training Metric
examples O
. O
As O
an O
example O
, O
during O
the O
experiments O
we O
noticed O
that O
using O
the O
embedding Method
vector Method
representation Method
, O
the O
network O
needs O
a O
lot O
of O
examples O
to O
learn O
embeddings O
that O
are O
more O
effective O
for O
retrieval Task
compared O
to O
pre O
- O
trained O
embeddings O
. O
Thanks O
to O
weak O
supervision O
, O
we O
can O
generate O
as O
much O
training Metric
data O
as O
we O
need O
with O
almost O
no O
cost O
. O
Several O
future O
directions O
can O
be O
pursued O
. O
An O
immediate O
task O
would O
be O
to O
study O
the O
performance O
of O
more O
expressive Method
neural Method
network Method
architectures Method
e.g. O
, O
CNNs Method
and O
LSTMs Method
, O
with O
weak Method
supervision Method
setup Method
. O
Other O
experiment O
is O
to O
leverage O
multiple O
weak O
supervision O
signals O
from O
different O
sources O
. O
For O
example O
, O
we O
have O
other O
unsupervised O
ranking O
signals O
such O
as O
query O
likelihood O
and O
PageRank O
and O
taking O
them O
into O
consideration O
might O
benefit O
the O
learning Method
process Method
. O
Other O
future O
work O
would O
be O
to O
investigate O
the O
boosting Method
mechanism Method
for O
the O
method O
we O
have O
in O
this O
paper O
. O
In O
other O
words O
, O
it O
would O
be O
interesting O
to O
study O
if O
it O
is O
possible O
to O
use O
the O
trained O
model O
on O
weakly O
supervised O
data O
to O
annotate O
data O
with O
more O
quality O
from O
original O
source O
of O
annotation O
and O
leverage O
the O
new O
data O
to O
train O
a O
better O
model O
. O
Finally O
, O
we O
can O
apply O
this O
idea O
to O
other O
information Task
retrieval Task
tasks O
, O
such O
as O
query Task
/ Task
document Task
classification Task
and O
clustering Task
. O
This O
research O
was O
supported O
in O
part O
by O
Netherlands O
Organization O
for O
Scientific O
Research O
through O
the O
Exploratory O
Political O
Search O
project O
( O
ExPoSe O
, O
NWO O
CI O
# O
314.99.108 O
) O
, O
by O
the O
Digging O
into O
Data O
Challenge O
through O
the O
Digging O
Into O
Linked O
Parliamentary O
Data O
project O
( O
DiLiPaD O
, O
NWO O
Digging O
into O
Data O
# O
600.006.014 O
) O
, O
and O
by O
the O
Center O
for O
Intelligent Task
Information Task
Retrieval Task
. O
Any O
opinions O
, O
findings O
and O
conclusions O
or O
recommendations O
expressed O
in O
this O
material O
are O
those O
of O
the O
authors O
and O
do O
not O
necessarily O
reflect O
those O
of O
the O
sponsors O
. O
bibliography O
: O
References O
