document O
: O
Sequence Method
Level Method
Training Method
with O
Recurrent Method
Neural Method
Networks Method
Many O
natural Task
language Task
processing Task
applications Task
use O
language Method
models Method
to O
generate O
text O
. O
These O
models O
are O
typically O
trained O
to O
predict O
the O
next O
word O
in O
a O
sequence O
, O
given O
the O
previous O
words O
and O
some O
context O
such O
as O
an O
image O
. O
However O
, O
at O
test O
time O
the O
model O
is O
expected O
to O
generate O
the O
entire O
sequence O
from O
scratch O
. O
This O
discrepancy O
makes O
generation Task
brittle O
, O
as O
errors O
may O
accumulate O
along O
the O
way O
. O
We O
address O
this O
issue O
by O
proposing O
a O
novel O
sequence Method
level Method
training Method
algorithm Method
that O
directly O
optimizes O
the O
metric Metric
used O
at O
test O
time O
, O
such O
as O
BLEU Metric
or O
ROUGE Metric
. O
On O
three O
different O
tasks O
, O
our O
approach O
outperforms O
several O
strong O
baselines O
for O
greedy Task
generation Task
. O
The O
method O
is O
also O
competitive O
when O
these O
baselines O
employ O
beam Method
search Method
, O
while O
being O
several O
times O
faster O
. O
section O
: O
Introduction O
Natural O
language O
is O
the O
most O
natural O
form O
of O
communication Task
for O
humans O
. O
It O
is O
therefore O
essential O
that O
interactive Method
AI Method
systems Method
are O
capable O
of O
generating O
text O
textgen O
. O
A O
wide O
variety O
of O
applications O
rely O
on O
text Task
generation Task
, O
including O
machine Task
translation Task
, O
video O
/ O
text O
summarization Task
, O
question Task
answering Task
, O
among O
others O
. O
From O
a O
machine Method
learning Method
perspective Method
, O
text Task
generation Task
is O
the O
problem O
of O
predicting O
a O
syntactically Task
and Task
semantically Task
correct Task
sequence Task
of O
consecutive O
words O
given O
some O
context O
. O
For O
instance O
, O
given O
an O
image O
, O
generate O
an O
appropriate O
caption O
or O
given O
a O
sentence O
in O
English Material
language Material
, O
translate O
it O
into O
French Material
. O
Popular O
choices O
for O
text Method
generation Method
models Method
are O
language Method
models Method
based O
on O
n Method
- Method
grams Method
kneser Method
+ Method
ney1995 Method
, O
feed Method
- Method
forward Method
neural Method
networks Method
nlm Method
, O
and O
recurrent Method
neural Method
networks Method
( O
RNNs Method
; O
Mikolov O
et O
al O
. O
, O
2010 O
) O
. O
These O
models O
when O
used O
as O
is O
to O
generate O
text O
suffer O
from O
two O
major O
drawbacks O
. O
First O
, O
they O
are O
trained O
to O
predict O
the O
next O
word O
given O
the O
previous O
ground O
truth O
words O
as O
input O
. O
However O
, O
at O
test O
time O
, O
the O
resulting O
models O
are O
used O
to O
generate O
an O
entire O
sequence O
by O
predicting O
one O
word O
at O
a O
time O
, O
and O
by O
feeding O
the O
generated O
word O
back O
as O
input O
at O
the O
next O
time O
step O
. O
This O
process O
is O
very O
brittle O
because O
the O
model O
was O
trained O
on O
a O
different O
distribution O
of O
inputs O
, O
namely O
, O
words O
drawn O
from O
the O
data O
distribution O
, O
as O
opposed O
to O
words O
drawn O
from O
the O
model O
distribution O
. O
As O
a O
result O
the O
errors O
made O
along O
the O
way O
will O
quickly O
accumulate O
. O
We O
refer O
to O
this O
discrepancy O
as O
exposure O
bias O
which O
occurs O
when O
a O
model O
is O
only O
exposed O
to O
the O
training O
data O
distribution O
, O
instead O
of O
its O
own O
predictions O
. O
Second O
, O
the O
loss O
function O
used O
to O
train O
these O
models O
is O
at O
the O
word O
level O
. O
A O
popular O
choice O
is O
the O
cross Method
- Method
entropy Method
loss Method
used O
to O
maximize O
the O
probability O
of O
the O
next O
correct O
word O
. O
However O
, O
the O
performance O
of O
these O
models O
is O
typically O
evaluated O
using O
discrete Metric
metrics Metric
. O
One O
such O
metric O
is O
called O
BLEU Metric
bleu Metric
for O
instance O
, O
which O
measures O
the O
n Metric
- Metric
gram Metric
overlap Metric
between O
the O
model Method
generation Method
and O
the O
reference O
text O
. O
Training O
these O
models O
to O
directly O
optimize O
metrics Metric
like O
BLEU Metric
is O
hard O
because O
a O
) O
these O
are O
not O
differentiable O
rosti2011 O
, O
and O
b O
) O
combinatorial Task
optimization Task
is O
required O
to O
determine O
which O
sub O
- O
string O
maximizes O
them O
given O
some O
context O
. O
Prior O
attempts O
mcallister2010 O
, O
he12 O
at O
optimizing O
test Metric
metrics Metric
were O
restricted O
to O
linear Method
models Method
, O
or O
required O
a O
large O
number O
of O
samples O
to O
work O
well O
auli2014 O
. O
This O
paper O
proposes O
a O
novel O
training Method
algorithm Method
which O
results O
in O
improved O
text Task
generation Task
compared O
to O
standard O
models O
. O
The O
algorithm O
addresses O
the O
two O
issues O
discussed O
above O
as O
follows O
. O
First O
, O
while O
training O
the O
generative Method
model Method
we O
avoid O
the O
exposure O
bias O
by O
using O
model Method
predictions Method
at O
training O
time O
. O
Second O
, O
we O
directly O
optimize O
for O
our O
final O
evaluation Metric
metric Metric
. O
Our O
proposed O
methodology O
borrows O
ideas O
from O
the O
reinforcement Method
learning Method
literature Method
sutton Method
- Method
rl Method
. O
In O
particular O
, O
we O
build O
on O
the O
REINFORCE Method
algorithm Method
proposed O
by O
reinforce Method
, O
to O
achieve O
the O
above O
two O
objectives O
. O
While O
sampling O
from O
the O
model O
during O
training O
is O
quite O
a O
natural O
step O
for O
the O
REINFORCE Method
algorithm Method
, O
optimizing O
directly O
for O
any O
test Metric
metric Metric
can O
also O
be O
achieved O
by O
it O
. O
REINFORCE O
side O
steps O
the O
issues O
associated O
with O
the O
discrete O
nature O
of O
the O
optimization Task
by O
not O
requiring O
rewards O
( O
or O
losses O
) O
to O
be O
differentiable O
. O
While O
REINFORCE Method
appears O
to O
be O
well O
suited O
to O
tackle O
the O
text Task
generation Task
problem Task
, O
it O
suffers O
from O
a O
significant O
issue O
. O
The O
problem O
setting O
of O
text Task
generation Task
has O
a O
very O
large O
action O
space O
which O
makes O
it O
extremely O
difficult O
to O
learn O
with O
an O
initial O
random Method
policy Method
. O
Specifically O
, O
the O
search O
space O
for O
text Task
generation Task
is O
of O
size O
, O
where O
is O
the O
number O
of O
words O
in O
the O
vocabulary O
( O
typically O
around O
or O
more O
) O
and O
is O
the O
length O
of O
the O
sentence O
( O
typically O
around O
to O
) O
. O
Towards O
that O
end O
, O
we O
introduce O
Mixed Method
Incremental Method
Cross Method
- Method
Entropy Method
Reinforce Method
( O
MIXER Method
) O
, O
which O
is O
our O
first O
major O
contribution O
of O
this O
work O
. O
MIXER Method
is O
an O
easy O
- O
to O
- O
implement O
recipe O
to O
make O
REINFORCE Method
work O
well O
for O
text Task
generation Task
applications Task
. O
It O
is O
based O
on O
two O
key O
ideas O
: O
incremental Method
learning Method
and O
the O
use O
of O
a O
hybrid Method
loss Method
function Method
which O
combines O
both O
REINFORCE O
and O
cross O
- O
entropy O
( O
see O
Sec O
. O
[ O
reference O
] O
for O
details O
) O
. O
Both O
ingredients O
are O
essential O
to O
training O
with O
large O
action O
spaces O
. O
In O
MIXER Method
, O
the O
model O
starts O
from O
the O
optimal Method
policy Method
given O
by O
cross Method
- Method
entropy Method
training Method
( O
as O
opposed O
to O
a O
random O
one O
) O
, O
from O
which O
it O
then O
slowly O
deviates O
, O
in O
order O
to O
make O
use O
of O
its O
own O
predictions O
, O
as O
is O
done O
at O
test O
time O
. O
Our O
second O
contribution O
is O
a O
thorough O
empirical O
evaluation O
on O
three O
different O
tasks O
, O
namely O
, O
Text Task
Summarization Task
, O
Machine Task
Translation Task
and O
Image Task
Captioning Task
. O
We O
compare O
against O
several O
strong O
baselines O
, O
including O
, O
RNNs Method
trained O
with O
cross Method
- Method
entropy Method
and O
Data Method
as Method
Demonstrator Method
( O
DAD Method
) O
sbengio O
- O
nips2015 O
, O
dad O
. O
We O
also O
compare O
MIXER Method
with O
another O
simple O
yet O
novel O
model O
that O
we O
propose O
in O
this O
paper O
. O
We O
call O
it O
the O
End Method
- Method
to Method
- Method
End Method
BackProp Method
model O
( O
see O
Sec O
. O
[ O
reference O
] O
for O
details O
) O
. O
Our O
results O
show O
that O
MIXER Method
with O
a O
simple O
greedy Method
search Method
achieves O
much O
better O
accuracy Metric
compared O
to O
the O
baselines O
on O
all O
the O
three O
tasks O
. O
In O
addition O
we O
show O
that O
MIXER Method
with O
greedy Method
search Method
is O
even O
more O
accurate O
than O
the O
cross Method
entropy Method
model Method
augmented O
with O
beam Method
search Method
at O
inference O
time O
as O
a O
post O
- O
processing O
step O
. O
This O
is O
particularly O
remarkable O
because O
MIXER Method
with O
greedy Method
search Method
is O
at O
least O
times O
faster O
than O
the O
cross Method
entropy Method
model Method
with O
a O
beam O
of O
size O
. O
Lastly O
, O
we O
note O
that O
MIXER Method
and O
beam Method
search Method
are O
complementary O
to O
each O
other O
and O
can O
be O
combined O
to O
further O
improve O
performance O
, O
although O
the O
extent O
of O
the O
improvement O
is O
task O
dependent O
. O
section O
: O
Related O
Work O
Sequence Method
models Method
are O
typically O
trained O
to O
predict O
the O
next O
word O
using O
the O
cross Metric
- Metric
entropy Metric
loss Metric
. O
At O
test O
time O
, O
it O
is O
common O
to O
use O
beam Method
search Method
to O
explore O
multiple O
alternative O
paths O
sutskever2014 O
, O
bahdanau O
- O
iclr2015 O
, O
rush O
- O
2015 O
. O
While O
this O
improves O
generation Task
by O
typically O
one O
or O
two O
BLEU Metric
points Metric
bleu Metric
, O
it O
makes O
the O
generation Task
at O
least O
times O
slower O
, O
where O
is O
the O
number O
of O
active O
paths O
in O
the O
beam O
( O
see O
Sec O
. O
[ O
reference O
] O
for O
more O
details O
) O
. O
The O
idea O
of O
improving O
generation Task
by O
letting O
the O
model O
use O
its O
own O
predictions O
at O
training O
time O
( O
the O
key O
proposal O
of O
this O
work O
) O
was O
first O
advocated O
by O
searn O
. O
In O
their O
seminal O
work O
, O
the O
authors O
first O
noticed O
that O
structured Task
prediction Task
problems Task
can O
be O
cast O
as O
a O
particular O
instance O
of O
reinforcement Method
learning Method
. O
They O
then O
proposed O
SEARN Method
, O
an O
algorithm O
to O
learn O
such O
structured Task
prediction Task
tasks Task
. O
The O
basic O
idea O
is O
to O
let O
the O
model O
use O
its O
own O
predictions O
at O
training O
time O
to O
produce O
a O
sequence O
of O
actions O
( O
e.g. O
, O
the O
choice O
of O
the O
next O
word O
) O
. O
Then O
, O
a O
search Method
algorithm Method
is O
run O
to O
determine O
the O
optimal O
action O
at O
each O
time O
step O
, O
and O
a O
classifier Method
( O
a.k.a O
. O
policy Method
) O
is O
trained O
to O
predict O
that O
action O
. O
A O
similar O
idea O
was O
later O
proposed O
by O
dagger Method
in O
an O
imitation Method
learning Method
framework Method
. O
Unfortunately O
, O
for O
text Task
generation Task
it O
is O
generally O
intractable O
to O
compute O
an O
oracle O
of O
the O
optimal O
target O
word O
given O
the O
words O
predicted O
so O
far O
. O
The O
oracle Task
issue Task
was O
later O
addressed O
by O
an O
algorithm O
called O
Data Method
As Method
Demonstrator Method
( O
DAD Method
) O
dad O
and O
applied O
for O
text Task
generation Task
by O
, O
whereby O
the O
target O
action O
at O
step O
is O
the O
- O
th O
action O
taken O
by O
the O
optimal Method
policy Method
( O
ground O
truth O
sequence O
) O
regardless O
of O
which O
input O
is O
fed O
to O
the O
system O
, O
whether O
it O
is O
ground O
truth O
, O
or O
the O
model O
’s O
prediction Task
. O
While O
DAD Method
usually O
improves O
generation Task
, O
it O
seems O
unsatisfactory O
to O
force O
the O
model O
to O
predict O
a O
certain O
word O
regardless O
of O
the O
preceding O
words O
( O
see O
sec O
. O
[ O
reference O
] O
for O
more O
details O
) O
. O
Finally O
, O
REINFORCE Method
has O
already O
been O
used O
for O
other O
applications O
, O
such O
as O
in O
computer Task
vision Task
vmnih O
- O
nips2014 O
, O
xu O
- O
icml2015 O
, O
ba_iclr15 O
, O
and O
for O
speech Task
recognition Task
. O
While O
they O
simply O
pre O
- O
trained O
with O
cross Method
- Method
entropy Method
loss Method
, O
we O
found O
that O
the O
use O
of O
a O
mixed O
loss O
and O
a O
more O
gentle O
incremental Method
learning Method
scheduling Method
to O
be O
important O
for O
all O
the O
tasks O
we O
considered O
. O
section O
: O
Models O
The O
learning Method
algorithms Method
we O
describe O
in O
the O
following O
sections O
are O
agnostic O
to O
the O
choice O
of O
the O
underlying O
model O
, O
as O
long O
as O
it O
is O
parametric O
. O
In O
this O
work O
, O
we O
focus O
on O
Recurrent Method
Neural Method
Networks Method
( O
RNNs Method
) O
as O
they O
are O
a O
popular O
choice O
for O
text Task
generation Task
. O
In O
particular O
, O
we O
use O
standard O
Elman Method
RNNs Method
elman1990 O
and O
LSTMs Method
lstm Method
. O
For O
the O
sake O
of O
simplicity O
but O
without O
loss O
of O
generality O
, O
we O
discuss O
next O
Elman Method
RNNs Method
. O
This O
is O
a O
parametric Method
model Method
that O
at O
each O
time O
step O
, O
takes O
as O
input O
a O
word O
as O
its O
input O
, O
together O
with O
an O
internal Method
representation Method
. O
is O
the O
the O
vocabulary O
of O
input O
words O
. O
This O
internal Method
representation Method
is O
a O
real O
- O
valued O
vector O
which O
encodes O
the O
history O
of O
words O
the O
model O
has O
seen O
so O
far O
. O
Optionally O
, O
the O
RNN Method
can O
also O
take O
as O
input O
an O
additional O
context O
vector O
, O
which O
encodes O
the O
context O
to O
be O
used O
while O
generating O
the O
output O
. O
In O
our O
experiments O
is O
computed O
using O
an O
attentive Method
decoder Method
inspired O
by O
and O
rush O
- O
2015 O
, O
the O
details O
of O
which O
are O
given O
in O
Section O
[ O
reference O
] O
of O
the O
supplementary O
material O
. O
The O
RNN Method
learns O
a O
recursive Method
function Method
to O
compute O
and O
outputs O
the O
distribution O
over O
the O
next O
word O
: O
The O
parametric O
expression O
for O
and O
depends O
on O
the O
type O
of O
RNN Method
. O
For O
Elman Method
RNNs Method
we O
have O
: O
where O
the O
parameters O
of O
the O
model O
are O
the O
set O
of O
matrices O
and O
also O
the O
additional O
parameters O
used O
to O
compute O
. O
is O
a O
vector O
whose O
components O
are O
, O
and O
is O
an O
indicator O
vector O
with O
only O
the O
- O
th O
component O
set O
to O
and O
the O
rest O
to O
. O
We O
assume O
the O
first O
word O
of O
the O
sequence O
is O
a O
special O
token O
indicating O
the O
beginning O
of O
a O
sequence O
, O
denoted O
by O
. O
All O
entries O
of O
the O
first O
hidden O
state O
are O
set O
to O
a O
constant O
value O
. O
Next O
, O
we O
are O
going O
to O
introduce O
both O
baselines O
and O
the O
model O
we O
propose O
. O
As O
we O
describe O
these O
models O
, O
it O
is O
useful O
to O
keep O
in O
mind O
the O
key O
characteristics O
of O
a O
text Task
generation Task
system Task
, O
as O
outlined O
in O
Table O
[ O
reference O
] O
. O
There O
are O
three O
dimensions O
which O
are O
important O
when O
training O
a O
model O
for O
text Task
generation Task
: O
the O
exposure O
bias O
which O
can O
adversely O
affect O
generation Task
at O
test O
time O
, O
the O
ability O
to O
fully O
back O
- O
propagate O
gradients O
( O
including O
with O
respect O
to O
the O
chosen O
inputs O
at O
each O
time O
step O
) O
, O
and O
a O
loss Method
operating O
at O
the O
sequence O
level O
. O
We O
will O
start O
discussing O
models O
that O
do O
not O
possess O
any O
of O
these O
desirable O
features O
, O
and O
then O
move O
towards O
models O
that O
better O
satisfy O
our O
requirements O
. O
The O
last O
model O
we O
propose O
, O
dubbed O
MIXER Method
, O
has O
all O
the O
desiderata O
. O
subsection O
: O
Word Method
- Method
Level Method
Training Method
We O
now O
review O
a O
collection O
of O
methodologies O
used O
for O
training O
text Method
generation Method
models Method
which O
optimize O
the O
prediction O
of O
only O
one O
word O
ahead O
of O
time O
. O
We O
start O
with O
the O
simplest O
and O
the O
most O
popular O
method O
which O
optimizes O
the O
cross Metric
- Metric
entropy Metric
loss Metric
at O
every O
time O
step O
. O
We O
then O
discuss O
a O
recently O
proposed O
modification O
to O
it O
which O
explicitly O
uses O
the O
model O
predictions O
during O
training O
. O
We O
finish O
by O
proposing O
a O
simple O
yet O
novel O
baseline O
which O
uses O
its O
model Method
prediction Method
during O
training O
and O
also O
has O
the O
ability O
to O
back O
propagate O
the O
gradients O
through O
the O
entire O
sequence O
. O
While O
these O
extensions O
tend O
to O
make O
generation Task
more O
robust O
, O
they O
still O
lack O
explicit O
supervision O
at O
the O
sequence O
level O
. O
subsubsection O
: O
Cross Method
Entropy Method
Training Method
( O
XENT Method
) O
Cross Method
- Method
entropy Method
loss Method
( O
XENT Method
) O
maximizes O
the O
probability O
of O
the O
observed O
sequence O
according O
to O
the O
model O
. O
If O
the O
target O
sequence O
is O
, O
then O
XENT Method
training O
involves O
minimizing Task
: O
When O
using O
an O
RNN Method
, O
each O
term O
is O
modeled O
as O
a O
parametric O
function O
as O
given O
in O
Equation O
( O
[ O
reference O
] O
) O
. O
This O
loss Method
function Method
trains O
the O
model O
to O
be O
good O
at O
greedily O
predicting O
the O
next O
word O
at O
each O
time O
step O
without O
considering O
the O
whole O
sequence O
. O
Training Method
proceeds O
by O
truncated Method
back Method
- Method
propagation Method
through O
time Method
bptt Method
with O
gradient Method
clipping Method
mikolov O
- O
2010 O
. O
Once O
trained O
, O
one O
can O
use O
the O
model O
to O
generate O
an O
entire O
sequence O
as O
follows O
. O
Let O
denote O
the O
word O
generated O
by O
the O
model O
at O
the O
- O
th O
time O
step O
. O
Then O
the O
next O
word O
is O
generated O
by O
: O
Notice O
that O
, O
the O
model O
is O
trained O
to O
maximize O
, O
where O
is O
the O
word O
in O
the O
ground O
truth O
sequence O
. O
However O
, O
during O
generation Task
the O
model O
is O
used O
as O
. O
In O
other O
words O
, O
during O
training O
the O
model O
is O
only O
exposed O
to O
the O
ground O
truth O
words O
. O
However O
, O
at O
test O
time O
the O
model O
has O
only O
access O
to O
its O
own O
predictions O
, O
which O
may O
not O
be O
correct O
. O
As O
a O
result O
, O
during O
generation Task
the O
model O
can O
potentially O
deviate O
quite O
far O
from O
the O
actual O
sequence O
to O
be O
generated O
. O
Figure O
[ O
reference O
] O
illustrates O
this O
discrepancy O
. O
The O
generation Task
described O
by O
Eq O
. O
( O
[ O
reference O
] O
) O
is O
a O
greedy Method
left Method
- Method
to Method
- Method
right Method
process Method
which O
does O
not O
necessarily O
produce O
the O
most O
likely O
sequence O
according O
to O
the O
model O
, O
because O
: O
The O
most O
likely O
sequence O
might O
contain O
a O
word O
which O
is O
sub O
- O
optimal O
at O
an O
intermediate O
time O
- O
step O
. O
This O
phenomena O
is O
commonly O
known O
as O
a O
search Metric
error Metric
. O
One O
popular O
way O
to O
reduce O
the O
effect O
of O
search Metric
error Metric
is O
to O
pursue O
not O
only O
one O
but O
next O
word O
candidates O
at O
each O
point O
. O
While O
still O
approximate O
, O
this O
strategy O
can O
recover O
higher O
scoring O
sequences O
that O
are O
often O
also O
better O
in O
terms O
of O
our O
final O
evaluation Metric
metric Metric
. O
This O
process O
is O
commonly O
know O
as O
Beam Task
Search Task
. O
The O
downside O
of O
using O
beam Method
search Method
is O
that O
it O
significantly O
slows O
down O
the O
generation Task
process Task
. O
The O
time Metric
complexity Metric
grows O
linearly O
in O
the O
number O
of O
beams O
, O
because O
we O
need O
to O
perform O
forward O
passes O
for O
our O
network O
, O
which O
is O
the O
most O
time O
intensive O
operation O
. O
The O
details O
of O
the O
Beam Method
Search Method
algorithm Method
are O
described O
in O
Section O
[ O
reference O
] O
. O
subsubsection O
: O
Data Method
As Method
Demonstrator Method
( O
DAD Method
) O
Conventional O
training Method
with O
XENT Method
suffers O
from O
exposure O
bias O
since O
training O
uses O
ground O
truth O
words O
as O
opposed O
to O
model O
predictions O
. O
DAD Method
, O
proposed O
in O
dad Method
and O
also O
used O
in O
sbengio O
- O
nips2015 O
for O
sequence Task
generation Task
, O
addresses O
this O
issue O
by O
mixing O
the O
ground O
truth O
training O
data O
with O
model Method
predictions Method
. O
At O
each O
time O
step O
and O
with O
a O
certain O
probability O
, O
DAD Method
takes O
as O
input O
either O
the O
prediction O
from O
the O
model O
at O
the O
previous O
time O
step O
or O
the O
ground O
truth O
data O
. O
sbengio O
- O
nips2015 O
proposed O
different O
annealing Method
schedules Method
for O
the O
probability O
of O
choosing O
the O
ground O
truth O
word O
. O
The O
annealing Method
schedules Method
are O
such O
that O
at O
the O
beginning O
, O
the O
algorithm O
always O
chooses O
the O
ground O
truth O
words O
. O
However O
, O
as O
the O
training O
progresses O
the O
model O
predictions O
are O
selected O
more O
often O
. O
This O
has O
the O
effect O
of O
making O
the O
model O
somewhat O
more O
aware O
of O
how O
it O
will O
be O
used O
at O
test O
time O
. O
Figure O
[ O
reference O
] O
illustrates O
the O
algorithm O
. O
A O
major O
limitation O
of O
DAD Method
is O
that O
at O
every O
time O
step O
the O
target O
labels O
are O
always O
selected O
from O
the O
ground O
truth O
data O
, O
regardless O
of O
how O
the O
input O
was O
chosen O
. O
As O
a O
result O
, O
the O
targets O
may O
not O
be O
aligned O
with O
the O
generated O
sequence O
, O
forcing O
the O
model O
to O
predict O
a O
potentially O
incorrect O
sequence O
. O
For O
instance O
, O
if O
the O
ground O
truth O
sequence O
is O
“ O
I O
took O
a O
long O
walk O
” O
and O
the O
model O
has O
so O
far O
predicted O
“ O
I O
took O
a O
walk O
” O
, O
DAD Method
will O
force O
the O
model O
to O
predict O
the O
word O
“ O
walk O
” O
a O
second O
time O
. O
Finally O
, O
gradients O
are O
not O
back O
- O
propagated O
through O
the O
samples O
drawn O
by O
the O
model O
and O
the O
XENT Method
loss O
is O
still O
at O
the O
word O
level O
. O
It O
is O
not O
well O
understood O
how O
these O
problems O
affect O
generation Task
. O
subsubsection O
: O
End Method
- Method
to Method
- Method
End Method
BackProp Method
( O
E2E Method
) O
The O
novel O
E2E Method
algorithm O
is O
perhaps O
the O
most O
natural O
and O
naïve O
approach O
approximating O
sequence Task
level Task
training Task
, O
which O
can O
also O
be O
interpreted O
as O
a O
computationally O
efficient O
approximation O
to O
beam Method
search Method
. O
The O
key O
idea O
is O
that O
at O
time O
step O
we O
propagate O
as O
input O
the O
top O
words O
predicted O
at O
the O
previous O
time O
step O
instead O
of O
the O
ground O
truth O
word O
. O
Specifically O
, O
we O
take O
the O
output O
distribution O
over O
words O
from O
the O
previous O
time O
step O
, O
and O
pass O
it O
through O
a O
- Method
max Method
layer Method
. O
This O
layer O
zeros O
all O
but O
the O
largest O
values O
and O
re O
- O
normalizes O
them O
to O
sum O
to O
one O
. O
We O
thus O
have O
: O
where O
are O
indexes O
of O
the O
words O
with O
largest O
probabilities O
and O
are O
their O
corresponding O
scores O
. O
At O
the O
time O
step O
, O
we O
take O
the O
largest O
scoring O
previous O
words O
as O
input O
whose O
contributions O
is O
weighted O
by O
their O
scores O
’ O
s. O
Smoothing O
the O
input O
this O
way O
makes O
the O
whole O
process O
differentiable O
and O
trainable O
using O
standard O
back Method
- Method
propagation Method
. O
Compared O
to O
beam Method
search Method
, O
this O
can O
be O
interpreted O
as O
fusing O
the O
possible O
next O
hypotheses O
together O
into O
a O
single O
path O
, O
as O
illustrated O
in O
Figure O
[ O
reference O
] O
. O
In O
practice O
we O
also O
employ O
a O
schedule O
, O
whereby O
we O
use O
only O
the O
ground O
truth O
words O
at O
the O
beginning O
and O
gradually O
let O
the O
model O
use O
its O
own O
top O
- O
predictions O
as O
training O
proceeds O
. O
While O
this O
algorithm O
is O
a O
simple O
way O
to O
expose O
the O
model O
to O
its O
own O
predictions O
, O
the O
loss O
function O
optimized O
is O
still O
XENT Method
at O
each O
time O
step O
. O
There O
is O
no O
explicit O
supervision O
at O
the O
sequence O
level O
while O
training O
the O
model O
. O
subsection O
: O
Sequence Method
Level Method
Training Method
We O
now O
introduce O
a O
novel O
algorithm O
for O
sequence Task
level Task
training Task
, O
which O
we O
call O
Mixed Method
Incremental Method
Cross Method
- Method
Entropy Method
Reinforce Method
( O
MIXER Method
) O
. O
The O
proposed O
method O
avoids O
the O
exposure Task
bias Task
problem Task
, O
and O
also O
directly O
optimizes O
for O
the O
final Metric
evaluation Metric
metric Metric
. O
Since O
MIXER Method
is O
an O
extension O
of O
the O
REINFORCE Method
algorithm Method
, O
we O
first O
describe O
REINFORCE Method
from O
the O
perspective O
of O
sequence Task
generation Task
. O
subsubsection O
: O
REINFORCE O
In O
order O
to O
apply O
the O
REINFORCE Method
algorithm Method
reinforce Method
, O
zaremba O
- O
arxiv2015 O
to O
the O
problem O
of O
sequence Task
generation Task
we O
cast O
our O
problem O
in O
the O
reinforcement Method
learning Method
( O
RL Method
) O
framework O
sutton O
- O
rl O
. O
Our O
generative Method
model Method
( O
the O
RNN Method
) O
can O
be O
viewed O
as O
an O
agent O
, O
which O
interacts O
with O
the O
external O
environment O
( O
the O
words O
and O
the O
context O
vector O
it O
sees O
as O
input O
at O
every O
time O
step O
) O
. O
The O
parameters O
of O
this O
agent O
defines O
a O
policy Method
, O
whose O
execution O
results O
in O
the O
agent O
picking O
an O
action O
. O
In O
the O
sequence Task
generation Task
setting Task
, O
an O
action O
refers O
to O
predicting O
the O
next O
word O
in O
the O
sequence O
at O
each O
time O
step O
. O
After O
taking O
an O
action O
the O
agent O
updates O
its O
internal O
state O
( O
the O
hidden O
units O
of O
RNN Method
) O
. O
Once O
the O
agent O
has O
reached O
the O
end O
of O
a O
sequence O
, O
it O
observes O
a O
reward O
. O
We O
can O
choose O
any O
reward O
function O
. O
Here O
, O
we O
use O
BLEU Metric
bleu Metric
and O
ROUGE Metric
- Metric
2 Metric
rouge Metric
since O
these O
are O
the O
metrics O
we O
use O
at O
test O
time O
. O
BLEU Metric
is O
essentially O
a O
geometric Metric
mean Metric
over O
n Metric
- Metric
gram Metric
precision Metric
scores Metric
as O
well O
as O
a O
brevity O
penalty O
liang2006 O
; O
in O
this O
work O
, O
we O
consider O
up O
to O
- O
grams O
. O
ROUGE Metric
- Metric
2 Metric
is O
instead O
recall O
over O
bi O
- O
grams O
. O
Like O
in O
imitation Method
learning Method
, O
we O
have O
a O
training O
set O
of O
optimal O
sequences O
of O
actions O
. O
During O
training O
we O
choose O
actions O
according O
to O
the O
current O
policy O
and O
only O
observe O
a O
reward O
at O
the O
end O
of O
the O
sequence O
( O
or O
after O
maximum O
sequence O
length O
) O
, O
by O
comparing O
the O
sequence O
of O
actions O
from O
the O
current O
policy O
against O
the O
optimal O
action O
sequence O
. O
The O
goal O
of O
training Task
is O
to O
find O
the O
parameters O
of O
the O
agent O
that O
maximize O
the O
expected O
reward O
. O
We O
define O
our O
loss O
as O
the O
negative O
expected O
reward O
: O
where O
is O
the O
word O
chosen O
by O
our O
model O
at O
the O
- O
th O
time O
step O
, O
and O
is O
the O
reward O
associated O
with O
the O
generated O
sequence O
. O
In O
practice O
, O
we O
approximate O
this O
expectation O
with O
a O
single O
sample O
from O
the O
distribution O
of O
actions O
implemented O
by O
the O
RNN Method
( O
right O
hand O
side O
of O
the O
equation O
above O
and O
Figure O
[ O
reference O
] O
of O
Supplementary O
Material O
) O
. O
We O
refer O
the O
reader O
to O
prior O
work O
zaremba O
- O
arxiv2015 O
, O
reinforce O
for O
the O
full O
derivation O
of O
the O
gradients O
. O
Here O
, O
we O
directly O
report O
the O
partial O
derivatives O
and O
their O
interpretation O
. O
The O
derivatives O
w.r.t O
. O
parameters O
are O
: O
where O
is O
the O
input O
to O
the O
softmax O
. O
The O
gradient O
of O
the O
loss O
with O
respect O
to O
is O
given O
by O
: O
where O
is O
the O
average O
reward O
at O
time O
. O
The O
interpretation O
of O
this O
weight Method
update Method
rule Method
is O
straightforward O
. O
While O
Equation O
[ O
reference O
] O
is O
standard O
back Method
- Method
propagation Method
( O
a.k.a O
. O
chain Method
rule Method
) O
, O
Equation O
[ O
reference O
] O
is O
almost O
exactly O
the O
same O
as O
the O
gradient O
of O
a O
multi Method
- Method
class Method
logistic Method
regression Method
classifier Method
. O
In O
logistic Task
regression Task
, O
the O
gradient O
is O
the O
difference O
between O
the O
prediction O
and O
the O
actual O
1 O
- O
of O
- O
N Method
representation Method
of O
the O
target O
word O
: O
Therefore O
, O
Equation O
[ O
reference O
] O
says O
that O
the O
chosen O
word O
acts O
like O
a O
surrogate O
target O
for O
our O
output O
distribution O
, O
at O
time O
. O
REINFORCE Method
first O
establishes O
a O
baseline O
, O
and O
then O
either O
encourages O
a O
word O
choice O
if O
, O
or O
discourages O
it O
if O
. O
The O
actual O
derivation O
suggests O
that O
the O
choice O
of O
this O
average O
reward O
is O
useful O
to O
decrease O
the O
variance Metric
of O
the O
gradient Method
estimator Method
since O
in O
Equation O
[ O
reference O
] O
we O
use O
a O
single O
sample O
from O
the O
distribution O
of O
actions O
. O
In O
our O
implementation O
, O
the O
baseline O
is O
estimated O
by O
a O
linear Method
regressor Method
which O
takes O
as O
input O
the O
hidden O
states O
of O
the O
RNN Method
. O
The O
regressor Method
is O
an O
unbiased Method
estimator Method
of Method
future Method
rewards Method
since O
it O
only O
uses O
past O
information O
. O
The O
parameters O
of O
the O
regressor Method
are O
trained O
by O
minimizing O
the O
mean Metric
squared Metric
loss Metric
: O
. O
In O
order O
to O
prevent O
feedback O
loops O
, O
we O
do O
not O
backpropagate O
this O
error O
through O
the O
recurrent Method
network Method
zaremba O
- O
arxiv2015 O
. O
REINFORCE Method
is O
an O
elegant O
algorithm O
to O
train O
at O
the O
sequence O
level O
using O
any O
user O
- O
defined O
reward O
. O
In O
this O
work O
, O
we O
use O
BLEU Metric
and O
ROUGE Metric
- Metric
2 Metric
as O
reward O
, O
however O
one O
could O
just O
as O
easily O
use O
any O
other O
metric O
. O
When O
presented O
as O
is O
, O
one O
major O
drawback O
associated O
with O
the O
algorithm O
is O
that O
it O
assumes O
a O
random Method
policy Method
to O
start O
with O
. O
This O
assumption O
can O
make O
the O
learning Task
for O
large Task
action Task
spaces Task
very O
challenging O
. O
Unfortunately O
, O
text Task
generation Task
is O
such O
a O
setting O
where O
the O
cardinality O
of O
the O
action O
set O
is O
in O
the O
order O
of O
( O
the O
number O
of O
words O
in O
the O
vocabulary O
) O
. O
This O
leads O
to O
a O
very O
high O
branching Metric
factor Metric
where O
it O
is O
extremely O
hard O
for O
a O
random Method
policy Method
to O
improve O
in O
any O
reasonable O
amount O
of O
time O
. O
In O
the O
next O
section O
we O
describe O
the O
MIXER Method
algorithm O
which O
addresses O
these O
issues O
, O
better O
targeting O
text Task
generation Task
applications Task
. O
subsubsection O
: O
Mixed Method
Incremental Method
Cross Method
- Method
Entropy Method
Reinforce Method
( O
MIXER Method
) O
The O
MIXER Method
algorithm O
borrows O
ideas O
both O
from O
DAGGER Method
dagger Method
and O
DAD Method
dad O
, O
sbengio O
- O
nips2015 O
and O
modifies O
the O
REINFORCE Method
appropriately O
. O
The O
first O
key O
idea O
is O
to O
change O
the O
initial O
policy O
of O
REINFORCE O
to O
make O
sure O
the O
model O
can O
effectively O
deal O
with O
the O
large O
action O
space O
of O
text Task
generation Task
. O
Instead O
of O
starting O
from O
a O
poor O
random Method
policy Method
and O
training O
the O
model O
to O
converge O
towards O
the O
optimal Method
policy Method
, O
we O
do O
the O
exact O
opposite O
. O
We O
start O
from O
the O
optimal Method
policy Method
and O
then O
slowly O
deviate O
from O
it O
to O
let O
the O
model O
explore O
and O
make O
use O
of O
its O
own O
predictions O
. O
We O
first O
train O
the O
RNN Method
with O
the O
cross Method
- Method
entropy Method
loss Method
for O
epochs O
using O
the O
ground O
truth O
sequences O
. O
This O
ensures O
that O
we O
start O
off O
with O
a O
much O
better O
policy O
than O
random O
because O
now O
the O
model O
can O
focus O
on O
a O
good O
part O
of O
the O
search O
space O
. O
This O
can O
be O
better O
understood O
by O
comparing O
the O
perplexity Metric
of O
a O
language Method
model Method
that O
is O
randomly O
initialized O
versus O
one O
that O
is O
trained O
. O
Perplexity Method
is O
a O
measure O
of O
uncertainty Metric
of O
the O
prediction Task
and O
, O
roughly O
speaking O
, O
it O
corresponds O
to O
the O
average O
number O
of O
words O
the O
model O
is O
‘ O
hesitating O
’ O
about O
when O
making O
a O
prediction Task
. O
A O
good O
language Method
model Method
trained O
on O
one O
of O
our O
data O
sets O
has O
perplexity O
of O
, O
whereas O
a O
random Method
model Method
is O
likely O
to O
have O
perplexity O
close O
to O
the O
size O
of O
the O
vocabulary O
, O
which O
is O
about O
. O
The O
second O
idea O
is O
to O
introduce O
model Method
predictions Method
during O
training O
with O
an O
annealing Method
schedule Method
in O
order O
to O
gradually O
teach O
the O
model O
to O
produce O
stable O
sequences O
. O
Let O
be O
the O
length O
of O
the O
sequence O
. O
After O
the O
initial O
epochs O
, O
we O
continue O
training O
the O
model O
for O
epochs O
, O
such O
that O
, O
for O
every O
sequence O
we O
use O
the O
XENT Method
loss O
for O
the O
first O
( O
) O
steps O
, O
and O
the O
REINFORCE Method
algorithm Method
for O
the O
remaining O
steps O
. O
In O
our O
experiments O
is O
typically O
set O
to O
two O
or O
three O
. O
Next O
we O
anneal O
the O
number O
of O
steps O
for O
which O
we O
use O
the O
XENT Method
loss O
for O
every O
sequence O
to O
( O
) O
and O
repeat O
the O
training O
for O
another O
epochs O
. O
We O
repeat O
this O
process O
until O
only O
REINFORCE Method
is O
used O
to O
train O
the O
whole O
sequence O
. O
See O
Algorithm O
[ O
reference O
] O
for O
the O
pseudo O
- O
code O
. O
We O
call O
this O
algorithm O
Mixed Method
Incremental Method
Cross Method
- Method
Entropy Method
Reinforce Method
( O
MIXER Method
) O
because O
we O
combine O
both O
XENT Method
and O
REINFORCE Method
, O
and O
we O
use O
incremental Method
learning Method
( O
a.k.a O
. O
curriculum Method
learning Method
) O
. O
The O
overall O
algorithm O
is O
illustrated O
in O
Figure O
[ O
reference O
] O
. O
By O
the O
end O
of O
training O
, O
the O
model O
can O
make O
effective O
use O
of O
its O
own O
predictions O
in O
- O
line O
with O
its O
use O
at O
test O
time O
. O
[ O
t O
] O
a O
set O
of O
sequences O
with O
their O
corresponding O
context O
. O
optimized O
for O
generation Task
. O
Initialize O
RNN Method
at O
random O
and O
set O
NXENT O
, O
NXE O
+ O
R O
and O
Δ O
= O
T O
, O
1 O
, O
- O
Δ O
s O
= O
= O
T O
train O
RNN Method
for O
NXENT O
epochs O
using O
XENT Method
only O
train O
RNN Method
for O
NXE O
+ O
R O
epochs O
. O
Use O
XENT Method
loss O
in O
the O
first O
s O
steps O
, O
and O
REINFORCE Method
( O
sampling O
from O
the O
model O
) O
in O
the O
remaining O
- O
Ts O
steps O
MIXER Method
pseudo O
- O
code O
. O
section O
: O
Experiments O
In O
all O
our O
experiments O
, O
we O
train O
conditional Method
RNNs Method
by O
unfolding O
them O
up O
to O
a O
certain O
maximum O
length O
. O
We O
chose O
this O
length O
to O
cover O
about O
of O
the O
target O
sentences O
in O
the O
data O
sets O
we O
consider O
. O
The O
remaining O
sentences O
are O
cropped O
to O
the O
chosen O
maximum O
length O
. O
For O
training Task
, O
we O
use O
stochastic Method
gradient Method
descent Method
with O
mini O
- O
batches O
of O
size O
and O
we O
reset O
the O
hidden O
states O
at O
the O
beginning O
of O
each O
sequence O
. O
Before O
updating O
the O
parameters O
we O
re O
- O
scale O
the O
gradients O
if O
their O
norm O
is O
above O
mikolov O
- O
2010 O
. O
We O
search O
over O
the O
values O
of O
hyper O
- O
parameter O
, O
such O
as O
the O
initial O
learning Metric
rate Metric
, O
the O
various O
scheduling O
parameters O
, O
number O
of O
epochs O
, O
etc O
. O
, O
using O
a O
held O
- O
out O
validation O
set O
. O
We O
then O
take O
the O
model O
that O
performed O
best O
on O
the O
validation O
set O
and O
compute O
BLEU Metric
or O
ROUGE Metric
score Metric
on O
the O
test O
set O
. O
In O
the O
following O
sections O
we O
report O
results O
on O
the O
test O
set O
only O
. O
Greedy Task
generation Task
is O
performed O
by O
taking O
the O
most O
likely O
word O
at O
each O
time O
step O
. O
subsection O
: O
Text Task
Summarization Task
We O
consider O
the O
problem O
of O
abstractive O
summarization Task
where O
, O
given O
a O
piece O
of O
“ O
source O
” O
text O
, O
we O
aim O
at O
generating O
its O
summary O
( O
the O
“ O
target O
” O
text O
) O
such O
that O
its O
meaning O
is O
intact O
. O
The O
data O
set O
we O
use O
to O
train O
and O
evaluate O
our O
models O
consists O
of O
a O
subset O
of O
the O
Gigaword Material
corpus Material
gigaword Material
as O
described O
in O
rush O
- O
2015 O
. O
This O
is O
a O
collection O
of O
news O
articles O
taken O
from O
different O
sources O
over O
the O
past O
two O
decades O
. O
Our O
version O
is O
organized O
as O
a O
set O
of O
example O
pairs O
, O
where O
each O
pair O
is O
composed O
of O
the O
first O
sentence O
of O
a O
news O
article O
( O
the O
source O
sentence O
) O
and O
its O
corresponding O
headline O
( O
the O
target O
sentence O
) O
. O
We O
pre O
- O
process O
the O
data O
in O
the O
same O
way O
as O
in O
rush O
- O
2015 O
, O
which O
consists O
of O
lower O
- O
casing O
and O
replacing O
the O
infrequent O
words O
with O
a O
special O
token O
denoted O
by O
“ O
unk O
” O
. O
After O
pre O
- O
processing O
there O
are O
unique O
words O
in O
the O
source O
dictionary O
and O
words O
in O
the O
target O
dictionary O
. O
The O
number O
of O
sample O
pairs O
in O
the O
training O
, O
validation O
and O
test O
set O
are O
, O
, O
and O
respectively O
. O
The O
average O
sequence O
length O
of O
the O
target O
headline O
is O
about O
words O
. O
We O
considered O
sequences O
up O
to O
words O
to O
comply O
with O
our O
initial O
constraint O
of O
covering O
at O
least O
% O
of O
the O
data O
. O
Our O
generative Method
model Method
is O
a O
conditional Method
Elman Method
RNN Method
( O
Equation O
[ O
reference O
] O
) O
with O
hidden O
units O
, O
where O
the O
conditioning O
vector O
is O
provided O
by O
a O
convolutional Method
attentive Method
encoder Method
, O
similar O
to O
the O
one O
described O
in O
Section O
3.2 O
of O
rush O
- O
2015 O
and O
inspired O
by O
. O
The O
details O
of O
our O
attentive Method
encoder Method
are O
mentioned O
in O
Section O
[ O
reference O
] O
of O
the O
Supplementary O
Material O
. O
We O
also O
tried O
LSTMs Method
as O
our O
generative Method
model Method
for O
this O
task O
, O
however O
it O
did O
not O
improve O
performance O
. O
We O
conjecture O
this O
is O
due O
to O
the O
fact O
that O
the O
target O
sentences O
in O
this O
data O
set O
are O
rather O
short O
. O
subsection O
: O
Machine Task
Translation Task
For O
the O
translation Task
task Task
, O
our O
generative Method
model Method
is O
an O
LSTM Method
with Method
hidden Method
units Method
and O
it O
uses O
the O
same O
attentive Method
encoder Method
architecture Method
as O
the O
one O
used O
for O
summarization Task
. O
We O
use O
data O
from O
the O
German Material
- Material
English Material
machine Material
translation Material
track Material
of O
the O
IWSLT Material
2014 Material
evaluation Material
campaign Material
cettolo2014 O
. O
The O
corpus O
consists O
of O
sentence Material
- Material
aligned Material
subtitles Material
of Material
TED Material
and O
TEDx Material
talks Material
. O
We O
pre O
- O
process O
the O
training O
data O
using O
the O
tokenizer Method
of O
the O
Moses Method
toolkit Method
koehn2007 O
and O
remove O
sentences O
longer O
than O
words O
as O
well O
as O
casing O
. O
The O
training O
data O
comprises O
of O
about O
sentences O
where O
the O
average O
English Material
sentence Material
is O
words O
long O
and O
the O
average O
German Material
sentence Material
is O
words O
long O
. O
In O
order O
to O
retain O
at O
least O
of O
this O
data O
, O
we O
unrolled O
our O
RNN Method
for O
steps O
. O
Our O
validation O
set O
comprises O
of O
sentence O
pairs O
which O
was O
taken O
from O
the O
training O
data O
. O
The O
test O
set O
is O
a O
concatenation Material
of Material
dev2010 Material
, O
dev2012 Material
, O
tst2010 Material
, O
tst2011 Material
and O
tst2012 Material
which O
results O
in O
sentence O
pairs O
. O
The O
English Material
dictionary Material
has O
words O
while O
the O
German O
has O
words O
. O
subsection O
: O
Image Task
Captioning Task
For O
the O
image Task
captioning Task
task Task
, O
we O
use O
the O
MSCOCO Material
dataset Material
mscoco Material
. O
We O
use O
the O
entire O
training O
set O
provided O
by O
the O
authors O
, O
which O
consists O
of O
around O
k O
images O
. O
We O
then O
took O
the O
original O
validation O
set O
( O
consisting O
of O
around O
k O
images O
) O
and O
randomly O
sampled O
( O
without O
replacement O
) O
images O
for O
validation O
and O
another O
for O
test O
. O
There O
are O
different O
captions O
for O
each O
image O
. O
At O
training O
time O
we O
sample O
one O
of O
these O
captions O
, O
while O
at O
test O
time O
we O
report O
the O
maximum O
BLEU Metric
score O
across O
the O
five O
captions O
. O
The O
context O
is O
represented O
by O
1024 O
features O
extracted O
by O
a O
Convolutional Method
Neural Method
Network Method
( O
CNN Method
) O
trained O
on O
the O
Imagenet Material
dataset Material
imagenet_cvpr09 O
; O
we O
do O
not O
back O
- O
propagate O
through O
these O
features O
. O
We O
use O
a O
similar O
experimental O
set O
up O
as O
described O
in O
sbengio O
- O
nips2015 O
. O
The O
RNN Method
is O
a O
single Method
layer Method
LSTM Method
with Method
hidden Method
units Method
and O
the O
image O
features O
are O
provided O
to O
the O
generative Method
model Method
as O
the O
first O
word O
in O
the O
sequence O
. O
We O
pre O
- O
process O
the O
captions O
by O
lower O
- O
casing O
all O
words O
and O
replacing O
all O
the O
words O
which O
appear O
less O
than O
3 O
times O
with O
a O
special O
token O
“ O
unk O
” O
. O
As O
a O
result O
the O
total O
number O
of O
unique O
words O
in O
our O
dataset O
is O
. O
Keeping O
in O
mind O
the O
rule O
, O
we O
unroll O
the O
RNN Method
for O
steps O
. O
subsection O
: O
Results O
In O
order O
to O
validate O
MIXER Method
, O
we O
compute O
BLEU Metric
score O
on O
the O
machine Task
translation Task
and O
image Task
captioning Task
task Task
, O
and O
ROUGE Metric
on O
the O
summarization Task
task O
. O
The O
input O
provided O
to O
the O
system O
is O
only O
the O
context O
and O
the O
beginning O
of O
sentence O
token O
. O
We O
apply O
the O
same O
protocol O
to O
the O
baseline O
methods O
as O
well O
. O
The O
scores O
on O
the O
test O
set O
are O
reported O
in O
Figure O
[ O
reference O
] O
. O
We O
observe O
that O
MIXER Method
produces O
the O
best O
generations O
and O
improves O
generation O
over O
XENT Method
by O
to O
points O
across O
all O
the O
tasks O
. O
Unfortunately O
the O
E2E Method
approach O
did O
not O
prove O
to O
be O
very O
effective O
. O
Training O
at O
the O
sequence O
level O
and O
directly O
optimizing O
for O
testing O
score O
yields O
better O
generations O
than O
turning O
a O
sequence O
of O
discrete O
decisions O
into O
a O
differentiable Method
process Method
amenable O
to O
standard O
back Method
- Method
propagation Method
of O
the O
error O
. O
DAD Method
is O
usually O
better O
than O
the O
XENT Method
, O
but O
not O
as O
good O
as O
MIXER Method
. O
Overall O
, O
these O
experiments O
demonstrate O
the O
importance O
of O
optimizing O
for O
the O
metric O
used O
at O
test O
time O
. O
In O
summarization Task
for O
instance O
, O
XENT Method
and O
MIXER Method
trained O
with O
ROUGE Metric
achieve O
a O
poor O
performance O
in O
terms O
of O
BLEU Metric
( O
8.16 O
and O
5.80 O
versus O
9.32 O
of O
MIXER Method
trained O
with O
BLEU Metric
) O
; O
likewise O
, O
MIXER Method
trained O
with O
BLEU Metric
does O
not O
achieve O
as O
good O
ROUGE Metric
score Metric
as O
a O
MIXER Method
optimizing Method
ROUGE Metric
at O
training O
time O
as O
well O
( O
15.1 O
versus O
16.22 O
, O
see O
also O
Figure O
[ O
reference O
] O
in O
Supplementary O
Material O
) O
. O
Next O
, O
we O
experimented O
with O
beam Task
search Task
. O
The O
results O
in O
Figure O
[ O
reference O
] O
suggest O
that O
all O
methods O
, O
including O
MIXER Method
, O
improve O
the O
quality O
of O
their O
generation Task
by O
using O
beam Method
search Method
. O
However O
, O
the O
extent O
of O
the O
improvement O
is O
very O
much O
task O
dependent O
. O
We O
observe O
that O
the O
greedy O
performance O
of O
MIXER Method
( O
i.e. O
, O
without O
beam Method
search Method
) O
can O
not O
be O
matched O
by O
baselines O
using O
beam Method
search Method
in O
two O
out O
of O
the O
three O
tasks O
. O
Moreover O
, O
MIXER Method
is O
several O
times O
faster O
since O
it O
relies O
only O
on O
greedy Method
search Method
. O
It O
is O
worth O
mentioning O
that O
the O
REINFORCE Method
baseline Method
did O
not O
work O
for O
these O
applications O
. O
Exploration Task
from O
a O
random Method
policy Method
has O
little O
chance O
of O
success O
. O
We O
do O
not O
report O
it O
since O
we O
were O
never O
able O
to O
make O
it O
converge O
within O
a O
reasonable O
amount O
of O
time O
. O
Using O
the O
hybrid O
XENT Method
- O
REINFORCE O
loss O
without O
incremental Method
learning Method
is O
also O
insufficient O
to O
make O
training O
take O
off O
from O
random O
chance O
. O
In O
order O
to O
gain O
some O
insight O
on O
what O
kind O
of O
schedule O
works O
, O
we O
report O
in O
Table O
[ O
reference O
] O
of O
Supplementary O
Material O
the O
best O
values O
we O
found O
after O
grid Method
search Method
over O
the O
hyper O
- O
parameters O
of O
MIXER Method
. O
Finally O
, O
we O
report O
some O
anecdotal O
examples O
of O
MIXER Method
generation O
in O
Figure O
[ O
reference O
] O
of O
Supplementary O
Material O
. O
section O
: O
Conclusions O
Our O
work O
is O
motivated O
by O
two O
major O
deficiencies O
in O
training O
the O
current O
generative Method
models Method
for O
text Task
generation Task
: O
exposure O
bias O
and O
a O
loss Method
which O
does O
not O
operate O
at O
the O
sequence O
level O
. O
While O
Reinforcement Method
learning Method
can O
potentially O
address O
these O
issues O
, O
it O
struggles O
in O
settings O
when O
there O
are O
very O
large O
action O
spaces O
, O
such O
as O
in O
text Task
generation Task
. O
Towards O
that O
end O
, O
we O
propose O
the O
MIXER Method
algorithm O
, O
which O
deals O
with O
these O
issues O
and O
enables O
successful O
training O
of O
reinforcement Method
learning Method
models Method
for O
text Task
generation Task
. O
We O
achieve O
this O
by O
replacing O
the O
initial O
random Method
policy Method
with O
the O
optimal Method
policy Method
of O
a O
cross Method
- Method
entropy Method
trained Method
model Method
and O
by O
gradually O
exposing O
the O
model O
more O
and O
more O
to O
its O
own O
predictions O
in O
an O
incremental Method
learning Method
framework Method
. O
Our O
results O
show O
that O
MIXER Method
outperforms O
three O
strong O
baselines O
for O
greedy Task
generation Task
and O
it O
is O
very O
competitive O
with O
beam Method
search Method
. O
The O
approach O
we O
propose O
is O
agnostic O
to O
the O
underlying O
model O
or O
the O
form O
of O
the O
reward O
function O
. O
In O
future O
work O
we O
would O
like O
to O
design O
better O
estimation Method
techniques Method
for O
the O
average O
reward O
, O
because O
poor O
estimates O
can O
lead O
to O
slow O
convergence O
of O
both O
REINFORCE O
and O
MIXER Method
. O
Finally O
, O
our O
training Method
algorithm Method
relies O
on O
a O
single O
sample O
while O
it O
would O
be O
interesting O
to O
investigate O
the O
effect O
of O
more O
comprehensive O
search Method
methods Method
at O
training O
time O
. O
subsubsection O
: O
Acknowledgments O
The O
authors O
would O
like O
to O
thank O
David O
Grangier O
, O
Tomas O
Mikolov O
, O
Leon O
Bottou O
, O
Ronan O
Collobert O
and O
Laurens O
van O
der O
Maaten O
for O
their O
insightful O
comments O
. O
We O
also O
would O
like O
to O
thank O
Alexander O
M. O
Rush O
for O
his O
help O
in O
preparing O
the O
data O
set O
for O
the O
summarization Task
task O
and O
Sam O
Gross O
for O
providing O
the O
image O
features O
. O
bibliography O
: O
References O
section O
: O
Supplementary O
Material O
subsection O
: O
Experiments O
subsubsection O
: O
Qualitative Metric
Comparison Metric
subsubsection O
: O
Hyperparameters O
subsubsection O
: O
Relative O
Gains O
Training O
with O
exposure O
bias O
Training O
in O
expectation O
( O
Reinforce O
) O
subsection O
: O
The O
Attentive Method
Encoder Method
Here O
we O
explain O
in O
detail O
how O
we O
generate O
the O
conditioning O
vector O
for O
our O
RNN Method
using O
the O
source O
sentence O
and O
the O
current O
hidden O
state O
. O
Let O
us O
denote O
by O
the O
source O
sentence O
which O
is O
composed O
of O
a O
sequence O
of O
words O
. O
With O
a O
slight O
overload O
of O
notation O
let O
also O
denote O
the O
dimensional Method
learnable Method
embedding Method
of O
the O
- O
th O
word O
( O
) O
. O
In O
addition O
the O
position O
of O
the O
word O
is O
also O
associated O
with O
a O
learnable O
embedding O
of O
size O
( O
) O
. O
Then O
the O
full O
embedding O
for O
the O
- O
th O
word O
in O
the O
input O
sentence O
is O
given O
by O
. O
In O
order O
for O
the O
embeddings O
to O
capture O
local O
context O
, O
we O
associate O
an O
aggregate Method
embedding Method
to O
each O
word O
in O
the O
source O
sentence O
. O
In O
particular O
for O
a O
word O
in O
the O
- O
th O
position O
, O
its O
aggregate Method
embedding Method
is O
computed O
by O
taking O
a O
window O
of O
consecutive O
words O
centered O
at O
position O
and O
averaging O
the O
embeddings O
of O
all O
the O
words O
in O
this O
window O
. O
More O
precisely O
, O
the O
aggregate Method
embedding Method
is O
given O
by O
: O
In O
our O
experiments O
the O
width O
was O
set O
to O
. O
In O
order O
to O
account O
for O
the O
words O
at O
the O
two O
boundaries O
of O
the O
input O
sentence O
we O
first O
pad O
the O
sequence O
on O
both O
sides O
with O
dummy O
words O
before O
computing O
the O
aggregate Method
vectors Method
s. O
Given O
these O
aggregate O
vectors O
of O
words O
, O
we O
compute O
the O
context O
vector O
( O
the O
final O
output O
of O
the O
encoder Method
) O
as O
: O
where O
the O
weights O
are O
computed O
as O
subsection O
: O
Beam Method
Search Method
Algorithm Method
Equation O
[ O
reference O
] O
always O
chooses O
the O
highest O
scoring O
next O
word O
candidate O
at O
each O
time O
step O
. O
At O
test O
time O
we O
can O
reduce O
the O
effect O
of O
search Metric
error Metric
by O
pursuing O
not O
only O
one O
but O
next O
word O
candidates O
at O
each O
point O
, O
which O
is O
commonly O
known O
as O
beam Method
search Method
. O
While O
still O
approximate O
, O
this O
strategy O
can O
recover O
higher O
scoring O
sequences O
that O
are O
often O
also O
better O
in O
terms O
of O
our O
final O
evaluation Metric
metric Metric
. O
The O
algorithm O
maintains O
the O
highest O
scoring O
partial O
sequences O
, O
where O
is O
a O
hyper O
- O
parameter O
. O
Setting O
reduces O
the O
algorithm O
to O
a O
greedy Task
left Task
- Task
to Task
- Task
right Task
search Task
( O
Eq O
. O
( O
[ O
reference O
] O
) O
) O
. O
[ O
! O
h O
] O
model O
, O
beam O
size O
sequence O
of O
words O
empty O
heaps O
an O
empty O
hidden O
state O
vector O
- O
most O
likely O
words O
from O
Pseudo O
- O
code O
of O
beam Method
search Method
with O
beam O
size O
k. O
subsection O
: O
Notes O
The O
current O
version O
of O
the O
paper O
updates O
the O
first O
version O
uploaded O
on O
arXiv O
as O
follows O
: O
on O
the O
summarization Task
task O
, O
we O
report O
results O
using O
both O
ROUGE Metric
- Metric
2 Metric
and O
BLEU Metric
to O
demonstrate O
that O
MIXER Method
can O
work O
with O
any O
metric O
. O
on O
machine Task
translation Task
and O
image Task
captioning Task
we O
use O
LSTM Method
instead O
of O
Elman Method
RNN Method
to O
demonstrate O
the O
MIXER Method
can O
work O
with O
any O
underlying O
parametric Method
model Method
. O
BLEU Metric
is O
evaluated O
using O
up O
to O
4 O
- O
grams O
, O
and O
it O
is O
computed O
at O
the O
corpus Metric
level Metric
( O
except O
in O
the O
image Task
captioning Task
case Task
) O
as O
this O
seems O
the O
most O
common O
practice O
in O
the O
summarization Task
and O
machine Task
translation Task
literature Task
. O
we O
have O
added O
several O
references O
as O
suggested O
by O
our O
reviewers O
we O
have O
shortened O
the O
paper O
by O
moving O
some O
content O
to O
the O
Supplementary O
Material O
. O
