document	O
:	O
Diverse	O
Image	Task
-	Task
to	Task
-	Task
Image	Task
Translation	Task
via	O
Disentangled	Method
Representations	Method
Image	Task
-	Task
to	Task
-	Task
image	Task
translation	Task
aims	O
to	O
learn	O
the	O
mapping	Task
between	Task
two	Task
visual	Task
domains	Task
.	O
There	O
are	O
two	O
main	O
challenges	O
for	O
many	O
applications	O
:	O
1	O
)	O
the	O
lack	O
of	O
aligned	O
training	O
pairs	O
and	O
2	O
)	O
multiple	O
possible	O
outputs	O
from	O
a	O
single	O
input	O
image	O
.	O
In	O
this	O
work	O
,	O
we	O
present	O
an	O
approach	O
based	O
on	O
disentangled	Method
representation	Method
for	O
producing	O
diverse	O
outputs	O
without	O
paired	O
training	O
images	O
.	O
To	O
achieve	O
diversity	O
,	O
we	O
propose	O
to	O
embed	O
images	O
onto	O
two	O
spaces	O
:	O
a	O
domain	O
-	O
invariant	O
content	O
space	O
capturing	O
shared	O
information	O
across	O
domains	O
and	O
a	O
domain	O
-	O
specific	O
attribute	O
space	O
.	O
Our	O
model	O
takes	O
the	O
encoded	O
content	O
features	O
extracted	O
from	O
a	O
given	O
input	O
and	O
the	O
attribute	O
vectors	O
sampled	O
from	O
the	O
attribute	O
space	O
to	O
produce	O
diverse	O
outputs	O
at	O
test	O
time	O
.	O
To	O
handle	O
unpaired	O
training	O
data	O
,	O
we	O
introduce	O
a	O
novel	O
cross	Method
-	Method
cycle	Method
consistency	Method
loss	Method
based	O
on	O
disentangled	Method
representations	Method
.	O
Qualitative	O
results	O
show	O
that	O
our	O
model	O
can	O
generate	O
diverse	O
and	O
realistic	O
images	O
on	O
a	O
wide	O
range	O
of	O
tasks	O
without	O
paired	O
training	O
data	O
.	O
For	O
quantitative	O
comparisons	O
,	O
we	O
measure	O
realism	Metric
with	O
user	O
study	O
and	O
diversity	Metric
with	O
a	O
perceptual	Metric
distance	Metric
metric	Metric
.	O
We	O
apply	O
the	O
proposed	O
model	O
to	O
domain	Method
adaptation	Method
and	O
show	O
competitive	O
performance	O
when	O
compared	O
to	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
on	O
the	O
MNIST	Material
-	Material
M	Material
and	O
the	O
LineMod	Material
datasets	Material
.	O
Photo	O
to	O
van	O
Gogh	O
Winter	O
to	O
summer	O
Photograph	O
to	O
portrait	O
Content	O
Attribute	O
Generated	O
Input	O
Output	O
Input	O
Output	O
[	O
CycleGAN	Method
]	O
[	O
UNIT	O
]	O
[	O
Ours	O
]	O
section	O
:	O
Introduction	O
Image	Task
-	Task
to	Task
-	Task
Image	Task
(	O
I2I	Task
)	O
translation	Task
aims	O
to	O
learn	O
the	O
mapping	O
between	O
different	O
visual	O
domains	O
.	O
Many	O
vision	Task
and	Task
graphics	Task
problems	Task
can	O
be	O
formulated	O
as	O
I2I	Task
translation	Task
problems	Task
,	O
such	O
as	O
colorization	O
(	O
grayscale	O
color	O
)	O
,	O
super	Task
-	Task
resolution	Task
(	O
low	Task
-	Task
resolution	Task
high	Task
-	Task
resolution	Task
)	O
,	O
and	O
photorealistic	Task
image	Task
synthesis	Task
(	O
label	Task
image	Task
)	O
.	O
Furthermore	O
,	O
I2I	Task
translation	Task
has	O
recently	O
shown	O
promising	O
results	O
in	O
facilitating	O
domain	Method
adaptation	Method
.	O
Learning	O
the	O
mapping	Task
between	Task
two	Task
visual	Task
domains	Task
is	O
challenging	O
for	O
two	O
main	O
reasons	O
.	O
First	O
,	O
aligned	O
training	O
image	O
pairs	O
are	O
either	O
difficult	O
to	O
collect	O
(	O
e.g.	O
,	O
day	O
scene	O
night	O
scene	O
)	O
or	O
do	O
not	O
exist	O
(	O
e.g.	O
,	O
artwork	O
real	O
photo	O
)	O
.	O
Second	O
,	O
many	O
such	O
mappings	O
are	O
inherently	O
multimodal	O
—	O
a	O
single	O
input	O
may	O
correspond	O
to	O
multiple	O
possible	O
outputs	O
.	O
To	O
handle	O
multimodal	O
translation	Task
,	O
one	O
possible	O
approach	O
is	O
to	O
inject	O
a	O
random	O
noise	O
vector	O
to	O
the	O
generator	O
for	O
modeling	O
the	O
data	Task
distribution	Task
in	O
the	O
target	O
domain	O
.	O
However	O
,	O
mode	Task
collapse	Task
may	O
still	O
occur	O
easily	O
since	O
the	O
generator	Method
often	O
ignores	O
the	O
additional	O
noise	O
vectors	O
.	O
Several	O
recent	O
efforts	O
have	O
been	O
made	O
to	O
address	O
these	O
issues	O
.	O
Pix2pix	Method
applies	O
conditional	Method
generative	Method
adversarial	Method
network	Method
to	O
I2I	Task
translation	Task
problems	Task
.	O
Nevertheless	O
,	O
the	O
training	Method
process	Method
requires	O
paired	O
data	O
.	O
A	O
number	O
of	O
recent	O
work	O
relaxes	O
the	O
dependency	O
on	O
paired	O
training	O
data	O
for	O
learning	O
I2I	Task
translation	Task
.	O
These	O
methods	O
,	O
however	O
,	O
produce	O
a	O
single	O
output	O
conditioned	O
on	O
the	O
given	O
input	O
image	O
.	O
As	O
shown	O
in	O
,	O
simply	O
incorporating	O
noise	O
vectors	O
as	O
additional	O
inputs	O
to	O
the	O
generator	Method
does	O
not	O
lead	O
the	O
increased	O
variations	O
of	O
the	O
generated	O
outputs	O
due	O
to	O
the	O
mode	Task
collapsing	Task
issue	Task
.	O
The	O
generators	O
in	O
these	O
methods	O
are	O
inclined	O
to	O
overlook	O
the	O
added	O
noise	O
vectors	O
.	O
Very	O
recently	O
,	O
BicycleGAN	Method
tackles	O
the	O
problem	O
of	O
generating	O
diverse	O
outputs	O
in	O
I2I	Task
problems	Task
by	O
encouraging	O
the	O
one	O
-	O
to	O
-	O
one	O
relationship	O
between	O
the	O
output	O
and	O
the	O
latent	O
vector	O
.	O
Nevertheless	O
,	O
the	O
training	Method
process	Method
of	O
BicycleGAN	Task
requires	O
paired	O
images	O
.	O
In	O
this	O
paper	O
,	O
we	O
propose	O
a	O
disentangled	Method
representation	Method
framework	Method
for	O
learning	Task
to	O
generate	O
diverse	O
outputs	O
with	O
unpaired	O
training	O
data	O
.	O
Specifically	O
,	O
we	O
propose	O
to	O
embed	O
images	O
onto	O
two	O
spaces	O
:	O
1	O
)	O
a	O
domain	Method
-	Method
invariant	Method
content	Method
space	Method
and	O
2	O
)	O
a	O
domain	O
-	O
specific	O
attribute	O
space	O
as	O
shown	O
in	O
Figure	O
[	O
reference	O
]	O
.	O
Our	O
generator	Method
learns	O
to	O
perform	O
I2I	Task
translation	Task
conditioned	O
on	O
content	O
features	O
and	O
a	O
latent	O
attribute	O
vector	O
.	O
The	O
domain	O
-	O
specific	O
attribute	O
space	O
aims	O
to	O
model	O
the	O
variations	O
within	O
a	O
domain	O
given	O
the	O
same	O
content	O
,	O
while	O
the	O
domain	O
-	O
invariant	O
content	O
space	O
captures	O
information	O
across	O
domains	O
.	O
We	O
achieve	O
this	O
representation	O
disentanglement	O
by	O
applying	O
a	O
content	Method
adversarial	Method
loss	Method
to	O
encourage	O
the	O
content	O
features	O
not	O
to	O
carry	O
domain	O
-	O
specific	O
cues	O
,	O
and	O
a	O
latent	Method
regression	Method
loss	Method
to	O
encourage	O
the	O
invertible	O
mapping	O
between	O
the	O
latent	O
attribute	O
vectors	O
and	O
the	O
corresponding	O
outputs	O
.	O
To	O
handle	O
unpaired	O
datasets	O
,	O
we	O
propose	O
a	O
cross	Method
-	Method
cycle	Method
consistency	Method
loss	Method
using	O
the	O
disentangled	Method
representations	Method
.	O
Given	O
a	O
pair	O
of	O
unaligned	O
images	O
,	O
we	O
first	O
perform	O
a	O
cross	Method
-	Method
domain	Method
mapping	Method
to	O
obtain	O
intermediate	O
results	O
by	O
swapping	O
the	O
attribute	O
vectors	O
from	O
both	O
images	O
.	O
We	O
can	O
then	O
reconstruct	O
the	O
original	O
input	O
image	O
pair	O
by	O
applying	O
the	O
cross	Method
-	Method
domain	Method
mapping	Method
one	O
more	O
time	O
and	O
use	O
the	O
proposed	O
cross	O
-	O
cycle	O
consistency	O
loss	O
to	O
enforce	O
the	O
consistency	O
between	O
the	O
original	O
and	O
the	O
reconstructed	O
images	O
.	O
At	O
test	O
time	O
,	O
we	O
can	O
use	O
either	O
1	O
)	O
randomly	O
sampled	O
vectors	O
from	O
the	O
attribute	O
space	O
to	O
generate	O
diverse	O
outputs	O
or	O
2	O
)	O
the	O
transferred	O
attribute	O
vectors	O
extracted	O
from	O
existing	O
images	O
for	O
example	O
-	O
guided	O
translation	Task
.	O
Figure	O
[	O
reference	O
]	O
shows	O
examples	O
of	O
the	O
two	O
testing	O
modes	O
.	O
We	O
evaluate	O
the	O
proposed	O
model	O
through	O
extensive	O
qualitative	Metric
and	Metric
quantitative	Metric
evaluation	Metric
.	O
In	O
a	O
wide	O
variety	O
of	O
I2I	Task
tasks	Task
,	O
we	O
show	O
diverse	O
translation	Task
results	O
with	O
randomly	O
sampled	O
attribute	O
vectors	O
and	O
example	O
-	O
guided	O
translation	Task
with	O
transferred	O
attribute	O
vectors	O
from	O
existing	O
images	O
.	O
We	O
evaluate	O
the	O
realism	O
of	O
our	O
results	O
with	O
a	O
user	O
study	O
and	O
the	O
diversity	Metric
using	O
perceptual	Metric
distance	Metric
metrics	Metric
.	O
Furthermore	O
,	O
we	O
demonstrate	O
the	O
potential	O
application	O
of	O
unsupervised	Method
domain	Method
adaptation	Method
.	O
On	O
the	O
tasks	O
of	O
adapting	Task
domains	Task
from	O
MNIST	Material
to	O
MNIST	Material
-	Material
M	Material
and	O
Synthetic	Material
Cropped	Material
LineMod	Material
to	O
Cropped	Material
LineMod	Material
,	O
we	O
show	O
competitive	O
performance	O
against	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
domain	Method
adaptation	Method
methods	O
.	O
We	O
make	O
the	O
following	O
contributions	O
:	O
1	O
)	O
We	O
introduce	O
a	O
disentangled	Method
representation	Method
framework	Method
for	O
image	O
-	O
to	O
-	O
image	O
translation	Task
.	O
We	O
apply	O
a	O
content	Method
discriminator	Method
to	O
facilitate	O
the	O
factorization	Task
of	Task
domain	Task
-	Task
invariant	Task
content	Task
space	Task
and	O
domain	O
-	O
specific	O
attribute	O
space	O
,	O
and	O
a	O
cross	Metric
-	Metric
cycle	Metric
consistency	Metric
loss	Metric
that	O
allows	O
us	O
to	O
train	O
the	O
model	O
with	O
unpaired	O
data	O
.	O
2	O
)	O
Extensive	O
qualitative	O
and	O
quantitative	O
experiments	O
show	O
that	O
our	O
model	O
compares	O
favorably	O
against	O
existing	O
I2I	Task
models	O
.	O
Images	O
generated	O
by	O
our	O
model	O
are	O
both	O
diverse	O
and	O
realistic	O
.	O
3	O
)	O
We	O
demonstrate	O
the	O
application	O
of	O
our	O
model	O
on	O
unsupervised	Method
domain	Method
adaptation	Method
.	O
We	O
achieve	O
competitive	O
results	O
on	O
both	O
the	O
MNIST	Material
-	Material
M	Material
and	O
the	O
Cropped	Material
LineMod	Material
datasets	Material
.	O
Our	O
code	O
,	O
data	O
and	O
more	O
results	O
are	O
available	O
at	O
.	O
section	O
:	O
Related	O
Work	O
Generative	Method
adversarial	Method
networks	Method
.	O
Recent	O
years	O
have	O
witnessed	O
rapid	O
progress	O
on	O
generative	Method
adversarial	Method
networks	Method
(	O
GANs	Method
)	O
for	O
image	Task
generation	Task
.	O
The	O
core	O
idea	O
of	O
GANs	Method
lies	O
in	O
the	O
adversarial	Method
loss	Method
that	O
enforces	O
the	O
distribution	O
of	O
generated	O
images	O
to	O
match	O
that	O
of	O
the	O
target	O
domain	O
.	O
The	O
generators	Method
in	O
GANs	Method
can	O
map	O
from	O
noise	O
vectors	O
to	O
realistic	O
images	O
.	O
Several	O
recent	O
efforts	O
explore	O
conditional	Method
GAN	Method
in	O
various	O
contexts	O
including	O
conditioned	O
on	O
text	O
,	O
low	O
-	O
resolution	O
images	O
,	O
video	O
frames	O
,	O
and	O
image	O
.	O
Our	O
work	O
focuses	O
on	O
using	O
GAN	Method
conditioned	O
on	O
an	O
input	O
image	O
.	O
In	O
contrast	O
to	O
several	O
existing	O
conditional	Method
GAN	Method
frameworks	Method
that	O
require	O
paired	O
training	O
data	O
,	O
our	O
model	O
produces	O
diverse	O
outputs	O
without	O
paired	O
data	O
.	O
This	O
suggests	O
that	O
our	O
method	O
has	O
wider	O
applicability	O
to	O
problems	O
where	O
paired	O
training	O
datasets	O
are	O
scarce	O
or	O
not	O
available	O
.	O
Image	Task
-	Task
to	Task
-	Task
image	Task
translation	Task
.	O
I2I	Task
translation	Task
aims	O
to	O
learn	O
the	O
mapping	O
from	O
a	O
source	O
image	O
domain	O
to	O
a	O
target	O
image	O
domain	O
.	O
Pix2pix	Method
applies	O
a	O
conditional	Method
GAN	Method
to	O
model	O
the	O
mapping	O
function	O
.	O
Although	O
high	O
-	O
quality	O
results	O
have	O
been	O
shown	O
,	O
the	O
model	Method
training	Method
requires	O
paired	O
training	O
data	O
.	O
To	O
train	O
with	O
unpaired	O
data	O
,	O
CycleGAN	Method
,	O
DiscoGAN	Method
,	O
and	O
UNIT	Method
leverage	O
cycle	Method
consistency	Method
to	O
regularize	O
the	O
training	O
.	O
However	O
,	O
these	O
methods	O
perform	O
generation	Task
conditioned	O
solely	O
on	O
an	O
input	O
image	O
and	O
thus	O
produce	O
one	O
single	O
output	O
.	O
Simply	O
injecting	O
a	O
noise	O
vector	O
to	O
a	O
generator	Method
is	O
usually	O
not	O
an	O
effective	O
solution	O
to	O
achieve	O
multimodal	Task
generation	Task
due	O
to	O
the	O
lack	O
of	O
regularization	O
between	O
the	O
noise	O
vectors	O
and	O
the	O
target	O
domain	O
.	O
On	O
the	O
other	O
hand	O
,	O
BicycleGAN	O
enforces	O
the	O
bijection	O
mapping	O
between	O
the	O
latent	O
and	O
target	O
space	O
to	O
tackle	O
the	O
mode	Task
collapse	Task
problem	Task
.	O
Nevertheless	O
,	O
the	O
method	O
is	O
only	O
applicable	O
to	O
problems	O
with	O
paired	O
training	O
data	O
.	O
Table	O
[	O
reference	O
]	O
shows	O
a	O
feature	O
-	O
by	O
-	O
feature	Metric
comparison	Metric
among	O
various	O
I2I	Task
models	O
.	O
Unlike	O
existing	O
work	O
,	O
our	O
method	O
enables	O
I2I	Task
translation	Task
with	O
diverse	O
outputs	O
in	O
the	O
absence	O
of	O
paired	O
training	O
data	O
.	O
Very	O
recently	O
,	O
several	O
concurrent	O
works	O
(	O
all	O
independently	O
developed	O
)	O
also	O
adopt	O
a	O
disentangled	Method
representation	Method
similar	O
to	O
our	O
work	O
for	O
learning	O
diverse	O
I2I	Task
translation	Task
from	O
unpaired	O
training	O
data	O
.	O
We	O
encourage	O
the	O
readers	O
to	O
review	O
these	O
works	O
for	O
a	O
complete	O
picture	O
.	O
Disentangled	Method
representations	Method
.	O
The	O
task	O
of	O
learning	Task
disentangled	Task
representation	Task
aims	O
at	O
modeling	O
the	O
factors	O
of	O
data	O
variations	O
.	O
Previous	O
work	O
makes	O
use	O
of	O
labeled	O
data	O
to	O
factorize	O
representations	O
into	O
class	Method
-	Method
related	Method
and	Method
class	Method
-	Method
independent	Method
components	Method
.	O
Recently	O
,	O
the	O
unsupervised	Task
setting	Task
has	O
been	O
explored	O
.	O
InfoGAN	Method
achieves	O
disentanglement	O
by	O
maximizing	O
the	O
mutual	O
information	O
between	O
latent	O
variables	O
and	O
data	O
variation	O
.	O
Similar	O
to	O
DrNet	Method
that	O
separates	O
time	O
-	O
independent	O
and	O
time	O
-	O
varying	O
components	O
with	O
an	O
adversarial	Method
loss	Method
,	O
we	O
apply	O
a	O
content	Method
adversarial	Method
loss	Method
to	O
disentangle	O
an	O
image	O
into	O
domain	O
-	O
invariant	O
and	O
domain	O
-	O
specific	O
representations	O
to	O
facilitate	O
learning	O
diverse	Task
cross	Task
-	Task
domain	Task
mappings	Task
.	O
Domain	Method
adaptation	Method
.	O
Domain	Method
adaptation	Method
techniques	Method
focus	O
on	O
addressing	O
the	O
domain	Task
-	Task
shift	Task
problem	Task
between	O
a	O
source	O
and	O
a	O
target	O
domain	O
.	O
Domain	Method
Adversarial	Method
Neural	Method
Network	Method
(	O
DANN	Method
)	O
and	O
its	O
variants	O
tackle	O
domain	Method
adaptation	Method
through	O
learning	O
domain	O
-	O
invariant	O
features	O
.	O
Sun	O
et	O
al	O
.	O
aims	O
to	O
map	O
features	O
in	O
the	O
source	O
domain	O
to	O
those	O
in	O
the	O
target	O
domain	O
.	O
I2I	Task
translation	Task
has	O
been	O
recently	O
applied	O
to	O
produce	O
simulated	O
images	O
in	O
the	O
target	O
domain	O
by	O
translating	O
images	O
from	O
the	O
source	O
domain	O
.	O
Different	O
from	O
the	O
aforementioned	O
I2I	Task
based	O
domain	Method
adaptation	Method
algorithms	O
,	O
our	O
method	O
does	O
not	O
utilize	O
source	O
domain	O
annotations	O
for	O
I2I	Task
translation	Task
.	O
[	O
Training	O
with	O
unpaired	O
images	O
]	O
[	O
Testing	O
with	O
random	O
attributes	O
]	O
[	O
Testing	O
with	O
a	O
given	O
attribute	O
]	O
section	O
:	O
Disentangled	Method
Representation	Method
for	O
I2I	Task
Translation	O
Our	O
goal	O
is	O
to	O
learn	O
a	O
multimodal	Task
mapping	Task
between	O
two	O
visual	O
domains	O
and	O
without	O
paired	O
training	O
data	O
.	O
As	O
illustrated	O
in	O
Figure	O
[	O
reference	O
]	O
,	O
our	O
framework	O
consists	O
of	O
content	Method
encoders	Method
,	O
attribute	Method
encoders	Method
,	O
generators	Method
,	O
and	O
domain	Method
discriminators	Method
for	O
both	O
domains	O
,	O
and	O
a	O
content	Method
discriminators	Method
.	O
Take	O
domain	O
as	O
an	O
example	O
,	O
the	O
content	Method
encoder	Method
maps	O
images	O
onto	O
a	O
shared	O
,	O
domain	O
-	O
invariant	O
content	O
space	O
(	O
)	O
and	O
the	O
attribute	Method
encoder	Method
maps	O
images	O
onto	O
a	O
domain	O
-	O
specific	O
attribute	O
space	O
(	O
)	O
.	O
The	O
generator	O
generates	O
images	O
conditioned	O
on	O
both	O
content	O
and	O
attribute	O
vectors	O
(	O
)	O
.	O
The	O
discriminator	Method
aims	O
to	O
discriminate	O
between	O
real	O
images	O
and	O
translated	O
images	O
in	O
the	O
domain	O
.	O
Content	Method
discriminator	Method
is	O
trained	O
to	O
distinguish	O
the	O
extracted	O
content	O
representations	O
between	O
two	O
domains	O
.	O
To	O
enable	O
multimodal	Task
generation	Task
at	O
test	O
time	O
,	O
we	O
regularize	O
the	O
attribute	O
vectors	O
so	O
that	O
they	O
can	O
be	O
drawn	O
from	O
a	O
prior	Method
Gaussian	Method
distribution	Method
.	O
In	O
this	O
section	O
,	O
we	O
first	O
discuss	O
the	O
strategies	O
used	O
to	O
disentangle	O
the	O
content	O
and	O
attribute	O
representations	O
in	O
Section	O
[	O
reference	O
]	O
and	O
then	O
introduce	O
the	O
proposed	O
cross	Method
-	Method
cycle	Method
consistency	Method
loss	Method
that	O
enables	O
the	O
training	O
on	O
unpaired	O
data	O
in	O
Section	O
[	O
reference	O
]	O
.	O
Finally	O
,	O
we	O
detail	O
the	O
loss	Method
functions	Method
in	O
Section	O
[	O
reference	O
]	O
.	O
subsection	O
:	O
Disentangle	O
Content	O
and	O
Attribute	Method
Representations	Method
Our	O
approach	O
embeds	O
input	O
images	O
onto	O
a	O
shared	O
content	O
space	O
,	O
and	O
domain	O
-	O
specific	O
attribute	O
spaces	O
,	O
and	O
.	O
Intuitively	O
,	O
the	O
content	Method
encoders	Method
should	O
encode	O
the	O
common	O
information	O
that	O
is	O
shared	O
between	O
domains	O
onto	O
,	O
while	O
the	O
attribute	Method
encoders	Method
should	O
map	O
the	O
remaining	O
domain	O
-	O
specific	O
information	O
onto	O
and	O
.	O
To	O
achieve	O
representation	Task
disentanglement	Task
,	O
we	O
apply	O
two	O
strategies	O
:	O
weight	Method
-	Method
sharing	Method
and	O
a	O
content	Method
discriminator	Method
.	O
First	O
,	O
similar	O
to	O
,	O
based	O
on	O
the	O
assumption	O
that	O
two	O
domains	O
share	O
a	O
common	O
latent	O
space	O
,	O
we	O
share	O
the	O
weight	O
between	O
the	O
last	O
layer	O
of	O
and	O
and	O
the	O
first	O
layer	O
of	O
and	O
.	O
Through	O
weight	Method
sharing	Method
,	O
we	O
force	O
the	O
content	Method
representation	Method
to	O
be	O
mapped	O
onto	O
the	O
same	O
space	O
.	O
However	O
,	O
sharing	O
the	O
same	O
high	O
-	O
level	O
mapping	O
functions	O
can	O
not	O
guarantee	O
the	O
same	O
content	Method
representations	Method
encode	O
the	O
same	O
information	O
for	O
both	O
domains	O
.	O
Therefore	O
,	O
we	O
propose	O
a	O
content	Method
discriminator	Method
which	O
aims	O
to	O
distinguish	O
the	O
domain	O
membership	O
of	O
the	O
encoded	O
content	O
features	O
and	O
.	O
On	O
the	O
other	O
hand	O
,	O
content	Method
encoders	Method
learn	O
to	O
produce	O
encoded	O
content	O
representations	O
whose	O
domain	O
membership	O
can	O
not	O
be	O
distinguished	O
by	O
the	O
content	Method
discriminator	Method
.	O
We	O
express	O
this	O
content	O
adversarial	O
loss	O
as	O
:	O
subsection	O
:	O
Cross	Metric
-	Metric
cycle	Metric
Consistency	Metric
Loss	Metric
With	O
the	O
disentangled	Method
representation	Method
where	O
the	O
content	O
space	O
is	O
shared	O
among	O
domains	O
and	O
the	O
attribute	O
space	O
encodes	O
intra	O
-	O
domain	O
variations	O
,	O
we	O
can	O
perform	O
I2I	Task
translation	Task
by	O
combining	O
a	O
content	Method
representation	Method
from	O
an	O
arbitrary	O
image	O
and	O
an	O
attribute	Method
representation	Method
from	O
an	O
image	O
of	O
the	O
target	O
domain	O
.	O
We	O
leverage	O
this	O
property	O
and	O
propose	O
a	O
cross	Method
-	Method
cycle	Method
consistency	Method
.	O
In	O
contrast	O
to	O
cycle	O
consistency	O
constraint	O
in	O
(	O
i.e.	O
,	O
)	O
which	O
assumes	O
one	O
-	O
to	O
-	O
one	O
mapping	O
between	O
the	O
two	O
domains	O
,	O
the	O
proposed	O
cross	Method
-	Method
cycle	Method
constraint	Method
exploit	O
the	O
disentangled	Method
content	Method
and	Method
attribute	Method
representations	Method
for	O
cyclic	Task
reconstruction	Task
.	O
Our	O
cross	O
-	O
cycle	O
constraint	O
consists	O
of	O
two	O
stages	O
of	O
I2I	Task
translation	Task
.	O
Forward	O
translation	Task
.	O
Given	O
a	O
non	O
-	O
corresponding	O
pair	O
of	O
images	O
and	O
,	O
we	O
encode	O
them	O
into	O
and	O
.	O
We	O
then	O
perform	O
the	O
first	O
translation	Task
by	O
swapping	O
the	O
attribute	Method
representation	Method
(	O
i.e.	O
,	O
and	O
)	O
to	O
generate	O
,	O
where	O
.	O
Backward	O
translation	Task
.	O
After	O
encoding	O
and	O
into	O
and	O
,	O
we	O
perform	O
the	O
second	O
translation	Task
by	O
once	O
again	O
swapping	O
the	O
attribute	Method
representation	Method
(	O
i.e.	O
,	O
and	O
)	O
.	O
Here	O
,	O
after	O
two	O
I2I	Task
translation	Task
stages	O
,	O
the	O
translation	Task
should	O
reconstruct	O
the	O
original	O
images	O
and	O
(	O
as	O
illustrated	O
in	O
Figure	O
[	O
reference	O
]	O
)	O
.	O
To	O
enforce	O
this	O
constraint	O
,	O
we	O
formulate	O
the	O
cross	Metric
-	Metric
cycle	Metric
consistency	Metric
loss	Metric
as	O
:	O
where	O
and	O
.	O
subsection	O
:	O
Other	O
Loss	Method
Functions	Method
Other	O
than	O
the	O
proposed	O
content	Method
adversarial	Method
loss	Method
and	O
cross	Method
-	Method
cycle	Method
consistency	Method
loss	Method
,	O
we	O
also	O
use	O
several	O
other	O
loss	Method
functions	Method
to	O
facilitate	O
network	Task
training	Task
.	O
We	O
illustrate	O
these	O
additional	O
losses	O
in	O
Figure	O
[	O
reference	O
]	O
.	O
Starting	O
from	O
the	O
top	O
-	O
right	O
,	O
in	O
the	O
counter	O
-	O
clockwise	O
order	O
:	O
Domain	O
adversarial	O
loss	O
.	O
We	O
impose	O
adversarial	O
loss	O
where	O
and	O
attempt	O
to	O
discriminate	O
between	O
real	O
images	O
and	O
generated	O
images	O
in	O
each	O
domain	O
,	O
while	O
and	O
attempt	O
to	O
generate	O
realistic	O
images	O
.	O
Self	O
-	O
reconstruction	O
loss	O
.	O
In	O
addition	O
to	O
the	O
cross	Method
-	Method
cycle	Method
reconstruction	Method
,	O
we	O
apply	O
a	O
self	Method
-	Method
reconstruction	Method
loss	Method
to	O
facilitate	O
the	O
training	Task
.	O
With	O
encoded	O
content	O
/	O
attribute	O
features	O
and	O
,	O
the	O
decoders	O
and	O
should	O
decode	O
them	O
back	O
to	O
original	O
input	O
and	O
.	O
That	O
is	O
,	O
and	O
.	O
KL	O
loss	O
.	O
In	O
order	O
to	O
perform	O
stochastic	Task
sampling	Task
at	O
test	O
time	O
,	O
we	O
encourage	O
the	O
attribute	Method
representation	Method
to	O
be	O
as	O
close	O
to	O
a	O
prior	Method
Gaussian	Method
distribution	Method
.	O
We	O
thus	O
apply	O
the	O
loss	O
,	O
where	O
.	O
Latent	Method
regression	Method
loss	Method
.	O
To	O
encourage	O
invertible	O
mapping	O
between	O
the	O
image	O
and	O
the	O
latent	O
space	O
,	O
we	O
apply	O
a	O
latent	Method
regression	Method
loss	Method
similar	O
to	O
.	O
We	O
draw	O
a	O
latent	O
vector	O
from	O
the	O
prior	Method
Gaussian	Method
distribution	Method
as	O
the	O
attribute	Method
representation	Method
and	O
attempt	O
to	O
reconstruct	O
it	O
with	O
and	O
.	O
Input	O
Generated	O
images	O
The	O
full	O
objective	Metric
function	Metric
of	O
our	O
network	O
is	O
:	O
where	O
the	O
hyper	O
-	O
parameters	O
s	O
control	O
the	O
importance	O
of	O
each	O
term	O
.	O
section	O
:	O
Experimental	O
Results	O
Implementation	O
details	O
.	O
We	O
implement	O
our	O
model	O
with	O
PyTorch	Method
.	O
We	O
use	O
the	O
input	O
image	O
size	O
of	O
for	O
all	O
of	O
our	O
experiments	O
except	O
domain	Method
adaptation	Method
.	O
For	O
the	O
content	Task
encoder	Task
,	O
we	O
use	O
an	O
architecture	O
consisting	O
of	O
three	O
convolution	Method
layers	Method
followed	O
by	O
four	O
residual	O
blocks	O
.	O
For	O
the	O
attribute	Method
encoder	Method
,	O
we	O
use	O
a	O
CNN	Method
architecture	Method
with	O
four	O
convolution	Method
layers	Method
followed	O
by	O
fully	Method
-	Method
connected	Method
layers	Method
.	O
We	O
set	O
the	O
size	O
of	O
the	O
attribute	O
vector	O
to	O
for	O
all	O
experiments	O
.	O
For	O
the	O
generator	Method
,	O
we	O
use	O
an	O
architecture	O
containing	O
four	O
residual	O
blocks	O
followed	O
by	O
three	O
fractionally	Method
strided	Method
convolution	Method
layers	Method
.	O
For	O
more	O
details	O
of	O
architecture	O
design	O
,	O
please	O
refer	O
to	O
the	O
supplementary	O
material	O
.	O
For	O
training	Task
,	O
we	O
use	O
the	O
Adam	Method
optimizer	Method
with	O
a	O
batch	O
size	O
of	O
,	O
a	O
learning	Metric
rate	Metric
of	O
,	O
and	O
exponential	Method
decay	Method
rates	Method
.	O
In	O
all	O
experiments	O
,	O
we	O
set	O
the	O
hyper	O
-	O
parameters	O
as	O
follows	O
:	O
,	O
,	O
,	O
,	O
,	O
and	O
.	O
We	O
also	O
apply	O
an	O
L1	Method
weight	Method
regularization	Method
on	O
the	O
content	Method
representation	Method
with	O
a	O
weight	O
of	O
.	O
We	O
follow	O
the	O
procedure	O
in	O
DCGAN	Method
for	O
training	O
the	O
model	O
with	O
adversarial	O
loss	O
.	O
Datasets	O
.	O
We	O
evaluate	O
our	O
model	O
on	O
several	O
datasets	O
include	O
Yosemite	Material
(	Material
summer	Material
and	Material
winter	Material
scenes	Material
)	O
,	O
artworks	O
(	O
Monet	O
and	O
van	O
Gogh	O
)	O
,	O
edge	O
-	O
to	O
-	O
shoes	O
and	O
photo	O
-	O
to	O
-	O
portrait	O
cropped	O
from	O
subsets	O
of	O
the	O
WikiArt	Material
dataset	Material
and	O
the	O
CelebA	Material
dataset	Material
.	O
We	O
also	O
perform	O
domain	Method
adaptation	Method
on	O
the	O
classification	Task
task	Task
with	O
MNIST	Material
to	O
MNIST	Material
-	Material
M	Material
,	O
and	O
on	O
the	O
classification	Task
and	Task
pose	Task
estimation	Task
tasks	Task
with	O
Synthetic	Material
Cropped	Material
LineMod	Material
to	O
Cropped	Material
LineMod	Material
.	O
Compared	O
methods	O
.	O
We	O
perform	O
the	O
evaluation	O
on	O
the	O
following	O
algorithms	O
:	O
DRIT	O
:	O
We	O
refer	O
to	O
our	O
proposed	O
model	O
,	O
Disentangled	Method
Representation	Method
for	O
Image	Task
-	Task
to	Task
-	Task
Image	Task
Translation	Task
,	O
as	O
DRIT	Method
.	O
DRIT	O
w	O
/	O
o	O
Dc	O
:	O
Our	O
proposed	O
model	O
without	O
the	O
content	Method
discriminator	Method
.	O
CycleGAN	Method
,	O
UNIT	O
,	O
BicycleGAN	Task
Cycle	Task
/	Task
Bicycle	Task
:	O
As	O
there	O
is	O
no	O
previous	O
work	O
addressing	O
the	O
problem	O
of	O
multimodal	Task
generation	Task
from	O
unpaired	O
training	O
data	O
,	O
we	O
construct	O
a	O
baseline	O
using	O
a	O
combination	O
of	O
CylceGAN	Method
and	O
BicycleGAN	Method
.	O
Here	O
,	O
we	O
first	O
train	O
CycleGAN	Method
on	O
unpaired	O
data	O
to	O
generate	O
corresponding	O
images	O
as	O
pseudo	O
image	O
pairs	O
.	O
We	O
then	O
use	O
this	O
pseudo	O
paired	O
data	O
to	O
train	O
BicycleGAN	Method
.	O
[	O
Inter	O
-	O
domain	O
attribute	O
transfer	O
]	O
[	O
Intra	Task
-	Task
domain	Task
attribute	Task
transfer	Task
]	O
Content	O
Attribute	O
Output	O
Content	O
Attribute	O
Output	O
subsection	O
:	O
Qualitative	Metric
Evaluation	Metric
Diversity	O
.	O
We	O
first	O
demonstrate	O
the	O
diversity	O
of	O
the	O
generated	O
images	O
on	O
several	O
different	O
tasks	O
in	O
Figure	O
[	O
reference	O
]	O
.	O
In	O
Figure	O
[	O
reference	O
]	O
,	O
we	O
compare	O
the	O
proposed	O
model	O
with	O
other	O
methods	O
.	O
Both	O
our	O
model	O
without	O
and	O
Cycle	Method
/	Method
Bicycle	Method
can	O
generate	O
diverse	O
results	O
.	O
However	O
,	O
the	O
results	O
contain	O
clearly	O
visible	O
artifacts	O
.	O
Without	O
the	O
content	Method
discriminator	Method
,	O
our	O
model	O
fails	O
to	O
capture	O
domain	O
-	O
related	O
details	O
(	O
e.g.	O
,	O
the	O
color	O
of	O
tree	O
and	O
sky	O
)	O
.	O
Therefore	O
,	O
the	O
variations	O
take	O
place	O
in	O
global	O
color	O
difference	O
.	O
Cycle	Method
/	Method
Bicycle	Method
is	O
trained	O
on	O
pseudo	O
paired	O
data	O
generated	O
by	O
CycleGAN	Method
.	O
The	O
quality	O
of	O
the	O
pseudo	O
paired	O
data	O
is	O
not	O
uniformly	O
ideal	O
.	O
As	O
a	O
result	O
,	O
the	O
generated	O
images	O
are	O
of	O
ill	O
-	O
quality	O
.	O
To	O
have	O
a	O
better	O
understanding	O
of	O
the	O
learned	O
domain	O
-	O
specific	O
attribute	O
space	O
,	O
we	O
perform	O
linear	Method
interpolation	Method
between	O
two	O
given	O
attributes	O
and	O
generate	O
the	O
corresponding	O
images	O
as	O
shown	O
in	O
Figure	O
[	O
reference	O
]	O
.	O
The	O
interpolation	O
results	O
verify	O
the	O
continuity	O
in	O
the	O
attribute	O
space	O
and	O
show	O
that	O
our	O
model	O
can	O
generalize	O
in	O
the	O
distribution	O
,	O
rather	O
than	O
memorize	O
trivial	O
visual	O
information	O
.	O
Attribute	Task
transfer	Task
.	O
We	O
demonstrate	O
the	O
results	O
of	O
the	O
attribute	Task
transfer	Task
in	O
Figure	O
[	O
reference	O
]	O
.	O
Thanks	O
to	O
the	O
representation	O
disentanglement	O
of	O
content	O
and	O
attribute	O
,	O
we	O
are	O
able	O
to	O
perform	O
attribute	Task
transfer	Task
from	O
images	O
of	O
desired	O
attributes	O
,	O
as	O
illustrated	O
in	O
Figure	O
[	O
reference	O
]	O
(	O
c	O
)	O
.	O
Moreover	O
,	O
since	O
the	O
content	O
space	O
is	O
shared	O
between	O
two	O
domains	O
,	O
we	O
can	O
generate	O
images	O
conditioned	O
on	O
content	O
features	O
encoded	O
from	O
either	O
domain	O
.	O
Thus	O
our	O
model	O
can	O
achieve	O
not	O
only	O
inter	O
-	O
domain	O
but	O
also	O
intra	Task
-	Task
domain	Task
attribute	Task
transfer	Task
.	O
Note	O
that	O
intra	Task
-	Task
domain	Task
attribute	Task
transfer	Task
is	O
not	O
explicitly	O
involved	O
in	O
the	O
training	Task
process	Task
.	O
subsection	O
:	O
Quantitative	Metric
Evaluation	Metric
Realism	O
vs.	O
diversity	Metric
.	O
Here	O
we	O
have	O
the	O
quantitative	O
evaluation	O
on	O
the	O
realism	Metric
and	O
diversity	O
of	O
the	O
generated	O
images	O
.	O
We	O
conduct	O
the	O
experiment	O
using	O
winter	O
summer	O
translation	Task
with	O
the	O
Yosemite	Material
dataset	Material
.	O
For	O
realism	Task
,	O
we	O
conduct	O
a	O
user	Task
study	Task
using	O
pairwise	Task
comparison	Task
.	O
Given	O
a	O
pair	O
of	O
images	O
sampled	O
from	O
real	O
images	O
and	O
translated	O
images	O
generated	O
from	O
various	O
methods	O
,	O
users	O
need	O
to	O
answer	O
the	O
question	O
“	O
Which	O
image	O
is	O
more	O
realistic	O
?	O
”	O
For	O
diversity	Task
,	O
similar	O
to	O
,	O
we	O
use	O
the	O
LPIPS	Method
metric	Method
to	O
measure	O
the	O
similarity	Metric
among	O
images	O
.	O
We	O
compute	O
the	O
distance	O
between	O
1000	O
pairs	O
of	O
randomly	O
sampled	O
images	O
translated	O
from	O
100	O
real	O
images	O
.	O
Figure	O
[	O
reference	O
]	O
and	O
Table	O
[	O
reference	O
]	O
show	O
the	O
results	O
of	O
realism	O
and	O
diversity	O
,	O
respectively	O
.	O
UNIT	Method
obtains	O
low	O
realism	Metric
score	Metric
,	O
suggesting	O
that	O
their	O
assumption	O
might	O
not	O
be	O
generally	O
applicable	O
.	O
CycleGAN	Method
achieves	O
the	O
highest	O
scores	O
in	O
realism	Metric
,	O
yet	O
the	O
diversity	O
is	O
limited	O
.	O
The	O
diversity	O
and	O
the	O
visual	Metric
quality	Metric
of	O
Cycle	O
/	O
Bicycle	O
are	O
constrained	O
by	O
the	O
data	O
CycleGAN	Method
can	O
generate	O
.	O
Our	O
results	O
also	O
demonstrate	O
the	O
need	O
for	O
the	O
content	Method
discriminator	Method
.	O
Reconstruction	Metric
ability	Metric
.	O
In	O
addition	O
to	O
diversity	Task
evaluation	Task
,	O
we	O
conduct	O
an	O
experiment	O
on	O
the	O
edge	O
-	O
to	O
-	O
shoes	O
dataset	O
to	O
measure	O
the	O
quality	Metric
of	O
the	O
disentangled	Method
encoding	Method
.	O
Our	O
model	O
was	O
trained	O
using	O
unpaired	O
data	O
.	O
At	O
test	O
time	O
,	O
given	O
a	O
paired	O
data	O
,	O
we	O
can	O
evaluate	O
the	O
quality	O
of	O
content	Metric
-	Metric
attribute	Metric
disentanglement	Metric
by	O
measuring	O
the	O
reconstruction	Metric
errors	Metric
of	Metric
with	Metric
.	O
We	O
compare	O
our	O
model	O
with	O
BicycleGAN	Method
,	O
which	O
requires	O
paired	O
data	O
during	O
training	O
.	O
Table	O
[	O
reference	O
]	O
shows	O
our	O
model	O
performs	O
comparably	O
with	O
BicycleGAN	Method
despite	O
training	O
without	O
paired	O
data	O
.	O
Moreover	O
,	O
the	O
result	O
suggests	O
that	O
the	O
content	Method
discriminator	Method
contributes	O
greatly	O
to	O
the	O
quality	O
of	O
disentangled	Method
representation	Method
.	O
subsection	O
:	O
Domain	Method
Adaptation	Method
We	O
demonstrate	O
that	O
the	O
proposed	O
image	O
-	O
to	O
-	O
image	O
translation	Task
scheme	O
can	O
benefit	O
unsupervised	Method
domain	Method
adaptation	Method
.	O
Following	O
PixelDA	Method
,	O
we	O
conduct	O
experiments	O
on	O
the	O
classification	Task
and	Task
pose	Task
estimation	Task
tasks	Task
using	O
MNIST	Material
to	O
MNIST	Material
-	Material
M	Material
,	O
and	O
Synthetic	Material
Cropped	Material
LineMod	Material
to	O
Cropped	Material
LineMod	Material
.	O
Several	O
example	O
images	O
in	O
these	O
datasets	O
are	O
shown	O
in	O
Figure	O
[	O
reference	O
]	O
(	O
a	O
)	O
and	O
(	O
b	O
)	O
.	O
To	O
evaluate	O
our	O
method	O
,	O
we	O
first	O
translate	O
the	O
labeled	O
source	O
images	O
to	O
the	O
target	O
domain	O
.	O
We	O
then	O
treat	O
the	O
generated	O
labeled	O
images	O
as	O
training	O
data	O
and	O
train	O
the	O
classifiers	Method
of	O
each	O
task	O
in	O
the	O
target	O
domain	O
.	O
For	O
a	O
fair	O
comparison	O
,	O
we	O
use	O
the	O
classifiers	Method
with	O
the	O
same	O
architecture	O
as	O
PixelDA	Method
.	O
We	O
compare	O
the	O
proposed	O
method	O
with	O
CycleGAN	Method
,	O
which	O
generates	O
the	O
most	O
realistic	O
images	O
in	O
the	O
target	O
domain	O
according	O
to	O
our	O
previous	O
experiment	O
,	O
and	O
three	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
domain	Method
adaptation	Method
algorithms	O
:	O
PixelDA	Method
,	O
DANN	Method
and	O
DSN	Method
.	O
[	O
Examples	O
from	O
MNIST	Material
/	O
MNIST	Material
-	Material
M	Material
]	O
[	O
Examples	O
from	O
Cropped	O
Linemod	O
]	O
MNIST	Material
MNIST	Material
-	Material
M	Material
(	O
Source	O
)	O
(	O
Target	O
)	O
Synthetic	Material
Real	Material
(	O
Source	O
)	O
(	O
Target	O
)	O
[	O
MNIST	Material
MNIST	Material
-	Material
M	Material
]	O
[	O
Synthetic	Material
Real	Material
Cropped	O
LineMod	O
]	O
Source	O
Generated	O
Source	O
Generated	O
[	O
MNIST	Material
-	Material
M	Material
]	O
Model	O
(	O
%	O
)	O
Source	O
-	O
only56.6CycleGAN	O
[	O
]	O
74.5Ours	O
,	O
×186.93Ours	O
,	O
×390.21Ours	O
,	O
×591.54DANN	O
[	O
]	O
77.4DSN	O
[	O
]	O
83.2PixelDA	O
[	O
]	O
95.9Target	O
-	O
only96.5	O
LineMod	O
]	O
Model	O
(	O
%	O
)	O
AngleError	O
(	O
(	O
47.33	O
)	O
73.7	O
(	O
89.2	O
)	O
CycleGAN	Method
[	O
]	O
68.1847.45Ours	O
,	O
×195.9142.06Ours	O
,	O
×397.0437.35Ours	O
,	O
×598.1234.4DANN	O
[	O
]	O
99.956.58DSN	O
[	O
]	O
10053.27PixelDA	O
[	O
]	O
99.9823.5Target	O
-	O
only10012.3	O
(	O
6.47	O
)	O
We	O
present	O
the	O
quantitative	O
comparisons	O
in	O
Table	O
[	O
reference	O
]	O
and	O
visual	O
results	O
from	O
our	O
method	O
in	O
Figure	O
[	O
reference	O
]	O
(	O
c	O
)(	O
d	O
)	O
.	O
Since	O
our	O
model	O
can	O
generate	O
diverse	O
output	O
,	O
we	O
generate	O
one	O
time	O
,	O
three	O
times	O
,	O
and	O
five	O
times	O
(	O
denoted	O
as	O
)	O
of	O
target	O
images	O
using	O
the	O
same	O
amount	O
of	O
source	O
images	O
.	O
Our	O
results	O
validate	O
that	O
the	O
proposed	O
method	O
can	O
simulate	O
diverse	O
images	O
in	O
the	O
target	O
domain	O
and	O
improve	O
the	O
performance	O
in	O
target	Task
tasks	Task
.	O
While	O
our	O
method	O
does	O
not	O
outperform	O
PixelDA	Method
,	O
we	O
note	O
that	O
unlike	O
PixelDA	Method
,	O
we	O
do	O
not	O
leverage	O
label	O
information	O
during	O
training	O
.	O
Compared	O
to	O
CycleGAN	Method
,	O
our	O
method	O
performs	O
favorably	O
even	O
with	O
the	O
same	O
amount	O
of	O
generated	O
images	O
(	O
i.e.	O
,	O
)	O
.	O
We	O
observe	O
that	O
CycleGAN	Method
suffers	O
from	O
the	O
mode	Task
collapse	Task
problem	Task
and	O
generates	O
images	O
with	O
similar	O
appearances	O
,	O
which	O
degrade	O
the	O
performance	O
of	O
the	O
adapted	Method
classifiers	Method
.	O
[	O
Summer	O
Winter	O
]	O
[	O
van	O
Gogh	O
Monet	O
]	O
subsection	O
:	O
Limitations	O
Our	O
method	O
has	O
the	O
following	O
limitations	O
.	O
First	O
,	O
due	O
to	O
the	O
limited	O
amount	O
of	O
training	O
data	O
,	O
the	O
attribute	O
space	O
is	O
not	O
fully	O
exploited	O
.	O
Our	O
I2I	Task
translation	Task
fails	O
when	O
the	O
sampled	O
attribute	O
vectors	O
locate	O
in	O
under	O
-	O
sampled	O
space	O
,	O
see	O
Figure	O
[	O
reference	O
]	O
(	O
a	O
)	O
.	O
Second	O
,	O
it	O
remains	O
difficult	O
when	O
the	O
domain	O
characteristics	O
differ	O
significantly	O
.	O
For	O
example	O
,	O
Figure	O
[	O
reference	O
]	O
(	O
b	O
)	O
shows	O
a	O
failure	O
case	O
on	O
the	O
human	O
figure	O
due	O
to	O
the	O
lack	O
of	O
human	O
-	O
related	O
portraits	O
in	O
Monet	O
collections	O
.	O
section	O
:	O
Conclusions	O
In	O
this	O
paper	O
,	O
we	O
present	O
a	O
novel	O
disentangled	Method
representation	Method
framework	Method
for	O
diverse	O
image	O
-	O
to	O
-	O
image	O
translation	Task
with	O
unpaired	O
data	O
.	O
we	O
propose	O
to	O
disentangle	O
the	O
latent	O
space	O
to	O
a	O
content	O
space	O
that	O
encodes	O
common	O
information	O
between	O
domains	O
,	O
and	O
a	O
domain	O
-	O
specific	O
attribute	O
space	O
that	O
can	O
model	O
the	O
diverse	O
variations	O
given	O
the	O
same	O
content	O
.	O
We	O
apply	O
a	O
content	Method
discriminator	Method
to	O
facilitate	O
the	O
representation	Task
disentanglement	Task
.	O
We	O
propose	O
a	O
cross	Method
-	Method
cycle	Method
consistency	Method
loss	Method
for	O
cyclic	Task
reconstruction	Task
to	O
train	O
in	O
the	O
absence	O
of	O
paired	O
data	O
.	O
Qualitative	O
and	O
quantitative	O
results	O
show	O
that	O
the	O
proposed	O
model	O
produces	O
realistic	O
and	O
diverse	O
images	O
.	O
We	O
also	O
apply	O
the	O
proposed	O
method	O
to	O
domain	Method
adaptation	Method
and	O
achieve	O
competitive	O
performance	O
compared	O
to	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
methods	O
.	O
section	O
:	O
Acknowledgements	O
This	O
work	O
is	O
supported	O
in	O
part	O
by	O
the	O
NSF	O
CAREER	O
Grant	O
#	O
1149783	O
,	O
the	O
NSF	O
Grant	O
#	O
1755785	O
,	O
and	O
gifts	O
from	O
Verisk	O
,	O
Adobe	O
and	O
Nvidia	O
.	O
bibliography	O
:	O
References	O
