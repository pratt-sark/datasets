Mask Method
R Method
- Method
CNN Method
section O
: O
Abstract O
We O
present O
a O
conceptually O
simple O
, O
flexible O
, O
and O
general O
framework O
for O
object O
instance O
segmentation Task
. O
Our O
approach O
efficiently O
detects O
objects O
in O
an O
image O
while O
simultaneously O
generating O
a O
high O
- O
quality O
segmentation Task
mask O
for O
each O
instance O
. O
The O
method O
, O
called O
Mask Method
R Method
- Method
CNN Method
, O
extends O
Faster O
R Method
- Method
CNN Method
by O
adding O
a O
branch O
for O
predicting O
an O
object O
mask O
in O
parallel O
with O
the O
existing O
branch O
for O
bounding Task
box Task
recognition Task
. O
Mask Method
R Method
- Method
CNN Method
is O
simple O
to O
train O
and O
adds O
only O
a O
small O
overhead O
to O
Faster O
R Method
- Method
CNN Method
, O
running O
at O
5 O
fps Metric
. O
Moreover O
, O
Mask Method
R Method
- Method
CNN Method
is O
easy O
to O
generalize O
to O
other O
tasks O
, O
e.g. O
, O
allowing O
us O
to O
estimate O
human O
poses O
in O
the O
same O
framework O
. O
We O
show O
top O
results O
in O
all O
three O
tracks O
of O
the O
COCO Material
suite O
of O
challenges O
, O
including O
instance Task
segmentation Task
, O
boundingbox O
object Task
detection Task
, O
and O
person O
keypoint Task
detection Task
. O
Without O
bells O
and O
whistles O
, O
Mask Method
R Method
- Method
CNN Method
outperforms O
all O
existing O
, O
single O
- O
model O
entries O
on O
every O
task O
, O
including O
the O
COCO Material
2016 O
challenge O
winners O
. O
We O
hope O
our O
simple O
and O
effective O
approach O
will O
serve O
as O
a O
solid O
baseline O
and O
help O
ease O
future O
research O
in O
instance Task
- Task
level Task
recognition Task
. O
Code O
has O
been O
made O
available O
at O
: O
https: O
// O
github.com O
/ O
facebookresearch O
/ O
Detectron O
. O
section O
: O
Introduction O
The O
vision Task
community Task
has O
rapidly O
improved O
object Task
detection Task
and O
semantic O
segmentation Task
results O
over O
a O
short O
period O
of O
time O
. O
In O
large O
part O
, O
these O
advances O
have O
been O
driven O
by O
powerful O
baseline O
systems O
, O
such O
as O
the O
Fast O
/ O
Faster O
R Method
- Method
CNN Method
[ O
reference O
][ O
reference O
] O
and O
Fully Method
Convolutional Method
Network Method
( O
FCN Method
) O
[ O
reference O
] O
frameworks O
for O
object Task
detection Task
and O
semantic O
segmentation Task
, O
respectively O
. O
These O
methods O
are O
conceptually O
intuitive O
and O
offer O
flexibility O
and O
robustness Metric
, O
together O
with O
fast O
training Metric
and Metric
inference Metric
time Metric
. O
Our O
goal O
in O
this O
work O
is O
to O
develop O
a O
comparably Method
enabling Method
framework Method
for O
instance Task
segmentation Task
. O
Instance O
segmentation Task
is O
challenging O
because O
it O
requires O
the O
correct O
detection Task
of Task
all Task
objects Task
in O
an O
image O
while O
also O
precisely O
segmenting O
each O
instance O
. O
It O
therefore O
combines O
elements O
from O
the O
classical O
computer Task
vision Task
tasks Task
of O
object Task
detection Task
, O
where O
the O
goal O
is O
to O
classify O
individual O
objects O
and O
localize O
each O
using O
a O
bounding O
box O
, O
and O
semantic O
segmentation Task
, O
where O
the O
goal O
is O
to O
classify O
each O
pixel O
into O
a O
fixed O
set O
of O
categories O
without O
differentiating O
object O
instances O
. O
[ O
reference O
] O
Given O
this O
, O
one O
might O
expect O
a O
complex O
method O
is O
required O
to O
achieve O
good O
results O
. O
However O
, O
we O
show O
that O
a O
surprisingly O
simple O
, O
flexible O
, O
and O
fast O
system O
can O
surpass O
prior O
state O
- O
of O
- O
the O
- O
art O
instance Task
segmentation Task
results O
. O
Our O
method O
, O
called O
Mask Method
R Method
- Method
CNN Method
, O
extends O
Faster O
R Method
- Method
CNN Method
[ O
reference O
] O
by O
adding O
a O
branch O
for O
predicting O
segmentation Task
masks O
on O
each O
Region O
of O
Interest O
( O
RoI O
) O
, O
in O
parallel O
with O
the O
existing O
branch O
for O
classification Task
and O
bounding Method
box Method
regression Method
( O
Figure O
1 O
) O
. O
The O
mask Method
branch Method
is O
a O
small O
FCN Method
applied O
to O
each O
RoI O
, O
predicting O
a O
segmentation Task
mask O
in O
a O
pixel O
- O
topixel O
manner O
. O
Mask Method
R Method
- Method
CNN Method
is O
simple O
to O
implement O
and O
train O
given O
the O
Faster O
R Method
- Method
CNN Method
framework O
, O
which O
facilitates O
a O
wide O
range O
of O
flexible O
architecture Method
designs Method
. O
Additionally O
, O
the O
mask O
branch O
only O
adds O
a O
small O
computational Metric
overhead Metric
, O
enabling O
a O
fast O
system O
and O
rapid O
experimentation O
. O
In O
principle O
Mask Method
R Method
- Method
CNN Method
is O
an O
intuitive O
extension O
of O
Faster O
R Method
- Method
CNN Method
, O
yet O
constructing O
the O
mask O
branch O
properly O
is O
critical O
for O
good O
results O
. O
Most O
importantly O
, O
Faster O
R Method
- Method
CNN Method
was O
not O
designed O
for O
pixel Task
- Task
to Task
- Task
pixel Task
alignment Task
between O
network O
inputs O
and O
outputs O
. O
This O
is O
most O
evident O
in O
how O
RoIPool Method
[ O
reference O
][ O
reference O
] O
, O
the O
de O
facto O
core Method
operation Method
for O
attending O
to O
instances O
, O
performs O
coarse Method
spatial Method
quantization Method
for O
feature Task
extraction Task
. O
To O
fix O
the O
misalignment O
, O
we O
propose O
a O
simple O
, O
quantization Method
- Method
free Method
layer Method
, O
called O
RoIAlign Method
, O
that O
faithfully O
preserves O
exact O
spatial O
locations O
. O
Despite O
being O
dining O
Figure O
2 O
. O
Mask Method
R Method
- Method
CNN Method
results O
on O
the O
COCO Material
test O
set O
. O
These O
results O
are O
based O
on O
ResNet Method
- Method
101 Method
[ O
reference O
] O
, O
achieving O
a O
mask Method
AP Method
of O
35.7 O
and O
running O
at O
5 O
fps O
. O
Masks O
are O
shown O
in O
color O
, O
and O
bounding O
box O
, O
category O
, O
and O
confidences O
are O
also O
shown O
. O
a O
seemingly O
minor O
change O
, O
RoIAlign Method
has O
a O
large O
impact O
: O
it O
improves O
mask Metric
accuracy Metric
by O
relative O
10 O
% O
to O
50 O
% O
, O
showing O
bigger O
gains O
under O
stricter Metric
localization Metric
metrics Metric
. O
Second O
, O
we O
found O
it O
essential O
to O
decouple O
mask Task
and Task
class Task
prediction Task
: O
we O
predict O
a O
binary O
mask O
for O
each O
class O
independently O
, O
without O
competition O
among O
classes O
, O
and O
rely O
on O
the O
network O
's O
RoI Method
classification Method
branch Method
to O
predict O
the O
category O
. O
In O
contrast O
, O
FCNs Method
usually O
perform O
per Task
- Task
pixel Task
multi Task
- Task
class Task
categorization Task
, O
which O
couples O
segmentation Task
and O
classification Task
, O
and O
based O
on O
our O
experiments O
works O
poorly O
for O
instance Task
segmentation Task
. O
Without O
bells O
and O
whistles O
, O
Mask Method
R Method
- Method
CNN Method
surpasses O
all O
previous O
state O
- O
of O
- O
the O
- O
art O
single Method
- Method
model Method
results O
on O
the O
COCO Material
instance O
segmentation Task
task O
[ O
reference O
] O
, O
including O
the O
heavilyengineered O
entries O
from O
the O
2016 O
competition O
winner O
. O
As O
a O
by O
- O
product O
, O
our O
method O
also O
excels O
on O
the O
COCO Material
object Task
detection Task
task O
. O
In O
ablation O
experiments O
, O
we O
evaluate O
multiple O
basic Method
instantiations Method
, O
which O
allows O
us O
to O
demonstrate O
its O
robustness O
and O
analyze O
the O
effects O
of O
core O
factors O
. O
Our O
models O
can O
run O
at O
about O
200ms O
per O
frame O
on O
a O
GPU O
, O
and O
training O
on O
COCO Material
takes O
one O
to O
two O
days O
on O
a O
single O
8 Method
- Method
GPU Method
machine Method
. O
We O
believe O
the O
fast O
train Metric
and Metric
test Metric
speeds Metric
, O
together O
with O
the O
framework O
's O
flexibility O
and O
accuracy Metric
, O
will O
benefit O
and O
ease O
future O
research O
on O
instance Task
segmentation Task
. O
Finally O
, O
we O
showcase O
the O
generality O
of O
our O
framework O
via O
the O
task O
of O
human Task
pose Task
estimation Task
on O
the O
COCO Material
keypoint O
dataset O
[ O
reference O
] O
. O
By O
viewing O
each O
keypoint O
as O
a O
one O
- O
hot O
binary O
mask O
, O
with O
minimal O
modification O
Mask Method
R Method
- Method
CNN Method
can O
be O
applied O
to O
detect O
instance Task
- Task
specific Task
poses Task
. O
Mask Method
R Method
- Method
CNN Method
surpasses O
the O
winner O
of O
the O
2016 O
COCO Material
keypoint O
competition O
, O
and O
at O
the O
same O
time O
runs O
at O
5 O
fps O
. O
Mask Method
R Method
- Method
CNN Method
, O
therefore O
, O
can O
be O
seen O
more O
broadly O
as O
a O
flexible O
framework O
for O
instance Task
- Task
level Task
recognition Task
and O
can O
be O
readily O
extended O
to O
more O
complex O
tasks O
. O
We O
have O
released O
code O
to O
facilitate O
future O
research O
. O
section O
: O
Related O
Work O
R Method
- Method
CNN Method
: O
The O
Region Method
- Method
based Method
CNN Method
( O
R Method
- Method
CNN Method
) O
approach O
[ O
reference O
] O
to O
bounding O
- O
box O
object Task
detection Task
is O
to O
attend O
to O
a O
manageable O
number O
of O
candidate O
object O
regions O
[ O
reference O
][ O
reference O
] O
and O
evaluate O
convolutional Method
networks Method
[ O
reference O
][ O
reference O
] O
independently O
on O
each O
RoI. Method
R Method
- Method
CNN Method
was O
extended O
[ O
reference O
][ O
reference O
] O
to O
allow O
attending O
to O
RoIs O
on O
feature O
maps O
using O
RoIPool O
, O
leading O
to O
fast O
speed Metric
and O
better O
accuracy Metric
. O
Faster O
R Method
- Method
CNN Method
[ O
reference O
] O
advanced O
this O
stream O
by O
learning O
the O
attention Method
mechanism Method
with O
a O
Region Method
Proposal Method
Network Method
( O
RPN Method
) O
. O
Faster O
R Method
- Method
CNN Method
is O
flexible O
and O
robust O
to O
many O
follow O
- O
up O
improvements O
( O
e.g. O
, O
[ O
reference O
][ O
reference O
][ O
reference O
] O
) O
, O
and O
is O
the O
current O
leading O
framework O
in O
several O
benchmarks O
. O
Instance Task
Segmentation Task
: O
Driven O
by O
the O
effectiveness O
of O
R Method
- Method
CNN Method
, O
many O
approaches O
to O
instance Task
segmentation Task
are O
based O
on O
segment Method
proposals Method
. O
Earlier O
methods O
[ O
reference O
][ O
reference O
][ O
reference O
][ O
reference O
] O
resorted O
to O
bottom O
- O
up O
segments O
[ O
reference O
][ O
reference O
] O
. O
DeepMask O
[ O
reference O
] O
and O
following O
works O
[ O
reference O
][ O
reference O
] O
learn O
to O
propose O
segment O
candidates O
, O
which O
are O
then O
classified O
by O
Fast Method
R Method
- Method
CNN Method
. O
In O
these O
methods O
, O
segmentation Task
precedes O
recognition Task
, O
which O
is O
slow O
and O
less O
accurate O
. O
Likewise O
, O
Dai O
et O
al O
. O
[ O
reference O
] O
proposed O
a O
complex O
multiple Method
- Method
stage Method
cascade Method
that O
predicts O
segment O
proposals O
from O
bounding O
- O
box O
proposals O
, O
followed O
by O
classification Task
. O
Instead O
, O
our O
method O
is O
based O
on O
parallel Task
prediction Task
of Task
masks Task
and Task
class Task
labels Task
, O
which O
is O
simpler O
and O
more O
flexible O
. O
Most O
recently O
, O
Li O
et O
al O
. O
[ O
reference O
] O
combined O
the O
segment Method
proposal Method
system Method
in O
[ O
reference O
] O
and O
object Task
detection Task
system O
in O
[ O
reference O
] O
for O
" O
fully O
convolutional O
instance O
segmentation Task
" O
( O
FCIS Method
) O
. O
The O
common O
idea O
in O
[ O
reference O
][ O
reference O
][ O
reference O
] O
is O
to O
predict O
a O
set O
of O
positionsensitive Method
output Method
channels Method
fully Method
convolutionally Method
. O
These O
channels O
simultaneously O
address O
object O
classes O
, O
boxes O
, O
and O
masks O
, O
making O
the O
system O
fast O
. O
But O
FCIS Method
exhibits O
systematic O
errors O
on O
overlapping O
instances O
and O
creates O
spurious O
edges O
( O
Figure O
6 O
) O
, O
showing O
that O
it O
is O
challenged O
by O
the O
fundamental O
difficulties O
of O
segmenting O
instances O
. O
Another O
family O
of O
solutions O
[ O
reference O
][ O
reference O
][ O
reference O
][ O
reference O
] O
to O
instance Task
segmentation Task
are O
driven O
by O
the O
success O
of O
semantic O
segmentation Task
. O
Starting O
from O
per Task
- Task
pixel Task
classification Task
results O
( O
e.g. O
, O
FCN O
outputs O
) O
, O
these O
methods O
attempt O
to O
cut O
the O
pixels O
of O
the O
same O
category O
into O
different O
instances O
. O
In O
contrast O
to O
the O
segmentation Task
- O
first O
strategy O
of O
these O
methods O
, O
Mask Method
R Method
- Method
CNN Method
is O
based O
on O
an O
instance Method
- Method
first Method
strategy Method
. O
We O
expect O
a O
deeper O
incorporation O
of O
both O
strategies O
will O
be O
studied O
in O
the O
future O
. O
section O
: O
Mask Method
R Method
- Method
CNN Method
Mask Method
R Method
- Method
CNN Method
is O
conceptually O
simple O
: O
Faster O
R Method
- Method
CNN Method
has O
two O
outputs O
for O
each O
candidate O
object O
, O
a O
class O
label O
and O
a O
bounding O
- O
box O
offset O
; O
to O
this O
we O
add O
a O
third O
branch O
that O
outputs O
the O
object O
mask O
. O
Mask Method
R Method
- Method
CNN Method
is O
thus O
a O
natural O
and O
intuitive O
idea O
. O
But O
the O
additional O
mask O
output O
is O
distinct O
from O
the O
class O
and O
box O
outputs O
, O
requiring O
extraction O
of O
much O
finer O
spatial O
layout O
of O
an O
object O
. O
Next O
, O
we O
introduce O
the O
key O
elements O
of O
Mask Method
R Method
- Method
CNN Method
, O
including O
pixel Task
- Task
to Task
- Task
pixel Task
alignment Task
, O
which O
is O
the O
main O
missing O
piece O
of O
Fast O
/ O
Faster O
R Method
- Method
CNN Method
. O
Faster O
R Method
- Method
CNN Method
: O
We O
begin O
by O
briefly O
reviewing O
the O
Faster O
R Method
- Method
CNN Method
detector O
[ O
reference O
] O
. O
Faster O
R Method
- Method
CNN Method
consists O
of O
two O
stages O
. O
The O
first O
stage O
, O
called O
a O
Region Method
Proposal Method
Network Method
( O
RPN Method
) Method
, O
proposes O
candidate O
object O
bounding O
boxes O
. O
The O
second O
stage O
, O
which O
is O
in O
essence O
Fast Method
R Method
- Method
CNN Method
[ O
reference O
] O
, O
extracts O
features O
using O
RoIPool O
from O
each O
candidate O
box O
and O
performs O
classification Task
and O
bounding Method
- Method
box Method
regression Method
. O
The O
features O
used O
by O
both O
stages O
can O
be O
shared O
for O
faster Task
inference Task
. O
We O
refer O
readers O
to O
[ O
reference O
] O
for O
latest O
, O
comprehensive O
comparisons O
between O
Faster O
R Method
- Method
CNN Method
and O
other O
frameworks O
. O
Mask Method
R Method
- Method
CNN Method
: O
Mask Method
R Method
- Method
CNN Method
adopts O
the O
same O
two O
- O
stage O
procedure O
, O
with O
an O
identical O
first O
stage O
( O
which O
is O
RPN Method
) O
. O
In O
the O
second O
stage O
, O
in O
parallel O
to O
predicting O
the O
class O
and O
box O
offset O
, O
Mask Method
R Method
- Method
CNN Method
also O
outputs O
a O
binary O
mask O
for O
each O
RoI. O
This O
is O
in O
contrast O
to O
most O
recent O
systems O
, O
where O
classification Task
depends O
on O
mask O
predictions O
( O
e.g. O
[ O
reference O
][ O
reference O
][ O
reference O
] O
) O
. O
Our O
approach O
follows O
the O
spirit O
of O
Fast Method
R Method
- Method
CNN Method
[ O
reference O
] O
that O
applies O
bounding Method
- Method
box Method
classification Method
and O
regression Method
in O
parallel O
( O
which O
turned O
out O
to O
largely O
simplify O
the O
multi Method
- Method
stage Method
pipeline Method
of O
original O
R Method
- Method
CNN Method
[ O
reference O
] O
) O
. O
Formally O
, O
during O
training Task
, O
we O
define O
a O
multi Task
- Task
task Task
loss Task
on O
each O
sampled O
RoI O
as O
L O
= O
L O
cls Method
+ O
L O
box O
+ O
L O
mask O
. O
The O
classification Metric
loss Metric
L Metric
cls Metric
and O
bounding Metric
- Metric
box Metric
loss Metric
L Metric
box Metric
are O
identical O
as O
those O
defined O
in O
[ O
reference O
] O
. O
The O
mask Method
branch Method
has O
a O
Km O
2 O
- O
dimensional O
output O
for O
each O
RoI O
, O
which O
encodes O
K O
binary O
masks O
of O
resolution O
m O
× O
m O
, O
one O
for O
each O
of O
the O
K O
classes O
. O
To O
this O
we O
apply O
a O
per Method
- Method
pixel Method
sigmoid Method
, O
and O
define O
L O
mask O
as O
the O
average Metric
binary Metric
cross Metric
- Metric
entropy Metric
loss Metric
. O
For O
an O
RoI O
associated O
with O
ground O
- O
truth O
class O
k O
, O
L O
mask O
is O
only O
defined O
on O
the O
k O
- O
th O
mask O
( O
other O
mask O
outputs O
do O
not O
contribute O
to O
the O
loss O
) O
. O
Our O
definition O
of O
L O
mask O
allows O
the O
network O
to O
generate O
masks O
for O
every O
class O
without O
competition O
among O
classes O
; O
we O
rely O
on O
the O
dedicated O
classification Method
branch Method
to O
predict O
the O
class O
label O
used O
to O
select O
the O
output O
mask O
. O
This O
decouples O
mask Method
and Method
class Method
prediction Method
. O
This O
is O
different O
from O
common O
practice O
when O
applying O
FCNs Method
[ O
reference O
] O
to O
semantic O
segmentation Task
, O
which O
typically O
uses O
a O
per Method
- Method
pixel Method
softmax Method
and O
a O
multinomial Method
cross Method
- Method
entropy Method
loss Method
. O
In O
that O
case O
, O
masks O
across O
classes O
compete O
; O
in O
our O
case O
, O
with O
a O
per Method
- Method
pixel Method
sigmoid Method
and O
a O
binary O
loss O
, O
they O
do O
not O
. O
We O
show O
by O
experiments O
that O
this O
formulation O
is O
key O
for O
good O
instance Task
segmentation Task
results O
. O
Mask Method
Representation Method
: O
A O
mask O
encodes O
an O
input O
object O
's O
spatial O
layout O
. O
Thus O
, O
unlike O
class O
labels O
or O
box O
offsets O
that O
are O
inevitably O
collapsed O
into O
short O
output O
vectors O
by O
fully Method
- Method
connected Method
( Method
fc Method
) Method
layers Method
, O
extracting O
the O
spatial O
structure O
of O
masks O
can O
be O
addressed O
naturally O
by O
the O
pixel O
- O
to O
- O
pixel O
correspondence O
provided O
by O
convolutions Method
. O
Specifically O
, O
we O
predict O
an O
m O
× O
m O
mask O
from O
each O
RoI O
using O
an O
FCN Method
[ O
reference O
] O
. O
This O
allows O
each O
layer O
in O
the O
mask O
branch O
to O
maintain O
the O
explicit O
m O
× O
m O
object O
spatial O
layout O
without O
collapsing O
it O
into O
a O
vector Method
representation Method
that O
lacks O
spatial O
dimensions O
. O
Unlike O
previous O
methods O
that O
resort O
to O
fc Method
layers Method
for O
mask Task
prediction Task
[ O
reference O
][ O
reference O
][ O
reference O
] O
, O
our O
fully Method
convolutional Method
representation Method
requires O
fewer O
parameters O
, O
and O
is O
more O
accurate O
as O
demonstrated O
by O
experiments O
. O
This O
pixel O
- O
to O
- O
pixel O
behavior O
requires O
our O
RoI O
features O
, O
which O
themselves O
are O
small O
feature O
maps O
, O
to O
be O
well O
aligned O
to O
faithfully O
preserve O
the O
explicit O
per O
- O
pixel O
spatial O
correspondence O
. O
This O
motivated O
us O
to O
develop O
the O
following O
RoIAlign Method
layer Method
that O
plays O
a O
key O
role O
in O
mask Task
prediction Task
. O
RoIAlign Method
: O
RoIPool Method
[ O
reference O
] O
is O
a O
standard O
operation O
for O
extracting O
a O
small O
feature O
map O
( O
e.g. O
, O
7×7 O
) O
from O
each O
RoI. O
RoIPool Method
first O
quantizes O
a O
floating O
- O
number O
RoI O
to O
the O
discrete O
granularity O
of O
the O
feature O
map O
, O
this O
quantized O
RoI O
is O
then O
subdivided O
into O
spatial O
bins O
which O
are O
themselves O
quantized O
, O
and O
finally O
feature O
values O
covered O
by O
each O
bin O
are O
aggregated O
( O
usually O
by O
max Method
pooling Method
) O
. O
Quantization Method
is O
performed O
, O
e.g. O
, O
on O
a O
continuous O
coordinate O
x O
by O
computing O
[ O
x O
/ O
16 O
] O
, O
where O
16 O
is O
a O
feature O
map O
stride O
and O
[ O
· O
] O
is O
rounding O
; O
likewise O
, O
quantization Task
is O
performed O
when O
dividing O
into O
bins O
( O
e.g. O
, O
7×7 O
) O
. O
These O
quantizations O
introduce O
misalignments O
between O
the O
RoI O
and O
the O
extracted O
features O
. O
While O
this O
may O
not O
impact O
classification Task
, O
which O
is O
robust O
to O
small O
translations O
, O
it O
has O
a O
large O
negative O
effect O
on O
predicting Task
pixel Task
- Task
accurate Task
masks Task
. O
To O
address O
this O
, O
we O
propose O
an O
RoIAlign Method
layer Method
that O
removes O
the O
harsh O
quantization O
of O
RoIPool O
, O
properly O
aligning O
the O
extracted O
features O
with O
the O
input O
. O
Our O
proposed O
change O
is O
simple O
: O
we O
avoid O
any O
quantization O
of O
the O
RoI O
boundaries O
or O
bins O
( O
i.e. O
, O
we O
use O
x O
/ O
16 O
instead O
of O
[ O
x O
/ O
16 O
] O
) O
. O
We O
use O
bilinear Method
interpolation Method
[ O
reference O
] O
to O
compute O
the O
exact O
values O
of O
the O
input O
features O
at O
four O
regularly O
sampled O
locations O
in O
each O
RoI O
bin O
, O
and O
aggregate O
the O
result O
( O
using O
max O
or O
average O
) O
, O
see O
Figure O
3 O
for O
details O
. O
We O
note O
that O
the O
results O
are O
not O
sensitive O
to O
the O
exact O
sampling O
locations O
, O
or O
how O
many O
points O
are O
sampled O
, O
as O
long O
as O
no O
quantization O
is O
performed O
. O
RoIAlign Method
leads O
to O
large O
improvements O
as O
we O
show O
in O
§ O
4.2 O
. O
We O
also O
compare O
to O
the O
RoIWarp Method
operation Method
proposed O
in O
[ O
reference O
] O
. O
Unlike O
RoIAlign Method
, O
RoIWarp Method
overlooked O
the O
alignment Task
issue Task
and O
was O
implemented O
in O
[ O
reference O
] O
as O
quantizing O
RoI O
just O
like O
RoIPool Method
. O
So O
even O
though O
RoIWarp Method
also O
adopts O
bilinear Method
resampling Method
motivated O
by O
[ O
reference O
] O
, O
it O
performs O
on O
par O
with O
RoIPool Method
as O
shown O
by O
experiments O
( O
more O
details O
in O
Table O
2c O
) O
, O
demonstrating O
the O
crucial O
role O
of O
alignment Task
. O
Network Method
Architecture Method
: O
To O
demonstrate O
the O
generality O
of O
our O
approach O
, O
we O
instantiate O
Mask Method
R Method
- Method
CNN Method
with O
multiple O
architectures O
. O
For O
clarity O
, O
we O
differentiate O
between O
: O
( O
i O
) O
the O
convolutional Method
backbone Method
architecture Method
used O
for O
feature Task
extraction Task
over O
an O
entire O
image O
, O
and O
( O
ii O
) O
the O
network Method
head Method
for O
bounding Task
- Task
box Task
recognition Task
( O
classification Task
and Task
regression Task
) O
and O
mask Task
prediction Task
that O
is O
applied O
separately O
to O
each O
RoI. O
We O
denote O
the O
backbone Method
architecture Method
using O
the O
nomenclature O
network O
- O
depth O
- O
features O
. O
We O
evaluate O
ResNet Method
[ O
reference O
] O
and O
ResNeXt Method
[ O
reference O
] O
networks O
of O
depth O
50 O
or O
101 O
layers O
. O
The O
original O
implementation O
of O
Faster O
R Method
- Method
CNN Method
with O
ResNets Method
[ O
reference O
] O
extracted O
features O
from O
the O
final O
convolutional Method
layer Method
of O
the O
4 O
- O
th O
stage O
, O
which O
we O
call O
C4 Method
. O
This O
backbone O
with O
ResNet Material
- Material
50 Material
, O
for O
example O
, O
is O
denoted O
by O
ResNet O
- O
50 O
- O
C4 O
. O
This O
is O
a O
common O
choice O
used O
in O
[ O
reference O
][ O
reference O
][ O
reference O
][ O
reference O
] O
. O
We O
also O
explore O
another O
more O
effective O
backbone O
recently O
proposed O
by O
Lin O
et O
al O
. O
[ O
reference O
] O
, O
called O
a O
Feature Method
Pyramid Method
Network Method
( O
FPN Method
) O
. O
FPN Method
uses O
a O
top Method
- Method
down Method
architecture Method
with O
lateral O
connections O
to O
build O
an O
in Method
- Method
network Method
feature Method
pyramid Method
from O
a O
single O
- O
scale O
input O
. O
Faster O
R Method
- Method
CNN Method
with O
an O
FPN Method
backbone Method
extracts O
RoI O
features O
from O
different O
levels O
of O
the O
feature O
pyramid O
according O
to O
their O
scale O
, O
but O
otherwise O
the O
rest O
of O
the O
approach O
is O
similar O
to O
vanilla Method
ResNet Method
. O
Using O
a O
ResNet Method
- Method
FPN Method
backbone Method
for O
feature Task
extraction Task
with O
Mask Method
R Method
- Method
CNN Method
gives O
excellent O
gains O
in O
both O
accuracy Metric
and O
speed Metric
. O
For O
further O
details O
on O
FPN Method
, O
we O
refer O
readers O
to O
[ O
reference O
] O
. O
For O
the O
network O
head O
we O
closely O
follow O
architectures O
presented O
in O
previous O
work O
to O
which O
we O
add O
a O
fully Method
convolutional Method
mask Method
prediction Method
branch Method
. O
Specifically O
, O
we O
extend O
the O
Faster O
R Method
- Method
CNN Method
box O
heads O
from O
the O
ResNet Method
[ O
reference O
] O
and O
FPN Method
[ O
reference O
] O
papers O
. O
Details O
are O
shown O
in O
Figure O
4 O
. O
The O
head O
on O
the O
ResNet Method
- Method
C4 Method
backbone Method
includes O
the O
5 O
- O
th O
stage O
of O
ResNet Method
( O
namely O
, O
the O
9 O
- O
layer O
' O
res5 O
' O
[ O
reference O
] O
) O
, O
which O
is O
computeintensive O
. O
For O
FPN Method
, O
the O
backbone O
already O
includes O
res5 O
and O
thus O
allows O
for O
a O
more O
efficient O
head O
that O
uses O
fewer O
filters O
. O
We O
note O
that O
our O
mask O
branches O
have O
a O
straightforward O
structure O
. O
More O
complex O
designs O
have O
the O
potential O
to O
improve O
performance O
but O
are O
not O
the O
focus O
of O
this O
work O
. O
Faster O
R Method
- Method
CNN Method
w O
/ O
ResNet Method
[ O
reference O
] O
Faster O
R Method
- Method
CNN Method
w Method
/ Method
FPN Method
[ O
reference O
] O
Figure O
4 O
. O
Head Method
Architecture Method
: O
We O
extend O
two O
existing O
Faster O
R Method
- Method
CNN Method
heads O
[ O
reference O
][ O
reference O
] O
. O
Left O
/ O
Right O
panels O
show O
the O
heads O
for O
the O
ResNet O
C4 O
and O
FPN Method
backbones Method
, O
from O
[ O
reference O
] O
and O
[ O
reference O
] O
, O
respectively O
, O
to O
which O
a O
mask O
branch O
is O
added O
. O
Numbers O
denote O
spatial O
resolution O
and O
channels O
. O
Arrows O
denote O
either O
conv Method
, O
deconv Method
, O
or O
fc Method
layers Method
as O
can O
be O
inferred O
from O
context O
( O
conv O
preserves O
spatial O
dimension O
while O
deconv Method
increases O
it O
) O
. O
All O
convs Method
are O
3×3 O
, O
except O
the O
output O
conv O
which O
is O
1×1 O
, O
deconvs O
are O
2×2 O
with O
stride O
2 O
, O
and O
we O
use O
ReLU Method
[ O
reference O
] O
in O
hidden O
layers O
. O
Left O
: O
' O
res5 O
' O
denotes O
ResNet O
's O
fifth O
stage O
, O
which O
for O
simplicity O
we O
altered O
so O
that O
the O
first O
conv Method
operates O
on O
a O
7×7 O
RoI O
with O
stride O
1 O
( O
instead O
of O
14×14 O
/ O
stride O
2 O
as O
in O
[ O
reference O
] O
) O
. O
Right O
: O
' O
×4 O
' O
denotes O
a O
stack O
of O
four O
consecutive O
convs O
. O
section O
: O
Implementation O
Details O
We O
set O
hyper O
- O
parameters O
following O
existing O
Fast O
/ O
Faster O
R Method
- Method
CNN Method
work O
[ O
reference O
][ O
reference O
][ O
reference O
] O
. O
Although O
these O
decisions O
were O
made O
for O
object Task
detection Task
in O
original O
papers O
[ O
reference O
][ O
reference O
][ O
reference O
] O
, O
we O
found O
our O
instance O
segmentation Task
system O
is O
robust O
to O
them O
. O
Training O
: O
As O
in O
Fast Method
R Method
- Method
CNN Method
, O
an O
RoI O
is O
considered O
positive O
if O
it O
has O
IoU O
with O
a O
ground O
- O
truth O
box O
of O
at O
least O
0.5 O
and O
negative O
otherwise O
. O
The O
mask O
loss O
L O
mask O
is O
defined O
only O
on O
positive O
RoIs O
. O
The O
mask O
target O
is O
the O
intersection O
between O
an O
RoI O
and O
its O
associated O
ground O
- O
truth O
mask O
. O
We O
adopt O
image Method
- Method
centric Method
training Method
[ O
reference O
] O
. O
Images O
are O
resized O
such O
that O
their O
scale O
( O
shorter O
edge O
) O
is O
800 O
pixels O
[ O
reference O
] O
. O
Each O
mini O
- O
batch O
has O
2 O
images O
per O
GPU O
and O
each O
image O
has O
N O
sampled O
RoIs O
, O
with O
a O
ratio O
of O
1:3 O
of O
positive O
to O
negatives O
[ O
reference O
] O
. O
N O
is O
64 O
for O
the O
C4 O
backbone O
( O
as O
in O
[ O
reference O
][ O
reference O
] O
) O
and O
512 O
for O
FPN Method
( O
as O
in O
[ O
reference O
] O
) O
. O
We O
train O
on O
8 O
GPUs Method
( O
so O
effective O
minibatch O
size O
is O
16 O
) O
for O
160k O
iterations O
, O
with O
a O
learning Metric
rate Metric
of O
0.02 O
which O
is O
decreased O
by O
10 O
at O
the O
120k O
iteration O
. O
We O
use O
a O
weight O
decay O
of O
0.0001 O
and O
momentum O
of O
0.9 O
. O
With O
ResNeXt Method
[ O
reference O
] O
, O
we O
train O
with O
1 O
image O
per O
GPU O
and O
the O
same O
number O
of O
iterations O
, O
with O
a O
starting O
learning Metric
rate Metric
of O
0.01 O
. O
The O
RPN O
anchors O
span O
5 O
scales O
and O
3 O
aspect O
ratios O
, O
following O
[ O
reference O
] O
. O
For O
convenient O
ablation O
, O
RPN Method
is O
trained O
separately O
and O
does O
not O
share O
features O
with O
Mask Method
R Method
- Method
CNN Method
, O
unless O
specified O
. O
For O
every O
entry O
in O
this O
paper O
, O
RPN Method
and O
Mask Method
R Method
- Method
CNN Method
have O
the O
same O
backbones O
and O
so O
they O
are O
shareable O
. O
Inference Task
: O
At O
test O
time O
, O
the O
proposal O
number O
is O
300 O
for O
the O
C4 Method
backbone Method
( O
as O
in O
[ O
reference O
] O
) O
and O
1000 O
for O
FPN Method
( O
as O
in O
[ O
reference O
] O
) O
. O
We O
run O
the O
box Method
prediction Method
branch Method
on O
these O
proposals O
, O
followed O
by O
non Method
- Method
maximum Method
suppression Method
[ O
reference O
] O
. O
The O
mask O
branch O
is O
then O
applied O
to O
the O
highest O
scoring O
100 O
detection O
boxes O
. O
Although O
this O
differs O
from O
the O
parallel Method
computation Method
used O
in O
training Task
, O
it O
speeds O
up O
inference Task
and O
improves O
accuracy Metric
( O
due O
to O
the O
use O
of O
fewer O
, O
more O
accurate O
RoIs O
) O
. O
The O
mask O
branch O
can O
predict O
K O
masks O
per O
RoI O
, O
but O
we O
only O
use O
the O
k O
- O
th O
mask O
, O
where O
k O
is O
the O
predicted O
class O
by O
the O
classification O
branch O
. O
The O
m×m O
floating O
- O
number O
mask O
output O
is O
then O
resized O
to O
the O
RoI O
size O
, O
and O
binarized O
at O
a O
threshold O
of O
0.5 O
. O
Note O
that O
since O
we O
only O
compute O
masks O
on O
the O
top O
100 O
detection O
boxes O
, O
Mask Method
R Method
- Method
CNN Method
adds O
a O
small O
overhead O
to O
its O
Faster O
R Method
- Method
CNN Method
counterpart O
( O
e.g. O
, O
∼20 O
% O
on O
typical O
models O
) O
. O
section O
: O
Experiments O
: O
Instance Task
Segmentation Task
We O
perform O
a O
thorough O
comparison O
of O
Mask Method
R Method
- Method
CNN Method
to O
the O
state O
of O
the O
art O
along O
with O
comprehensive O
ablations O
on O
the O
COCO Material
dataset O
[ O
reference O
] O
. O
We O
report O
the O
standard O
COCO Material
metrics O
including O
AP Metric
( O
averaged O
over O
IoU Metric
thresholds Metric
) O
, O
AP Metric
50 O
, O
AP Metric
75 O
, O
and O
AP Metric
S O
, O
AP Metric
M O
, O
AP Metric
L O
( O
AP Metric
at O
different O
scales O
) O
. O
Unless O
noted O
, O
AP Metric
is O
evaluating O
using O
mask Metric
IoU. Metric
As O
in O
previous O
work O
[ O
reference O
][ O
reference O
] O
, O
we O
train O
using O
the O
union O
of O
80k O
train O
images O
and O
a O
35k O
subset O
of O
val O
images O
( O
trainval35k O
) O
, O
and O
report O
ablations Method
on O
the O
remaining O
5k O
val O
images O
( O
minival O
) O
. O
We O
also O
report O
results O
on O
test O
- O
dev O
[ O
reference O
] O
. O
section O
: O
Main O
Results O
We O
compare O
Mask Method
R Method
- Method
CNN Method
to O
the O
state O
- O
of O
- O
the O
- O
art O
methods O
in O
instance Task
segmentation Task
in O
Table O
1 O
. O
All O
instantiations O
of O
our O
model O
outperform O
baseline O
variants O
of O
previous O
state O
- O
of O
- O
the Method
- Method
art Method
models Method
. O
This O
includes O
MNC Method
[ O
reference O
] O
and O
FCIS Method
[ O
reference O
] O
, O
the O
winners O
of O
the O
COCO Material
2015 O
and O
2016 O
segmentation Task
challenges O
, O
respectively O
. O
Without O
bells O
and O
whistles O
, O
Mask Method
R Method
- Method
CNN Method
with O
ResNet Method
- Method
101 Method
- Method
FPN Method
backbone Method
outperforms O
FCIS Method
+++ Method
[ O
reference O
] O
, O
which O
includes O
multi O
- O
scale Metric
train Metric
/ Metric
test Metric
, O
horizontal Metric
flip Metric
test Metric
, O
and O
online Task
hard Task
example Task
mining Task
( O
OHEM Method
) O
[ O
reference O
] O
. O
While O
outside O
the O
scope O
of O
this O
work O
, O
we O
expect O
many O
such O
improvements O
to O
be O
applicable O
to O
ours O
. O
Mask Method
R Method
- Method
CNN Method
outputs O
are O
visualized O
in O
Figures O
2 O
and O
5 O
. O
Mask Method
R Method
- Method
CNN Method
achieves O
good O
results O
even O
under O
challenging O
conditions O
. O
In O
Figure O
6 O
we O
compare O
our O
Mask Method
R Method
- Method
CNN Method
baseline O
and O
FCIS Method
+++ Method
[ O
reference O
] O
. O
FCIS Method
+++ Method
exhibits O
systematic O
artifacts O
on O
overlapping O
instances O
, O
suggesting O
that O
it O
is O
challenged O
by O
the O
fundamental O
difficulty O
of O
instance Task
segmentation Task
. O
Mask Method
R Method
- Method
CNN Method
shows O
no O
such O
artifacts O
. O
Table O
2 O
. O
Ablations Method
. O
We O
train O
on O
trainval35k Method
, O
test O
on O
minival Method
, O
and O
report O
mask Method
AP Method
unless O
otherwise O
noted O
. O
section O
: O
Ablation Task
Experiments O
We O
run O
a O
number O
of O
ablations Method
to O
analyze O
Mask Method
R Method
- Method
CNN Method
. O
Results O
are O
shown O
in O
Table O
2 O
and O
discussed O
in O
detail O
next O
. O
Architecture O
: O
Table O
2a O
shows O
Mask Method
R Method
- Method
CNN Method
with O
various O
backbones O
. O
It O
benefits O
from O
deeper Method
networks Method
( O
50 O
vs. O
101 O
) O
and O
advanced O
designs O
including O
FPN Method
and O
ResNeXt Method
. O
We O
note O
that O
not O
all O
frameworks O
automatically O
benefit O
from O
deeper O
or O
advanced O
networks O
( O
see O
benchmarking O
in O
[ O
reference O
] O
) O
. O
Multinomial O
vs. O
Independent O
Masks O
: O
Mask Method
R Method
- Method
CNN Method
decouples O
mask Task
and Task
class Task
prediction Task
: O
as O
the O
existing O
box O
branch O
predicts O
the O
class O
label O
, O
we O
generate O
a O
mask O
for O
each O
class O
without O
competition O
among O
classes O
( O
by O
a O
per Method
- Method
pixel Method
sigmoid Method
and O
a O
binary O
loss O
) O
. O
In O
Table O
2b O
, O
we O
compare O
this O
to O
using O
a O
per Method
- Method
pixel Method
softmax Method
and O
a O
multinomial O
loss O
( O
as O
commonly O
used O
in O
FCN Method
[ O
reference O
] O
) O
. O
This O
alternative O
couples O
the O
tasks O
of O
mask Task
and Task
class Task
prediction Task
, O
and O
results O
in O
a O
severe O
loss O
in O
mask Method
AP Method
( O
5.5 O
points O
) O
. O
This O
suggests O
that O
once O
the O
instance O
has O
been O
classified O
as O
a O
whole O
( O
by O
the O
box O
branch O
) O
, O
it O
is O
sufficient O
to O
predict O
a O
binary O
mask O
without O
concern O
for O
the O
categories O
, O
which O
makes O
the O
model O
easier O
to O
train O
. O
Class O
- O
Specific O
vs. O
Class Method
- Method
Agnostic Method
Masks Method
: O
Our O
default Method
instantiation Method
predicts O
class O
- O
specific O
masks O
, O
i.e. O
, O
one O
m×m O
mask O
per O
class O
. O
Interestingly O
, O
Mask Method
R Method
- Method
CNN Method
with O
classagnostic O
masks O
( O
i.e. O
, O
predicting O
a O
single O
m×m O
output O
regardless O
of O
class O
) O
is O
nearly O
as O
effective O
: O
it O
has O
29.7 O
mask O
AP Metric
vs. O
30.3 O
for O
the O
class Method
- Method
specific Method
counterpart Method
on O
ResNet Method
- Method
50 Method
- Method
C4 Method
. O
This O
further O
highlights O
the O
division O
of O
labor O
in O
our O
approach O
which O
largely O
decouples O
classification Task
and O
segmentation Task
. O
RoIAlign Method
: O
An O
evaluation O
of O
our O
proposed O
RoIAlign Method
layer Method
is O
shown O
in O
Table O
2c O
. O
For O
this O
experiment O
we O
use O
the O
ResNet O
- O
50 O
- O
C4 O
backbone O
, O
which O
has O
stride O
16 O
. O
RoIAlign Method
improves O
AP Metric
by O
about O
3 O
points O
over O
RoIPool Method
, O
with O
much O
of O
the O
gain O
coming O
at O
high O
IoU Metric
( O
AP Metric
75 O
) O
. O
RoIAlign Method
is O
insensitive O
to O
max O
/ O
average O
pool O
; O
we O
use O
average O
in O
the O
rest O
of O
the O
paper O
. O
Additionally O
, O
we O
compare O
with O
RoIWarp Method
proposed O
in O
MNC Method
[ O
reference O
] O
that O
also O
adopt O
bilinear Method
sampling Method
. O
As O
discussed O
in O
§ O
3 O
, O
RoIWarp O
still O
quantizes O
the O
RoI O
, O
losing O
alignment O
with O
the O
input O
. O
As O
can O
be O
seen O
in O
Table O
2c O
, O
RoIWarp Method
performs O
on O
par O
with O
RoIPool Method
and O
much O
worse O
than O
RoIAlign Method
. O
This O
highlights O
that O
proper O
alignment Task
is O
key O
. O
We O
also O
evaluate O
RoIAlign Method
with O
a O
ResNet Method
- Method
50 Method
- Method
C5 Method
backbone Method
, O
which O
has O
an O
even O
larger O
stride O
of O
32 O
pixels O
. O
We O
use O
the O
same O
head O
as O
in O
Figure O
4 O
( O
right O
) O
, O
as O
the O
res5 O
head O
is O
not O
applicable O
. O
( O
50 O
% O
relative O
improvement O
) O
. O
Moreover O
, O
we O
note O
that O
with O
RoIAlign O
, O
using O
stride O
- O
32 O
C5 O
features O
( O
30.9 O
AP Metric
) O
is O
more O
accurate O
than O
using O
stride O
- O
16 O
C4 O
features O
( O
30.3 O
AP Metric
, O
Table O
2c O
) O
. O
RoIAlign Method
largely O
resolves O
the O
long O
- O
standing O
challenge O
of O
using O
large Task
- Task
stride Task
features Task
for O
detection O
and O
segmentation Task
. O
Finally O
, O
RoIAlign Method
shows O
a O
gain O
of O
1.5 O
mask Method
AP Method
and O
0.5 O
box Metric
AP Metric
when O
used O
with O
FPN Method
, O
which O
has O
finer O
multi O
- O
level O
strides O
. O
For O
keypoint Task
detection Task
that O
requires O
finer Task
alignment Task
, O
RoIAlign O
shows O
large O
gains O
even O
with O
FPN Method
( O
Table O
6 O
) O
. O
Mask O
Branch O
: O
Segmentation Task
is O
a O
pixel Task
- Task
to Task
- Task
pixel Task
task Task
and O
we O
exploit O
the O
spatial O
layout O
of O
masks O
by O
using O
an O
FCN Method
. O
In O
Table O
2e O
, O
we O
compare O
multi Method
- Method
layer Method
perceptrons Method
( O
MLP Method
) O
and O
FCNs Method
, O
using O
a O
ResNet Method
- Method
50 Method
- Method
FPN Method
backbone Method
. O
Using O
FCNs Method
gives O
a O
2.1 O
mask O
AP Metric
gain O
over O
MLPs Method
. O
We O
note O
that O
we O
choose O
this O
backbone O
so O
that O
the O
conv O
layers O
of O
the O
FCN Method
head Method
are O
not O
pre O
- O
trained O
, O
for O
a O
fair O
comparison O
with O
MLP Method
. O
section O
: O
Bounding Task
Box Task
Detection Task
Results O
We O
compare O
Mask Method
R Method
- Method
CNN Method
to O
the O
state O
- O
of O
- O
the O
- O
art O
COCO Task
bounding Task
- Task
box Task
object Task
detection Task
in O
Table O
3 O
. O
For O
this O
result O
, O
even O
though O
the O
full O
Mask Method
R Method
- Method
CNN Method
model O
is O
trained O
, O
only O
the O
classification O
and O
box O
outputs O
are O
used O
at O
inference Task
( O
the O
mask O
output O
is O
ignored O
) O
. O
Mask Method
R Method
- Method
CNN Method
using O
ResNet Method
- Method
101 Method
- Method
FPN Method
outperforms O
the O
base O
variants O
of O
all O
previous O
state O
- O
ofthe O
- O
art O
models O
, O
including O
the O
single Method
- Method
model Method
variant Method
of O
G Method
- Method
RMI Method
[ O
reference O
] O
, O
the O
winner O
of O
the O
COCO Material
2016 O
Detection O
Challenge O
. O
Using O
ResNeXt Method
- Method
101 Method
- Method
FPN Method
, O
Mask Method
R Method
- Method
CNN Method
further O
improves O
results O
, O
with O
a O
margin O
of O
3.0 O
points O
box O
AP Metric
over O
the O
best O
previous O
single O
model O
entry O
from O
[ O
reference O
] O
( O
which O
used O
Inception O
- O
ResNet O
- O
v2 O
- O
TDM O
) O
. O
As O
a O
further O
comparison O
, O
we O
trained O
a O
version O
of O
Mask Method
R Method
- Method
CNN Method
but O
without O
the O
mask O
branch O
, O
denoted O
by O
" O
Faster O
R Method
- Method
CNN Method
, O
RoIAlign Method
" O
in O
Table O
3 O
. O
This O
model O
performs O
better O
than O
the O
model O
presented O
in O
[ O
reference O
] O
due O
to O
RoIAlign O
. O
On O
the O
other O
hand O
, O
it O
is O
0.9 O
points O
box O
AP Metric
lower O
than O
Mask Method
R Method
- Method
CNN Method
. O
This O
gap O
of O
Mask Method
R Method
- Method
CNN Method
on O
box Task
detection Task
is O
therefore O
due O
solely O
to O
the O
benefits O
of O
multi Task
- Task
task Task
training Task
. O
Lastly O
, O
we O
note O
that O
Mask Method
R Method
- Method
CNN Method
attains O
a O
small O
gap O
between O
its O
mask O
and O
box O
AP Metric
: O
e.g. O
, O
2.7 O
points O
between O
37.1 O
( O
mask O
, O
Table O
1 O
) O
and O
39.8 O
( O
box O
, O
Table O
3 O
) O
. O
This O
indicates O
that O
our O
approach O
largely O
closes O
the O
gap O
between O
object Task
detection Task
and O
the O
more O
challenging O
instance O
segmentation Task
task O
. O
section O
: O
Timing O
Inference Task
: O
We O
train O
a O
ResNet Method
- Method
101 Method
- Method
FPN Method
model Method
that O
shares O
features O
between O
the O
RPN O
and O
Mask Method
R Method
- Method
CNN Method
stages O
, O
following O
the O
4 Method
- Method
step Method
training Method
of O
Faster O
R Method
- Method
CNN Method
[ O
reference O
] O
. O
This O
model O
runs O
at O
195ms O
per O
image O
on O
an O
Nvidia Material
Tesla Material
M40 Material
GPU Material
( O
plus O
15ms O
CPU O
time O
resizing O
the O
outputs O
to O
the O
original O
resolution O
) O
, O
and O
achieves O
statistically O
the O
same O
mask O
AP Metric
as O
the O
unshared O
one O
. O
We O
also O
report O
that O
the O
ResNet Method
- Method
101 Method
- Method
C4 Method
variant Method
takes O
∼400ms O
as O
it O
has O
a O
heavier O
box O
head O
( O
Figure O
4 O
) O
, O
so O
we O
do O
not O
recommend O
using O
the O
C4 Method
variant Method
in O
practice O
. O
Although O
Mask Method
R Method
- Method
CNN Method
is O
fast O
, O
we O
note O
that O
our O
design O
is O
not O
optimized O
for O
speed Metric
, O
and O
better O
speed Metric
/ Metric
accuracy Metric
tradeoffs Metric
could O
be O
achieved O
[ O
reference O
] O
, O
e.g. O
, O
by O
varying O
image O
sizes O
and O
proposal O
numbers O
, O
which O
is O
beyond O
the O
scope O
of O
this O
paper O
. O
Training O
: O
Mask Method
R Method
- Method
CNN Method
is O
also O
fast O
to O
train O
. O
Training Task
with O
ResNet Method
- Method
50 Method
- Method
FPN Method
on O
COCO Material
trainval35k O
takes O
32 O
hours O
in O
our O
synchronized Method
8 Method
- Method
GPU Method
implementation Method
( O
0.72s O
per O
16 O
- O
image O
mini O
- O
batch O
) O
, O
and O
44 O
hours O
with O
ResNet Method
- Method
101 Method
- Method
FPN Method
. O
In O
fact O
, O
fast Task
prototyping Task
can O
be O
completed O
in O
less O
than O
one O
day O
when O
training O
on O
the O
train O
set O
. O
We O
hope O
such O
rapid O
training O
will O
remove O
a O
major O
hurdle O
in O
this O
area O
and O
encourage O
more O
people O
to O
perform O
research O
on O
this O
challenging O
topic O
. O
section O
: O
Mask Method
R Method
- Method
CNN Method
for O
Human Task
Pose Task
Estimation Task
Our O
framework O
can O
easily O
be O
extended O
to O
human Task
pose Task
estimation Task
. O
We O
model O
a O
keypoint O
's O
location O
as O
a O
one O
- O
hot O
mask O
, O
and O
adopt O
Mask Method
R Method
- Method
CNN Method
to O
predict O
K O
masks O
, O
one O
for O
each O
of O
K O
keypoint O
types O
( O
e.g. O
, O
left O
shoulder O
, O
right O
elbow O
) O
. O
This O
task O
helps O
demonstrate O
the O
flexibility O
of O
Mask Method
R Method
- Method
CNN Method
. O
We O
note O
that O
minimal O
domain O
knowledge O
for O
human Task
pose Task
is O
exploited O
by O
our O
system O
, O
as O
the O
experiments O
are O
mainly O
to O
demonstrate O
the O
generality O
of O
the O
Mask Method
R Method
- Method
CNN Method
framework O
. O
We O
expect O
that O
domain O
knowledge O
( O
e.g. O
, O
modeling O
structures O
[ O
reference O
] O
) O
will O
be O
complementary O
to O
our O
simple O
approach O
. O
Implementation O
Details O
: O
We O
make O
minor O
modifications O
to O
the O
segmentation Task
system O
when O
adapting O
it O
for O
keypoints Task
. O
For O
each O
of O
the O
K O
keypoints Task
of O
an O
instance O
, O
the O
training O
target O
is O
a O
one O
- O
hot O
m O
× O
m O
binary O
mask O
where O
only O
a O
single O
pixel O
is O
labeled O
as O
foreground O
. O
During O
training Task
, O
for O
each O
visible O
ground O
- O
truth O
keypoint O
, O
we O
minimize O
the O
cross Metric
- Metric
entropy Metric
loss Metric
over O
an O
m O
2 O
- O
way O
softmax O
output O
( O
which O
encourages O
a O
Table O
4 O
. O
Keypoint O
detection O
AP Metric
on O
COCO Material
test O
- O
dev O
. O
Ours O
is O
a O
single O
model O
( O
ResNet Method
- Method
50 Method
- Method
FPN Method
) O
that O
runs O
at O
5 O
fps O
. O
CMU Method
- Method
Pose Method
+++ Method
[ O
reference O
] O
is O
the O
2016 O
competition O
winner O
that O
uses O
multi Task
- Task
scale Task
testing Task
, O
post Method
- Method
processing Method
with O
CPM Method
[ O
reference O
] O
, O
and O
filtering Method
with O
an O
object Method
detector Method
, O
adding O
a O
cumulative O
∼5 O
points O
( O
clarified O
in O
personal O
communication O
) O
. O
† O
: O
G Method
- Method
RMI Method
was O
trained O
on O
COCO Material
plus O
MPII O
[ O
reference O
] O
( O
25k O
images O
) O
, O
using O
two O
models O
( O
Inception Method
- Method
ResNet Method
- Method
v2 Method
for O
bounding Task
box Task
detection Task
and O
ResNet Method
- Method
101 Method
for O
keypoints Task
) O
. O
single O
point O
to O
be O
detected O
) O
. O
We O
note O
that O
as O
in O
instance Task
segmentation Task
, O
the O
K O
keypoints Task
are O
still O
treated O
independently O
. O
We O
adopt O
the O
ResNet Method
- Method
FPN Method
variant Method
, O
and O
the O
keypoint Method
head Method
architecture Method
is O
similar O
to O
that O
in O
Figure O
4 O
( O
right O
) O
. O
The O
keypoint O
head O
consists O
of O
a O
stack O
of O
eight O
3×3 Method
512 Method
- Method
d Method
conv Method
layers Method
, O
followed O
by O
a O
deconv Method
layer Method
and O
2× Method
bilinear Method
upscaling Method
, O
producing O
an O
output O
resolution Metric
of O
56×56 O
. O
We O
found O
that O
a O
relatively O
high O
resolution O
output O
( O
compared O
to O
masks O
) O
is O
required O
for O
keypoint Metric
- Metric
level Metric
localization Metric
accuracy Metric
. O
Models O
are O
trained O
on O
all O
COCO Material
trainval35k O
images O
that O
contain O
annotated O
keypoints Task
. O
To O
reduce O
overfitting O
, O
as O
this O
training O
set O
is O
smaller O
, O
we O
train O
using O
image O
scales O
randomly O
sampled O
from O
[ O
640 O
, O
800 O
] O
pixels O
; O
inference O
is O
on O
a O
single O
scale O
of O
800 O
pixels O
. O
We O
train O
for O
90k O
iterations O
, O
starting O
from O
a O
learning Metric
rate Metric
of O
0.02 O
and O
reducing O
it O
by O
10 O
at O
60k O
and O
80k O
iterations O
. O
We O
use O
bounding Method
- Method
box Method
NMS Method
with O
a O
threshold O
of O
0.5 O
. O
Other O
details O
are O
identical O
as O
in O
§ O
3.1 O
. O
section O
: O
Main O
Results O
and O
Ablations O
: O
We O
evaluate O
the O
person O
keypoint O
AP Metric
( O
AP Metric
kp Metric
) O
and O
experiment O
with O
a O
ResNet Method
- Method
50 Method
- Method
FPN Method
backbone Method
; O
more O
backbones O
will O
be O
studied O
in O
the O
appendix O
. O
Table O
4 O
shows O
that O
our O
result O
( O
62.7 O
AP Metric
kp O
) O
is O
0.9 O
points O
higher O
than O
the O
COCO Material
2016 O
keypoint Task
detection Task
winner O
[ O
reference O
] O
that O
uses O
a O
multi Method
- Method
stage Method
processing Method
pipeline Method
( O
see O
caption O
of O
Table O
4 O
) O
. O
Our O
method O
is O
considerably O
simpler O
and O
faster O
. O
More O
importantly O
, O
we O
have O
a O
unified O
model O
that O
can O
si O
- O
Table O
5 O
. O
Multi Task
- Task
task Task
learning Task
of Task
box Task
, O
mask O
, O
and O
keypoint O
about O
the O
person O
category O
, O
evaluated O
on O
minival Method
. O
All O
entries O
are O
trained O
on O
the O
same O
data O
for O
fair O
comparisons O
. O
The O
backbone O
is O
ResNet O
- O
50 O
- O
FPN O
. O
The O
entries O
with O
64.2 O
and O
64.7 O
AP Metric
on O
minival Method
have O
test O
- O
dev O
AP Metric
of O
62.7 O
and O
63.1 O
, O
respectively O
( O
see O
Table O
4 O
) O
. O
multaneously O
predict O
boxes O
, O
segments O
, O
and O
keypoints Task
while O
running O
at O
5 O
fps O
. O
Adding O
a O
segment O
branch O
( O
for O
the O
person O
category O
) O
improves O
the O
AP Metric
kp Metric
to O
63.1 O
( O
Table O
4 O
) O
on O
test O
- O
dev O
. O
More O
ablations O
of O
multi Task
- Task
task Task
learning Task
on O
minival Task
are O
in O
Table O
5 O
. O
Adding O
the O
mask O
branch O
to O
the O
box Method
- Method
only Method
( O
i.e. O
, O
Faster O
R Method
- Method
CNN Method
) O
or O
keypoint Method
- Method
only Method
versions Method
consistently O
improves O
these O
tasks O
. O
However O
, O
adding O
the O
keypoint O
branch O
reduces O
the O
box O
/ O
mask O
AP Metric
slightly O
, O
suggesting O
that O
while O
keypoint Task
detection Task
benefits O
from O
multitask Method
training Method
, O
it O
does O
not O
in O
turn O
help O
the O
other O
tasks O
. O
Nevertheless O
, O
learning O
all O
three O
tasks O
jointly O
enables O
a O
unified O
system O
to O
efficiently O
predict O
all O
outputs O
simultaneously O
( O
Figure O
7 O
) O
. O
We O
also O
investigate O
the O
effect O
of O
RoIAlign O
on O
keypoint Task
detection Task
( O
Table O
6 O
) O
. O
Though O
this O
ResNet Method
- Method
50 Method
- Method
FPN Method
backbone Method
has O
finer O
strides O
( O
e.g. O
, O
4 O
pixels O
on O
the O
finest O
level O
) O
, O
RoIAlign O
still O
shows O
significant O
improvement O
over O
RoIPool Method
and O
increases O
AP Metric
kp Metric
by O
4.4 O
points O
. O
This O
is O
because O
keypoint Method
detections Method
are O
more O
sensitive O
to O
localization Metric
accuracy Metric
. O
This O
again O
indicates O
that O
alignment Task
is O
essential O
for O
pixel Task
- Task
level Task
localization Task
, O
including O
masks O
and O
keypoints Task
. O
Given O
the O
effectiveness O
of O
Mask Method
R Method
- Method
CNN Method
for O
extracting Task
object Task
bounding Task
boxes Task
, O
masks O
, O
and O
keypoints Task
, O
we O
expect O
it O
be O
an O
effective O
framework O
for O
other O
instance Task
- Task
level Task
tasks Task
. O
section O
: O
Appendix O
A O
: O
Experiments O
on O
Cityscapes Material
We O
further O
report O
instance Task
segmentation Task
results O
on O
the O
Cityscapes Material
[ O
reference O
] O
dataset O
. O
This O
dataset O
has O
fine O
annotations O
for O
2975 O
train O
, O
500 O
val O
, O
and O
1525 O
test O
images O
. O
It O
has O
20k O
coarse O
training O
images O
without O
instance O
annotations O
, O
which O
we O
do O
not O
use O
. O
All O
images O
are O
2048×1024 O
pixels O
. O
The O
instance O
segmentation Task
task O
involves O
8 O
object O
categories O
, O
whose O
numbers O
of O
instances O
on O
the O
fine O
training O
set O
are O
: O
Instance O
segmentation Task
performance O
on O
this O
task O
is O
measured O
by O
the O
COCO Material
- O
style O
mask O
AP Metric
( O
averaged O
over O
IoU O
thresholds O
) O
; O
AP Metric
50 O
( O
i.e. O
, O
mask Method
AP Method
at O
an O
IoU O
of O
0.5 O
) O
is O
also O
reported O
. O
Implementation O
: O
We O
apply O
our O
Mask Method
R Method
- Method
CNN Method
models O
with O
the O
ResNet Method
- Method
FPN Method
- Method
50 Method
backbone Method
; O
we O
found O
the O
101 O
- O
layer O
counterpart O
performs O
similarly O
due O
to O
the O
small O
dataset O
size O
. O
We O
train O
with O
image O
scale O
( O
shorter O
side O
) O
randomly O
sampled O
from O
[ O
800 O
, O
1024 O
] O
, O
which O
reduces O
overfitting O
; O
inference Task
is O
on O
a O
single O
scale O
of O
1024 O
pixels O
. O
We O
use O
a O
mini O
- O
batch O
size O
of O
1 O
image O
per O
GPU O
( O
so O
8 O
on O
8 O
GPUs O
) O
and O
train O
the O
model O
for O
24k O
iterations O
, O
starting O
from O
a O
learning Metric
rate Metric
of O
0.01 O
and O
reducing O
it O
to O
0.001 O
at O
18k O
iterations O
. O
It O
takes O
∼4 O
hours O
of O
training O
on O
a O
single O
8 Method
- Method
GPU Method
machine Method
under O
this O
setting O
. O
Results O
: O
Table O
7 O
compares O
our O
results O
to O
the O
state O
of O
the O
art O
on O
the O
val O
and O
test O
sets O
. O
Without O
using O
the O
coarse O
training O
set O
, O
our O
method O
achieves O
26.2 O
AP Metric
on O
test O
, O
which O
is O
over O
30 O
% O
relative O
improvement O
over O
the O
previous O
best O
entry O
( O
DIN O
[ O
reference O
] O
) O
, O
and O
is O
also O
better O
than O
the O
concurrent O
work O
of O
SGN Method
's Method
25.0 Method
[ O
reference O
] O
. O
Both O
DIN Method
and O
SGN Method
use O
fine O
+ O
coarse O
data O
. O
Compared O
to O
the O
best O
entry O
using O
fine O
data O
only O
( O
17.4 O
AP Metric
) O
, O
we O
achieve O
a O
∼50 O
% O
improvement O
. O
For O
the O
person Task
and Task
car Task
categories Task
, O
the O
Cityscapes Material
dataset O
exhibits O
a O
large O
number O
of O
within O
- O
category O
overlapping O
instances O
( O
on O
average O
6 O
people O
and O
9 O
cars O
per O
image O
) O
. O
We O
argue O
that O
within O
- O
category O
overlap O
is O
a O
core O
difficulty O
of O
instance Task
segmentation Task
. O
Our O
method O
shows O
massive O
improvement O
on O
these O
two O
categories O
over O
the O
other O
best O
entries O
( O
relative O
∼40 O
% O
improvement O
on O
person O
from O
21.8 O
to O
30.5 O
and O
∼20 O
% O
improvement O
on O
car Task
from O
39.4 O
to O
46.9 O
) O
, O
even O
though O
our O
method O
does O
not O
exploit O
the O
coarse O
data O
. O
A O
main O
challenge O
of O
the O
Cityscapes Material
dataset O
is O
training O
models O
in O
a O
low Task
- Task
data Task
regime Task
, O
particularly O
for O
the O
categories O
of O
truck O
, O
bus O
, O
and O
train Task
, O
which O
have O
about O
200 O
- O
500 O
train O
- O
ing O
samples O
each O
. O
To O
partially O
remedy O
this O
issue O
, O
we O
further O
report O
a O
result O
using O
COCO Material
pre O
- O
training O
. O
To O
do O
this O
, O
we O
initialize O
the O
corresponding O
7 O
categories O
in O
Cityscapes Material
from O
a O
pre O
- O
trained O
COCO Material
Mask Method
R Method
- Method
CNN Method
model O
( O
rider O
being O
randomly O
initialized O
) O
. O
We O
fine O
- O
tune O
this O
model O
for O
4k O
iterations O
in O
which O
the O
learning Metric
rate Metric
is O
reduced O
at O
3k O
iterations O
, O
which O
takes O
∼1 O
hour O
for O
training O
given O
the O
COCO Material
model O
. O
The O
COCO Material
pre O
- O
trained O
Mask Method
R Method
- Method
CNN Method
model O
achieves O
32.0 O
AP Metric
on O
test O
, O
almost O
a O
6 O
point O
improvement O
over O
the O
fine Method
- Method
only Method
counterpart Method
. O
This O
indicates O
the O
important O
role O
the O
amount O
of O
training O
data O
plays O
. O
It O
also O
suggests O
that O
methods O
on O
Cityscapes Material
might O
be O
influenced O
by O
their O
lowshot Metric
learning Metric
performance Metric
. O
We O
show O
that O
using O
COCO Material
pretraining O
is O
an O
effective O
strategy O
on O
this O
dataset O
. O
Finally O
, O
we O
observed O
a O
bias O
between O
the O
val O
and O
test O
AP Metric
, O
as O
is O
also O
observed O
from O
the O
results O
of O
[ O
reference O
][ O
reference O
][ O
reference O
] O
. O
We O
found O
that O
this O
bias O
is O
mainly O
caused O
by O
the O
truck O
, O
bus O
, O
and O
train O
categories O
, O
with O
the O
fine Method
- Method
only Method
model Method
having O
val O
/ O
test O
AP Metric
of O
28.8 O
/ O
22.8 O
, O
53.5 O
/ O
32.2 O
, O
and O
33.0 O
/ O
18.6 O
, O
respectively O
. O
This O
suggests O
that O
there O
is O
a O
domain O
shift O
on O
these O
categories O
, O
which O
also O
have O
little O
training O
data O
. O
COCO Material
pre O
- O
training O
helps O
to O
improve O
results O
the O
most O
on O
these O
categories O
; O
however O
, O
the O
domain O
shift O
persists O
with O
38.0 O
/ O
30.1 O
, O
57.5 O
/ O
40.9 O
, O
and O
41.2 O
/ O
30.9 O
val O
/ O
test O
AP Metric
, O
respectively O
. O
Note O
that O
for O
the O
person O
and O
car O
categories O
we O
do O
not O
see O
any O
such O
bias O
( O
val O
/ O
test O
AP Metric
are O
within O
±1 O
point O
) O
. O
Example O
results O
on O
Cityscapes Material
are O
shown O
in O
Figure O
8 O
. O
section O
: O
Appendix O
B O
: O
Enhanced O
Results O
on O
COCO Material
As O
a O
general O
framework O
, O
Mask Method
R Method
- Method
CNN Method
is O
compatible O
with O
complementary O
techniques O
developed O
for O
detection O
/ O
segmentation Task
, O
including O
improvements O
made O
to O
Fast O
/ O
Faster O
R Method
- Method
CNN Method
and O
FCNs Method
. O
In O
this O
appendix O
we O
describe O
some O
techniques O
that O
improve O
over O
our O
original O
results O
. O
Thanks O
to O
its O
generality O
and O
flexibility O
, O
Mask Method
R Method
- Method
CNN Method
was O
used O
as O
the O
framework O
by O
the O
three O
winning O
teams O
in O
the O
COCO Material
2017 O
instance O
segmentation Task
competition O
, O
which O
all O
significantly O
outperformed O
the O
previous O
state O
of O
the O
art O
. O
section O
: O
Instance Task
Segmentation Task
and O
Object Task
Detection Task
We O
report O
some O
enhanced O
results O
of O
Mask Method
R Method
- Method
CNN Method
in O
Table O
8 O
. O
Overall O
, O
the O
improvements O
increase O
mask O
AP Metric
5.1 O
points O
( O
from O
36.7 O
to O
41.8 O
) O
and O
box O
AP Metric
7.7 O
points O
( O
from O
39.6 O
to O
47.3 O
) O
. O
Each O
model O
improvement O
increases O
both O
mask Method
AP Method
and O
box Metric
AP Metric
consistently O
, O
showing O
good O
generalization O
of O
the O
Mask Method
R Method
- Method
CNN Method
framework O
. O
We O
detail O
the O
improvements O
next O
. O
These O
results O
, O
along O
with O
future O
updates O
, O
can O
be O
reproduced O
by O
our O
released O
code O
at O
https: O
// O
github.com O
/ O
facebookresearch O
/ O
Detectron O
, O
and O
can O
serve O
as O
higher O
baselines O
for O
future O
research O
. O
Updated O
baseline O
: O
We O
start O
with O
an O
updated O
baseline O
with O
a O
different O
set O
of O
hyper O
- O
parameters O
. O
We O
lengthen O
the O
training O
to O
180k O
iterations O
, O
in O
which O
the O
learning Metric
rate Metric
is O
reduced O
by O
10 O
at O
120k O
and O
160k O
iterations O
. O
We O
also O
change O
the O
NMS O
threshold O
to O
0.5 O
( O
from O
a O
default O
value O
of O
0.3 O
) O
. O
The O
updated O
baseline O
has O
37.0 O
mask O
AP Metric
and O
40.5 O
box O
AP Metric
. O
End Task
- Task
to Task
- Task
end Task
training Task
: O
All O
previous O
results O
used O
stagewise Method
training Method
, O
i.e. O
, O
training O
RPN Method
as O
the O
first O
stage O
and O
Mask Method
R Method
- Method
CNN Method
as O
the O
second O
. O
Following O
[ O
reference O
] O
, O
we O
evaluate O
endto Method
- Method
end Method
( O
' O
e2e Method
' O
) O
training O
that O
jointly O
trains O
RPN Method
and O
Mask Method
R Method
- Method
CNN Method
. O
We O
adopt O
the O
' O
approximate O
' O
version O
in O
[ O
reference O
] O
that O
only O
computes O
partial O
gradients O
in O
the O
RoIAlign O
layer O
by O
ignoring O
the O
gradient O
w.r.t O
. O
RoI O
coordinates O
. O
Table O
8 O
shows O
that O
e2e Method
training O
improves O
mask Method
AP Method
by O
0.6 O
and O
box Metric
AP Metric
by O
1.2 O
. O
ImageNet Task
- Task
5k Task
pre Task
- Task
training Task
: O
Following O
[ O
reference O
] O
, O
we O
experiment O
with O
models O
pre O
- O
trained O
on O
a O
5k O
- O
class O
subset O
of O
ImageNet Material
( O
in O
contrast O
to O
the O
standard O
1k O
- O
class O
subset O
) O
. O
This O
5× O
increase O
in O
pre O
- O
training O
data O
improves O
both O
mask O
and O
box O
1 O
AP Metric
. O
As O
a O
reference O
, O
[ O
reference O
] O
used O
∼250× O
more O
images O
( O
300 O
M O
) O
and O
reported O
a O
2 O
- O
3 O
box O
AP Metric
improvement O
on O
their O
baselines O
. O
Train Method
- Method
time Method
augmentation Method
: O
Scale Method
augmentation Method
at O
train O
time O
further O
improves O
results O
. O
During O
training O
, O
we O
randomly O
sample O
a O
scale O
from O
[ O
640 O
, O
800 O
] O
pixels O
and O
we O
increase O
the O
number O
of O
iterations O
to O
260k O
( O
with O
the O
learning Metric
rate Metric
reduced O
by O
10 O
at O
200k O
and O
240k O
iterations O
) O
. O
Train Method
- Method
time Method
augmentation Method
improves O
mask Method
AP Method
by O
0.6 O
and O
box O
AP Metric
by O
0.8 O
. O
Model Method
architecture Method
: O
By O
upgrading O
the O
101 Method
- Method
layer Method
ResNeXt Method
to O
its O
152 O
- O
layer O
counterpart O
[ O
reference O
] O
, O
we O
observe O
an O
increase O
of O
0.5 O
mask Method
AP Method
and O
0.6 O
box O
AP Metric
. O
This O
shows O
a O
deeper O
model O
can O
still O
improve O
results O
on O
COCO Material
. O
Using O
the O
recently O
proposed O
non Method
- Method
local Method
( O
NL Method
) O
model O
[ O
reference O
] O
, O
we O
achieve O
40.3 O
mask O
AP Metric
and O
45.0 O
box O
AP Metric
. O
This O
result O
is O
without O
test O
- O
time O
augmentation O
, O
and O
the O
method O
runs O
at O
3fps O
on O
an O
Nvidia O
Tesla O
P100 O
GPU O
at O
test O
time O
. O
Test Task
- Task
time Task
augmentation Task
: O
We O
combine O
the O
model O
results O
evaluated O
using O
scales O
of O
[ O
400 O
, O
1200 O
] O
pixels O
with O
a O
step O
of O
100 O
and O
on O
their O
horizontal O
flips O
. O
This O
gives O
us O
a O
singlemodel O
result O
of O
41.8 O
mask O
AP Metric
and O
47.3 O
box O
AP Metric
. O
The O
above O
result O
is O
the O
foundation O
of O
our O
submission O
to O
the O
COCO Material
2017 O
competition O
( O
which O
also O
used O
an O
ensemble O
, O
not O
discussed O
here O
) O
. O
The O
first O
three O
winning O
teams O
for O
the O
instance O
segmentation Task
task O
were O
all O
reportedly O
based O
on O
an O
extension O
of O
the O
Mask Method
R Method
- Method
CNN Method
framework O
. O
section O
: O
Keypoint Task
Detection Task
We O
report O
enhanced O
results O
of O
keypoint Task
detection Task
in O
Table O
9 O
. O
As O
an O
updated O
baseline O
, O
we O
extend O
the O
training Method
schedule Method
to O
130k O
iterations O
in O
which O
the O
learning Metric
rate Metric
is O
reduced O
by O
10 O
at O
100k O
and O
120k O
iterations O
. O
This O
improves O
AP Metric
kp Metric
by O
about O
1 O
point O
. O
Replacing O
ResNet Method
- Method
50 Method
with O
ResNet O
- O
101 O
and O
ResNeXt O
- O
101 O
increases O
AP Metric
kp Metric
to O
66.1 O
and O
67.3 O
, O
respectively O
. O
With O
a O
recent O
method O
called O
data Method
distillation Method
[ O
reference O
] O
, O
we O
are O
able O
to O
exploit O
the O
additional O
120k O
unlabeled O
images O
provided O
by O
COCO Material
. O
In O
brief O
, O
data Task
distillation Task
is O
a O
self Method
- Method
training Method
strategy Method
that O
uses O
a O
model O
trained O
on O
labeled O
data O
to O
predict O
annotations O
on O
unlabeled O
images O
, O
and O
in O
turn O
updates O
the O
model O
with O
these O
new O
annotations O
. O
Mask Method
R Method
- Method
CNN Method
provides O
an O
effective O
framework O
for O
such O
a O
self Method
- Method
training Method
strategy Method
. O
With O
data Method
distillation Method
, O
Mask Method
R Method
- Method
CNN Method
AP Metric
kp O
improve O
by O
1.8 O
points O
to O
69.1 O
. O
We O
observe O
that O
Mask Method
R Method
- Method
CNN Method
can O
benefit O
from O
extra O
data O
, O
even O
if O
that O
data O
is O
unlabeled O
. O
By O
using O
the O
same O
test O
- O
time O
augmentation O
as O
used O
for O
instance Task
segmentation Task
, O
we O
further O
boost O
AP Metric
kp Metric
to O
70.4 O
. O
section O
: O
section O
: O
Acknowledgements O
: O
We O
would O
like O
to O
acknowledge O
Ilija O
Radosavovic O
for O
contributions O
to O
code O
release O
and O
enhanced O
results O
, O
and O
the O
Caffe2 O
team O
for O
engineering O
support O
. O
section O
: O
