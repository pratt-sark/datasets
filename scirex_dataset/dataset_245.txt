document	O
:	O
Pythia	Method
v0.1	Method
:	O
the	O
Winning	O
Entry	O
to	O
the	O
VQA	Task
Challenge	Task
2018	O
This	O
document	O
describes	O
Pythia	Method
v0.1	Method
,	O
the	O
winning	O
entry	O
from	O
Facebook	O
AI	O
Research	O
(	O
FAIR	O
)	O
’s	O
A	O
-	O
STAR	O
team	O
to	O
the	O
VQA	Task
Challenge	Task
2018	O
.	O
Our	O
starting	O
point	O
is	O
a	O
modular	O
re	O
-	O
implementation	O
of	O
the	O
bottom	Method
-	Method
up	Method
top	Method
-	Method
down	Method
(	Method
up	Method
-	Method
down	Method
)	Method
model	Method
.	O
We	O
demonstrate	O
that	O
by	O
making	O
subtle	O
but	O
important	O
changes	O
to	O
the	O
model	Method
architecture	Method
and	O
the	O
learning	Metric
rate	Metric
schedule	Metric
,	O
fine	O
-	O
tuning	O
image	O
features	O
,	O
and	O
adding	O
data	Method
augmentation	Method
,	O
we	O
can	O
significantly	O
improve	O
the	O
performance	O
of	O
the	O
up	Method
-	Method
down	Method
model	Method
on	O
VQA	Material
v2.0	Material
dataset	Material
–	O
from	O
65.67	O
%	O
to	O
70.24	O
%	O
.	O
Furthermore	O
,	O
by	O
using	O
a	O
diverse	O
ensemble	O
of	O
models	O
trained	O
with	O
different	O
features	O
and	O
on	O
different	O
datasets	O
,	O
we	O
are	O
able	O
to	O
significantly	O
improve	O
over	O
the	O
‘	O
standard	O
’	O
way	O
of	O
ensembling	Method
(	O
same	O
model	O
with	O
different	O
random	O
seeds	O
)	O
by	O
1.31	O
%	O
.	O
Overall	O
,	O
we	O
achieve	O
72.27	O
%	O
on	O
the	O
test	Metric
-	Metric
std	Metric
split	Metric
of	O
the	O
VQA	Material
v2.0	Material
dataset	Material
.	O
Our	O
code	O
in	O
its	O
entirety	O
(	O
training	O
,	O
evaluation	Task
,	O
data	Task
-	Task
augmentation	Task
,	O
ensembling	Task
)	O
and	O
pre	O
-	O
trained	Method
models	Method
are	O
publicly	O
available	O
at	O
:	O
.	O
section	O
:	O
Introduction	O
We	O
present	O
Pythia	Method
v0.1	Method
,	O
a	O
modular	Method
framework	Method
for	O
Visual	Task
Question	Task
Answering	Task
research	Task
,	O
which	O
formed	O
the	O
basis	O
for	O
the	O
winning	O
entry	O
to	O
the	O
VQA	Task
Challenge	Task
2018	O
from	O
Facebook	O
AI	O
Research	O
(	O
FAIR	O
)	O
’s	O
A	O
-	O
STAR	O
team	O
.	O
The	O
motivation	O
for	O
Pythia	Method
comes	O
from	O
the	O
following	O
observation	O
–	O
a	O
majority	O
of	O
today	O
’s	O
Visual	Method
Question	Method
Answering	Method
(	O
VQA	Method
)	Method
models	Method
fit	O
a	O
particular	O
design	Method
paradigm	Method
,	O
with	O
modules	O
for	O
question	Task
encoding	Task
,	O
image	Task
feature	Task
extraction	Task
,	O
fusion	O
of	O
the	O
two	O
(	O
typically	O
with	O
attention	O
)	O
,	O
and	O
classification	Method
over	O
the	O
space	O
of	O
answers	O
.	O
The	O
long	O
-	O
term	O
goal	O
of	O
Pythia	Method
is	O
to	O
serve	O
as	O
a	O
platform	O
for	O
easy	O
and	O
modular	Task
research	Task
&	Task
development	Task
in	O
VQA	Task
and	O
related	O
directions	O
like	O
visual	Task
dialog	Task
.	O
The	O
name	O
‘	O
Pythia	Method
’	O
is	O
an	O
homage	O
to	O
the	O
Oracle	O
of	O
Apollo	O
at	O
Delphi	O
,	O
who	O
answered	O
questions	O
in	O
Ancient	O
Greece	O
.	O
The	O
starting	O
point	O
for	O
Pythia	Method
v0.1	Method
is	O
a	O
modular	O
reimplementation	O
of	O
the	O
bottom	Method
-	Method
up	Method
top	Method
-	Method
down	Method
(	Method
up	Method
-	Method
down	Method
)	Method
model	Method
.	O
In	O
this	O
study	O
,	O
we	O
demonstrate	O
that	O
by	O
making	O
a	O
sequence	O
of	O
subtle	O
but	O
important	O
changes	O
,	O
we	O
can	O
significantly	O
improve	O
the	O
performance	O
as	O
summarized	O
in	O
Table	O
1	O
.	O
section	O
:	O
Bottom	O
-	O
Up	O
and	O
Top	O
-	O
Down	O
Attention	O
We	O
perform	O
ablations	Method
and	O
augmentations	Method
over	O
the	O
baseline	O
system	O
of	O
the	O
up	Method
-	Method
down	Method
model	Method
,	O
which	O
was	O
the	O
basis	O
of	O
the	O
winning	O
entry	O
to	O
the	O
2017	O
VQA	Task
challenge	Task
.	O
The	O
key	O
idea	O
in	O
up	O
-	O
down	O
is	O
the	O
use	O
of	O
an	O
object	Method
detector	Method
–	O
Faster	O
RCNN	Method
pre	Method
-	O
trained	O
on	O
the	O
Visual	Material
Genome	Material
dataset	Material
–	O
to	O
extract	O
image	O
features	O
with	O
bottom	Method
-	Method
up	Method
attention	Method
,	O
,	O
visual	Method
feed	Method
-	Method
forward	Method
attention	Method
.	O
Specifically	O
,	O
a	O
ResNet	O
-	O
101	O
was	O
chosen	O
as	O
the	O
backbone	Method
network	Method
,	O
and	O
its	O
entire	O
Res	O
-	O
5	O
block	O
was	O
used	O
as	O
the	O
second	O
-	O
stage	O
region	Method
classifier	Method
for	O
detection	Task
.	O
After	O
training	O
,	O
each	O
region	O
was	O
then	O
represented	O
by	O
the	O
2048	O
feature	O
after	O
average	Method
pooling	Method
from	O
a	O
grid	O
.	O
The	O
question	O
text	O
is	O
then	O
used	O
to	O
compute	O
the	O
top	O
-	O
down	O
attention	O
,	O
,	O
task	O
specific	O
attention	O
,	O
for	O
each	O
object	O
in	O
the	O
image	O
.	O
Multi	Task
-	Task
modal	Task
fusion	Task
is	O
done	O
through	O
a	O
simple	O
Hadamard	Method
product	Method
followed	O
by	O
a	O
multi	Method
-	Method
label	Method
classifier	Method
using	O
a	O
sigmoid	Method
activation	Method
function	Method
to	O
predict	O
the	O
answer	O
scores	O
.	O
Their	O
performance	O
reached	O
70.34	O
%	O
on	O
VQA	Material
2.0	Material
test	Material
-	Material
std	Material
split	Material
with	O
an	O
ensemble	O
of	O
30	O
models	O
trained	O
with	O
different	O
seeds	O
.	O
For	O
presentation	O
clarity	O
,	O
we	O
present	O
our	O
proposed	O
changes	O
(	O
and	O
the	O
respective	O
improvements	O
)	O
in	O
a	O
sequence	O
;	O
however	O
,	O
we	O
also	O
found	O
them	O
to	O
be	O
independently	O
useful	O
.	O
subsection	O
:	O
Model	O
Architecture	O
We	O
made	O
a	O
few	O
changes	O
to	O
the	O
up	Method
-	Method
down	Method
model	Method
to	O
improve	O
training	Metric
speed	Metric
and	O
accuracy	Metric
.	O
Instead	O
of	O
using	O
the	O
gated	Method
hyperbolic	Method
tangent	Method
activation	Method
,	O
we	O
use	O
weight	Method
normalization	Method
followed	O
by	O
ReLU	Method
to	O
reduce	O
computation	O
.	O
We	O
also	O
replaced	O
feature	Method
concatenation	Method
with	O
element	Method
-	Method
wise	Method
multiplication	Method
to	O
combine	O
the	O
features	O
from	O
text	O
and	O
visual	O
modalities	O
when	O
computing	O
the	O
top	Task
-	Task
down	Task
attention	Task
.	O
To	O
compute	O
the	O
question	Method
representation	Method
,	O
we	O
used	O
300	O
GloVe	O
vectors	O
to	O
initialize	O
the	O
word	O
embeddings	O
and	O
then	O
passed	O
it	O
to	O
a	O
GRU	Method
network	Method
and	O
a	O
question	Method
attention	Method
module	Method
to	O
extract	O
attentive	O
text	O
features	O
.	O
For	O
fusing	O
the	O
image	O
and	O
text	O
information	O
,	O
we	O
found	O
the	O
best	O
-	O
performing	O
hidden	Metric
size	Metric
to	O
be	O
5000	O
.	O
With	O
these	O
modifications	O
,	O
we	O
were	O
able	O
to	O
improve	O
the	O
performance	O
of	O
the	O
model	O
from	O
65.32	O
%	O
to	O
66.91	O
%	O
on	O
VQA	Material
v2.0	Material
test	O
-	O
dev	O
.	O
subsection	O
:	O
Learning	Method
Schedule	Method
Our	O
model	O
is	O
optimized	O
by	O
Adamax	Method
,	O
a	O
variant	O
of	O
Adam	Method
with	Method
infinite	Method
norm	Method
.	O
In	O
one	O
popular	O
implementation	O
of	O
up	Method
-	Method
down	Method
learning	Method
rate	Method
is	O
set	O
to	O
0.002	O
with	O
a	O
batch	O
size	O
of	O
512	O
.	O
We	O
found	O
that	O
reducing	O
the	O
batch	O
size	O
improves	O
performance	O
–	O
which	O
suggests	O
that	O
there	O
is	O
potential	O
for	O
improving	O
performance	O
by	O
increasing	O
the	O
learning	Metric
rate	Metric
.	O
However	O
,	O
naively	O
increasing	O
the	O
learning	Metric
rate	Metric
resulted	O
in	O
divergence	O
.	O
To	O
increase	O
the	O
learning	Metric
rate	Metric
,	O
we	O
thus	O
deployed	O
the	O
warm	Method
up	Method
strategy	Method
commonly	O
used	O
for	O
large	Task
learning	Task
-	Task
rate	Task
training	Task
of	Task
networks	Task
.	O
Specifically	O
,	O
we	O
begin	O
with	O
a	O
learning	Metric
rate	Metric
of	O
0.002	O
,	O
linearly	O
increasing	O
it	O
at	O
each	O
iteration	O
till	O
it	O
reaches	O
0.01	O
at	O
iteration	O
1000	O
.	O
Next	O
,	O
we	O
first	O
reduce	O
the	O
learning	Metric
rate	Metric
by	O
a	O
factor	O
of	O
0.1	O
at	O
5	O
and	O
then	O
reduce	O
it	O
every	O
2	O
iterations	O
,	O
and	O
stop	O
training	O
at	O
12	O
.	O
With	O
this	O
we	O
increase	O
the	O
performance	O
from	O
66.91	O
%	O
to	O
68.05	O
%	O
on	O
test	Metric
-	Metric
dev	Metric
.	O
subsection	O
:	O
Fine	O
-	O
Tuning	Task
Bottom	Task
-	Task
Up	Task
Features	Task
Fine	Task
tuning	Task
pre	Task
-	Task
trained	Task
features	Task
is	O
a	O
well	O
known	O
technique	O
to	O
better	O
tailor	O
the	O
features	O
to	O
the	O
task	O
at	O
hand	O
and	O
thus	O
improve	O
model	O
performance	O
.	O
Different	O
from	O
Anderson	Method
,	O
we	O
also	O
used	O
the	O
new	O
state	O
-	O
of	O
-	O
the	O
-	O
art	Method
detectors	Method
based	O
on	O
feature	Method
pyramid	Method
networks	Method
(	O
FPN	Method
)	O
from	O
Detectron	Method
,	O
which	O
uses	O
ResNeXt	O
as	O
backbone	O
and	O
has	O
two	O
fully	Method
connected	Method
layers	Method
(	O
fc6	Method
and	O
fc7	Method
)	O
for	O
region	Task
classification	Task
.	O
This	O
allows	O
us	O
to	O
extract	O
the	O
2048	O
fc6	O
features	O
and	O
fine	O
-	O
tune	O
the	O
fc7	O
parameters	O
,	O
as	O
opposed	O
to	O
the	O
original	O
up	O
-	O
down	O
,	O
where	O
fine	O
-	O
tuning	O
previous	O
layers	O
requires	O
significantly	O
more	O
storage	O
/	O
IO	O
and	O
computation	O
on	O
convolutional	O
feature	O
maps	O
.	O
Similar	O
to	O
up	O
-	O
down	O
,	O
we	O
also	O
used	O
Visual	O
Genome	O
(	O
VG	Material
)	O
with	O
both	O
objects	O
and	O
attributes	O
annotations	O
to	O
train	O
the	O
detector	O
.	O
We	O
set	O
the	O
fine	Metric
-	Metric
tune	Metric
learning	Metric
rate	Metric
as	O
0.1	O
times	O
the	O
overall	O
learning	Metric
rate	Metric
.	O
We	O
are	O
able	O
to	O
reach	O
a	O
performance	O
of	O
68.49	O
%	O
on	O
test	O
-	O
dev	O
with	O
this	O
fine	Method
-	Method
tuning	Method
.	O
subsection	O
:	O
Data	Task
Augmentation	Task
We	O
added	O
additional	O
training	O
data	O
from	O
Visual	Material
Genome	Material
and	Material
Visual	Material
Dialog	Material
(	O
VisDial	Material
v0.9	Material
)	O
datasets	O
.	O
For	O
VisDial	Material
,	O
we	O
converted	O
the	O
10	O
turns	O
in	O
a	O
dialog	O
to	O
10	O
independent	O
question	O
-	O
answer	O
pairs	O
.	O
Since	O
both	O
VG	Material
and	O
VisDial	Material
datasets	Material
only	O
have	O
a	O
single	O
ground	O
-	O
truth	O
answer	O
while	O
VQA	O
has	O
10	O
,	O
we	O
simply	O
replicated	O
the	O
answer	O
to	O
each	O
question	O
in	O
VG	Material
and	O
VisDial	Material
10	O
times	O
to	O
make	O
the	O
data	O
format	O
compatible	O
with	O
the	O
VQA	Method
evaluation	Method
protocol	Method
.	O
We	O
also	O
performed	O
additional	O
data	Task
augmentation	Task
by	O
mirroring	O
the	O
images	O
in	O
the	O
VQA	Material
dataset	Material
.	O
We	O
do	O
some	O
basic	O
processing	O
of	O
the	O
questions	O
and	O
answers	O
for	O
the	O
mirrored	O
images	O
by	O
interchanging	O
the	O
tokens	O
“	O
left	O
”	O
and	O
“	O
right	O
”	O
in	O
the	O
questions	O
and	O
answers	O
which	O
contain	O
them	O
.	O
When	O
adding	O
these	O
additional	O
datasets	O
,	O
we	O
reduce	O
the	O
learning	Metric
rate	Metric
as	O
we	O
described	O
in	O
Section	O
[	O
reference	O
]	O
first	O
at	O
15	O
iterations	O
,	O
respectively	O
,	O
and	O
stop	O
training	O
at	O
22	O
iterations	O
.	O
As	O
a	O
result	O
of	O
data	Task
augmentation	Task
,	O
we	O
are	O
able	O
to	O
improve	O
our	O
single	O
model	O
performance	O
from	O
68.49	O
%	O
to	O
69.24	O
%	O
on	O
test	Metric
-	Metric
dev	Metric
.	O
subsection	O
:	O
Post	O
-	O
Challenge	O
Improvements	O
Anderson	Method
uses	O
only	O
the	O
features	O
pooled	O
from	O
object	O
proposals	O
(	O
called	O
bottom	O
-	O
up	O
features	O
)	O
to	O
represent	O
an	O
image	O
.	O
Our	O
hypothesis	O
is	O
that	O
such	O
a	O
representation	O
does	O
not	O
fully	O
capture	O
a	O
holistic	O
spatial	O
information	O
about	O
the	O
image	O
and	O
visual	O
representations	O
from	O
image	O
regions	O
not	O
covered	O
by	O
the	O
proposals	O
.	O
To	O
test	O
this	O
hypothesis	O
,	O
we	O
combined	O
grid	O
-	O
level	O
image	O
features	O
together	O
with	O
bottom	O
-	O
up	O
features	O
.	O
We	O
follow	O
the	O
same	O
procedure	O
as	O
to	O
extract	O
grid	O
-	O
level	O
features	O
from	O
ResNet152	Material
.	O
Object	O
-	O
level	O
features	O
and	O
grid	O
-	O
level	O
features	O
are	O
separately	O
fused	O
with	O
features	O
from	O
questions	O
and	O
then	O
are	O
concatenated	O
to	O
fed	O
to	O
classification	Task
.	O
Before	O
the	O
challenge	O
deadline	O
,	O
we	O
had	O
experimented	O
with	O
this	O
only	O
on	O
images	O
from	O
the	O
VQA	Material
dataset	Material
without	O
fine	Method
-	Method
tuning	Method
.	O
After	O
the	O
challenge	O
,	O
we	O
performed	O
more	O
comprehensive	O
experiments	O
and	O
found	O
that	O
adding	O
grid	O
level	O
features	O
helps	O
to	O
further	O
improve	O
the	O
performance	O
to	O
69.81	O
%	O
.	O
Instead	O
of	O
using	O
an	O
adaptive	Method
protocol	Method
for	O
choosing	O
the	O
number	O
of	O
object	O
proposals	O
(	O
between	O
10	O
and	O
100	O
)	O
per	O
image	O
as	O
as	O
done	O
in	O
,	O
we	O
also	O
experimented	O
with	O
using	O
a	O
simpler	O
(	O
but	O
slower	O
)	O
strategy	O
of	O
using	O
100	O
objects	O
proposals	O
for	O
all	O
images	O
.	O
As	O
can	O
be	O
seen	O
in	O
Table	O
[	O
reference	O
]	O
,	O
with	O
features	O
from	O
100	O
bounding	O
-	O
boxes	O
,	O
we	O
reach	O
70.01	O
%	O
for	O
test	Metric
-	Metric
dev	Metric
and	O
70.24	O
%	O
for	O
test	O
-	O
std	Metric
on	O
VQA	Material
2.0	Material
.	O
subsection	O
:	O
Model	Method
Ensembling	Method
All	O
ensembling	O
experiments	O
described	O
below	O
involve	O
models	O
trained	O
before	O
the	O
challenge	O
deadline	O
.	O
That	O
is	O
,	O
they	O
do	O
not	O
include	O
the	O
two	O
after	O
-	O
challenge	O
experiments	O
described	O
in	O
Section	O
[	O
reference	O
]	O
.	O
We	O
tried	O
two	O
strategies	O
for	O
ensembling	Task
.	O
First	O
,	O
we	O
choose	O
our	O
best	O
single	O
model	O
and	O
train	O
the	O
same	O
network	O
with	O
different	O
seeds	O
,	O
and	O
finally	O
average	O
the	O
predictions	O
from	O
each	O
model	O
.	O
As	O
can	O
be	O
seen	O
from	O
Fig	O
[	O
reference	O
]	O
,	O
the	O
performance	O
plateaus	O
at	O
70.96	O
%	O
.	O
Second	O
,	O
we	O
choose	O
models	O
trained	O
with	O
different	O
settings	O
,	O
,	O
the	O
tweaked	Method
up	Method
-	Method
down	Method
model	Method
trained	O
on	O
the	O
VQA	Material
dataset	Material
with	O
/	O
without	O
data	Method
augmentation	Method
and	O
models	O
trained	O
with	O
image	O
features	O
extracted	O
from	O
different	O
Detectron	Method
models	Method
with	O
/	O
without	O
data	Method
augmentation	Method
.	O
As	O
can	O
be	O
seen	O
,	O
this	O
ensembling	Method
strategy	Method
is	O
much	O
more	O
effective	O
than	O
the	O
previous	O
one	O
.	O
Ensembling	O
30	O
diverse	O
models	O
,	O
we	O
reach	O
72.18	O
%	O
on	O
test	Metric
-	Metric
dev	Metric
and	O
72.27	O
%	O
on	O
test	Metric
-	Metric
std	Metric
of	O
VQA	Material
v2.0	Material
.	O
section	O
:	O
Acknowledgements	O
We	O
would	O
like	O
to	O
thank	O
Peter	O
Anderson	O
,	O
Abhishek	O
Das	O
,	O
Stefan	O
Lee	O
,	O
Jiasen	O
Lu	O
,	O
Jianwei	O
Yang	O
,	O
Licheng	O
Yu	O
,	O
Luowei	O
Zhou	O
for	O
helpful	O
discussions	O
,	O
Peter	O
Anderson	O
for	O
providing	O
training	O
data	O
for	O
the	O
Visual	O
Genome	O
detector	O
,	O
Deshraj	O
Yadav	O
for	O
responses	O
on	O
EvalAI	O
related	O
questions	O
,	O
Stefan	O
Lee	O
for	O
suggesting	O
the	O
name	O
‘	O
Pythia	O
’	O
,	O
Abhishek	O
Das	O
,	O
Abhishek	O
Kadian	O
for	O
feedback	O
on	O
our	O
codebase	O
and	O
Meet	O
Shah	O
for	O
making	O
a	O
docker	O
image	O
for	O
our	O
demo	O
.	O
bibliography	O
:	O
References	O
