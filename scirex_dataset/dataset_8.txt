VQA Task
: O
Visual Task
Question Task
Answering Task
section O
: O
Abstract O
- O
We O
propose O
the O
task O
of O
free O
- O
form O
and O
open O
- O
ended O
Visual Task
Question Task
Answering Task
( O
VQA Task
) O
. O
Given O
an O
image O
and O
a O
natural O
language O
question O
about O
the O
image O
, O
the O
task O
is O
to O
provide O
an O
accurate O
natural O
language O
answer O
. O
Mirroring Task
real Task
- Task
world Task
scenarios Task
, O
such O
as O
helping O
the O
visually O
impaired O
, O
both O
the O
questions O
and O
answers O
are O
open O
- O
ended O
. O
Visual O
questions O
selectively O
target O
different O
areas O
of O
an O
image O
, O
including O
background O
details O
and O
underlying O
context O
. O
As O
a O
result O
, O
a O
system O
that O
succeeds O
at O
VQA Task
typically O
needs O
a O
more O
detailed O
understanding O
of O
the O
image O
and O
complex O
reasoning O
than O
a O
system O
producing O
generic Task
image Task
captions Task
. O
Moreover O
, O
VQA Task
is O
amenable O
to O
automatic Task
evaluation Task
, O
since O
many O
open O
- O
ended O
answers O
contain O
only O
a O
few O
words O
or O
a O
closed O
set O
of O
answers O
that O
can O
be O
provided O
in O
a O
multiple O
- O
choice O
format O
. O
We O
provide O
a O
dataset O
containing O
∼0.25 O
M O
images O
, O
∼0.76 O
M O
questions O
, O
and O
∼10 O
M O
answers O
( O
www.visualqa.org O
) O
, O
and O
discuss O
the O
information O
it O
provides O
. O
Numerous O
baselines O
and O
methods O
for O
VQA Task
are O
provided O
and O
compared O
with O
human Metric
performance Metric
. O
Our O
VQA Task
demo O
is O
available O
on O
CloudCV O
( O
http: O
// O
cloudcv.org O
/ O
vqa O
) O
. O
section O
: O
INTRODUCTION O
We O
are O
witnessing O
a O
renewed O
excitement O
in O
multi O
- O
discipline O
Artificial O
Intelligence O
( O
AI O
) O
research O
problems O
. O
In O
particular O
, O
research O
in O
image Task
and Task
video Task
captioning Task
that O
combines O
Computer Method
Vision Method
( O
CV Method
) O
, O
Natural Method
Language Method
Processing Method
( O
NLP Method
) O
, O
and O
Knowledge Method
Representation Method
& Method
Reasoning Method
( O
KR Method
) O
has O
dramatically O
increased O
in O
the O
past O
year O
[ O
reference O
] O
, O
[ O
reference O
] O
, O
[ O
reference O
] O
, O
[ O
reference O
] O
, O
[ O
reference O
] O
, O
[ O
reference O
] O
, O
[ O
reference O
] O
. O
Part O
of O
this O
excitement O
stems O
from O
a O
belief O
that O
multi Task
- Task
discipline Task
tasks Task
like O
image Task
captioning Task
are O
a O
step O
towards O
solving O
AI O
. O
However O
, O
the O
current O
state O
of O
the O
art O
demonstrates O
that O
a O
coarse O
scene O
- O
level O
understanding O
of O
an O
image O
paired O
with O
word O
n O
- O
gram O
statistics O
suffices O
to O
generate O
reasonable O
image Task
captions Task
, O
which O
suggests O
image Task
captioning Task
may O
not O
be O
as O
" O
AI O
- O
complete O
" O
as O
desired O
. O
What O
makes O
for O
a O
compelling O
" O
AI Task
- Task
complete Task
" Task
task Task
? O
We O
believe O
that O
in O
order O
to O
spawn O
the O
next O
generation O
of O
AI Method
algorithms Method
, O
an O
ideal O
task O
should O
( O
i O
) O
require O
multi O
- O
modal O
knowledge O
beyond O
a O
single O
sub O
- O
domain O
( O
such O
as O
CV Method
) O
and O
( O
ii O
) O
have O
a O
well O
- O
defined O
quantitative Metric
evaluation Metric
metric Metric
to O
track O
progress O
. O
For O
some O
tasks O
, O
such O
as O
image Task
captioning Task
, O
automatic Task
evaluation Task
is O
still O
a O
difficult O
and O
open O
research O
problem O
[ O
reference O
] O
, O
[ O
reference O
] O
, O
[ O
reference O
] O
. O
In O
this O
paper O
, O
we O
introduce O
the O
task O
of O
free Task
- Task
form Task
and Task
openended Task
Visual Task
Question Task
Answering Task
( O
VQA Task
) O
. O
A O
VQA Task
system O
takes O
as O
input O
an O
image O
and O
a O
free O
- O
form O
, O
open O
- O
ended O
, O
naturallanguage O
question O
about O
the O
image O
and O
produces O
a O
naturallanguage O
answer O
as O
the O
output O
. O
This O
goal Task
- Task
driven Task
task Task
is O
applicable O
to O
scenarios O
encountered O
when O
visually O
- O
impaired O
users O
[ O
reference O
] O
or O
intelligence Task
analysts Task
actively O
elicit O
visual O
information O
. O
Example O
questions O
are O
shown O
in O
Fig O
. O
1 O
. O
Open O
- O
ended O
questions O
require O
a O
potentially O
vast O
set O
of O
AI Task
capabilities Task
to O
answer O
- O
fine Method
- Method
grained Method
recognition Method
( O
e.g. O
, O
" O
What O
kind O
of O
cheese O
is O
on O
the O
pizza O
? O
" O
) O
, O
object Method
detection Method
( O
e.g. O
, O
" O
How O
many O
bikes O
are O
there O
? O
" O
) O
, O
activity Method
recognition Method
( O
e.g. O
, O
" O
Is O
this O
man O
crying O
? O
" O
) O
, O
knowledge Method
base Method
reasoning Method
( O
e.g. O
, O
" O
Is O
this O
a O
vegetarian O
pizza O
? O
" O
) O
, O
and O
commonsense Method
reasoning Method
( O
e.g. O
, O
" O
Does O
this O
person O
have O
20 O
/ O
20 O
vision O
? O
" O
, O
" O
Is O
this O
person O
expecting O
company O
? O
" O
) O
. O
VQA Task
[ O
reference O
] O
, O
[ O
reference O
] O
, O
[ O
reference O
] O
, O
[ O
reference O
] O
is O
also O
amenable O
to O
automatic Task
quantitative Task
evaluation Task
, O
making O
it O
possible O
to O
effectively O
track O
progress O
on O
this O
task O
. O
While O
the O
answer O
to O
many O
questions O
is O
simply O
" O
yes O
" O
or O
" O
no O
" O
, O
the O
process O
for O
determining O
a O
correct O
answer O
is O
typically O
far O
from O
trivial O
( O
e.g. O
in O
Fig O
. O
1 O
, O
" O
Does O
this O
person O
have O
20 O
/ O
20 O
vision O
? O
" O
) O
. O
Moreover O
, O
since O
questions O
about O
images O
often O
tend O
to O
seek O
specific O
information O
, O
simple O
oneto O
- O
three O
word O
answers O
are O
sufficient O
for O
many O
questions O
. O
In O
such O
scenarios O
, O
we O
can O
easily O
evaluate O
a O
proposed O
algorithm O
by O
the O
number O
of O
questions O
it O
answers O
correctly O
. O
In O
this O
paper O
, O
we O
present O
both O
an O
open Task
- Task
ended Task
answering Task
task Task
and O
a O
multiplechoice Task
task Task
[ O
reference O
] O
, O
[ O
reference O
] O
. O
Unlike O
the O
open Task
- Task
ended Task
task Task
that O
requires O
a O
free O
- O
form O
response O
, O
the O
multiple Task
- Task
choice Task
task Task
only O
requires O
an O
algorithm O
to O
pick O
from O
a O
predefined O
list O
of O
possible O
answers O
. O
We O
present O
a O
large O
dataset O
that O
contains O
204 O
, O
721 O
images O
from O
the O
MS Material
COCO Material
dataset Material
[ O
reference O
] O
and O
a O
newly O
created O
abstract Material
scene Material
dataset Material
[ O
reference O
] O
, O
[ O
reference O
] O
that O
contains O
50 O
, O
000 O
scenes O
. O
The O
MS Material
COCO Material
dataset Material
has O
images O
depicting O
diverse O
and O
complex O
scenes O
that O
are O
effective O
at O
eliciting O
compelling O
and O
diverse O
questions O
. O
We O
collected O
a O
new O
dataset O
of O
" O
realistic O
" O
abstract Material
scenes Material
to O
enable O
research O
focused O
only O
on O
the O
high O
- O
level O
reasoning O
required O
for O
VQA Task
by O
removing O
the O
need O
to O
parse O
real Material
images Material
. O
Three O
questions O
were O
collected O
for O
each O
image O
or O
scene O
. O
Each O
question O
was O
answered O
by O
ten O
subjects O
along O
with O
their O
confidence O
. O
The O
dataset O
contains O
over O
760 O
K O
questions O
with O
around O
10 O
M O
answers O
. O
While O
the O
use O
of O
open O
- O
ended O
questions O
offers O
many O
benefits O
, O
it O
is O
still O
useful O
to O
understand O
the O
types O
of O
questions O
that O
are O
being O
asked O
and O
which O
types O
various O
algorithms O
may O
be O
good O
at O
answering O
. O
To O
this O
end O
, O
we O
analyze O
the O
types O
of O
questions O
asked O
and O
the O
types O
of O
answers O
provided O
. O
Through O
several O
visualizations Method
, O
we O
demonstrate O
the O
astonishing O
diversity O
of O
the O
questions O
asked O
. O
We O
also O
explore O
how O
the O
information O
content O
of O
questions O
and O
their O
answers O
differs O
from O
image O
captions O
. O
For O
baselines O
, O
we O
offer O
several O
approaches O
that O
use O
a O
combination O
of O
both O
text O
and O
state O
- O
of O
- O
the O
- O
art O
visual Method
features Method
[ O
reference O
] O
. O
As O
part O
of O
the O
VQA Task
initiative Task
, O
we O
will O
organize O
an O
annual O
challenge O
and O
associated O
workshop O
to O
discuss O
state O
- O
of O
- O
the O
- O
art O
methods O
and O
best O
practices O
. O
VQA Task
poses O
a O
rich O
set O
of O
challenges O
, O
many O
of O
which O
have O
been O
viewed O
as O
the O
holy O
grail O
of O
automatic Task
image Task
understanding Task
and O
AI O
in O
general O
. O
However O
, O
it O
includes O
as O
building O
blocks O
several O
components O
that O
the O
CV Method
, O
NLP Method
, O
and O
KR Method
[ O
reference O
] O
, O
[ O
reference O
] O
, O
[ O
reference O
] O
, O
[ O
reference O
] O
, O
[ O
reference O
] O
communities O
have O
made O
significant O
progress O
on O
during O
the O
past O
few O
decades O
. O
VQA Task
provides O
an O
attractive O
balance O
between O
pushing O
the O
state O
of O
the O
art O
, O
while O
being O
accessible O
enough O
for O
the O
communities O
to O
start O
making O
progress O
on O
the O
task O
. O
section O
: O
RELATED O
WORK O
VQA Task
Efforts O
. O
Several O
recent O
papers O
have O
begun O
to O
study O
visual Task
question Task
answering Task
[ O
reference O
] O
, O
[ O
reference O
] O
, O
[ O
reference O
] O
, O
[ O
reference O
] O
. O
However O
, O
unlike O
our O
work O
, O
these O
are O
fairly O
restricted O
( O
sometimes O
synthetic O
) O
settings O
with O
small O
datasets O
. O
For O
instance O
, O
[ O
reference O
] O
only O
considers O
questions O
whose O
answers O
come O
from O
a O
predefined O
closed O
world O
of O
16 O
basic O
colors O
or O
894 O
object O
categories O
. O
[ O
reference O
] O
also O
considers O
questions O
generated O
from O
templates O
from O
a O
fixed O
vocabulary O
of O
objects O
, O
attributes O
, O
relationships O
between O
objects O
, O
etc O
. O
In O
contrast O
, O
our O
proposed O
task O
involves O
open O
- O
ended O
, O
free O
- O
form O
questions O
and O
answers O
provided O
by O
humans O
. O
Our O
goal O
is O
to O
increase O
the O
diversity O
of O
knowledge O
and O
kinds O
of O
reasoning O
needed O
to O
provide O
correct O
answers O
. O
Critical O
to O
achieving O
success O
on O
this O
more O
difficult O
and O
unconstrained Task
task Task
, O
our O
VQA Material
dataset Material
is O
two O
orders O
of O
magnitude O
larger O
than O
[ O
reference O
] O
, O
[ O
reference O
] O
( O
> O
250 O
, O
000 O
vs. O
2 O
, O
591 O
and O
1 O
, O
449 O
images O
respectively O
) O
. O
The O
proposed O
VQA Task
task Task
has O
connections O
to O
other O
related O
work O
: O
[ O
reference O
] O
has O
studied O
joint Task
parsing Task
of Task
videos Task
and O
corresponding O
text O
to O
answer O
queries O
on O
two O
datasets O
containing O
15 O
video O
clips O
each O
. O
[ O
reference O
] O
uses O
crowdsourced O
workers O
to O
answer O
questions O
about O
visual O
content O
asked O
by O
visually O
- O
impaired O
users O
. O
In O
concurrent O
work O
, O
[ O
reference O
] O
proposed O
combining O
an O
LSTM Method
for O
the O
question O
with O
a O
CNN Method
for O
the O
image O
to O
generate O
an O
answer O
. O
In O
their O
model O
, O
the O
LSTM Method
question O
representation O
is O
conditioned O
on O
the O
CNN O
image O
features O
at O
each O
time O
step O
, O
and O
the O
final O
LSTM Method
hidden O
state O
is O
used O
to O
sequentially O
decode O
the O
answer O
phrase O
. O
In O
contrast O
, O
the O
model O
developed O
in O
this O
paper O
explores O
" O
late Task
fusion Task
" Task
- O
i.e O
. O
, O
the O
LSTM Method
question O
representation O
and O
the O
CNN O
image O
features O
are O
computed O
independently O
, O
fused O
via O
an O
element Method
- Method
wise Method
multiplication Method
, O
and O
then O
passed O
through O
fullyconnected Method
layers Method
to O
generate O
a O
softmax O
distribution O
over O
output O
answer O
classes O
. O
[ O
reference O
] O
generates O
abstract Material
scenes Material
to O
capture O
visual O
common O
sense O
relevant O
to O
answering O
( O
purely O
textual O
) O
fill Task
- Task
inthe Task
- Task
blank Task
and Task
visual Task
paraphrasing Task
questions Task
. O
[ O
reference O
] O
and O
[ O
reference O
] O
use O
visual O
information O
to O
assess O
the O
plausibility O
of O
common O
sense O
assertions O
. O
[ O
reference O
] O
introduced O
a O
dataset O
of O
10k O
images O
and O
prompted O
captions O
that O
describe O
specific O
aspects O
of O
a O
scene O
( O
e.g. O
, O
individual O
objects O
, O
what O
will O
happen O
next O
) O
. O
Concurrent O
with O
our O
work O
, O
[ O
reference O
] O
collected O
questions O
& O
answers O
in O
Chinese O
( O
later O
translated O
to O
English O
by O
humans O
) O
for O
COCO Material
images Material
. O
[ O
reference O
] O
automatically O
generated O
four O
types O
of O
questions O
( O
object O
, O
count O
, O
color O
, O
location O
) O
using O
COCO O
captions O
. O
Text Method
- Method
based Method
Q Method
& Method
A Method
is O
a O
well O
studied O
problem O
in O
the O
NLP Task
and Task
text Task
processing Task
communities Task
( O
recent O
examples O
being O
[ O
reference O
] O
, O
[ O
reference O
] O
, O
[ O
reference O
] O
, O
[ O
reference O
] O
) O
. O
Other O
related O
textual Task
tasks Task
include O
sentence Task
completion Task
( O
e.g. O
, O
[ O
reference O
] O
with O
multiple O
- O
choice O
answers O
) O
. O
These O
approaches O
provide O
inspiration O
for O
VQA Task
techniques O
. O
One O
key O
concern O
in O
text Task
is O
the O
grounding Task
of Task
questions Task
. O
For O
instance O
, O
[ O
reference O
] O
synthesized O
textual O
descriptions O
and O
QA O
- O
pairs O
grounded O
in O
a O
simulation O
of O
actors O
and O
objects O
in O
a O
fixed O
set O
of O
locations O
. O
VQA Task
is O
naturally O
grounded O
in O
images O
- O
requiring O
the O
understanding O
of O
both O
text O
( O
questions O
) O
and O
vision O
( O
images O
) O
. O
Our O
questions O
are O
generated O
by O
humans O
, O
making O
the O
need O
for O
commonsense O
knowledge O
and O
complex O
reasoning O
more O
essential O
. O
Describing Task
Visual Task
Content Task
. O
Related O
to O
VQA Task
are O
the O
tasks O
of O
image Task
tagging Task
[ O
reference O
] O
, O
[ O
reference O
] O
, O
image Task
captioning Task
[ O
reference O
] O
, O
[ O
reference O
] O
, O
[ O
reference O
] O
, O
[ O
reference O
] O
, O
[ O
reference O
] O
, O
[ O
reference O
] O
, O
[ O
reference O
] O
, O
[ O
reference O
] O
, O
[ O
reference O
] O
, O
[ O
reference O
] O
and O
video Task
captioning Task
[ O
reference O
] O
, O
[ O
reference O
] O
, O
where O
words O
or O
sentences O
are O
generated O
to O
describe O
visual O
content O
. O
While O
these O
tasks O
require O
both O
visual O
and O
semantic O
knowledge O
, O
captions O
can O
often O
be O
non O
- O
specific O
( O
e.g. O
, O
observed O
by O
[ O
reference O
] O
) O
. O
The O
questions O
in O
VQA Task
require O
detailed O
specific O
information O
about O
the O
image O
for O
which O
generic O
image O
captions O
are O
of O
little O
use O
[ O
reference O
] O
. O
Other O
Vision Task
+ Task
Language Task
Tasks Task
. O
Several O
recent O
papers O
have O
explored O
tasks O
at O
the O
intersection O
of O
vision Task
and Task
language Task
that O
are O
easier O
to O
evaluate O
than O
image Task
captioning Task
, O
such O
as O
coreference Task
resolution Task
[ O
reference O
] O
, O
[ O
reference O
] O
or O
generating O
referring O
expressions O
[ O
reference O
] O
, O
[ O
reference O
] O
for O
a O
particular O
object O
in O
an O
image O
that O
would O
allow O
a O
human O
to O
identify O
which O
object O
is O
being O
referred O
to O
( O
e.g. O
, O
" O
the O
one O
in O
a O
red O
shirt O
" O
, O
" O
the O
dog O
on O
the O
left O
" O
) O
. O
While O
task O
- O
driven O
and O
concrete O
, O
a O
limited O
set O
of O
visual O
concepts O
( O
e.g. O
, O
color O
, O
location O
) O
tend O
to O
be O
captured O
by O
referring O
expressions O
. O
As O
we O
demonstrate O
, O
a O
richer O
variety O
of O
visual O
concepts O
emerge O
from O
visual O
questions O
and O
their O
answers O
. O
section O
: O
VQA Task
DATASET O
COLLECTION O
We O
now O
describe O
the O
Visual Task
Question Task
Answering Task
( O
VQA Task
) O
dataset O
. O
We O
begin O
by O
describing O
the O
real Material
images Material
and O
abstract Material
scenes Material
used O
to O
collect O
the O
questions O
. O
Next O
, O
we O
describe O
our O
process O
of O
collecting O
questions O
and O
their O
corresponding O
answers O
. O
Analysis O
of O
the O
questions O
and O
answers O
gathered O
as O
well O
as O
baselines O
' O
& O
methods O
' O
results O
are O
provided O
in O
following O
sections O
. O
Real Material
Images Material
. O
We O
use O
the O
123 O
, O
287 O
training O
and O
validation O
images O
and O
81 O
, O
434 O
test O
images O
from O
the O
newly O
- O
released O
Microsoft Material
Common Material
Objects Material
in Material
Context Material
( O
MS Material
COCO Material
) O
[ O
reference O
] O
dataset O
. O
The O
MS Material
COCO Material
dataset Material
was O
gathered O
to O
find O
images O
containing O
multiple O
objects O
and O
rich O
contextual O
information O
. O
Given O
the O
visual O
complexity O
of O
these O
images O
, O
they O
are O
well O
- O
suited O
for O
our O
VQA Task
task Task
. O
The O
more O
diverse O
our O
collection O
of O
images O
, O
the O
more O
diverse O
, O
comprehensive O
, O
and O
interesting O
the O
resultant O
set O
of O
questions O
and O
their O
answers O
. O
Abstract O
Scenes O
. O
The O
VQA Task
task Task
with O
real Material
images Material
requires O
the O
use O
of O
complex O
and O
often O
noisy O
visual Method
recognizers Method
. O
To O
attract O
researchers O
interested O
in O
exploring O
the O
high Task
- Task
level Task
reasoning Task
required O
for O
VQA Task
, O
but O
not O
the O
low Task
- Task
level Task
vision Task
tasks Task
, O
we O
create O
a O
new O
abstract Material
scenes Material
dataset O
[ O
reference O
] O
, O
[ O
reference O
] O
, O
[ O
reference O
] O
, O
[ O
reference O
] O
containing O
50 O
K O
scenes O
. O
The O
dataset O
contains O
20 O
" O
paperdoll O
" O
human Method
models Method
[ O
reference O
] O
spanning O
genders O
, O
races O
, O
and O
ages O
with O
8 O
different O
expressions O
. O
The O
limbs O
are O
adjustable O
to O
allow O
for O
continuous O
pose O
variations O
. O
The O
clipart O
may O
be O
used O
to O
depict O
both O
indoor O
and O
outdoor O
scenes O
. O
The O
set O
contains O
over O
100 O
objects O
and O
31 O
animals O
in O
various O
poses O
. O
The O
use O
of O
this O
clipart O
enables O
the O
creation O
of O
more O
realistic O
scenes O
( O
see O
bottom O
row O
of O
Fig O
. O
2 O
) O
that O
more O
closely O
mirror O
real Material
images Material
than O
previous O
papers O
[ O
reference O
] O
, O
[ O
reference O
] O
, O
[ O
reference O
] O
. O
See O
the O
appendix O
for O
the O
user O
interface O
, O
additional O
details O
, O
and O
examples O
. O
Splits O
. O
For O
real Material
images Material
, O
we O
follow O
the O
same O
train Method
/ Method
val Method
/ Method
test Method
split Method
strategy Method
as O
the O
MC Material
COCO Material
dataset Material
[ O
reference O
] O
( O
including O
testdev O
, O
test O
- O
standard O
, O
test O
- O
challenge O
, O
test O
- O
reserve O
) O
. O
For O
the O
VQA Task
challenge O
( O
see O
section O
6 O
) O
, O
test O
- O
dev O
is O
used O
for O
debugging O
and O
validation O
experiments O
and O
allows O
for O
unlimited O
submission O
to O
the O
evaluation O
server O
. O
Test O
- O
standard O
is O
the O
' O
default O
' O
test O
data O
for O
the O
VQA Task
competition Task
. O
When O
comparing O
to O
the O
state O
of O
the O
art O
( O
e.g. O
, O
in O
papers O
) O
, O
results O
should O
be O
reported O
on O
test O
- O
standard O
. O
Test O
- O
standard O
is O
also O
used O
to O
maintain O
a O
public O
leaderboard O
that O
is O
updated O
upon O
submission O
. O
Test O
- O
reserve O
is O
used O
to O
protect O
against O
possible O
overfitting O
. O
If O
there O
are O
substantial O
differences O
between O
a O
method O
's O
scores O
on O
test O
- O
standard O
and O
test O
- O
reserve O
, O
this O
raises O
a O
red O
- O
flag O
and O
prompts O
further O
investigation O
. O
Results O
on O
test O
- O
reserve O
are O
not O
publicly O
revealed O
. O
Finally O
, O
test O
- O
challenge O
is O
used O
to O
determine O
the O
winners O
of O
the O
challenge O
. O
For O
abstract Material
scenes Material
, O
we O
created O
splits O
for O
standardization Task
, O
separating O
the O
scenes O
into O
20K O
/ O
10K O
/ O
20 O
K O
for O
train O
/ O
val O
/ O
test O
splits O
, O
respectively O
. O
There O
are O
no O
subsplits O
( O
test O
- O
dev O
, O
test O
- O
standard O
, O
test O
- O
challenge O
, O
test O
- O
reserve O
) O
for O
abstract Material
scenes Material
. O
Captions O
. O
The O
MS Material
COCO Material
dataset Material
[ O
reference O
] O
, O
[ O
reference O
] O
already O
contains O
five O
single O
- O
sentence O
captions O
for O
all O
images O
. O
We O
also O
collected O
five O
single O
- O
captions O
for O
all O
abstract Material
scenes Material
using O
the O
same O
user O
interface O
1 O
for O
collection O
. O
Questions O
. O
Collecting O
interesting O
, O
diverse O
, O
and O
well O
- O
posed O
questions O
is O
a O
significant O
challenge O
. O
Many O
simple O
questions O
may O
only O
require O
low O
- O
level O
computer O
vision O
knowledge O
, O
such O
as O
" O
What O
color O
is O
the O
cat O
? O
" O
or O
" O
How O
many O
chairs O
are O
present O
in O
the O
scene O
? O
" O
. O
However O
, O
we O
also O
want O
questions O
that O
require O
commonsense O
knowledge O
about O
the O
scene O
, O
such O
as O
" O
What O
sound O
does O
the O
pictured O
animal O
make O
? O
" O
. O
Importantly O
, O
questions O
should O
also O
require O
the O
image O
to O
correctly O
answer O
and O
not O
be O
answerable O
using O
just O
commonsense O
information O
, O
e.g. O
, O
in O
Fig O
. O
1 O
, O
" O
What O
is O
the O
mustache O
made O
of O
? O
" O
. O
By O
having O
a O
wide O
variety O
of O
question O
types O
and O
difficulty O
, O
we O
may O
be O
able O
to O
measure O
the O
continual O
progress O
of O
both O
visual Task
understanding Task
and O
commonsense Method
reasoning Method
. O
We O
tested O
and O
evaluated O
a O
number O
of O
user Method
interfaces Method
for O
collecting O
such O
" O
interesting O
" O
questions O
. O
Specifically O
, O
we O
ran O
pilot O
studies O
asking O
human O
subjects O
to O
ask O
questions O
about O
a O
given O
image O
that O
they O
believe O
a O
" O
toddler O
" O
, O
" O
alien O
" O
, O
or O
" O
smart O
robot O
" O
would O
have O
trouble O
answering O
. O
We O
found O
the O
" O
smart O
robot O
" O
interface O
to O
elicit O
the O
most O
interesting O
and O
diverse O
questions O
. O
As O
shown O
in O
the O
appendix O
, O
our O
final O
interface O
stated O
: O
" O
We O
have O
built O
a O
smart O
robot O
. O
It O
understands O
a O
lot O
about O
images O
. O
It O
can O
recognize O
and O
name O
all O
the O
objects O
, O
it O
knows O
where O
the O
objects O
are O
, O
it O
can O
recognize O
the O
scene O
( O
e.g. O
, O
kitchen O
, O
beach O
) O
, O
people O
's O
expressions O
and O
poses O
, O
and O
properties O
of O
objects O
( O
e.g. O
, O
color O
of O
objects O
, O
their O
texture O
) O
. O
Your O
task O
is O
to O
stump O
this O
smart O
robot O
! O
Ask O
a O
question O
about O
this O
scene O
that O
this O
smart O
robot O
probably O
can O
not O
answer O
, O
but O
any O
human O
can O
easily O
answer O
while O
looking O
at O
the O
scene O
in O
the O
image O
. O
" O
To O
bias O
against O
generic O
image O
- O
independent O
questions O
, O
subjects O
were O
instructed O
to O
ask O
questions O
that O
require O
the O
image O
to O
answer O
. O
The O
same O
user O
interface O
was O
used O
for O
both O
the O
real Material
images Material
and O
abstract Material
scenes Material
. O
In O
total O
, O
three O
questions O
from O
unique O
workers O
were O
gathered O
for O
each O
image O
/ O
scene O
. O
When O
writing O
a O
question O
, O
the O
subjects O
were O
shown O
the O
previous O
questions O
already O
asked O
for O
that O
image O
to O
increase O
the O
question O
diversity O
. O
In O
total O
, O
the O
dataset O
contains O
over O
∼0.76 O
M O
questions O
. O
Answers O
. O
Open O
- O
ended O
questions O
result O
in O
a O
diverse O
set O
of O
possible O
answers O
. O
For O
many O
questions O
, O
a O
simple O
" O
yes O
" O
or O
" O
no O
" O
response O
is O
sufficient O
. O
However O
, O
other O
questions O
may O
require O
a O
short O
phrase O
. O
Multiple O
different O
answers O
may O
also O
be O
correct O
. O
For O
instance O
, O
the O
answers O
" O
white O
" O
, O
" O
tan O
" O
, O
or O
" O
off O
- O
white O
" O
may O
all O
be O
correct O
answers O
to O
the O
same O
question O
. O
Human O
subjects O
may O
also O
disagree O
on O
the O
" O
correct O
" O
answer O
, O
e.g. O
, O
some O
saying O
" O
yes O
" O
while O
others O
say O
" O
no O
" O
. O
To O
handle O
these O
discrepancies O
, O
we O
gather O
10 O
answers O
for O
each O
question O
from O
unique O
workers O
, O
while O
also O
ensuring O
that O
the O
worker O
answering O
a O
question O
did O
not O
ask O
it O
. O
We O
ask O
the O
subjects O
to O
provide O
answers O
that O
are O
" O
a O
brief O
phrase O
and O
not O
a O
complete O
sentence O
. O
Respond O
matter O
- O
offactly O
and O
avoid O
using O
conversational O
language O
or O
inserting O
your O
opinion O
. O
" O
In O
addition O
to O
answering O
the O
questions O
, O
the O
subjects O
were O
asked O
" O
Do O
you O
think O
you O
were O
able O
to O
answer O
the O
question O
correctly O
? O
" O
and O
given O
the O
choices O
of O
" O
no O
" O
, O
" O
maybe O
" O
, O
and O
" O
yes O
" O
. O
See O
the O
appendix O
for O
more O
details O
about O
the O
user O
interface O
to O
collect O
answers O
. O
See O
Section O
4 O
for O
an O
analysis O
of O
the O
answers O
provided O
. O
For O
testing O
, O
we O
offer O
two O
modalities O
for O
answering O
the O
ques O
- O
For O
the O
open Task
- Task
ended Task
task Task
, O
the O
generated O
answers O
are O
evaluated O
using O
the O
following O
accuracy Metric
metric Metric
: O
accuracy Metric
= O
min O
( O
# O
humans O
that O
provided O
that O
answer O
3 O
, O
1 O
) O
i.e. O
, O
an O
answer O
is O
deemed O
100 O
% O
accurate O
if O
at O
least O
3 O
workers O
provided O
that O
exact O
answer O
. O
[ O
reference O
] O
Before O
comparison O
, O
all O
responses O
are O
made O
lowercase O
, O
numbers O
converted O
to O
digits O
, O
and O
punctuation O
& O
articles O
removed O
. O
We O
avoid O
using O
soft Metric
metrics Metric
such O
as O
Word2Vec Method
[ O
reference O
] O
, O
since O
they O
often O
group O
together O
words O
that O
we O
wish O
to O
distinguish O
, O
such O
as O
" O
left O
" O
and O
" O
right O
" O
. O
We O
also O
avoid O
using O
evaluation Metric
metrics Metric
from O
machine Task
translation Task
such O
as O
BLEU Metric
and O
ROUGE Metric
because O
such O
metrics O
are O
typically O
applicable O
and O
reliable O
for O
sentences O
containing O
multiple O
words O
. O
In O
VQA Task
, O
most O
answers O
( O
89.32 O
% O
) O
are O
single O
word O
; O
thus O
there O
no O
high O
- O
order O
n O
- O
gram O
matches O
between O
predicted O
answers O
and O
ground O
- O
truth O
answers O
, O
and O
low O
- O
order O
n O
- O
gram O
matches O
degenerate O
to O
exact Method
- Method
string Method
matching Method
. O
Moreover O
, O
these O
automatic Metric
metrics Metric
such O
as O
BLEU Metric
and O
ROUGE Metric
have O
been O
found O
to O
poorly O
correlate O
with O
human Metric
judgement Metric
for O
tasks O
such O
as O
image Task
caption Task
evaluation Task
[ O
reference O
] O
. O
For O
multiple Task
- Task
choice Task
task Task
, O
18 O
candidate O
answers O
are O
created O
for O
each O
question O
. O
As O
with O
the O
open Task
- Task
ended Task
task Task
, O
the O
accuracy Metric
of O
a O
chosen O
option O
is O
computed O
based O
on O
the O
number O
of O
human O
subjects O
who O
provided O
that O
answer O
( O
divided O
by O
3 O
and O
clipped O
at O
1 O
) O
. O
We O
generate O
a O
candidate O
set O
of O
correct O
and O
incorrect O
answers O
from O
four O
sets O
of O
answers O
: O
Correct O
: O
The O
most O
common O
( O
out O
of O
ten O
) O
correct O
answer O
. O
Plausible O
: O
To O
generate O
incorrect O
, O
but O
still O
plausible O
answers O
we O
ask O
three O
subjects O
to O
answer O
the O
questions O
without O
seeing O
the O
image O
. O
See O
the O
appendix O
for O
more O
details O
about O
the O
user O
interface O
to O
collect O
these O
answers O
. O
If O
three O
unique O
answers O
are O
not O
found O
, O
we O
gather O
additional O
answers O
from O
nearest Method
neighbor Method
questions O
using O
a O
bag Method
- Method
of Method
- Method
words Method
model Method
. O
The O
use O
of O
these O
answers O
helps O
ensure O
the O
image O
, O
and O
not O
just O
commonsense O
knowledge O
, O
is O
necessary O
to O
answer O
the O
question O
. O
Popular O
: O
These O
are O
the O
10 O
most O
popular O
answers O
. O
For O
instance O
, O
these O
are O
" O
yes O
" O
, O
" O
no O
" O
, O
" O
2 O
" O
, O
" O
1 O
" O
, O
" O
white O
" O
, O
" O
3 O
" O
, O
" O
red O
" O
, O
" O
blue O
" O
, O
" O
4 O
" O
, O
" O
green O
" O
for O
real Material
images Material
. O
The O
inclusion O
of O
the O
most O
popular O
answers O
makes O
it O
more O
difficult O
for O
algorithms O
to O
infer O
the O
type O
of O
question O
from O
the O
set O
of O
answers O
provided O
, O
i.e. O
, O
learning O
that O
it O
is O
a O
" O
yes O
or O
no O
" O
question O
just O
because O
" O
yes O
" O
and O
" O
no O
" O
are O
present O
in O
the O
answers O
. O
Random O
: O
Correct O
answers O
from O
random O
questions O
in O
the O
dataset O
. O
To O
generate O
a O
total O
of O
18 O
candidate O
answers O
, O
we O
first O
find O
the O
union O
of O
the O
correct O
, O
plausible O
, O
and O
popular O
answers O
. O
We O
include O
random O
answers O
until O
18 O
unique O
answers O
are O
found O
. O
The O
order O
of O
the O
answers O
is O
randomized O
. O
Example O
multiple O
choice O
questions O
are O
in O
the O
appendix O
. O
Note O
that O
all O
18 O
candidate O
answers O
are O
unique O
. O
But O
since O
10 O
different O
subjects O
answered O
every O
question O
, O
it O
is O
possible O
that O
more O
than O
one O
of O
those O
10 O
answers O
be O
present O
in O
the O
18 O
choices O
. O
In O
such O
cases O
, O
according O
to O
the O
accuracy Metric
metric Metric
, O
multiple O
options O
could O
have O
a O
non O
- O
zero O
accuracy O
. O
section O
: O
Real Material
Images Material
Abstract O
Scenes O
section O
: O
VQA Task
DATASET Task
ANALYSIS Task
In O
this O
section O
, O
we O
provide O
an O
analysis O
of O
the O
questions O
and O
answers O
in O
the O
VQA Material
train Material
dataset Material
. O
To O
gain O
an O
understanding O
of O
the O
types O
of O
questions O
asked O
and O
answers O
provided O
, O
we O
visualize O
the O
distribution O
of O
question O
types O
and O
answers O
. O
We O
also O
explore O
how O
often O
the O
questions O
may O
be O
answered O
without O
the O
image O
using O
just O
commonsense O
information O
. O
Finally O
, O
we O
analyze O
whether O
the O
information O
contained O
in O
an O
image O
caption O
is O
sufficient O
to O
answer O
the O
questions O
. O
The O
dataset O
includes O
614 O
, O
163 O
questions O
and O
7 O
, O
984 O
, O
119 O
answers O
( O
including O
answers O
provided O
by O
workers O
with O
and O
without O
looking O
at O
the O
image O
) O
for O
204 O
, O
721 O
images O
from O
the O
MS Material
COCO Material
dataset Material
[ O
reference O
] O
and O
150 O
, O
000 O
questions O
with O
1 O
, O
950 O
, O
000 O
answers O
for O
50 O
, O
000 O
abstract Material
scenes Material
. O
section O
: O
Questions O
Types O
of O
Question O
. O
Given O
the O
structure O
of O
questions O
generated O
in O
the O
English O
language O
, O
we O
can O
cluster O
questions O
into O
different O
types O
based O
on O
the O
words O
that O
start O
the O
question O
. O
Fig O
. O
3 O
shows O
the O
distribution O
of O
questions O
based O
on O
the O
first O
four O
words O
of O
the O
questions O
for O
both O
the O
real Material
images Material
( O
left O
) O
and O
abstract Material
scenes Material
( O
right O
) O
. O
Interestingly O
, O
the O
distribution O
of O
questions O
is O
quite O
similar O
for O
both O
real Material
images Material
and O
abstract Material
scenes Material
. O
This O
helps O
demonstrate O
that O
the O
type O
of O
questions O
elicited O
by O
the O
abstract Material
scenes Material
is O
similar O
to O
those O
elicited O
by O
the O
real Material
images Material
. O
There O
exists O
a O
surprising O
variety O
of O
question O
types O
, O
including O
" O
What O
is O
. O
. O
. O
" O
, O
" O
Is O
there O
. O
. O
. O
" O
, O
" O
How O
many O
. O
. O
. O
" O
, O
and O
" O
Does O
the O
. O
. O
. O
" O
. O
Quantitatively O
, O
the O
percentage O
of O
questions O
for O
different O
types O
is O
shown O
in O
Table O
3 O
. O
Several O
example O
questions O
and O
answers O
are O
shown O
in O
Fig O
. O
2 O
. O
A O
particularly O
interesting O
type O
of O
question O
is O
the O
" O
What O
is O
. O
. O
. O
" O
questions O
, O
since O
they O
have O
a O
diverse O
set O
2 O
. O
In O
order O
to O
be O
consistent O
with O
' O
human Metric
accuracies Metric
' O
reported O
in O
Section O
4 O
, O
machine Metric
accuracies Metric
are O
averaged O
over O
all O
[ O
reference O
] O
sets O
of O
human O
annotators O
Lengths O
. O
Fig O
. O
4 O
shows O
the O
distribution O
of O
question O
lengths O
. O
We O
see O
that O
most O
questions O
range O
from O
four O
to O
ten O
words O
. O
section O
: O
Answers O
Typical O
Answers O
. O
Lengths O
. O
Most O
answers O
consist O
of O
a O
single O
word O
, O
with O
the O
distribution O
of O
answers O
containing O
one O
, O
two O
, O
or O
three O
words O
, O
respectively O
being O
89.32 O
% O
, O
6.91 O
% O
, O
and O
2.74 O
% O
for O
real Material
images Material
and O
90.51 O
% O
, O
5.89 O
% O
, O
and O
2.49 O
% O
for O
abstract Material
scenes Material
. O
The O
brevity O
of O
answers O
is O
not O
surprising O
, O
since O
the O
questions O
tend O
to O
elicit O
specific O
information O
from O
the O
images O
. O
This O
is O
in O
contrast O
section O
: O
Answers O
with O
Images O
Answers O
without O
Images O
with O
image O
captions O
that O
generically O
describe O
the O
entire O
image O
and O
hence O
tend O
to O
be O
longer O
. O
The O
brevity O
of O
our O
answers O
makes O
automatic Task
evaluation Task
feasible O
. O
While O
it O
may O
be O
tempting O
to O
believe O
the O
brevity O
of O
the O
answers O
makes O
the O
problem O
easier O
, O
recall O
that O
they O
are O
human O
- O
provided O
open O
- O
ended O
answers O
to O
open O
- O
ended O
questions O
. O
The O
questions O
typically O
require O
complex O
reasoning O
to O
arrive O
at O
these O
deceptively O
simple O
answers O
( O
see O
Fig O
. O
2 O
) O
. O
There O
are O
currently O
23 O
, O
234 O
unique O
one O
- O
word O
answers O
in O
our O
dataset O
for O
real Material
images Material
and O
3 O
, O
770 O
for O
abstract Material
scenes Material
. O
' O
Yes O
/ O
No O
' O
and O
' O
Number O
' O
Answers O
. O
Many O
questions O
are O
answered O
using O
either O
" O
yes O
" O
or O
" O
no O
" O
( O
or O
sometimes O
" O
maybe O
" O
) O
- O
38.37 O
% O
and O
40.66 O
% O
of O
the O
questions O
on O
real Material
images Material
and O
abstract Material
scenes Material
respectively O
. O
Among O
these O
' O
yes O
/ O
no O
' O
questions O
, O
there O
is O
a O
bias O
towards O
" O
yes O
" O
- O
58.83 O
% O
and O
55.86 O
% O
of O
' O
yes O
/ O
no O
' O
answers O
are O
" O
yes O
" O
for O
real Material
images Material
and O
abstract Material
scenes Material
. O
Question O
types O
such O
as O
" O
How O
many O
. O
. O
. O
" O
are O
answered O
using O
numbers O
- O
12.31 O
% O
and O
14.48 O
% O
of O
the O
questions O
on O
real Material
images Material
and O
abstract Material
scenes Material
are O
' O
number O
' O
questions O
. O
" O
2 O
" O
is O
the O
most O
popular O
answer O
among O
the O
' O
number O
' O
questions O
, O
making O
up O
26.04 O
% O
of O
the O
' O
number O
' O
answers O
for O
real Material
images Material
and O
39.85 O
% O
for O
abstract Material
scenes Material
. O
Subject O
Confidence O
. O
When O
the O
subjects O
answered O
the O
questions O
, O
we O
asked O
" O
Do O
you O
think O
you O
were O
able O
to O
answer O
the O
question O
correctly O
? O
" O
. O
Fig O
. O
6 O
shows O
the O
distribution O
of O
responses O
. O
A O
majority O
of O
the O
answers O
were O
labeled O
as O
confident O
for O
both O
real Material
images Material
and O
abstract Material
scenes Material
. O
Inter Metric
- Metric
human Metric
Agreement Metric
. O
Does O
the O
self O
- O
judgment O
of O
confidence O
correspond O
to O
the O
answer O
agreement O
between O
subjects O
? O
Fig O
. O
6 O
shows O
the O
percentage O
of O
questions O
in O
which O
( O
i O
) O
7 O
or O
more O
, O
( O
ii O
) O
3−7 O
, O
or O
( O
iii O
) O
less O
than O
3 O
subjects O
agree O
on O
the O
answers O
given O
their O
average O
confidence O
score O
( O
0 O
= O
not O
confident O
, O
1 O
= O
confident O
) O
. O
As O
expected O
, O
the O
agreement O
between O
subjects O
7 O
or O
more O
same O
3 O
- O
7 O
same O
less O
than O
3 O
same O
# O
of O
Questions O
increases O
with O
confidence O
. O
However O
, O
even O
if O
all O
of O
the O
subjects O
are O
confident O
the O
answers O
may O
still O
vary O
. O
This O
is O
not O
surprising O
since O
some O
answers O
may O
vary O
, O
yet O
have O
very O
similar O
meaning O
, O
such O
as O
" O
happy O
" O
and O
" O
joyful O
" O
. O
As O
shown O
in O
Table O
1 O
( O
Question Material
+ Material
Image Material
) O
, O
there O
is O
significant O
inter O
- O
human O
agreement O
in O
the O
answers O
for O
both O
real Material
images Material
( O
83.30 O
% O
) O
and O
abstract Material
scenes Material
( O
87.49 O
% O
) O
. O
Note O
that O
on O
average O
each O
question O
has O
2.70 O
unique O
answers O
for O
real Material
images Material
and O
2.39 O
for O
abstract Material
scenes Material
. O
The O
agreement O
is O
significantly O
higher O
( O
> O
95 O
% O
) O
for O
" O
yes O
/ O
no O
" O
questions O
and O
lower O
for O
other O
questions O
( O
< O
76 O
% O
) O
, O
possibly O
due O
to O
the O
fact O
that O
we O
perform O
exact Method
string Method
matching Method
and O
do O
not O
account O
for O
synonyms O
, O
plurality O
, O
etc O
. O
Note O
that O
the O
automatic Task
determination Task
of Task
synonyms Task
is O
a O
difficult O
problem O
, O
since O
the O
level O
of O
answer O
granularity O
can O
vary O
across O
questions O
. O
section O
: O
Commonsense O
Knowledge O
Is O
the O
Image O
Necessary O
? O
Clearly O
, O
some O
questions O
can O
sometimes O
be O
answered O
correctly O
using O
commonsense O
knowledge O
alone O
without O
the O
need O
for O
an O
image O
, O
e.g. O
, O
" O
What O
is O
the O
color O
of O
the O
fire O
hydrant O
? O
" O
. O
We O
explore O
this O
issue O
by O
asking O
three O
subjects O
to O
answer O
the O
questions O
without O
seeing O
the O
image O
( O
see O
the O
examples O
in O
blue O
in O
Fig O
. O
2 O
) O
. O
In O
Table O
1 O
( O
Question O
) O
, O
we O
show O
the O
percentage O
of O
questions O
for O
which O
the O
correct O
answer O
is O
provided O
over O
all O
questions O
, O
" O
yes O
/ O
no O
" O
questions O
, O
and O
the O
other O
questions O
that O
are O
not O
" O
yes O
/ O
no O
" O
. O
For O
" O
yes O
/ O
no O
" O
questions O
, O
the O
human O
subjects O
respond O
better O
than O
chance O
. O
For O
other O
questions O
, O
humans O
are O
only O
correct O
about O
21 O
% O
of O
the O
time O
. O
This O
demonstrates O
that O
understanding O
the O
visual O
information O
is O
critical O
to O
VQA Task
and O
that O
commonsense O
information O
alone O
is O
not O
sufficient O
. O
To O
show O
the O
qualitative O
difference O
in O
answers O
provided O
with O
and O
without O
images O
, O
we O
show O
the O
distribution O
of O
answers O
for O
various O
question O
types O
in O
Fig O
. O
5 O
( O
bottom O
) O
. O
The O
distribution O
of O
colors O
, O
numbers O
, O
and O
even O
" O
yes O
/ O
no O
" O
responses O
is O
surprisingly O
different O
for O
answers O
with O
and O
without O
images O
. O
Which O
Questions O
Require O
Common O
Sense O
? O
In O
order O
to O
identify O
questions O
that O
require O
commonsense Method
reasoning Method
to O
answer O
, O
we O
conducted O
two O
AMT Method
studies Method
( O
on O
a O
subset O
10 O
K O
questions O
from O
the O
real Material
images Material
of O
VQA Task
trainval O
) O
asking O
subjects O
- O
1 O
) O
Whether O
or O
not O
they O
believed O
a O
question O
required O
commonsense O
to O
answer O
the O
question O
, O
and O
2 O
) O
The O
youngest O
age O
group O
that O
they O
believe O
a O
person O
must O
be O
in O
order O
to O
be O
able O
to O
correctly O
answer O
the O
question O
- O
toddler O
( O
3 O
- O
4 O
) O
, O
younger O
child O
( O
5 O
- O
8 O
) O
, O
older O
child O
( O
9 O
- O
12 O
) O
, O
teenager O
[ O
reference O
][ O
reference O
][ O
reference O
][ O
reference O
][ O
reference O
] O
, O
adult O
( O
18 O
+ O
) O
. O
Each O
question O
was O
shown O
to O
10 O
subjects O
. O
We O
found O
that O
for O
47.43 O
% O
of O
questions O
3 O
or O
more O
subjects O
voted O
' O
yes O
' O
to O
commonsense O
, O
( O
18.14 O
% O
: O
6 O
or O
more O
) O
. O
In O
the O
' O
perceived O
human O
age O
required O
to O
answer O
question O
' O
study O
, O
we O
found O
the O
following O
distribution O
of O
responses O
: O
toddler O
: O
15.3 O
% O
, O
younger O
child O
: O
39.7 O
% O
, O
older O
child O
: O
28.4 O
% O
, O
teenager O
: O
11.2 O
% O
, O
adult O
: O
5.5 O
% O
. O
In O
Figure O
7 O
we O
show O
several O
questions O
for O
which O
a O
majority O
of O
subjects O
picked O
the O
specified O
age O
range O
. O
Surprisingly O
the O
perceived O
age O
needed O
to O
answer O
the O
questions O
is O
fairly O
well O
distributed O
across O
the O
different O
age O
ranges O
. O
As O
expected O
the O
questions O
that O
were O
judged O
answerable O
by O
an O
adult O
( O
18 O
+ O
) O
generally O
need O
specialized O
knowledge O
, O
whereas O
those O
answerable O
by O
a O
toddler O
( O
3 O
- O
4 O
) O
are O
more O
generic O
. O
We O
measure O
the O
degree O
of O
commonsense O
required O
to O
answer O
a O
question O
as O
the O
percentage O
of O
subjects O
( O
out O
of O
10 O
) O
who O
voted O
" O
yes O
" O
in O
our O
" O
whether O
or O
not O
a O
question O
requires O
commonsense O
" O
study O
. O
A O
fine O
- O
grained O
breakdown O
of O
average Metric
age Metric
and O
average Metric
degree Metric
of Metric
common Metric
sense Metric
( O
on O
a O
scale O
of O
0 O
− O
100 O
) O
required O
to O
answer O
a O
question O
is O
shown O
in O
Table O
3 O
. O
The O
average O
age O
and O
the O
average O
degree O
of O
commonsense O
across O
all O
questions O
is O
8.92 O
and O
31.01 O
% O
respectively O
. O
It O
is O
important O
to O
distinguish O
between O
: O
1 O
) O
How O
old O
someone O
needs O
to O
be O
to O
be O
able O
to O
answer O
a O
question O
correctly O
, O
and O
2 O
) O
How O
old O
people O
think O
someone O
needs O
to O
be O
to O
be O
able O
to O
answer O
a O
question O
correctly O
. O
Our O
age Method
annotations Method
capture O
the O
latter O
- O
perceptions O
of O
MTurk O
workers O
in O
an O
uncontrolled O
environment O
. O
As O
such O
, O
the O
relative O
ordering O
of O
question O
types O
in O
Table O
3 O
is O
more O
important O
than O
absolute O
age O
numbers O
. O
The O
two O
rankings O
of O
questions O
in O
terms O
of O
common O
sense O
required O
according O
to O
the O
two O
studies O
were O
largely O
correlated O
( O
Pearson Metric
's Metric
rank Metric
correlation Metric
: O
0.58 O
) O
. O
section O
: O
Captions O
vs. O
Questions O
Do O
generic O
image O
captions O
provide O
enough O
information O
to O
answer O
the O
questions O
? O
section O
: O
VQA Task
BASELINES O
AND O
METHODS O
In O
this O
section O
, O
we O
explore O
the O
difficulty O
of O
the O
VQA Material
dataset Material
for O
the O
MS Material
COCO Material
images O
using O
several O
baselines O
and O
novel O
methods O
. O
We O
train O
on O
VQA Task
train O
+ O
val O
. O
Unless O
stated O
otherwise O
, O
all O
human Metric
accuracies Metric
are O
on O
test O
- O
standard O
, O
machine Metric
accuracies Metric
are O
on O
test O
- O
dev O
, O
and O
results O
involving O
human O
captions O
( O
in O
gray O
font O
) O
are O
trained O
on O
train O
and O
tested O
on O
val O
( O
because O
captions O
are O
not O
available O
for O
test O
) O
. O
section O
: O
Baselines O
We O
implemented O
the O
following O
baselines O
: O
1 O
) O
random O
: O
We O
randomly O
choose O
an O
answer O
from O
the O
top O
1 O
K O
answers O
of O
the O
VQA Task
train O
/ O
val O
dataset O
. O
2 O
) O
prior O
( O
" O
yes O
" O
) O
: O
We O
always O
select O
the O
most O
popular O
answer O
( O
" O
yes O
" O
) O
for O
both O
the O
open Task
- Task
ended Task
and Task
multiple Task
- Task
choice Task
tasks Task
. O
Note O
that O
" O
yes O
" O
is O
always O
one O
of O
the O
choices O
for O
the O
multiple O
- O
choice O
questions O
. O
3 O
) O
per O
Q Method
- Method
type Method
prior Method
: O
For O
the O
open Task
- Task
ended Task
task Task
, O
we O
pick O
the O
most O
popular O
answer O
per O
question O
type O
( O
see O
the O
appendix O
for O
details O
) O
. O
For O
the O
multiple Task
- Task
choice Task
task Task
, O
we O
pick O
the O
answer O
( O
from O
the O
provided O
choices O
) O
that O
is O
most O
similar O
to O
the O
picked O
answer O
for O
the O
open O
- O
ended O
task O
using O
cosine O
similarity O
in O
Word2Vec O
[ O
reference O
] O
feature O
space O
. O
4 O
) O
nearest Method
neighbor Method
: O
Given O
a O
test O
image O
, O
question O
pair O
, O
we O
first O
find O
the O
K O
nearest Method
neighbor Method
questions O
and O
associated O
images O
from O
the O
training O
set O
. O
See O
appendix O
for O
details O
on O
how O
neighbors O
are O
found O
. O
Next O
, O
for O
the O
open Task
- Task
ended Task
task Task
, O
we O
pick O
the O
most O
frequent O
ground O
truth O
answer O
from O
this O
set O
of O
nearest Method
neighbor Method
question O
, O
image O
pairs O
. O
Similar O
to O
the O
" O
per O
Q Method
- Method
type Method
prior Method
" O
baseline O
, O
for O
the O
multiple Task
- Task
choice Task
task Task
, O
we O
pick O
the O
answer O
( O
from O
the O
provided O
choices O
) O
that O
is O
most O
similar O
to O
the O
picked O
answer O
for O
the O
open O
- O
ended O
task O
using O
cosine O
similarity O
in O
Word2Vec Method
[ O
reference O
] O
feature O
space O
. O
section O
: O
Methods O
For O
our O
methods O
, O
we O
develop O
a O
2 Method
- Method
channel Method
vision Method
( Method
image Method
) Method
+ Method
language Method
( Method
question Method
) Method
model Method
that O
culminates O
with O
a O
softmax O
over O
K O
possible O
outputs O
. O
We O
choose O
the O
top O
K O
= O
1000 O
most O
frequent O
answers O
as O
possible O
outputs O
. O
This O
set O
of O
answers O
covers O
82.67 O
% O
of O
the O
train O
+ O
val O
answers O
. O
We O
describe O
the O
different O
components O
of O
our O
model O
below O
: O
Image Task
Channel Task
: O
This O
channel O
provides O
an O
embedding O
for O
the O
image O
. O
We O
experiment O
with O
two O
embeddings O
- O
1 O
) O
I O
: O
The O
activations O
from O
the O
last O
hidden Method
layer Method
of O
VGGNet Method
[ O
reference O
] O
are O
used O
as O
4096 Task
- Task
dim Task
image Task
embedding Task
. O
2 O
) O
norm O
I O
: O
These O
are O
2 O
normalized O
activations O
from O
the O
last O
hidden Method
layer Method
of O
VGGNet Method
[ O
reference O
] O
. O
Question Task
Channel Task
: O
This O
channel O
provides O
an O
embedding O
for O
the O
question O
. O
We O
experiment O
with O
three O
embeddings O
- O
1 O
) O
Bag Task
- Task
of Task
- Task
Words Task
Question Task
( O
BoW Task
Q Task
) O
: O
The O
top O
1 O
, O
000 O
words O
in O
the O
questions O
are O
used O
to O
create O
a O
bag Method
- Method
of Method
- Method
words Method
representation Method
. O
Since O
there O
is O
a O
strong O
correlation O
between O
the O
words O
that O
start O
a O
question O
and O
the O
answer O
( O
see O
Fig O
. O
5 O
) O
, O
we O
find O
the O
top O
10 O
first O
, O
second O
, O
and O
third O
words O
of O
the O
questions O
and O
create O
a O
30 Method
dimensional Method
bag Method
- Method
of Method
- Method
words Method
representation Method
. O
These O
features O
are O
concatenated O
to O
get O
a O
1 Method
, Method
030 Method
- Method
dim Method
embedding Method
for O
the O
question O
. O
. O
This O
model O
uses O
a O
two O
layer O
LSTM Method
to O
encode O
the O
questions O
and O
the O
last O
hidden Method
layer Method
of O
VGGNet Method
[ O
reference O
] O
to O
encode O
the O
images O
. O
The O
image O
features O
are O
then O
2 O
normalized O
. O
Both O
the O
question O
and O
image O
features O
are O
transformed O
to O
a O
common O
space O
and O
fused O
via O
element Method
- Method
wise Method
multiplication Method
, O
which O
is O
then O
passed O
through O
a O
fully Method
connected Method
layer Method
followed O
by O
a O
softmax Method
layer Method
to O
obtain O
a O
distribution O
over O
answers O
. O
being O
512 O
- O
dim O
) O
from O
each O
of O
the O
two O
hidden Method
layers Method
of O
the O
LSTM Method
. O
Hence O
2 O
( O
hidden Method
layers Method
) O
x O
2 O
( O
cell O
state O
and O
hidden O
state O
) O
x O
512 O
( O
dimensionality O
of O
each O
of O
the O
cell O
states O
, O
as O
well O
as O
hidden O
states O
) O
in O
Fig O
. O
8 O
. O
This O
is O
followed O
by O
a O
fully Method
- Method
connected Method
layer Method
+ Method
tanh Method
non Method
- Method
linearity Method
to O
transform O
2048 Task
- Task
dim Task
embedding Task
to O
1024 O
- O
dim O
. O
The O
question O
words O
are O
encoded O
in O
the O
same O
way O
as O
in O
LSTM Method
Q. O
Multi O
- O
Layer O
Perceptron O
( O
MLP O
) O
: O
The O
image O
and O
question O
embeddings O
are O
combined O
to O
obtain O
a O
single O
embedding O
. O
1 O
) O
For O
BoW Task
Q Task
+ O
I Method
method Method
, O
we O
simply O
concatenate O
the O
BoW O
Q O
and O
I O
embeddings O
. O
2 O
) O
For O
LSTM Method
Q O
+ O
I O
, O
and O
deeper O
LSTM Method
Q O
+ O
norm O
I O
( O
Fig O
. O
8 O
) O
methods O
, O
the O
image Task
embedding Task
is O
first O
transformed O
to O
1024 O
- O
dim O
by O
a O
fully Method
- Method
connected Method
layer Method
+ Method
tanh Method
non Method
- Method
linearity Method
to O
match O
the O
LSTM Method
embedding O
of O
the O
question O
. O
The O
transformed O
image O
and O
LSTM Method
embeddings O
( O
being O
in O
a O
common O
space O
) O
are O
then O
fused O
via O
element Method
- Method
wise Method
multiplication Method
. O
This O
combined O
image Method
+ Method
question Method
embedding Method
is O
then O
passed O
to O
an O
MLP Method
- Method
a Method
fully Method
connected Method
neural Method
network Method
classifier Method
with O
2 O
hidden Method
layers Method
and O
1000 O
hidden O
units O
( O
dropout O
0.5 O
) O
in O
each O
layer O
with O
tanh O
non O
- O
linearity O
, O
followed O
by O
a O
softmax Method
layer Method
to O
obtain O
a O
distribution O
over O
K O
answers O
. O
The O
entire O
model O
is O
learned O
end O
- O
to O
- O
end O
with O
a O
cross Metric
- Metric
entropy Metric
loss Metric
. O
VGGNet Method
parameters Method
are O
frozen O
to O
those O
learned O
for O
ImageNet Task
classification Task
and O
not O
fine O
- O
tuned O
in O
the O
image O
channel O
. O
We O
also O
experimented O
with O
providing O
captions O
as O
input O
to O
our O
model O
. O
Similar O
to O
Table O
1 O
, O
we O
assume O
that O
a O
human O
- O
generated O
caption O
is O
given O
as O
input O
. O
We O
use O
a O
bag Method
- Method
of Method
- Method
words Method
representation Method
containing O
the O
1 O
, O
000 O
most O
popular O
words O
in O
the O
captions O
as O
the O
caption O
embedding O
( O
Caption O
) O
. O
For O
BoW Method
Question Method
+ Method
Caption Method
( O
BoW Method
Q Method
+ Method
C Method
) Method
method Method
, O
we O
simply O
concatenate O
the O
BoW Method
Q Method
and Method
C Method
embeddings Method
. O
possible O
K O
answers O
and O
multiple O
- O
choice O
picks O
the O
answer O
that O
has O
the O
highest O
activation O
from O
the O
potential O
answers O
. O
[ O
reference O
] O
. O
The O
accuracy Metric
of O
our O
best O
model O
( O
deeper O
LSTM Method
Q O
+ O
norm O
I O
( O
Fig O
. O
8 O
) O
, O
selected O
using O
VQA Task
test O
- O
dev O
accuracies O
) O
on O
VQA Task
teststandard O
is O
[ O
reference O
] O
.16 O
% O
( O
open O
- O
ended O
) O
/ O
63.09 O
% O
( O
multiple Metric
- Metric
choice Metric
) O
. O
section O
: O
Results O
We O
can O
see O
that O
our O
model O
is O
able O
to O
significantly O
outperform O
both O
the O
vision Method
- Method
alone Method
and Method
language Method
- Method
alone Method
baselines Method
. O
As O
a O
general O
trend O
, O
results O
on O
multiple Task
- Task
choice Task
are O
better O
than O
open O
- O
ended O
. O
All O
methods O
are O
significantly O
worse O
than O
human O
performance O
. O
Our O
VQA Task
demo O
is O
available O
on O
CloudCV O
[ O
1 O
] O
- O
http: O
// O
cloudcv O
. O
org O
/ O
vqa O
. O
This O
will O
be O
updated O
with O
newer O
models O
as O
we O
develop O
them O
. O
To O
gain O
further O
insights O
into O
these O
results O
, O
we O
computed O
accuracies Metric
by O
question O
type O
in O
Table O
3 O
. O
Interestingly O
, O
for O
question O
types O
that O
require O
more O
reasoning O
, O
such O
as O
" O
Is O
the O
" O
or O
" O
How O
many O
" O
, O
the O
scene O
- O
level O
image O
features O
do O
not O
provide O
any O
additional O
information O
. O
However O
, O
for O
questions O
that O
can O
be O
answered O
using O
scene O
- O
level O
information O
, O
such O
as O
" O
What O
sport O
, O
" O
we O
do O
see O
an O
improvement O
. O
Similarly O
, O
for O
questions O
whose O
answer O
may O
be O
contained O
in O
a O
generic O
caption O
we O
see O
improvement O
, O
such O
as O
" O
What O
animal O
" O
. O
For O
all O
question O
types O
, O
the O
results O
are O
worse O
than O
human Metric
accuracies Metric
. O
We O
also O
analyzed O
the O
accuracies Metric
of O
our O
best O
model O
( O
deeper O
LSTM Method
Q O
+ O
norm O
I O
) O
on O
a O
subset O
of O
questions O
with O
certain O
specific O
( O
ground O
truth O
) O
answers O
. O
In O
Fig O
. O
9 O
, O
we O
show O
the O
average O
accuracy Metric
of O
the O
model O
on O
questions O
with O
50 O
most O
frequent O
ground O
truth O
answers O
on O
the O
VQA Material
validation Material
set Material
( O
plot O
is O
sorted O
by O
accuracy Metric
, O
not O
frequency O
) O
. O
We O
can O
see O
that O
the O
model O
performs O
well O
for O
answers O
that O
are O
common O
visual O
objects O
such O
as O
" O
wii O
" O
, O
" O
tennis O
" O
, O
" O
bathroom O
" O
while O
the O
performance O
is O
somewhat O
underwhelming O
for O
counts O
( O
e.g. O
, O
" O
2 O
" O
, O
" O
1 O
" O
, O
" O
3 O
" O
) O
, O
and O
particularly O
poor O
for O
higher O
counts O
( O
e.g. O
, O
" O
5 O
" O
, O
" O
6 O
" O
, O
" O
10 O
" O
, O
" O
8 O
" O
, O
" O
7 O
" O
) O
. O
In O
Fig O
. O
10 O
, O
we O
show O
the O
distribution O
of O
50 O
most O
frequently O
predicted O
answers O
when O
the O
system O
is O
correct O
on O
the O
VQA Material
validation Material
set Material
( O
plot O
is O
sorted O
by O
prediction O
frequency O
, O
not O
accuracy Metric
) O
. O
In O
this O
analysis O
, O
" O
system O
is O
correct O
" O
implies O
that O
it O
has O
VQA Task
accuracy O
1.0 O
( O
see O
section O
3 O
for O
accuracy Metric
metric Metric
) O
. O
We O
can O
see O
that O
the O
frequent O
ground O
truth O
answers O
( O
e.g. O
, O
" O
yes O
" O
, O
" O
no O
" O
, O
" O
2 O
" O
, O
" O
white O
" O
, O
" O
red O
" O
, O
" O
blue O
" O
, O
" O
1 O
" O
, O
" O
green O
" O
) O
are O
more O
frequently O
predicted O
than O
others O
when O
the O
model O
is O
correct O
. O
Finally O
, O
evaluating O
our O
best O
model O
( O
deeper O
LSTM Method
Q O
+ O
norm O
I O
) O
on O
the O
validation O
questions O
for O
which O
we O
have O
age O
annotations O
( O
how O
old O
a O
human O
needs O
to O
be O
to O
answer O
the O
question O
correctly O
) O
, O
we O
estimate O
that O
our O
model O
performs O
as O
well O
as O
a O
4.74 O
year O
old O
child O
! O
The O
average O
age O
required O
on O
the O
same O
set O
of O
questions O
is O
8.98 O
. O
Evaluating O
the O
same O
model O
on O
the O
validation O
questions O
for O
which O
we O
have O
commonsense O
annotations O
( O
whether O
the O
question O
requires O
commonsense O
to O
answer O
it O
) O
, O
we O
estimate O
that O
it O
has O
degree O
of O
commonsense O
of O
17.35 O
% O
. O
The O
average O
degree O
of O
commonsense O
required O
on O
same O
set O
of O
questions O
is O
31.23 O
% O
. O
Again O
, O
these O
estimates O
reflect O
the O
age O
and O
commonsense O
perceived O
by O
MTurk O
workers O
that O
would O
be O
required O
to O
answer O
the O
question O
. O
See O
the O
appendix O
for O
details O
. O
We O
further O
analyzed O
the O
performance O
of O
the O
model O
for O
different O
age O
groups O
on O
the O
validation O
questions O
for O
which O
we O
have O
age O
annotations O
. O
In O
Fig O
. O
11 O
, O
we O
computed O
the O
average O
accuracy Metric
of O
the O
predictions O
made O
by O
the O
model O
for O
questions O
belonging O
to O
different O
age O
groups O
. O
Perhaps O
as O
expected O
, O
the O
accuracy Metric
of O
the O
model O
decreases O
as O
the O
age O
of O
the O
question O
increases O
( O
from O
61.07 O
% O
at O
3 O
− O
4 O
age O
group O
to O
47.83 O
% O
at O
18 O
+ O
age O
group O
) O
. O
In O
Fig O
. O
12 O
, O
we O
show O
the O
distribution O
of O
age O
of O
questions O
for O
different O
levels O
of O
accuracies Metric
achieved O
by O
our O
system O
on O
the O
validation O
questions O
for O
which O
we O
have O
age O
annotations O
. O
It O
is O
interesting O
to O
see O
that O
the O
relative O
proportions O
of O
different O
age O
groups O
is O
consistent O
across O
all O
accuracy O
bins O
with O
questions O
belonging O
to O
the O
age O
group O
5 O
- O
8 O
comprising O
the O
majority O
of O
the O
predictions O
which O
is O
expected O
because O
5 O
- O
8 O
is O
the O
most O
common O
age O
group O
in O
the O
dataset O
( O
see O
Fig O
. O
7 O
) O
. O
Table O
4 O
shows O
the O
accuracy Metric
of O
different O
ablated Method
versions Method
of O
our O
best O
model O
( O
deeper O
LSTM Method
Q O
+ O
norm O
I O
) O
for O
both O
the O
openended Task
and Task
multiple Task
- Task
choice Task
tasks Task
on O
the O
VQA Material
test Material
- Material
dev Material
for O
real Material
images Material
. O
The O
different O
ablated O
versions O
are O
as O
follows O
- O
1 O
) O
Without O
I O
Norm O
: O
In O
this O
model O
, O
the O
activations O
from O
the O
last O
hidden Method
layer Method
of O
VGGNet Method
[ O
reference O
] O
are O
not O
2 O
- O
normalized O
. O
Comparing O
the O
accuracies Metric
in O
Table O
4 O
and O
parameters O
in O
the O
following O
fully Method
- Method
connected Method
layer Method
. O
Comparing O
the O
accuracies Metric
in O
Table O
4 O
and O
Table O
2 O
, O
we O
can O
see O
that O
element Method
- Method
wise Method
fusion Method
performs O
better O
by O
0.95 O
% O
for O
open Task
- Task
ended Task
task Task
and O
by O
1.24 O
% O
for O
multiple Task
- Task
choice Task
task Task
. O
3 O
) O
K O
= O
500 O
: O
In O
this O
model O
, O
we O
use O
K O
= O
500 O
most O
frequent O
answers O
as O
possible O
outputs O
. O
Comparing O
the O
accuracies Metric
in O
Table O
4 O
and O
Table O
2 O
, O
we O
can O
see O
that O
K O
= O
1000 O
performs O
better O
than O
K O
= O
500 O
by O
0 O
.82 O
% O
for O
open Task
- Task
ended Task
task Task
and O
by O
1.92 O
% O
for O
multiple Task
- Task
choice Task
task Task
. O
section O
: O
4 O
) O
K O
= O
2000 O
: O
In O
this O
model O
, O
we O
use O
K O
= O
2000 O
most O
frequent O
answers O
as O
possible O
outputs O
. O
Comparing O
the O
accuracies Metric
in O
Table O
4 O
and O
Table O
2 O
, O
we O
can O
see O
that O
K O
= O
2000 O
performs O
better O
then O
K O
= O
1000 O
by O
0.40 O
% O
for O
open Task
- Task
ended Task
task Task
and O
by O
1.16 O
% O
for O
multiple Task
- Task
choice Task
task Task
. O
5 O
) O
Truncated O
Q O
Vocab O
@ O
5 O
: O
In O
this O
model O
, O
the O
input O
vocabulary O
to O
the O
embedding Method
layer Method
( O
which O
encodes O
the O
question O
words O
) O
consists O
of O
only O
those O
question O
words O
which O
occur O
atleast O
5 O
times O
in O
the O
training O
dataset O
, O
thus O
reducing O
the O
vocabulary Metric
size Metric
from O
14770 O
( O
when O
all O
question O
words O
are O
used O
) O
to O
5134 O
( O
65.24 O
% O
reduction O
) O
. O
Remaining O
question O
words O
are O
replaced O
with O
UNK O
( O
unknown O
) O
tokens O
. O
Comparing O
the O
accuracies Metric
in O
Table O
4 O
and O
Table O
2 O
, O
we O
can O
see O
that O
truncating O
the O
question O
vocabulary O
@ O
5 O
performs O
better O
than O
using O
all O
questions O
words O
by O
0.24 O
% O
for O
openended Task
task Task
and O
by O
0.17 O
% O
for O
multiple Task
- Task
choice Task
task Task
. O
6 O
) O
Truncated O
Q O
Vocab O
@ O
11 O
: O
In O
this O
model O
, O
the O
input O
vocabulary O
to O
the O
embedding Method
layer Method
( O
which O
encodes O
the O
question O
words O
) O
consists O
of O
only O
those O
question O
words O
which O
occur O
atleast O
11 O
times O
in O
the O
training O
dataset O
, O
thus O
reducing O
the O
vocabulary Metric
size Metric
from O
14770 O
( O
when O
all O
question O
words O
are O
used O
) O
to O
3561 O
( O
75.89 O
% O
reduction O
) O
. O
Remaining O
question O
words O
are O
replaced O
with O
UNK O
( O
unknown O
) O
tokens O
. O
Comparing O
the O
accuracies Metric
in O
Table O
4 O
and O
Table O
2 O
, O
we O
can O
see O
that O
truncating O
the O
question O
vocabulary O
@ O
11 O
performs O
better O
than O
using O
all O
questions O
words O
by O
0.06 O
% O
for O
open Task
- Task
ended Task
task Task
and O
by O
0.02 O
% O
for O
multiple Task
- Task
choice Task
task Task
. O
7 O
) O
Filtered O
Dataset O
: O
We O
created O
a O
filtered O
version O
of O
the O
VQA Material
train Material
+ Material
val Material
dataset Material
in O
which O
we O
only O
keep O
the O
answers O
with O
subject O
confidence O
" O
yes O
" O
. O
Also O
, O
we O
keep O
only O
those O
questions O
for O
which O
at O
least O
50 O
% O
( O
5 O
out O
of O
10 O
) O
answers O
are O
annotated O
with O
subject O
confidence O
" O
yes O
" O
. O
The O
resulting O
filtered O
dataset O
consists O
of O
344600 O
questions O
, O
compared O
to O
369861 O
questions O
in O
the O
original O
dataset O
, O
thus O
leading O
to O
only O
6.83 O
% O
reduction O
in O
the O
size O
of O
the O
dataset O
. O
The O
filtered O
dataset O
has O
8.77 O
answers O
per O
question O
on O
average O
. O
We O
did O
not O
filter O
the O
test O
set O
so O
that O
accuracies Metric
of O
the O
model O
trained O
on O
the O
filtered O
dataset O
can O
be O
compared O
with O
that O
of O
the O
model O
trained O
on O
the O
original O
dataset O
. O
The O
row O
" O
Filtered O
Dataset O
" O
in O
Table O
4 O
shows O
the O
performance O
of O
the O
deeper O
LSTM Method
Q O
+ O
norm O
I O
model O
when O
trained O
on O
the O
filtered O
dataset O
. O
Comparing O
these O
accuracies Metric
with O
the O
corresponding O
accuracies Metric
in O
Table O
2 O
, O
we O
can O
see O
that O
the O
model O
trained O
on O
filtered Method
version Method
performs O
worse O
by O
[ O
reference O
] O
.13 O
% O
for O
open Task
- Task
ended Task
task Task
and O
by O
1.88 O
% O
for O
multiplechoice Task
task Task
. O
section O
: O
VQA Task
CHALLENGE O
AND O
WORKSHOP O
We O
have O
set O
up O
an O
evaluation O
server O
[ O
reference O
] O
where O
results O
may O
be O
uploaded O
for O
the O
test O
set O
and O
it O
returns O
an O
accuracy Metric
breakdown Metric
. O
We O
are O
organizing O
an O
annual O
challenge O
and O
workshop O
to O
facilitate O
systematic O
progress O
in O
this O
area O
; O
the O
first O
instance O
of O
the O
workshop O
will O
be O
held O
at O
CVPR O
2016 O
[ O
reference O
] O
. O
We O
suggest O
that O
papers O
reporting O
results O
on O
the O
VQA Material
dataset Material
- O
1 O
) O
Report O
test Metric
- Metric
standard Metric
accuracies Metric
, O
which O
can O
be O
calculated O
using O
either O
of O
the O
non Method
- Method
test Method
- Method
dev Method
phases Method
, O
i.e. O
, O
" O
test2015 O
" O
or O
" O
Challenge O
test2015 O
" O
on O
the O
following O
links O
: O
[ O
oe O
- O
real O
| O
oe O
- O
abstract O
| O
mc O
- O
real O
| O
mc O
- O
abstract O
] O
. O
2 O
) O
Compare O
their O
test O
- O
standard O
accuracies Metric
with O
those O
on O
the O
corresponding O
test2015 O
leaderboards O
[ O
oe O
- O
real O
- O
leaderboard O
| O
oe O
- O
abstract O
- O
leaderboard O
| O
mc O
- O
real O
- O
leaderboard O
| O
mcabstract Method
- O
leaderboard O
] O
. O
For O
more O
details O
, O
please O
see O
the O
challenge O
page O
[ O
reference O
] O
. O
Screenshots O
of O
leaderboards Method
for O
open Material
- Material
ended Material
- Material
real Material
and O
multiple Material
- Material
choice Material
- Material
real Material
are O
shown O
in O
Fig O
. O
13 O
. O
We O
also O
compare O
the O
test O
- O
standard O
accuracies Metric
of O
our O
best O
model O
( O
deeper O
LSTM Method
Q O
+ O
norm O
I O
) O
for O
both O
open Task
- Task
ended Task
and Task
multiple Task
- Task
choice Task
tasks Task
( O
real Material
images Material
) O
with O
other O
entries O
( O
as O
of O
October O
28 O
, O
2016 O
) O
on O
the O
corresponding O
leaderboards O
in O
Table O
5 O
. O
section O
: O
CONCLUSION O
AND O
DISCUSSION O
In O
conclusion O
, O
we O
introduce O
the O
task O
of O
Visual Task
Question Task
Answering Task
( O
VQA Task
) O
. O
[ O
reference O
] O
language O
question O
about O
the O
image O
, O
the O
task O
is O
to O
provide O
an O
accurate O
natural O
language O
answer O
. O
We O
provide O
a O
dataset O
containing O
over O
250 O
K O
images O
, O
760 O
K O
questions O
, O
and O
around O
10 O
M O
answers O
. O
We O
demonstrate O
the O
wide O
variety O
of O
questions O
and O
answers O
in O
our O
dataset O
, O
as O
well O
as O
the O
diverse O
set O
of O
AI O
capabilities O
in O
computer Method
vision Method
, O
natural Method
language Method
processing Method
, O
and O
commonsense Method
reasoning Method
required O
to O
answer O
these O
questions O
accurately O
. O
The O
questions O
we O
solicited O
from O
our O
human O
subjects O
were O
open O
- O
ended O
and O
not O
task O
- O
specific O
. O
For O
some O
application O
domains O
, O
it O
would O
be O
useful O
to O
collect O
task O
- O
specific O
questions O
. O
For O
instance O
, O
questions O
may O
be O
gathered O
from O
subjects O
who O
are O
visually O
impaired O
[ O
reference O
] O
, O
or O
the O
questions O
could O
focused O
on O
one O
specific O
domain O
( O
say O
sports O
) O
. O
Bigham O
et O
al O
. O
[ O
reference O
] O
created O
an O
application O
that O
allows O
the O
visually O
impaired O
to O
capture O
images O
and O
ask O
open O
- O
ended O
questions O
that O
are O
answered O
by O
human O
subjects O
. O
Interestingly O
, O
these O
questions O
can O
rarely O
be O
answered O
using O
generic Method
captions Method
. O
Training O
on O
task O
- O
specific O
datasets O
may O
help O
enable O
practical O
VQA Task
applications Task
. O
We O
believe O
VQA Task
has O
the O
distinctive O
advantage O
of O
pushing O
the O
frontiers O
on O
" O
AI Task
- Task
complete Task
" Task
problems Task
, O
while O
being O
amenable O
to O
automatic Task
evaluation Task
. O
Given O
the O
recent O
progress O
in O
the O
community O
, O
we O
believe O
the O
time O
is O
ripe O
to O
take O
on O
such O
an O
endeavor O
. O
section O
: O
APPENDIX O
OVERVIEW O
In O
the O
appendix O
, O
we O
provide O
: O
I O
- O
Additional O
analysis O
comparing O
captions O
and O
Q O
& O
A O
data O
II O
- O
Qualitative O
visualizations Method
for O
" O
What O
is O
" O
questions O
III O
- O
Human O
accuracy Metric
on O
multiple Task
- Task
choice Task
questions Task
IV O
- O
Details O
on O
VQA Task
baselines O
V O
- O
"Age O
" O
and O
" O
Commonsense O
" O
of O
our O
model O
VI O
- O
Details O
on O
the O
abstract O
scene O
dataset O
VII O
- O
User O
interfaces O
used O
to O
collect O
the O
dataset O
VIII O
- O
List O
of O
the O
top O
answers O
in O
the O
dataset O
IX O
- O
Additional O
examples O
from O
the O
VQA Material
dataset Material
APPENDIX O
I O
: O
CAPTIONS O
vs. O
QUESTIONS O
Do O
questions O
and O
answers O
provide O
further O
information O
about O
the O
visual O
world O
beyond O
that O
captured O
by O
captions O
? O
One O
method O
for O
determining O
whether O
the O
information O
captured O
by O
questions O
& O
answers O
is O
different O
from O
the O
information O
captured O
by O
captions O
is O
to O
measure O
some O
of O
the O
differences O
in O
the O
word O
distributions O
from O
the O
two O
datasets O
. O
We O
cast O
this O
comparison O
in O
terms O
of O
nouns O
, O
verbs O
, O
and O
adjectives O
by O
extracting O
all O
words O
from O
the O
caption O
data O
( O
MS Material
COCO Material
captions Material
for O
real Material
images Material
and O
captions O
collected O
by O
us O
for O
abstract Material
scenes Material
) O
using O
the O
Stanford Method
part Method
- Method
of Method
- Method
speech Method
( Method
POS Method
) O
[ O
reference O
] O
tagger O
[ O
reference O
] O
. O
We O
normalize O
the O
word O
frequencies O
from O
captions O
, O
questions O
, O
and O
answers O
per O
image O
, O
and O
compare O
captions O
vs. O
questions O
and O
answers O
combined O
. O
Using O
a O
Kolmogorov Method
- Method
Smirnov Method
test Method
to O
determine O
whether O
the O
underlying O
distributions O
of O
the O
two O
datasets O
differ O
, O
we O
find O
a O
significant O
difference O
for O
all O
three O
parts O
of O
speech O
( O
p O
< O
.001 O
) O
for O
both O
real Material
images Material
and O
abstract Material
scenes Material
. O
This O
helps O
motivate O
the O
VQA Task
task Task
as O
a O
way O
to O
learn O
information O
about O
visual O
scenes O
; O
although O
both O
captions O
and O
questions O
& O
answers O
provide O
information O
about O
the O
visual O
world O
, O
they O
do O
it O
from O
different O
perspectives O
, O
with O
different O
underlying O
biases O
[ O
reference O
] O
, O
and O
can O
function O
as O
complementary O
to O
one O
another O
. O
[ O
reference O
] O
. O
Noun O
tags O
begin O
with O
NN O
, O
verb O
tags O
begin O
with O
VB O
, O
adjective O
tags O
begin O
with O
JJ O
, O
and O
prepositions O
are O
tagged O
as O
IN O
. O
We O
illustrate O
the O
similarities O
and O
differences O
between O
the O
word O
distributions O
in O
captions O
vs. O
questions O
& O
answers O
as O
Venn O
- O
style O
word O
clouds O
[ O
reference O
] O
with O
size O
indicating O
the O
normalized O
count O
- O
Fig O
. O
15 O
( O
nouns O
) O
, O
Fig O
. O
16 O
( O
verbs O
) O
, O
and O
Fig O
. O
17 O
( O
adjectives O
) O
for O
real Material
images Material
and O
Fig O
. O
18 O
( O
nouns O
) O
, O
Fig O
. O
19 O
( O
verbs O
) O
, O
and O
Fig O
. O
20 O
( O
adjectives O
) O
for O
abstract Material
scenes Material
. O
[ O
reference O
] O
The O
left O
side O
shows O
the O
top O
words O
in O
questions O
& O
answers O
, O
the O
right O
the O
top O
words O
in O
captions O
, O
and O
the O
center O
the O
words O
common O
to O
both O
, O
with O
size O
indicating O
the O
harmonic O
mean O
of O
the O
counts O
. O
We O
see O
that O
adjectives O
in O
captions O
capture O
some O
clearly O
visual O
properties O
discussed O
in O
previous O
work O
on O
vision O
to O
language O
[ O
reference O
] O
, O
such O
as O
material O
and O
pattern O
, O
while O
the O
questions O
& O
answers O
have O
more O
adjectives O
that O
capture O
what O
is O
usual O
( O
e.g. O
, O
" O
dominant O
" O
, O
" O
approximate O
" O
, O
" O
higher O
" O
) O
and O
other O
kinds O
of O
commonsense O
properties O
( O
e.g. O
, O
" O
edible O
" O
, O
" O
possible O
" O
, O
" O
unsafe O
" O
, O
" O
acceptable O
" O
) O
. O
Interestingly O
, O
we O
see O
that O
question O
& O
answer O
nouns O
capture O
information O
about O
" O
ethnicity O
" O
and O
" O
hairstyle O
" O
, O
while O
caption O
nouns O
capture O
information O
about O
pluralized O
visible O
objects O
( O
e.g. O
, O
" O
cellphones O
" O
, O
" O
daughters O
" O
) O
and O
groups O
( O
e.g. O
, O
" O
trio O
" O
, O
" O
some O
" O
) O
, O
among O
other O
differences O
. O
" O
Man O
" O
and O
" O
people O
" O
are O
common O
in O
both O
captions O
and O
questions O
& O
answers O
. O
One O
key O
piece O
to O
understanding O
the O
visual Task
world Task
is O
understanding O
spatial O
relationships O
, O
and O
so O
we O
additionally O
extract O
spatial O
prepositions O
and O
plot O
their O
proportions O
in O
the O
captions O
vs. O
the O
questions O
& O
answers O
data O
in O
Fig O
. O
14 O
( O
left O
) O
for O
real Material
images Material
and O
Fig O
. O
14 O
( O
right O
) O
for O
abstract Material
scenes Material
. O
We O
see O
that O
questions O
& O
7 O
. O
Visualization Task
created O
using O
http: O
// O
worditout.com O
/ O
. O
answers O
have O
a O
higher O
proportion O
of O
specific O
spatial O
relations O
( O
i.e. O
, O
" O
in O
" O
, O
" O
on O
" O
) O
compared O
to O
captions O
, O
which O
have O
a O
higher O
proportion O
of O
general O
spatial O
relations O
( O
i.e. O
, O
" O
with O
" O
, O
" O
near O
" O
) O
. O
For O
each O
of O
the O
two O
datasets O
, O
real O
and O
abstract O
, O
first O
two O
rows O
are O
the O
human Metric
accuracies Metric
for O
multiple Task
- Task
choice Task
questions Task
when O
subjects O
were O
shown O
both O
the O
image O
and O
the O
question O
. O
Majority O
vote O
means O
we O
consider O
the O
answer O
picked O
by O
majority O
of O
the O
three O
subjects O
to O
be O
the O
predicted O
answer O
by O
humans O
and O
compute O
accuracy Metric
of O
that O
answer O
for O
each O
question O
. O
Average O
means O
we O
compute O
the O
accuracy Metric
of O
each O
of O
the O
answers O
picked O
by O
the O
subjects O
and O
record O
their O
average O
for O
each O
question O
. O
The O
last O
row O
is O
the O
inter O
- O
human O
agreement O
for O
open Task
- Task
ended Task
answers Task
task Task
when O
subjects O
were O
shown O
both O
the O
image O
and O
the O
question O
. O
All O
accuracies Metric
are O
evaluated O
on O
a O
random O
subset O
of O
3000 O
questions O
. O
section O
: O
APPENDIX O
II O
: O
" O
WHAT O
IS O
" O
ANALYSIS O
In O
Fig O
. O
21 O
, O
we O
show O
the O
distribution O
of O
questions O
starting O
with O
" O
What O
is O
" O
by O
their O
first O
five O
words O
for O
both O
real Material
images Material
and O
abstract Material
scenes Material
. O
Note O
the O
diversity O
of O
objects O
referenced O
in O
the O
questions O
, O
as O
well O
as O
, O
the O
relations O
between O
objects O
, O
such O
as O
" O
holding O
" O
and O
" O
sitting O
on O
" O
. O
In O
Fig O
. O
22 O
, O
we O
show O
the O
distribution O
of O
answers O
for O
" O
What O
is O
" O
questions O
ending O
in O
different O
words O
. O
For O
instance O
, O
questions O
ending O
in O
" O
eating O
" O
have O
answers O
such O
as O
" O
pizza O
" O
, O
" O
watermelon O
" O
and O
" O
hot O
dog O
" O
. O
Notice O
the O
diversity O
in O
answers O
for O
some O
questions O
, O
such O
as O
those O
that O
end O
with O
" O
for O
? O
" O
or O
" O
picture O
? O
" O
. O
Other O
questions O
result O
in O
intuitive O
responses O
, O
such O
as O
" O
holding O
? O
" O
and O
the O
response O
" O
umbrella O
" O
. O
section O
: O
APPENDIX O
III O
: O
MULTIPLE Task
- Task
CHOICE Task
HUMAN Task
AC Task
- Task
CURACY Task
To O
compute O
human Metric
accuracy Metric
for O
multiple Task
- Task
choice Task
questions Task
, O
we O
collected O
three O
human O
answers O
per O
question O
on O
a O
random O
subset O
of O
3 O
, O
000 O
questions O
for O
both O
real Material
images Material
and O
abstract Material
scenes Material
. O
In O
Table O
6 O
, O
we O
show O
the O
human Metric
accuracies Metric
for O
multiple O
choice O
questions O
. O
Table O
6 O
also O
shows O
the O
inter O
- O
human Metric
agreement Metric
for O
open Task
- Task
ended Task
answer Task
task Task
. O
In O
comparison O
to O
openended O
answer O
, O
the O
multiple Metric
- Metric
choice Metric
accuracies Metric
are O
more O
or O
less O
same O
for O
" O
yes O
/ O
no O
" O
questions O
and O
significantly O
better O
( O
≈ O
15 O
% O
increase O
for O
real Material
images Material
and O
≈ O
11 O
% O
increase O
for O
abstract Material
scenes Material
) O
for O
" O
other O
" O
questions O
. O
Since O
" O
other O
" O
questions O
may O
be O
ambiguous O
, O
the O
increase O
in O
accuracy Metric
using O
multiple O
choice O
is O
not O
surprising O
. O
section O
: O
APPENDIX O
IV O
: O
DETAILS O
ON O
VQA Task
BASELINES O
" O
per O
Q Method
- Method
type Method
prior Method
" O
baseline O
. O
We O
decide O
on O
different O
question O
types O
based O
on O
first O
few O
words O
of O
questions O
in O
the O
real Material
images Material
training O
set O
and O
ensure O
that O
each O
question O
type O
has O
at O
least O
30 O
questions O
in O
the O
training O
dataset O
. O
The O
most O
popular O
answer O
for O
each O
question O
type O
is O
also O
computed O
on O
real Material
images Material
training O
set O
. O
" O
nearest Method
neighbor Method
" O
baseline O
. O
For O
every O
question O
in O
the O
VQA Task
test O
- O
standard O
set O
, O
we O
find O
its O
k O
nearest Method
neighbor Method
questions O
in O
the O
training O
set O
using O
cosine O
similarity O
in O
Skip O
- O
Thought O
[ O
reference O
] O
feature O
space O
. O
We O
also O
experimented O
with O
bag O
of O
words O
and O
Word2Vec O
[ O
reference O
] O
feature O
spaces O
but O
we O
obtained O
the O
best O
performance O
with O
Skip O
- O
Thought O
. O
In O
this O
set O
of O
k O
questions O
and O
their O
associated O
images O
, O
we O
find O
the O
image O
which O
is O
most O
similar O
to O
the O
query O
image O
using O
cosine O
similarity O
in O
fc7 O
feature O
space O
. O
We O
use O
the O
fc7 O
features O
from O
the O
caffenet Method
model Method
in O
BVLC Method
Caffe Method
[ O
reference O
] O
. O
The O
most O
common O
ground O
truth O
answer O
of O
this O
most O
similar O
image O
and O
question O
pair O
is O
the O
predicted O
answer O
for O
the O
query O
image O
and O
question O
pair O
. O
We O
pick O
k O
= O
4 O
on O
the O
test O
- O
dev O
set O
. O
APPENDIX O
V O
: O
" O
AGE O
" O
AND O
" O
COMMONSENSE O
" O
section O
: O
OF O
OUR O
MODEL O
We O
estimate O
the O
age O
and O
degree O
of O
commonsense O
of O
our O
best O
model O
( O
deeper O
LSTM Method
Q O
+ O
norm O
I O
) O
, O
selected O
using O
VQA Task
testdev O
accuracies O
) O
. O
To O
estimate O
the O
age O
, O
we O
compute O
a O
weighted O
average O
of O
the O
average Metric
age Metric
per O
question O
, O
weighted O
by O
the O
accuracy Metric
of O
the O
model O
's O
predicted O
answer O
for O
that O
question O
, O
on O
the O
subset O
of O
questions O
in O
the O
VQA Material
validation Material
set Material
for O
which O
we O
have O
age O
annotations O
( O
how O
old O
a O
human O
needs O
to O
be O
to O
answer O
the O
question O
correctly O
) O
. O
To O
estimate O
the O
degree O
of O
commonsense O
, O
we O
compute O
a O
weighted O
average O
of O
the O
average Metric
degree Metric
of Metric
commonsense Metric
per O
question O
, O
weighted O
by O
the O
accuracy Metric
of O
the O
model O
's O
predicted O
answer O
for O
that O
question O
, O
on O
the O
subset O
of O
questions O
in O
the O
VQA Task
validation O
set O
for O
which O
we O
have O
commonsense O
annotations O
( O
whether O
the O
question O
requires O
commonsense O
to O
answer O
it O
) O
. O
section O
: O
APPENDIX O
VI O
: O
ABSTRACT O
SCENES O
DATASET O
In O
Fig O
. O
23 O
( O
left O
) O
, O
we O
show O
a O
subset O
of O
the O
objects O
that O
are O
present O
in O
the O
abstract Material
scenes Material
dataset O
. O
For O
more O
examples O
of O
the O
scenes O
generated O
, O
please O
see O
Fig O
. O
28 O
. O
The O
user O
interface O
used O
to O
create O
the O
scenes O
is O
shown O
in O
Fig O
. O
23 O
( O
right O
) O
. O
Subjects O
used O
a O
drag Method
- Method
and Method
- Method
drop Method
interface Method
to O
create O
the O
scenes O
. O
Each O
object O
could O
be O
flipped O
horizontally O
and O
scaled O
. O
The O
scale O
of O
the O
object O
determined O
the O
rendering O
order O
of O
the O
objects O
. O
Many O
objects O
have O
different O
attributes O
corresponding O
to O
different O
poses O
or O
types O
. O
Most O
animals O
have O
five O
different O
discrete O
poses O
. O
Humans O
have O
eight O
discrete O
expressions O
and O
their O
poses O
may O
be O
continuously O
adjusted O
using O
a O
" O
paperdoll Method
" Method
model Method
[ O
reference O
] O
. O
section O
: O
APPENDIX O
VII O
: O
USER O
INTERFACES O
In O
Fig O
. O
24 O
, O
we O
show O
the O
AMT Method
interface Method
that O
we O
used O
to O
collect O
questions O
for O
images O
. O
Note O
that O
we O
tell O
the O
workers O
that O
the O
robot O
already O
knows O
the O
answer O
to O
the O
previously O
asked O
question O
( O
s O
) O
, O
inspiring O
them O
to O
ask O
different O
kinds O
of O
questions O
, O
thereby O
increasing O
the O
diversity O
of O
our O
dataset O
. O
Fig O
. O
25 O
shows O
the O
AMT Method
interface Method
used O
for O
collecting O
answers O
to O
the O
previously O
collected O
questions O
when O
subjects O
were O
shown O
the O
corresponding O
images O
. O
Fig O
. O
26 O
shows O
the O
interface O
that O
was O
used O
to O
collect O
answers O
to O
questions O
when O
subjects O
were O
not O
shown O
the O
corresponding O
image O
( O
i.e. O
, O
to O
help O
in O
gathering O
incorrect O
, O
but O
plausible O
, O
answers O
for O
the O
multiplechoice Task
task Task
and O
to O
assess O
how O
accurately O
the O
questions O
can O
be O
answered O
using O
common O
sense O
knowledge O
alone O
) O
. O
section O
: O
Real Material
Images Material
Abstract O
Scenes O
What O
is O
What O
is O
The O
AMT Method
interface Method
used O
to O
collect O
answers O
to O
a O
question O
when O
subjects O
were O
not O
shown O
the O
image O
while O
answering O
the O
question O
using O
only O
commonsense O
to O
collect O
the O
plausible O
, O
but O
incorrect O
, O
multiple O
- O
choice O
answers O
. O
section O
: O
21 O
section O
: O
APPENDIX O
VIII O
: O
ANSWER Task
DISTRIBUTION Task
The O
top O
250 O
answers O
in O
our O
real Material
images Material
dataset O
along O
with O
their O
counts O
and O
percentage O
counts O
are O
given O
below O
. O
The O
answers O
have O
been O
presented O
in O
different O
colors O
to O
show O
the O
different O
Part O
- O
of O
- O
Speech O
( O
POS O
) O
tagging O
of O
the O
answers O
with O
the O
following O
color O
code O
: O
yes O
/ O
no O
, O
noun O
, O
verb O
, O
adjective O
, O
adverb O
, O
and O
numeral O
. O
" O
yes O
" O
( O
566613 O
, O
22.82 O
% O
) O
, O
" O
no O
" O
( O
381307 O
, O
15.35 O
% O
) O
, O
" O
2 O
" O
( O
80031 O
, O
3.22 O
% O
) O
, O
" O
1 O
" O
( O
46537 O
, O
1.87 O
% O
) O
, O
" O
white O
" O
( O
41753 O
, O
1.68 O
% O
) O
, O
" O
3 O
" O
( O
41334 O
, O
1.66 O
% O
) O
, O
" O
red O
" O
( O
33834 O
, O
1.36 O
% O
) O
, O
" O
blue O
" O
( O
28881 O
, O
1.16 O
% O
) O
, O
" O
4 O
" O
( O
27174 O
, O
1.09 O
% O
) O
, O
" O
green O
" O
( O
22453 O
, O
0.9 O
% O
) O
, O
" O
black O
" O
( O
21852 O
, O
0.88 O
% O
) O
, O
" O
yellow O
" O
( O
17312 O
, O
0.7 O
% O
) O
, O
" O
brown O
" O
( O
14488 O
, O
0.58 O
% O
) O
, O
" O
5 O
" O
( O
14373 O
, O
0.58 O
% O
) O
, O
" O
tennis O
" O
( O
10941 O
, O
0.44% O
), O
"baseball O
" O
( O
10299 O
, O
0.41 O
% O
) O
, O
" O
6 O
" O
( O
10103 O
, O
0.41 O
% O
) O
, O
" O
orange O
" O
( O
9136 O
, O
0.37 O
% O
) O
, O
" O
0 O
" O
( O
8812 O
, O
0.35 O
% O
) O
, O
" O
bathroom O
" O
( O
8473 O
, O
0.34 O
% O
) O
, O
" O
wood O
" O
( O
8219 O
, O
0.33 O
% O
) O
, O
" O
right O
" O
( O
8209 O
, O
0.33 O
% O
) O
, O
" O
left O
" O
( O
8058 O
, O
0.32 O
% O
) O
, O
" O
frisbee O
" O
( O
7671 O
, O
0.31 O
% O
) O
, O
" O
pink O
" O
( O
7519 O
, O
0.3 O
% O
) O
, O
" O
gray O
" O
( O
7385 O
, O
0.3 O
% O
) O
, O
" O
pizza O
" O
( O
6892 O
, O
0.28 O
% O
) O
, O
" O
7 O
" O
( O
6005 O
, O
0.24 O
% O
) O
, O
" O
kitchen O
" O
( O
5926 O
, O
0.24 O
% O
) O
, O
" O
8 O
" O
( O
5592 O
, O
0.23 O
% O
) O
, O
" O
cat O
" O
( O
5514 O
, O
0.22 O
% O
) O
, O
" O
skiing O
" O
( O
5189 O
, O
0.21 O
% O
) O
, O
" O
skateboarding O
" O
( O
5122 O
, O
0.21 O
% O
) O
, O
" O
dog O
" O
( O
5092 O
, O
0.21 O
% O
) O
, O
" O
snow O
" O
( O
4867 O
, O
0.2 O
% O
) O
, O
" O
black O
and O
white O
" O
( O
4852 O
, O
0.2 O
% O
) O
, O
" O
skateboard O
" O
( O
4697 O
, O
0.19 O
% O
) O
, O
" O
surfing O
" O
( O
4544 O
, O
0.18 O
% O
) O
, O
" O
water O
" O
( O
4513 O
, O
0.18 O
% O
) O
, O
" O
giraffe O
" O
( O
4027 O
, O
0.16 O
% O
) O
, O
" O
grass O
" O
( O
3979 O
, O
0.16 O
% O
) O
, O
" O
surfboard O
" O
( O
3934 O
, O
0.16 O
% O
) O
, O
" O
wii O
" O
( O
3898 O
, O
0.16 O
% O
) O
, O
" O
kite O
" O
( O
3852 O
, O
0.16 O
% O
) O
, O
" O
10 O
" O
( O
3756 O
, O
0.15 O
% O
) O
, O
" O
purple O
" O
( O
3722 O
, O
0.15 O
% O
) O
, O
" O
elephant O
" O
( O
3646 O
, O
0.15 O
% O
) O
, O
" O
broccoli O
" O
( O
3604 O
, O
0.15 O
% O
) O
, O
" O
man O
" O
( O
3590 O
, O
0.14 O
% O
) O
, O
" O
winter O
" O
( O
3490 O
, O
0.14 O
% O
) O
, O
" O
stop O
" O
( O
3413 O
, O
0.14 O
% O
) O
, O
" O
train O
" O
( O
3226 O
, O
0.13 O
% O
) O
, O
" O
9 O
" O
( O
3217 O
, O
0.13 O
% O
) O
, O
" O
apple O
" O
( O
3189 O
, O
0.13 O
% O
) O
, O
" O
silver O
" O
( O
3186 O
, O
0.13 O
% O
) O
, O
" O
horse O
" O
( O
3159 O
, O
0.13 O
% O
) O
, O
" O
banana O
" O
( O
3151 O
, O
0.13 O
% O
) O
, O
" O
umbrella O
" O
( O
3139 O
, O
0.13 O
% O
) O
, O
" O
eating O
" O
( O
3117 O
, O
0.13 O
% O
) O
, O
" O
sheep O
" O
( O
2927 O
, O
0.12 O
% O
) O
, O
" O
bear O
" O
( O
2803 O
, O
0.11 O
% O
) O
, O
" O
phone O
" O
( O
2772 O
, O
0.11 O
% O
) O
, O
" O
12 O
" O
( O
2633 O
, O
0.11 O
% O
) O
, O
" O
motorcycle O
" O
( O
2608 O
, O
0.11 O
% O
) O
, O
" O
cake O
" O
( O
2602 O
, O
0.1 O
% O
) O
, O
" O
wine O
" O
( O
2574 O
, O
0.1 O
% O
) O
, O
" O
beach O
" O
( O
2536 O
, O
0.1 O
% O
) O
, O
" O
soccer O
" O
( O
2504 O
, O
0.1 O
% O
) O
, O
" O
sunny O
" O
( O
2475 O
, O
0.1 O
% O
) O
, O
" O
zebra O
" O
( O
2403 O
, O
0.1 O
% O
) O
, O
" O
tan O
" O
( O
2402 O
, O
0.1 O
% O
) O
, O
" O
brick O
" O
( O
2395 O
, O
0.1 O
% O
) O
, O
" O
female O
" O
( O
2372 O
, O
0.1 O
% O
) O
, O
" O
bananas O
" O
( O
2350 O
, O
0.09 O
% O
) O
, O
" O
table O
" O
( O
2331 O
, O
0.09 O
% O
) O
, O
" O
laptop O
" O
( O
2316 O
, O
0.09 O
% O
) O
, O
" O
hat O
" O
( O
2277 O
, O
0.09 O
% O
) O
, O
" O
bench O
" O
( O
2259 O
, O
0.09 O
% O
) O
, O
" O
flowers O
" O
( O
2219 O
, O
0.09 O
% O
) O
, O
" O
woman O
" O
( O
2197 O
, O
0.09 O
% O
) O
, O
" O
male O
" O
( O
2170 O
, O
0.09 O
% O
) O
, O
" O
cow O
" O
( O
2084 O
, O
0.08 O
% O
) O
, O
" O
food O
" O
( O
2083 O
, O
0.08 O
% O
) O
, O
" O
living O
room O
" O
( O
2022 O
, O
0.08 O
% O
) O
, O
" O
bus O
" O
( O
2011 O
, O
0.08 O
% O
) O
, O
" O
snowboarding O
" O
( O
1990 O
, O
0.08 O
% O
) O
, O
" O
kites O
" O
( O
1979 O
, O
0.08 O
% O
) O
, O
" O
cell O
phone O
" O
( O
1943 O
, O
0.08 O
% O
) O
, O
" O
helmet O
" O
( O
1885 O
, O
0.08 O
% O
) O
, O
" O
maybe O
" O
( O
1853 O
, O
0.07 O
% O
) O
, O
" O
outside O
" O
( O
1846 O
, O
0.07 O
% O
) O
, O
" O
hot O
dog O
" O
( O
1809 O
, O
0.07 O
% O
) O
, O
" O
night O
" O
( O
1805 O
, O
0.07 O
% O
) O
, O
" O
trees O
" O
( O
1785 O
, O
0.07 O
% O
) O
, O
" O
11 O
" O
( O
1753 O
, O
0.07 O
% O
) O
, O
" O
bird O
" O
( O
1739 O
, O
0.07 O
% O
) O
, O
" O
down O
" O
( O
1732 O
, O
0.07 O
% O
) O
, O
" O
bed O
" O
( O
1587 O
, O
0.06 O
% O
) O
, O
" O
camera O
" O
( O
1560 O
, O
0.06 O
% O
) O
, O
" O
tree O
" O
( O
1547 O
, O
0.06 O
% O
) O
, O
" O
christmas O
" O
( O
1544 O
, O
0.06 O
% O
) O
, O
" O
fence O
" O
( O
1543 O
, O
0.06 O
% O
) O
, O
" O
nothing O
" O
( O
1538 O
, O
0.06 O
% O
) O
, O
" O
unknown O
" O
( O
1532 O
, O
0.06 O
% O
) O
, O
" O
tennis O
racket O
" O
( O
1525 O
, O
0.06 O
% O
) O
, O
" O
red O
and O
white O
" O
( O
1518 O
, O
0.06 O
% O
) O
, O
" O
bedroom O
" O
( O
1500 O
, O
0.06 O
% O
) O
, O
" O
bat O
" O
( O
1494 O
, O
0.06 O
% O
) O
, O
" O
glasses O
" O
( O
1491 O
, O
0.06 O
% O
) O
, O
" O
tile O
" O
( O
1487 O
, O
0.06 O
% O
) O
, O
" O
metal O
" O
( O
1470 O
, O
0.06 O
% O
) O
, O
" O
blue O
and O
white O
" O
( O
1440 O
, O
0.06 O
% O
) O
, O
" O
fork O
" O
( O
1439 O
, O
0.06 O
% O
) O
, O
" O
plane O
" O
( O
1439 O
, O
0.06 O
% O
) O
, O
" O
airport O
" O
( O
1422 O
, O
0.06 O
% O
) O
, O
" O
cloudy O
" O
( O
1413 O
, O
0.06 O
% O
) O
, O
" O
15 O
" O
( O
1407 O
, O
0.06 O
% O
) O
, O
" O
up O
" O
( O
1399 O
, O
0.06 O
% O
) O
, O
" O
blonde O
" O
( O
1398 O
, O
0.06 O
% O
) O
, O
" O
day O
" O
( O
1396 O
, O
0.06 O
% O
) O
, O
" O
teddy O
bear O
" O
( O
1386 O
, O
0.06 O
% O
) O
, O
" O
glass O
" O
( O
1379 O
, O
0.06 O
% O
) O
, O
" O
20 O
" O
( O
1365 O
, O
0.05 O
% O
) O
, O
" O
beer O
" O
( O
1345 O
, O
0.05 O
% O
) O
, O
" O
car O
" O
( O
1331 O
, O
0.05 O
% O
) O
, O
" O
sitting O
" O
( O
1328 O
, O
0.05 O
% O
) O
, O
" O
boat O
" O
( O
1326 O
, O
0.05 O
% O
) O
, O
" O
standing O
" O
( O
1326 O
, O
0.05 O
% O
) O
, O
" O
clear O
" O
( O
1318 O
, O
0.05 O
% O
) O
, O
" O
13 O
" O
( O
1318 O
, O
0.05 O
% O
) O
, O
" O
nike O
" O
( O
1293 O
, O
0.05 O
% O
) O
, O
" O
sand O
" O
( O
1282 O
, O
0.05 O
% O
) O
, O
" O
open O
" O
( O
1279 O
, O
0.05 O
% O
) O
, O
" O
cows O
" O
( O
1271 O
, O
0.05 O
% O
) O
, O
" O
bike O
" O
( O
1267 O
, O
0.05 O
% O
) O
, O
" O
chocolate O
" O
( O
1266 O
, O
0.05 O
% O
) O
, O
" O
donut O
" O
( O
1263 O
, O
0.05 O
% O
) O
, O
" O
airplane O
" O
( O
1247 O
, O
0.05 O
% O
) O
, O
" O
birthday O
" O
( O
1241 O
, O
0.05 O
% O
) O
, O
" O
carrots O
" O
( O
1239 O
, O
0.05 O
% O
) O
, O
" O
skis O
" O
( O
1220 O
, O
0.05 O
% O
) O
, O
" O
girl O
" O
( O
1220 O
, O
0.05 O
% O
) O
, O
" O
many O
" O
( O
1211 O
, O
0.05 O
% O
) O
, O
" O
zoo O
" O
( O
1204 O
, O
0.05 O
% O
) O
, O
" O
suitcase O
" O
( O
1199 O
, O
0.05 O
% O
) O
, O
" O
old O
" O
( O
1180 O
, O
0.05 O
% O
) O
, O
" O
chair O
" O
( O
1174 O
, O
0.05 O
% O
) O
, O
" O
beige O
" O
( O
1170 O
, O
0.05 O
% O
) O
, O
" O
ball O
" O
( O
1169 O
, O
0.05 O
% O
) O
, O
" O
ocean O
" O
( O
1168 O
, O
0.05 O
% O
) O
, O
" O
sandwich O
" O
( O
1168 O
, O
0.05 O
% O
) O
, O
" O
tie O
" O
( O
1166 O
, O
0.05 O
% O
) O
, O
" O
horses O
" O
( O
1163 O
, O
0.05 O
% O
) O
, O
" O
palm O
" O
( O
1163 O
, O
0.05 O
% O
) O
, O
" O
stripes O
" O
( O
1155 O
, O
0.05 O
% O
) O
, O
" O
fall O
" O
( O
1146 O
, O
0.05 O
% O
) O
, O
" O
cheese O
" O
( O
1142 O
, O
0.05 O
% O
) O
, O
" O
scissors O
" O
( O
1134 O
, O
0.05 O
% O
) O
, O
" O
round O
" O
( O
1125 O
, O
0.05 O
% O
) O
, O
" O
chinese O
" O
( O
1123 O
, O
0.05 O
% O
) O
, O
" O
knife O
" O
( O
1120 O
, O
0.05 O
% O
) O
, O
" O
14 O
" O
( O
1110 O
, O
0.04 O
% O
) O
, O
" O
toilet O
" O
( O
1099 O
, O
0.04 O
% O
) O
, O
" O
do O
n't O
know O
" O
( O
1085 O
, O
0.04 O
% O
) O
, O
" O
snowboard O
" O
( O
1083 O
, O
0.04 O
% O
) O
, O
" O
truck O
" O
( O
1076 O
, O
0.04 O
% O
) O
, O
" O
boy O
" O
( O
1070 O
, O
0.04 O
% O
) O
, O
" O
coffee O
" O
( O
1070 O
, O
0.04 O
% O
) O
, O
" O
cold O
" O
( O
1064 O
, O
0.04 O
% O
) O
, O
" O
fruit O
" O
( O
1064 O
, O
0.04 O
% O
) O
, O
" O
walking O
" O
( O
1053 O
, O
0.04 O
% O
) O
, O
" O
wedding O
" O
( O
1051 O
, O
0.04 O
% O
) O
, O
" O
lot O
" O
( O
1050 O
, O
0.04 O
% O
) O
, O
" O
sunglasses O
" O
( O
1047 O
, O
0.04 O
% O
) O
, O
" O
mountains O
" O
( O
1030 O
, O
0.04 O
% O
) O
, O
" O
wall O
" O
( O
1009 O
, O
0.04 O
% O
) O
, O
" O
elephants O
" O
( O
1006 O
, O
0.04 O
% O
) O
, O
" O
wetsuit O
" O
( O
998 O
, O
0.04 O
% O
) O
, O
" O
square O
" O
( O
994 O
, O
0.04 O
% O
) O
, O
" O
toothbrush O
" O
( O
989 O
, O
0.04 O
% O
) O
, O
" O
sleeping O
" O
( O
986 O
, O
0.04 O
% O
) O
, O
" O
fire O
hydrant O
" O
( O
977 O
, O
0.04 O
% O
) O
, O
" O
bicycle O
" O
( O
973 O
, O
0.04 O
% O
) O
, O
" O
overcast O
" O
( O
968 O
, O
0.04 O
% O
) O
, O
" O
donuts O
" O
( O
961 O
, O
0.04 O
% O
) O
, O
" O
plastic O
" O
( O
961 O
, O
0.04 O
% O
) O
, O
" O
breakfast O
" O
( O
955 O
, O
0.04 O
% O
) O
, O
" O
tv O
" O
( O
953 O
, O
0.04 O
% O
) O
, O
" O
paper O
" O
( O
952 O
, O
0.04 O
% O
) O
, O
" O
ground O
" O
( O
949 O
, O
0.04 O
% O
) O
, O
" O
asian O
" O
( O
938 O
, O
0.04 O
% O
) O
, O
" O
plaid O
" O
( O
936 O
, O
0.04 O
% O
) O
, O
" O
dirt O
" O
( O
933 O
, O
0.04 O
% O
) O
, O
" O
mirror O
" O
( O
928 O
, O
0.04 O
% O
) O
, O
" O
usa O
" O
( O
928 O
, O
0.04 O
% O
) O
, O
" O
chicken O
" O
( O
925 O
, O
0.04 O
% O
) O
, O
" O
plate O
" O
( O
920 O
, O
0.04 O
% O
) O
, O
" O
clock O
" O
( O
912 O
, O
0.04 O
% O
) O
, O
" O
luggage O
" O
( O
908 O
, O
0.04 O
% O
) O
, O
" O
none O
" O
( O
908 O
, O
0.04 O
% O
) O
, O
" O
street O
" O
( O
905 O
, O
0.04 O
% O
) O
, O
" O
on O
table O
" O
( O
904 O
, O
0.04 O
% O
) O
, O
" O
spoon O
" O
( O
899 O
, O
0.04 O
% O
) O
, O
" O
cooking O
" O
( O
898 O
, O
0.04 O
% O
) O
, O
" O
daytime O
" O
( O
896 O
, O
0.04 O
% O
) O
, O
" O
16 O
" O
( O
893 O
, O
0.04 O
% O
) O
, O
" O
africa O
" O
( O
890 O
, O
0.04 O
% O
) O
, O
" O
stone O
" O
( O
884 O
, O
0.04 O
% O
) O
, O
" O
not O
sure O
" O
( O
873 O
, O
0.04 O
% O
) O
, O
" O
window O
" O
( O
868 O
, O
0.03 O
% O
) O
, O
" O
sun O
" O
( O
865 O
, O
0.03 O
% O
) O
, O
" O
gold O
" O
( O
860 O
, O
0.03 O
% O
) O
, O
" O
people O
" O
( O
856 O
, O
0.03 O
% O
) O
, O
" O
racket O
" O
( O
847 O
, O
0.03 O
% O
) O
, O
" O
zebras O
" O
( O
845 O
, O
0.03 O
% O
) O
, O
" O
carrot O
" O
( O
841 O
, O
0.03 O
% O
) O
, O
" O
person O
" O
( O
835 O
, O
0.03 O
% O
) O
, O
" O
fish O
" O
( O
835 O
, O
0.03 O
% O
) O
, O
" O
happy O
" O
( O
824 O
, O
0.03 O
% O
) O
, O
" O
circle O
" O
( O
822 O
, O
0.03 O
% O
) O
, O
" O
oranges O
" O
( O
817 O
, O
0.03 O
% O
) O
, O
" O
backpack O
" O
( O
812 O
, O
0.03 O
% O
) O
, O
" O
25 O
" O
( O
810 O
, O
0.03 O
% O
) O
, O
" O
leaves O
" O
( O
809 O
, O
0.03 O
% O
) O
, O
" O
watch O
" O
( O
804 O
, O
0.03 O
% O
) O
, O
" O
mountain O
" O
( O
800 O
, O
0.03 O
% O
) O
, O
" O
no O
one O
" O
( O
798 O
, O
0.03 O
% O
) O
, O
" O
ski O
poles O
" O
( O
792 O
, O
0.03 O
% O
) O
, O
" O
city O
" O
( O
791 O
, O
0.03 O
% O
) O
, O
" O
couch O
" O
( O
790 O
, O
0.03 O
% O
) O
, O
" O
afternoon O
" O
( O
782 O
, O
0.03 O
% O
) O
, O
" O
jeans O
" O
( O
781 O
, O
0.03 O
% O
) O
, O
" O
brown O
and O
white O
" O
( O
779 O
, O
0.03 O
% O
) O
, O
" O
summer O
" O
( O
774 O
, O
0.03 O
% O
) O
, O
" O
giraffes O
" O
( O
772 O
, O
0.03 O
% O
) O
, O
" O
computer O
" O
( O
771 O
, O
0.03 O
% O
) O
, O
" O
refrigerator O
" O
( O
768 O
, O
0.03 O
% O
) O
, O
" O
birds O
" O
( O
762 O
, O
0.03 O
% O
) O
, O
" O
child O
" O
( O
761 O
, O
0.03 O
% O
) O
, O
" O
park O
" O
( O
759 O
, O
0.03 O
% O
) O
, O
" O
flying O
kite O
" O
( O
756 O
, O
0.03 O
% O
) O
, O
" O
restaurant O
" O
( O
747 O
, O
0.03 O
% O
) O
, O
" O
evening O
" O
( O
738 O
, O
0.03 O
% O
) O
, O
" O
graffiti O
" O
( O
736 O
, O
0.03 O
% O
) O
, O
" O
30 O
" O
( O
730 O
, O
0.03 O
% O
) O
, O
" O
grazing O
" O
( O
727 O
, O
0.03 O
% O
) O
, O
" O
flower O
" O
( O
723 O
, O
0.03 O
% O
) O
, O
" O
remote O
" O
( O
720 O
, O
0.03 O
% O
) O
, O
" O
hay O
" O
( O
719 O
, O
0.03 O
% O
) O
, O
" O
50 O
" O
( O
716 O
, O
0.03 O
% O
) O
. O
section O
: O
APPENDIX O
IX O
: O
ADDITIONAL O
EXAMPLES O
To O
provide O
insight O
into O
the O
dataset O
, O
we O
provide O
additional O
examples O
. O
In O
Fig O
. O
27 O
, O
Fig O
. O
28 O
, O
and O
Fig O
. O
29 O
, O
we O
show O
a O
random O
selection O
of O
the O
VQA Material
dataset Material
for O
the O
MS Material
COCO Material
[ O
reference O
] O
images O
, O
abstract Material
scenes Material
, O
and O
multiple Material
- Material
choice Material
questions Material
, O
respectively O
. O
section O
: O
section O
: O
woman O
on O
right O
Q O
: O
Is O
the O
girl O
standing O
? O
Q O
: O
Does O
the O
girl O
have O
a O
lot O
of O
toys O
? O
( O
p O
) O
yes O
3 O
of O
them O
( O
q O
) O
no O
image O
( O
r O
) O
children O
and O
toys O
Q O
: O
What O
sport O
are O
they O
playing O
? O
( O
p O
) O
n200 O
( O
q O
) O
public O
storage O
( O
r O
) O
pasta O
, O
sauce O
, O
meat O
Q O
: O
How O
many O
umbrellas O
are O
in O
the O
photo O
? O
( O
p O
) O
dresses O
( O
q O
) O
3 O
to O
5 O
( O
r O
) O
two O
way O
traffic O
Q O
: O
Where O
is O
the O
blanket O
? O
( O
p O
) O
to O
be O
pet O
( O
q O
) O
she O
fell O
( O
r O
) O
boy O
is O
playing O
with O
her O
toys O
Q O
: O
Why O
is O
the O
boy O
playing O
with O
his O
sister O
's O
toys O
? O
( O
a O
) O
yes O
section O
: O
