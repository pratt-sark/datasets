Image Task
Super Task
- Task
Resolution Task
Using O
Deep Method
Convolutional Method
Networks Method
section O
: O
Abstract O
- O
We O
propose O
a O
deep Method
learning Method
method Method
for O
single Task
image Task
super Task
- Task
resolution Task
( O
SR Task
) O
. O
Our O
method O
directly O
learns O
an O
end Task
- Task
to Task
- Task
end Task
mapping Task
between O
the O
low O
/ O
high O
- O
resolution O
images O
. O
The O
mapping Method
is O
represented O
as O
a O
deep O
convolutional O
neural O
network O
( O
CNN Method
) O
that O
takes O
the O
low O
- O
resolution O
image O
as O
the O
input O
and O
outputs O
the O
high O
- O
resolution O
one O
. O
We O
further O
show O
that O
traditional O
sparse O
- O
coding O
- O
based O
SR Task
methods O
can O
also O
be O
viewed O
as O
a O
deep Method
convolutional Method
network Method
. O
But O
unlike O
traditional O
methods O
that O
handle O
each O
component O
separately O
, O
our O
method O
jointly O
optimizes O
all O
layers O
. O
Our O
deep O
CNN Method
has O
a O
lightweight O
structure O
, O
yet O
demonstrates O
state O
- O
of O
- O
the O
- O
art O
restoration Metric
quality Metric
, O
and O
achieves O
fast O
speed Metric
for O
practical O
on Task
- Task
line Task
usage Task
. O
We O
explore O
different O
network O
structures O
and O
parameter O
settings O
to O
achieve O
tradeoffs O
between O
performance O
and O
speed Metric
. O
Moreover O
, O
we O
extend O
our O
network O
to O
cope O
with O
three O
color O
channels O
simultaneously O
, O
and O
show O
better O
overall O
reconstruction Metric
quality Metric
. O
section O
: O
INTRODUCTION O
Single Task
image Task
super Task
- Task
resolution Task
( O
SR Task
) O
[ O
reference O
] O
, O
which O
aims O
at O
recovering O
a O
high Task
- Task
resolution Task
image Task
from O
a O
single O
lowresolution O
image O
, O
is O
a O
classical O
problem O
in O
computer Task
vision Task
. O
This O
problem O
is O
inherently O
ill O
- O
posed O
since O
a O
multiplicity O
of O
solutions O
exist O
for O
any O
given O
low O
- O
resolution O
pixel O
. O
In O
other O
words O
, O
it O
is O
an O
underdetermined Task
inverse Task
problem Task
, O
of O
which O
solution O
is O
not O
unique O
. O
Such O
a O
problem O
is O
typically O
mitigated O
by O
constraining O
the O
solution O
space O
by O
strong O
prior O
information O
. O
To O
learn O
the O
prior O
, O
recent O
state O
- O
of O
- O
the O
- O
art O
methods O
mostly O
adopt O
the O
example Method
- Method
based Method
[ O
reference O
] O
strategy O
. O
These O
methods O
either O
exploit O
internal O
similarities O
of O
the O
same O
image O
[ O
reference O
] O
, O
[ O
reference O
] O
, O
[ O
reference O
] O
, O
[ O
reference O
] O
, O
[ O
reference O
] O
, O
or O
learn O
mapping O
functions O
from O
external O
low O
- O
and O
high O
- O
resolution O
exemplar O
pairs O
[ O
reference O
] O
, O
[ O
reference O
] O
, O
[ O
reference O
] O
, O
[ O
reference O
] O
, O
[ O
reference O
] O
, O
[ O
reference O
] O
, O
[ O
reference O
] O
, O
[ O
reference O
] O
, O
[ O
reference O
] O
, O
[ O
reference O
] O
, O
[ O
reference O
] O
, O
[ O
reference O
] O
, O
[ O
reference O
] O
. O
The O
external O
example Method
- Method
based Method
methods Method
can O
be O
formulated O
for O
generic Task
image Task
super Task
- Task
resolution Task
, O
or O
can O
be O
designed O
to O
suit O
domain Task
specific Task
tasks Task
, O
i.e. O
, O
face Task
hallucination Task
[ O
reference O
] O
, O
[ O
reference O
] O
, O
according O
to O
the O
training O
samples O
provided O
. O
The O
sparse Method
- Method
coding Method
- Method
based Method
method Method
[ O
reference O
] O
, O
[ O
reference O
] O
is O
one O
of O
the O
representative O
external O
example O
- O
based O
SR Task
methods O
. O
This O
method O
involves O
several O
steps O
in O
its O
solution O
pipeline O
. O
First O
, O
overlapping O
patches O
are O
densely O
cropped O
from O
the O
input O
image O
and O
pre O
- O
processed O
( O
e.g. O
, O
subtracting O
mean O
and O
normalization Method
) O
. O
These O
patches O
are O
then O
encoded O
by O
a O
low Method
- Method
resolution Method
dictionary Method
. O
The O
sparse O
coefficients O
are O
passed O
into O
a O
high Method
- Method
resolution Method
dictionary Method
for O
reconstructing Task
high Task
- Task
resolution Task
patches Task
. O
The O
overlapping O
re O
- O
constructed O
patches O
are O
aggregated O
( O
e.g. O
, O
by O
weighted Method
averaging Method
) O
to O
produce O
the O
final O
output O
. O
This O
pipeline O
is O
shared O
by O
most O
external O
example Method
- Method
based Method
methods Method
, O
which O
pay O
particular O
attention O
to O
learning O
and O
optimizing O
the O
dictionaries O
[ O
reference O
] O
, O
[ O
reference O
] O
, O
[ O
reference O
] O
or O
building O
efficient O
mapping O
functions O
[ O
reference O
] O
, O
[ O
reference O
] O
, O
[ O
reference O
] O
, O
[ O
reference O
] O
. O
However O
, O
the O
rest O
of O
the O
steps O
in O
the O
pipeline O
have O
been O
rarely O
optimized O
or O
considered O
in O
an O
unified Method
optimization Method
framework Method
. O
In O
this O
paper O
, O
we O
show O
that O
the O
aforementioned O
pipeline O
is O
equivalent O
to O
a O
deep Method
convolutional Method
neural Method
network Method
[ O
reference O
] O
( O
more O
details O
in O
Section O
3.2 O
) O
. O
Motivated O
by O
this O
fact O
, O
we O
consider O
a O
convolutional Method
neural Method
network Method
that O
directly O
learns O
an O
end Task
- Task
to Task
- Task
end Task
mapping Task
between O
low O
- O
and O
high O
- O
resolution O
images O
. O
Our O
method O
differs O
fundamentally O
from O
existing O
external Method
example Method
- Method
based Method
approaches Method
, O
in O
that O
ours O
does O
not O
explicitly O
learn O
the O
dictionaries O
[ O
reference O
] O
, O
[ O
reference O
] O
, O
[ O
reference O
] O
or O
manifolds O
[ O
reference O
] O
, O
[ O
reference O
] O
for O
modeling O
the O
patch O
space O
. O
These O
are O
implicitly O
achieved O
via O
hidden Method
layers Method
. O
Furthermore O
, O
the O
patch Task
extraction Task
and O
aggregation Task
are O
also O
formulated O
as O
convolutional Method
layers Method
, O
so O
are O
involved O
in O
the O
optimization Task
. O
In O
our O
method O
, O
the O
entire O
SR Task
pipeline O
is O
fully O
obtained O
through O
learning Method
, O
with O
little O
pre O
/ O
postprocessing O
. O
We O
name O
the O
proposed O
model O
Super Method
- Method
Resolution Method
Convolutional Method
Neural Method
Network Method
( O
SRCNN Method
) O
[ O
reference O
] O
. O
The O
proposed O
SRCNN Method
has O
several O
appealing O
properties O
. O
First O
, O
its O
structure O
is O
intentionally O
designed O
with O
simplicity O
in O
mind O
, O
and O
yet O
provides O
superior O
accuracy Metric
[ O
reference O
] O
compared O
with O
state O
- O
of O
- O
the O
- O
art O
example Method
- Method
based Method
methods Method
. O
numbers O
of O
filters O
and O
layers O
, O
our O
method O
achieves O
fast O
speed Metric
for O
practical O
on O
- O
line O
usage O
even O
on O
a O
CPU O
. O
Our O
method O
is O
faster O
than O
a O
number O
of O
example Method
- Method
based Method
methods Method
, O
because O
it O
is O
fully O
feed Method
- Method
forward Method
and O
does O
not O
need O
to O
solve O
any O
optimization Task
problem Task
on O
usage O
. O
Third O
, O
experiments O
show O
that O
the O
restoration Metric
quality Metric
of O
the O
network O
can O
be O
further O
improved O
when O
( O
i O
) O
larger O
and O
more O
diverse O
datasets O
are O
available O
, O
and O
/ O
or O
( O
ii O
) O
a O
larger O
and O
deeper O
model O
is O
used O
. O
On O
the O
contrary O
, O
larger O
datasets O
/ O
models O
can O
present O
challenges O
for O
existing O
example Method
- Method
based Method
methods Method
. O
Furthermore O
, O
the O
proposed O
network O
can O
cope O
with O
three O
channels O
of O
color O
images O
simultaneously O
to O
achieve O
improved O
super Metric
- Metric
resolution Metric
performance Metric
. O
Overall O
, O
the O
contributions O
of O
this O
study O
are O
mainly O
in O
three O
aspects O
: O
1 O
) O
We O
present O
a O
fully Method
convolutional Method
neural Method
network Method
for O
image Task
super Task
- Task
resolution Task
. O
The O
network O
directly O
learns O
an O
end Task
- Task
to Task
- Task
end Task
mapping Task
between O
lowand O
high O
- O
resolution O
images O
, O
with O
little O
pre O
/ O
postprocessing O
beyond O
the O
optimization Task
. O
2 O
) O
We O
establish O
a O
relationship O
between O
our O
deeplearning O
- O
based O
SR Task
method O
and O
the O
traditional O
sparse O
- O
coding O
- O
based O
SR Task
methods O
. O
This O
relationship O
provides O
a O
guidance O
for O
the O
design O
of O
the O
network O
structure O
. O
3 O
) O
We O
demonstrate O
that O
deep Method
learning Method
is O
useful O
in O
the O
classical O
computer Task
vision Task
problem Task
of Task
superresolution Task
, O
and O
can O
achieve O
good O
quality Metric
and O
speed Metric
. O
A O
preliminary O
version O
of O
this O
work O
was O
presented O
earlier O
[ O
reference O
] O
. O
The O
present O
work O
adds O
to O
the O
initial O
version O
in O
significant O
ways O
. O
Firstly O
, O
we O
improve O
the O
SRCNN Method
by O
introducing O
larger O
filter O
size O
in O
the O
non O
- O
linear O
mapping O
layer O
, O
and O
explore O
deeper O
structures O
by O
adding O
nonlinear Method
mapping Method
layers Method
. O
Secondly O
, O
we O
extend O
the O
SRCNN Method
to O
process O
three O
color O
channels O
( O
either O
in O
YCbCr O
or O
RGB O
color O
space O
) O
simultaneously O
. O
Experimentally O
, O
we O
demonstrate O
that O
performance O
can O
be O
improved O
in O
comparison O
to O
the O
single Method
- Method
channel Method
network Method
. O
Thirdly O
, O
considerable O
new O
analyses O
and O
intuitive O
explanations O
are O
added O
to O
the O
initial O
results O
. O
We O
also O
extend O
the O
original O
experiments O
from O
Set5 Material
[ O
reference O
] O
and O
Set14 Material
[ O
reference O
] O
test O
images O
to O
BSD200 O
[ O
reference O
] O
( O
200 O
test O
images O
) O
. O
In O
addition O
, O
we O
compare O
with O
a O
number O
of O
recently O
published O
methods O
and O
confirm O
that O
our O
model O
still O
outperforms O
existing O
approaches O
using O
different O
evaluation Metric
metrics Metric
. O
section O
: O
RELATED O
WORK O
section O
: O
Image Task
Super Task
- Task
Resolution Task
According O
to O
the O
image O
priors O
, O
single Method
- Method
image Method
super Method
resolution Method
algorithms Method
can O
be O
categorized O
into O
four O
typesprediction O
models O
, O
edge Method
based Method
methods Method
, O
image Method
statistical Method
methods Method
and O
patch Method
based Method
( Method
or Method
example Method
- Method
based Method
) Method
methods Method
. O
These O
methods O
have O
been O
thoroughly O
investigated O
and O
evaluated O
in O
Yang O
et O
al O
. O
's O
work O
[ O
reference O
] O
. O
Among O
them O
, O
the O
example Method
- Method
based Method
methods Method
[ O
reference O
] O
, O
[ O
reference O
] O
, O
[ O
reference O
] O
, O
[ O
reference O
] O
achieve O
the O
state O
- O
of O
- O
the O
- O
art O
performance O
. O
The O
internal Method
example Method
- Method
based Method
methods Method
exploit O
the O
selfsimilarity O
property O
and O
generate O
exemplar O
patches O
from O
the O
input O
image O
. O
It O
is O
first O
proposed O
in O
Glasner O
's O
work O
[ O
reference O
] O
, O
and O
several O
improved O
variants O
[ O
reference O
] O
, O
[ O
reference O
] O
are O
proposed O
to O
accelerate O
the O
implementation O
. O
The O
external Method
example Method
- Method
based Method
methods Method
[ O
reference O
] O
, O
[ O
reference O
] O
, O
[ O
reference O
] O
, O
[ O
reference O
] O
, O
[ O
reference O
] O
, O
[ O
reference O
] O
, O
[ O
reference O
] O
, O
[ O
reference O
] O
, O
[ O
reference O
] O
, O
[ O
reference O
] O
learn O
a O
mapping O
between O
low O
/ O
highresolution O
patches O
from O
external O
datasets O
. O
These O
studies O
vary O
on O
how O
to O
learn O
a O
compact O
dictionary O
or O
manifold O
space O
to O
relate O
low O
/ O
high O
- O
resolution O
patches O
, O
and O
on O
how O
representation Method
schemes Method
can O
be O
conducted O
in O
such O
spaces O
. O
In O
the O
pioneer O
work O
of O
Freeman O
et O
al O
. O
[ O
reference O
] O
, O
the O
dictionaries Method
are O
directly O
presented O
as O
low O
/ O
high O
- O
resolution O
patch O
pairs O
, O
and O
the O
nearest Method
neighbour Method
( O
NN Method
) O
of O
the O
input O
patch O
is O
found O
in O
the O
low O
- O
resolution O
space O
, O
with O
its O
corresponding O
high O
- O
resolution O
patch O
used O
for O
reconstruction Task
. O
Chang O
et O
al O
. O
[ O
reference O
] O
introduce O
a O
manifold Method
embedding Method
technique Method
as O
an O
alternative O
to O
the O
NN Method
strategy Method
. O
In O
Yang O
et O
al O
. O
's O
work O
[ O
reference O
] O
, O
[ O
reference O
] O
, O
the O
above O
NN Method
correspondence Method
advances O
to O
a O
more O
sophisticated O
sparse Method
coding Method
formulation Method
. O
Other O
mapping Method
functions Method
such O
as O
kernel Method
regression Method
[ O
reference O
] O
, O
simple Method
function Method
[ O
reference O
] O
, O
random Method
forest Method
[ O
reference O
] O
and O
anchored Method
neighborhood Method
regression Method
[ O
reference O
] O
, O
[ O
reference O
] O
are O
proposed O
to O
further O
improve O
the O
mapping Metric
accuracy Metric
and O
speed Metric
. O
The O
sparsecoding Method
- Method
based Method
method Method
and O
its O
several O
improvements O
[ O
reference O
] O
, O
[ O
reference O
] O
, O
[ O
reference O
] O
are O
among O
the O
state O
- O
of O
- O
the O
- O
art O
SR Task
methods O
nowadays O
. O
In O
these O
methods O
, O
the O
patches O
are O
the O
focus O
of O
the O
optimization Task
; O
the O
patch Task
extraction Task
and O
aggregation Task
steps O
are O
considered O
as O
pre Task
/ Task
post Task
- Task
processing Task
and O
handled O
separately O
. O
The O
majority O
of O
SR Task
algorithms O
[ O
reference O
] O
, O
[ O
reference O
] O
, O
[ O
reference O
] O
, O
[ O
reference O
] O
, O
[ O
reference O
] O
, O
[ O
reference O
] O
, O
[ O
reference O
] O
, O
[ O
reference O
] O
focus O
on O
gray Task
- Task
scale Task
or O
single Task
- Task
channel Task
image Task
super Task
- Task
resolution Task
. O
For O
color O
images O
, O
the O
aforementioned O
methods O
first O
transform O
the O
problem O
to O
a O
different O
color O
space O
( O
YCbCr O
or O
YUV O
) O
, O
and O
SR Task
is O
applied O
only O
on O
the O
luminance O
channel O
. O
There O
are O
also O
works O
attempting O
to O
super O
- O
resolve O
all O
channels O
simultaneously O
. O
For O
example O
, O
Kim O
and O
Kwon O
[ O
reference O
] O
and O
Dai O
et O
al O
. O
[ O
reference O
] O
apply O
their O
model O
to O
each O
RGB O
channel O
and O
combined O
them O
to O
produce O
the O
final O
results O
. O
However O
, O
none O
of O
them O
has O
analyzed O
the O
SR Task
performance O
of O
different O
channels O
, O
and O
the O
necessity O
of O
recovering O
all O
three O
channels O
. O
section O
: O
Convolutional Method
Neural Method
Networks Method
Convolutional Method
neural Method
networks Method
( O
CNN Method
) O
date O
back O
decades O
[ O
reference O
] O
and O
deep Method
CNNs Method
have O
recently O
shown O
an O
explosive O
popularity O
partially O
due O
to O
its O
success O
in O
image Task
classification Task
[ O
reference O
] O
, O
[ O
reference O
] O
. O
They O
have O
also O
been O
successfully O
applied O
to O
other O
computer Task
vision Task
fields Task
, O
such O
as O
object Task
detection Task
[ O
reference O
] O
, O
[ O
reference O
] O
, O
[ O
reference O
] O
, O
face Task
recognition Task
[ O
reference O
] O
, O
and O
pedestrian Task
detection Task
[ O
reference O
] O
. O
Several O
factors O
are O
of O
central O
importance O
in O
this O
progress O
: O
( O
i O
) O
the O
efficient O
training Method
implementation Method
on O
modern O
powerful O
GPUs Method
[ O
reference O
] O
, O
( O
ii O
) O
the O
proposal O
of O
the O
Rectified Method
Linear Method
Unit Method
( O
ReLU Method
) O
[ O
reference O
] O
which O
makes O
convergence Task
much O
faster O
while O
still O
presents O
good O
quality O
[ O
reference O
] O
, O
and O
( O
iii O
) O
the O
easy O
access O
to O
an O
abundance O
of O
data O
( O
like O
ImageNet Method
[ O
reference O
] O
) O
for O
training O
larger Method
models Method
. O
Our O
method O
also O
benefits O
from O
these O
progresses O
. O
section O
: O
Deep Method
Learning Method
for O
Image Task
Restoration Task
There O
have O
been O
a O
few O
studies O
of O
using O
deep Method
learning Method
techniques Method
for O
image Task
restoration Task
. O
The O
multi Method
- Method
layer Method
perceptron Method
( Method
MLP Method
) Method
, O
whose O
all O
layers O
are O
fully O
- O
connected O
( O
in O
contrast O
to O
convolutional Method
) O
, O
is O
applied O
for O
natural Task
image Task
denoising Task
[ O
reference O
] O
and O
post Task
- Task
deblurring Task
denoising Task
[ O
reference O
] O
. O
More O
closely O
related O
to O
our O
work O
, O
the O
convolutional Method
neural Method
network Method
is O
applied O
for O
natural Task
image Task
denoising Task
[ O
reference O
] O
and O
removing O
noisy O
patterns O
( O
dirt O
/ O
rain O
) O
[ O
reference O
] O
. O
These O
restoration Task
problems Task
are O
more O
or O
less O
denoising Task
- Task
driven Task
. O
Cui O
et O
al O
. O
[ O
reference O
] O
propose O
to O
embed O
auto Method
- Method
encoder Method
networks Method
in O
their O
superresolution Method
pipeline Method
under O
the O
notion O
internal Method
examplebased Method
approach Method
[ O
reference O
] O
. O
The O
deep Method
model Method
is O
not O
specifically O
designed O
to O
be O
an O
end Task
- Task
to Task
- Task
end Task
solution Task
, O
since O
each O
layer O
of O
the O
cascade Method
requires O
independent O
optimization O
of O
the O
self Method
- Method
similarity Method
search Method
process Method
and O
the O
auto Method
- Method
encoder Method
. O
On O
the O
contrary O
, O
the O
proposed O
SRCNN Method
optimizes O
an O
end Task
- Task
toend Task
mapping Task
. O
Further O
, O
the O
SRCNN Method
is O
faster O
at O
speed Metric
. O
It O
is O
not O
only O
a O
quantitatively O
superior O
method O
, O
but O
also O
a O
practically O
useful O
one O
. O
section O
: O
CONVOLUTIONAL Method
NEURAL Method
NETWORKS Method
FOR O
SUPER Task
- Task
RESOLUTION Task
section O
: O
Formulation O
Consider O
a O
single O
low O
- O
resolution O
image O
, O
we O
first O
upscale O
it O
to O
the O
desired O
size O
using O
bicubic Method
interpolation Method
, O
which O
is O
the O
only O
pre O
- O
processing O
we O
perform O
[ O
reference O
] O
. O
Let O
us O
denote O
the O
interpolated O
image O
as O
Y. O
Our O
goal O
is O
to O
recover O
from O
Y O
an O
image O
F O
( O
Y O
) O
that O
is O
as O
similar O
as O
possible O
to O
the O
ground O
truth O
high O
- O
resolution O
image O
X. O
For O
the O
ease O
of O
presentation O
, O
we O
still O
call O
Y O
a O
" O
low O
- O
resolution O
" O
image O
, O
although O
it O
has O
the O
same O
size O
as O
X. O
We O
wish O
to O
learn O
a O
mapping Task
F Task
, O
which O
conceptually O
consists O
of O
three O
operations O
: O
1 O
) O
Patch Method
extraction Method
and O
representation Task
: O
this O
operation O
extracts O
( O
overlapping O
) O
patches O
from O
the O
lowresolution O
image O
Y O
and O
represents O
each O
patch O
as O
a O
high O
- O
dimensional O
vector O
. O
These O
vectors O
comprise O
a O
set O
of O
feature O
maps O
, O
of O
which O
the O
number O
equals O
to O
the O
dimensionality O
of O
the O
vectors O
. O
2 O
) O
Non Method
- Method
linear Method
mapping Method
: O
this O
operation O
nonlinearly O
maps O
each O
high O
- O
dimensional O
vector O
onto O
another O
high O
- O
dimensional O
vector O
. O
Each O
mapped O
vector O
is O
conceptually O
the O
representation O
of O
a O
high Task
- Task
resolution Task
patch Task
. O
These O
vectors O
comprise O
another O
set O
of O
feature Method
maps Method
. O
3 O
) O
Reconstruction Task
: O
this O
operation O
aggregates O
the O
above O
high Method
- Method
resolution Method
patch Method
- Method
wise Method
representations Method
to O
generate O
the O
final O
high O
- O
resolution O
image O
. O
This O
image O
is O
expected O
to O
be O
similar O
to O
the O
ground O
truth O
X. O
We O
will O
show O
that O
all O
these O
operations O
form O
a O
convolutional Method
neural Method
network Method
. O
An O
overview O
of O
the O
network O
is O
depicted O
in O
Figure O
2 O
. O
Next O
we O
detail O
our O
definition O
of O
each O
operation O
. O
section O
: O
Patch Task
extraction Task
and O
representation Task
A O
popular O
strategy O
in O
image Task
restoration Task
( O
e.g. O
, O
[ O
reference O
] O
) O
is O
to O
densely O
extract O
patches O
and O
then O
represent O
them O
by O
a O
set O
of O
pre O
- O
trained O
bases O
such O
as O
PCA Method
, O
DCT Method
, O
Haar Method
, O
etc O
. O
This O
is O
equivalent O
to O
convolving O
the O
image O
by O
a O
set O
of O
filters Method
, O
each O
of O
which O
is O
a O
basis O
. O
In O
our O
formulation O
, O
we O
involve O
the O
optimization O
of O
these O
bases O
into O
the O
optimization Task
of Task
the Task
network Task
. O
Formally O
, O
our O
first O
layer O
is O
expressed O
as O
an O
operation O
F O
1 O
: O
where O
W O
1 O
and O
B O
1 O
represent O
the O
filters O
and O
biases O
respectively O
, O
and O
' O
* O
' O
denotes O
the O
convolution Method
operation Method
. O
Here O
, O
W O
1 O
corresponds O
to O
n O
1 O
filters O
of O
support O
c O
× O
f O
1 O
× O
f O
1 O
, O
where O
c O
is O
the O
number O
of O
channels O
in O
the O
input O
image O
, O
f O
1 O
is O
the O
spatial O
size O
of O
a O
filter Method
. O
Intuitively O
, O
W O
1 O
applies O
n O
1 O
convolutions Method
on O
the O
image O
, O
and O
each O
convolution Method
has O
[ O
reference O
] O
. O
Bicubic Method
interpolation Method
is O
also O
a O
convolutional Method
operation Method
, O
so O
it O
can O
be O
formulated O
as O
a O
convolutional Method
layer Method
. O
However O
, O
the O
output O
size O
of O
this O
layer O
is O
larger O
than O
the O
input O
size O
, O
so O
there O
is O
a O
fractional O
stride O
. O
To O
take O
advantage O
of O
the O
popular O
well Method
- Method
optimized Method
implementations Method
such O
as O
cuda Method
- Method
convnet Method
[ O
reference O
] O
, O
we O
exclude O
this O
" O
layer O
" O
from O
learning Task
. O
a O
kernel Method
size Method
c O
× O
f O
1 O
× O
f O
1 O
. O
The O
output O
is O
composed O
of O
n O
1 O
feature O
maps O
. O
B O
1 O
is O
an O
n O
1 O
- O
dimensional O
vector O
, O
whose O
each O
element O
is O
associated O
with O
a O
filter Method
. O
We O
apply O
the O
Rectified Method
Linear Method
Unit Method
( O
ReLU Method
, O
max O
( O
0 O
, O
x O
) O
) O
[ O
reference O
] O
on O
the O
filter O
responses O
4 O
. O
section O
: O
Non Task
- Task
linear Task
mapping Task
The O
first O
layer O
extracts O
an O
n O
1 O
- O
dimensional O
feature O
for O
each O
patch O
. O
In O
the O
second O
operation O
, O
we O
map O
each O
of O
these O
n O
1 O
- O
dimensional O
vectors O
into O
an O
n O
2 O
- O
dimensional O
one O
. O
This O
is O
equivalent O
to O
applying O
n Method
2 Method
filters Method
which O
have O
a O
trivial O
spatial O
support O
1 O
× O
1 O
. O
This O
interpretation O
is O
only O
valid O
for O
1 Method
× Method
1 Method
filters Method
. O
But O
it O
is O
easy O
to O
generalize O
to O
larger O
filters O
like O
3 O
× O
3 O
or O
5 O
× O
5 O
. O
In O
that O
case O
, O
the O
non Method
- Method
linear Method
mapping Method
is O
not O
on O
a O
patch O
of O
the O
input O
image O
; O
instead O
, O
it O
is O
on O
a O
3 O
× O
3 O
or O
5 O
× O
5 O
" O
patch O
" O
of O
the O
feature O
map O
. O
The O
operation O
of O
the O
second O
layer O
is O
: O
Here O
W O
2 O
contains O
n O
2 O
filters O
of O
size O
n O
1 O
× O
f O
2 O
× O
f O
2 O
, O
and O
B O
2 O
is O
n O
2 O
- O
dimensional O
. O
Each O
of O
the O
output O
n O
2 O
- O
dimensional O
vectors O
is O
conceptually O
a O
representation O
of O
a O
high Task
- Task
resolution Task
patch Task
that O
will O
be O
used O
for O
reconstruction Task
. O
It O
is O
possible O
to O
add O
more O
convolutional O
layers O
to O
increase O
the O
non O
- O
linearity O
. O
But O
this O
can O
increase O
the O
complexity O
of O
the O
model O
( O
n O
2 O
× O
f O
2 O
× O
f O
2 O
× O
n O
2 O
parameters O
for O
one O
layer O
) O
, O
and O
thus O
demands O
more O
training O
time O
. O
We O
will O
explore O
deeper O
structures O
by O
introducing O
additional O
non O
- O
linear O
mapping O
layers O
in O
Section O
4.3.3 O
. O
section O
: O
Reconstruction Task
In O
the O
traditional O
methods O
, O
the O
predicted O
overlapping O
high O
- O
resolution O
patches O
are O
often O
averaged O
to O
produce O
the O
final O
full O
image O
. O
The O
averaging Method
can O
be O
considered O
as O
a O
pre O
- O
defined Method
filter Method
on O
a O
set O
of O
feature O
maps O
( O
where O
each O
position O
is O
the O
" O
flattened O
" O
vector O
form O
of O
a O
highresolution O
patch O
) O
. O
Motivated O
by O
this O
, O
we O
define O
a O
convolutional Method
layer Method
to O
produce O
the O
final O
high O
- O
resolution O
image O
: O
4 O
. O
The O
ReLU Method
can O
be O
equivalently O
considered O
as O
a O
part O
of O
the O
second O
operation O
( O
Non Task
- Task
linear Task
mapping Task
) O
, O
and O
the O
first O
operation O
( O
Patch Task
extraction Task
and Task
representation Task
) O
becomes O
purely O
linear Method
convolution Method
. O
Here O
W O
3 O
corresponds O
to O
c O
filters O
of O
a O
size O
n O
2 O
× O
f O
3 O
× O
f O
3 O
, O
and O
B O
3 O
is O
a O
c O
- O
dimensional O
vector O
. O
If O
the O
representations O
of O
the O
high Task
- Task
resolution Task
patches Task
are O
in O
the O
image O
domain O
( O
i.e. O
, O
we O
can O
simply O
reshape O
each O
representation O
to O
form O
the O
patch O
) O
, O
we O
expect O
that O
the O
filters O
act O
like O
an O
averaging Method
filter Method
; O
if O
the O
representations O
of O
the O
high O
- O
resolution O
patches O
are O
in O
some O
other O
domains O
( O
e.g. O
, O
coefficients O
in O
terms O
of O
some O
bases O
) O
, O
we O
expect O
that O
W O
3 O
behaves O
like O
first O
projecting O
the O
coefficients O
onto O
the O
image O
domain O
and O
then O
averaging Method
. O
In O
either O
way O
, O
W O
3 O
is O
a O
set O
of O
linear Method
filters Method
. O
Interestingly O
, O
although O
the O
above O
three O
operations O
are O
motivated O
by O
different O
intuitions O
, O
they O
all O
lead O
to O
the O
same O
form O
as O
a O
convolutional Method
layer Method
. O
We O
put O
all O
three O
operations O
together O
and O
form O
a O
convolutional Method
neural Method
network Method
( O
Figure O
2 O
) O
. O
In O
this O
model O
, O
all O
the O
filtering O
weights O
and O
biases O
are O
to O
be O
optimized O
. O
Despite O
the O
succinctness O
of O
the O
overall O
structure O
, O
our O
SRCNN Method
model O
is O
carefully O
developed O
by O
drawing O
extensive O
experience O
resulted O
from O
significant O
progresses O
in O
super Task
- Task
resolution Task
[ O
reference O
] O
, O
[ O
reference O
] O
. O
We O
detail O
the O
relationship O
in O
the O
next O
section O
. O
section O
: O
Relationship O
to O
Sparse Method
- Method
Coding Method
- Method
Based Method
Methods Method
We O
show O
that O
the O
sparse O
- O
coding O
- O
based O
SR Task
methods O
[ O
reference O
] O
, O
[ O
reference O
] O
can O
be O
viewed O
as O
a O
convolutional Method
neural Method
network Method
. O
Figure O
3 O
shows O
an O
illustration O
. O
In O
the O
sparse Method
- Method
coding Method
- Method
based Method
methods Method
, O
let O
us O
consider O
that O
an O
f O
1 O
× O
f O
1 O
low O
- O
resolution O
patch O
is O
extracted O
from O
the O
input O
image O
. O
Then O
the O
sparse Method
coding Method
solver Method
, O
like O
Feature Method
- Method
Sign Method
[ O
reference O
] O
, O
will O
first O
project O
the O
patch O
onto O
a O
( O
lowresolution O
) O
dictionary O
. O
If O
the O
dictionary O
size O
is O
n O
1 O
, O
this O
is O
equivalent O
to O
applying O
n O
1 O
linear Method
filters Method
( O
f O
1 O
× O
f O
1 O
) O
on O
the O
input O
image O
( O
the O
mean Method
subtraction Method
is O
also O
a O
linear O
operation O
so O
can O
be O
absorbed O
) O
. O
This O
is O
illustrated O
as O
the O
left O
part O
of O
Figure O
3 O
. O
The O
sparse Method
coding Method
solver Method
will O
then O
iteratively O
process O
the O
n O
1 O
coefficients O
. O
The O
outputs O
of O
this O
solver O
are O
n O
2 O
coefficients O
, O
and O
usually O
n O
2 O
= O
n O
1 O
in O
the O
case O
of O
sparse Task
coding Task
. O
These O
n O
2 O
coefficients O
are O
the O
representation O
of O
the O
high Task
- Task
resolution Task
patch Task
. O
In O
this O
sense O
, O
the O
sparse Method
coding Method
solver Method
behaves O
as O
a O
special O
case O
of O
a O
non Method
- Method
linear Method
mapping Method
operator Method
, O
whose O
spatial O
support O
is O
1 O
× O
1 O
. O
See O
the O
middle O
part O
of O
Figure O
3 O
. O
However O
, O
the O
sparse Method
coding Method
solver Method
is O
not O
feed Method
- Method
forward Method
, O
i.e. O
, O
it O
is O
an O
iterative Method
algorithm Method
. O
On O
the O
contrary O
, O
our O
non Method
- Method
linear Method
operator Method
is O
fully O
feed O
- O
forward O
and O
can O
be O
computed O
efficiently O
. O
If O
we O
set O
f O
2 O
= O
1 O
, O
then O
our O
non Method
- Method
linear Method
operator Method
can O
be O
considered O
as O
a O
pixel Method
- Method
wise Method
fully Method
- Method
connected Method
layer Method
. O
It O
is O
worth O
noting O
that O
" O
the O
sparse Method
coding Method
solver Method
" O
in O
SRCNN Method
refers O
to O
the O
first O
two O
layers O
, O
but O
not O
just O
the O
second O
layer O
or O
the O
activation O
function O
( O
ReLU Method
) O
. O
Thus O
the O
nonlinear Method
operation Method
in O
SRCNN Method
is O
also O
well O
optimized O
through O
the O
learning Method
process Method
. O
The O
above O
n O
2 O
coefficients O
( O
after O
sparse Method
coding Method
) O
are O
then O
projected O
onto O
another O
( O
high O
- O
resolution O
) O
dictionary O
to O
produce O
a O
high Task
- Task
resolution Task
patch Task
. O
The O
overlapping O
high O
- O
resolution O
patches O
are O
then O
averaged O
. O
As O
discussed O
above O
, O
this O
is O
equivalent O
to O
linear Method
convolutions Method
on O
the O
n O
2 O
feature O
maps O
. O
If O
the O
high O
- O
resolution O
patches O
used O
for O
reconstruction Task
are O
of O
size O
f O
3 O
× O
f O
3 O
, O
then O
the O
linear Method
filters Method
have O
an O
equivalent O
spatial O
support O
of O
size O
f O
3 O
× O
f O
3 O
. O
See O
the O
right O
part O
of O
Figure O
3 O
. O
The O
above O
discussion O
shows O
that O
the O
sparse O
- O
codingbased O
SR Task
method O
can O
be O
viewed O
as O
a O
kind O
of O
convolutional Method
neural Method
network Method
( O
with O
a O
different O
non O
- O
linear O
mapping O
) O
. O
But O
not O
all O
operations O
have O
been O
considered O
in O
the O
optimization Task
in O
the O
sparse O
- O
coding O
- O
based O
SR Task
methods O
. O
On O
the O
contrary O
, O
in O
our O
convolutional Method
neural Method
network Method
, O
the O
low O
- O
resolution O
dictionary O
, O
high O
- O
resolution O
dictionary O
, O
non Method
- Method
linear Method
mapping Method
, O
together O
with O
mean Method
subtraction Method
and O
averaging Method
, O
are O
all O
involved O
in O
the O
filters O
to O
be O
optimized O
. O
So O
our O
method O
optimizes O
an O
end Task
- Task
to Task
- Task
end Task
mapping Task
that O
consists O
of O
all O
operations O
. O
The O
above O
analogy O
can O
also O
help O
us O
to O
design O
hyperparameters O
. O
For O
example O
, O
we O
can O
set O
the O
filter O
size O
of O
the O
last O
layer O
to O
be O
smaller O
than O
that O
of O
the O
first O
layer O
, O
and O
thus O
we O
rely O
more O
on O
the O
central O
part O
of O
the O
highresolution O
patch O
( O
to O
the O
extreme O
, O
if O
f O
3 O
= O
1 O
, O
we O
are O
using O
the O
center O
pixel O
with O
no O
averaging O
) O
. O
We O
can O
also O
set O
n O
2 O
< O
n O
1 O
because O
it O
is O
expected O
to O
be O
sparser O
. O
A O
typical O
and O
basic O
setting O
is O
f O
1 O
= O
9 O
, O
f O
2 O
= O
1 O
, O
f O
3 O
= O
5 O
, O
n O
1 O
= O
64 O
, O
and O
n O
2 O
= O
32 O
( O
we O
evaluate O
more O
settings O
in O
the O
experiment O
section O
) O
. O
On O
the O
whole O
, O
the O
estimation O
of O
a O
high O
resolution O
pixel O
utilizes O
the O
information O
of O
( O
9 O
+ O
5 O
− O
1 O
) O
2 O
= O
169 O
pixels O
. O
Clearly O
, O
the O
information O
exploited O
for O
reconstruction Task
is O
comparatively O
larger O
than O
that O
used O
in O
existing O
external Method
example Method
- Method
based Method
approaches Method
, O
e.g. O
, O
using O
( O
5 O
+ O
5−1 O
) O
2 O
= O
81 O
pixels O
5 O
[ O
reference O
] O
, O
[ O
reference O
] O
. O
This O
is O
one O
of O
the O
reasons O
why O
the O
SRCNN Method
gives O
superior O
performance O
. O
section O
: O
Training O
Learning O
the O
end Task
- Task
to Task
- Task
end Task
mapping Task
function Task
F Task
requires O
the O
estimation O
of O
network O
parameters O
Θ O
= O
{ O
W O
1 O
, O
W O
2 O
, O
W O
3 O
, O
B O
1 O
, O
B O
2 O
, O
B O
3 O
} O
. O
This O
is O
achieved O
through O
minimizing O
the O
loss O
between O
the O
reconstructed O
images O
F O
( O
Y O
; O
Θ O
) O
and O
the O
corresponding O
ground O
truth O
highresolution O
images O
X. O
Given O
a O
set O
of O
high O
- O
resolution O
images O
{ O
X O
i O
} O
and O
their O
corresponding O
low O
- O
resolution O
images O
{ O
Y O
i O
} O
, O
we O
use O
Mean Metric
Squared Metric
Error Metric
( O
MSE Metric
) O
as O
the O
loss Metric
function Metric
: O
where O
n O
is O
the O
number O
of O
training O
samples O
. O
Using O
MSE Metric
as O
the O
loss O
function O
favors O
a O
high O
PSNR Metric
. O
The O
PSNR Metric
is O
a O
widely O
- O
used O
metric O
for O
quantitatively Task
evaluating Task
image Task
restoration Task
quality Task
, O
and O
is O
at O
least O
partially O
related O
to O
the O
perceptual Metric
quality Metric
. O
It O
is O
worth O
noticing O
that O
the O
convolutional Method
neural Method
networks Method
do O
not O
preclude O
the O
usage O
of O
other O
kinds O
of O
loss O
functions O
, O
if O
only O
the O
loss O
functions O
are O
derivable O
. O
If O
a O
better O
perceptually Metric
motivated Metric
metric Metric
is O
given O
during O
training O
, O
it O
is O
flexible O
for O
the O
network O
to O
adapt O
to O
that O
metric O
. O
On O
the O
contrary O
, O
such O
a O
flexibility O
is O
in O
general O
difficult O
to O
achieve O
for O
traditional O
" O
handcrafted Method
" Method
methods Method
. O
Despite O
that O
the O
proposed O
model O
is O
trained O
favoring O
a O
high O
PSNR Metric
, O
we O
still O
observe O
satisfactory O
performance O
when O
the O
model O
is O
evaluated O
using O
alternative O
evaluation Metric
metrics Metric
, O
e.g. O
, O
SSIM Metric
, O
MSSIM Metric
( O
see O
Section O
4.4.1 O
) O
. O
The O
loss Task
is O
minimized O
using O
stochastic Method
gradient Method
descent Method
with O
the O
standard O
backpropagation Method
[ O
reference O
] O
. O
In O
particular O
, O
the O
weight O
matrices O
are O
updated O
as O
5 O
. O
The O
patches O
are O
overlapped O
with O
4 O
pixels O
at O
each O
direction O
. O
where O
∈ O
{ O
1 O
, O
2 O
, O
3 O
} O
and O
i O
are O
the O
indices O
of O
layers O
and O
iterations O
, O
η O
is O
the O
learning O
rate O
, O
and O
is O
the O
derivative O
. O
The O
filter O
weights O
of O
each O
layer O
are O
initialized O
by O
drawing O
randomly O
from O
a O
Gaussian Method
distribution Method
with O
zero O
mean O
and O
standard O
deviation O
0.001 O
( O
and O
0 O
for O
biases O
) O
. O
The O
learning Metric
rate Metric
is O
10 O
−4 O
for O
the O
first O
two O
layers O
, O
and O
10 O
−5 O
for O
the O
last O
layer O
. O
We O
empirically O
find O
that O
a O
smaller O
learning Metric
rate Metric
in O
the O
last O
layer O
is O
important O
for O
the O
network O
to O
converge O
( O
similar O
to O
the O
denoising Task
case Task
[ O
reference O
] O
) O
. O
In O
the O
training O
phase O
, O
the O
ground O
truth O
images O
{ O
X O
i O
} O
are O
prepared O
as O
f O
sub O
×f O
sub O
×c O
- O
pixel O
sub O
- O
images O
randomly O
cropped O
from O
the O
training O
images O
. O
By O
" O
sub O
- O
images O
" O
we O
mean O
these O
samples O
are O
treated O
as O
small O
" O
images O
" O
rather O
than O
" O
patches O
" O
, O
in O
the O
sense O
that O
" O
patches O
" O
are O
overlapping O
and O
require O
some O
averaging O
as O
post Task
- Task
processing Task
but O
" O
sub O
- O
images O
" O
need O
not O
. O
To O
synthesize O
the O
low O
- O
resolution O
samples O
{ O
Y O
i O
} O
, O
we O
blur O
a O
sub O
- O
image O
by O
a O
Gaussian Method
kernel Method
, O
sub O
- O
sample O
it O
by O
the O
upscaling O
factor O
, O
and O
upscale O
it O
by O
the O
same O
factor O
via O
bicubic Method
interpolation Method
. O
To O
avoid O
border O
effects O
during O
training O
, O
all O
the O
convolutional Method
layers Method
have O
no O
padding O
, O
and O
the O
network O
produces O
a O
smaller O
output O
( O
( O
2 O
× O
c O
) O
. O
The O
MSE Metric
loss O
function O
is O
evaluated O
only O
by O
the O
difference O
between O
the O
central O
pixels O
of O
X O
i O
and O
the O
network O
output O
. O
Although O
we O
use O
a O
fixed O
image O
size O
in O
training O
, O
the O
convolutional Method
neural Method
network Method
can O
be O
applied O
on O
images O
of O
arbitrary O
sizes O
during O
testing O
. O
We O
implement O
our O
model O
using O
the O
cuda Method
- Method
convnet Method
package Method
[ O
reference O
] O
. O
We O
have O
also O
tried O
the O
Caffe Method
package Method
[ O
reference O
] O
and O
observed O
similar O
performance O
. O
section O
: O
EXPERIMENTS O
We O
first O
investigate O
the O
impact O
of O
using O
different O
datasets O
on O
the O
model O
performance O
. O
Next O
, O
we O
examine O
the O
filters Method
learned O
by O
our O
approach O
. O
We O
then O
explore O
different O
architecture O
designs O
of O
the O
network O
, O
and O
study O
the O
relations O
between O
super Metric
- Metric
resolution Metric
performance Metric
and O
factors O
like O
depth O
, O
number O
of O
filters O
, O
and O
filter O
sizes O
. O
Subsequently O
, O
we O
compare O
our O
method O
with O
recent O
state O
- O
ofthe O
- O
arts O
both O
quantitatively O
and O
qualitatively O
. O
Following O
[ O
reference O
] O
, O
super Task
- Task
resolution Task
is O
only O
applied O
on O
the O
luminance O
channel O
( O
Y O
channel O
in O
YCbCr O
color O
space O
) O
in O
Sections O
4.1 O
- O
4.4 O
, O
so O
c O
= O
1 O
in O
the O
first O
/ O
last O
layer O
, O
and O
performance O
( O
e.g. O
, O
PSNR Metric
and O
SSIM Metric
) O
is O
evaluated O
on O
the O
Y O
channel O
. O
At O
last O
, O
we O
extend O
the O
network O
to O
cope O
with O
color O
images O
and O
evaluate O
the O
performance O
on O
different O
channels O
. O
section O
: O
Training O
Data O
As O
shown O
in O
the O
literature O
, O
deep Method
learning Method
generally O
benefits O
from O
big Task
data Task
training Task
. O
For O
comparison O
, O
we O
use O
a O
relatively O
small O
training O
set O
[ O
reference O
] O
, O
[ O
reference O
] O
that O
consists O
of O
91 O
images O
, O
and O
a O
large O
training O
set O
that O
consists O
of O
395 O
, O
909 O
images O
from O
the O
ILSVRC O
2013 O
ImageNet Method
detection O
training O
partition O
. O
The O
size O
of O
training O
sub O
- O
images O
is O
f O
sub O
= O
33 O
. O
Thus O
the O
91 O
- O
image O
dataset O
can O
be O
decomposed O
into O
24 O
, O
800 O
sub O
- O
images O
, O
which O
are O
extracted O
from O
original O
images O
with O
a O
stride O
of O
14 O
. O
Whereas O
the O
ImageNet Method
provides O
over O
5 O
million O
sub O
- O
images O
even O
using O
a O
stride O
of O
33 O
. O
We O
use O
the O
basic O
network O
settings O
, O
i.e. O
, O
f O
1 O
= O
9 O
, O
f O
2 O
= O
1 O
, O
f O
3 O
= O
5 O
, O
n O
1 O
= O
64 O
, O
and O
n O
2 O
= O
32 O
. O
We O
use O
the O
Set5 Material
[ O
reference O
] O
as O
the O
validation O
set O
. O
We O
observe O
a O
similar O
trend O
even O
if O
we O
use O
the O
larger O
Set14 Material
set O
[ O
reference O
] O
. O
The O
upscaling O
factor O
is O
3 O
. O
We O
use O
the O
sparse Method
- Method
coding Method
- Method
based Method
method Method
[ O
reference O
] O
as O
our O
baseline O
, O
which O
achieves O
an O
average Metric
PSNR Metric
value Metric
of O
31.42 O
dB. O
The O
test O
convergence Metric
curves Metric
of O
using O
different O
training O
sets O
are O
shown O
in O
Figure O
4 O
. O
The O
training Metric
time Metric
on O
ImageNet Method
is O
about O
the O
same O
as O
on O
the O
91 O
- O
image O
dataset O
since O
the O
number O
of O
backpropagations Method
is O
the O
same O
. O
As O
can O
be O
observed O
, O
with O
the O
same O
number O
of O
backpropagations O
( O
i.e. O
, O
8 O
× O
10 O
8 O
) O
, O
the O
SRCNN Method
+ O
ImageNet Method
achieves O
32.52 O
dB O
, O
higher O
than O
32.39 O
dB O
yielded O
by O
that O
trained O
on O
91 O
images O
. O
The O
results O
positively O
indicate O
that O
SRCNN Method
performance O
may O
be O
further O
boosted O
using O
a O
larger O
training O
set O
, O
but O
the O
effect O
of O
big O
data O
is O
not O
as O
impressive O
as O
that O
shown O
in O
high Task
- Task
level Task
vision Task
problems Task
[ O
reference O
] O
. O
This O
is O
mainly O
because O
that O
the O
91 O
images O
have O
already O
captured O
sufficient O
variability O
of O
natural O
images O
. O
On O
the O
other O
hand O
, O
our O
SRCNN Method
is O
a O
relatively O
small O
network O
( O
8 O
, O
032 O
parameters O
) O
, O
which O
could O
not O
overfit O
the O
91 O
images O
( O
24 O
, O
800 O
samples O
) O
. O
Nevertheless O
, O
we O
adopt O
the O
ImageNet Method
, O
which O
contains O
more O
diverse O
data O
, O
as O
the O
default O
training O
set O
in O
the O
following O
experiments O
. O
Figure O
5 O
shows O
examples O
of O
learned O
first Method
- Method
layer Method
filters Method
trained O
on O
the O
ImageNet Method
by O
an O
upscaling O
factor O
3 O
. O
Please O
refer O
to O
our O
published O
implementation O
for O
upscaling O
factors O
2 O
and O
4 O
. O
Interestingly O
, O
each O
learned O
filter O
has O
its O
specific O
functionality O
. O
For O
instance O
, O
the O
filters Method
g Method
and O
h O
are O
like O
Laplacian Method
/ Method
Gaussian Method
filters Method
, O
the O
filters O
a O
- O
e O
are O
like O
edge Method
detectors Method
at O
different O
directions O
, O
and O
the O
filter Method
f Method
is O
like O
a O
texture Method
extractor Method
. O
Example O
feature O
maps O
of O
different O
layers O
are O
shown O
in O
figure O
6 O
. O
Obviously O
, O
feature O
maps O
of O
the O
first O
layer O
contain O
different O
structures O
( O
e.g. O
, O
edges O
at O
different O
directions O
) O
, O
while O
that O
of O
the O
second O
layer O
are O
mainly O
different O
on O
intensities O
. O
section O
: O
Learned Method
Filters Method
for O
Super Task
- Task
Resolution Task
section O
: O
Model O
and O
Performance O
Trade O
- O
offs O
Based O
on O
the O
basic O
network O
settings O
( O
i.e. O
, O
f O
1 O
= O
9 O
, O
f O
2 O
= O
1 O
, O
f O
3 O
= O
5 O
, O
n O
1 O
= O
64 O
, O
and O
n O
2 O
= O
32 O
) O
, O
we O
will O
progressively O
modify O
some O
of O
these O
parameters O
to O
investigate O
the O
best O
trade O
- O
off O
between O
performance O
and O
speed Metric
, O
and O
study O
the O
relations O
between O
performance O
and O
parameters O
. O
section O
: O
Filter O
number O
In O
general O
, O
the O
performance O
would O
improve O
if O
we O
increase O
the O
network O
width O
[ O
reference O
] O
, O
i.e. O
, O
adding O
more O
filters O
, O
at O
the O
cost O
of O
running Metric
time Metric
. O
Specifically O
, O
based O
on O
our O
network O
default O
settings O
of O
n O
1 O
= O
64 O
and O
n O
2 O
= O
32 O
, O
we O
conduct O
two O
experiments O
: O
( O
i O
) O
one O
is O
with O
a O
larger O
network O
with O
n O
1 O
= O
128 O
and O
n O
2 O
= O
64 O
, O
and O
( O
ii O
) O
the O
other O
is O
with O
a O
smaller O
network O
with O
n O
1 O
= O
32 O
and O
n O
2 O
= O
16 O
. O
Similar O
to O
Section O
4.1 O
, O
we O
also O
train O
the O
two O
models O
on O
ImageNet Method
and O
test O
on O
Set5 Material
with O
an O
upscaling O
factor O
3 O
. O
The O
results O
observed O
at O
8 O
× O
10 O
8 O
backpropagations O
are O
shown O
in O
Table O
1 O
. O
It O
is O
clear O
that O
superior O
performance O
could O
be O
achieved O
by O
increasing O
the O
width O
. O
However O
, O
if O
a O
fast O
restoration O
speed Metric
is O
desired O
, O
a O
small O
network O
width O
is O
preferred O
, O
which O
could O
still O
achieve O
better O
performance O
than O
the O
sparsecoding Method
- Method
based Method
method Method
( O
31.42 O
dB O
) O
. O
section O
: O
Filter Method
size Method
In O
this O
section O
, O
we O
examine O
the O
network O
sensitivity O
to O
different O
filter O
sizes O
. O
In O
previous O
experiments O
, O
we O
set O
filter O
size O
f O
1 O
= O
9 O
, O
f O
2 O
= O
1 O
and O
f O
3 O
= O
5 O
, O
and O
the O
network O
could O
be O
denoted O
as O
9 O
- O
1 O
- O
5 O
. O
First O
, O
to O
be O
consistent O
with O
sparse Method
- Method
coding Method
- Method
based Method
methods Method
, O
we O
fix O
the O
filter O
size O
of O
the O
second O
layer O
to O
be O
f O
2 O
= O
1 O
, O
and O
enlarge O
the O
filter O
size O
of O
other O
layers O
to O
f O
1 O
= O
11 O
and O
f O
3 O
= O
7 O
( O
11 O
- O
1 O
- O
7 O
) O
. O
All O
the O
other O
[ O
reference O
] O
. O
We O
use O
' O
width O
' O
to O
term O
the O
number O
of O
filters O
in O
a O
layer O
, O
following O
[ O
reference O
] O
. O
The O
term O
' O
width O
' O
may O
have O
other O
meanings O
in O
the O
literature O
. O
settings O
remain O
the O
same O
with O
Section O
4.1 O
. O
The O
results O
with O
an O
upscaling O
factor O
3 O
on O
Set5 Material
are O
32.57 O
dB O
, O
which O
is O
slightly O
higher O
than O
the O
32.52 O
dB O
reported O
in O
Section O
4.1 O
. O
This O
indicates O
that O
a O
reasonably O
larger O
filter O
size O
could O
grasp O
richer O
structural O
information O
, O
which O
in O
turn O
lead O
to O
better O
results O
. O
Then O
we O
further O
examine O
networks O
with O
a O
larger O
filter O
size O
of O
the O
second O
layer O
. O
Specifically O
, O
we O
fix O
the O
filter O
size O
f O
1 O
= O
9 O
, O
f O
3 O
= O
5 O
, O
and O
enlarge O
the O
filter O
size O
of O
the O
second O
layer O
to O
be O
( O
i O
) O
f O
2 O
= O
3 O
( O
9 O
- O
3 O
- O
5 O
) O
and O
( O
ii O
) O
f O
2 O
= O
5 O
( O
9 O
- O
5 O
- O
5 O
) O
. O
Convergence O
curves O
in O
Figure O
7 O
show O
that O
using O
a O
larger O
filter O
size O
could O
significantly O
improve O
the O
performance O
. O
Specifically O
, O
the O
average O
PSNR Metric
values O
achieved O
by O
9 O
- O
3 O
- O
5 O
and O
9 O
- O
5 O
- O
5 O
on O
Set5 Material
with O
8 O
× O
10 O
8 O
backpropagations O
are O
32.66 O
dB O
and O
32.75 O
dB O
, O
respectively O
. O
The O
results O
suggest O
that O
utilizing O
neighborhood O
information O
in O
the O
mapping Task
stage Task
is O
beneficial O
. O
However O
, O
the O
deployment O
speed Metric
will O
also O
decrease O
with O
a O
larger O
filter O
size O
. O
For O
example O
, O
the O
number O
of O
parameters O
of O
9 O
- O
1 O
- O
5 O
, O
9 O
- O
3 O
- O
5 O
, O
and O
9 O
- O
5 O
- O
5 O
is O
8 O
, O
032 O
, O
24 O
, O
416 O
, O
and O
57 O
, O
184 O
respectively O
. O
The O
complexity Metric
of O
9 O
- O
5 O
- O
5 O
is O
almost O
twice O
of O
9 O
- O
3 O
- O
5 O
, O
but O
the O
performance O
improvement O
is O
marginal O
. O
Therefore O
, O
the O
choice O
of O
the O
network O
scale O
should O
always O
be O
a O
trade O
- O
off O
between O
performance O
and O
speed Metric
. O
section O
: O
Number O
of O
layers O
Recent O
study O
by O
He O
and O
Sun O
[ O
reference O
] O
suggests O
that O
CNN Method
could O
benefit O
from O
increasing O
the O
depth O
of O
network O
moderately O
. O
Here O
, O
we O
try O
deeper O
structures O
by O
adding O
another O
non Method
- Method
linear Method
mapping Method
layer Method
, O
which O
has O
n O
22 O
= O
16 O
filters O
with O
size O
f O
22 O
= O
1 O
. O
We O
conduct O
three O
controlled O
experiments O
, O
i.e. O
, O
9 O
- O
1 O
- O
1 O
- O
5 O
, O
9 O
- O
3 O
- O
1 O
- O
5 O
, O
9 O
- O
5 O
- O
1 O
- O
5 O
, O
which O
add O
an O
additional O
layer O
on O
9 O
- O
1 O
- O
5 O
, O
9 O
- O
3 O
- O
5 O
, O
and O
9 O
- O
5 O
- O
5 O
, O
respectively O
. O
The O
initialization Method
scheme Method
and O
learning Metric
rate Metric
of O
the O
additional Method
layer Method
are O
the O
same O
as O
the O
second O
layer O
. O
From O
Figures O
13 O
( O
a O
) O
, O
13 O
( O
b O
) O
and O
8 O
( O
c O
) O
, O
we O
can O
observe O
that O
the O
four Method
- Method
layer Method
networks Method
converge O
slower O
than O
the O
three Method
- Method
layer Method
network Method
. O
Nevertheless O
, O
given O
enough O
training O
time O
, O
the O
deeper Method
networks Method
will O
finally O
catch O
up O
and O
converge O
to O
the O
three O
- O
layer O
ones O
. O
The O
effectiveness O
of O
deeper O
structures O
for O
super Task
resolution Task
is O
found O
not O
as O
apparent O
as O
that O
shown O
in O
image Task
classification Task
[ O
reference O
] O
. O
Furthermore O
, O
we O
find O
that O
deeper Method
networks Method
do O
not O
always O
result O
in O
better O
performance O
. O
Specifically O
, O
if O
we O
add O
an O
additional O
layer O
with O
n O
22 O
= O
32 O
filters O
on O
9 O
- O
1 O
- O
5 O
network O
, O
then O
the O
performance O
degrades O
and O
fails O
to O
surpass O
the O
three O
- O
layer Method
network Method
( O
see O
Figure O
9 O
( O
a O
) O
) O
. O
If O
we O
go O
deeper O
by O
adding O
two O
non Method
- Method
linear Method
mapping Method
layers Method
with O
n O
22 O
= O
32 O
and O
n O
23 O
= O
16 O
filters O
on O
9 O
- O
1 O
- O
5 O
, O
then O
we O
have O
to O
set O
a O
smaller O
learning Metric
rate Metric
to O
ensure O
convergence O
, O
but O
we O
still O
do O
not O
observe O
superior O
performance O
after O
a O
week O
of O
training O
( O
see O
Figure O
9 O
( O
a O
) O
) O
. O
We O
also O
tried O
to O
enlarge O
the O
filter O
size O
of O
the O
additional O
layer O
to O
f O
22 O
= O
3 O
, O
and O
explore O
two O
deep Method
structures Method
- O
9 O
- O
3 O
- O
3 O
- O
5 O
and O
9 O
- O
3 O
- O
3 O
- O
3 O
. O
However O
, O
from O
the O
convergence O
curves O
shown O
in O
Figure O
9 O
( O
b O
) O
, O
these O
two O
networks O
do O
not O
show O
better O
results O
than O
the O
9 O
- O
3 O
- O
1 O
- O
5 O
network O
. O
All O
these O
experiments O
indicate O
that O
it O
is O
not O
" O
the O
deeper O
the O
better O
" O
in O
this O
deep Method
model Method
for O
super Task
- Task
resolution Task
. O
It O
may O
be O
caused O
by O
the O
difficulty O
of O
training O
. O
Our O
CNN Method
network O
contains O
no O
pooling Method
layer Method
or O
full Method
- Method
connected Method
layer Method
, O
thus O
it O
is O
sensitive O
to O
the O
initialization O
parameters O
and O
learning Metric
rate Metric
. O
When O
we O
go O
deeper O
( O
e.g. O
, O
4 O
or O
5 O
layers O
) O
, O
we O
find O
it O
hard O
to O
set O
appropriate O
learning Metric
rates Metric
that O
guarantee O
convergence Metric
. O
Even O
it O
converges O
, O
the O
network O
may O
fall O
into O
a O
bad O
local O
minimum O
, O
and O
the O
learned O
filters O
are O
of O
less O
diversity O
even O
given O
enough O
training O
time O
. O
This O
phenomenon O
is O
also O
observed O
in O
[ O
reference O
] O
, O
where O
improper O
increase O
of O
depth O
leads O
to O
accuracy Metric
saturation Metric
or O
degradation Metric
for O
image Task
classification Task
. O
Why O
" O
deeper O
is O
not O
better O
" O
is O
still O
an O
open O
question O
, O
which O
requires O
investigations O
to O
better O
understand O
gradients O
and O
training O
dynamics O
in O
deep Method
architectures Method
. O
Therefore O
, O
we O
still O
adopt O
three Method
- Method
layer Method
networks Method
in O
the O
following O
experiments O
. O
section O
: O
Comparisons O
to O
State O
- O
of O
- O
the O
- O
Arts O
In O
this O
section O
, O
we O
show O
the O
quantitative O
and O
qualitative O
results O
of O
our O
method O
in O
comparison O
to O
state O
- O
of O
- O
the O
- O
art O
methods O
. O
We O
adopt O
the O
model O
with O
good O
performancespeed O
trade O
- O
off O
: O
a O
three Method
- Method
layer Method
network Method
with O
f O
1 O
= O
9 O
, O
f O
2 O
= O
5 O
, O
f O
3 O
= O
5 O
, O
n O
1 O
= O
64 O
, O
and O
n O
2 O
= O
32 O
trained O
on O
the O
ImageNet Method
. O
For O
each O
upscaling O
factor O
∈ O
{ O
2 O
, O
3 O
, O
4 O
} O
, O
we O
train O
a O
specific O
network O
for O
that O
factor O
[ O
reference O
] O
. O
Comparisons O
. O
We O
compare O
our O
SRCNN Method
with O
the O
stateof O
- O
the O
- O
art O
SR Task
methods O
: O
• O
SC Method
- Method
sparse Method
coding Method
- Method
based Method
method Method
of O
Yang O
et O
al O
. O
[ O
reference O
] O
• O
NE O
+ O
LLE O
- Method
neighbour Method
embedding Method
+ O
locally Method
linear Method
embedding Method
method Method
[ O
reference O
] O
• O
ANR Method
- Method
Anchored Method
Neighbourhood Method
Regression Method
method Method
[ O
reference O
] O
• O
A O
+ O
- O
Adjusted O
Anchored Method
Neighbourhood Method
Regression Method
method Method
[ O
reference O
] O
, O
and O
• O
KK Method
- Method
the Method
method Method
described O
in O
[ O
reference O
] O
, O
which O
achieves O
the O
best O
performance O
among O
external O
examplebased Method
methods Method
, O
according O
to O
the O
comprehensive O
evaluation O
conducted O
in O
Yang O
et O
al O
. O
's O
work O
[ O
reference O
] O
The O
implementations O
are O
all O
from O
the O
publicly O
available O
codes O
provided O
by O
the O
authors O
, O
and O
all O
images O
are O
downsampled O
using O
the O
same O
bicubic Method
kernel Method
. O
Test O
set O
. O
The O
Set5 Material
[ O
2 O
] O
( O
5 O
images O
) O
, O
Set14 Material
[ O
51 O
] O
( O
14 O
images O
) O
and O
BSD200 O
[ O
reference O
] O
( O
200 O
images O
) O
[ O
reference O
] O
are O
used O
to O
evaluate O
the O
performance O
of O
upscaling O
factors O
2 O
, O
3 O
, O
and O
4 O
. O
Evaluation Metric
metrics Metric
. O
Apart O
from O
the O
widely O
used O
PSNR Metric
and O
SSIM Metric
[ O
reference O
] O
indices O
, O
we O
also O
adopt O
another O
four O
evaluation Metric
matrices Metric
, O
namely O
information Metric
fidelity Metric
criterion Metric
( O
IFC Metric
) O
[ O
reference O
] O
, O
noise Metric
quality Metric
measure Metric
( O
NQM Metric
) O
[ O
reference O
] O
, O
weighted Metric
peak Metric
signal Metric
- Metric
to Metric
- Metric
noise Metric
ratio Metric
( O
WPSNR Metric
) O
and O
multiscale Metric
structure Metric
similarity Metric
index Metric
( O
MSSSIM Metric
) O
[ O
reference O
] O
, O
which O
obtain O
high O
correlation O
with O
the O
human Metric
perceptual Metric
scores Metric
as O
reported O
in O
[ O
reference O
] O
. O
section O
: O
Quantitative Metric
and Metric
qualitative Metric
evaluation Metric
As O
shown O
in O
Tables O
2 O
, O
3 O
and O
4 O
, O
the O
proposed O
SRCNN Method
yields O
the O
highest O
scores O
in O
most O
evaluation Metric
matrices Metric
[ O
reference O
] O
. O
In O
the O
area O
of O
denoising Task
[ O
reference O
] O
, O
for O
each O
noise O
level O
a O
specific O
network O
is O
trained O
. O
8 O
. O
We O
use O
the O
same O
200 O
images O
as O
in O
[ O
reference O
] O
. O
in O
all O
experiments O
[ O
reference O
] O
. O
Note O
that O
our O
SRCNN Method
results O
are O
based O
on O
the O
checkpoint O
of O
8 O
× O
10 O
8 O
backpropagations Method
. O
Specifically O
, O
for O
the O
upscaling O
factor O
3 O
, O
the O
average O
gains O
on O
PSNR Metric
achieved O
by O
SRCNN Method
are O
0.15 O
dB O
, O
0.17 O
dB O
, O
and O
0.13 O
dB O
, O
higher O
than O
the O
next O
best O
approach O
, O
A O
+ O
[ O
reference O
] O
, O
on O
the O
three O
datasets O
. O
When O
we O
take O
a O
look O
at O
other O
evaluation Metric
metrics Metric
, O
we O
observe O
that O
SC Method
, O
to O
our O
surprise O
, O
gets O
even O
lower O
scores O
than O
the O
bicubic Method
interpolation Method
on O
IFC Method
and O
NQM Method
. O
It O
is O
clear O
that O
the O
results O
of O
SC Method
are O
more O
visually O
pleasing O
than O
that O
of O
bicubic Method
interpolation Method
. O
This O
indicates O
that O
these O
two O
metrics O
may O
not O
truthfully O
reveal O
the O
image Metric
quality Metric
. O
Thus O
, O
regardless O
of O
these O
two O
metrics O
, O
SRCNN Method
achieves O
the O
best O
performance O
among O
all O
methods O
and O
scaling O
factors O
. O
It O
is O
worth O
pointing O
out O
that O
SRCNN Method
surpasses O
the O
bicubic Method
baseline Method
at O
the O
very O
beginning O
of O
the O
learning O
stage O
( O
see O
Figure O
1 O
) O
, O
and O
with O
moderate O
training O
, O
SR Task
- O
CNN Method
outperforms O
existing O
state O
- O
of O
- O
the O
- O
art O
methods O
( O
see O
Figure O
4 O
) O
. O
Yet O
, O
the O
performance O
is O
far O
from O
converge O
. O
We O
conjecture O
that O
better O
results O
can O
be O
obtained O
given O
longer O
training O
time O
( O
see O
Figure O
10 O
) O
. O
Figures O
14 O
, O
15 O
and O
16 O
show O
the O
super Metric
- Metric
resolution Metric
results O
of O
different O
approaches O
by O
an O
upscaling O
factor O
3 O
. O
As O
can O
be O
observed O
, O
the O
SRCNN Method
produces O
much O
sharper O
edges O
than O
other O
approaches O
without O
any O
obvious O
artifacts O
across O
the O
image O
. O
In O
addition O
, O
we O
report O
to O
another O
recent O
deep Method
learning Method
method Method
for O
image Task
super Task
- Task
resolution Task
( O
DNC Task
) O
of O
Cui O
et O
al O
. O
[ O
reference O
] O
. O
As O
they O
employ O
a O
different O
blur O
kernel O
( O
a O
Gaussian Method
filter Method
with O
a O
standard O
deviation O
of O
0.55 O
) O
, O
we O
train O
a O
specific O
network O
( O
9 O
- O
5 O
- O
5 O
) O
using O
the O
same O
blur O
kernel O
as O
DNC Method
for O
fair O
quantitative O
comparison O
. O
The O
upscaling O
factor O
is O
3 O
and O
the O
training O
set O
is O
the O
91 O
- O
image O
dataset O
. O
From O
the O
convergence O
curve O
shown O
in O
Figure O
11 O
, O
we O
observe O
that O
our O
SRCNN Method
surpasses O
DNC Method
with O
just O
2.7 O
× O
10 O
7 O
backprops O
, O
and O
a O
larger O
margin O
can O
be O
obtained O
given O
longer O
training O
time O
. O
This O
also O
demonstrates O
that O
the O
end Method
- Method
to Method
- Method
end Method
learning Method
is O
superior O
to O
DNC Method
, O
even O
if O
that O
model O
is O
already O
" O
deep O
" O
. O
Figure O
12 O
shows O
the O
running Metric
time Metric
comparisons O
of O
several O
state O
- O
of O
- O
the O
- O
art O
methods O
, O
along O
with O
their O
restoration Method
performance O
on O
Set14 Material
. O
All O
baseline O
methods O
are O
obtained O
[ O
reference O
] O
. O
The O
PSNR Metric
value O
of O
each O
image O
can O
be O
found O
in O
the O
supplementary O
file O
. O
section O
: O
Running O
time O
from O
the O
corresponding O
authors O
' O
MATLAB Method
+ Method
MEX Method
implementation Method
, O
whereas O
ours O
are O
in O
pure O
C O
++ O
. O
We O
profile O
the O
running O
time O
of O
all O
the O
algorithms O
using O
the O
same O
machine O
( O
Intel O
CPU O
3.10 O
GHz O
and O
16 O
GB O
memory O
) O
. O
Note O
that O
the O
processing Metric
time Metric
of O
our O
approach O
is O
highly O
linear O
to O
the O
test O
image O
resolution O
, O
since O
all O
images O
go O
through O
the O
same O
number O
of O
convolutions O
. O
Our O
method O
is O
always O
a O
trade O
- O
off O
between O
performance O
and O
speed Metric
. O
To O
show O
this O
, O
we O
train O
three O
networks O
for O
comparison O
, O
which O
are O
9 O
- O
1 O
- O
5 O
, O
9 O
- O
3 O
- O
5 O
, O
and O
9 O
- O
5 O
- O
5 O
. O
It O
is O
clear O
that O
the O
9 Method
- Method
1 Method
- Method
5 Method
network Method
is O
the O
fastest O
, O
while O
it O
still O
achieves O
better O
performance O
than O
the O
next O
state O
- O
of O
- O
the O
- O
art O
A O
+ O
. O
Other O
methods O
are O
several O
times O
or O
even O
orders O
of O
magnitude O
slower O
in O
comparison O
to O
9 O
- O
1 O
- O
5 O
network O
. O
Note O
the O
speed Metric
gap O
is O
not O
mainly O
caused O
by O
the O
different O
MATLAB Method
/ Method
C Method
++ Method
implementations Method
; O
rather O
, O
the O
other O
methods O
need O
to O
solve O
complex O
optimization Task
problems Task
on O
usage O
( O
e.g. O
, O
sparse Task
coding Task
or O
embedding Task
) O
, O
whereas O
our O
method O
is O
completely O
feed Method
- Method
forward Method
. O
The O
9 O
- O
5 O
- O
5 O
network O
achieves O
the O
best O
performance O
but O
at O
the O
cost O
of O
the O
running Metric
time Metric
. O
The O
test O
- O
time O
speed Metric
of O
our O
CNN Method
can O
be O
further O
accelerated O
in O
many O
ways O
, O
e.g. O
, O
approximating O
or O
simplifying O
the O
trained O
networks O
[ O
reference O
] O
, O
[ O
reference O
] O
, O
[ O
reference O
] O
, O
with O
possible O
slight O
degradation O
in O
performance O
. O
section O
: O
Experiments O
on O
Color O
Channels O
In O
previous O
experiments O
, O
we O
follow O
the O
conventional O
approach O
to O
super Task
- Task
resolve Task
color Task
images Task
. O
Specifically O
, O
we O
first O
transform O
the O
color O
images O
into O
the O
YCbCr O
space O
. O
The O
SR Task
algorithms O
are O
only O
applied O
on O
the O
Y O
channel O
, O
while O
the O
Cb O
, O
Cr O
channels O
are O
upscaled O
by O
bicubic Method
interpolation Method
. O
It O
is O
interesting O
to O
find O
out O
if O
super Metric
- Metric
resolution Metric
performance Metric
can O
be O
improved O
if O
we O
jointly O
consider O
all O
three O
channels O
in O
the O
process O
. O
Our O
method O
is O
flexible O
to O
accept O
more O
channels O
without O
altering O
the O
learning Method
mechanism Method
and O
network Method
design Method
. O
In O
particular O
, O
it O
can O
readily O
deal O
with O
three O
channels O
simultaneously O
by O
setting O
the O
input O
channels O
to O
c O
= O
3 O
. O
In O
the O
following O
experiments O
, O
we O
explore O
different O
training Method
strategies Method
for O
color Task
image Task
super Task
- Task
resolution Task
, O
and O
subsequently O
evaluate O
their O
performance O
on O
different O
channels O
. O
Implementation O
details O
. O
Training O
is O
performed O
on O
the O
91 O
- O
image O
dataset O
, O
and O
testing O
is O
conducted O
on O
the O
Set5 Material
[ O
reference O
] O
. O
The O
network O
settings O
are O
: O
c O
= O
3 O
, O
f O
1 O
= O
9 O
, O
f O
2 O
= O
1 O
, O
f O
3 O
= O
5 O
, O
n O
1 O
= O
64 O
, O
and O
n O
2 O
= O
32 O
. O
As O
we O
have O
proved O
the O
SRCNN Method
( O
9 O
- O
3 O
- O
5 O
) O
SRCNN Method
[ O
reference O
] O
-- O
> O
Faster O
Slower O
< O
-- O
Fig O
. O
12 O
. O
The O
proposed O
SRCNN Method
achieves O
the O
stateof O
- O
the O
- O
art O
super Metric
- Metric
resolution Metric
quality Metric
, O
whilst O
maintains O
high O
and O
competitive O
speed Metric
in O
comparison O
to O
existing O
external Method
example Method
- Method
based Method
methods Method
. O
The O
chart O
is O
based O
on O
Set14 Material
results O
summarized O
in O
Table O
3 O
. O
The O
implementation O
of O
all O
three O
SRCNN Method
networks O
are O
available O
on O
our O
project O
page O
. O
Comparisons O
. O
We O
compare O
our O
method O
with O
the O
stateof O
- O
art O
color O
SR Task
method O
- O
KK O
[ O
reference O
] O
. O
We O
also O
try O
different O
learning Method
strategies Method
for O
comparison O
: O
• O
Y O
only O
: O
this O
is O
our O
baseline O
method O
, O
which O
is O
a O
single O
- O
channel O
( O
c O
= O
1 O
) O
network O
trained O
only O
on O
the O
luminance O
channel O
. O
The O
Cb O
, O
Cr O
channels O
are O
upscaled O
using O
bicubic Method
interpolation Method
. O
• O
YCbCr Method
: O
training Method
is O
performed O
on O
the O
three O
channels O
of O
the O
YCbCr O
space O
. O
• O
Y O
pre O
- O
train O
: O
first O
, O
to O
guarantee O
the O
performance O
on O
the O
Y O
channel O
, O
we O
only O
use O
the O
MSE Metric
of O
the O
Y O
channel O
as O
the O
loss O
to O
pre O
- O
train O
the O
network O
. O
Then O
we O
employ O
the O
MSE Metric
of O
all O
channels O
to O
fine O
- O
tune O
the O
parameters O
. O
• O
CbCr O
pre O
- O
train O
: O
we O
use O
the O
MSE Metric
of O
the O
Cb O
, O
Cr O
channels O
as O
the O
loss O
to O
pre O
- O
train O
the O
network O
, O
then O
fine O
- O
tune O
the O
parameters O
on O
all O
channels O
. O
• O
RGB O
: O
training Method
is O
performed O
on O
the O
three O
channels O
of O
the O
RGB O
space O
. O
The O
results O
are O
shown O
in O
Table O
5 O
, O
where O
we O
have O
the O
following O
observations O
. O
( O
i O
) O
If O
we O
directly O
train O
on O
the O
YCbCr O
channels O
, O
the O
results O
are O
even O
worse O
than O
that O
of O
bicubic Method
interpolation Method
. O
The O
training O
falls O
into O
a O
bad O
local O
minimum O
, O
due O
to O
the O
inherently O
different O
characteristics O
of O
the O
Y O
and O
Cb O
, O
Cr O
channels O
. O
( O
ii O
) O
If O
we O
pre O
- O
train O
on O
the O
Y O
or O
Cb O
, O
Cr O
channels O
, O
the O
performance O
finally O
improves O
, O
but O
is O
still O
not O
better O
than O
" O
Y O
only O
" O
on O
the O
color O
image O
( O
see O
the O
last O
column O
of O
Table O
5 O
, O
where O
PSNR Metric
is O
computed O
Fig O
. O
13 O
. O
Chrominance O
channels O
of O
the O
first Method
- Method
layer Method
filters Method
using O
the O
" O
Y Method
pre Method
- Method
train Method
" Method
strategy Method
. O
in O
RGB O
color O
space O
) O
. O
This O
suggests O
that O
the O
Cb O
, O
Cr O
channels O
could O
decrease O
the O
performance O
of O
the O
Y Method
channel Method
when O
training Task
is O
performed O
in O
a O
unified Method
network Method
. O
( O
iii O
) O
We O
observe O
that O
the O
Cb O
, O
Cr O
channels O
have O
higher O
PSNR Metric
values O
for O
" O
Y O
pre O
- O
train O
" O
than O
for O
" O
CbCr O
pre O
- O
train O
" O
. O
The O
reason O
lies O
on O
the O
differences O
between O
the O
Cb O
, O
Cr O
channels O
and O
the O
Y Method
channel Method
. O
Visually O
, O
the O
Cb O
, O
Cr O
channels O
are O
more O
blurry O
than O
the O
Y O
channel O
, O
thus O
are O
less O
affected O
by O
the O
downsampling Method
process Method
. O
When O
we O
pre O
- O
train O
on O
the O
Cb O
, O
Cr O
channels O
, O
there O
are O
only O
a O
few O
filters O
being O
activated O
. O
Then O
the O
training O
will O
soon O
fall O
into O
a O
bad O
local O
minimum O
during O
fine Method
- Method
tuning Method
. O
On O
the O
other O
hand O
, O
if O
we O
pre O
- O
train O
on O
the O
Y O
channel O
, O
more O
filters O
will O
be O
activated O
, O
and O
the O
performance O
on O
Cb O
, O
Cr O
channels O
will O
be O
pushed O
much O
higher O
. O
Figure O
13 O
shows O
the O
Cb O
, O
Cr O
channels O
of O
the O
first Method
- Method
layer Method
filters Method
with O
" O
Y O
pre O
- O
train O
" O
, O
of O
which O
the O
patterns O
largely O
differ O
from O
that O
shown O
in O
Figure O
5 O
. O
( O
iv O
) O
Training O
on O
the O
RGB O
channels O
achieves O
the O
best O
result O
on O
the O
color O
image O
. O
Different O
from O
the O
YCbCr O
channels O
, O
the O
RGB O
channels O
exhibit O
high O
crosscorrelation O
among O
each O
other O
. O
The O
proposed O
SRCNN Method
is O
capable O
of O
leveraging O
such O
natural O
correspondences O
between O
the O
channels O
for O
reconstruction Task
. O
Therefore O
, O
the O
model O
achieves O
comparable O
result O
on O
the O
Y O
channel O
as O
" O
Y O
only O
" O
, O
and O
better O
results O
on O
Cb O
, O
Cr O
channels O
than O
bicubic Method
interpolation Method
. O
( O
v O
) O
In O
KK O
[ O
reference O
] O
, O
super Task
- Task
resolution Task
is O
applied O
on O
each O
RGB O
channel O
separately O
. O
When O
we O
transform O
its O
results O
to O
YCbCr O
space O
, O
the O
PSNR Metric
value O
of O
Y O
channel O
is O
similar O
as O
" O
Y O
only O
" O
, O
but O
that O
of O
Cb O
, O
Cr O
channels O
are O
poorer O
than O
bicubic Method
interpolation Method
. O
The O
result O
suggests O
that O
the O
algorithm O
is O
biased O
to O
the O
Y O
channel O
. O
On O
the O
whole O
, O
our O
method O
trained O
on O
RGB O
channels O
achieves O
better O
performance O
than O
KK Method
and O
the O
singlechannel Method
network Method
( O
" O
Y O
only O
" O
) O
. O
It O
is O
also O
worth O
noting O
that O
the O
improvement O
compared O
with O
the O
single Method
- Method
channel Method
network Method
is O
not O
that O
significant O
( O
i.e. O
, O
0.07 O
dB O
) O
. O
This O
indicates O
that O
the O
Cb O
, O
Cr O
channels O
barely O
help O
in O
improving O
the O
performance O
. O
section O
: O
CONCLUSION O
We O
have O
presented O
a O
novel O
deep Method
learning Method
approach Method
for O
single Task
image Task
super Task
- Task
resolution Task
( O
SR Task
) O
. O
We O
show O
that O
conventional O
sparse O
- O
coding O
- O
based O
SR Task
methods O
can O
be O
reformulated O
into O
a O
deep Method
convolutional Method
neural Method
network Method
. O
The O
proposed O
approach O
, O
SRCNN Method
, O
learns O
an O
end Task
- Task
to Task
- Task
end Task
mapping Task
between O
low O
- O
and O
high O
- O
resolution O
images O
, O
with O
little O
extra O
pre O
/ O
post O
- O
processing O
beyond O
the O
optimization Task
. O
With O
a O
lightweight Method
structure Method
, O
the O
SRCNN Method
has O
achieved O
superior O
performance O
than O
the O
state O
- O
of O
- O
the O
- O
art O
methods O
. O
We O
conjecture O
that O
additional O
performance O
can O
be O
further O
gained O
by O
exploring O
more O
filters O
and O
different O
training Method
strategies Method
. O
Besides O
, O
the O
proposed O
structure O
, O
with O
its O
advantages O
of O
simplicity O
and O
robustness Metric
, O
could O
be O
applied O
to O
other O
low Task
- Task
level Task
vision Task
problems Task
, O
such O
as O
image Task
deblurring Task
or O
simultaneous O
SR Task
+ O
denoising O
. O
One O
could O
also O
investigate O
a O
network O
to O
cope O
with O
different O
upscaling O
factors O
. O
section O
: O
section O
: O
section O
: O
