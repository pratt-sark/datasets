ReasoNet Method
: O
Learning O
to O
Stop Task
Reading Task
in O
Machine Task
Comprehension Task
section O
: O
ABSTRACT O
Teaching O
a O
computer O
to O
read O
and O
answer O
general O
questions O
pertaining O
to O
a O
document O
is O
a O
challenging O
yet O
unsolved O
problem O
. O
In O
this O
paper O
, O
we O
describe O
a O
novel O
neural Method
network Method
architecture Method
called O
the O
Reasoning Method
Network Method
( O
ReasoNet Method
) O
for O
machine Task
comprehension Task
tasks Task
. O
ReasoNets Method
make O
use O
of O
multiple O
turns O
to O
e O
ectively O
exploit O
and O
then O
reason O
over O
the O
relation O
among O
queries O
, O
documents O
, O
and O
answers O
. O
Di O
erent O
from O
previous O
approaches O
using O
a O
xed O
number O
of O
turns O
during O
inference Task
, O
ReasoNets Method
introduce O
a O
termination O
state O
to O
relax O
this O
constraint O
on O
the O
reasoning O
depth O
. O
With O
the O
use O
of O
reinforcement Task
learning Task
, O
ReasoNets Method
can O
dynamically O
determine O
whether O
to O
continue O
the O
comprehension Task
process Task
after O
digesting O
intermediate O
results O
, O
or O
to O
terminate O
reading O
when O
it O
concludes O
that O
existing O
information O
is O
adequate O
to O
produce O
an O
answer O
. O
ReasoNets Method
achieve O
superior O
performance O
in O
machine O
comprehension O
datasets O
, O
including O
unstructured Material
CNN Material
and Material
Daily Material
Mail Material
datasets Material
, O
the O
Stanford Material
SQuAD Material
dataset Material
, O
and O
a O
structured Material
Graph Material
Reachability Material
dataset Material
. O
section O
: O
INTRODUCTION O
Teaching Task
machines Task
to O
read O
, O
process O
, O
and O
comprehend O
natural O
language O
documents O
is O
a O
coveted O
goal O
for O
arti Task
cial Task
intelligence Task
[ O
reference O
][ O
reference O
][ O
reference O
] O
. O
Genuine O
reading Task
comprehension Task
is O
extremely O
challenging O
, O
since O
e O
ective Task
comprehension Task
involves O
thorough O
understanding Task
of Task
documents Task
and O
sophisticated O
inference Task
. O
Toward O
solving O
this O
machine Task
reading Task
comprehension Task
problem Task
, O
in O
recent O
years O
, O
several O
works O
have O
collected O
various O
datasets O
, O
in O
the O
form O
of O
question O
, O
passage O
, O
and O
answer O
, O
to O
test O
machine O
on O
answering O
a O
question O
based O
on O
the O
provided O
passage O
[ O
reference O
][ O
reference O
][ O
reference O
][ O
reference O
] O
. O
Some O
large O
- O
scale O
cloze O
- O
style O
datasets O
[ O
reference O
][ O
reference O
] O
have O
gained O
signi O
ca O
nt O
attention O
along O
with O
powerful O
deep Method
learning Method
models Method
. O
Recent O
approaches O
on O
cloze O
- O
style O
datasets O
can O
be O
separated O
into O
two O
categories O
: O
single O
- O
turn O
and O
multi Task
- Task
turn Task
reasoning Task
. O
Single Method
turn Method
reasoning Method
models Method
utilize O
attention Method
mechanisms Method
[ O
reference O
] O
to O
emphasize O
speci O
c O
parts O
of O
the O
document O
which O
are O
relevant O
to O
the O
query O
. O
Permission O
to O
make O
digital O
or O
hard O
copies O
of O
all O
or O
part O
of O
this O
work O
for O
personal O
or O
classroom O
use O
is O
granted O
without O
fee O
provided O
that O
copies O
are O
not O
made O
or O
distributed O
for O
pro O
t O
or O
commercial O
advantage O
and O
that O
copies O
bear O
this O
notice O
and O
the O
full O
citation O
on O
the O
rst O
page O
. O
Copyrights O
for O
components O
of O
this O
work O
owned O
by O
others O
than O
ACM O
must O
be O
honored O
. O
Abstracting O
with O
credit O
is O
permitted O
. O
To O
copy O
otherwise O
, O
or O
republish O
, O
to O
post O
on O
servers O
or O
to O
redistribute O
to O
lists O
, O
requires O
prior O
speci O
c O
permission O
and O
/ O
or O
a O
fee O
. O
Request O
permissions O
from O
permissions@acm.org O
. O
These O
attention Method
models Method
subsequently O
calculate O
the O
relevance O
between O
a O
query O
and O
the O
corresponding O
weighted O
representations O
of O
document O
subunits O
( O
e.g. O
sentences O
or O
words O
) O
to O
score O
target O
candidates O
[ O
reference O
][ O
reference O
][ O
reference O
] O
. O
However O
, O
considering O
the O
sophistication O
of O
the O
problem O
, O
after O
a O
single Task
- Task
turn Task
comprehension Task
, O
readers O
often O
revisit O
some O
speci O
c O
passage O
or O
the O
question O
to O
grasp O
a O
better O
understanding O
of O
the O
problem O
. O
With O
this O
motivation O
, O
recent O
advances O
in O
reading Task
comprehension Task
have O
made O
use O
of O
multiple O
turns O
to O
infer O
the O
relation O
between O
query O
, O
document O
and O
answer O
[ O
reference O
][ O
reference O
][ O
reference O
][ O
reference O
] O
. O
By O
repeatedly O
processing O
the O
document O
and O
the O
question O
after O
digesting O
intermediate O
information O
, O
multi Method
- Method
turn Method
reasoning Method
can O
generally O
produce O
a O
better O
answer O
and O
these O
existing O
works O
have O
demonstrated O
its O
superior O
performance O
consistently O
. O
Existing O
multi Method
- Method
turn Method
models Method
have O
a O
pre O
- O
de O
ned O
number O
of O
hops O
or O
iterations O
in O
their O
inference Task
without O
regard O
to O
the O
complexity O
of O
each O
individual O
query O
or O
document O
. O
However O
, O
when O
human O
read O
a O
document O
with O
a O
question O
in O
mind O
, O
we O
often O
decide O
whether O
we O
want O
to O
stop O
reading O
if O
we O
believe O
the O
observed O
information O
is O
adequate O
already O
to O
answer O
the O
question O
, O
or O
continue O
reading O
after O
digesting O
intermediate O
information O
until O
we O
can O
answer O
the O
question O
with O
con O
dence O
. O
This O
behavior O
generally O
varies O
from O
document O
to O
document O
or O
question O
to O
question O
because O
it O
is O
related O
to O
the O
sophistication O
of O
the O
document O
or O
the O
di O
culty O
of O
the O
question O
. O
Meanwhile O
, O
the O
analysis O
in O
[ O
reference O
] O
also O
illustrates O
the O
huge O
variations O
in O
the O
di O
culty O
level O
with O
respect O
to O
questions O
in O
the O
CNN Material
/ Material
Daily Material
Mail Material
datasets Material
[ O
reference O
] O
. O
For O
a O
signi O
ca O
nt O
part O
of O
the O
datasets O
, O
this O
analysis O
shows O
that O
the O
problem O
can O
not O
be O
solved O
without O
appropriate O
reasoning O
on O
both O
its O
query O
and O
document O
. O
With O
this O
motivation O
, O
we O
propose O
a O
novel O
neural Method
network Method
architecture Method
called O
Reasoning Method
Network Method
( O
ReasoNet Method
) O
. O
which O
tries O
to O
mimic O
the O
inference Task
process Task
of O
human Task
readers Task
. O
With O
a O
question O
in O
mind O
, O
ReasoNets O
read O
a O
document O
repeatedly O
, O
each O
time O
focusing O
on O
di O
erent O
parts O
of O
the O
document O
until O
a O
satisfying O
answer O
is O
found O
or O
formed O
. O
This O
reminds O
us O
of O
a O
Chinese O
proverb O
: O
" O
The O
meaning O
of O
a O
book O
will O
become O
clear O
if O
you O
read O
it O
hundreds O
of O
times O
. O
" O
. O
Moreover O
, O
unlike O
previous O
approaches O
using O
xed O
number O
of O
hops O
or O
iterations O
, O
ReasoNets Method
introduce O
a O
termination O
state O
in O
the O
inference Task
. O
This O
state O
can O
decide O
whether O
to O
continue O
the O
inference O
to O
the O
next O
turn O
after O
digesting O
intermediate O
information O
, O
or O
to O
terminate O
the O
whole O
inference O
when O
it O
concludes O
that O
existing O
information O
is O
sufcient O
to O
yield O
an O
answer O
. O
The O
number O
of O
turns O
in O
the O
inference Task
is O
dynamically O
modeled O
by O
both O
the O
document O
and O
the O
query O
, O
and O
can O
be O
learned O
automatically O
according O
to O
the O
di O
culty O
of O
the O
problem O
. O
One O
of O
the O
signi O
ca O
nt O
challenges O
ReasoNets O
face O
is O
how O
to O
design O
an O
e O
cient O
training Method
method Method
, O
since O
the O
termination O
state O
is O
discrete O
and O
not O
connected O
to O
the O
nal O
output O
. O
This O
prohibits O
canonical Method
back Method
- Method
propagation Method
method Method
being O
directly O
applied O
to O
train O
ReasoNets Method
. O
Motivated O
by O
[ O
reference O
][ O
reference O
] O
, O
we O
tackle O
this O
challenge O
by O
proposing O
a O
reinforcement Task
learning Task
approach O
, O
which O
utilizes O
an O
instance Method
- Method
dependent Method
reward Method
baseline Method
, O
to O
successfully O
train O
ReasoNets Method
. O
Finally O
, O
by O
accounting O
for O
a O
dynamic O
termination O
state O
during O
inference Task
and O
applying O
proposed O
deep O
reinforcement Task
learning Task
optimization O
method O
, O
ReasoNets Method
achieve O
the O
state O
- O
of O
- O
the O
- O
art O
results O
in O
machine Material
comprehension Material
datasets Material
, O
including O
unstructured Material
CNN Material
and Material
Daily Material
Mail Material
datasets Material
, O
and O
the O
proposed O
structured Material
Graph Material
Reachability Material
dataset Material
, O
when O
the O
paper O
is O
rst O
publicly O
available O
on O
arXiv O
. O
[ O
reference O
] O
At O
the O
time O
of O
the O
paper O
submission O
, O
we O
apply O
ReasoNet Method
to O
the O
competitive O
Stanford Material
Question Material
Answering Material
Dataset Material
( O
SQuAD Material
) O
, O
ReasoNets Method
outperform O
all O
existing O
published O
approaches O
and O
rank O
at O
second O
place O
on O
the O
test O
set O
leaderboard O
. O
[ O
reference O
] O
This O
paper O
is O
organized O
as O
follows O
. O
In O
Section O
2 O
, O
we O
review O
and O
compare O
recent O
work O
on O
machine Task
reading Task
comprehension Task
tasks Task
. O
In O
Section O
3 O
, O
we O
introduce O
our O
proposed O
ReasoNet Method
model O
architecture O
and O
training O
objectives O
. O
Section O
4 O
presents O
the O
experimental O
setting O
and O
results O
on O
unstructured Task
and Task
structured Task
machine Task
reading Task
comprehension Task
tasks Task
. O
section O
: O
RELATED O
WORK O
Recently O
, O
with O
large O
- O
scale O
datasets O
available O
and O
the O
impressive O
advance O
of O
various O
statistical Method
models Method
, O
machine Task
reading Task
comprehension Task
tasks Task
have O
attracted O
much O
attention O
. O
Here O
we O
mainly O
focus O
on O
the O
related O
work O
in O
cloze O
- O
style O
datasets O
[ O
reference O
][ O
reference O
] O
. O
Based O
on O
how O
they O
perform O
the O
inference Task
, O
we O
can O
classify O
their O
models O
into O
two O
categories O
: O
single O
- O
turn O
and O
multi Task
- Task
turn Task
reasoning Task
. O
Single Method
- Method
turn Method
reasoning Method
: O
Single Method
turn Method
reasoning Method
models Method
utilize O
an O
attention Method
mechanism Method
to O
emphasize O
some O
sections O
of O
a O
document O
which O
are O
relevant O
to O
a O
query O
. O
This O
can O
be O
thought O
of O
as O
treating O
some O
parts O
unimportant O
while O
focusing O
on O
other O
important O
ones O
to O
nd O
the O
most O
probable O
answer O
. O
Hermann O
et O
al O
. O
[ O
reference O
] O
propose O
the O
attentive Method
reader Method
and O
the O
impatient Method
reader Method
models Method
using O
neural Method
networks Method
with O
an O
attention O
over O
passages O
to O
predict O
candidates O
. O
Hill O
et O
al O
. O
[ O
reference O
] O
use O
attention Method
over O
window Method
- Method
based Method
memory Method
, O
which O
encodes O
a O
window O
of O
words O
around O
entity O
candidates O
, O
by O
leveraging O
an O
endto Method
- Method
end Method
memory Method
network Method
[ O
reference O
] O
. O
Meanwhile O
, O
given O
the O
same O
entity O
candidate O
can O
appear O
multiple O
times O
in O
a O
passage O
, O
Kadlec O
et O
al O
. O
[ O
reference O
] O
propose O
the O
attention Method
- Method
sum Method
reader Method
to O
sum O
up O
all O
the O
attention O
scores O
for O
the O
same O
entity O
. O
This O
score O
captures O
the O
relevance O
between O
a O
query O
and O
a O
candidate O
. O
Chen O
et O
al O
. O
[ O
reference O
] O
propose O
using O
a O
bilinear Method
term Method
similarity Method
function Method
to O
calculate O
attention O
scores O
with O
pretrained O
word O
embeddings O
. O
Trischler O
et O
al O
. O
[ O
reference O
] O
propose O
the O
EpiReader Method
which O
uses O
two O
neural Method
network Method
structures Method
: O
one O
extracts O
candidates O
using O
the O
attention Method
- Method
sum Method
reader Method
; O
the O
other O
reranks O
candidates O
based O
on O
a O
bilinear Metric
term Metric
similarity Metric
score Metric
calculated O
from O
query Method
and Method
passage Method
representations Method
. O
Multi Task
- Task
turn Task
reasoning Task
: O
For O
complex O
passages O
and O
complex O
queries O
, O
human O
readers O
often O
revisit O
the O
given O
document O
in O
order O
to O
perform O
deeper Task
inference Task
after O
reading O
a O
document O
. O
Several O
recent O
studies O
try O
to O
simulate O
this O
revisit O
by O
combining O
the O
information O
in O
the O
query O
with O
the O
new O
information O
digested O
from O
previous O
iterations O
[ O
reference O
][ O
reference O
][ O
reference O
][ O
reference O
][ O
reference O
] O
. O
Hill O
et O
al O
. O
[ O
reference O
] O
use O
multiple Method
hops Method
memory Method
network Method
to O
augment O
the O
query O
with O
new O
information O
from O
the O
previous O
hop O
. O
Gated Method
Attention Method
reader Method
[ O
reference O
] O
is O
an O
extension O
of O
the O
attention Method
- Method
sum Method
reader Method
with O
multiple O
iterations O
by O
pushing O
the O
query Method
encoding Method
into O
an O
attention Method
- Method
based Method
gate Method
in O
each O
iteration O
. O
Iterative Method
Alternative Method
( O
IA Method
) O
reader O
[ O
reference O
] O
produces O
a O
new O
query O
glimpse O
and O
document O
glimpse O
in O
each O
iteration O
and O
utilizes O
them O
alternatively O
in O
the O
next O
iteration O
. O
Cui O
et O
al O
. O
[ O
reference O
] O
further O
propose O
to O
extend O
the O
query O
- O
speci O
c O
attention O
to O
both O
query Task
- Task
to Task
- Task
document Task
attention Task
and O
document Task
- Task
to Task
- Task
query Task
attention Task
, O
which O
is O
built O
from O
the O
intermediate O
results O
in O
the O
query O
- O
speci O
c O
attention O
. O
By O
reading O
documents O
and O
enriching O
the O
query O
in O
an O
iterative O
fashion O
, O
multi Method
- Method
turn Method
reasoning Method
has O
demonstrated O
their O
superior O
performance O
consistently O
. O
Our O
proposed O
approach O
explores O
the O
idea O
of O
using O
both O
attentionsum O
to O
aggregate O
candidate O
attention O
scores O
and O
multiple O
turns O
to O
attain O
a O
better O
reasoning O
capability O
. O
Unlike O
previous O
approaches O
using O
a O
xed O
number O
of O
hops O
or O
iterations O
, O
motivated O
by O
[ O
reference O
][ O
reference O
] O
, O
we O
propose O
a O
termination Method
module Method
in O
the O
inference Task
. O
The O
termination Method
module Method
can O
decide O
whether O
to O
continue O
to O
infer O
the O
next O
turn O
after O
digesting O
intermediate O
information O
, O
or O
to O
terminate O
the O
whole O
inference Task
process Task
when O
it O
concludes O
existing O
information O
is O
su O
cient O
to O
yield O
an O
answer O
. O
The O
number O
of O
turns O
in O
the O
inference Task
is O
dynamically O
modeled O
by O
both O
a O
document O
and O
a O
query O
, O
and O
is O
generally O
related O
to O
the O
complexity O
of O
the O
document O
and O
the O
query O
. O
section O
: O
REASONING Task
NETWORKS Task
ReasoNets Method
are O
devised O
to O
mimic O
the O
inference Task
process Task
of Task
human Task
readers Task
. O
ReasoNets O
read O
a O
document O
repeatedly O
with O
attention O
on O
di O
erent O
parts O
each O
time O
until O
a O
satisfying O
answer O
is O
found O
. O
As O
shown O
in O
Figure O
1 O
, O
a O
ReasoNet Method
is O
composed O
of O
the O
following O
components O
: O
Memory Method
: O
The O
external O
memory O
is O
denoted O
as O
M. O
It O
is O
a O
list O
of O
word O
vectors O
, O
M O
= O
{ O
m O
i O
} O
i=1 O
.. O
D O
, O
where O
m O
i O
is O
a O
xed O
dimensional O
vector O
. O
For O
example O
, O
in O
the O
Graph Task
Reachability Task
, O
m O
i O
is O
the O
vector Method
representation Method
of O
each O
word O
in O
the O
graph O
description O
encoded O
by O
a O
bidirectional O
- O
RNN Method
. O
Please O
refer O
to O
Section O
4 O
for O
the O
detailed O
setup O
in O
each O
experiment O
. O
Attention Method
: O
The O
attention O
vector O
x O
t O
is O
generated O
based O
on O
the O
current O
internal O
state O
s O
t O
and O
the O
external O
memory O
M O
: O
x O
t O
= O
f O
at O
t O
( O
s O
t O
, O
M O
; O
θ O
x O
) O
. O
Please O
refer O
to O
Section O
4 O
for O
the O
detailed O
setup O
in O
each O
experiment O
. O
Internal O
State O
: O
The O
internal O
state O
is O
denoted O
as O
s O
which O
is O
a O
vector Method
representation Method
of Method
the Method
question Method
state Method
. O
Typically O
, O
the O
initial O
state O
s O
1 O
is O
the O
last Method
- Method
word Method
vector Method
representation Method
of O
query O
by O
an O
RNN Method
. O
The O
t O
- O
th O
time O
step O
of O
the O
internal O
state O
is O
represented O
by O
s O
t O
. O
The O
sequence O
of O
internal O
states O
are O
modeled O
by O
an O
RNN Method
: O
s O
t O
+ O
1 O
= O
RNN Method
( O
s O
t O
, O
x O
t O
; O
θ O
s O
) O
, O
where O
x O
t O
is O
the O
attention O
vector O
mentioned O
above O
. O
Termination O
Gate O
: O
The O
termination O
gate O
generates O
a O
random O
variable O
according O
to O
the O
current O
internal O
state O
; O
t O
t O
∼ O
p O
( O
·| O
f O
t O
( O
s O
t O
; O
θ O
t O
) O
) O
) O
. O
t O
t O
is O
a O
binary O
random O
variable O
. O
If O
t O
t O
is O
true O
, O
the O
ReasoNet Method
stops O
, O
and O
the O
answer Method
module Method
executes O
at O
time O
step O
t O
; O
otherwise O
the O
ReasoNet Method
generates O
an O
attention O
vector O
x O
t O
+ O
1 O
, O
and O
feeds O
the O
vector O
into O
the O
state Method
network Method
to O
update O
the O
next O
internal O
state O
s O
t O
+ O
1 O
. O
Answer O
: O
The O
action O
of O
answer Method
module Method
is O
triggered O
when O
the O
termination O
gate O
variable O
is O
true O
: O
a O
t O
∼ O
p O
( O
·| O
f O
a O
( O
s O
t O
; O
θ O
a O
) O
) O
. O
In O
Algorithm O
1 O
, O
we O
describe O
the O
stochastic Method
inference Method
process Method
of O
a O
ReasoNet Method
. O
The O
process O
can O
be O
considered O
as O
solving O
a O
Partially Task
Observable Task
Markov Task
Decision Task
Process Task
( O
POMDP Task
) O
[ O
reference O
] O
in O
the O
reinforcement Task
learning Task
( O
RL Task
) O
literature O
. O
The O
state O
sequence O
s O
1:T O
is O
hidden O
Step O
t O
= O
1 O
; O
Maximum O
Step O
T O
max O
Output O
: O
Termination O
Step O
T O
, O
Answer O
a O
T O
1 O
Sample O
t O
t O
from O
the O
distribution O
p O
( O
·| O
f O
t O
( O
s O
t O
; O
θ O
t O
) O
) O
; O
2 O
if O
t O
t O
is O
false O
, O
go O
to O
Step O
3 O
; O
otherwise O
Step O
6 O
; O
3 O
Generate O
attention O
vector O
x O
t O
= O
f O
at O
t O
( O
s O
t O
, O
M O
; O
θ O
x O
) O
; O
4 O
Update O
internal O
state O
s O
t O
+ O
1 O
= O
RNN Method
( O
s O
t O
, O
x O
t O
; O
θ O
s O
) O
; O
5 O
Set O
t O
= O
t O
+ O
1 O
; O
if O
t O
< O
T O
max O
go O
to O
Step O
1 O
; O
otherwise O
Step O
6 O
; O
6 O
Generate O
answer O
a O
t O
∼ O
p O
( O
·| O
f O
a O
( O
s O
t O
; O
θ O
a O
) O
) O
; O
7 O
Return O
T O
= O
t O
and O
a O
T O
= O
a O
t O
; O
and O
dynamic O
, O
controlled O
by O
an O
RNN Method
sequence O
model O
. O
The O
ReasoNet Method
performs O
an O
answer O
action O
a O
T O
at O
the O
T O
- O
th O
step O
, O
which O
implies O
that O
the O
termination O
gate O
variables O
t O
1:T O
= O
( O
t O
1 O
= O
0 O
, O
t O
2 O
= O
0 O
, O
... O
, O
t O
T O
−1 O
= O
0 O
, O
t O
T O
= O
1 O
) O
. O
The O
ReasoNet Method
learns O
a O
stochastic Method
policy Method
π Method
( O
( O
t O
t O
, O
a O
t O
) O
|s O
t O
; O
θ O
) O
with O
parameters O
θ O
to O
get O
a O
distribution O
of O
termination O
actions O
, O
to O
continue O
reading O
or O
to O
stop O
, O
and O
of O
answer O
actions O
if O
the O
model O
decides O
to O
stop O
at O
the O
current O
step O
. O
The O
termination O
step O
T O
varies O
from O
instance O
to O
instance O
. O
The O
learnable O
parameters O
θ O
of O
the O
ReasoNet Method
are O
the O
embedding O
matrices O
θ O
W O
, O
attention Method
network Method
θ O
x O
, O
the O
state O
RNN Method
network O
θ O
s O
, O
the O
answer Method
action Method
network Method
θ O
a O
, O
and O
the O
termination Method
gate Method
network Method
θ O
t O
. O
The O
parameters O
θ O
= O
{ O
θ O
W O
, O
θ O
x O
, O
θ O
s O
, O
θ O
a O
, O
θ O
t O
} O
are O
trained O
by O
maximizing O
the O
total Metric
expect Metric
reward Metric
. O
The O
expected Metric
reward Metric
for O
an O
instance O
is O
de O
ned O
as O
: O
The O
reward O
can O
only O
be O
received O
at O
the O
nal O
termination O
step O
when O
an O
answer O
action O
a O
T O
is O
performed O
. O
We O
de O
ne O
r O
T O
= O
1 O
if O
t O
T O
= O
1 O
and O
the O
answer O
is O
correct O
, O
and O
r O
T O
= O
0 O
otherwise O
. O
The O
rewards O
on O
intermediate O
steps O
are O
zeros O
, O
{ O
r O
t O
= O
0 O
} O
t O
= O
1 O
... O
T O
−1 O
. O
can O
be O
maximized O
by O
directly O
applying O
gradient Method
based Method
optimization Method
methods Method
. O
The O
gradient O
of O
is O
given O
by O
: O
Motivated O
by O
the O
REINFORCE Method
algorithm Method
[ O
reference O
] O
, O
we O
compute O
∇ O
θ O
( O
θ O
) O
: O
where O
A O
† O
is O
all O
the O
possible O
episodes O
, O
T O
, O
t O
1:T O
, O
a O
T O
and O
r O
T O
are O
the O
termination O
step O
, O
termination O
action O
, O
answer O
action O
, O
and O
reward O
, O
respectively O
, O
for O
the O
( O
t O
1:T O
, O
a O
T O
) O
episode O
. O
b O
T O
is O
called O
the O
reward O
baseline O
in O
the O
RL Task
literature O
to O
lower O
the O
variance O
[ O
reference O
] O
. O
It O
is O
common O
to O
, O
and O
can O
be O
updated O
via O
an O
online Method
moving Method
average Method
approach Method
: O
b O
T O
= O
λb O
T O
+ O
( O
1 O
− O
λ O
) O
r O
T O
. O
However O
, O
we O
empirically O
nd O
that O
the O
above O
approach O
leads O
to O
slow O
convergence O
in O
training Task
ReasoNets Task
. O
Intuitively O
, O
the O
average O
baselines O
{ O
b O
T O
; O
T O
= O
1 O
.. O
T O
max O
} O
are O
global O
variables O
independent O
of O
instances O
. O
It O
is O
hard O
for O
these O
baselines O
to O
capture O
the O
dynamic O
termination O
behavior O
of O
ReasoNets O
. O
Since O
ReasoNets O
may O
stop O
at O
di O
erent O
time O
steps O
for O
di O
erent O
instances O
, O
the O
adoption O
of O
a O
global O
variable O
without O
considering O
the O
dynamic O
variance O
in O
each O
instance O
is O
inappropriate O
. O
To O
resolve O
this O
weakness O
in O
traditional O
methods O
and O
account O
for O
the O
dynamic O
characteristic O
of O
ReasoNets O
, O
we O
propose O
an O
instance Method
- Method
dependent Method
baseline Method
method Method
to O
calculate O
∇ O
θ O
( O
θ O
) O
, O
as O
illustrated O
in O
Section O
3.1 O
. O
Empirical O
results O
show O
that O
the O
proposed O
reward Method
schema Method
achieves O
better O
results O
compared O
to O
baseline O
approaches O
. O
section O
: O
Training O
Details O
In O
the O
machine Task
reading Task
comprehension Task
tasks Task
, O
a O
training O
dataset O
is O
a O
collection O
of O
triplets O
of O
query O
q O
, O
passage O
p O
, O
and O
answer O
a. O
Say O
q O
n O
, O
p O
n O
, O
a O
n O
is O
the O
n O
- O
th O
training O
instance O
. O
The O
rst O
step O
is O
to O
extract O
memory O
M O
from O
p O
n O
by O
mapping O
each O
symbolic O
in O
the O
passage O
to O
a O
contextual Method
representation Method
given O
by O
the O
concatenation O
of O
forward O
and O
backward O
RNN Method
hidden O
states O
, O
i.e. O
, O
, O
and O
extract O
initial O
state O
s O
1 O
from O
q O
n O
by O
assigning O
. O
Given O
M O
and O
s O
1 O
for O
the O
n O
- O
th O
training O
instance O
, O
a O
ReasoNet Method
executes O
|A O
† O
| O
episodes O
, O
where O
all O
possible O
episodes O
A O
† O
can O
be O
enumerated O
by O
setting O
a O
maximum O
step O
. O
Each O
episode O
generates O
actions O
and O
a O
reward O
from O
the O
last O
step O
: O
( O
t O
1:T O
, O
a O
T O
) O
, O
r O
T O
( O
t O
1:T O
, O
a O
T O
) O
∈A O
† O
. O
Therefore O
, O
the O
gradient O
of O
can O
be O
rewritten O
as O
: O
where O
the O
baseline O
b O
= O
( O
t O
1:T O
, O
a O
T O
) O
∈A O
† O
π O
( O
t O
1:T O
, O
a O
T O
; O
θ O
) O
r O
T O
is O
the O
average O
reward O
on O
the O
|A O
† O
| O
episodes O
for O
the O
n O
- O
th O
training O
instance O
. O
It O
allows O
di O
erent O
baselines O
for O
di O
erent O
training O
instances O
. O
This O
can O
be O
benecial O
since O
the O
complexity O
of O
training O
instances O
varies O
signi O
cantly O
. O
In O
experiments O
, O
we O
empirically O
nd O
using O
( O
r O
T O
b O
− O
1 O
) O
in O
replace O
of O
( O
r O
T O
− O
b O
) O
can O
lead O
to O
a O
faster O
convergence Metric
. O
Therefore O
, O
we O
adopt O
this O
approach O
to O
train O
ReasoNets Task
in O
the O
experiments O
. O
section O
: O
EXPERIMENTS O
In O
this O
section O
, O
we O
evaluate O
the O
performance O
of O
ReasoNets Method
in O
machine O
comprehension O
datasets O
, O
including O
unstructured Material
CNN Material
and Material
Daily Material
Mail Material
datasets Material
, O
the O
Stanford Material
SQuAD Material
dataset Material
, O
and O
a O
structured Material
Graph Material
Reachability Material
dataset Material
. O
section O
: O
CNN Material
and Material
Daily Material
Mail Material
Datasets Material
We O
examine O
the O
performance O
of O
ReasoNets Method
on O
CNN Material
and Material
Daily Material
Mail Material
datasets Material
. O
[ O
reference O
] O
The O
detailed O
settings O
of O
the O
ReasoNet Method
model O
are O
as O
follows O
. O
Vocab Metric
Size Metric
: O
For O
training O
our O
ReasoNet Method
, O
we O
keep O
the O
most O
frequent O
|V O
| O
= O
101k O
words O
( O
not O
including O
584 O
entities O
and O
1 O
placeholder O
marker O
) O
in O
the O
CNN Material
dataset Material
, O
and O
|V O
| O
= O
151k O
words O
( O
not O
including O
530 O
entities O
and O
1 O
placeholder O
marker O
) O
in O
the O
Daily Material
Mail Material
dataset Material
. O
Embedding Method
Layer Method
: O
We O
choose O
300 O
- O
dimensional O
word O
embeddings O
, O
and O
use O
the O
300 Method
- Method
dimensional Method
pretrained Method
Glove Method
word Method
embeddings Method
[ O
reference O
] O
for O
initialization Task
. O
We O
also O
apply O
dropout Method
with O
probability O
0.2 O
to O
the O
embedding Method
layer Method
. O
Bi Method
- Method
GRU Method
Encoder Method
: O
We O
apply O
bidirectional Method
GRU Method
for O
encoding O
query Task
and Task
passage Task
into O
vector Method
representations Method
. O
We O
set O
the O
number O
of O
hidden O
units O
to O
be O
256 O
and O
384 O
for O
the O
CNN Material
and Material
Daily Material
Mail Material
datasets Material
, O
respectively O
. O
The O
recurrent O
weights O
of O
GRUs Method
are O
initialized O
with O
random Method
orthogonal Method
matrices Method
. O
The O
other O
weights O
in O
GRU O
cell O
are O
initialized O
from O
a O
uniform O
distribution O
between O
−0.01 O
and O
0.01 O
. O
We O
use O
a O
shared O
GRU Method
model Method
for O
both O
query Task
and Task
passage Task
. O
Memory O
and O
Attention Task
: O
The O
memory O
of O
the O
ReasoNet Method
on O
CNN Material
and Material
Daily Material
Mail Material
dataset Material
is O
composed O
of O
query O
memory O
and O
passage O
memory O
. O
M O
= O
( O
M O
quer O
, O
M O
doc O
) O
, O
where O
M O
quer O
and O
M O
doc O
are O
extracted O
from O
query Method
bidirectional Method
- Method
GRU Method
encoder Method
and O
passage Method
bidirectional Method
- Method
GRU Method
encoder Method
respectively O
. O
We O
choose O
projected Method
cosine Method
similarity Method
function Method
as O
the O
attention Method
module Method
. O
The O
attention O
score O
a O
doc O
t O
, O
i O
on O
memory O
m O
doc O
i O
given O
the O
state O
s O
t O
is O
computed O
as O
follows O
: O
where O
W O
t O
and O
b O
t O
are O
the O
weight O
matrix O
and O
bias O
vector O
, O
respectively O
. O
Answer Method
Module Method
: O
We O
apply O
a O
linear Method
projection Method
from O
GRU O
outputs O
and O
make O
predictions O
on O
the O
entity O
candidates O
. O
Following O
the O
[ O
reference O
] O
The O
CNN Material
and Material
Daily Material
Mail Material
datasets Material
are O
available O
at O
https: O
// O
github.com O
/ O
deepmind O
/ O
rcdata O
settings O
in O
AS O
Reader O
[ O
reference O
] O
, O
we O
sum O
up O
scores O
from O
the O
same O
candidate O
and O
make O
a O
prediction O
. O
Thus O
, O
AS O
Reader O
can O
be O
viewed O
as O
a O
special O
case O
of O
ReasoNets O
with O
T O
max O
= O
1 O
. O
[ O
reference O
] O
Other O
Details O
: O
The O
maximum O
reasoning O
step O
, O
T O
max O
is O
set O
to O
5 O
in O
experiments O
on O
both O
CNN Material
and Material
Daily Material
Mail Material
datasets Material
. O
We O
use O
ADAM Method
optimizer Method
[ O
reference O
] O
for O
parameter Task
optimization Task
with O
an O
initial O
learning Metric
rate Metric
of O
0.0005 O
, O
β O
1 O
= O
0.9 O
and O
β O
2 O
= O
0.999 O
; O
The O
absolute O
value O
of O
gradient O
on O
each O
parameter O
is O
clipped O
within O
0.001 O
. O
The O
batch O
size O
is O
64 O
for O
both O
CNN Material
and Material
Daily Material
Mail Material
datasets Material
. O
For O
each O
batch O
of O
the O
CNN Material
and Material
Daily Material
Mail Material
datasets Material
, O
we O
randomly O
reshu O
e O
the O
assignment O
of O
named O
entities O
[ O
reference O
] O
. O
This O
forces O
the O
model O
to O
treat O
the O
named O
entities O
as O
semantically O
meaningless O
labels O
. O
In O
the O
prediction Task
of Task
test Task
cases Task
, O
we O
randomly O
reshu O
e O
named O
entities O
up O
to O
4 O
times O
, O
and O
report O
the O
averaged O
answer O
. O
Models O
are O
trained O
on O
GTX Method
TitanX O
12 O
GB O
. O
It O
takes O
7 O
hours O
per O
epoch O
to O
train O
on O
the O
Daily Material
Mail Material
dataset Material
and O
3 O
hours O
per O
epoch O
to O
train O
on O
the O
CNN Material
dataset Material
. O
The O
models O
are O
usually O
converged O
within O
6 O
epochs O
on O
both O
CNN Material
and Material
Daily Material
Mail Material
datasets Material
. O
[ O
reference O
] O
When O
ReasoNet Method
is O
set O
with O
T O
max O
= O
1 O
in O
CNN Material
and O
Daily Material
Mail Material
, O
it O
directly O
applies O
s O
0 O
to O
make O
predictions O
on O
the O
entity O
candidates O
, O
without O
performing O
attention O
on O
the O
memory Method
module Method
. O
The O
prediction Method
module Method
in O
ReasoNets Method
is O
the O
same O
as O
in O
AS O
Reader O
. O
It O
sums O
up O
the O
scores O
from O
the O
same O
entity O
candidates O
, O
where O
the O
scores O
are O
calculated O
by O
the O
inner O
product O
between O
s O
t O
and O
m O
d O
oc O
e O
, O
where O
m O
d O
oc O
e O
is O
an O
embedding O
vector O
of O
one O
entity O
candidate O
in O
the O
passage O
. O
Query O
: O
passenger O
@placeholder O
, O
36 O
, O
died O
at O
the O
scene O
Passage O
: O
( O
@entity0 O
) O
what O
was O
supposed O
to O
be O
a O
fantasy O
sports O
car O
ride O
at O
@entity3 O
turned O
deadly O
when O
a O
@entity4 O
crashed O
into O
a O
guardrail O
. O
the O
crash O
took O
place O
sunday O
at O
the O
@entity8 O
, O
which O
bills O
itself O
as O
a O
chance O
to O
drive O
your O
dream O
car O
on O
a O
racetrack O
. O
the O
@entity4 O
's O
passenger O
, O
36 O
- O
year O
- O
old O
@entity14 O
of O
@entity15 O
, O
@entity16 O
, O
died O
at O
the O
scene O
, O
@entity13 O
said O
. O
the O
driver O
of O
the O
@entity4 O
, O
24 O
- O
year O
- O
old O
@entity18 O
of O
@entity19 O
, O
@entity16 O
, O
lost O
control O
of O
the O
vehicle O
, O
the O
@entity13 O
said O
. O
he O
was O
hospitalized O
with O
minor O
injuries O
. O
@entity24 O
, O
which O
operates O
the O
@entity8 O
at O
@entity3 O
, O
released O
a O
statement O
sunday O
night O
about O
the O
crash O
. O
" O
on O
behalf O
of O
everyone O
in O
the O
organization O
, O
it O
is O
with O
a O
very O
heavy O
heart O
that O
we O
extend O
our O
deepest O
sympathies O
to O
those O
involved O
in O
today O
's O
tragic O
accident O
in O
@entity36 O
, O
" O
the O
company O
said O
. O
@entity24 O
also O
operates O
the O
@entity3 O
-- O
a O
chance O
to O
drive O
or O
ride O
in O
@entity39 O
race O
cars O
named O
for O
the O
winningest O
driver O
in O
the O
sport O
's O
history O
. O
@entity0 O
's O
@entity43 O
and O
@entity44 O
contributed O
to O
this O
report O
. O
section O
: O
Answer O
: O
@entity14 O
Step Metric
Termination Metric
Probability Metric
Attention O
Sum O
1 O
0.0011 O
0.4916 O
2 O
0.5747 O
0.5486 O
3 O
0.9178 O
0.5577 O
Step O
3 O
Step O
1 O
Step O
2 O
Figure O
3 O
: O
Results O
of O
a O
test O
example O
69e1f777e41bf67d5a22b7c69ae76f0ae873cf43.story O
from O
the O
CNN Material
dataset Material
. O
The O
numbers O
next O
to O
the O
underline O
bars O
indicate O
the O
rank O
of O
the O
attention O
scores O
. O
The O
corresponding O
termination Metric
probability Metric
and O
the O
sum O
of O
attention O
scores O
for O
the O
answer O
entity O
are O
shown O
in O
the O
table O
on O
the O
right O
. O
Results O
: O
Table O
1 O
shows O
the O
performance O
of O
all O
the O
existing O
single Method
model Method
baselines Method
and O
our O
proposed O
ReasoNet Method
. O
Among O
all O
the O
baselines O
, O
AS O
Reader O
could O
be O
viewed O
as O
a O
special O
case O
of O
ReasoNet Method
with O
T O
max O
= O
1 O
. O
Comparing O
with O
the O
AS Method
Reader Method
, O
ReasoNet Method
shows O
the O
signi O
ca O
nt O
improvement O
by O
capturing O
multi Task
- Task
turn Task
reasoning Task
in O
the O
paragraph O
. O
Iterative Method
Attention Method
Reader Method
, O
EpiReader Method
and O
GA Method
Reader Method
are O
the O
three O
multi Method
- Method
turn Method
reasoning Method
models Method
with O
xed O
reasoning O
steps O
. O
ReasoNet Method
also O
outperforms O
all O
of O
them O
by O
integrating O
termination O
gate O
in O
the O
model O
which O
allows O
di O
erent O
reasoning O
steps O
for O
di O
erent O
test O
cases O
. O
AoA O
Reader Method
is O
another O
single Method
- Method
turn Method
reasoning Method
model Method
, O
it O
captures O
the O
word O
alignment O
signals O
between O
query O
and O
passage O
, O
and O
shows O
a O
big O
improvement O
over O
AS O
Reader Method
. O
ReasoNet Method
obtains O
comparable O
results O
with O
AoA Method
Reader Method
on O
CNN Material
test Material
set Material
. O
We O
expect O
that O
ReasoNet Method
could O
be O
improved O
further O
by O
incorporating O
the O
word O
alignment O
information O
in O
the O
memory Method
module Method
as O
suggested O
in O
AoA Method
Reader Method
. O
We O
show O
the O
distribution O
of O
termination O
step O
distribution O
of O
ReasoNets O
in O
the O
CNN Material
dataset Material
in O
Figure O
2 O
. O
The O
distributions O
spread O
out O
across O
di O
erent O
steps O
. O
Around O
70 O
% O
of O
the O
instances O
terminate O
in O
the O
last O
step O
. O
Figure O
3 O
gives O
a O
test O
example O
on O
CNN Material
dataset Material
, O
which O
illustrates O
the O
inference Task
process Task
of O
the O
ReasoNet Method
. O
The O
model O
initially O
focuses O
on O
wrong O
entities O
with O
low O
termination O
probability O
. O
In O
the O
second O
and O
third O
steps O
, O
the O
model O
focuses O
on O
the O
right O
clue O
with O
higher O
termination O
probability O
. O
Interestingly O
, O
we O
also O
nd O
its O
query O
attention O
focuses O
on O
the O
placeholder O
token O
throughout O
all O
the O
steps O
. O
section O
: O
SQuAD Material
Dataset O
In O
this O
section O
, O
we O
evaluate O
ReasoNet Method
model O
on O
the O
task O
of O
question Task
answering Task
using O
the O
SQuAD Material
dataset O
[ O
reference O
] O
. O
[ O
reference O
] O
SQuAD Material
is O
a O
machine O
comprehension O
dataset O
on O
536 O
Wikipedia Material
articles Material
, O
with O
more O
than O
100 O
, O
000 O
questions O
. O
Two O
metrics O
are O
used O
to O
evaluate O
models O
: O
Exact Metric
Match Metric
( O
EM Metric
) O
and O
a O
softer Metric
metric Metric
, O
F1 Metric
score Metric
, O
which O
measures O
the O
weighted O
average O
of O
the O
precision Metric
and O
recall Metric
rate O
at O
the O
character Metric
level Metric
. O
The O
dataset O
consists O
of O
90k O
/ O
10k O
training O
/ O
dev O
question O
- O
contextanswer O
tuples O
with O
a O
large O
hidden O
test O
set O
. O
The O
model O
architecture O
used O
for O
this O
task O
is O
as O
follows O
: O
[ O
reference O
] O
SQuAD Material
Competition O
Website O
is O
https: O
// O
rajpurkar.github.io O
/ O
SQuAD Material
- O
explorer O
/ O
Vocab O
Size O
: O
We O
use O
the O
python Method
NLTK Method
tokenizer Method
6 O
to O
preprocess O
passages O
and O
questions O
, O
and O
obtain O
about O
100 O
K O
words O
in O
the O
vocabulary O
. O
Embedding Method
Layer Method
: O
We O
use O
the O
100 O
- O
dimensional O
pretrained O
Glove O
vectors O
[ O
reference O
] O
as O
word O
embeddings O
. O
These O
Glove O
vectors O
are O
xed O
during O
the O
model Method
training Method
. O
To O
alleviate O
the O
out Task
- Task
of Task
- Task
vocabulary Task
issue Task
, O
we O
adopt O
one Method
layer Method
100 Method
- Method
dimensional Method
convolutional Method
neural Method
network Method
on O
character O
- O
level O
with O
a O
width O
size O
of O
5 O
and O
each O
character O
encoded O
as O
an O
8 O
- O
dimensional O
vector O
following O
the O
work O
[ O
reference O
] O
. O
The O
100 O
- O
dimensional O
Glove O
word O
vector O
and O
the O
100 O
- O
dimensional O
character O
- O
level O
vector O
are O
concatenated O
to O
obtain O
a O
200 O
- O
dimensional O
vector O
for O
each O
word O
. O
Bi Method
- Method
GRU Method
Encoder Method
: O
We O
apply O
bidirectional Method
GRU Method
for O
encoding O
query Task
and Task
passage Task
into O
vector Method
representations Method
. O
The O
number O
of O
hidden O
units O
is O
set O
to O
128 O
. O
Memory Method
: O
We O
use O
bidirectional Method
- Method
GRU Method
encoders Method
to O
extract O
the O
query Method
representation Method
M Method
quer Method
and O
the O
passage Method
representation Method
M Method
doc Method
, O
given O
a O
query O
and O
a O
passage O
. O
We O
compute O
the O
similarity O
matrix O
Table O
4 O
: O
Small O
and O
large O
random O
graph O
in O
the O
Graph Material
Reachability Material
dataset Material
. O
Note O
that O
" O
A O
→ O
B O
" O
represents O
an O
edge O
connected O
from O
A O
to O
B O
and O
the O
# O
symbol O
is O
used O
as O
a O
delimiter O
between O
di O
erent O
edges O
. O
Small Task
Graph Task
Large Task
Graph Task
No O
Yes O
between O
each O
word O
in O
the O
query O
and O
each O
word O
in O
the O
passage O
. O
The O
similarity O
matrix O
is O
denoted O
as O
S O
∈ O
R O
T× O
, O
where O
T O
and O
are O
the O
number O
of O
words O
in O
the O
passage O
and O
query O
, O
respectively O
, O
and O
] O
∈ O
R O
, O
where O
w O
S O
is O
a O
trainable O
weight O
vector O
, O
• O
denotes O
the O
elementwise Method
multiplication Method
, O
and O
[ O
; O
] O
is O
the O
vector O
concatenation O
across O
row O
. O
We O
then O
compute O
the O
context Task
- Task
to Task
- Task
query Task
attention Task
and O
query Task
- Task
to Task
- Task
context Task
attention Task
from O
the O
similarity O
matrix O
S O
by O
following O
recent O
co Method
- Method
attention Method
work O
[ O
reference O
] O
to O
obtain O
the O
query Method
- Method
aware Method
passage Method
representation Method
G. Method
We O
feed O
G O
to O
a O
128 Method
- Method
dimensional Method
bidirectional Method
GRU Method
to O
obtain O
the O
memory O
M O
= O
bidirectional Method
- Method
GRU Method
( Method
G Method
) O
, O
where O
M O
∈ O
R O
256×T O
. O
Internal Method
State Method
Controller Method
: O
We O
use O
a O
GRU Method
model Method
with O
256 Method
- Method
dimensional Method
hidden Method
units Method
as O
the O
internal Method
state Method
controller Method
. O
The O
initial O
state O
of O
the O
GRU Method
controller Method
is O
the O
last Method
- Method
word Method
representation Method
of O
the O
query Method
bidirectional Method
- Method
GRU Method
encoder Method
. O
Termination Method
Module Method
: O
We O
use O
the O
same O
termination Method
module Method
as O
in O
the O
CNN Task
and Task
Daily Task
Mail Task
experiments Task
. O
Answer Method
Module Method
: O
SQuAD Material
task O
requires O
the O
model O
to O
nd O
a O
span O
in O
the O
passage O
to O
answer O
the O
query O
. O
Thus O
the O
answer Method
module Method
requires O
to O
predict O
the O
start O
and O
end O
indices O
of O
the O
answer O
span O
in O
the O
passage O
. O
The O
probability O
distribution O
of O
selecting O
the O
start O
index O
over O
the O
passage O
at O
state O
s O
t O
is O
computed O
by O
: O
where O
S O
t O
is O
given O
via O
tiling O
s O
t O
by O
T O
times O
across O
the O
column O
and O
w O
p O
1 O
is O
a O
trainable O
weight O
vector O
. O
The O
probability O
distribution O
of O
selecting O
the O
end O
index O
over O
passage O
is O
computed O
in O
a O
similar O
manner O
: O
Other O
Details O
: O
The O
maximum O
reasoning O
step O
T O
max O
is O
set O
to O
10 O
in O
SQuAD Material
experiments O
. O
We O
use O
AdaDelta Method
optimizer Method
[ O
reference O
] O
for O
parameter Task
optimization Task
with O
an O
initial O
learning Metric
rate Metric
of O
0.5 O
and O
a O
batch O
size O
of O
32 O
. O
Models O
are O
trained O
on O
GTX Method
TitanX O
12 O
GB O
. O
It O
takes O
about O
40 O
minutes O
per O
epoch O
for O
training Task
, O
with O
18 O
epochs O
in O
total O
. O
Results O
: O
In O
the O
Table O
2 O
, O
we O
report O
the O
performance O
of O
all O
models O
in O
the O
SQuAD Material
leaderboard O
. O
[ O
reference O
] O
In O
the O
upper O
part O
of O
the O
Table O
2 O
, O
we O
compare O
ReasoNet Method
with O
all O
published O
baselines O
at O
the O
time O
of O
submission O
. O
Speci O
cally O
, O
BiDAF Method
model Method
could O
be O
viewed O
as O
a O
special O
case O
of O
ReasoNet Method
with O
T O
max O
= O
1 O
. O
It O
is O
worth O
noting O
that O
this O
SQuAD Material
leaderboard O
is O
highly O
active O
and O
competitive O
. O
The O
test O
set O
is O
hidden O
to O
all O
models O
and O
all O
the O
results O
on O
the O
leaderboard O
are O
produced O
and O
reported O
by O
the O
organizer O
; O
thus O
all O
the O
results O
here O
are O
reproducible O
. O
In O
Table O
2 O
, O
we O
demonstrate O
that O
ReasoNet Method
outperforms O
all O
existing O
published O
approaches O
. O
While O
we O
compare O
ReasoNet Method
with O
BiDAF Method
, O
ReasoNet Method
exceeds O
BiDAF Method
both O
in O
single O
model O
and O
ensemble Method
model Method
cases Method
. O
This O
demonstrates O
the O
importance O
of O
the O
dynamic Task
multi Task
- Task
turn Task
reasoning Task
over O
a O
passage O
. O
In O
the O
bottom O
part O
of O
Table O
2 O
, O
we O
compare O
ReasoNet Method
with O
all O
unpublished O
methods O
at O
the O
time O
of O
this O
submission O
, O
ReasoNet Method
holds O
the O
second O
position O
in O
all O
the O
competing O
approaches O
in O
the O
SQuAD Material
leaderboard O
. O
section O
: O
Graph Task
Reachability Task
Task Task
Recent O
analysis O
and O
results O
[ O
reference O
] O
on O
the O
cloze Task
- Task
style Task
machine Task
comprehension Task
tasks Task
have O
suggested O
some O
simple O
models O
without O
multiturn Method
reasoning Method
can O
achieve O
reasonable O
performance O
. O
Based O
on O
these O
results O
, O
we O
construct O
a O
synthetic Material
structured Material
Graph Material
Reachability Material
dataset Material
[ O
reference O
] O
to O
evaluate O
longer Task
range Task
machine Task
inference Task
and Task
reasoning Task
capability Task
, O
since O
we O
anticipate O
ReasoNets Method
to O
have O
the O
capability O
to O
handle O
long O
range O
relationships O
. O
We O
generate O
two O
synthetic O
datasets O
: O
a O
small O
graph O
dataset O
and O
a O
large O
graph O
dataset O
. O
In O
the O
small O
graph O
dataset O
, O
it O
contains O
500 O
K O
small O
graphs O
, O
where O
each O
graph O
contains O
9 O
nodes O
and O
16 O
direct O
Step O
1 O
Step O
2 O
Step O
0 O
Step O
3 O
Step O
4 O
, O
5 O
, O
7 O
Step O
6 O
, O
8 O
Step O
9 O
Step O
Step O
2 O
Step O
3 O
Step O
1 O
Step O
4 O
Steps O
5 O
, O
6 O
, O
8 O
Steps O
7 O
, O
9 O
Step O
10 O
Figure O
4 O
: O
An O
example O
of O
graph Task
reachability Task
result O
, O
given O
a O
query O
" O
10 O
→ O
17 O
" O
( O
Answer O
: O
Yes O
) O
. O
The O
red O
circles O
highlight O
the O
nodes O
/ O
edges O
which O
have O
the O
highest O
attention O
in O
each O
step O
. O
The O
corresponding O
termination Metric
probability Metric
and O
prediction Task
results O
are O
shown O
in O
the O
table O
. O
The O
model O
terminates O
at O
step O
10 O
. O
edges O
to O
randomly O
connect O
pairs O
of O
nodes O
. O
The O
large O
graph O
dataset O
contains O
500 O
K O
graphs O
, O
where O
each O
graph O
contains O
18 O
nodes O
and O
32 O
random O
direct O
edges O
. O
Duplicated O
edges O
are O
removed O
. O
Table O
3 O
shows O
the O
graph O
reachability O
statistics O
on O
the O
two O
datasets O
. O
In O
Table O
4 O
, O
we O
show O
examples O
of O
a O
small O
graph O
and O
a O
large O
graph O
in O
the O
synthetic O
dataset O
. O
Both O
graph O
and O
query O
are O
represented O
by O
a O
sequence O
of O
symbols O
. O
The O
details O
settings O
of O
the O
ReasoNet Method
are O
listed O
as O
follows O
in O
the O
reachability Task
tasks Task
. O
Embedding Method
Layer Method
We O
use O
a O
100 O
- O
dimensional O
embedding O
vector O
for O
each O
symbol O
in O
the O
query Task
and Task
graph Task
description Task
. O
Bi Method
- Method
LSTM Method
Encoder Method
: O
We O
apply O
a O
bidirectional Method
- Method
LSTM Method
layer Method
with O
128 O
and O
256 O
cells O
on O
query O
embeddings O
in O
the O
small O
and O
large O
graph O
datasets O
, O
respectively O
. O
The O
last O
states O
of O
bidirectional Method
- Method
LSTM Method
on O
query O
are O
concatenated O
to O
be O
the O
initial O
internal O
state O
We O
apply O
another O
bidirectional Method
- Method
LSTM Method
layer Method
with O
128 O
and O
256 O
cells O
on O
graph Task
description Task
embeddings Task
in O
the O
small O
and O
large O
graph O
datasets O
, O
respectively O
. O
It O
maps O
each O
symbol O
i O
to O
a O
contextual Method
representation Method
given O
by O
the O
concatenation Method
of Method
forward Method
and Method
backward Method
LSTM Method
hidden Method
states Method
section O
: O
Internal Method
State Method
Controller Method
: O
We O
use O
a O
GRU Method
model Method
with O
128 O
- O
dimensional O
and O
256 O
- O
dimensional O
hidden O
units O
as O
the O
internal Method
state Method
controller Method
for O
the O
small O
and O
large O
graph O
datasets O
, O
respectively O
. O
The O
initial O
state O
of O
the O
GRU Method
controller Method
is O
s O
1 O
. O
Answer Method
Module Method
: O
The O
nal O
answer O
is O
either O
" O
Yes O
" O
or O
" O
No O
" O
and O
hence O
logistical Method
regression Method
is O
used O
as O
the O
answer O
module O
: O
Termination Method
Module Method
: O
We O
use O
the O
same O
termination Method
module Method
as O
in O
the O
CNN Task
and Task
Daily Task
Mail Task
experiments Task
. O
Other O
Details O
: O
The O
maximum O
reasoning O
step O
T O
max O
is O
set O
to O
15 O
and O
25 O
for O
the O
small O
graph O
and O
large O
graph O
dataset O
, O
respectively O
. O
We O
use O
AdaDelta Method
optimizer Method
[ O
reference O
] O
for O
parameter Task
optimization Task
with O
an O
initial O
learning Metric
rate Metric
of O
0.5 O
and O
a O
batch O
size O
of O
32 O
. O
We O
denote O
" O
ReasoNet Method
" O
as O
the O
standard O
ReasoNet Method
with O
termination O
gate O
, O
as O
described O
in O
Section O
3.1 O
. O
To O
study O
the O
e O
ectiveness O
of O
the O
termination O
gate O
in O
ReasoNets O
, O
we O
remove O
the O
termination O
gate O
and O
use O
the O
prediction O
from O
the O
last O
state O
, O
â O
= O
a O
T O
max O
( O
T O
max O
is O
the O
maximum O
reasoning O
step O
) O
, O
denoted O
as O
" O
ReasoNet Method
- Method
Last Method
" O
. O
To O
study O
the O
e O
ectiveness O
of O
multi Task
- Task
turn Task
reasoning Task
, O
we O
choose O
" O
ReasoNet Method
- O
T O
max O
= O
2 O
" O
, O
which O
only O
has O
single Method
- Method
turn Method
reasoning Method
. O
We O
compare O
ReasoNets Method
with O
a O
two Method
layer Method
deep Method
LSTM Method
model Method
[ O
reference O
] O
with O
128 O
hidden O
units O
, O
denoted O
as O
" O
Deep Method
LSTM Method
Reader Method
" O
, O
as O
a O
baseline O
. O
Table O
5 O
shows O
the O
performance O
of O
these O
models O
on O
the O
graph Material
reachability Material
dataset Material
. O
Deep Method
LSTM Method
Reader Method
achieves O
90.92 O
% O
and O
71.55 O
% O
accuracy Metric
in O
the O
small O
and O
large O
graph O
dataset O
, O
respectively O
, O
which O
indicates O
the O
graph Task
reachibility Task
task Task
is O
not O
trivial O
. O
The O
results O
of O
ReasoNet Method
- O
T O
max O
= O
2 O
are O
comparable O
with O
the O
results O
of O
Deep Method
LSTM Method
Reader Method
, O
since O
both O
Deep Method
LSTM Method
Reader Method
and O
ReasoNet Method
- O
T O
max O
= O
2 O
perform O
single Method
- Method
turn Method
reasoning Method
. O
The O
ReasoNet Method
- O
Last O
model O
achieves O
100 O
% O
accuracy Metric
on O
the O
small O
graph O
dataset O
, O
while O
the O
ReasoNet Method
- O
Last O
model O
achieves O
Step O
Step O
1 O
Step O
2 O
Step O
2 O
Step O
1 O
Step O
1 O
Step O
1 O
Figure O
4 O
, O
we O
can O
observe O
that O
the O
model O
does O
not O
make O
a O
rm Task
prediction Task
till O
step O
9 O
. O
The O
highest O
attention O
word O
at O
each O
step O
shows O
the O
reasoning O
process O
of O
the O
model O
. O
Interestingly O
, O
the O
model O
starts O
from O
the O
end O
node O
[ O
reference O
] O
, O
traverses O
backward O
till O
nding O
the O
starting O
node O
( O
10 O
) O
in O
step O
9 O
, O
and O
makes O
a O
rm Task
termination Task
prediction Task
. O
On O
the O
other O
hand O
, O
in O
Figure O
5 O
, O
the O
model O
learns O
to O
stop O
in O
step O
2 O
. O
In O
step O
1 O
, O
the O
model O
looks O
for O
neighbor O
nodes O
[ O
reference O
][ O
reference O
][ O
reference O
] O
) O
to O
4 O
and O
9 O
. O
Then O
, O
the O
model O
gives O
up O
in O
step O
2 O
and O
predict O
" O
No O
" O
. O
All O
of O
these O
demonstrate O
the O
dynamic O
termination O
characteristic O
and O
potential O
reasoning O
capability O
of O
ReasoNets Method
. O
To O
better O
grasp O
when O
ReasoNets O
stop O
reasoning O
, O
we O
show O
the O
distribution O
of O
termination O
steps O
in O
ReasoNets O
on O
the O
test O
set O
. O
The O
termination O
step O
is O
chosen O
with O
the O
maximum O
termination O
probability O
p O
( O
k O
) O
= O
t O
k O
k O
−1 O
i=1 O
( O
1 O
− O
t O
i O
) O
, O
where O
t O
i O
is O
the O
termination O
probability O
at O
step O
i. O
Figure O
6 O
shows O
the O
termination O
step O
distribution O
of O
ReasoNets O
in O
the O
graph Material
reachability Material
dataset Material
. O
The O
distributions O
spread O
out O
across O
di O
erent O
steps O
. O
Around O
16 O
% O
and O
35 O
% O
of O
the O
instances O
terminate O
in O
the O
last O
step O
for O
the O
small O
and O
large O
graph O
, O
respectively O
. O
We O
study O
the O
correlation O
between O
the O
termination O
steps O
and O
the O
complexity O
of O
test O
instances O
in O
Figure O
7 O
. O
Given O
the O
query O
, O
we O
use O
the O
Breadth Method
- Method
First Method
Search Method
( O
BFS Method
) O
algorithm O
over O
the O
target O
graph O
to O
analyze O
the O
complexity O
of O
test O
instances O
. O
For O
example O
, O
BFS Method
- O
Step O
Figure O
7 O
shows O
that O
test O
instances O
with O
larger O
BFS Method
- O
Steps O
require O
more O
reasoning O
steps O
. O
The O
correlation O
between O
BFS Method
steps O
and O
ReasoNet Method
termination O
steps O
in O
the O
graph O
reachability O
dataset O
, O
where O
T O
max O
is O
set O
to O
15 O
and O
25 O
in O
the O
small O
graph O
and O
large O
graph O
dataset O
, O
respectively O
, O
and O
BFS Method
- O
Step= O
−1 O
denotes O
unreachable O
cases O
. O
The O
value O
indicates O
the O
number O
of O
instances O
in O
each O
case O
. O
section O
: O
CONCLUSION O
In O
this O
paper O
, O
we O
propose O
ReasoNets Method
that O
dynamically O
decide O
whether O
to O
continue O
or O
to O
terminate O
the O
inference Task
process Task
in O
machine Task
comprehension Task
tasks Task
. O
With O
the O
use O
of O
the O
instance Method
- Method
dependent Method
baseline Method
method Method
, O
our O
proposed O
model O
achieves O
superior O
results O
in O
machine O
comprehension O
datasets O
, O
including O
unstructured Material
CNN Material
and Material
Daily Material
Mail Material
datasets Material
, O
the O
Stanford Material
SQuAD Material
dataset Material
, O
and O
a O
proposed O
structured O
Graph O
Reachability O
dataset O
. O
section O
: O
