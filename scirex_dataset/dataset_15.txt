Fast Task
Online Task
Object Task
Tracking Task
and Task
Segmentation Task
: O
A O
Unifying Method
Approach Method
section O
: O
Abstract O
In O
this O
paper O
we O
illustrate O
how O
to O
perform O
both O
visual Task
object Task
tracking Task
and O
semi Task
- Task
supervised Task
video Task
object Task
segmentation Task
, O
in O
real O
- O
time O
, O
with O
a O
single O
simple O
approach O
. O
Our O
method O
, O
dubbed O
SiamMask Method
, O
improves O
the O
offline Method
training Method
procedure Method
of O
popular O
fully Method
- Method
convolutional Method
Siamese Method
approaches Method
for O
object Task
tracking Task
by O
augmenting O
their O
loss O
with O
a O
binary Task
segmentation Task
task Task
. O
Once O
trained O
, O
SiamMask Method
solely O
relies O
on O
a O
single O
bounding Method
box Method
initialisation Method
and O
operates O
online O
, O
producing O
class Method
- Method
agnostic Method
object Method
segmentation Method
masks Method
and O
rotated O
bounding O
boxes O
at O
35 O
frames O
per O
second O
. O
Despite O
its O
simplicity O
, O
versatility O
and O
fast O
speed O
, O
our O
strategy O
allows O
us O
to O
establish O
a O
new O
state O
- O
of O
- O
the O
- O
art O
among O
real Method
- Method
time Method
trackers Method
on O
VOT Material
- Material
2018 Material
, O
while O
at O
the O
same O
time O
demonstrating O
competitive O
performance O
and O
the O
best O
speed O
for O
the O
semisupervised Task
video Task
object Task
segmentation Task
task Task
on O
DAVIS O
- O
2016 O
and O
DAVIS O
- O
2017 O
. O
The O
project O
website O
is O
http: O
// O
www O
. O
robots.ox.ac.uk O
/ O
Ëœqwang O
/ O
SiamMask Method
. O
section O
: O
Introduction O
Tracking Task
is O
a O
fundamental O
task O
in O
any O
video Task
application Task
requiring O
some O
degree O
of O
reasoning O
about O
objects O
of O
interest O
, O
as O
it O
allows O
to O
establish O
object O
correspondances O
between O
frames O
[ O
reference O
] O
. O
It O
finds O
use O
in O
a O
wide O
range O
of O
scenarios O
such O
as O
automatic Task
surveillance Task
, O
vehicle Task
navigation Task
, O
video Task
labelling Task
, O
human Task
- Task
computer Task
interaction Task
and O
activity Task
recognition Task
. O
Given O
the O
location O
of O
an O
arbitrary O
target O
of O
interest O
in O
the O
first O
frame O
of O
a O
video O
, O
the O
aim O
of O
visual Task
object Task
tracking Task
is O
to O
estimate O
its O
position O
in O
all O
the O
subsequent O
frames O
[ O
reference O
][ O
reference O
][ O
reference O
] O
. O
For O
many O
applications O
, O
it O
is O
important O
that O
tracking Task
can O
be O
performed O
online O
, O
while O
the O
video O
is O
streaming O
. O
In O
other O
words O
, O
the O
tracker O
should O
not O
make O
use O
of O
future O
frames O
to O
* O
Equal O
contribution O
. O
Work O
done O
while O
at O
University O
of O
Oxford O
. O
section O
: O
Init O
Estimates O
Figure O
1 O
. O
Our O
proposed O
method O
aims O
at O
distilling O
the O
best O
from O
the O
two O
tasks O
of O
object Task
tracking Task
and O
video Task
object Task
segmentation Task
. O
Like O
conventional O
object Method
trackers Method
, O
it O
relies O
on O
a O
simple O
bounding Method
box Method
initialisation Method
( O
blue O
) O
and O
operates O
online O
. O
Differently O
from O
state O
- O
ofthe O
- O
art O
trackers O
such O
as O
ECO Method
[ O
reference O
] O
( O
red O
) O
, O
SiamMask Method
( O
green O
) O
is O
able O
to O
produce O
binary O
segmentation O
masks O
, O
which O
can O
more O
accurately O
describe O
the O
target O
object O
. O
reason O
about O
the O
current O
position O
of O
the O
object O
[ O
reference O
] O
. O
This O
is O
the O
scenario O
portrayed O
by O
visual Task
object Task
tracking Task
benchmarks O
, O
which O
represent O
the O
target O
object O
with O
a O
simple O
axisaligned O
[ O
reference O
][ O
reference O
][ O
reference O
][ O
reference O
][ O
reference O
] O
or O
rotated O
[ O
reference O
] O
bounding O
box O
. O
Such O
a O
simple O
annotation O
helps O
to O
keep O
the O
cost O
of O
data Task
labelling Task
low O
; O
what O
is O
more O
, O
it O
allows O
a O
user O
to O
perform O
a O
quick O
and O
simple O
initialisation O
of O
the O
target O
. O
Similar O
to O
object Task
tracking Task
, O
the O
task O
of O
semi Task
- Task
supervised Task
video Task
object Task
segmentation Task
( O
VOS Task
) O
requires O
estimating O
the O
position O
of O
an O
arbitrary O
target O
specified O
in O
the O
first O
frame O
of O
a O
video O
. O
However O
, O
in O
this O
case O
the O
object Method
representation Method
consists O
of O
a O
binary Method
segmentation Method
mask Method
which O
expresses O
whether O
each O
pixel O
belongs O
to O
the O
target O
or O
not O
[ O
reference O
] O
. O
Such O
a O
detailed Method
representation Method
is O
more O
desirable O
for O
applications O
that O
require O
pixel O
- O
level O
information O
, O
like O
video Task
editing Task
[ O
reference O
] O
and O
rotoscoping O
[ O
reference O
] O
. O
Understandably O
, O
producing O
pixel Task
- Task
level Task
estimates Task
requires O
more O
computational O
re O
- O
sources O
than O
a O
simple O
bounding Method
box Method
. O
As O
a O
consequence O
, O
VOS Method
methods Method
have O
been O
traditionally O
slow O
, O
often O
requiring O
several O
seconds O
per O
frame O
( O
e.g. O
[ O
reference O
][ O
reference O
][ O
reference O
][ O
reference O
] O
) O
. O
Very O
recently O
, O
there O
has O
been O
a O
surge O
of O
interest O
in O
faster O
approaches O
[ O
reference O
][ O
reference O
][ O
reference O
][ O
reference O
][ O
reference O
][ O
reference O
][ O
reference O
] O
. O
However O
, O
even O
the O
fastest O
still O
can O
not O
operate O
in O
real O
- O
time O
. O
In O
this O
paper O
, O
we O
aim O
at O
narrowing O
the O
gap O
between O
arbitrary Task
object Task
tracking Task
and O
VOS Task
by O
proposing O
SiamMask Method
, O
a O
simple O
multi Method
- Method
task Method
learning Method
approach Method
that O
can O
be O
used O
to O
address O
both O
problems O
. O
Our O
method O
is O
motivated O
by O
the O
success O
of O
fast Method
tracking Method
approaches Method
based O
on O
fullyconvolutional Method
Siamese Method
networks Method
trained O
offline O
on O
millions O
of O
pairs O
of O
video O
frames O
[ O
reference O
][ O
reference O
] O
and O
by O
the O
very O
recent O
availability O
of O
a O
large O
video O
dataset O
with O
pixel O
- O
wise O
annotations O
such O
as O
YouTube O
- O
VOS O
[ O
reference O
] O
. O
We O
aim O
at O
retaining O
the O
offline Metric
trainability Metric
and O
online Metric
speed Metric
of O
these O
methods O
while O
at O
the O
same O
time O
significantly O
refining O
their O
representation O
of O
the O
target O
object O
, O
which O
is O
limited O
to O
a O
simple O
axis O
- O
aligned O
bounding O
box O
. O
To O
achieve O
this O
goal O
, O
we O
simultaneously O
train O
a O
Siamese Method
network Method
on O
three O
tasks O
, O
each O
corresponding O
to O
a O
different O
strategy O
to O
establish O
correspondances O
between O
the O
target O
object O
and O
candidate O
regions O
in O
the O
new O
frames O
. O
As O
in O
the O
fully Method
- Method
convolutional Method
approach Method
of O
Bertinetto O
et O
al O
. O
[ O
reference O
] O
, O
one O
task O
is O
to O
learn O
a O
measure O
of O
similarity O
between O
the O
target O
object O
and O
multiple O
candidates O
in O
a O
sliding Method
window Method
fashion Method
. O
The O
output O
is O
a O
dense O
response O
map O
which O
only O
indicates O
the O
location O
of O
the O
object O
, O
without O
providing O
any O
information O
about O
its O
spatial O
extent O
. O
To O
refine O
this O
information O
, O
we O
simultaneously O
learn O
two O
further O
tasks O
: O
bounding Method
box Method
regression Method
using O
a O
Region Method
Proposal Method
Network Method
[ O
reference O
][ O
reference O
] O
and O
classagnostic Method
binary Method
segmentation Method
[ O
reference O
] O
. O
Notably O
, O
binary O
labels O
are O
only O
required O
during O
offline Task
training Task
to O
compute O
the O
segmentation Task
loss Task
and O
not O
during O
tracking Task
. O
In O
our O
proposed O
architecture O
, O
each O
task O
is O
represented O
by O
a O
different O
branch O
departing O
from O
a O
shared Method
CNN Method
and O
contributes O
towards O
a O
final O
loss Metric
, O
which O
sums O
the O
three O
outputs O
together O
. O
Once O
trained O
, O
SiamMask Method
solely O
relies O
on O
a O
single O
bounding Method
box Method
initialisation Method
, O
operates O
online O
without O
updates O
and O
produces O
object O
segmentation O
masks O
and O
rotated O
bounding O
boxes O
at O
35 O
frames O
per O
second O
. O
Despite O
its O
simplicity O
and O
fast O
speed O
, O
SiamMask Method
establishes O
a O
new O
state O
- O
of O
- O
the O
- O
art O
on O
VOT Material
- Material
2018 Material
for O
the O
problem O
of O
real Task
- Task
time Task
object Task
tracking Task
. O
Moreover O
, O
the O
same O
method O
is O
also O
very O
competitive O
against O
recent O
semi Method
- Method
supervised Method
VOS Method
approaches Method
on O
DAVIS O
- O
2016 O
and O
DAVIS O
- O
2017 O
, O
while O
being O
the O
fastest O
by O
a O
large O
margin O
. O
This O
result O
is O
achieved O
with O
a O
simple O
bounding Method
box Method
initialisation Method
( O
as O
opposed O
to O
a O
mask O
) O
and O
without O
adopting O
costly O
techniques O
often O
used O
by O
VOS Method
approaches Method
such O
as O
fine Method
- Method
tuning Method
[ O
reference O
][ O
reference O
][ O
reference O
][ O
reference O
] O
, O
data Method
augmentation Method
[ O
reference O
][ O
reference O
] O
and O
optical Method
flow Method
[ O
reference O
][ O
reference O
][ O
reference O
][ O
reference O
][ O
reference O
] O
. O
The O
rest O
of O
this O
paper O
is O
organised O
as O
follows O
. O
Section O
2 O
briefly O
outlines O
some O
of O
the O
most O
relevant O
prior O
work O
in O
visual Task
object Task
tracking Task
and O
semi Task
- Task
supervised Task
VOS Task
; O
Section O
3 O
describes O
our O
proposal O
; O
Section O
4 O
evaluates O
it O
on O
four O
benchmarks O
and O
illustrates O
several O
ablative O
studies O
; O
Section O
5 O
concludes O
the O
paper O
. O
section O
: O
Related O
Work O
In O
this O
section O
, O
we O
briefly O
cover O
most O
representative O
techniques O
for O
the O
two O
problems O
tackled O
in O
this O
paper O
. O
Visual Task
object Task
tracking Task
. O
Arguably O
, O
until O
very O
recently O
, O
the O
most O
popular O
paradigm O
for O
tracking Task
arbitrary Task
objects Task
has O
been O
to O
train O
online O
a O
discriminative Method
classifier Method
exclusively O
from O
the O
ground O
- O
truth O
information O
provided O
in O
the O
first O
frame O
of O
a O
video O
( O
and O
then O
update O
it O
online O
) O
. O
This O
strategy O
has O
often O
been O
referred O
to O
as O
tracking Task
- Task
by Task
- Task
detection Task
( O
e.g. O
[ O
reference O
][ O
reference O
] O
) O
. O
In O
the O
past O
few O
years O
, O
the O
Correlation Method
Filter Method
, O
a O
simple O
algorithm O
that O
allows O
to O
discriminate O
between O
the O
template O
of O
an O
arbitrary O
target O
and O
its O
2D O
translations O
, O
rose O
to O
prominence O
as O
particularly O
fast O
and O
effective O
strategy O
for O
tracking Task
- Task
by Task
- Task
detection Task
thanks O
to O
the O
pioneering O
work O
of O
Bolme O
et O
al O
. O
[ O
reference O
] O
. O
Performance O
of O
Correlation Method
Filter Method
- Method
based Method
trackers Method
has O
then O
been O
notably O
improved O
with O
the O
adoption O
of O
multi Method
- Method
channel Method
formulations Method
[ O
reference O
][ O
reference O
] O
, O
spatial O
constraints O
[ O
reference O
][ O
reference O
][ O
reference O
][ O
reference O
] O
and O
deep O
features O
( O
e.g. O
[ O
reference O
][ O
reference O
] O
) O
. O
Recently O
, O
a O
radically O
different O
approach O
has O
been O
introduced O
[ O
reference O
][ O
reference O
][ O
reference O
] O
. O
Instead O
of O
learning O
a O
discrimative Method
classifier Method
online O
, O
the O
idea O
is O
to O
train O
( O
offline O
) O
a O
similarity Method
function Method
on O
pairs O
of O
video O
frames O
. O
At O
test O
time O
, O
this O
function O
can O
be O
simply O
evaluated O
on O
a O
new O
video O
, O
once O
per O
frame O
. O
Evolutions O
of O
the O
fully Method
- Method
convolutional Method
Siamese Method
approach Method
[ O
reference O
] O
considerably O
improved O
tracking Task
performance O
by O
making O
use O
of O
region Method
proposals Method
[ O
reference O
] O
, O
hard Method
negative Method
mining Method
[ O
reference O
] O
, O
ensembling Method
[ O
reference O
] O
and O
memory Method
networks Method
[ O
reference O
] O
. O
Most O
modern O
trackers O
, O
including O
all O
the O
ones O
mentioned O
above O
, O
use O
a O
rectangular O
bounding O
box O
both O
to O
initialise O
the O
target O
and O
to O
estimate O
its O
position O
in O
the O
subsequent O
frames O
. O
Despite O
its O
convenience O
, O
a O
simple O
rectangle O
often O
fails O
to O
properly O
represent O
an O
object O
, O
as O
it O
is O
evident O
in O
the O
examples O
of O
Figure O
1 O
. O
This O
motivated O
us O
to O
propose O
a O
tracker Method
able O
to O
produce O
binary O
segmentation O
masks O
while O
still O
only O
relying O
on O
a O
bounding Method
box Method
initialisation Method
. O
Interestingly O
, O
in O
the O
past O
it O
was O
not O
uncommon O
for O
trackers Method
to O
produce O
a O
coarse O
binary O
mask O
of O
the O
target O
object O
( O
e.g. O
[ O
reference O
][ O
reference O
][ O
reference O
] O
) O
. O
However O
, O
to O
the O
best O
of O
our O
knowledge O
, O
the O
only O
recent O
tracker O
that O
, O
like O
ours O
, O
is O
able O
to O
operate O
online O
and O
produce O
a O
binary O
mask O
starting O
from O
a O
bounding Method
box Method
initialisation Method
is O
the O
superpixel Method
- Method
based Method
approach Method
of O
Yeo O
et O
al O
. O
[ O
reference O
] O
. O
However O
, O
at O
4 O
frames O
per O
seconds O
( O
fps O
) O
, O
its O
fastest O
variant O
is O
significantly O
slower O
that O
our O
proposal O
( O
35 O
fps O
) O
. O
Furthermore O
, O
When O
using O
CNN O
features O
, O
its O
speed O
is O
affected O
by O
a O
60 O
- O
fold O
decrease O
, O
plummeting O
below O
0.1 O
fps O
. O
Finally O
, O
it O
has O
not O
demonstrated O
to O
be O
competitive O
on O
mod Task
- Task
ern Task
tracking Task
or O
VOS Method
benchmarks Method
[ O
reference O
] O
. O
Similar O
to O
us O
, O
the O
methods O
of O
Perazzi O
et O
al O
. O
[ O
reference O
] O
and O
Ci O
et O
al O
. O
[ O
reference O
] O
can O
also O
start O
from O
a O
rectangle O
and O
output O
per O
- O
frame O
masks O
. O
However O
, O
they O
require O
fine O
- O
tuning O
at O
test O
time O
, O
which O
makes O
them O
slow O
. O
Semi Task
- Task
supervised Task
video Task
object Task
segmentation Task
. O
Benchmarks O
for O
arbitrary Task
object Task
tracking Task
( O
e.g. O
[ O
reference O
][ O
reference O
] O
) O
assume O
that O
trackers O
receive O
input O
frames O
in O
a O
sequential O
fashion O
. O
This O
aspect O
is O
generally O
referred O
to O
with O
the O
attributes O
online O
or O
causal O
[ O
reference O
] O
. O
Moreover O
, O
methods O
are O
often O
focused O
on O
achieving O
a O
speed O
that O
exceeds O
the O
ones O
of O
typical O
video O
framerates O
[ O
reference O
] O
. O
Conversely O
, O
semi Method
- Method
supervised Method
VOS Method
algorithms Method
have O
been O
traditionally O
more O
concerned O
with O
an O
accurate O
representation O
of O
the O
object O
of O
interest O
[ O
reference O
][ O
reference O
] O
. O
In O
order O
to O
exploit O
consistency O
between O
video O
frames O
, O
several O
methods O
propagate O
the O
supervisory O
segmentation O
mask O
of O
the O
first O
frame O
to O
the O
temporally O
adjacent O
ones O
via O
graph Method
labeling Method
approaches Method
( O
e.g. O
[ O
reference O
][ O
reference O
][ O
reference O
][ O
reference O
][ O
reference O
] O
) O
. O
In O
particular O
, O
Bao O
et O
al O
. O
[ O
reference O
] O
recently O
proposed O
a O
very O
accurate O
method O
that O
makes O
use O
of O
a O
spatio Method
- Method
temporal Method
MRF Method
in O
which O
temporal O
dependencies O
are O
modelled O
by O
optical O
flow O
, O
while O
spatial O
dependencies O
are O
expressed O
by O
a O
CNN Method
. O
Another O
popular O
strategy O
is O
to O
process O
video O
frames O
independently O
( O
e.g. O
[ O
reference O
][ O
reference O
][ O
reference O
] O
) O
, O
similarly O
to O
what O
happens O
in O
most O
tracking Method
approaches Method
. O
For O
example O
, O
in O
OSVOS O
- O
S O
Maninis O
et O
al O
. O
[ O
reference O
] O
do O
not O
make O
use O
of O
any O
temporal O
information O
. O
They O
rely O
on O
a O
fully Method
- Method
convolutional Method
network Method
pretrained O
for O
classification Task
and O
then O
, O
at O
test O
time O
, O
they O
finetune O
it O
using O
the O
ground O
- O
truth O
mask O
provided O
in O
the O
first O
frame O
. O
MaskTrack Method
[ O
reference O
] O
instead O
is O
trained O
from O
scratch O
on O
individual O
images O
, O
but O
it O
does O
exploit O
some O
form O
of O
temporality O
at O
test O
time O
by O
using O
the O
latest O
mask O
prediction O
and O
optical O
flow O
as O
additional O
input O
to O
the O
network O
. O
Aiming O
towards O
the O
highest O
possible O
accuracy Metric
, O
at O
test O
time O
VOS Method
methods Method
often O
feature O
computationally O
intensive O
techniques O
such O
as O
fine Method
- Method
tuning Method
[ O
reference O
][ O
reference O
][ O
reference O
][ O
reference O
] O
, O
data Method
augmentation Method
[ O
reference O
][ O
reference O
] O
and O
optical Method
flow Method
[ O
reference O
][ O
reference O
][ O
reference O
][ O
reference O
][ O
reference O
] O
. O
Therefore O
, O
these O
approaches O
are O
generally O
characterised O
by O
low O
framerates O
and O
the O
inability O
to O
operate O
online O
. O
For O
example O
, O
it O
is O
not O
uncommon O
for O
methods O
to O
require O
minutes O
[ O
reference O
][ O
reference O
] O
or O
even O
hours O
[ O
reference O
][ O
reference O
] O
for O
videos O
that O
are O
just O
a O
few O
seconds O
long O
. O
Recently O
, O
there O
has O
been O
an O
increasing O
interest O
in O
the O
VOS O
community O
towards O
faster O
methods O
[ O
reference O
][ O
reference O
][ O
reference O
][ O
reference O
][ O
reference O
][ O
reference O
] O
. O
To O
the O
best O
of O
our O
knowledge O
, O
the O
fastest O
approaches O
with O
a O
performance O
competitive O
with O
the O
state O
- O
of O
- O
the O
- O
art O
are O
the O
ones O
of O
Yang O
et O
al O
. O
[ O
reference O
] O
and O
Wug O
et O
al O
. O
[ O
reference O
] O
. O
The O
former O
uses O
a O
meta Method
- Method
network Method
" Method
modulator Method
" Method
to O
quickly O
adapt O
the O
parameters O
of O
a O
segmentation Method
network Method
during O
test O
time O
, O
while O
the O
latter O
does O
not O
use O
any O
fine Method
- Method
tuning Method
and O
adopts O
an O
encoder Method
- Method
decoder Method
Siamese Method
architecture Method
trained O
in O
multiple O
stages O
. O
Both O
these O
methods O
run O
below O
10 O
frames O
per O
sec O
- O
section O
: O
Methodology O
To O
allow O
online O
operability O
and O
fast O
speed O
, O
we O
adopt O
the O
fully Method
- Method
convolutional Method
Siamese Method
framework Method
[ O
reference O
] O
. O
Moreover O
, O
to O
illustratate O
that O
our O
approach O
is O
agnostic O
to O
the O
specific O
fully Method
- Method
convolutional Method
method Method
used O
as O
a O
starting O
point O
( O
e.g. O
[ O
reference O
][ O
reference O
][ O
reference O
][ O
reference O
][ O
reference O
] O
) O
, O
we O
consider O
the O
popular O
SiamFC Method
[ O
reference O
] O
and O
SiamRPN Method
[ O
reference O
] O
as O
two O
representative O
examples O
. O
We O
first O
introduce O
them O
in O
Section O
3.1 O
and O
then O
describe O
our O
approach O
in O
Section O
3.2 O
. O
section O
: O
Fully Method
- Method
convolutional Method
Siamese Method
networks Method
SiamFC O
. O
Bertinetto O
et O
al O
. O
[ O
reference O
] O
propose O
to O
use O
, O
as O
a O
fundamental O
building O
block O
of O
a O
tracking Method
system Method
, O
an O
offlinetrained Method
fully Method
- Method
convolutional Method
Siamese Method
network Method
that O
compares O
an O
exemplar O
image O
z O
against O
a O
( O
larger O
) O
search O
image O
x O
to O
obtain O
a O
dense O
response O
map O
. O
z O
and O
x O
are O
, O
respectively O
, O
a O
wÃ—h O
crop O
centered O
on O
the O
target O
object O
and O
a O
larger O
crop O
centered O
on O
the O
last O
estimated O
position O
of O
the O
target O
. O
The O
two O
inputs O
are O
processed O
by O
the O
same O
CNN Method
f Method
Î¸ Method
, O
yielding O
two O
feature O
maps O
that O
are O
cross O
- O
correlated O
: O
In O
this O
paper O
, O
we O
refer O
to O
each O
spatial O
element O
of O
the O
response O
map O
( O
left O
- O
hand O
side O
of O
Eq O
. O
1 O
) O
as O
response O
of O
a O
candidate O
window O
( O
RoW O
) O
. O
For O
example O
, O
g O
n O
Î¸ O
( O
z O
, O
x O
) O
, O
encodes O
a O
similarity O
between O
the O
examplar O
z O
and O
n O
- O
th O
candidate O
window O
in O
x. O
For O
SiamFC Method
, O
the O
goal O
is O
for O
the O
maximum O
value O
of O
the O
response O
map O
to O
correspond O
to O
the O
target O
location O
in O
the O
search O
area O
x. O
Instead O
, O
in O
order O
to O
allow O
each O
RoW O
to O
encode O
richer O
information O
about O
the O
target O
object O
, O
we O
replace O
the O
simple O
cross Method
- Method
correlation Method
of O
Eq O
. O
1 O
with O
depth O
- O
wise O
crosscorrelation O
[ O
reference O
] O
and O
produce O
a O
multi Method
- Method
channel Method
response Method
map Method
. O
SiamFC Method
is O
trained O
offline O
on O
millions O
of O
video O
frames O
with O
the O
logistic O
loss O
[ O
4 O
, O
Section O
2.2 O
] O
, O
which O
we O
refer O
to O
as O
L O
sim O
. O
SiamRPN Method
. O
Li O
et O
al O
. O
[ O
reference O
] O
considerably O
improve O
the O
performance O
of O
SiamFC Method
by O
relying O
on O
a O
region Method
proposal Method
network Method
( O
RPN Method
) O
[ O
reference O
] O
, O
which O
allows O
to O
estimate O
the O
target O
location O
with O
a O
bounding O
box O
of O
variable O
aspect O
ratio O
. O
In O
particular O
, O
in O
SiamRPN Method
each O
RoW O
encodes O
a O
set O
of O
k O
anchor O
box O
proposals O
and O
corresponding O
object O
/ O
background O
scores O
. O
Therefore O
, O
SiamRPN Method
outputs O
box Method
predictions Method
in O
parallel O
with O
classification O
scores O
. O
The O
two O
output O
branches O
are O
trained O
using O
the O
smooth O
L O
1 O
and O
the O
cross O
- O
entropy O
losses O
[ O
31 O
, O
Section O
3.2 O
] O
. O
In O
the O
following O
, O
we O
refer O
to O
them O
as O
L O
box O
and O
L Metric
score Metric
respectively O
. O
section O
: O
SiamMask Method
Unlike O
existing O
tracking Method
methods Method
that O
rely O
on O
lowfidelity Method
object Method
representations Method
, O
we O
argue O
the O
importance O
of O
producing O
per O
- O
frame O
binary O
segmentation O
masks O
. O
To O
this O
aim O
we O
show O
that O
, O
besides O
similarity O
scores O
and O
bounding O
box O
coordinates O
, O
it O
is O
possible O
for O
the O
RoW O
of O
a O
fullyconvolutional Method
Siamese Method
network Method
to O
also O
encode O
the O
information O
necessary O
to O
produce O
a O
pixel O
- O
wise O
binary O
mask O
. O
This O
can O
be O
achieved O
by O
extending O
existing O
Siamese Method
trackers Method
with O
an O
extra O
branch O
and O
loss O
. O
We O
predict O
wÃ—h O
binary O
masks O
( O
one O
for O
each O
RoW O
) O
using O
a O
simple O
two Method
- Method
layers Method
neural Method
network Method
h Method
Ï† Method
with O
learnable O
parameters O
Ï† O
. O
Let O
m O
n O
denote O
the O
predicted O
mask O
corresponding O
to O
the O
n O
- O
th O
RoW O
, O
From O
Eq O
. O
2 O
we O
can O
see O
that O
the O
mask Task
prediction Task
is O
a O
function O
of O
both O
the O
image O
to O
segment O
x O
and O
the O
target O
object O
in O
z. O
In O
this O
way O
, O
z O
can O
be O
used O
as O
a O
reference O
to O
guide O
the O
segmentation Task
process Task
, O
such O
that O
objects O
of O
any O
arbitrary O
class O
can O
be O
tracked O
. O
This O
clearly O
means O
that O
, O
given O
a O
different O
reference O
image O
z O
, O
the O
network O
will O
produce O
a O
different O
segmentation O
mask O
for O
x. O
Loss O
function O
. O
During O
training O
, O
each O
RoW O
is O
labelled O
with O
a O
ground O
- O
truth O
binary O
label O
y O
n O
âˆˆ O
{ O
Â±1 O
} O
and O
also O
associated O
with O
a O
pixel O
- O
wise O
ground O
- O
truth O
mask O
c O
n O
of O
size O
wÃ—h O
. O
Let O
c O
ij O
n O
âˆˆ O
{ O
Â±1 O
} O
denote O
the O
label O
corresponding O
to O
pixel O
( O
i O
, O
j O
) O
of O
the O
object O
mask O
in O
the O
n O
- O
th O
candidate O
RoW. O
The O
loss O
function O
L O
mask O
( O
Eq O
. O
3 O
) O
for O
the O
mask Task
prediction Task
task Task
is O
a O
binary Method
logistic Method
regression Method
loss Method
over O
all O
RoWs O
: O
Thus O
, O
the O
classification Method
layer Method
of O
h Method
Ï† Method
consists O
of O
wÃ—h Method
classifiers Method
, O
each O
indicating O
whether O
a O
given O
pixel O
belongs O
to O
the O
object O
in O
the O
candidate O
window O
or O
not O
. O
Note O
that O
L O
mask O
is O
considered O
only O
for O
positive O
RoWs O
( O
i.e. O
with O
y O
n O
= O
1 O
) O
. O
Mask Method
representation Method
. O
In O
contrast O
to O
semantic Method
segmentation Method
methodsÃ  Method
- Method
la Method
FCN Method
[ O
reference O
] O
and O
Mask Method
R Method
- Method
CNN Method
[ O
reference O
] O
, O
which O
maintain O
explicit O
spatial O
information O
throughout O
the O
network O
, O
our O
approach O
follows O
the O
spirit O
of O
[ O
reference O
][ O
reference O
] O
and O
generates O
masks O
starting O
from O
a O
flattened Method
representation Method
of Method
the Method
object Method
. O
In O
particular O
, O
in O
our O
case O
this O
representation O
corresponds O
to O
one O
of O
the O
1Ã—1Ã—256 O
RoWs O
produced O
by O
the O
depth O
- O
wise O
cross O
- O
correlation O
between O
f O
Î¸ O
( O
z O
) O
and O
f O
Î¸ O
( O
x O
) O
. O
Importantly O
, O
the O
network Method
h Method
Ï† Method
of O
the O
segmentation Task
task Task
is O
composed O
of O
two O
1Ã—1 Method
convolutional Method
layers Method
, O
one O
with O
256 O
and O
the O
other O
with O
63 O
2 O
channels O
( O
Figure O
2 O
) O
. O
This O
allows O
every O
pixel Method
classifier Method
to O
utilise O
information O
contained O
in O
the O
entire O
RoW O
and O
thus O
to O
have O
a O
complete O
view O
of O
its O
corresponding O
candidate O
window O
in O
x O
, O
which O
is O
critical O
to O
disambiguate O
between O
instances O
that O
look O
like O
the O
target O
( O
e.g. O
last O
row O
of O
Figure O
5 O
) O
, O
also O
known O
as O
distractors O
[ O
reference O
] O
. O
With O
the O
aim O
of O
producing O
a O
more O
accurate O
object O
mask O
, O
we O
follow O
the O
strategy O
of O
[ O
reference O
] O
, O
which O
merges O
low O
and O
high O
resolution O
features O
using O
multiple O
refinement Method
modules Method
made O
of O
upsampling Method
layers Method
and O
skip O
connections O
. O
Further O
details O
can O
be O
found O
in O
the O
appendix O
A. O
Two O
variants O
. O
For O
our O
experiments O
, O
we O
augment O
the O
architectures O
of O
SiamFC Method
[ O
reference O
] O
and O
SiamRPN Method
[ O
reference O
] O
with O
our O
segmentation O
branch O
and O
the O
loss O
L O
mask O
, O
obtaining O
what O
we O
call O
the O
two O
- O
branch Method
and Method
three Method
- Method
branch Method
variants Method
of O
SiamMask Method
. O
These O
respectively O
optimise O
the O
multi O
- O
task O
losses O
L O
2B O
and O
L O
3B O
, O
defined O
as O
: O
We O
refer O
the O
reader O
to O
[ O
4 O
, O
Section O
2.2 O
] O
for O
L O
sim O
and O
to O
[ O
reference O
][ O
reference O
] O
for O
L O
box O
and O
L Metric
score Metric
. O
For O
L O
3B O
, O
a O
RoW O
is O
considered O
positive O
( O
y O
n O
= O
1 O
) O
if O
one O
of O
its O
anchor O
boxes O
has O
IOU O
with O
the O
ground O
- O
truth O
box O
of O
at O
least O
0.6 O
and O
negative O
( O
y O
n O
= O
âˆ’1 O
) O
otherwise O
. O
For O
L O
2B O
, O
we O
adopt O
the O
same O
strategy O
of O
[ O
reference O
] O
to O
define O
positive O
and O
negative O
samples O
. O
We O
did O
not O
search O
over O
the O
hyperparameters O
of O
Eq O
. O
4 O
and O
Eq O
. O
5 O
and O
simply O
set O
Î» O
1 O
= O
32 O
like O
in O
[ O
reference O
] O
and O
Î» O
2 O
= O
Î» O
3 O
= O
1 O
. O
The O
taskspecific O
branches O
for O
the O
box O
and O
score O
outputs O
are O
consti O
- O
tuted O
by O
two O
1Ã—1 O
convolutional Method
layers Method
. O
Figure O
2 O
illustrates O
the O
two O
variants O
of O
SiamMask Method
. O
Box Task
generation Task
. O
Note O
that O
, O
while O
VOS Metric
benchmarks Metric
require O
binary O
masks O
, O
typical O
tracking Method
benchmarks Method
such O
as O
VOT Task
[ O
reference O
] O
require O
a O
bounding O
box O
as O
final O
representation O
of O
the O
target O
object O
. O
We O
consider O
three O
different O
strategies O
to O
generate O
a O
bounding O
box O
from O
a O
binary O
mask O
( O
Figure O
3 O
) O
: O
( O
1 O
) O
axis O
- O
aligned O
bounding O
rectangle O
( O
Min Method
- Method
max Method
) O
, O
( O
2 O
) O
rotated Method
minimum Method
bounding Method
rectangle Method
( O
MBR Method
) O
and O
( O
3 O
) O
the O
optimisation Method
strategy Method
used O
for O
the O
automatic Task
bounding Task
box Task
generation Task
proposed O
in O
VOT Task
- O
2016 O
[ O
reference O
] O
( O
Opt O
) O
. O
We O
empirically O
evaluate O
these O
alternatives O
in O
Section O
4 O
( O
Table O
1 O
) O
. O
section O
: O
Implementation O
details O
Network Method
architecture Method
. O
For O
both O
our O
variants O
, O
we O
use O
a O
ResNet Method
- Method
50 Method
[ O
reference O
] O
until O
the O
final O
convolutional O
layer O
of O
the O
4 O
- O
th O
stage O
as O
our O
backbone O
f O
Î¸ O
. O
In O
order O
to O
obtain O
a O
high O
spatial O
resolution O
in O
deeper O
layers O
, O
we O
reduce O
the O
output O
stride O
to O
8 O
by O
using O
convolutions Method
with O
stride O
1 O
. O
Moreover O
, O
we O
increase O
the O
receptive O
field O
by O
using O
dilated Method
convolutions Method
[ O
reference O
] O
. O
In O
our O
model O
, O
we O
add O
to O
the O
shared O
backbone O
f O
Î¸ O
an O
unshared Method
adjust Method
layer Method
( O
1Ã—1 O
conv O
with O
256 O
outputs O
) O
. O
For O
simplicity O
, O
we O
omit O
it O
in O
Eq O
. O
1 O
. O
We O
describe O
the O
network Method
architectures Method
in O
more O
detail O
in O
Appendix O
A. O
Training O
. O
Like O
SiamFC Method
[ O
reference O
] O
, O
we O
use O
examplar O
and O
search O
image O
patches O
of O
127Ã—127 O
and O
255Ã—255 O
pixels O
respectively O
. O
During O
training O
, O
we O
randomly O
jitter O
examplar O
and O
search O
patches O
. O
Specifically O
, O
we O
consider O
random O
translations O
( O
up O
to O
Â±8 O
pixels O
) O
and O
rescaling O
( O
of O
2 O
Â±1 O
/ O
8 O
and O
2 O
section O
: O
Â±1 O
/ O
4 O
for O
examplar O
and O
search Task
respectively O
) O
. O
The O
network Method
backbone Method
is O
pre O
- O
trained O
on O
the O
ImageNet Task
- Task
1k Task
classification Task
task Task
. O
We O
use O
SGD Method
with O
a O
first O
warmup O
phase O
in O
which O
the O
learning Metric
rate Metric
increases O
linearly O
from O
10 O
âˆ’3 O
to O
5Ã—10 O
âˆ’3 O
for O
the O
first O
5 O
epochs O
and O
then O
descreases O
logarithmically O
until O
5Ã—10 O
âˆ’4 O
for O
15 O
more O
epochs O
. O
We O
train O
all O
our O
models O
using O
COCO Method
[ O
reference O
] O
, O
ImageNet O
- O
VID O
[ O
reference O
] O
and O
YouTube O
- O
VOS O
[ O
reference O
] O
. O
Inference O
. O
During O
tracking Task
, O
SiamMask Method
is O
simply O
evaluated O
once O
per O
frame O
, O
without O
any O
adaptation O
. O
In O
both O
our O
variants O
, O
we O
select O
the O
output O
mask O
using O
the O
location O
attaining O
the O
maximum O
score O
in O
the O
classification O
branch O
. O
Then O
, O
after O
having O
applied O
a O
per Method
- Method
pixel Method
sigmoid Method
, O
we O
binarise O
the O
output O
of O
the O
mask O
branch O
with O
a O
threshold O
0.5 O
. O
In O
the O
twobranch O
variant O
, O
for O
each O
video O
frame O
after O
the O
first O
one O
, O
we O
fit O
the O
output O
mask O
with O
the O
Min O
- O
max O
box O
and O
use O
it O
as O
reference O
to O
crop O
the O
next O
frame O
search O
region O
. O
Instead O
, O
in O
the O
three O
- O
branch O
variant O
, O
we O
find O
more O
effecitve O
to O
exploit O
the O
highest O
- O
scoring O
output O
of O
the O
box O
branch O
as O
reference O
. O
For O
the O
implementation O
of O
SiamMask Method
, O
we O
used O
PyTorch Method
. O
Code O
, O
pre O
- O
computed O
results O
and O
pre O
- O
trained O
models O
will O
be O
made O
available O
. O
section O
: O
Experiments O
In O
this O
section O
, O
we O
evaluate O
our O
approach O
on O
two O
related O
tasks O
: O
visual Task
object Task
tracking Task
( O
on O
VOT Task
- O
2016 O
and O
VOT Material
- Material
2018 Material
) O
and O
semi Task
- Task
supervised Task
video Task
object Task
segmentation Task
( O
on O
DAVIS O
- O
2016 O
and O
DAVIS O
- O
2017 O
) O
. O
We O
refer O
to O
our O
two O
- O
branch Method
and Method
three Method
- Method
branch Method
variants Method
with O
SiamMask Method
- O
2B O
and O
SiamMask Method
respectively O
. O
section O
: O
Evaluation O
for O
visual Task
object Task
tracking Task
Datasets O
and O
settings O
. O
We O
adopt O
two O
widely O
used O
benchmarks O
for O
the O
evaluation O
of O
the O
object Task
tracking Task
task Task
: O
VOT Task
- O
2016 O
[ O
reference O
] O
and O
VOT Material
- Material
2018 Material
[ O
reference O
] O
, O
both O
annotated O
with O
rotated O
bounding O
boxes O
. O
We O
use O
VOT Task
- O
2016 O
to O
conduct O
an O
experiment O
to O
understand O
how O
different O
types O
of O
representation O
affect O
the O
performance O
. O
For O
this O
first O
experiment O
, O
we O
use O
mean Metric
intersection Metric
over Metric
union Metric
( Metric
IOU Metric
) O
and O
Average Metric
Precision Metric
( O
AP Metric
) Metric
@{0.5 Metric
, O
0.7 O
} O
IOU Metric
. O
We O
then O
compare O
against O
the O
stateof O
- O
the O
- O
art O
on O
VOT Material
- Material
2018 Material
, O
using O
the O
official O
VOT Task
toolkit O
and O
the O
Expected Metric
Average Metric
Overlap Metric
( O
EAO Metric
) O
, O
a O
measure O
that O
considers O
both O
accuracy Metric
and O
robustness Metric
of O
a O
tracker O
[ O
reference O
] O
. O
How O
much O
does O
the O
object Method
representation Method
matter O
? O
Existing O
tracking Method
methods Method
typically O
predict O
axis O
- O
aligned O
bounding O
boxes O
with O
a O
fixed O
[ O
reference O
][ O
reference O
][ O
reference O
][ O
reference O
] O
or O
variable O
[ O
reference O
][ O
reference O
][ O
reference O
] O
aspect O
ratio O
. O
We O
are O
interested O
in O
understanding O
to O
which O
extent O
producing O
a O
per O
- O
frame O
binary O
mask O
can O
improve O
tracking Task
. O
In O
order O
to O
focus O
on O
representation Task
accuracy Task
, O
for O
this O
experiment O
only O
we O
ignore O
the O
temporal O
aspect O
and O
sample O
video O
frames O
at O
random O
. O
The O
approaches O
described O
in O
the O
following O
paragraph O
are O
tested O
on O
randomly O
cropped O
search O
patches O
( O
with O
random O
shifts O
within O
Â±16 O
pixels O
and O
scale O
deformations O
up O
to O
2 O
1Â±0.25 O
) O
from O
the O
sequences O
of O
VOT Task
- O
2016 O
. O
In O
Table O
1 O
, O
we O
compare O
our O
three O
- O
branch Method
variant Method
using O
the O
Min Method
- Method
max Method
, Method
MBR Method
and Method
Opt Method
approaches Method
( O
described O
at O
the O
end O
of O
Section O
3.2 O
and O
in O
Figure O
3 O
) O
. O
For O
perspective O
, O
we O
also O
report O
results O
for O
SiamFC Method
and Method
SiamRPN Method
as O
representative O
of O
the O
fixed Method
and Method
variable Method
aspect Method
- Method
ratio Method
approaches Method
, O
together O
with O
three O
oracles O
that O
have O
access O
to O
per O
- O
frame O
groundtruth O
information O
and O
serve O
as O
upper O
bound O
for O
the O
different O
representation Method
strategies Method
. O
( O
1 O
) O
The O
fixed O
aspect O
- O
ratio O
oracle O
uses O
the O
per O
- O
frame O
ground O
- O
truth O
area O
and O
center O
location O
, O
but O
fixes O
the O
aspect O
reatio O
to O
the O
one O
of O
the O
first O
frame O
mIOU Metric
( O
% O
) O
mAP@0 O
. O
[ O
reference O
] O
and O
produces O
an O
axis O
- O
aligned O
bounding O
box O
. O
( O
2 O
) O
The O
Minmax Method
oracle Method
uses O
the O
minimal O
enclosing O
rectangle O
of O
the O
rotated O
ground O
- O
truth O
bounding O
box O
to O
produce O
an O
axis O
- O
aligned O
bounding O
box O
. O
( O
3 O
) O
Finally O
, O
the O
MBR Method
oracle Method
uses O
the O
rotated O
minimum O
bounding O
rectangle O
of O
the O
ground O
- O
truth O
. O
Note O
that O
( O
1 O
) O
, O
( O
2 O
) O
and O
( O
3 O
) O
can O
be O
considered O
, O
respectively O
, O
the O
performance Metric
upper Metric
bounds Metric
for O
the O
representation Method
strategies Method
of O
SiamFC Method
, O
SiamRPN Method
and O
SiamMask Method
. O
Table O
1 O
shows O
that O
our O
method O
achieves O
the O
best O
mIOU Metric
, O
no O
matter O
the O
box Method
generation Method
strategy Method
used O
( O
Figure O
3 O
) O
. O
Albeit O
SiamMask Method
- O
Opt O
offers O
the O
highest O
IOU Metric
and Metric
mAP Metric
, O
it O
requires O
significant O
computational O
resources O
due O
to O
its O
slow O
optimisation Method
procedure Method
[ O
reference O
] O
. O
Instead O
, O
we O
adopt O
the O
MBR Method
strategy Method
( O
whose O
computational Metric
overhead Metric
is O
negligible O
) O
for O
our O
final O
object Task
tracking Task
evaluation Task
. O
SiamMask Method
- O
MBR O
achieves O
a O
mAP@0.5 Metric
IOU Metric
of O
85.4 O
, O
with O
a O
respective O
improvement O
of O
+ O
29 O
and O
+ O
9.2 O
points O
w.r.t O
. O
the O
two O
fully Method
- Method
convolutional Method
baselines Method
. O
Interestingly O
, O
the O
gap O
significantly O
widens O
when O
considering O
mAP Metric
at O
the O
higher O
accuracy O
regime O
of O
0.7 O
IOU Metric
: O
+ O
41.6 O
and O
+ O
18.4 O
respectively O
. O
Notably O
, O
our O
accuracy Metric
results O
are O
not O
far O
from O
the O
fixed O
aspectratio O
oracle O
. O
Moreover O
, O
comparing O
the O
upper Metric
bound Metric
performance Metric
represented O
by O
the O
oracles O
, O
it O
is O
possible O
to O
notice O
how O
, O
by O
simply O
changing O
the O
bounding Method
box Method
representation Method
, O
there O
is O
a O
great O
room O
of O
improvement O
( O
e.g. O
+ O
10.6 O
% O
mIOU Metric
improvement O
between O
the O
fixed Metric
aspect Metric
- Metric
ratio Metric
and O
the O
MBR Method
oracles Method
) O
. O
Overall O
, O
this O
study O
shows O
how O
the O
MBR Method
strategy Method
to O
obtain O
a O
rotated O
bounding O
box O
from O
a O
binary O
mask O
of O
the O
object O
offers O
a O
significant O
advantage O
over O
popular O
strategies O
that O
simply O
report O
axis O
- O
aligned O
bounding O
boxes O
. O
Results O
on O
VOT Material
- Material
2018 Material
. O
In O
Table O
2 O
we O
compare O
the O
two O
variants O
of O
SiamMask Method
against O
seven O
recently O
published O
state O
- O
of O
- O
the O
- O
art O
trackers O
on O
the O
VOT Material
- Material
2018 Material
benchmark Material
. O
Both O
achieve O
outstanding O
performance O
and O
run O
in O
real O
- O
time O
. O
In O
particular O
, O
our O
three O
- O
branch Method
variant Method
( O
SiamMask Method
) O
significantly O
outperforms O
the O
very O
recent O
and O
top O
performing O
DaSiamRPN Method
[ O
reference O
] O
. O
Even O
without O
box Method
regression Method
branch Method
, O
our O
simpler O
two O
- O
branch Method
variant Method
( O
SiamMask Method
- O
2B O
) O
achieves O
a O
high O
EAO Metric
of O
0.334 O
, O
which O
is O
in O
par O
with O
SA Method
Siam Method
R Method
[ O
reference O
] O
and O
superior O
to O
any O
other O
real Method
- Method
time Method
method Method
in O
the O
published O
lit O
- O
erature O
. O
SiamMask Method
provides O
a O
further O
relative O
gain O
of O
3.9 O
% O
, O
achieving O
a O
EAO Metric
of O
0.347 O
, O
which O
establishes O
a O
new O
stateof O
- O
the O
- O
art O
for O
real Task
- Task
time Task
tracking Task
. O
Our O
model O
is O
particularly O
strong O
under O
the O
accuracy Metric
metric Metric
, O
showing O
a O
significant O
advantage O
with O
respect O
to O
the O
Correlation Method
Filter Method
- Method
based Method
trackers Method
CSRDCF Method
[ O
reference O
] O
, O
STRCF Method
[ O
reference O
] O
and O
ECO O
[ O
reference O
] O
. O
This O
is O
not O
surprising O
, O
as O
SiamMask Method
relies O
on O
a O
richer O
object Method
representation Method
, O
as O
outlined O
in O
Table O
1 O
. O
Interestingly O
, O
similarly O
to O
us O
He O
et O
al O
. O
( O
SA O
Siam O
R O
) O
[ O
reference O
] O
are O
motivated O
to O
achieve O
a O
more O
accurate O
target Method
representation Method
. O
To O
this O
aim O
, O
they O
consider O
multiple O
rotated O
and O
rescaled O
bounding O
boxes O
as O
candidates O
. O
However O
, O
like O
SiamFC Method
[ O
reference O
] O
, O
SA Method
Siam Method
R Method
is O
still O
constrained O
to O
a O
fixed O
aspect O
- O
ratio O
bounding O
box O
. O
section O
: O
Evaluation O
for O
semi Task
- Task
supervised Task
VOS Task
In O
the O
following O
we O
show O
how O
, O
once O
trained O
, O
the O
same O
method O
can O
also O
be O
used O
for O
the O
task O
of O
video Task
object Task
segmentation Task
, O
achieving O
competitive O
performance O
without O
requiring O
any O
adaptation O
at O
test O
time O
. O
Importantly O
, O
differently O
to O
typical O
VOS Method
approaches Method
, O
ours O
can O
operate O
online O
, O
runs O
in O
real O
- O
time O
and O
only O
requires O
a O
simple O
bounding Method
box Method
initialisation Method
. O
Datasets O
and O
settings O
. O
We O
report O
the O
performance O
of O
SiamMask Method
on O
the O
popular O
DAVIS O
- O
2016 O
[ O
reference O
] O
and O
DAVIS O
- O
2017 O
[ O
reference O
] O
benchmarks O
. O
For O
both O
datasets O
, O
we O
use O
the O
official Metric
performance Metric
measures Metric
: O
the O
Jaccard Metric
index Metric
( O
J Metric
) O
to O
express O
region Metric
similarity Metric
and O
the O
F Metric
- Metric
measure Metric
( O
F Metric
) O
to O
express O
contour Metric
accuracy Metric
. O
For O
each O
measure O
C O
âˆˆ O
{ O
J O
, O
F O
} O
, O
three O
statistics O
are O
considered O
: O
mean Metric
C Metric
M Metric
, O
recall Metric
C Metric
O Metric
, O
and O
decay Metric
C Metric
D Metric
, O
which O
informs O
us O
about O
the O
gain O
/ O
loss O
of O
performance O
over O
time O
[ O
reference O
] O
. O
To O
initialise O
SiamMask Method
, O
we O
extract O
the O
axis O
- O
aligned O
bounding O
box O
( O
Min Method
- Method
max Method
strategy Method
, O
Figure O
3 O
) O
from O
the O
mask O
provided O
in O
the O
first O
frame O
. O
Similarly O
to O
most O
VOS Method
methods Method
, O
in O
case O
of O
multiple O
objects O
in O
the O
same O
video O
( O
DAVIS O
- O
2017 O
) O
we O
simply O
perform O
multiple O
inferences O
. O
Results O
on O
DAVIS O
- O
2016 O
and O
2017 O
. O
In O
the O
semisupervised Task
setting Task
, O
VOS Method
methods Method
are O
initialised O
with O
a O
binary O
mask O
[ O
reference O
] O
Table O
3 O
. O
Results O
on O
DAVIS O
2016 O
( O
validation O
set O
) O
. O
FT O
and O
M O
respectively O
denote O
if O
the O
method O
requires O
fine Task
- Task
tuning Task
and O
whether O
it O
is O
initialised O
with O
a O
mask O
( O
) O
or O
a O
bounding O
box O
( O
) O
. O
Speed Metric
is O
measured O
in O
frames O
per O
second O
( O
fps O
) O
. O
tionally O
intensive O
techniques O
at O
test O
time O
such O
as O
finetuning O
[ O
reference O
][ O
reference O
][ O
reference O
][ O
reference O
] O
, O
data Method
augmentation Method
[ O
reference O
][ O
reference O
] O
, O
inference O
on O
MRF Method
/ Method
CRF Method
[ O
reference O
][ O
reference O
][ O
reference O
][ O
reference O
] O
and O
optical Method
flow Method
[ O
reference O
][ O
reference O
][ O
reference O
][ O
reference O
][ O
reference O
] O
. O
As O
a O
consequence O
, O
it O
is O
not O
uncommon O
for O
VOS Method
techniques Method
to O
require O
several O
minutes O
to O
process O
the O
short O
sequences O
of O
DAVIS O
. O
Clearly O
, O
these O
strategies O
make O
the O
online Task
applicability Task
( O
which O
is O
our O
focus O
) O
impossible O
. O
For O
this O
reason O
, O
in O
our O
comparison O
( O
Table O
3 O
and O
4 O
, O
Figure O
4 O
) O
we O
mainly O
concentrate O
on O
fast O
state O
- O
of O
- O
the O
- O
art O
approaches O
. O
Table O
3 O
shows O
how O
SiamMask Method
can O
be O
considered O
as O
a O
strong O
baseline O
for O
online Task
VOS Task
. O
First O
, O
it O
is O
almost O
two O
orders O
of O
magnitude O
faster O
than O
accurate O
approaches O
such O
as O
OnAVOS Method
[ O
reference O
] O
or O
SFL Method
[ O
reference O
] O
. O
Second O
, O
it O
is O
competitive O
with O
recent O
VOS Method
methods Method
that O
do O
not O
employ O
fine Method
- Method
tuning Method
, O
while O
being O
four O
times O
more O
efficient O
than O
the O
fastest O
ones O
( O
i.e. O
OSMN Method
[ O
reference O
] O
and O
RGMP Method
[ O
reference O
] O
) O
. O
Interestingly O
, O
we O
note O
that O
SiamMask Method
achieves O
the O
best O
decay Metric
[ O
reference O
] O
for O
region Metric
similarity Metric
( O
J Metric
D Metric
, O
) O
and O
contour Metric
accuracy Metric
( O
F Metric
D Metric
) O
on O
both O
DAVIS O
- O
2016 O
and O
DAVIS O
- O
2017 O
. O
This O
suggests O
that O
our O
method O
is O
robust O
over O
time O
and O
thus O
it O
is O
indicated O
for O
particularly O
long O
sequences O
. O
Table O
5 O
. O
Ablation O
studies O
on O
VOT Material
- Material
2018 Material
and O
DAVIS O
- O
2016 O
. O
Figure O
4 O
offers O
a O
clearer O
overview O
of O
the O
tradeoff O
between O
segmentation Metric
accuracy Metric
( O
as O
mean Metric
IOU Metric
, O
which O
corresponds O
to O
J O
M O
) O
and O
speed Metric
( O
in O
frames O
per O
second O
) O
. O
Among O
the O
methods O
of O
Table O
3 O
that O
do O
not O
fine O
tune O
the O
model O
online O
, O
the O
recently O
proposed O
FAVOS Method
[ O
reference O
] O
obtains O
the O
best O
results O
. O
However O
, O
it O
combines O
several O
independent O
modules O
( O
a O
part Method
- Method
based Method
tracker Method
, O
a O
segmentation Method
network Method
and O
a O
similarity Method
- Method
based Method
aggregation Method
module Method
) O
, O
while O
SiamMask Method
is O
only O
evaluated O
with O
a O
single O
model O
and O
it O
is O
almost O
50 O
times O
faster O
. O
Qualitative O
results O
of O
SiamMask Method
for O
both O
VOT Task
and O
DAVIS O
sequences O
are O
shown O
in O
Figure O
5 O
, O
10 O
and O
11 O
. O
Despite O
the O
high O
speed O
, O
SiamMask Method
produces O
accurate O
segmentation O
masks O
even O
in O
presence O
of O
distractors O
. O
section O
: O
Further O
analysis O
In O
this O
section O
, O
we O
illustrate O
ablation Task
studies Task
, O
failure O
cases O
and O
timings O
of O
our O
methods O
. O
Network Method
architecture Method
. O
In O
Table O
5 O
, O
AN O
and O
RN O
denote O
whether O
we O
use O
AlexNet O
or O
ResNet O
- O
50 O
as O
the O
shared O
backbone O
f O
Î¸ O
( O
Figure O
2 O
) O
, O
while O
with O
" O
w O
/ O
o O
R O
" O
we O
mean O
that O
the O
method O
does O
not O
use O
the O
refinement Method
strategy Method
of O
Pinheiro O
et O
al O
. O
[ O
reference O
] O
. O
From O
the O
results O
of O
Table O
5 O
, O
it O
is O
possible O
to O
make O
several O
observations O
. O
( O
1 O
) O
The O
first O
set O
of O
rows O
shows O
that O
, O
by O
simply O
updating O
the O
architecture Method
of Method
f Method
Î¸ Method
, O
it O
is O
possible O
to O
achieve O
an O
important O
performance O
improvement O
. O
However O
, O
this O
comes O
at O
the O
cost O
of O
speed Metric
, O
especially O
for O
SiamRPN Method
. O
( O
2 O
) O
SiamMask Method
- O
2B O
and O
SiamMask Method
considerably O
improve O
over O
their O
baselines O
( O
with O
same O
f O
Î¸ O
) O
SiamFC Method
and O
SiamRPN Method
. O
With O
a O
relative O
+ O
33 O
% O
in O
EAO Metric
, O
the O
gap O
of O
the O
two Method
- Method
branch Method
variant Method
is O
particularly O
important O
. O
( O
3 O
) O
Interestingly O
, O
the O
refinement Method
approach Method
of O
Pinheiro O
et O
al O
. O
[ O
reference O
] O
is O
very O
important O
for O
the O
contour Metric
accuracy Metric
F Metric
M Metric
, O
but O
less O
so O
for O
the O
other O
metrics O
. O
Multi Task
- Task
task Task
learning Task
. O
We O
conducted O
two O
further O
experiments O
to O
disentangle O
the O
effect O
of O
multi Task
- Task
task Task
learning Task
[ O
reference O
][ O
reference O
] O
to O
the O
one O
of O
using O
the O
MBR O
box O
( O
from O
a O
binary O
mask O
) O
as O
representation O
for O
the O
target O
object O
instead O
of O
a O
traditional O
axis O
- O
aligned O
bounding O
box O
. O
Results O
are O
reported O
in O
Table O
5 O
. O
To O
achieve O
this O
, O
we O
modified O
the O
two O
variants O
of O
SiamMask Method
so O
that O
, O
respectively O
, O
they O
report O
an O
axis O
- O
aligned O
bounding O
box O
from O
the O
score O
branch O
( O
SiamMask Method
- Method
2B Method
- Method
box Method
) O
or O
the O
box O
branch O
( O
SiamMask Method
- Method
box Method
) O
. O
Therefore O
, O
despite O
having O
been O
trained O
, O
the O
mask O
branch O
is O
not O
used O
during O
inference Task
. O
We O
can O
observe O
how O
both O
variants O
obtain O
an O
improvement O
with O
respect O
to O
their O
simpler O
counterparts O
: O
from O
0.251 O
to O
0.265 O
EAO Metric
for O
the O
two O
- O
branch O
and O
from O
0.329 O
to O
0.331 O
for O
the O
three O
- O
branch O
. O
However O
, O
for O
both O
variants O
the O
gap O
between O
SiamMask Method
- Method
box Method
and O
SiamMask Method
is O
higher O
. O
This O
implies O
that O
, O
despite O
being O
meaningful O
, O
the O
improvement O
brought O
simply O
by O
training O
multiple O
related O
tasks O
together O
is O
less O
relevant O
than O
the O
type O
of O
target O
object Method
representation Method
used O
. O
Timing O
. O
SiamMask Method
operates O
online O
without O
any O
adaptation O
to O
the O
test O
sequence O
. O
On O
a O
single O
NVIDIA Method
Titan Method
X Method
GPU Method
, O
we O
measured O
an O
average Metric
speed Metric
of O
35 O
and O
40 O
frames O
per O
second O
, O
respectively O
for O
the O
two O
- O
branch O
and O
three Method
- Method
branch Method
variants Method
. O
Note O
that O
the O
highest O
computational Metric
burden Metric
comes O
from O
the O
feature Method
extractor Method
f O
Î¸ O
. O
For O
this O
reason O
, O
changing O
architecture O
is O
a O
convenient O
way O
to O
obtain O
different O
speed O
/ O
performance O
trade O
- O
offs O
. O
Failure O
cases O
. O
Finally O
, O
we O
discuss O
two O
scenarios O
in O
which O
SiamMask Method
fails O
: O
motion O
blur O
and O
" O
non O
- O
object O
" O
pattern O
( O
Figure O
6 O
) O
. O
Despite O
being O
different O
in O
nature O
, O
these O
two O
cases O
arguably O
arise O
from O
the O
complete O
lack O
of O
similar O
training O
samples O
in O
a O
training O
set O
such O
as O
YouTube O
- O
VOS O
[ O
reference O
] O
, O
which O
is O
focused O
on O
objects O
that O
can O
be O
unambiguously O
segmented O
from O
the O
foreground O
. O
section O
: O
Conclusion O
We O
introduced O
SiamMask Method
, O
a O
simple O
approach O
that O
enables O
fully Method
- Method
convolutional Method
Siamese Method
trackers Method
to O
produce O
classagnostic O
binary O
segmentation O
masks O
of O
the O
target O
object O
. O
We O
show O
how O
it O
can O
be O
applied O
with O
success O
to O
both O
tasks O
of O
visual Task
object Task
tracking Task
and O
semi Task
- Task
supervised Task
video Task
object Task
segmentation Task
, O
showing O
better O
accuracy Metric
than O
state O
- O
of O
- O
the O
- O
art O
trackers O
and O
, O
at O
the O
same O
time O
, O
the O
fastest O
speed O
among O
VOS Method
methods Method
. O
The O
two O
variants O
of O
SiamMask Method
we O
proposed O
are O
initialised O
with O
a O
simple O
bounding Method
box Method
, O
operate O
online O
, O
run O
in O
real O
- O
time O
and O
do O
not O
require O
any O
adaptation O
to O
the O
test O
sequence O
. O
We O
hope O
that O
our O
work O
will O
inspire O
further O
studies O
that O
consider O
the O
two O
problems O
of O
visual Task
object Task
tracking Task
and O
video Task
object Task
segmentation Task
together O
. O
section O
: O
A. O
Network Method
architecture Method
details O
Network O
backbone O
. O
Table O
6 O
illustrates O
the O
details O
of O
our O
backbone Method
architecture Method
( O
f O
Î¸ O
in O
the O
main O
paper O
) O
. O
For O
both O
variants O
, O
we O
use O
a O
ResNet Method
- Method
50 Method
[ O
reference O
] O
until O
the O
final O
convolutional Method
layer Method
of O
the O
4 O
- O
th O
stage O
. O
In O
order O
to O
obtain O
a O
higher O
spatial O
resolution O
in O
deep O
layers O
, O
we O
reduce O
the O
output O
stride O
to O
8 O
by O
using O
convolutions Method
with O
stride O
1 O
. O
Moreover O
, O
we O
increase O
the O
receptive O
field O
by O
using O
dilated Method
convolutions Method
[ O
reference O
] O
. O
Specifically O
, O
we O
set O
the O
stride O
to O
1 O
and O
the O
dilation O
rate O
to O
2 O
in O
the O
3Ã—3 O
conv O
layer O
of O
conv4 Method
1 O
. O
Differently O
to O
the O
original O
ResNet O
- O
50 O
, O
there O
is O
no O
downsampling O
in O
conv4 O
x. O
We O
also O
add O
to O
the O
backbone O
an O
adjust Method
layer Method
( O
a O
1Ã—1 Method
convolutional Method
layer Method
with O
256 O
output O
channels O
) O
. O
Examplar O
and O
search O
patches O
share O
the O
network O
's O
parameters O
from O
conv1 O
to O
conv4 O
x O
, O
while O
the O
parameters O
of O
the O
adjust Method
layer Method
are O
not O
shared O
. O
The O
output O
features O
of O
the O
adjust Method
layer Method
are O
then O
depth O
- O
wise O
cross O
- O
correlated O
, O
resulting O
a O
feature O
map O
of O
size O
17 O
Ã— O
17 O
. O
Network O
heads O
. O
The O
network Method
architecture Method
of O
the O
branches O
of O
both O
variants O
are O
shows O
in O
Table O
7 O
Mask Method
refinement Method
module Method
. O
With O
the O
aim O
of O
producing O
a O
more O
accurate O
object O
mask O
, O
we O
follow O
the O
strategy O
of O
[ O
reference O
] O
, O
which O
merges O
low O
and O
high O
resolution O
features O
using O
multiple O
refinement Method
modules Method
made O
of O
upsampling Method
layers Method
and O
skip O
connections O
. O
Figure O
9 O
illustrates O
how O
a O
mask O
is O
generated O
with O
stacked Method
refinement Method
modules Method
. O
Figure O
7 O
gives O
an O
example O
of O
refinement Method
module Method
U O
3 O
. O
section O
: O
B. O
Further O
qualitative O
results O
Different O
masks O
at O
different O
locations O
. O
Our O
model O
generates O
a O
mask O
for O
each O
RoW. O
During O
inference Task
, O
we O
rely O
on O
the O
score O
branch O
to O
select O
the O
final O
output O
mask O
( O
using O
the O
location O
attaining O
the O
maximum O
score O
) O
. O
The O
example O
of O
Figure O
8 O
illustrates O
the O
multiple O
output O
masks O
produced O
by O
the O
mask O
branch O
, O
each O
corresponding O
to O
a O
different O
RoW. O
Benchmark O
sequences O
. O
More O
qualitative O
results O
for O
VOT Task
and O
DAVIS Task
sequences Task
are O
shown O
in O
Figure O
10 O
and O
11 O
. O
ResNet O
- O
50 O
Figure O
11 O
. O
Further O
qualitative O
results O
of O
our O
method O
on O
sequences O
from O
the O
semi Task
- Task
supervised Task
video Task
object Task
segmentation Task
benchmarks O
DAVIS O
- O
2016 O
[ O
reference O
] O
and O
DAVIS O
- O
2017 O
[ O
reference O
] O
. O
section O
: O
