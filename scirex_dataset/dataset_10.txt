document O
: O
DensePose Task
: O
Dense Task
Human Task
Pose Task
Estimation Task
In O
The O
Wild O
In O
this O
work O
, O
we O
establish O
dense O
correspondences O
between O
an O
RGB O
image O
and O
a O
surface Method
- Method
based Method
representation Method
of Method
the Method
human Method
body Method
, O
a O
task O
we O
refer O
to O
as O
dense Task
human Task
pose Task
estimation Task
. O
We O
first O
gather O
dense O
correspondences O
for O
50 O
K O
persons O
appearing O
in O
the O
COCO Material
dataset Material
by O
introducing O
an O
efficient O
annotation Method
pipeline Method
. O
We O
then O
use O
our O
dataset O
to O
train O
CNN Method
- Method
based Method
systems Method
that O
deliver O
dense Task
correspondence Task
‘ O
in O
the O
wild O
’ O
, O
namely O
in O
the O
presence O
of O
background O
, O
occlusions O
and O
scale O
variations O
. O
We O
improve O
our O
training O
set O
’s O
effectiveness O
by O
training O
an O
‘ O
inpainting Method
’ Method
network Method
that O
can O
fill O
in O
missing O
ground O
truth O
values O
, O
and O
report O
clear O
improvements O
with O
respect O
to O
the O
best O
results O
that O
would O
be O
achievable O
in O
the O
past O
. O
We O
experiment O
with O
fully Method
- Method
convolutional Method
networks Method
and O
region Method
- Method
based Method
models Method
and O
observe O
a O
superiority O
of O
the O
latter O
; O
we O
further O
improve O
accuracy Metric
through O
cascading O
, O
obtaining O
a O
system O
that O
delivers O
highly O
- O
accurate O
results O
in O
real O
time O
. O
Supplementary O
materials O
and O
videos O
are O
provided O
on O
the O
project O
page O
. O
section O
: O
Introduction O
This O
work O
aims O
at O
pushing O
further O
the O
envelope O
of O
human Task
understanding Task
in O
images O
by O
establishing O
dense Task
correspondences Task
from O
a O
2D O
image O
to O
a O
3D Method
, Method
surface Method
- Method
based Method
representation Method
of Method
the Method
human Method
body Method
. O
We O
can O
understand O
this O
task O
as O
involving O
several O
other O
problems O
, O
such O
as O
object Task
detection Task
, O
pose Task
estimation Task
, O
part Task
and Task
instance Task
segmentation Task
either O
as O
special O
cases O
or O
prerequisites O
. O
Addressing O
this O
task O
has O
applications O
in O
problems O
that O
require O
going O
beyond O
plain Task
landmark Task
localization Task
, O
such O
as O
graphics Task
, O
augmented Task
reality Task
, O
or O
human Task
- Task
computer Task
interaction Task
, O
and O
could O
also O
be O
a O
stepping O
stone O
towards O
general O
3D Task
- Task
based Task
object Task
understanding Task
. O
The O
task O
of O
establishing O
dense Task
correspondences Task
from O
an O
image O
to O
a O
surface Method
- Method
based Method
model Method
has O
been O
addressed O
mostly O
in O
the O
setting O
where O
a O
depth O
sensor O
is O
available O
, O
as O
in O
the O
Vitruvian O
manifold O
of O
, O
metric Method
regression Method
forests Method
, O
or O
the O
more O
recent O
dense Method
point Method
cloud Method
correspondence Method
of O
. O
By O
contrast O
, O
in O
our O
case O
we O
consider O
a O
single O
RGB O
image O
as O
input O
, O
based O
on O
which O
we O
establish O
a O
correspondence O
between O
surface O
points O
and O
image O
pixels O
. O
Several O
other O
works O
have O
recently O
aimed O
at O
recovering O
dense Task
correspondences Task
between O
pairs O
or O
sets O
of O
RGB O
images O
in O
an O
unsupervised Task
setting Task
. O
More O
recently O
, O
used O
the O
equivariance Method
principle Method
in O
order O
to O
align O
sets O
of O
images O
to O
a O
common O
coordinate O
system O
, O
while O
following O
the O
general O
idea O
of O
groupwise Task
image Task
alignment Task
, O
e.g. O
. O
While O
these O
works O
are O
aiming O
at O
general O
categories O
, O
our O
work O
is O
focused O
on O
arguably O
the O
most O
important O
visual O
category O
, O
humans O
. O
For O
humans O
one O
can O
simplify O
the O
task O
by O
exploiting O
parametric Method
deformable Method
surface Method
models Method
, O
such O
as O
the O
Skinned Method
Multi Method
- Method
Person Method
Linear Method
( Method
SMPL Method
) Method
model Method
of O
, O
or O
the O
more O
recent O
Adam Method
model Method
of O
obtained O
through O
carefully O
controlled Method
3D Method
surface Method
acquisition Method
. O
Turning O
to O
the O
task O
of O
image Task
- Task
to Task
- Task
surface Task
mapping Task
, O
in O
, O
the O
authors O
propose O
a O
two O
- O
stage O
method O
of O
first O
detecting Task
human Task
landmarks Task
through O
a O
CNN Method
and O
then O
fitting O
a O
parametric Method
deformable Method
surface Method
model Method
to O
the O
image O
through O
iterative Method
minimization Method
. O
In O
parallel O
to O
our O
work O
, O
develop O
the O
method O
of O
to O
operate O
in O
an O
end O
- O
to O
- O
end O
fashion O
, O
incorporating O
the O
iterative Method
reprojection Method
error Method
minimization Method
as O
a O
module O
of O
a O
deep Method
network Method
that O
recovers O
3D O
camera O
pose O
and O
the O
low O
- O
dimensional O
body O
parametrization O
. O
Our O
methodology O
differs O
from O
all O
these O
works O
in O
that O
we O
take O
a O
full O
- O
blown O
supervised Method
learning Method
approach Method
and O
gather O
ground O
- O
truth O
correspondences O
between O
images O
and O
a O
detailed O
, O
accurate O
parametric Method
surface Method
model Method
of O
the O
human O
body O
: O
rather O
than O
using O
the O
SMPL Method
model Method
at O
test O
time O
we O
only O
use O
it O
as O
a O
means O
of O
defining O
our O
problem O
during O
training Task
. O
Our O
approach O
can O
be O
understood O
as O
the O
next O
step O
in O
the O
line O
of O
works O
on O
extending O
the O
standard O
for O
humans O
in O
. O
Human Task
part Task
segmentation Task
masks Task
have O
been O
provided O
in O
the O
Fashionista O
, O
PASCAL O
- O
Parts O
, O
and O
Look O
- O
Into O
- O
People O
( O
LIP O
) O
datasets O
; O
these O
can O
be O
understood O
as O
providing O
a O
coarsened O
version O
of O
image Task
- Task
to Task
- Task
surface Task
correspondence Task
, O
where O
rather O
than O
continuous O
coordinates O
one O
predicts O
discretized O
part O
labels O
. O
Surface Method
- Method
level Method
supervision Method
was O
only O
recently O
introduced O
for O
synthetic O
images O
in O
, O
while O
in O
a O
dataset O
of O
8515 O
images O
is O
annotated O
with O
keypoints O
and O
semi O
- O
automated Method
fits Method
of Method
3D Method
models Method
to O
images O
. O
In O
this O
work O
instead O
of O
compromising O
the O
extent O
and O
realism O
of O
our O
training O
set O
we O
introduce O
a O
novel O
annotation Method
pipeline Method
that O
allows O
us O
to O
gather O
ground O
- O
truth O
correspondences O
for O
50 O
K O
images O
of O
the O
COCO Material
dataset Material
, O
yielding O
our O
new O
DensePose Material
- Material
COCO Material
dataset O
. O
Our O
work O
is O
closest O
in O
spirit O
to O
the O
recent O
DenseReg Method
framework Method
, O
where O
CNNs Method
were O
trained O
to O
successfully O
establish O
dense O
correspondences O
between O
a O
3D Method
model Method
and O
images O
‘ O
in O
the O
wild O
’ O
. O
That O
work O
focused O
mainly O
on O
faces O
, O
and O
evaluated O
their O
results O
on O
datasets O
with O
moderate O
pose O
variability O
. O
Here O
, O
however O
, O
we O
are O
facing O
new O
challenges O
, O
due O
to O
the O
higher O
complexity O
and O
flexibility O
of O
the O
human O
body O
, O
as O
well O
as O
the O
larger O
variation O
in O
poses O
. O
We O
address O
these O
challenges O
by O
designing O
appropriate O
architectures O
, O
as O
described O
in O
Sec O
. O
[ O
reference O
] O
, O
which O
yield O
substantial O
improvements O
over O
a O
DenseReg Method
- Method
type Method
fully Method
convolutional Method
architecture Method
. O
By O
combining O
our O
approach O
with O
the O
recent O
Mask Method
- Method
RCNN Method
system Method
of O
we O
show O
that O
a O
discriminatively Method
trained Method
model Method
can O
recover O
highly O
- O
accurate O
correspondence O
fields O
for O
complex O
scenes O
involving O
tens O
of O
persons O
with O
real Metric
- Metric
time Metric
speed Metric
: O
on O
a O
GTX O
1080 O
GPU Method
our O
system O
operates O
at O
20 O
- O
26 O
frames O
per O
second O
for O
a O
image O
or O
4 O
- O
5 O
frames O
per O
second O
for O
a O
image O
. O
Our O
contributions O
can O
be O
summarized O
in O
three O
points O
. O
Firstly O
, O
as O
described O
in O
Sec O
. O
[ O
reference O
] O
, O
we O
introduce O
the O
first O
manually O
- O
collected O
ground O
truth O
dataset O
for O
the O
task O
, O
by O
gathering O
dense O
correspondences O
between O
the O
SMPL Method
model Method
and O
persons O
appearing O
in O
the O
COCO Material
dataset Material
. O
This O
is O
accomplished O
through O
a O
novel O
annotation Method
pipeline Method
that O
exploits O
3D O
surface O
information O
during O
annotation Task
. O
Secondly O
, O
as O
described O
in O
Sec O
. O
[ O
reference O
] O
, O
we O
use O
the O
resulting O
dataset O
to O
train O
CNN Method
- Method
based Method
systems Method
that O
deliver O
dense Task
correspondence Task
‘ O
in O
the O
wild O
’ O
, O
by O
regressing O
body O
surface O
coordinates O
at O
any O
image O
pixel O
. O
We O
experiment O
with O
both O
fully Method
- Method
convolutional Method
architectures Method
, O
relying O
on O
Deeplab Method
, O
and O
also O
with O
region Method
- Method
based Method
systems Method
, O
relying O
on O
Mask Method
- Method
RCNN Method
, O
observing O
a O
superiority O
of O
region Method
- Method
based Method
models Method
over O
fully Method
- Method
convolutional Method
networks Method
. O
We O
also O
consider O
cascading O
variants O
of O
our O
approach O
, O
yielding O
further O
improvements O
over O
existing O
architectures O
. O
Thirdly O
, O
we O
explore O
different O
ways O
of O
exploiting O
our O
constructed O
ground O
truth O
information O
. O
Our O
supervision O
signal O
is O
defined O
over O
a O
randomly O
chosen O
subset O
of O
image O
pixels O
per O
training O
sample O
. O
We O
use O
these O
sparse O
correspondences O
to O
train O
a O
‘ O
teacher Method
’ Method
network Method
that O
can O
‘ O
inpaint O
’ O
the O
supervision O
signal O
in O
the O
rest O
of O
the O
image O
domain O
. O
Using O
this O
inpainted O
signal O
results O
in O
clearly O
better O
performance O
when O
compared O
to O
either O
sparse O
points O
, O
or O
any O
other O
existing O
dataset O
, O
as O
shown O
experimentally O
in O
Sec O
. O
[ O
reference O
] O
. O
Our O
experiments O
indicate O
that O
dense Task
human Task
pose Task
estimation Task
is O
to O
a O
large O
extent O
feasible O
, O
but O
still O
has O
space O
for O
improvement O
. O
We O
conclude O
our O
paper O
with O
some O
qualitative O
results O
and O
directions O
that O
show O
the O
potential O
of O
the O
method O
. O
We O
will O
make O
code O
and O
data O
publicly O
available O
from O
our O
project O
’s O
webpage O
, O
. O
section O
: O
COCO Material
- Material
DensePose Material
Dataset Material
Gathering O
rich O
, O
high O
- O
quality O
training O
sets O
has O
been O
a O
catalyst O
for O
progress O
in O
the O
classification Task
, Task
detection Task
and Task
segmentation Task
tasks Task
. O
There O
currently O
exists O
no O
manually O
collected O
ground O
- O
truth O
for O
dense Task
human Task
pose Task
estimation Task
for O
real O
images O
. O
The O
works O
of O
and O
can O
be O
used O
as O
surrogates O
, O
but O
as O
we O
show O
in O
Sec O
. O
[ O
reference O
] O
provide O
worse O
supervision O
. O
In O
this O
Section O
we O
introduce O
our O
COCO Material
- Material
DensePose Material
dataset Material
, O
alongside O
with O
evaluation Metric
measures Metric
that O
allow O
us O
to O
quantify O
progress O
in O
the O
task O
in O
Sec O
. O
[ O
reference O
] O
. O
We O
have O
gathered O
annotations O
for O
50 O
K O
humans O
, O
collecting O
more O
then O
5 O
million O
manually O
annotated O
correspondences O
. O
We O
start O
with O
a O
presentation O
of O
our O
annotation Method
pipeline Method
, O
since O
this O
required O
several O
design O
choices O
that O
may O
be O
more O
generally O
useful O
for O
3D Task
annotation Task
. O
We O
then O
turn O
to O
an O
analysis O
of O
the O
accuracy Metric
of O
the O
gathered O
ground Metric
- Metric
truth Metric
, O
alongside O
with O
the O
resulting O
performance O
measures O
used O
to O
assess O
the O
different O
methods O
. O
subsection O
: O
Annotation Method
System Method
In O
this O
work O
, O
we O
involve O
human Task
annotators Task
to O
establish O
dense O
correspondences O
from O
2D O
images O
to O
surface Method
- Method
based Method
representations Method
of Method
the Method
human Method
body Method
. O
If O
done O
naively O
, O
this O
would O
require O
‘ O
hunting O
vertices O
’ O
for O
every O
2D O
image O
point O
, O
by O
manipulating O
a O
surface O
through O
rotations O
- O
which O
can O
be O
frustratingly O
inefficient O
. O
Instead O
, O
we O
construct O
an O
annotation Method
pipeline Method
through O
which O
we O
can O
efficiently O
gather O
annotations O
for O
image Task
- Task
to Task
- Task
surface Task
correspondence Task
. O
As O
shown O
in O
Fig O
. O
[ O
reference O
] O
, O
in O
the O
first O
stage O
we O
ask O
annotators O
to O
delineate O
regions O
corresponding O
to O
visible O
, O
semantically O
defined O
body O
parts O
. O
These O
include O
Head O
, O
Torso O
, O
Lower O
/ O
Upper O
Arms O
, O
Lower O
/ O
Upper O
Legs O
, O
Hands O
and O
Feet O
. O
In O
order O
to O
use O
simplify O
the O
UV Method
parametrization Method
we O
design O
the O
parts O
to O
be O
isomorphic O
to O
a O
plane O
, O
partitioning O
the O
limbs O
and O
torso O
into O
lower O
- O
upper O
and O
frontal O
- O
back O
parts O
. O
For O
head O
, O
hands O
and O
feet O
, O
we O
use O
the O
manually O
obtained O
UV O
fields O
provided O
in O
the O
SMPL Method
model Method
. O
For O
the O
rest O
of O
the O
parts O
we O
obtain O
the O
unwrapping Method
via O
multi Method
- Method
dimensional Method
scaling Method
applied O
to O
pairwise O
geodesic O
distances O
. O
The O
UV O
fields O
for O
the O
resulting O
24 O
parts O
are O
visualized O
in O
Fig O
. O
[ O
reference O
] O
( O
right O
) O
. O
We O
instruct O
the O
annotators O
to O
estimate O
the O
body O
part O
behind O
the O
clothes O
, O
so O
that O
for O
instance O
wearing O
a O
large O
skirt O
would O
not O
complicate O
the O
subsequent O
annotation Task
of Task
correspondences Task
. O
In O
the O
second O
stage O
we O
sample O
every O
part O
region O
with O
a O
set O
of O
roughly O
equidistant O
points O
obtained O
via O
k Method
- Method
means Method
and O
request O
the O
annotators O
to O
bring O
these O
points O
in O
correspondence O
with O
the O
surface O
. O
The O
number O
of O
sampled O
points O
varies O
based O
on O
the O
size O
of O
the O
part O
and O
the O
maximum O
number O
of O
sampled O
points O
per O
part O
is O
14 O
. O
In O
order O
to O
simplify O
this O
task O
we O
‘ O
unfold O
’ O
the O
part O
surface O
by O
providing O
six O
pre O
- O
rendered O
views O
of O
the O
same O
body O
part O
and O
allow O
the O
user O
to O
place O
landmarks O
on O
any O
of O
them O
Fig O
. O
[ O
reference O
] O
. O
This O
allows O
the O
annotator O
to O
choose O
the O
most O
convenient O
point O
of O
view O
by O
selecting O
one O
among O
six O
options O
instead O
of O
manually O
rotating O
the O
surface O
. O
As O
the O
user O
indicates O
a O
point O
on O
any O
of O
the O
rendered O
part O
views O
, O
its O
surface O
coordinates O
are O
used O
to O
simultaneously O
show O
its O
position O
on O
the O
remaining O
views O
– O
this O
gives O
a O
global O
overview O
of O
the O
correspondence O
. O
The O
image O
points O
are O
presented O
to O
the O
annotator O
in O
a O
horizontal O
/ O
vertical O
succession O
, O
which O
makes O
it O
easier O
to O
deliver O
geometrically O
consistent O
annotations O
by O
avoiding O
self O
- O
crossings O
of O
the O
surface O
. O
This O
two O
- O
stage O
annotation Method
process Method
has O
allowed O
us O
to O
very O
efficiently O
gather O
highly O
accurate O
correspondences O
. O
If O
we O
quantify O
the O
complexity Metric
of O
the O
annotation Task
task Task
in O
terms O
of O
the O
time O
it O
takes O
to O
complete O
it O
, O
we O
have O
seen O
that O
the O
part Task
segmentation Task
and O
correspondence Task
annotation Task
tasks Task
take O
approximately O
the O
same O
time O
, O
which O
is O
surprising O
given O
the O
more O
challenging O
nature O
of O
the O
latter O
task O
. O
Visualizations O
of O
the O
collected O
annotations O
are O
provided O
in O
Fig O
. O
[ O
reference O
] O
, O
where O
the O
partitioning O
of O
the O
surface O
and O
U O
, O
V O
coordinates O
are O
shown O
in O
Fig O
. O
[ O
reference O
] O
. O
subsection O
: O
Accuracy Metric
of O
human O
annotators O
We O
assess O
human O
annotator O
with O
respect O
to O
a O
gold O
- O
standard O
measure O
of O
performance O
. O
Typically O
in O
pose Task
estimation Task
one O
asks O
multiple O
annotators O
to O
label O
the O
same O
landmark O
, O
which O
is O
then O
used O
to O
assess O
the O
variance O
in O
position O
, O
e.g. O
. O
In O
our O
case O
, O
we O
can O
render O
images O
where O
we O
have O
access O
to O
the O
true O
mesh O
coordinates O
used O
to O
render O
a O
pixel O
. O
We O
thereby O
directly O
compare O
the O
true O
position O
used O
during O
rendering Task
and O
the O
one O
estimated O
by O
annotators O
, O
rather O
than O
first O
estimating O
a O
’ O
consensus O
’ O
landmark O
location O
among O
multiple O
human O
annotators O
. O
In O
particular O
, O
we O
provide O
annotators O
with O
synthetic O
images O
generated O
through O
the O
exact O
same O
surface Method
model Method
as O
the O
one O
we O
use O
in O
our O
ground Task
- Task
truth Task
annotation Task
, O
exploiting O
the O
rendering Method
system Method
and O
textures O
of O
. O
We O
then O
ask O
annotators O
to O
bring O
the O
synthesized O
images O
into O
correspondence O
with O
the O
surface O
using O
our O
annotation Method
tool Method
, O
and O
for O
every O
image O
estimate O
the O
geodesic O
distance O
between O
the O
correct O
surface O
point O
, O
and O
the O
point O
estimated O
by O
human O
annotators O
: O
where O
measures O
the O
geodesic O
distance O
between O
two O
surface O
points O
. O
For O
any O
image O
, O
we O
annotate O
and O
estimate O
the O
error O
only O
on O
a O
randomly O
sampled O
set O
of O
surface O
points O
and O
interpolate O
the O
errors O
on O
the O
remainder O
of O
the O
surface O
. O
Finally O
, O
we O
average O
the O
errors O
across O
all O
examples O
used O
to O
assess O
annotator Task
performance O
. O
As O
shown O
in O
Fig O
. O
[ O
reference O
] O
the O
annotation Metric
errors Metric
are O
substantially O
smaller O
on O
small O
surface O
parts O
with O
distinctive O
features O
that O
could O
help O
localization Task
( O
face O
, O
hands O
, O
feet O
) O
, O
while O
on O
larger O
uniform O
areas O
that O
are O
typically O
covered O
by O
clothes O
( O
torso O
, O
back O
, O
hips O
) O
the O
annotator O
errors O
can O
get O
larger O
. O
subsection O
: O
Evaluation Metric
Measures Metric
We O
consider O
two O
different O
ways O
of O
summarizing O
correspondence O
accuracy Metric
over O
the O
whole O
human O
body O
, O
including O
pointwise Method
and Method
per Method
- Method
instance Method
evaluation Method
. O
paragraph O
: O
Pointwise Task
evaluation Task
. O
This O
approach O
evaluates O
correspondence O
accuracy Metric
over O
the O
whole O
image O
domain O
through O
the O
Ratio O
of O
Correct O
Point O
( O
RCP O
) O
correspondences O
, O
where O
a O
correspondence O
is O
declared O
correct O
if O
the O
geodesic O
distance O
is O
below O
a O
certain O
threshold O
. O
As O
the O
threshold O
varies O
, O
we O
obtain O
a O
curve O
, O
whose O
area O
provides O
us O
with O
a O
scalar O
summary O
of O
the O
correspondence O
accuracy Metric
. O
For O
any O
given O
image O
we O
have O
a O
varying O
set O
of O
points O
coming O
with O
ground O
- O
truth O
signals O
. O
We O
summarize O
performance O
on O
the O
ensemble O
of O
such O
points O
, O
gathered O
across O
images O
. O
We O
evaluate O
the O
area O
under O
the O
curve O
( O
AUC Metric
) O
, O
, O
for O
two O
different O
values O
of O
yielding O
and O
respectively O
, O
where O
is O
understood O
as O
being O
an O
accuracy Metric
measure O
for O
more O
refined O
correspondence Task
. O
This O
performance Metric
measure Metric
is O
easily O
applicable O
to O
both O
single O
- O
and O
multi Task
- Task
person Task
scenarios Task
and O
can O
deliver O
directly O
comparable O
values O
. O
In O
Fig O
. O
[ O
reference O
] O
, O
we O
provide O
the O
per O
- O
part O
pointwise O
evaluation O
of O
the O
human Metric
annotator Metric
performance Metric
on O
synthetic O
data O
, O
which O
can O
be O
seen O
as O
an O
upper O
bound O
for O
the O
performance O
of O
our O
systems O
. O
paragraph O
: O
Per Metric
- Metric
instance Metric
evaluation Metric
. O
Inspired O
by O
the O
object Method
keypoint Method
similarity Method
( Method
OKS Method
) Method
measure Method
used O
for O
pose Task
evaluation Task
on O
the O
COCO Material
dataset Material
, O
we O
introduce O
geodesic Method
point Method
similarity Method
( O
GPS Method
) O
as O
a O
correspondence O
matching Method
score O
: O
where O
is O
the O
set O
of O
ground O
truth O
points O
annotated O
on O
person O
instance O
, O
is O
the O
vertex O
estimated O
by O
a O
model O
at O
point O
, O
is O
the O
ground O
truth O
vertex O
and O
is O
a O
normalizing O
parameter O
. O
We O
set O
so O
that O
a O
single O
point O
has O
a O
GPS O
value O
of O
if O
its O
geodesic O
distance O
from O
the O
ground O
truth O
equals O
the O
average O
half O
- O
size O
of O
a O
body O
segment O
, O
corresponding O
to O
approximately O
cm O
. O
Intuitively O
, O
this O
means O
that O
a O
score O
of O
can O
be O
achieved O
by O
a O
perfect O
part Method
segmentation Method
model Method
, O
while O
going O
above O
that O
also O
requires O
a O
more O
precise O
localization O
of O
a O
point O
on O
the O
surface O
. O
Once O
the O
matching Method
is O
performed O
, O
we O
follow O
the O
COCO Method
challenge Method
protocol Method
and O
evaluate O
Average Metric
Precision Metric
( O
AP Metric
) O
and O
Average Metric
Recall Metric
( O
AR Metric
) O
at O
a O
number O
of O
GPS O
thresholds O
ranging O
from O
0.5 O
to O
0.95 O
, O
which O
corresponds O
to O
the O
range O
of O
geodesic O
distances O
between O
and O
cm O
. O
We O
use O
the O
same O
range O
of O
distances O
to O
perform O
both O
per Task
- Task
instance Task
and O
per Task
- Task
point Task
evaluation Task
. O
section O
: O
Learning O
Dense Task
Human Task
Pose Task
Estimation Task
We O
now O
turn O
to O
the O
task O
of O
training O
a O
deep Method
network Method
that O
predicts O
dense O
correspondences O
between O
image O
pixels O
and O
surface O
points O
. O
Such O
a O
task O
was O
recently O
addressed O
in O
the O
Dense Method
Regression Method
( Method
DenseReg Method
) Method
system Method
of O
through O
a O
fully Method
- Method
convolutional Method
network Method
architecture Method
. O
In O
this O
work O
, O
we O
introduce O
improved O
architectures O
by O
combining O
the O
DenseReg Method
approach Method
with O
the O
Mask Method
- Method
RCNN Method
architecture Method
, O
yielding O
our O
‘ O
DensePose Method
- Method
RCNN Method
’ Method
system Method
. O
We O
develop O
cascaded Method
extensions Method
of O
DensePose Method
- Method
RCNN Method
that O
further O
improve O
accuracy Metric
and O
describe O
a O
training Method
- Method
based Method
interpolation Method
method Method
that O
allows O
us O
to O
turn O
a O
sparse O
supervision O
signal O
into O
a O
denser O
and O
more O
effective O
variant O
. O
subsection O
: O
Fully Task
- Task
convolutional Task
dense Task
pose Task
regression Task
The O
simplest O
architecture O
choice O
consists O
in O
using O
a O
fully Method
convolutional Method
network Method
( O
FCN Method
) O
that O
combines O
a O
classification Task
and O
a O
regression Task
task Task
, O
similar O
to O
DenseReg Method
. O
In O
a O
first O
step O
, O
we O
classify O
a O
pixel O
as O
belonging O
to O
either O
background O
, O
or O
one O
among O
several O
region O
parts O
which O
provide O
a O
coarse O
estimate O
of O
surface O
coordinates O
. O
This O
amounts O
to O
a O
labelling Task
task Task
that O
is O
trained O
using O
a O
standard O
cross Method
- Method
entropy Method
loss Method
. O
In O
a O
second O
step O
, O
a O
regression Method
system Method
indicates O
the O
exact O
coordinates O
of O
the O
pixel O
within O
the O
part O
. O
Since O
the O
human O
body O
has O
a O
complicated O
structure O
, O
we O
break O
it O
into O
multiple O
independent O
pieces O
and O
parameterize O
each O
piece O
using O
a O
local Method
two Method
- Method
dimensional Method
coordinate Method
system Method
, O
that O
identifies O
the O
position O
of O
any O
node O
on O
this O
surface O
part O
. O
Intuitively O
, O
we O
can O
say O
that O
we O
first O
use O
appearance O
to O
make O
a O
coarse O
estimate O
of O
where O
the O
pixel O
belongs O
to O
and O
then O
align O
it O
to O
the O
exact O
position O
through O
some O
small Method
- Method
scale Method
correction Method
. O
Concretely O
, O
coordinate Task
regression Task
at O
an O
image O
position O
can O
be O
formulated O
as O
follows O
: O
where O
in O
the O
first O
stage O
we O
assign O
position O
to O
the O
body O
part O
that O
has O
highest O
posterior O
probability O
, O
as O
calculated O
by O
the O
classification O
branch O
, O
and O
in O
the O
second O
stage O
we O
use O
the O
regressor Method
that O
places O
the O
point O
in O
the O
continuous O
coordinates O
parametrization O
of O
part O
. O
In O
our O
case O
, O
can O
take O
25 O
values O
( O
one O
is O
background O
) O
, O
meaning O
that O
is O
a O
25 O
- O
way O
classification O
unit O
, O
and O
we O
train O
24 O
regression Method
functions Method
, O
each O
of O
which O
provides O
2D O
coordinates O
within O
its O
respective O
part O
. O
While O
training Task
, O
we O
use O
a O
cross Method
- Method
entropy Method
loss Method
for O
the O
part Task
classification Task
and O
a O
smooth Method
loss Method
for O
training O
each O
regressor O
. O
The O
regression Task
loss Task
is O
only O
taken O
into O
account O
for O
a O
part O
if O
the O
pixel O
is O
within O
the O
specific O
part O
. O
subsection O
: O
Region Method
- Method
based Method
Dense Method
Pose Method
Regression Method
Using O
an O
FCN Method
makes O
the O
system O
particularly O
easy O
to O
train O
, O
but O
loads O
the O
same O
deep Method
network Method
with O
too O
many O
tasks O
, O
including O
part Task
segmentation Task
and O
pixel Task
localization Task
, O
while O
at O
the O
same O
time O
requiring O
scale O
- O
invariance O
which O
becomes O
challenging O
for O
humans O
in O
COCO Material
. O
Here O
we O
adopt O
the O
region Method
- Method
based Method
approach Method
of O
, O
which O
consists O
in O
a O
cascade Method
of Method
proposing Method
regions Method
- Method
of Method
- Method
interest Method
( O
ROI O
) O
, O
extracting O
region O
- O
adapted O
features O
through O
ROI Method
pooling Method
and O
feeding O
the O
resulting O
features O
into O
a O
region Method
- Method
specific Method
branch Method
. O
Such O
architectures O
decompose O
the O
complexity O
of O
the O
task O
into O
controllable O
modules O
and O
implement O
a O
scale Method
- Method
selection Method
mechanism Method
through O
ROI Method
- Method
pooling Method
. O
At O
the O
same O
time O
, O
they O
can O
also O
be O
trained O
jointly O
in O
an O
end O
- O
to O
- O
end O
manner O
. O
We O
adopt O
the O
settings O
introduced O
in O
, O
involving O
the O
construction O
of O
Feature Method
Pyramid Method
Network Method
features Method
, O
and O
ROI Method
- Method
Align Method
pooling Method
, O
which O
have O
been O
shown O
to O
be O
important O
for O
tasks O
that O
require O
spatial O
accuracy Metric
. O
We O
adapt O
this O
architecture O
to O
our O
task O
, O
so O
as O
to O
obtain O
dense O
part O
labels O
and O
coordinates O
within O
each O
of O
the O
selected O
regions O
. O
As O
shown O
in O
Fig O
. O
[ O
reference O
] O
, O
we O
introduce O
a O
fully Method
- Method
convolutional Method
network Method
on O
top O
of O
ROI Method
- Method
pooling Method
that O
is O
entirely O
devoted O
to O
these O
two O
tasks O
, O
generating O
a O
classification Method
and O
a O
regression Method
head Method
that O
provide O
the O
part Task
assignment Task
and O
part O
coordinate O
predictions O
, O
as O
in O
DenseReg Method
. O
For O
simplicity O
, O
we O
use O
the O
exact O
same O
architecture O
used O
in O
the O
keypoint O
branch O
of O
Mask Method
- Method
RCNN Method
, O
consisting O
of O
a O
stack O
of O
8 O
alternating Method
fully Method
convolutional Method
and Method
ReLU Method
layers Method
with O
512 O
channels O
. O
At O
the O
top O
of O
this O
branch O
we O
have O
the O
same O
classification O
and O
regression O
losses O
as O
in O
the O
FCN Method
baseline Method
, O
but O
we O
now O
use O
a O
supervision O
signal O
that O
is O
cropped O
within O
the O
proposed O
region O
. O
During O
inference Task
, O
our O
system O
operates O
at O
25fps O
on O
320x240 O
images O
and O
4 O
- O
5fps O
on O
800x1100 O
images O
using O
a O
GTX1080 O
graphics O
card O
. O
subsection O
: O
Multi Method
- Method
task Method
cascaded Method
architectures Method
Inspired O
by O
the O
success O
of O
recent O
pose Method
estimation Method
models Method
based O
on O
iterative Method
refinement Method
we O
experiment O
with O
cascaded Method
architectures Method
. O
Cascading Method
can O
improve O
performance O
both O
by O
providing O
context O
to O
the O
following O
stages O
, O
and O
also O
through O
the O
benefits O
of O
deep Method
supervision Method
. O
As O
shown O
in O
Fig O
. O
[ O
reference O
] O
, O
we O
do O
not O
confine O
ourselves O
to O
cascading O
within O
a O
single O
task O
, O
but O
also O
exploit O
information O
from O
related O
tasks O
, O
such O
as O
keypoint Task
estimation Task
and O
instance Task
segmentation Task
, O
which O
have O
successfully O
been O
addressed O
by O
the O
Mask Method
- Method
RCNN Method
architecture Method
. O
This O
allows O
us O
to O
exploit O
task O
synergies O
and O
the O
complementary O
merits O
of O
different O
sources O
of O
supervision O
. O
subsection O
: O
Distillation Task
- Task
based Task
ground Task
- Task
truth Task
interpolation Task
Even O
though O
we O
aim O
at O
dense Task
pose Task
estimation Task
at O
test O
time O
, O
in O
every O
training O
sample O
we O
annotate O
only O
a O
sparse O
subset O
of O
the O
pixels O
, O
approximately O
100 O
- O
150 O
per O
human O
. O
This O
does O
not O
necessarily O
pose O
a O
problem O
during O
training Task
, O
since O
we O
can O
make O
our O
classification Method
/ Method
regression Method
losses Method
oblivious O
to O
points O
where O
the O
ground O
- O
truth O
correspondence O
was O
not O
collected O
, O
simply O
by O
not O
including O
them O
in O
the O
summation O
over O
the O
per O
- O
pixel O
losses O
. O
However O
, O
we O
have O
observed O
that O
we O
obtain O
substantially O
better O
results O
by O
“ O
inpainting O
” O
the O
values O
of O
the O
supervision O
signal O
on O
positions O
that O
were O
not O
originally O
annotated O
. O
For O
this O
we O
adopt O
a O
learning Method
- Method
based Method
approach Method
where O
we O
firstly O
train O
a O
“ O
teacher Method
” Method
network Method
( O
depicted O
in O
Fig O
. O
[ O
reference O
] O
) O
to O
reconstruct O
the O
ground O
- O
truth O
values O
wherever O
these O
are O
observed O
, O
and O
then O
deploy O
it O
on O
the O
full O
image O
domain O
, O
yielding O
a O
dense O
supervision O
signal O
. O
In O
particular O
, O
we O
only O
keep O
the O
network O
’s O
predictions O
on O
areas O
that O
are O
labelled O
as O
foreground O
, O
as O
indicated O
by O
the O
part O
masks O
collected O
by O
humans O
, O
in O
order O
to O
ignore O
network O
errors O
on O
background O
regions O
. O
section O
: O
Experiments O
In O
all O
of O
the O
following O
experiments O
, O
we O
assess O
the O
methods O
on O
a O
test O
set O
of O
1.5k O
images O
containing O
2.3k O
humans O
, O
using O
as O
training O
set O
of O
48 O
K O
humans O
. O
Our O
test O
- O
set O
coincides O
with O
the O
COCO O
keypoints O
- O
minival O
partition O
used O
by O
and O
the O
training O
set O
with O
the O
COCO O
- O
train O
partition O
. O
We O
are O
currently O
collecting O
annotations O
for O
the O
remainder O
of O
the O
COCO Material
dataset Material
, O
which O
will O
soon O
allow O
us O
to O
also O
have O
a O
competition O
mode O
evaluation O
. O
Before O
assessing O
dense Task
pose Task
estimation Task
‘ O
in O
the O
- O
wild O
’ O
in O
Sec O
. O
[ O
reference O
] O
, O
we O
start O
in O
Sec O
. O
[ O
reference O
] O
with O
the O
more O
restricted O
‘ O
Single O
- O
Person O
’ O
setting O
where O
we O
use O
as O
inputs O
images O
cropped O
around O
ground O
- O
truth O
boxes O
. O
This O
factors O
out O
the O
effects O
of O
detection Task
performance O
and O
provides O
us O
with O
a O
controlled O
setting O
to O
assess O
the O
usefulness O
of O
the O
COCO Material
- Material
DensePose Material
dataset Material
. O
subsection O
: O
Single Task
- Task
Person Task
Dense Task
Pose Task
Estimation Task
We O
start O
in O
Sec O
. O
[ O
reference O
] O
by O
comparing O
the O
COCO Material
- Material
DensePose Material
dataset Material
to O
other O
sources O
of O
supervision Method
for O
dense Task
pose Task
estimation Task
and O
then O
in O
Sec O
. O
[ O
reference O
] O
compare O
the O
performance O
of O
the O
model Method
- Method
based Method
system Method
of O
with O
our O
discriminatively Method
- Method
trained Method
system Method
. O
Clearly O
the O
system O
of O
was O
not O
trained O
with O
the O
same O
amount O
of O
data O
as O
our O
model O
; O
this O
comparison O
therefore O
serves O
primarily O
to O
show O
the O
merit O
of O
our O
large O
- O
scale O
dataset O
for O
discriminative Task
training Task
. O
subsubsection O
: O
Manual Task
supervision Task
versus O
surrogates O
We O
start O
by O
assessing O
whether O
COCO Method
- Method
DensePose Method
improves O
the O
accuracy Metric
of O
dense Task
pose Task
estimation Task
with O
respect O
to O
the O
prior O
semi O
- O
automated O
, O
or O
synthetic O
supervision O
signals O
described O
below O
. O
A O
semi Method
- Method
automated Method
method Method
is O
used O
for O
the O
‘ O
Unite O
the O
People O
’ O
( O
UP O
) O
dataset O
of O
, O
where O
human O
annotators O
verified O
the O
results O
of O
fitting O
the O
SMPL Method
3D Method
deformable Method
model Method
to O
2D O
images O
. O
However O
, O
model Method
fitting Method
often O
fails O
in O
the O
presence O
of O
occlusions O
, O
or O
extreme O
poses O
, O
and O
is O
never O
guaranteed O
to O
be O
entirely O
successful O
– O
for O
instance O
, O
even O
after O
rejecting O
a O
large O
fraction O
of O
the O
fitting O
results O
, O
the O
feet O
are O
still O
often O
misaligned O
in O
. O
This O
both O
decimates O
the O
training O
set O
and O
obfuscates O
evaluation O
, O
since O
the O
ground O
- O
truth O
itself O
may O
have O
systematic O
errors O
. O
Synthetic Task
ground Task
- Task
truth Task
can O
be O
established O
by O
rendering Method
images Method
using O
surface Method
- Method
based Method
models Method
. O
This O
has O
recently O
been O
applied O
to O
human Task
pose Task
in O
the O
SURREAL O
dataset O
of O
, O
where O
the O
SMPL Method
model Method
was O
rendered O
with O
the O
CMU O
Mocap O
dataset O
poses O
. O
However O
, O
covariate O
shift O
can O
emerge O
because O
of O
the O
different O
statistics O
of O
rendered O
and O
natural O
images O
. O
Since O
both O
of O
these O
two O
methods O
use O
the O
same O
SMPL Method
surface Method
model Method
as O
the O
one O
we O
use O
in O
our O
work O
, O
we O
can O
directly O
compare O
results O
, O
and O
also O
combine O
datasets O
. O
We O
render O
our O
dense O
coordinates O
and O
our O
dense O
part O
labels O
on O
the O
SMPL Method
model Method
for O
all O
8514 O
images O
of O
UP O
dataset O
and O
60k O
SURREAL Method
models Method
for O
comparison O
. O
In O
Fig O
. O
[ O
reference O
] O
we O
assess O
the O
test O
performance O
of O
ResNet Method
- Method
101 Method
FCNs Method
of Method
stride Method
8 Method
trained O
with O
different O
datasets O
, O
using O
a O
Deeplab Method
- Method
type Method
architecture Method
. O
During O
training O
we O
augment O
samples O
from O
all O
of O
the O
datasets O
with O
scaling O
, O
cropping O
and O
rotation O
. O
We O
observe O
that O
the O
surrogate O
datasets O
lead O
to O
weaker O
performance O
, O
while O
their O
combination O
yields O
improved O
results O
. O
Still O
, O
their O
performance O
is O
substantially O
lower O
than O
the O
one O
obtained O
by O
training O
on O
our O
DensePose Material
dataset Material
, O
while O
combining O
the O
DensePose Method
with O
SURREAL Method
results O
in O
a O
moderate O
drop O
in O
network Task
performance O
. O
Based O
on O
these O
results O
we O
rely O
exclusively O
on O
the O
DensePose Material
dataset Material
for O
training O
in O
the O
remaining O
experiments O
, O
even O
though O
domain Method
adaptation Method
could O
be O
used O
in O
the O
future O
to O
exploit O
synthetic O
sources O
of O
supervision O
. O
The O
last O
line O
in O
the O
table O
of O
Fig O
. O
[ O
reference O
] O
( O
’ O
DensePose O
’ O
) O
indicates O
an O
additional O
performance O
boost O
that O
we O
get O
by O
using O
the O
COCO O
human O
segmentation O
masks O
in O
order O
to O
replace O
background O
intensities O
with O
an O
average O
intensity O
during O
both O
training O
and O
testing O
and O
also O
by O
evaluating O
the O
network O
at O
multiple O
scales O
and O
averaging O
the O
results O
. O
Clearly O
, O
the O
results O
with O
other O
methods O
are O
not O
directly O
comparable O
, O
since O
we O
are O
using O
additional O
information O
to O
remove O
background O
structures O
. O
Still O
, O
the O
resulting O
predictions O
are O
substantially O
closer O
to O
human O
performance O
– O
we O
therefore O
use O
this O
as O
the O
‘ O
teacher Method
network Method
’ O
to O
obtain O
dense O
supervision O
for O
the O
experiments O
in O
Sec O
. O
[ O
reference O
] O
. O
subsubsection O
: O
FCNN Method
- Method
vs Method
Model Method
- Method
based Method
pose Method
estimation Method
In O
Fig O
. O
[ O
reference O
] O
we O
compare O
our O
method O
to O
the O
SMPLify Method
pipeline Method
of O
, O
which O
fits O
the O
3D Method
SMPL Method
model Method
to O
an O
image O
based O
on O
a O
pre O
- O
computed O
set O
of O
landmark O
points O
. O
We O
use O
the O
code O
provided O
by O
with O
both O
DeeperCut Method
pose Method
estimation Method
landmark Method
detector Method
for O
14 O
- O
landmark O
results O
and O
with O
the O
91 O
- O
landmark O
alternative O
proposed O
in O
. O
Note O
that O
these O
landmark Method
detectors Method
were O
trained O
on O
the O
MPII O
dataset O
. O
Since O
the O
whole O
body O
is O
visible O
in O
the O
MPII O
dataset O
, O
for O
a O
fair O
comparison O
we O
separately O
evaluate O
on O
images O
where O
16 O
/ O
17 O
or O
17 O
/ O
17 O
landmarks O
are O
visible O
and O
on O
the O
whole O
test O
set O
. O
We O
observe O
that O
while O
being O
orders O
of O
magnitude O
faster O
( O
0.04 O
- O
0.25 O
” O
vs O
60 O
- O
200 O
” O
) O
our O
bottom Method
- Method
up Method
, O
feedforward Method
method Method
largely O
outperforms O
the O
iterative Method
, Method
model Method
fitting Method
result O
. O
As O
mentioned O
above O
, O
this O
difference O
in O
accuracy Metric
indicates O
the O
merit O
of O
having O
at O
our O
disposal O
DensePose Material
- Material
COCO Material
for O
discriminative Task
training Task
. O
subsection O
: O
Multi Task
- Task
Person Task
Dense Task
Pose Task
Estimation Task
Having O
established O
the O
merit O
of O
the O
DensePose Material
- Material
COCO Material
dataset O
, O
we O
now O
turn O
to O
examining O
the O
impact O
of O
network Method
architecture Method
on O
dense Task
pose Task
estimation Task
in Task
- Task
the Task
- Task
wild Task
. O
In O
Fig O
. O
[ O
reference O
] O
we O
summarize O
our O
experimental O
findings O
using O
the O
same O
RCP Metric
measure Metric
used O
in O
Fig O
. O
[ O
reference O
] O
. O
We O
observe O
firstly O
that O
the O
FCN Method
- Method
based Method
performance O
in O
- O
the O
- O
wild O
( O
curve O
‘ O
DensePose Method
- Method
FCN Method
’ Method
) O
is O
now O
dramatically O
lower O
than O
that O
of O
the O
DensePose O
curve O
in O
Fig O
. O
[ O
reference O
] O
. O
Even O
though O
we O
apply O
a O
multi Method
- Method
scale Method
testing Method
strategy Method
that O
fuses O
probabilities O
from O
multiple O
runs O
using O
input O
images O
of O
different O
scale O
, O
the O
FCN Method
is O
not O
sufficiently O
robust O
to O
deal O
with O
the O
variability O
in O
object O
scale O
. O
We O
then O
observe O
in O
curve O
‘ O
DensePose Method
- Method
RCNN Method
’ O
a O
big O
boost O
in O
performance O
thanks O
to O
switching O
to O
a O
region Method
- Method
based Method
system Method
. O
The O
networks O
up O
to O
here O
have O
been O
trained O
using O
the O
sparse O
set O
of O
points O
that O
have O
been O
manually O
annotated O
. O
In O
curve O
‘ O
DensePose Task
- Task
RCNN Task
- Task
Distillation Task
’ Task
we O
see O
that O
using O
the O
dense O
supervision O
signal O
delivered O
by O
our O
DensePose Method
system Method
on O
the O
training O
set O
yields O
a O
substantial O
improvement O
. O
Finally O
, O
in O
‘ O
DensePose Method
- Method
RCNN Method
- Method
Cascade Method
’ O
we O
show O
the O
performance O
achieved O
thanks O
to O
the O
introduction O
of O
cascading O
: O
Sec O
. O
[ O
reference O
] O
almost O
matches O
the O
’ O
DensePose O
’ O
curve O
of O
Fig O
. O
[ O
reference O
] O
. O
This O
is O
a O
remarkably O
positive O
result O
: O
as O
described O
in O
Sec O
. O
[ O
reference O
] O
, O
the O
‘ O
DensePose O
’ O
curve O
corresponds O
to O
a O
very O
privileged O
evaluation O
, O
involving O
( O
a O
) O
cropping O
objects O
around O
their O
ground O
- O
truth O
boxes O
and O
fixing O
their O
scale O
( O
b O
) O
removing O
background O
variation O
from O
both O
training O
and O
testing O
, O
by O
using O
ground O
- O
truth O
object O
masks O
and O
( O
c O
) O
ensembling O
over O
scales O
. O
It O
can O
therefore O
be O
understood O
as O
an O
upper O
bound O
of O
what O
we O
could O
expect O
to O
obtain O
when O
operating O
in O
- O
the O
- O
wild O
. O
We O
see O
that O
our O
best O
system O
is O
marginally O
below O
that O
level O
of O
performance O
, O
which O
clearly O
reveals O
the O
power O
of O
the O
three O
modifications O
we O
introduce O
, O
namely O
region Method
- Method
based Method
processing Method
, O
inpainting O
the O
supervision O
signal O
, O
and O
cascading Method
. O
In O
Table O
[ O
reference O
] O
we O
report O
the O
AP Metric
and O
AR Metric
metrics O
described O
in O
Sec O
. O
[ O
reference O
] O
as O
we O
change O
different O
choices O
in O
our O
architecture O
. O
We O
have O
conducted O
experiments O
using O
both O
ResNet Method
- Method
50 Method
and Method
ResNet Method
- Method
101 Method
backbones Method
and O
observed O
an O
only O
insignificant O
boost O
in O
performance O
with O
the O
larger O
model O
( O
first O
two O
rows O
in O
Table O
[ O
reference O
] O
) O
. O
The O
rest O
of O
our O
experiments O
are O
therefore O
based O
on O
the O
ResNet Method
- Method
50 Method
- Method
FPN Method
version Method
of Method
DensePose Method
- Method
RCNN Method
. O
The O
following O
two O
experiments O
shown O
in O
the O
middle O
section O
of O
Table O
[ O
reference O
] O
indicate O
the O
impact O
on O
multi Task
- Task
task Task
learning Task
. O
Augmenting O
the O
network O
with O
the O
mask O
or O
keypoint O
branches O
yields O
improvements O
with O
any O
of O
these O
two O
auxiliary Task
tasks Task
. O
The O
last O
section O
of O
Table O
[ O
reference O
] O
reports O
improvements O
in O
dense Task
pose Task
estimation Task
obtained O
through O
cascading O
using O
the O
network O
setup O
from O
Fig O
. O
[ O
reference O
] O
. O
Incorporating O
additional O
guidance O
in O
particular O
from O
the O
keypoint O
branch O
significantly O
boosts O
performance O
. O
subsection O
: O
Qualitative O
Results O
In O
this O
section O
we O
provide O
additional O
qualitative O
results O
to O
further O
demonstrate O
the O
performance O
of O
our O
method O
. O
In O
Fig O
. O
[ O
reference O
] O
we O
show O
qualitative O
results O
generated O
by O
our O
method O
, O
where O
the O
correspondence O
is O
visualized O
in O
terms O
of O
‘ O
fishnets O
’ O
, O
namely O
isocontours O
of O
estimated O
UV O
coordinates O
that O
are O
superimposed O
on O
humans O
. O
As O
these O
results O
indicate O
, O
our O
method O
is O
able O
to O
handle O
large O
amounts O
of O
occlusion O
, O
scale O
, O
and O
pose O
variation O
, O
while O
also O
successfully O
hallucinating O
the O
human O
body O
behind O
clothes O
such O
as O
dresses O
or O
skirts O
. O
In O
Fig O
. O
[ O
reference O
] O
we O
demonstrate O
a O
simple O
graphics Task
- Task
oriented Task
application Task
, O
where O
we O
map O
texture O
RGB O
intensities O
taken O
from O
to O
estimated O
UV O
body O
coordinates O
- O
the O
whole O
video O
is O
available O
on O
our O
project O
’s O
website O
. O
section O
: O
Conclusion O
In O
this O
work O
we O
have O
tackled O
the O
task O
of O
dense Task
human Task
pose Task
estimation Task
using O
discriminative Method
trained Method
models Method
. O
We O
have O
introduced O
COCO Material
- Material
DensePose Material
, O
a O
large O
- O
scale O
dataset O
of O
ground O
- O
truth O
image O
- O
surface O
correspondences O
and O
developed O
novel O
architectures O
that O
allow O
us O
to O
recover O
highly O
- O
accurate O
dense O
correspondences O
between O
images O
and O
the O
body O
surface O
in O
multiple O
frames O
per O
second O
. O
We O
anticipate O
that O
this O
will O
pave O
the O
way O
both O
for O
downstream Task
tasks Task
in O
augmented Task
reality Task
or Task
graphics Task
, O
but O
also O
help O
us O
tackle O
the O
general O
problem O
of O
associating Task
images Task
with O
semantic Method
3D Method
object Method
representations Method
. O
section O
: O
Acknowledgements O
We O
thank O
the O
authors O
of O
for O
sharing O
their O
code O
, O
Piotr O
Dollar O
for O
guidance O
and O
proposals O
related O
to O
our O
dataset O
’s O
quality O
, O
Tsung O
- O
Yi O
Lin O
for O
his O
help O
with O
COCO O
- O
related O
issues O
and O
H. O
Yiğit O
Güler O
for O
his O
help O
with O
backend Task
development Task
. O
bibliography O
: O
References O
