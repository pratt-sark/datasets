Published O
as O
a O
conference O
paper O
at O
ICLR O
2016 O
REASONING Task
ABOUT Task
ENTAILMENT Task
WITH O
NEURAL Task
ATTENTION Task
section O
: O
ABSTRACT O
While O
most O
approaches O
to O
automatically Task
recognizing Task
entailment Task
relations Task
have O
used O
classifiers Method
employing O
hand O
engineered O
features O
derived O
from O
complex O
natural Task
language Task
processing Task
pipelines O
, O
in O
practice O
their O
performance O
has O
been O
only O
slightly O
better O
than O
bag Method
- Method
of Method
- Method
word Method
pair Method
classifiers Method
using O
only O
lexical O
similarity O
. O
The O
only O
attempt O
so O
far O
to O
build O
an O
end O
- O
to O
- O
end O
differentiable Method
neural Method
network Method
for O
entailment Task
failed O
to O
outperform O
such O
a O
simple O
similarity Method
classifier Method
. O
In O
this O
paper O
, O
we O
propose O
a O
neural Method
model Method
that O
reads O
two O
sentences O
to O
determine O
entailment O
using O
long Method
short Method
- Method
term Method
memory Method
units Method
. O
We O
extend O
this O
model O
with O
a O
word Method
- Method
by Method
- Method
word Method
neural Method
attention Method
mechanism Method
that O
encourages O
reasoning O
over O
entailments O
of O
pairs O
of O
words O
and O
phrases O
. O
Furthermore O
, O
we O
present O
a O
qualitative O
analysis O
of O
attention Method
weights O
produced O
by O
this O
model O
, O
demonstrating O
such O
reasoning Method
capabilities Method
. O
On O
a O
large O
entailment O
dataset O
this O
model O
outperforms O
the O
previous O
best O
neural Method
model Method
and O
a O
classifier Method
with O
engineered O
features O
by O
a O
substantial O
margin O
. O
It O
is O
the O
first O
generic O
end O
- O
to O
- O
end Method
differentiable Method
system Method
that O
achieves O
state O
- O
of O
- O
the O
- O
art O
accuracy Metric
on O
a O
textual O
entailment O
dataset O
. O
section O
: O
INTRODUCTION O
The O
ability O
to O
determine O
the O
semantic O
relationship O
between O
two O
sentences O
is O
an O
integral O
part O
of O
machines O
that O
understand O
and O
reason O
with O
natural O
language O
. O
Recognizing Task
textual Task
entailment Task
( O
RTE Task
) O
is O
the O
task O
of O
determining O
whether O
two O
natural O
language O
sentences O
are O
( O
i O
) O
contradicting O
each O
other O
, O
( O
ii O
) O
not O
related O
, O
or O
whether O
( O
iii O
) O
the O
first O
sentence O
( O
called O
premise O
) O
entails O
the O
second O
sentence O
( O
called O
hypothesis O
) O
. O
This O
task O
is O
important O
since O
many O
natural Task
language Task
processing Task
( O
NLP Task
) O
problems O
, O
such O
as O
information Task
extraction Task
, O
relation Task
extraction Task
, O
text Task
summarization Task
or O
machine Task
translation Task
, O
rely O
on O
it O
explicitly O
or O
implicitly O
and O
could O
benefit O
from O
more O
accurate O
RTE Task
systems O
[ O
reference O
] O
. O
State O
- O
of O
- O
the O
- O
art O
systems O
for O
RTE Task
so O
far O
relied O
heavily O
on O
engineered O
NLP Task
pipelines O
, O
extensive O
manual O
creation O
of O
features O
, O
as O
well O
as O
various O
external O
resources O
and O
specialized O
subcomponents O
such O
as O
negation Method
detection Method
( O
e.g. O
[ O
reference O
][ O
reference O
][ O
reference O
][ O
reference O
] O
. O
Despite O
the O
success O
of O
neural Method
networks Method
for O
paraphrase Task
detection Task
( O
e.g. O
[ O
reference O
][ O
reference O
][ O
reference O
] O
, O
end O
- O
to O
- O
end O
differentiable Method
neural Method
architectures Method
failed O
to O
get O
close O
to O
acceptable O
performance O
for O
RTE Task
due O
to O
the O
lack O
of O
large O
high O
- O
quality O
datasets O
. O
An O
end O
- O
to O
- O
end O
differentiable Method
solution Method
to O
RTE Task
is O
desirable O
, O
since O
it O
avoids O
specific O
assumptions O
about O
the O
underlying O
language O
. O
In O
particular O
, O
there O
is O
no O
need O
for O
language O
features O
like O
part O
- O
of O
- O
speech O
tags O
or O
dependency Method
parses Method
. O
Furthermore O
, O
a O
generic O
sequence Method
- Method
to Method
- Method
sequence Method
solution Method
allows O
to O
extend O
the O
concept O
of O
capturing Task
entailment Task
across O
any O
sequential O
data O
, O
not O
only O
natural O
language O
. O
Recently O
, O
[ O
reference O
] O
published O
the O
Stanford Material
Natural Material
Language Material
Inference Material
( O
SNLI Material
) O
corpus O
accompanied O
by O
a O
neural Method
network Method
with O
long Method
short Method
- Method
term Method
memory Method
units Method
[ O
reference O
] O
, O
which O
achieves O
an O
accuracy Metric
of O
77.6 O
% O
for O
RTE Task
on O
this O
dataset O
. O
It O
is O
the O
first O
time O
a O
generic O
neural Method
model Method
without O
hand O
- O
crafted O
features O
got O
close O
to O
the O
accuracy Metric
of O
a O
simple O
lexicalized Method
classifier Method
with O
engineered O
features O
for O
RTE Task
. O
This O
can O
be O
explained O
by O
the O
high O
quality O
1 O
arXiv:1509.06664v4 O
[ O
cs O
. O
CL O
] O
1 O
Mar O
2016 O
and O
size O
of O
SNLI Material
compared O
to O
the O
two O
orders O
of O
magnitude O
smaller O
and O
partly O
synthetic O
datasets O
so O
far O
used O
to O
evaluate O
RTE Task
systems O
. O
Bowman O
et O
al O
. O
's O
LSTM Method
encodes O
the O
premise O
and O
hypothesis O
as O
dense O
fixed O
- O
length O
vectors O
whose O
concatenation O
is O
subsequently O
used O
in O
a O
multi Method
- Method
layer Method
perceptron Method
( Method
MLP Method
) O
for O
classification Task
. O
In O
contrast O
, O
we O
are O
proposing O
an O
attentive Method
neural Method
network Method
that O
is O
capable O
of O
reasoning O
over O
entailments O
of O
pairs O
of O
words O
and O
phrases O
by O
processing O
the O
hypothesis O
conditioned O
on O
the O
premise O
. O
Our O
contributions O
are O
threefold O
: O
( O
i O
) O
We O
present O
a O
neural Method
model Method
based O
on O
LSTMs Method
that O
reads O
two O
sentences O
in O
one O
go O
to O
determine O
entailment O
, O
as O
opposed O
to O
mapping O
each O
sentence O
independently O
into O
a O
semantic O
space O
( O
§ O
2.2 O
) O
, O
( O
ii O
) O
We O
extend O
this O
model O
with O
a O
neural Method
word Method
- Method
by Method
- Method
word Method
attention Method
mechanism O
to O
encourage O
reasoning O
over O
entailments O
of O
pairs O
of O
words O
and O
phrases O
( O
§ O
2.4 O
) O
, O
and O
( O
iii O
) O
We O
provide O
a O
detailed O
qualitative O
analysis O
of O
neural O
attention Method
for O
RTE Task
( O
§ O
4.1 O
) O
. O
Our O
benchmark O
LSTM Method
achieves O
an O
accuracy Metric
of O
80.9 O
% O
on O
SNLI Material
, O
outperforming O
a O
simple O
lexicalized Method
classifier Method
tailored O
to O
RTE Task
by O
2.7 O
percentage O
points O
. O
An O
extension O
with O
word Method
- Method
by Method
- Method
word Method
neural Method
attention Method
surpasses O
this O
strong O
benchmark O
LSTM Method
result O
by O
2.6 O
percentage O
points O
, O
setting O
a O
new O
state O
- O
of O
- O
the O
- O
art O
accuracy Metric
of O
83.5 O
% O
for O
recognizing Task
entailment Task
on O
SNLI Material
. O
section O
: O
METHODS O
In O
this O
section O
we O
discuss O
LSTMs Method
( O
§ O
2.1 O
) O
and O
describe O
how O
they O
can O
be O
applied O
to O
RTE Task
( O
§ O
2.2 O
) O
. O
We O
introduce O
an O
extension O
of O
an O
LSTM Method
for O
RTE Task
with O
neural O
attention Method
( O
§ O
2.3 O
) O
and O
word Method
- Method
by Method
- Method
word Method
attention Method
( O
§ O
2.4 O
) O
. O
Finally O
, O
we O
show O
how O
such O
attentive Method
models Method
can O
easily O
be O
used O
for O
attending O
both O
ways O
: O
over O
the O
premise O
conditioned O
on O
the O
hypothesis O
and O
over O
the O
hypothesis O
conditioned O
on O
the O
premise O
( O
§ O
2.5 O
) O
. O
section O
: O
LSTMS Method
Recurrent Method
neural Method
networks Method
( O
RNNs Method
) O
with O
long O
short O
- O
term O
memory O
( O
LSTM Method
) O
units O
[ O
reference O
] O
have O
been O
successfully O
applied O
to O
a O
wide O
range O
of O
NLP Task
tasks O
, O
such O
as O
machine Task
translation Task
, O
constituency Task
parsing Task
, O
language Task
modeling Task
[ O
reference O
] O
and O
recently O
RTE Task
[ O
reference O
] O
. O
LSTMs Method
encompass O
memory Method
cells Method
that O
can O
store O
information O
for O
a O
long O
period O
of O
time O
, O
as O
well O
as O
three O
types O
of O
gates O
that O
control O
the O
flow O
of O
information O
into O
and O
out O
of O
these O
cells O
: O
input O
gates O
( O
Eq O
. O
2 O
) O
, O
forget O
gates O
( O
Eq O
. O
3 O
) O
and O
output O
gates O
( O
Eq O
. O
4 O
) O
. O
Given O
an O
input O
vector O
x O
t O
at O
time O
step O
t O
, O
the O
previous O
output O
h O
t−1 O
and O
cell O
state O
c O
t−1 O
, O
an O
LSTM Method
with O
hidden Method
size Method
k Method
computes O
the O
next O
output O
h O
t O
and O
cell O
state O
c O
t O
as O
where O
k O
trained O
biases O
that O
parameterize O
the O
gates O
and O
transformations O
of O
the O
input O
, O
σ O
denotes O
the O
element O
- O
wise O
application O
of O
the O
sigmoid Method
function Method
and O
the O
element O
- O
wise O
multiplication O
of O
two O
vectors O
. O
section O
: O
RECOGNIZING Task
TEXTUAL Task
ENTAILMENT Task
WITH O
LSTMS Method
LSTMs Method
can O
readily O
be O
used O
for O
RTE Task
by O
independently O
encoding O
the O
premise O
and O
hypothesis O
as O
dense O
vectors O
and O
taking O
their O
concatenation O
as O
input O
to O
an O
MLP Method
classifier Method
[ O
reference O
] O
. O
This O
demonstrates O
that O
LSTMs Method
can O
learn O
semantically Method
rich Method
sentence Method
representations Method
that O
are O
suitable O
for O
determining Task
textual Task
entailment Task
. O
section O
: O
CONDITIONAL Method
ENCODING Method
In O
contrast O
to O
learning O
sentence Task
representations Task
, O
we O
are O
interested O
in O
neural Method
models Method
that O
read O
both O
sentences O
to O
determine O
entailment O
, O
thereby O
reasoning O
over O
entailments O
of O
pairs O
of O
words O
and O
phrases O
. O
Figure O
1 O
shows O
the O
high O
- O
level O
structure O
of O
this O
model O
. O
The O
premise O
( O
left O
) O
is O
read O
by O
an O
LSTM Method
. O
A O
second O
LSTM Method
with O
different O
parameters O
is O
reading O
a O
delimiter O
and O
the O
hypothesis O
( O
right O
) O
, O
but O
its O
memory O
state O
is O
initialized O
with O
the O
last O
cell O
state O
of O
the O
previous O
LSTM Method
( O
c O
5 O
in O
the O
example O
) O
, O
i.e. O
it O
is O
conditioned O
on O
the O
representation O
that O
the O
first O
LSTM Method
built O
for O
the O
premise O
( O
A O
) O
. O
We O
use O
word2vec O
vectors O
[ O
reference O
] O
as O
word Method
representations Method
, O
which O
we O
do O
not O
optimize O
during O
training O
. O
Out O
- O
ofvocabulary O
words O
in O
the O
training O
set O
are O
randomly O
initialized O
by O
sampling O
values O
uniformly O
from O
( O
−0.05 O
, O
0.05 O
) O
and O
optimized O
during O
training O
. O
1 O
Out O
- O
of O
- O
vocabulary O
words O
encountered O
at O
inference O
time O
on O
the O
validation O
and O
test O
corpus O
are O
set O
to O
fixed O
random O
vectors O
. O
By O
not O
tuning O
representations O
of O
words O
for O
which O
we O
have O
word2vec O
vectors O
, O
we O
ensure O
that O
at O
inference O
time O
their O
representation O
stays O
close O
to O
unseen O
similar O
words O
for O
which O
we O
have O
word2vec O
embeddings O
. O
We O
use O
a O
linear Method
layer Method
to O
project O
word O
vectors O
to O
the O
dimensionality O
of O
the O
hidden O
size O
of O
the O
LSTM Method
, O
yielding O
input O
vectors O
x O
i O
. O
Finally O
, O
for O
classification Task
we O
use O
a O
softmax O
layer O
over O
the O
output O
of O
a O
non O
- O
linear O
projection O
of O
the O
last O
output O
vector O
( O
h O
9 O
in O
the O
example O
) O
into O
the O
target O
space O
of O
the O
three O
classes O
( O
ENTAILMENT O
, O
NEUTRAL O
or O
CONTRADICTION O
) O
, O
and O
train O
using O
the O
cross Method
- Method
entropy Method
loss Method
. O
section O
: O
ATTENTION O
Attentive Method
neural Method
networks Method
have O
recently O
demonstrated O
success O
in O
a O
wide O
range O
of O
tasks O
ranging O
from O
handwriting Task
synthesis Task
[ O
reference O
] O
, O
digit Task
classification Task
[ O
reference O
] O
, O
machine Task
translation Task
, O
image Task
captioning Task
[ O
reference O
] O
, O
speech Task
recognition Task
[ O
reference O
] O
and O
sentence Task
summarization Task
[ O
reference O
] O
, O
to O
geometric Task
reasoning Task
[ O
reference O
] O
. O
The O
idea O
is O
to O
allow O
the O
model O
to O
attend O
over O
past O
output O
vectors O
( O
see O
Figure O
1 O
B O
) O
, O
thereby O
mitigating O
the O
LSTM Method
's O
cell O
state O
bottleneck O
. O
More O
precisely O
, O
an O
LSTM Method
with Method
attention Method
for O
RTE Task
does O
not O
need O
to O
capture O
the O
whole O
semantics O
of O
the O
premise O
in O
its O
cell O
state O
. O
Instead O
, O
it O
is O
sufficient O
to O
output O
vectors O
while O
reading O
the O
premise O
and O
accumulating O
a O
representation O
in O
the O
cell O
state O
that O
informs O
the O
second O
LSTM Method
which O
of O
the O
output O
vectors O
of O
the O
premise O
it O
needs O
to O
attend O
over O
to O
determine O
the O
RTE Task
class O
. O
Let O
Y O
∈ O
R O
k×L O
be O
a O
matrix O
consisting O
of O
output O
vectors O
[ O
h O
1 O
· O
· O
· O
h O
L O
] O
that O
the O
first O
LSTM Method
produced O
when O
reading O
the O
L O
words O
of O
the O
premise O
, O
where O
k O
is O
a O
hyperparameter O
denoting O
the O
size O
of O
embeddings O
and O
hidden O
layers O
. O
Furthermore O
, O
let O
e O
L O
∈ O
R O
L O
be O
a O
vector O
of O
1s O
and O
h O
N O
be O
the O
last O
output O
vector O
after O
the O
premise O
and O
hypothesis O
were O
processed O
by O
the O
two O
LSTMs Method
respectively O
. O
The O
attention Method
mechanism O
will O
produce O
a O
vector O
α O
of O
attention Method
weights O
and O
a O
weighted O
representation O
r O
of O
the O
premise O
via O
where O
W O
y O
, O
W O
h O
∈ O
R O
k×k O
are O
trained O
projection O
matrices O
, O
w O
∈ O
R O
k O
is O
a O
trained O
parameter O
vector O
and O
w O
T O
denotes O
its O
transpose O
. O
Note O
that O
the O
outer O
product O
W O
h O
h O
N O
⊗ O
e O
L O
is O
repeating O
the O
linearly O
transformed O
h O
N O
as O
many O
times O
as O
there O
are O
words O
in O
the O
premise O
( O
i.e. O
L O
times O
) O
. O
Hence O
, O
the O
intermediate O
attention Method
representation O
m O
i O
( O
ith O
column O
vector O
in O
M O
) O
of O
the O
ith O
word O
in O
the O
premise O
is O
obtained O
from O
a O
non Method
- Method
linear Method
combination Method
of O
the O
premise O
's O
output O
vector O
h O
i O
( O
ith O
column O
vector O
in O
Y O
) O
and O
the O
transformed O
h O
N O
. O
The O
attention Method
weight O
for O
the O
ith O
word O
in O
the O
premise O
is O
the O
result O
of O
a O
weighted O
combination O
( O
parameterized O
by O
w O
) O
of O
values O
in O
m O
i O
. O
The O
final O
sentence Task
- Task
pair Task
representation Task
is O
obtained O
from O
a O
non Method
- Method
linear Method
combination Method
of O
the O
attentionweighted Method
representation Method
r Method
of O
the O
premise O
and O
the O
last O
output O
vector O
h O
N O
using O
where O
W O
p O
, O
W O
x O
∈ O
R O
k×k O
are O
trained O
projection O
matrices O
. O
section O
: O
WORD Task
- Task
BY Task
- Task
WORD Task
ATTENTION Task
For O
determining O
whether O
one O
sentence O
entails O
another O
it O
can O
be O
a O
good O
strategy O
to O
check O
for O
entailment Task
or O
contradiction O
of O
individual O
word O
- O
and O
phrase O
- O
pairs O
. O
To O
encourage O
such O
behavior O
we O
employ O
neural Method
word Method
- Method
by Method
- Method
word Method
attention Method
similar O
to O
, O
[ O
reference O
] O
and O
[ O
reference O
] O
. O
The O
difference O
is O
that O
we O
do O
not O
use O
attention Method
to O
generate O
words O
, O
but O
to O
obtain O
a O
sentence Method
- Method
pair Method
encoding Method
from O
fine O
- O
grained Method
reasoning Method
via O
soft O
- O
alignment O
of O
words O
and O
phrases O
in O
the O
premise O
and O
hypothesis O
. O
In O
our O
case O
, O
this O
amounts O
to O
attending O
over O
the O
first O
LSTM Method
's O
output O
vectors O
of O
the O
premise O
while O
the O
second O
LSTM Method
processes O
the O
hypothesis O
one O
word O
at O
a O
time O
, O
thus O
generating O
attention Method
weight O
- O
vectors O
α O
t O
over O
all O
output O
vectors O
of O
the O
premise O
for O
every O
word O
x O
t O
with O
t O
∈ O
( O
L O
+ O
1 O
, O
N O
) O
in O
the O
hypothesis O
( O
Figure O
1 O
C O
) O
. O
This O
can O
be O
modeled O
as O
follows O
: O
Note O
that O
r O
t O
is O
dependent O
on O
the O
previous O
attention Method
representation O
r O
t−1 O
to O
inform O
the O
model O
about O
what O
was O
attended O
over O
in O
the O
previous O
step O
( O
see O
Eq O
. O
11 O
and O
13 O
) O
. O
As O
in O
the O
previous O
section O
, O
the O
final O
sentence Task
- Task
pair Task
representation Task
is O
obtained O
from O
a O
non O
- O
linear Method
combination Method
of O
the O
last O
attention Method
- O
weighted O
representation O
of O
the O
premise O
( O
here O
based O
on O
the O
last O
word O
of O
the O
hypothesis O
) O
r O
N O
and O
the O
last O
output O
vector O
using O
2.5 O
TWO O
- O
WAY O
ATTENTION O
Inspired O
by O
bidirectional O
LSTMs Method
that O
read O
a O
sequence O
and O
its O
reverse O
for O
improved O
encoding Task
[ O
reference O
] O
, O
we O
introduce O
two Method
- Method
way Method
attention Method
for O
RTE Task
. O
The O
idea O
is O
to O
use O
the O
same O
model O
( O
i.e. O
same O
structure O
and O
weights O
) O
to O
attend O
over O
the O
premise O
conditioned O
on O
the O
hypothesis O
, O
as O
well O
as O
to O
attend O
over O
the O
hypothesis O
conditioned O
on O
the O
premise O
, O
by O
simply O
swapping O
the O
two O
sequences O
. O
This O
produces O
two O
sentence Method
- Method
pair Method
representations Method
that O
we O
concatenate O
for O
classification Task
. O
section O
: O
EXPERIMENTS O
We O
conduct O
experiments O
on O
the O
Stanford Material
Natural Material
Language Material
Inference Material
corpus O
[ O
reference O
] O
. O
This O
corpus O
is O
two O
orders O
of O
magnitude O
larger O
than O
other O
existing O
RTE Task
corpora O
such O
as O
Sentences O
Involving O
Compositional O
Knowledge O
( O
SICK O
, O
[ O
reference O
] O
. O
Furthermore O
, O
a O
large O
part O
of O
training O
examples O
in O
SICK O
were O
generated O
heuristically O
from O
other O
examples O
. O
In O
contrast O
, O
all O
sentence O
- O
pairs O
in O
SNLI Material
stem O
from O
human O
annotators O
. O
The O
size O
and O
quality O
of O
SNLI Material
make O
it O
a O
suitable O
resource O
for O
training O
neural Method
architectures Method
such O
as O
the O
ones O
proposed O
in O
this O
paper O
. O
We O
use O
ADAM Method
[ O
reference O
] O
for O
optimization Task
with O
a O
first O
momentum O
coefficient O
of O
0.9 O
and O
a O
second O
momentum O
coefficient O
of O
0.999 O
. O
2 O
For O
every O
model O
we O
perform O
a O
small O
grid Method
search Method
[ O
reference O
] O
. O
Subsequently O
, O
we O
take O
the O
best O
configuration O
based O
on O
performance O
on O
the O
validation O
set O
, O
and O
evaluate O
only O
that O
configuration O
on O
the O
test O
set O
. O
section O
: O
RESULTS O
AND O
DISCUSSION O
Results O
on O
the O
SNLI Material
corpus O
are O
summarized O
in O
Table O
1 O
. O
The O
total O
number O
of O
model O
parameters O
, O
including O
tunable O
word O
representations O
, O
is O
denoted O
by O
|θ| O
W O
+ O
M O
( O
without O
word Method
representations Method
|θ| O
M O
) O
. O
To O
ensure O
a O
comparable O
number O
of O
parameters O
to O
Bowman O
et O
al O
. O
's O
model O
that O
encodes O
the O
premise O
and O
hypothesis O
independently O
using O
one O
LSTM Method
, O
we O
also O
run O
experiments O
for O
conditional Task
encoding Task
where O
the O
parameters O
of O
both O
LSTMs Method
are O
shared O
( O
" O
Conditional Method
encoding Method
, O
shared O
" O
with O
k O
= O
100 O
) O
as O
opposed O
to O
using O
two O
independent O
LSTMs Method
. O
In O
addition O
, O
we O
compare O
our O
attentive Method
models Method
to O
two O
benchmark O
LSTMs Method
whose O
hidden O
sizes O
were O
chosen O
so O
that O
they O
have O
at O
least O
as O
many O
parameters O
as O
the O
attentive Method
models Method
. O
Since O
we O
are O
not O
tuning O
word O
vectors O
for O
which O
we O
have O
word2vec O
embeddings O
, O
the O
total O
number O
of O
parameters O
|θ| O
W O
+ O
M O
of O
our O
models O
is O
considerably O
smaller O
. O
We O
also O
compare O
our O
models O
against O
the O
benchmark O
lexicalized Method
classifier Method
used O
by O
Bowman Method
et O
al O
. O
, O
which O
constructs O
features O
from O
the O
BLEU Metric
score Metric
between O
the O
premise O
and O
hypothesis O
, O
length O
difference O
, O
word O
overlap O
, O
uni O
- O
and O
bigrams O
, O
part O
- O
of O
- O
speech O
tags O
, O
as O
well O
as O
cross O
uni O
- O
and O
bigrams O
. O
Conditional Method
Encoding Method
We O
found O
that O
processing O
the O
hypothesis O
conditioned O
on O
the O
premise O
instead O
of O
encoding O
each O
sentence O
independently O
gives O
an O
improvement O
of O
3.3 O
percentage O
points O
in O
accuracy Metric
over O
Bowman O
et O
al O
. O
's O
LSTM Method
. O
We O
argue O
this O
is O
due O
to O
information O
being O
able O
to O
flow O
from O
the O
part O
of O
the O
model O
that O
processes O
the O
premise O
to O
the O
part O
that O
processes O
the O
hypothesis O
. O
Specifically O
, O
the O
model O
does O
not O
waste O
capacity O
on O
encoding O
the O
hypothesis O
( O
in O
fact O
it O
does O
not O
need O
to O
encode O
the O
hypothesis O
at O
all O
) O
, O
but O
can O
read O
the O
hypothesis O
in O
a O
more O
focused O
way O
by O
checking O
words O
and O
phrases O
for O
contradictions O
and O
entailments O
based O
on O
the O
semantic Method
representation Method
of O
the O
premise O
. O
One O
interpretation O
is O
that O
the O
LSTM Method
is O
approximating O
a O
finite Method
- Method
state Method
automaton Method
for O
RTE Task
( O
cf O
. O
[ O
reference O
] O
. O
Another O
difference O
to O
Bowman O
et O
al O
. O
's O
model O
is O
that O
we O
are O
using O
word2vec Method
instead O
of O
GloVe Method
for O
word Method
representations Method
and O
, O
more O
importantly O
, O
do O
not O
fine O
- O
tune O
these O
word Method
embeddings Method
. O
The O
drop O
in O
accuracy Metric
from O
train O
to O
test O
set O
is O
less O
severe O
for O
our O
models O
, O
which O
suggest O
that O
fine Task
- Task
tuning Task
word Task
embeddings Task
could O
be O
a O
cause O
of O
overfitting O
. O
Our O
LSTM Method
outperforms O
a O
simple O
lexicalized Method
classifier Method
by O
2.7 O
percentage O
points O
. O
To O
the O
best O
of O
our O
knowledge O
, O
this O
is O
the O
first O
instance O
of O
a O
neural Method
end Method
- Method
to Method
- Method
end Method
differentiable Method
model Method
to O
achieve O
state O
- O
ofthe O
- O
art O
performance O
on O
a O
textual O
entailment O
dataset O
. O
Attention Task
By O
incorporating O
an O
attention Method
mechanism O
we O
found O
a O
0.9 O
percentage O
point O
improvement O
over O
a O
single O
LSTM Method
with O
a O
hidden O
size O
of O
159 O
, O
and O
a O
1.4 O
percentage O
point O
increase O
over O
a O
benchmark O
model O
that O
uses O
two O
LSTMs Method
for O
conditional Method
encoding Method
( O
one O
for O
the O
premise O
and O
one O
for O
the O
hypothesis O
conditioned O
on O
the O
representation O
of O
the O
premise O
) O
. O
The O
attention Method
model Method
produces O
output O
vectors O
summarizing O
contextual O
information O
of O
the O
premise O
that O
is O
useful O
to O
attend O
over O
later O
when O
reading O
the O
hypothesis O
. O
Therefore O
, O
when O
reading O
the O
premise O
, O
the O
model O
does O
not O
have O
to O
build O
up O
a O
semantic Method
representation Method
of O
the O
whole O
premise O
, O
but O
instead O
a O
representation O
that O
helps O
attending O
over O
the O
right O
output O
vectors O
when O
processing O
the O
hypothesis O
. O
In O
contrast O
, O
the O
output O
vectors O
of O
the O
premise O
are O
not O
used O
by O
the O
benchmark O
LSTMs Method
. O
Thus O
, O
these O
models O
have O
to O
build O
up O
a O
representation O
of O
the O
whole O
premise O
and O
carry O
it O
over O
through O
the O
cell O
state O
to O
the O
part O
that O
processes O
the O
hypothesis O
- O
a O
bottleneck O
that O
can O
be O
overcome O
to O
some O
degree O
by O
using O
attention Method
. O
Word Method
- Method
by Method
- Method
word Method
Attention Method
Enabling O
the O
model O
to O
attend O
over O
output O
vectors O
of O
the O
premise O
for O
every O
word O
in O
the O
hypothesis O
yields O
another O
1.2 O
percentage O
point O
improvement O
compared O
to O
attending O
based O
only O
on O
the O
last O
output O
vector O
of O
the O
premise O
. O
We O
argue O
that O
this O
is O
due O
to O
the O
model O
being O
able O
to O
check O
for O
entailment O
or O
contradiction O
of O
individual O
words O
and O
phrases O
in O
the O
hypothesis O
, O
and O
demonstrate O
this O
effect O
in O
the O
qualitative Task
analysis Task
below O
. O
section O
: O
Two O
- O
way O
Attention O
Allowing O
the O
model O
to O
also O
attend O
over O
the O
hypothesis O
based O
on O
the O
premise O
does O
not O
seem O
to O
improve O
performance O
for O
RTE Task
. O
We O
suspect O
that O
this O
is O
due O
to O
entailment O
being O
an O
asymmetric O
relation O
. O
Hence O
, O
using O
the O
same O
LSTM Method
to O
encode O
the O
hypothesis O
( O
in O
one O
direction O
) O
and O
the O
premise O
( O
in O
the O
other O
direction O
) O
might O
lead O
to O
noise O
in O
the O
training O
signal O
. O
This O
could O
be O
addressed O
by O
training O
different O
LSTMs Method
at O
the O
cost O
of O
doubling O
the O
number O
of O
model O
parameters O
. O
section O
: O
QUALITATIVE Method
ANALYSIS Method
It O
is O
instructive O
to O
analyze O
which O
output O
representations O
the O
model O
is O
attending O
over O
when O
deciding O
the O
class O
of O
an O
RTE Task
example O
. O
Note O
that O
interpretations O
based O
on O
attention Method
weights O
have O
to O
be O
taken O
with O
care O
since O
the O
model O
is O
not O
forced O
to O
solely O
rely O
on O
representations O
obtained O
from O
attention Method
( O
see O
h O
N O
in O
Eq O
. O
10 O
and O
14 O
) O
. O
In O
the O
following O
we O
visualize O
and O
discuss O
the O
attention Method
patterns O
of O
the O
presented O
attentive Method
models Method
. O
For O
each O
attentive Method
model Method
we O
hand O
- O
picked O
examples O
from O
ten O
randomly O
drawn O
samples O
of O
the O
validation O
set O
. O
Attention O
Figure O
2 O
shows O
to O
what O
extent O
the O
attentive Method
model Method
focuses O
on O
contextual O
representations O
of O
the O
premise O
after O
both O
LSTMs Method
processed O
the O
premise O
and O
hypothesis O
respectively O
. O
Note O
how O
the O
model O
pays O
attention Method
to O
output O
vectors O
of O
words O
that O
are O
semantically O
coherent O
with O
the O
premise O
[ O
reference O
] O
or O
in O
contradiction O
, O
as O
caused O
by O
a O
single O
word O
( O
" O
blue O
" O
vs. O
" O
pink O
" O
, O
2b O
) O
or O
multiple O
words O
[ O
reference O
] O
. O
Interestingly O
, O
the O
model O
shows O
contextual O
understanding O
by O
not O
attending O
over O
" O
yellow O
" O
, O
the O
color O
( O
g O
) O
Figure O
3 O
: O
Word O
- O
by O
- O
word O
attention Method
visualizations O
. O
of O
the O
toy O
, O
but O
" O
pink O
" O
, O
the O
color O
of O
the O
coat O
. O
However O
, O
for O
more O
involved O
examples O
with O
longer O
premises O
we O
found O
that O
attention Method
is O
more O
uniformly O
distributed O
( O
2d O
) O
. O
This O
suggests O
that O
conditioning O
attention Method
only O
on O
the O
last O
output O
has O
limitations O
when O
multiple O
words O
need O
to O
be O
considered O
for O
deciding O
the O
RTE Task
class O
. O
Word Method
- Method
by Method
- Method
word Method
Attention Method
Visualizations O
of O
word O
- O
by O
- O
word O
attention Method
are O
depicted O
in O
Figure O
3 O
. O
We O
found O
that O
word Method
- Method
by Method
- Method
word Method
attention Method
can O
easily O
detect O
if O
the O
hypothesis O
is O
simply O
a O
reordering O
of O
words O
in O
the O
premise O
( O
3a O
) O
. O
Furthermore O
, O
it O
is O
able O
to O
resolve O
synonyms O
( O
" O
airplane O
" O
and O
" O
aircraft O
" O
, O
3c O
) O
and O
capable O
of O
matching O
multi O
- O
word O
expressions O
to O
single O
words O
( O
" O
garbage O
can O
" O
to O
" O
trashcan O
" O
, O
3b O
) O
. O
It O
is O
also O
noteworthy O
that O
irrelevant O
parts O
of O
the O
premise O
, O
such O
as O
words O
capturing O
little O
meaning O
or O
whole O
uninformative O
relative O
clauses O
, O
are O
correctly O
neglected O
for O
determining O
entailment Task
( O
" O
which O
also O
has O
a O
rope O
leading O
out O
of O
it O
" O
, O
3b O
) O
. O
Word O
- O
by O
- O
word O
attention Method
seems O
to O
also O
work O
well O
when O
words O
in O
the O
premise O
and O
hypothesis O
are O
connected O
via O
deeper O
semantics O
or O
common O
- O
sense O
knowledge O
( O
" O
snow O
" O
can O
be O
found O
" O
outside O
" O
and O
a O
" O
mother O
" O
is O
an O
" O
adult O
" O
, O
3e O
and O
3 O
g O
) O
. O
Furthermore O
, O
the O
model O
is O
able O
to O
resolve O
one O
- O
to O
- O
many O
relationships O
( O
" O
kids O
" O
to O
" O
boy O
" O
and O
" O
girl O
" O
, O
3d O
) O
Attention Task
can O
fail O
, O
for O
example O
when O
the O
two O
sentences O
and O
their O
words O
are O
entirely O
unrelated O
( O
3f O
) O
. O
In O
such O
cases O
, O
the O
model O
seems O
to O
back O
up O
to O
attending O
over O
function O
words O
, O
and O
the O
sentence Method
- Method
pair Method
representation Method
is O
likely O
dominated O
by O
the O
last O
output O
vector O
( O
h O
N O
) O
instead O
of O
the O
attention Method
- O
weighted O
representation O
( O
see O
Eq O
. O
14 O
) O
. O
section O
: O
CONCLUSION O
In O
this O
paper O
, O
we O
show O
how O
the O
state O
- O
of O
- O
the O
- O
art O
in O
recognizing Task
textual Task
entailment Task
on O
a O
large O
, O
humancurated O
and O
annotated O
corpus O
, O
can O
be O
improved O
with O
general O
end O
- O
to O
- O
end Method
differentiable Method
models Method
. O
Our O
results O
demonstrate O
that O
LSTM Method
recurrent O
neural O
networks O
that O
read O
pairs O
of O
sequences O
to O
produce O
a O
final O
representation O
from O
which O
a O
simple O
classifier Method
predicts O
entailment Method
, O
outperform O
both O
a O
neural Method
baseline Method
as O
well O
as O
a O
classifier Method
with O
hand O
- O
engineered O
features O
. O
Extending O
these O
models O
with O
attention Method
over O
the O
premise O
provides O
further O
improvements O
to O
the O
predictive O
abilities O
of O
the O
system O
, O
resulting O
in O
a O
new O
state O
- O
of O
- O
the O
- O
art O
accuracy Metric
for O
recognizing Task
entailment Task
on O
the O
Stanford Material
Natural Material
Language Material
Inference Material
corpus O
. O
The O
models O
presented O
here O
are O
general Method
sequence Method
models Method
, O
requiring O
no O
appeal O
to O
Natural Task
Languagespecific Task
processing Task
beyond O
tokenization O
, O
and O
are O
therefore O
a O
suitable O
target O
for O
transfer Task
learning Task
through O
pre O
- O
training O
the O
recurrent Method
systems Method
on O
other O
corpora O
, O
and O
conversely O
, O
applying O
the O
models O
trained O
on O
this O
corpus O
to O
other O
entailment Task
tasks Task
. O
Future O
work O
will O
focus O
on O
such O
transfer Task
learning Task
tasks Task
, O
as O
well O
as O
scaling O
the O
methods O
presented O
here O
to O
larger O
units O
of O
text O
( O
e.g. O
paragraphs O
and O
entire O
documents O
) O
using O
hierarchical O
attention Method
mechanisms O
. O
Additionally O
, O
it O
would O
be O
worthwhile O
exploring O
how O
other O
, O
more O
structured O
forms O
of O
attention Method
( O
e.g. O
[ O
reference O
] O
, O
or O
other O
forms O
of O
differentiable O
memory O
( O
e.g. O
[ O
reference O
][ O
reference O
] O
could O
help O
improve O
performance O
on O
RTE Task
over O
the O
neural Method
models Method
presented O
in O
this O
paper O
. O
Furthermore O
, O
we O
aim O
to O
investigate O
the O
application O
of O
these O
generic O
models O
to O
non Task
- Task
natural Task
language Task
sequential Task
entailment Task
problems Task
. O
section O
: O
section O
: O
ACKNOWLEDGEMENTS O
We O
thank O
Nando O
de O
Freitas O
, O
Samuel O
Bowman O
, O
Jonathan O
Berant O
, O
Danqi O
Chen O
, O
Christopher O
Manning O
, O
and O
the O
anonymous O
ICLR O
reviewers O
for O
their O
helpful O
comments O
on O
drafts O
of O
this O
paper O
. O
section O
: O
