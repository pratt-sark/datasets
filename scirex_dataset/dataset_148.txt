Image	Task
generation	Task
has	O
been	O
successfully	O
cast	O
as	O
an	O
autoregressive	Task
sequence	Task
generation	Task
or	O
transformation	Task
problem	Task
.	O
Recent	O
work	O
has	O
shown	O
that	O
self	Method
-	Method
attention	Method
is	O
an	O
effective	O
way	O
of	O
modeling	Task
textual	Task
sequences	Task
.	O
In	O
this	O
work	O
,	O
we	O
generalize	O
a	O
recently	O
proposed	O
model	Method
architecture	Method
based	O
on	O
self	Method
-	Method
attention	Method
,	O
the	O
Transformer	Method
,	O
to	O
a	O
sequence	Method
modeling	Method
formulation	Method
of	O
image	Task
generation	Task
with	O
a	O
tractable	O
likelihood	O
.	O
By	O
restricting	O
the	O
self	Method
-	Method
attention	Method
mechanism	Method
to	O
attend	O
to	O
local	O
neighborhoods	O
we	O
significantly	O
increase	O
the	O
size	O
of	O
images	O
the	O
model	O
can	O
process	O
in	O
practice	O
,	O
despite	O
maintaining	O
significantly	O
larger	O
receptive	O
fields	O
per	O
layer	O
than	O
typical	O
convolutional	Method
neural	Method
networks	Method
.	O
While	O
conceptually	O
simple	O
,	O
our	O
generative	Method
models	Method
significantly	O
outperform	O
the	O
current	O
state	O
of	O
the	O
art	O
in	O
image	Task
generation	Task
on	O
ImageNet	Material
,	O
improving	O
the	O
best	O
published	O
negative	Metric
log	Metric
-	Metric
likelihood	Metric
on	O
ImageNet	Material
from	O
3.83	O
to	O
3.77	O
.	O
We	O
also	O
present	O
results	O
on	O
image	Task
super	Task
-	Task
resolution	Task
with	O
a	O
large	O
magnification	Metric
ratio	Metric
,	O
applying	O
an	O
encoder	Method
-	Method
decoder	Method
configuration	Method
of	O
our	O
architecture	O
.	O
In	O
a	O
human	O
evaluation	O
study	O
,	O
we	O
find	O
that	O
images	O
generated	O
by	O
our	O
super	Method
-	Method
resolution	Method
model	Method
fool	O
human	O
observers	O
three	O
times	O
more	O
often	O
than	O
the	O
previous	O
state	O
of	O
the	O
art	O
.	O
section	O
:	O
Introduction	O
Recent	O
advances	O
in	O
modeling	O
the	O
distribution	Task
of	Task
natural	Task
images	Task
with	O
neural	Method
networks	Method
allow	O
them	O
to	O
generate	O
increasingly	O
natural	O
-	O
looking	O
images	O
.	O
Some	O
models	O
,	O
such	O
as	O
the	O
PixelRNN	Method
and	O
PixelCNN	Method
,	O
have	O
a	O
tractable	O
likelihood	O
.	O
Beyond	O
licensing	O
the	O
comparatively	O
simple	O
and	O
stable	O
training	O
regime	O
of	O
directly	O
maximizing	Task
log	Task
-	Task
likelihood	Task
,	O
this	O
enables	O
the	O
straightforward	O
application	O
of	O
these	O
models	O
in	O
problems	O
such	O
as	O
image	Task
compression	Task
and	O
probabilistic	Task
planning	Task
and	Task
exploration	Task
.	O
The	O
likelihood	O
is	O
made	O
tractable	O
by	O
modeling	O
the	O
joint	O
distribution	O
of	O
the	O
pixels	O
in	O
the	O
image	O
as	O
the	O
product	O
of	O
conditional	O
distributions	O
.	O
Thus	O
turning	O
the	O
problem	O
into	O
a	O
sequence	Task
modeling	Task
problem	Task
,	O
the	O
state	O
of	O
the	O
art	O
approaches	O
apply	O
recurrent	Method
or	O
convolutional	Method
neural	Method
networks	Method
to	O
predict	O
each	O
next	O
pixel	O
given	O
all	O
previously	O
generated	O
pixels	O
.	O
Training	O
recurrent	Method
neural	O
networks	O
to	O
sequentially	O
predict	O
each	O
pixel	O
of	O
even	O
a	O
small	O
image	O
is	O
computationally	O
very	O
challenging	O
.	O
Thus	O
,	O
parallelizable	Method
models	Method
that	O
use	O
convolutional	Method
neural	Method
networks	Method
such	O
as	O
the	O
PixelCNN	Method
have	O
recently	O
received	O
much	O
more	O
attention	O
,	O
and	O
have	O
now	O
surpassed	O
the	O
PixelRNN	Method
in	O
quality	Metric
.	O
One	O
disadvantage	O
of	O
CNNs	Method
compared	O
to	O
RNNs	Method
is	O
their	O
typically	O
fairly	O
limited	O
receptive	O
field	O
.	O
This	O
can	O
adversely	O
affect	O
their	O
ability	O
to	O
model	O
long	Task
-	Task
range	Task
phenomena	Task
common	O
in	O
images	O
,	O
such	O
as	O
symmetry	O
and	O
occlusion	O
,	O
especially	O
with	O
a	O
small	O
number	O
of	O
layers	O
.	O
Growing	O
the	O
receptive	O
field	O
has	O
been	O
shown	O
to	O
improve	O
quality	Metric
significantly	O
.	O
Doing	O
so	O
,	O
however	O
,	O
comes	O
at	O
a	O
significant	O
cost	O
in	O
number	O
of	O
parameters	O
and	O
consequently	O
computational	Metric
performance	O
and	O
can	O
make	O
training	O
such	O
models	O
more	O
challenging	O
.	O
In	O
this	O
work	O
we	O
show	O
that	O
self	Method
-	Method
attention	Method
can	O
achieve	O
a	O
better	O
balance	O
in	O
the	O
trade	O
-	O
off	O
between	O
the	O
virtually	O
unlimited	O
receptive	O
field	O
of	O
the	O
necessarily	O
sequential	O
PixelRNN	Method
and	O
the	O
limited	O
receptive	O
field	O
of	O
the	O
much	O
more	O
parallelizable	O
PixelCNN	Method
and	O
its	O
various	O
extensions	O
.	O
We	O
adopt	O
similar	O
factorizations	O
of	O
the	O
joint	Method
pixel	Method
distribution	Method
as	O
previous	O
work	O
.	O
Following	O
recent	O
work	O
on	O
modeling	Task
text	Task
,	O
however	O
,	O
we	O
propose	O
eschewing	O
recurrent	Method
and	O
convolutional	O
networks	O
in	O
favor	O
of	O
the	O
Image	Method
Transformer	Method
,	O
a	O
model	O
based	O
entirely	O
on	O
a	O
self	Method
-	Method
attention	Method
mechanism	Method
.	O
The	O
specific	O
,	O
locally	Task
restricted	Task
form	Task
of	Task
multi	Task
-	Task
head	Task
self	Task
-	Task
attention	Task
we	O
propose	O
can	O
be	O
interpreted	O
as	O
a	O
sparsely	Method
parameterized	Method
form	Method
of	Method
gated	Method
convolution	Method
.	O
By	O
decoupling	O
the	O
size	O
of	O
the	O
receptive	O
field	O
from	O
the	O
number	O
of	O
parameters	O
,	O
this	O
allows	O
us	O
to	O
use	O
significantly	O
larger	O
receptive	O
fields	O
than	O
the	O
PixelCNN	Method
.	O
Despite	O
comparatively	O
low	O
resource	O
requirements	O
for	O
training	Task
,	O
the	O
Image	Method
Transformer	Method
attains	O
a	O
new	O
state	O
of	O
the	O
art	O
in	O
modeling	O
images	O
from	O
the	O
standard	O
ImageNet	Material
data	O
set	O
,	O
as	O
measured	O
by	O
log	Metric
-	Metric
likelihood	Metric
.	O
Our	O
experiments	O
indicate	O
that	O
increasing	O
the	O
size	O
of	O
the	O
receptive	O
field	O
plays	O
a	O
significant	O
role	O
in	O
this	O
improvement	O
.	O
We	O
observe	O
significant	O
improvements	O
up	O
to	O
effective	O
receptive	O
field	O
sizes	O
of	O
256	O
pixels	O
,	O
while	O
the	O
PixelCNN	Method
with	O
5x5	Method
filters	Method
used	O
25	O
.	O
Many	O
applications	O
of	O
image	Method
density	Method
models	Method
require	O
conditioning	O
on	O
additional	O
information	O
of	O
various	O
kinds	O
:	O
from	O
images	O
in	O
enhancement	Task
or	Task
reconstruction	Task
tasks	Task
such	O
as	O
super	Task
-	Task
resolution	Task
,	O
in	Task
-	Task
painting	Task
and	O
denoising	Task
to	O
text	O
when	O
synthesizing	O
images	O
from	O
natural	O
language	O
descriptions	O
.	O
In	O
visual	Task
planning	Task
tasks	Task
,	O
conditional	O
image	Task
generation	Task
models	O
could	O
predict	O
future	O
frames	O
of	O
video	O
conditioned	O
on	O
previous	O
frames	O
and	O
taken	O
actions	O
.	O
In	O
this	O
work	O
we	O
hence	O
also	O
evaluate	O
two	O
different	O
methods	O
of	O
performing	O
conditional	O
image	Task
generation	Task
with	O
the	O
Image	Method
Transformer	Method
.	O
In	O
image	Task
-	Task
class	Task
conditional	Task
generation	Task
we	O
condition	O
on	O
an	O
embedding	O
of	O
one	O
of	O
a	O
small	O
number	O
of	O
image	O
classes	O
.	O
In	O
super	Task
-	Task
resolution	Task
with	O
high	Metric
magnification	Metric
ratio	Metric
(	O
4x	O
)	O
,	O
we	O
condition	O
on	O
a	O
very	O
low	O
-	O
resolution	O
image	O
,	O
employing	O
the	O
Image	Method
Transformer	Method
in	O
an	O
encoder	Method
-	Method
decoder	Method
configuration	Method
.	O
In	O
comparison	O
to	O
recent	O
work	O
on	O
autoregressive	Task
super	Task
-	Task
resolution	Task
,	O
a	O
human	O
evaluation	O
study	O
found	O
images	O
generated	O
by	O
our	O
models	O
to	O
look	O
convincingly	O
natural	O
significantly	O
more	O
often	O
.	O
section	O
:	O
Background	O
There	O
is	O
a	O
broad	O
variety	O
of	O
types	O
of	O
image	Task
generation	Task
models	O
in	O
the	O
literature	O
.	O
This	O
work	O
is	O
strongly	O
inspired	O
by	O
autoregressive	Method
models	Method
such	O
as	O
fully	Method
visible	Method
belief	Method
networks	Method
and	O
NADE	O
Bengio00	O
,	O
larochelle2011	O
in	O
that	O
we	O
also	O
factor	O
the	O
joint	O
probability	O
of	O
the	O
image	O
pixels	O
into	O
conditional	O
distributions	O
.	O
Following	O
PixelRNN	Method
PixelRNN	Method
,	O
we	O
also	O
model	O
the	O
color	O
channels	O
of	O
the	O
output	O
pixels	O
as	O
discrete	O
values	O
generated	O
from	O
a	O
multinomial	Method
distribution	Method
,	O
implemented	O
using	O
a	O
simple	O
softmax	Method
layer	Method
.	O
The	O
current	O
state	O
of	O
the	O
art	O
in	O
modeling	Task
images	Task
on	O
CIFAR	Material
-	Material
10	Material
data	Material
set	Material
was	O
achieved	O
by	O
PixelCNN	Method
++	Method
,	O
which	O
models	O
the	O
output	O
pixel	O
distribution	O
with	O
a	O
discretized	O
logistic	O
mixture	O
likelihood	O
,	O
conditioning	O
on	O
whole	O
pixels	O
instead	O
of	O
color	O
channels	O
and	O
changes	O
to	O
the	O
architecture	O
PixelCNNpp	Method
.	O
These	O
modifications	O
are	O
readily	O
applicable	O
to	O
our	O
model	O
,	O
which	O
we	O
plan	O
to	O
evaluate	O
in	O
future	O
work	O
.	O
Another	O
,	O
popular	O
direction	O
of	O
research	O
in	O
image	Task
generation	Task
is	O
training	Method
models	Method
with	O
an	O
adversarial	Method
loss	Method
gan	Method
.	O
Typically	O
,	O
in	O
this	O
regime	O
a	O
generator	Method
network	Method
is	O
trained	O
in	O
opposition	O
to	O
a	O
discriminator	Method
network	Method
trying	O
to	O
determine	O
if	O
a	O
given	O
image	O
is	O
real	O
or	O
generated	O
.	O
In	O
contrast	O
to	O
the	O
often	O
blurry	O
images	O
generated	O
by	O
networks	Method
trained	O
with	O
likelihood	Method
-	Method
based	Method
losses	Method
,	O
generative	Method
adversarial	Method
networks	Method
(	O
GANs	Method
)	O
have	O
been	O
shown	O
to	O
produce	O
sharper	O
images	O
with	O
realistic	O
high	O
-	O
frequency	O
detail	O
in	O
generation	Task
and	O
image	Task
super	Task
-	Task
resolution	Task
tasks	Task
StackGAN	Method
,	O
SRGAN	Method
.	O
While	O
very	O
promising	O
,	O
GANs	Method
have	O
various	O
drawbacks	O
.	O
They	O
are	O
notoriously	O
unstable	O
DCGAN	Method
,	O
motivating	O
a	O
large	O
number	O
of	O
methods	O
attempting	O
to	O
make	O
their	O
training	O
more	O
robust	O
unrolled_gans	O
,	O
began	O
.	O
Another	O
common	O
issue	O
is	O
that	O
of	O
mode	Task
collapse	Task
,	O
where	O
generated	O
images	O
fail	O
to	O
reflect	O
the	O
diversity	O
in	O
the	O
training	O
set	O
unrolled_gans	O
.	O
A	O
related	O
problem	O
is	O
that	O
GANs	Method
do	O
not	O
have	O
a	O
density	O
in	O
closed	O
-	O
form	O
.	O
This	O
makes	O
it	O
challenging	O
to	O
measure	O
the	O
degree	O
to	O
which	O
the	O
models	O
capture	O
diversity	O
.	O
This	O
also	O
complicates	O
model	O
design	O
.	O
Objectively	O
evaluating	O
and	O
comparing	O
,	O
say	O
,	O
different	O
hyperparameter	O
choices	O
is	O
typically	O
much	O
more	O
difficult	O
in	O
GANs	Method
than	O
in	O
models	O
with	O
a	O
tractable	O
likelihood	O
.	O
section	O
:	O
Model	O
Architecture	O
subsection	O
:	O
Image	Method
Representation	Method
We	O
treat	O
pixel	O
intensities	O
as	O
either	O
discrete	O
categories	O
or	O
ordinal	O
values	O
;	O
this	O
setting	O
depends	O
on	O
the	O
distribution	O
(	O
Section	O
[	O
reference	O
]	O
)	O
.	O
For	O
categories	O
,	O
each	O
of	O
the	O
input	O
pixels	O
’	O
three	O
color	O
channels	O
is	O
encoded	O
using	O
a	O
channel	O
-	O
specific	O
set	O
of	O
-	O
dimensional	O
embedding	O
vectors	O
of	O
the	O
intensity	O
values	O
.	O
For	O
output	O
intensities	O
,	O
we	O
share	O
a	O
single	O
,	O
separate	O
set	O
of	O
-	O
dimensional	O
embeddings	O
across	O
the	O
channels	O
.	O
For	O
an	O
image	O
of	O
width	O
and	O
height	O
,	O
we	O
combine	O
the	O
width	O
and	O
channel	O
dimensions	O
yielding	O
a	O
3	O
-	O
dimensional	O
tensor	O
with	O
shape	O
.	O
For	O
ordinal	O
values	O
,	O
we	O
run	O
a	O
1x3	O
window	O
size	O
,	O
1x3	O
strided	Method
convolution	Method
to	O
combine	O
the	O
channels	O
per	O
pixel	O
to	O
form	O
an	O
input	O
representation	O
with	O
shape	O
.	O
To	O
each	O
pixel	Method
representation	Method
,	O
we	O
add	O
a	O
-	Method
dimensional	Method
encoding	Method
of	Method
coordinates	Method
of	O
that	O
pixel	O
.	O
We	O
evaluated	O
two	O
different	O
coordinate	Method
encodings	Method
:	O
sine	O
and	O
cosine	O
functions	O
of	O
the	O
coordinates	O
,	O
with	O
different	O
frequencies	O
across	O
different	O
dimensions	O
,	O
following	O
,	O
and	O
learned	O
position	O
embeddings	O
.	O
Since	O
we	O
need	O
to	O
represent	O
two	O
coordinates	O
,	O
we	O
use	O
of	O
the	O
dimensions	O
to	O
encode	O
the	O
row	O
number	O
and	O
the	O
other	O
of	O
the	O
dimensions	O
to	O
encode	O
the	O
the	O
column	O
and	O
color	O
channel	O
.	O
subsection	O
:	O
Self	O
-	O
Attention	O
For	O
image	Task
-	Task
conditioned	Task
generation	Task
,	O
as	O
in	O
our	O
super	Method
-	Method
resolution	Method
models	Method
,	O
we	O
use	O
an	O
encoder	Method
-	Method
decoder	Method
architecture	Method
.	O
The	O
encoder	Method
generates	O
a	O
contextualized	Method
,	Method
per	Method
-	Method
pixel	Method
-	Method
channel	Method
representation	Method
of	Method
the	Method
source	Method
image	Method
.	O
The	O
decoder	Method
autoregressively	Method
generates	O
an	O
output	O
image	O
of	O
pixel	O
intensities	O
,	O
one	O
channel	O
per	O
pixel	O
at	O
each	O
time	O
step	O
.	O
While	O
doing	O
so	O
,	O
it	O
consumes	O
the	O
previously	O
generated	O
pixels	O
and	O
the	O
input	O
image	Method
representation	Method
generated	O
by	O
the	O
encoder	Method
.	O
For	O
both	O
the	O
encoder	Method
and	Method
decoder	Method
,	O
the	O
Image	Method
Transformer	Method
uses	O
stacks	O
of	O
self	Method
-	Method
attention	Method
and	O
position	Method
-	Method
wise	Method
feed	Method
-	Method
forward	Method
layers	Method
,	O
similar	O
to	O
aiayn	Method
.	O
In	O
addition	O
,	O
the	O
decoder	Method
uses	O
an	O
attention	Method
mechanism	Method
to	O
consume	O
the	O
encoder	Method
representation	Method
.	O
For	O
unconditional	Task
and	Task
class	Task
-	Task
conditional	Task
generation	Task
,	O
we	O
employ	O
the	O
Image	Method
Transformer	Method
in	O
a	O
decoder	Method
-	Method
only	Method
configuration	Method
.	O
Before	O
we	O
describe	O
how	O
we	O
scale	O
self	Task
-	Task
attention	Task
to	O
images	O
comprised	O
of	O
many	O
more	O
positions	O
than	O
typically	O
found	O
in	O
sentences	O
,	O
we	O
give	O
a	O
brief	O
description	O
of	O
self	Task
-	Task
attention	Task
.	O
Each	O
self	Method
-	Method
attention	Method
layer	Method
computes	O
a	O
-	Method
dimensional	Method
representation	Method
for	O
each	O
position	O
,	O
that	O
is	O
,	O
each	O
channel	O
of	O
each	O
pixel	O
.	O
To	O
recompute	O
the	O
representation	O
for	O
a	O
given	O
position	O
,	O
it	O
first	O
compares	O
the	O
position	O
’s	O
current	O
representation	O
to	O
other	O
positions	O
’	O
representations	O
,	O
obtaining	O
an	O
attention	O
distribution	O
over	O
the	O
other	O
positions	O
.	O
This	O
distribution	O
is	O
then	O
used	O
to	O
weight	O
the	O
contribution	O
of	O
the	O
other	O
positions	O
’	O
representations	O
to	O
the	O
next	O
representation	O
for	O
the	O
position	O
at	O
hand	O
.	O
Equations	O
[	O
reference	O
]	O
and	O
[	O
reference	O
]	O
outline	O
the	O
computation	O
in	O
our	O
self	Method
-	Method
attention	Method
and	Method
fully	Method
-	Method
connected	Method
feed	Method
-	Method
forward	Method
layers	Method
;	O
Figure	O
[	O
reference	O
]	O
depicts	O
it	O
.	O
and	O
are	O
the	O
parameters	O
of	O
the	O
feed	Method
-	Method
forward	Method
layer	Method
,	O
and	O
are	O
shared	O
across	O
all	O
the	O
positions	O
in	O
a	O
layer	O
.	O
These	O
fully	O
describe	O
all	O
operations	O
performed	O
in	O
every	O
layer	O
,	O
independently	O
for	O
each	O
position	O
,	O
with	O
the	O
exception	O
of	O
multi	Task
-	Task
head	Task
attention	Task
.	O
For	O
details	O
of	O
multi	Task
-	Task
head	Task
self	Task
-	Task
attention	Task
,	O
see	O
aiayn	O
.	O
In	O
more	O
detail	O
,	O
following	O
previous	O
work	O
,	O
we	O
call	O
the	O
current	O
representation	O
of	O
the	O
pixel	O
’s	O
channel	O
,	O
or	O
position	O
,	O
to	O
be	O
recomputed	O
the	O
query	O
.	O
The	O
other	O
positions	O
whose	O
representations	O
will	O
be	O
used	O
in	O
computing	O
a	O
new	O
representation	O
for	O
are	O
which	O
together	O
comprise	O
the	O
columns	O
of	O
the	O
memory	O
matrix	O
.	O
Note	O
that	O
can	O
also	O
contain	O
.	O
We	O
first	O
transform	O
and	O
linearly	O
by	O
learned	O
matrices	O
and	O
,	O
respectively	O
.	O
The	O
self	Method
-	Method
attention	Method
mechanism	Method
then	O
compares	O
to	O
each	O
of	O
the	O
pixel	O
’s	O
channel	O
representations	O
in	O
the	O
memory	O
with	O
a	O
dot	O
-	O
product	O
,	O
scaled	O
by	O
.	O
We	O
apply	O
the	O
function	O
to	O
the	O
resulting	O
compatibility	O
scores	O
,	O
treating	O
the	O
obtained	O
vector	O
as	O
attention	O
distribution	O
over	O
the	O
pixel	O
channels	O
in	O
the	O
memory	O
.	O
After	O
applying	O
another	O
linear	Method
transformation	Method
to	O
the	O
memory	O
,	O
we	O
compute	O
a	O
weighted	Method
average	Method
of	O
the	O
transformed	O
memory	O
,	O
weighted	O
by	O
the	O
attention	Method
distribution	Method
.	O
In	O
the	O
decoders	O
of	O
our	O
different	O
models	O
we	O
mask	O
the	O
outputs	O
of	O
the	O
comparisons	O
appropriately	O
so	O
that	O
the	O
model	O
can	O
not	O
attend	O
to	O
positions	O
in	O
the	O
memory	O
that	O
have	O
not	O
been	O
generated	O
,	O
yet	O
.	O
To	O
the	O
resulting	O
vector	O
we	O
then	O
apply	O
a	O
single	Method
-	Method
layer	Method
fully	Method
-	Method
connected	Method
feed	Method
-	Method
forward	Method
neural	Method
network	Method
with	O
rectified	Method
linear	Method
activation	Method
followed	O
by	O
another	O
linear	Method
transformation	Method
.	O
The	O
learned	O
parameters	O
of	O
these	O
are	O
shared	O
across	O
all	O
positions	O
but	O
different	O
from	O
layer	O
to	O
layer	O
.	O
As	O
illustrated	O
in	O
Figure	O
[	O
reference	O
]	O
,	O
we	O
perform	O
dropout	Method
,	O
merge	O
in	O
residual	O
connections	O
and	O
perform	O
layer	Method
normalization	Method
after	O
each	O
application	O
of	O
self	Method
-	Method
attention	Method
and	O
the	O
position	Method
-	Method
wise	Method
feed	Method
-	Method
forward	Method
networks	Method
layernorm2016	O
,	O
srivastava2014dropout	O
.	O
The	O
entire	O
self	O
-	O
attention	O
operation	O
can	O
be	O
implemented	O
using	O
highly	O
optimized	O
matrix	Method
multiplication	Method
code	Method
and	O
executed	O
in	O
parallel	O
for	O
all	O
pixels	O
’	O
channels	O
.	O
subsection	O
:	O
Local	Task
Self	Task
-	Task
Attention	Task
The	O
number	O
of	O
positions	O
included	O
in	O
the	O
memory	O
,	O
or	O
the	O
number	O
of	O
columns	O
of	O
,	O
has	O
tremendous	O
impact	O
on	O
the	O
scalability	O
of	O
the	O
self	Method
-	Method
attention	Method
mechanism	Method
,	O
which	O
has	O
a	O
time	Metric
complexity	Metric
in	O
.	O
The	O
encoders	Method
of	O
our	O
super	Method
-	Method
resolution	Method
models	Method
operate	O
on	O
pixel	O
images	O
and	O
it	O
is	O
computationally	O
feasible	O
to	O
attend	O
to	O
all	O
of	O
their	O
positions	O
.	O
The	O
decoders	Method
in	O
our	O
experiments	O
,	O
however	O
,	O
produce	O
pixel	O
images	O
with	O
positions	O
,	O
rendering	O
attending	O
to	O
all	O
positions	O
impractical	O
.	O
Inspired	O
by	O
convolutional	Method
neural	Method
networks	Method
we	O
address	O
this	O
by	O
adopting	O
a	O
notion	O
of	O
locality	O
,	O
restricting	O
the	O
positions	O
in	O
the	O
memory	O
matrix	O
to	O
a	O
local	O
neighborhood	O
around	O
the	O
query	O
position	O
.	O
Changing	O
this	O
neighborhood	O
per	O
query	O
position	O
,	O
however	O
,	O
would	O
prohibit	O
packing	O
most	O
of	O
the	O
computation	O
necessary	O
for	O
self	Task
-	Task
attention	Task
into	O
two	O
matrix	Method
multiplications	Method
-	O
one	O
for	O
computing	O
the	O
pairwise	Task
comparisons	Task
and	O
another	O
for	O
generating	O
the	O
weighted	Method
averages	Method
.	O
To	O
avoid	O
this	O
,	O
we	O
partition	O
the	O
image	O
into	O
query	O
blocks	O
and	O
associate	O
each	O
of	O
these	O
with	O
a	O
larger	O
memory	O
block	O
that	O
also	O
contains	O
the	O
query	O
block	O
.	O
For	O
all	O
queries	O
from	O
a	O
given	O
query	O
block	O
,	O
the	O
model	O
attends	O
to	O
the	O
same	O
memory	O
matrix	O
,	O
comprised	O
of	O
all	O
positions	O
from	O
the	O
memory	O
block	O
.	O
The	O
self	O
-	O
attention	O
is	O
then	O
computed	O
for	O
all	O
query	O
blocks	O
in	O
parallel	O
.	O
The	O
feed	Method
-	Method
forward	Method
networks	Method
and	O
layer	Method
normalizations	Method
are	O
computed	O
in	O
parallel	O
for	O
all	O
positions	O
.	O
In	O
our	O
experiments	O
we	O
use	O
two	O
different	O
schemes	O
for	O
choosing	O
query	O
blocks	O
and	O
their	O
associated	O
memory	O
block	O
neighborhoods	O
,	O
resulting	O
in	O
two	O
different	O
factorizations	O
of	O
the	O
joint	O
pixel	O
distribution	O
into	O
conditional	O
distributions	O
.	O
Both	O
are	O
illustrated	O
in	O
Figure	O
[	O
reference	O
]	O
.	O
paragraph	O
:	O
1D	Method
Local	Method
Attention	O
For	O
1D	Task
local	Task
attention	Task
(	O
Section	O
[	O
reference	O
]	O
)	O
we	O
first	O
flatten	O
the	O
input	O
tensor	O
with	O
positional	Method
encodings	Method
in	O
raster	O
-	O
scan	O
order	O
,	O
similar	O
to	O
previous	O
work	O
PixelRNN	Method
.	O
To	O
compute	O
self	Task
-	Task
attention	Task
on	O
the	O
resulting	O
linearized	O
image	O
,	O
we	O
then	O
partition	O
the	O
length	O
into	O
non	O
-	O
overlapping	O
query	O
blocks	O
of	O
length	O
,	O
padding	O
with	O
zeroes	O
if	O
necessary	O
.	O
While	O
contiguous	O
in	O
the	O
linearized	O
image	O
,	O
these	O
blocks	O
can	O
be	O
discontiguous	O
in	O
image	O
coordinate	O
space	O
.	O
For	O
each	O
query	O
block	O
we	O
build	O
the	O
memory	O
block	O
from	O
the	O
same	O
positions	O
as	O
and	O
an	O
additional	O
positions	O
corresponding	O
to	O
pixels	O
that	O
have	O
been	O
generated	O
before	O
,	O
which	O
can	O
result	O
in	O
overlapping	O
memory	O
blocks	O
.	O
paragraph	O
:	O
2D	O
Local	O
Attention	O
In	O
2D	Method
local	Method
attention	Method
models	Method
,	O
we	O
partition	O
the	O
input	O
tensor	O
with	O
positional	Method
encodings	Method
into	O
rectangular	O
query	O
blocks	O
contiguous	O
in	O
the	O
original	O
image	O
space	O
.	O
We	O
generate	O
the	O
image	O
one	O
query	O
block	O
after	O
another	O
,	O
ordering	O
the	O
blocks	O
in	O
raster	O
-	O
scan	O
order	O
.	O
Within	O
each	O
block	O
,	O
we	O
generate	O
individual	O
positions	O
,	O
or	O
pixel	O
channels	O
,	O
again	O
in	O
raster	O
-	O
scan	O
order	O
.	O
As	O
illustrated	O
in	O
the	O
right	O
half	O
of	O
Figure	O
[	O
reference	O
]	O
,	O
we	O
generate	O
the	O
blocks	O
outlined	O
in	O
grey	O
lines	O
left	O
-	O
to	O
-	O
right	O
and	O
top	O
-	O
to	O
-	O
bottom	O
.	O
We	O
use	O
2	O
-	O
dimensional	O
query	O
blocks	O
of	O
a	O
size	O
specified	O
by	O
height	O
and	O
width	O
,	O
and	O
memory	O
blocks	O
extending	O
the	O
query	O
block	O
to	O
the	O
top	O
,	O
left	O
and	O
right	O
by	O
,	O
and	O
again	O
pixels	O
,	O
respectively	O
.	O
In	O
both	O
1D	O
and	O
2D	Task
local	Task
attention	Task
,	O
we	O
mask	O
attention	O
weights	O
in	O
the	O
query	O
and	O
memory	O
blocks	O
such	O
that	O
positions	O
that	O
have	O
not	O
yet	O
been	O
generated	O
are	O
ignored	O
.	O
As	O
can	O
be	O
seen	O
in	O
Figure	O
[	O
reference	O
]	O
,	O
2D	O
local	O
attention	O
balances	O
horizontal	O
and	O
vertical	O
conditioning	O
context	O
much	O
more	O
evenly	O
.	O
We	O
believe	O
this	O
might	O
have	O
an	O
increasingly	O
positive	O
effect	O
on	O
quality	Metric
with	O
growing	O
image	O
size	O
as	O
the	O
conditioning	O
information	O
in	O
1D	O
local	O
attention	O
becomes	O
increasingly	O
dominated	O
by	O
pixels	O
next	O
to	O
a	O
given	O
position	O
as	O
opposed	O
to	O
above	O
it	O
.	O
subsection	O
:	O
Loss	Method
Function	Method
We	O
perform	O
maximum	Method
likelihood	Method
,	O
in	O
which	O
we	O
maximize	O
with	O
respect	O
to	O
network	O
parameters	O
,	O
and	O
where	O
the	O
network	O
outputs	O
all	O
parameters	O
of	O
the	O
autoregressive	Method
distribution	Method
.	O
We	O
experiment	O
with	O
two	O
settings	O
of	O
the	O
distribution	O
:	O
a	O
categorical	O
distribution	O
across	O
each	O
channel	O
PixelRNN	Method
and	O
a	O
mixture	Method
of	Method
discretized	Method
logistics	Method
over	O
three	O
channels	O
PixelCNNpp	O
.	O
The	O
categorical	Method
distribution	Method
(	O
cat	Method
)	O
captures	O
each	O
intensity	O
value	O
as	O
a	O
discrete	O
outcome	O
and	O
factorizes	O
across	O
channels	O
.	O
In	O
total	O
,	O
there	O
are	O
parameters	O
for	O
each	O
pixel	O
;	O
for	O
images	O
,	O
the	O
network	O
outputs	O
dimensions	O
.	O
Unlike	O
the	O
categorical	O
distribution	O
,	O
the	O
discretized	Method
mixture	Method
of	Method
logistics	Method
(	O
DMOL	Method
)	O
captures	O
two	O
important	O
properties	O
:	O
the	O
ordinal	O
nature	O
of	O
pixel	O
intensities	O
and	O
simpler	O
dependence	O
across	O
channels	O
PixelCNNpp	O
.	O
For	O
each	O
pixel	O
,	O
the	O
number	O
of	O
parameters	O
is	O
times	O
the	O
number	O
of	O
mixture	Method
components	Method
:	O
for	O
one	O
unnormalized	O
mixture	O
probability	O
,	O
three	O
means	O
,	O
three	O
standard	O
deviations	O
,	O
and	O
three	O
coefficients	O
which	O
capture	O
the	O
linear	O
dependence	O
.	O
For	O
10	O
mixtures	O
,	O
this	O
translates	O
to	O
parameters	O
for	O
each	O
pixel	O
;	O
for	O
images	O
,	O
the	O
network	O
outputs	O
dimensions	O
,	O
which	O
is	O
a	O
7x	O
reduction	O
enabling	O
denser	O
gradients	O
and	O
lower	O
memory	O
.	O
section	O
:	O
Inference	Task
Across	O
all	O
of	O
the	O
presented	O
experiments	O
,	O
we	O
use	O
categorical	Method
sampling	Method
during	O
decoding	Method
with	O
a	O
tempered	O
PixelRecursiveSuperResolution	O
.	O
We	O
adjust	O
the	O
concentration	O
of	O
the	O
distribution	O
we	O
sample	O
from	O
with	O
a	O
temperature	O
by	O
which	O
we	O
divide	O
the	O
logits	O
for	O
the	O
channel	O
intensities	O
.	O
We	O
tuned	O
between	O
and	O
,	O
observing	O
the	O
highest	O
perceptual	Metric
quality	Metric
in	O
unconditioned	Task
and	Task
class	Task
-	Task
conditional	Task
image	Task
generation	Task
with	O
.	O
For	O
super	Task
-	Task
resolution	Task
we	O
present	O
results	O
for	O
different	O
temperatures	O
in	O
Table	O
[	O
reference	O
]	O
.	O
section	O
:	O
Experiments	O
All	O
code	O
we	O
used	O
to	O
develop	O
,	O
train	O
,	O
and	O
evaluate	O
our	O
models	O
is	O
available	O
in	O
Tensor2Tensor	O
tensor2tensor	O
.	O
For	O
all	O
experiments	O
we	O
optimize	O
with	O
Adam	Method
kingma2014adam	O
,	O
and	O
vary	O
the	O
learning	Metric
rate	Metric
as	O
specified	O
in	O
.	O
We	O
train	O
our	O
models	O
on	O
both	O
p100	O
and	O
k40	O
GPUs	O
,	O
with	O
batch	O
sizes	O
ranging	O
from	O
to	O
per	O
GPU	O
.	O
subsection	O
:	O
Generative	Method
Image	Method
Modeling	Method
Our	O
unconditioned	Method
and	O
class	Method
-	Method
conditioned	Method
image	Method
generation	Method
models	Method
both	O
use	O
1D	Method
local	Method
attention	Method
,	O
with	O
and	O
a	O
total	O
memory	O
size	O
of	O
.	O
On	O
CIFAR	Material
-	Material
10	Material
our	O
best	O
unconditional	Method
models	Method
achieve	O
a	O
perplexity	O
of	O
bits	Metric
/	Metric
dim	Metric
on	O
the	O
test	O
set	O
using	O
either	O
DMOL	Method
or	O
categorical	O
.	O
For	O
categorical	O
,	O
we	O
use	O
layers	O
with	O
,	O
heads=	O
,	O
feed	Method
-	Method
forward	Method
dimension	Method
with	O
a	O
dropout	O
of	O
.	O
In	O
DMOL	Method
,	O
our	O
best	O
config	O
uses	O
layers	O
,	O
,	O
heads=	O
,	O
feed	Method
-	Method
forward	Method
dimension	Method
and	O
a	O
dropout	O
of	O
.	O
This	O
is	O
a	O
considerable	O
improvement	O
over	O
two	O
baselines	O
:	O
the	O
PixelRNN	Method
and	O
PixelCNN	Method
++	Method
.	O
Introduced	O
after	O
the	O
Image	Method
Transformer	Method
,	O
the	O
also	O
self	Method
-	Method
attention	Method
based	Method
PixelSNAIL	Method
model	Method
reaches	O
a	O
significantly	O
lower	O
perplexity	Metric
of	O
bits	O
/	O
dim	Metric
on	O
CIFAR	Material
-	Material
10	Material
.	O
On	O
the	O
more	O
challenging	O
ImageNet	Material
data	O
set	O
,	O
however	O
,	O
the	O
Image	Method
Transformer	Method
performs	O
significantly	O
better	O
than	O
PixelSNAIL	Method
.	O
We	O
also	O
train	O
smaller	O
layer	O
CIFAR	Material
-	Material
10	Material
models	O
which	O
have	O
,	O
dimensions	O
in	O
the	O
feed	O
-	O
forward	O
layers	O
,	O
attention	O
heads	O
and	O
use	O
dropout	O
of	O
,	O
and	O
achieve	O
bits	O
/	O
dim	O
,	O
matching	O
the	O
PixelCNN	Method
model	O
.	O
Our	O
best	O
CIFAR	Material
-	Material
10	Material
model	O
with	O
DMOL	Method
has	O
and	O
feed	Method
-	Method
forward	Method
layer	Method
layer	Method
dimension	Method
of	O
and	O
perform	O
attention	O
in	O
dimensions	O
.	O
ImageNet	Material
is	O
a	O
much	O
larger	O
dataset	O
,	O
with	O
many	O
more	O
categories	O
than	O
CIFAR	Material
-	Material
10	Material
,	O
requiring	O
more	O
parameters	O
in	O
a	O
generative	Method
model	Method
.	O
Our	O
ImageNet	Material
unconditioned	Method
generation	O
model	O
has	O
self	Method
-	Method
attention	Method
and	Method
feed	Method
-	Method
forward	Method
layers	Method
,	O
,	O
attention	O
heads	O
,	O
dimensions	O
in	O
the	O
feed	Method
-	Method
forward	Method
layers	Method
,	O
and	O
dropout	O
of	O
.	O
It	O
significantly	O
outperforms	O
the	O
Gated	O
PixelCNN	Method
and	O
establishes	O
a	O
new	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
of	O
bits	Metric
/	Metric
dim	Metric
with	O
checkpoint	Method
averaging	Method
.	O
We	O
trained	O
only	O
unconditional	Method
generative	Method
models	Method
on	O
ImageNet	Material
,	O
since	O
class	O
labels	O
were	O
not	O
available	O
in	O
the	O
dataset	O
provided	O
by	O
.	O
Table	O
[	O
reference	O
]	O
shows	O
that	O
growing	O
the	O
receptive	O
field	O
improves	O
perplexity	O
significantly	O
.	O
We	O
believe	O
this	O
to	O
highlight	O
a	O
key	O
advantage	O
of	O
local	Method
self	Method
-	Method
attention	Method
over	O
CNNs	Method
:	O
namely	O
that	O
the	O
number	O
of	O
parameters	O
used	O
by	O
local	Method
self	Method
-	Method
attention	Method
is	O
independent	O
of	O
the	O
size	O
of	O
the	O
receptive	O
field	O
.	O
Furthermore	O
,	O
while	O
,	O
self	Method
-	Method
attention	Method
still	O
requires	O
fewer	O
floating	O
-	O
point	O
operations	O
.	O
For	O
experiments	O
with	O
the	O
categorical	O
distribution	O
we	O
evaluated	O
both	O
coordinate	Method
encoding	Method
schemes	Method
described	O
in	O
Section	O
[	O
reference	O
]	O
and	O
found	O
no	O
difference	O
in	O
quality	Metric
.	O
For	O
DMOL	Method
we	O
only	O
evaluated	O
learned	O
coordinate	O
embeddings	O
.	O
subsection	O
:	O
Conditioning	O
on	O
Image	Task
Class	Task
We	O
represent	O
the	O
image	O
classes	O
as	O
learned	O
-	O
dimensional	O
embeddings	O
per	O
class	O
and	O
simply	O
add	O
the	O
respective	O
embedding	O
to	O
the	O
input	O
representation	O
of	O
every	O
input	O
position	O
together	O
with	O
the	O
positional	Method
encodings	Method
.	O
We	O
trained	O
the	O
class	O
-	O
conditioned	O
Image	O
Transformer	Method
on	O
CIFAR	Material
-	Material
10	Material
,	O
achieving	O
very	O
similar	O
log	Metric
-	Metric
likelihoods	Metric
as	O
in	O
unconditioned	Method
generation	O
.	O
The	O
perceptual	Metric
quality	Metric
of	O
generated	O
images	O
,	O
however	O
,	O
is	O
significantly	O
higher	O
than	O
that	O
of	O
our	O
unconditioned	Method
models	O
.	O
The	O
samples	O
from	O
our	O
-	O
layer	O
class	Method
-	Method
conditioned	Method
models	Method
in	O
Table	O
[	O
reference	O
]	O
,	O
show	O
that	O
we	O
can	O
generate	O
realistic	O
looking	O
images	O
for	O
some	O
categories	O
,	O
such	O
as	O
cars	O
and	O
trucks	O
.	O
subsection	O
:	O
Image	Task
Super	Task
-	Task
Resolution	Task
Super	Task
-	Task
resolution	Task
is	O
the	O
process	O
of	O
recovering	O
a	O
high	Task
resolution	Task
image	Task
from	O
a	O
low	O
resolution	O
image	O
while	O
generating	O
realistic	O
and	O
plausible	O
details	O
.	O
Following	O
PixelRecursiveSuperResolution	Method
,	O
in	O
our	O
experimental	O
setup	O
we	O
enlarge	O
an	O
pixel	O
image	O
four	O
-	O
fold	O
to	O
,	O
a	O
process	O
that	O
is	O
massively	O
underspecified	O
:	O
the	O
model	O
has	O
to	O
generate	O
aspects	O
such	O
as	O
texture	O
of	O
hair	O
,	O
makeup	O
,	O
skin	O
and	O
sometimes	O
even	O
gender	O
that	O
can	O
not	O
possibly	O
be	O
recovered	O
from	O
the	O
source	O
image	O
.	O
Here	O
,	O
we	O
use	O
the	O
Image	Method
Transformer	Method
in	O
an	O
encoder	Method
-	Method
decoder	Method
configuration	Method
,	O
connecting	O
the	O
encoder	Method
and	O
decoder	Method
through	O
an	O
attention	Method
mechanism	Method
aiayn	Method
.	O
For	O
the	O
encoder	Method
,	O
we	O
use	O
embeddings	O
for	O
RGB	O
intensities	O
for	O
each	O
pixel	O
in	O
the	O
8	O
image	O
and	O
add	O
dimensional	Method
positional	Method
encodings	Method
for	O
each	O
row	O
and	O
width	O
position	O
.	O
Since	O
the	O
input	O
is	O
small	O
,	O
we	O
flatten	O
the	O
whole	O
image	O
as	O
a	O
tensor	O
,	O
where	O
is	O
typically	O
.	O
We	O
then	O
feed	O
this	O
sequence	O
to	O
our	O
stack	O
of	O
transformer	Method
encoder	Method
layers	Method
that	O
uses	O
repeated	O
self	Method
-	Method
attention	Method
and	Method
feed	Method
forward	Method
layers	Method
.	O
In	O
the	O
encoder	Method
we	O
do	O
n’t	O
require	O
masking	O
,	O
but	O
allow	O
any	O
input	O
pixel	O
to	O
attend	O
to	O
any	O
other	O
pixel	O
.	O
In	O
the	O
decoder	Method
,	O
we	O
use	O
a	O
stack	Method
of	Method
local	Method
self	Method
-	Method
attention	Method
,	O
encoder	Method
-	Method
decoder	Method
-	Method
attention	Method
and	O
feed	Method
-	Method
forward	Method
layers	Method
.	O
We	O
found	O
using	O
two	O
to	O
three	O
times	O
fewer	O
encoder	O
than	O
decoder	O
layers	O
to	O
be	O
ideal	O
for	O
this	O
task	O
.	O
We	O
perform	O
end	O
-	O
to	O
-	O
end	Task
training	Task
of	O
the	O
encoder	Method
-	Method
decoder	Method
model	Method
for	O
Super	Task
resolution	Task
using	O
the	O
log	Metric
-	Metric
likelihood	Metric
objective	Metric
function	Metric
.	O
Our	O
method	O
generates	O
higher	O
resolution	O
images	O
that	O
look	O
plausible	O
and	O
realistic	O
across	O
two	O
datasets	O
.	O
For	O
both	O
of	O
the	O
following	O
data	O
sets	O
,	O
we	O
resized	O
the	O
image	O
to	O
pixels	O
for	O
the	O
input	O
and	O
pixels	O
for	O
the	O
label	O
using	O
TensorFlow	Method
’s	Method
interpolation	Method
method	Method
.	O
paragraph	O
:	O
CelebA	O
We	O
trained	O
both	O
our	O
1D	Method
Local	Method
and	O
2D	Method
Local	Method
models	Method
on	O
the	O
standard	O
CelebA	Material
data	Material
set	Material
of	Material
celebrity	Material
faces	Material
with	O
cropped	O
boundaries	O
.	O
With	O
the	O
1D	Method
Local	Method
,	O
we	O
achieve	O
a	O
negative	Metric
log	Metric
likelihood	Metric
(	O
NLL	Metric
)	O
of	O
bits	O
/	O
dim	O
on	O
the	O
dev	O
set	O
,	O
using	O
,	O
memory	O
size	O
of	O
,	O
self	Method
-	Method
attention	Method
and	O
feed	Method
-	Method
forward	Method
layers	Method
,	O
,	O
attention	O
heads	O
,	O
dimensions	O
in	O
the	O
feed	Method
-	Method
forward	Method
layers	Method
,	O
and	O
a	O
dropout	Method
of	O
.	O
With	O
the	O
2D	Method
Local	Method
model	Method
,	O
we	O
only	O
change	O
the	O
query	O
and	O
memory	O
to	O
now	O
represent	O
a	O
block	O
of	O
size	O
pixels	O
and	O
pixels	O
respectively	O
.	O
This	O
model	O
achieves	O
a	O
NLL	O
of	O
bits	O
/	O
dim	O
.	O
Existing	O
automated	Metric
metrics	Metric
like	O
pSNR	Method
,	O
SSIM	Method
and	O
MS	Method
-	Method
SSIM	Method
have	O
been	O
shown	O
to	O
not	O
correlate	O
with	O
perceptual	Metric
image	Metric
quality	Metric
PixelRecursiveSuperResolution	Metric
.	O
Hence	O
,	O
we	O
conducted	O
a	O
human	Task
evaluation	Task
study	O
on	O
Amazon	Material
Mechanical	Material
Turk	Material
where	O
each	O
worker	O
is	O
required	O
to	O
make	O
a	O
binary	O
choice	O
when	O
shown	O
one	O
generated	O
and	O
one	O
real	O
image	O
.	O
Following	O
the	O
same	O
procedure	O
for	O
the	O
evaluation	O
study	O
as	O
,	O
we	O
show	O
pairs	O
of	O
images	O
,	O
selected	O
randomly	O
from	O
the	O
validation	O
set	O
,	O
to	O
workers	O
each	O
.	O
Each	O
generated	O
and	O
original	O
image	O
is	O
upscaled	O
to	O
pixels	O
using	O
the	O
Bilinear	Method
interpolation	Method
method	Method
.	O
Each	O
worker	O
then	O
has	O
-	O
seconds	O
to	O
make	O
a	O
choice	O
between	O
these	O
two	O
images	O
.	O
In	O
our	O
method	O
,	O
workers	O
choose	O
images	O
from	O
our	O
model	O
up	O
to	O
%	O
of	O
the	O
time	O
,	O
a	O
significant	O
improvement	O
over	O
previous	O
models	O
.	O
Sampling	O
temperature	O
of	O
and	O
2D	O
local	O
attention	O
maximized	O
perceptual	Metric
quality	Metric
as	O
measured	O
by	O
this	O
evaluation	O
.	O
To	O
measure	O
how	O
well	O
the	O
high	O
resolution	O
samples	O
correspond	O
to	O
the	O
low	O
resolution	O
input	O
,	O
we	O
calculate	O
Consistency	Metric
,	O
the	O
distance	Metric
between	O
the	O
low	O
resolution	O
input	O
and	O
a	O
bicubic	Method
downsampled	Method
version	Method
of	O
the	O
high	O
resolution	O
sample	O
.	O
We	O
observe	O
a	O
Consistency	Metric
score	Metric
of	O
which	O
is	O
on	O
par	O
with	O
the	O
models	O
in	O
.	O
We	O
quantify	O
that	O
our	O
models	O
are	O
more	O
effective	O
than	O
exemplar	Method
based	Method
Super	Method
Resolution	Method
techniques	Method
like	O
Nearest	Method
Neighbors	Method
,	O
which	O
perform	O
a	O
naive	O
look	O
-	O
up	O
of	O
the	O
training	O
data	O
to	O
find	O
the	O
high	O
resolution	O
output	O
.	O
We	O
take	O
a	O
bicubic	Method
down	Method
-	Method
sampled	Method
version	Method
of	O
our	O
high	O
resolution	O
sample	O
,	O
find	O
the	O
nearest	O
low	O
resolution	O
input	O
image	O
in	O
the	O
training	O
data	O
for	O
that	O
sample	O
,	O
and	O
calculate	O
the	O
MS	Metric
-	Metric
SSIM	Metric
score	Metric
between	O
the	O
high	O
resolution	O
sample	O
and	O
the	O
corresponding	O
high	O
resolution	O
image	O
in	O
the	O
training	O
data	O
.	O
On	O
average	O
,	O
we	O
get	O
a	O
MS	Metric
-	Metric
SSIM	Metric
score	Metric
of	O
,	O
on	O
samples	O
from	O
the	O
validation	O
set	O
,	O
which	O
shows	O
that	O
our	O
models	O
do	O
n’t	O
merely	O
learn	O
to	O
copy	O
training	O
images	O
but	O
generate	O
high	O
-	O
quality	O
images	O
by	O
adding	O
synthesized	O
details	O
on	O
the	O
low	O
resolution	O
input	O
image	O
.	O
paragraph	O
:	O
CIFAR	Material
-	Material
10	Material
We	O
also	O
trained	O
a	O
super	Method
-	Method
resolution	Method
model	Method
on	O
the	O
CIFAR	Material
-	Material
10	Material
data	Material
set	Material
.	O
Our	O
model	O
reached	O
a	O
negative	Metric
log	Metric
-	Metric
likelihood	Metric
of	O
using	O
1D	Method
local	Method
attention	Method
and	O
using	O
2D	Method
local	Method
attention	Method
on	O
the	O
test	O
set	O
.	O
As	O
seen	O
in	O
Figure	O
[	O
reference	O
]	O
,	O
our	O
model	O
commonly	O
generates	O
plausible	O
looking	O
objects	O
even	O
though	O
the	O
input	O
images	O
seem	O
to	O
barely	O
show	O
any	O
discernible	O
structure	O
beyond	O
coarse	O
shapes	O
.	O
section	O
:	O
Conclusion	O
In	O
this	O
work	O
we	O
demonstrate	O
that	O
models	O
based	O
on	O
self	Method
-	Method
attention	Method
can	O
operate	O
effectively	O
on	O
modalities	O
other	O
than	O
text	O
,	O
and	O
through	O
local	Method
self	Method
-	Method
attention	Method
scale	O
to	O
significantly	O
larger	O
structures	O
than	O
sentences	O
.	O
With	O
fewer	O
layers	O
,	O
its	O
larger	O
receptive	O
fields	O
allow	O
the	O
Image	Method
Transformer	Method
to	O
significantly	O
improve	O
over	O
the	O
state	O
of	O
the	O
art	O
in	O
unconditional	O
,	O
probabilistic	Task
image	Task
modeling	Task
of	O
comparatively	O
complex	O
images	O
from	O
ImageNet	Material
as	O
well	O
as	O
super	Task
-	Task
resolution	Task
.	O
We	O
further	O
hope	O
to	O
have	O
provided	O
additional	O
evidence	O
that	O
even	O
in	O
the	O
light	O
of	O
generative	Method
adversarial	Method
networks	Method
,	O
likelihood	Method
-	Method
based	Method
models	Method
of	Method
images	Method
is	O
very	O
much	O
a	O
promising	O
area	O
for	O
further	O
research	O
-	O
as	O
is	O
using	O
network	Method
architectures	Method
such	O
as	O
the	O
Image	Method
Transformer	Method
in	O
GANs	Method
.	O
In	O
future	O
work	O
we	O
would	O
like	O
to	O
explore	O
a	O
broader	O
variety	O
of	O
conditioning	O
information	O
including	O
free	O
-	O
form	O
text	O
,	O
as	O
previously	O
proposed	O
Mansimov15	O
,	O
and	O
tasks	O
combining	O
modalities	O
such	O
as	O
language	Method
-	Method
driven	Method
editing	Method
of	Method
images	Method
.	O
Fundamentally	O
,	O
we	O
aim	O
to	O
move	O
beyond	O
still	O
images	O
to	O
video	O
Kalchbrenner16	O
and	O
towards	O
applications	O
in	O
model	Method
-	Method
based	Method
reinforcement	Method
learning	Method
.	O
bibliography	O
:	O
References	O
