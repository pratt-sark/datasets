Feature Method
Pyramid Method
Networks Method
for O
Object Task
Detection Task
section O
: O
Abstract O
Feature Method
pyramids Method
are O
a O
basic O
component O
in O
recognition Method
systems Method
for O
detecting Task
objects Task
at O
different O
scales O
. O
But O
recent O
deep Method
learning Method
object Method
detectors Method
have O
avoided O
pyramid Method
representations Method
, O
in O
part O
because O
they O
are O
compute O
and O
memory O
intensive O
. O
In O
this O
paper O
, O
we O
exploit O
the O
inherent O
multi O
- O
scale O
, O
pyramidal O
hierarchy O
of O
deep Method
convolutional Method
networks Method
to O
construct O
feature O
pyramids O
with O
marginal O
extra O
cost O
. O
A O
topdown Method
architecture Method
with O
lateral O
connections O
is O
developed O
for O
building O
high Task
- Task
level Task
semantic Task
feature Task
maps Task
at O
all O
scales O
. O
This O
architecture O
, O
called O
a O
Feature Method
Pyramid Method
Network Method
( O
FPN Method
) O
, O
shows O
significant O
improvement O
as O
a O
generic O
feature Method
extractor Method
in O
several O
applications O
. O
Using O
FPN Method
in O
a O
basic O
Faster Method
R Method
- Method
CNN Method
system Method
, O
our O
method O
achieves O
state O
- O
of O
- O
the O
- O
art O
singlemodel O
results O
on O
the O
COCO Material
detection Material
benchmark Material
without O
bells O
and O
whistles O
, O
surpassing O
all O
existing O
single O
- O
model O
entries O
including O
those O
from O
the O
COCO Material
2016 O
challenge O
winners O
. O
In O
addition O
, O
our O
method O
can O
run O
at O
6 O
FPS O
on O
a O
GPU O
and O
thus O
is O
a O
practical O
and O
accurate O
solution O
to O
multi Task
- Task
scale Task
object Task
detection Task
. O
Code O
will O
be O
made O
publicly O
available O
. O
section O
: O
Introduction O
Recognizing Task
objects Task
at O
vastly O
different O
scales O
is O
a O
fundamental O
challenge O
in O
computer Task
vision Task
. O
Feature Method
pyramids Method
built O
upon O
image Method
pyramids Method
( O
for O
short O
we O
call O
these O
featurized Method
image Method
pyramids Method
) O
form O
the O
basis O
of O
a O
standard O
solution O
[ O
reference O
] O
( O
Fig O
. O
1 O
( O
a O
) O
) O
. O
These O
pyramids O
are O
scale O
- O
invariant O
in O
the O
sense O
that O
an O
object O
's O
scale O
change O
is O
offset O
by O
shifting O
its O
level O
in O
the O
pyramid O
. O
Intuitively O
, O
this O
property O
enables O
a O
model O
to O
detect O
objects O
across O
a O
large O
range O
of O
scales O
by O
scanning O
the O
model O
over O
both O
positions O
and O
pyramid O
levels O
. O
Featurized Method
image Method
pyramids Method
were O
heavily O
used O
in O
the O
era O
of O
hand O
- O
engineered O
features O
[ O
reference O
][ O
reference O
] O
. O
They O
were O
so O
critical O
that O
object Method
detectors Method
like O
DPM Method
[ O
reference O
] O
required O
dense Method
scale Method
sampling Method
to O
achieve O
good O
results O
( O
e.g. O
, O
10 O
scales O
per O
octave O
) O
. O
For O
recognition Task
tasks Task
, O
engineered O
features O
have O
largely O
been O
replaced O
with O
features O
computed O
by O
deep Method
convolutional Method
networks Method
( O
ConvNets Method
) O
[ O
reference O
][ O
reference O
] O
. O
Aside O
from O
being O
capable O
of O
representing O
higher O
- O
level O
semantics O
, O
ConvNets Method
are O
also O
more O
robust O
to O
variance O
in O
scale O
and O
thus O
facilitate O
recognition Task
from O
features O
computed O
on O
a O
single O
input O
scale O
[ O
reference O
][ O
reference O
][ O
reference O
] O
( O
Fig O
. O
1 O
( O
b O
) O
) O
. O
But O
even O
with O
this O
robustness O
, O
pyramids O
are O
still O
needed O
to O
get O
the O
most O
accurate O
results O
. O
All O
recent O
top O
entries O
in O
the O
ImageNet Material
[ O
reference O
] O
and O
COCO Material
[ O
reference O
] O
detection Task
challenges Task
use O
multi Method
- Method
scale Method
testing Method
on O
featurized Method
image Method
pyramids Method
( O
e.g. O
, O
[ O
reference O
][ O
reference O
] O
) O
. O
The O
principle O
advantage O
of O
featurizing O
each O
level O
of O
an O
image Method
pyramid Method
is O
that O
it O
produces O
a O
multi Method
- Method
scale Method
feature Method
representation Method
in O
which O
all O
levels O
are O
semantically O
strong O
, O
including O
the O
high O
- O
resolution O
levels O
. O
Nevertheless O
, O
featurizing O
each O
level O
of O
an O
image Method
pyramid Method
has O
obvious O
limitations O
. O
Inference Metric
time Metric
increases O
considerably O
( O
e.g. O
, O
by O
four O
times O
[ O
reference O
] O
) O
, O
making O
this O
approach O
impractical O
for O
real O
applications O
. O
Moreover O
, O
training O
deep Method
networks Method
end O
- O
to O
- O
end O
on O
an O
image O
pyramid O
is O
infeasible O
in O
terms O
of O
memory O
, O
and O
so O
, O
if O
exploited O
, O
image O
pyramids O
are O
used O
only O
at O
test O
time O
[ O
reference O
][ O
reference O
][ O
reference O
][ O
reference O
] O
, O
which O
creates O
an O
inconsistency O
between O
train O
/ O
test O
- O
time Method
inference Method
. O
For O
these O
reasons O
, O
Fast Method
and O
Faster Method
R Method
- Method
CNN Method
[ O
reference O
][ O
reference O
] O
opt O
to O
not O
use O
featurized O
image O
pyramids O
under O
default O
settings O
. O
However O
, O
image Method
pyramids Method
are O
not O
the O
only O
way O
to O
compute O
a O
multi Method
- Method
scale Method
feature Method
representation Method
. O
A O
deep Method
ConvNet Method
computes O
a O
feature Method
hierarchy Method
layer Method
by Method
layer Method
, O
and O
with O
subsampling Method
layers Method
the O
feature O
hierarchy O
has O
an O
inherent O
multiscale O
, O
pyramidal O
shape O
. O
This O
in O
- O
network O
feature O
hierarchy O
produces O
feature O
maps O
of O
different O
spatial O
resolutions O
, O
but O
introduces O
large O
semantic O
gaps O
caused O
by O
different O
depths O
. O
The O
high O
- O
resolution O
maps O
have O
low O
- O
level O
features O
that O
harm O
their O
representational Method
capacity Method
for O
object Task
recognition Task
. O
The O
Single Method
Shot Method
Detector Method
( O
SSD Method
) O
[ O
reference O
] O
is O
one O
of O
the O
first O
attempts O
at O
using O
a O
ConvNet O
's O
pyramidal O
feature O
hierarchy O
as O
if O
it O
were O
a O
featurized O
image O
pyramid O
( O
Fig O
. O
1 O
( O
c O
) O
) O
. O
Ideally O
, O
the O
SSD Method
- Method
style Method
pyramid Method
would O
reuse O
the O
multi O
- O
scale O
feature O
maps O
from O
different O
layers O
computed O
in O
the O
forward O
pass O
and O
thus O
come O
free O
of O
cost O
. O
But O
to O
avoid O
using O
low O
- O
level O
features O
SSD O
foregoes O
reusing O
already O
computed O
layers O
and O
instead O
builds O
the O
pyramid O
starting O
from O
high O
up O
in O
the O
network O
( O
e.g. O
, O
conv4 O
3 O
of O
VGG Method
nets Method
[ O
reference O
] O
) O
and O
then O
by O
adding O
several O
new O
layers O
. O
Thus O
it O
misses O
the O
opportunity O
to O
reuse O
the O
higher O
- O
resolution O
maps O
of O
the O
feature O
hierarchy O
. O
We O
show O
that O
these O
are O
important O
for O
detecting Task
small Task
objects Task
. O
The O
goal O
of O
this O
paper O
is O
to O
naturally O
leverage O
the O
pyramidal O
shape O
of O
a O
ConvNet O
's O
feature O
hierarchy O
while O
creating O
a O
feature Method
pyramid Method
that O
has O
strong O
semantics O
at O
all O
scales O
. O
To O
achieve O
this O
goal O
, O
we O
rely O
on O
an O
architecture O
that O
combines O
low O
- O
resolution O
, O
semantically O
strong O
features O
with O
high O
- O
resolution O
, O
semantically O
weak O
features O
via O
a O
top Method
- Method
down Method
pathway Method
and O
lateral Method
connections Method
( O
Fig O
. O
1 O
( O
d O
) O
) O
. O
The O
result O
is O
a O
feature Method
pyramid Method
that O
has O
rich O
semantics O
at O
all O
levels O
and O
is O
built O
quickly O
from O
a O
single O
input O
image O
scale O
. O
In O
other O
words O
, O
we O
show O
how O
to O
create O
in Method
- Method
network Method
feature Method
pyramids Method
that O
can O
be O
used O
to O
replace O
featurized O
image O
pyramids O
without O
sacrificing O
representational O
power O
, O
speed O
, O
or O
memory O
. O
Similar O
architectures O
adopting O
top Method
- Method
down Method
and Method
skip Method
connections Method
are O
popular O
in O
recent O
research O
[ O
reference O
][ O
reference O
][ O
reference O
][ O
reference O
] O
. O
Their O
goals O
are O
to O
produce O
a O
single O
high O
- O
level O
feature O
map O
of O
a O
fine O
resolution O
on O
which O
the O
predictions O
are O
to O
be O
made O
( O
Fig O
. O
2 O
top O
) O
. O
On O
the O
contrary O
, O
our O
method O
leverages O
the O
architecture O
as O
a O
feature O
pyramid O
where O
predictions O
( O
e.g. O
, O
object O
detections O
) O
are O
independently O
made O
on O
each O
level O
( O
Fig O
. O
2 O
bottom O
) O
. O
Our O
model O
echoes O
a O
featurized Method
image Method
pyramid Method
, O
which O
has O
not O
been O
explored O
in O
these O
works O
. O
We O
evaluate O
our O
method O
, O
called O
a O
Feature Method
Pyramid Method
Network Method
( O
FPN Method
) O
, O
in O
various O
systems O
for O
detection Task
and Task
segmentation Task
[ O
reference O
][ O
reference O
][ O
reference O
] O
. O
Without O
bells O
and O
whistles O
, O
we O
report O
a O
state O
- O
of O
- O
the O
- O
art O
single O
- O
model O
result O
on O
the O
challenging O
COCO Material
detection Material
benchmark Material
[ O
reference O
] O
simply O
based O
on O
FPN Method
and O
predict O
predict O
predict O
predict O
Figure O
2 O
. O
Top O
: O
a O
top Method
- Method
down Method
architecture Method
with O
skip O
connections O
, O
where O
predictions O
are O
made O
on O
the O
finest O
level O
( O
e.g. O
, O
[ O
reference O
] O
) O
. O
Bottom O
: O
our O
model O
that O
has O
a O
similar O
structure O
but O
leverages O
it O
as O
a O
feature O
pyramid O
, O
with O
predictions O
made O
independently O
at O
all O
levels O
. O
a O
basic O
Faster Method
R Method
- Method
CNN Method
detector O
[ O
reference O
] O
, O
surpassing O
all O
existing O
heavily O
- O
engineered O
single O
- O
model O
entries O
of O
competition O
winners O
. O
In O
ablation O
experiments O
, O
we O
find O
that O
for O
bounding Task
box Task
proposals Task
, O
FPN Method
significantly O
increases O
the O
Average Metric
Recall Metric
( O
AR Metric
) O
by O
8.0 O
points O
; O
for O
object Task
detection Task
, O
it O
improves O
the O
COCO Material
- O
style O
Average Metric
Precision Metric
( O
AP Metric
) O
by O
2.3 O
points O
and O
PASCAL O
- O
style O
AP Metric
by O
3.8 O
points O
, O
over O
a O
strong O
single O
- O
scale O
baseline O
of O
Faster Method
R Method
- Method
CNN Method
on O
ResNets Method
[ O
reference O
] O
. O
Our O
method O
is O
also O
easily O
extended O
to O
mask Task
proposals Task
and O
improves O
both O
instance O
segmentation O
AR Metric
and O
speed Metric
over O
state O
- O
of O
- O
the O
- O
art O
methods O
that O
heavily O
depend O
on O
image O
pyramids O
. O
In O
addition O
, O
our O
pyramid Method
structure Method
can O
be O
trained O
end O
- O
toend O
with O
all O
scales O
and O
is O
used O
consistently O
at O
train Metric
/ Metric
test Metric
time Metric
, O
which O
would O
be O
memory O
- O
infeasible O
using O
image Method
pyramids Method
. O
As O
a O
result O
, O
FPNs Method
are O
able O
to O
achieve O
higher O
accuracy Metric
than O
all O
existing O
state O
- O
of O
- O
the O
- O
art O
methods O
. O
Moreover O
, O
this O
improvement O
is O
achieved O
without O
increasing O
testing Metric
time Metric
over O
the O
single O
- O
scale O
baseline O
. O
We O
believe O
these O
advances O
will O
facilitate O
future O
research O
and O
applications O
. O
Our O
code O
will O
be O
made O
publicly O
available O
. O
section O
: O
Related O
Work O
Hand O
- O
engineered O
features O
and O
early Method
neural Method
networks Method
. O
SIFT O
features O
[ O
reference O
] O
were O
originally O
extracted O
at O
scale O
- O
space O
extrema O
and O
used O
for O
feature Task
point Task
matching Task
. O
HOG O
features O
[ O
reference O
] O
, O
and O
later O
SIFT O
features O
as O
well O
, O
were O
computed O
densely O
over O
entire O
image O
pyramids O
. O
These O
HOG Method
and Method
SIFT Method
pyramids Method
have O
been O
used O
in O
numerous O
works O
for O
image O
classification Method
, O
object Task
detection Task
, O
human Task
pose Task
estimation Task
, O
and O
more O
. O
There O
has O
also O
been O
significant O
interest O
in O
computing O
featurized Task
image Task
pyramids Task
quickly O
. O
Dollár O
et O
al O
. O
[ O
reference O
] O
demonstrated O
fast O
pyramid Task
computation Task
by O
first O
computing O
a O
sparsely Method
sampled Method
( Method
in Method
scale Method
) Method
pyramid Method
and O
then O
interpolating O
missing O
levels O
. O
Before O
HOG Method
and O
SIFT Method
, O
early O
work O
on O
face Task
detection Task
with O
ConvNets Method
[ O
reference O
][ O
reference O
] O
computed O
shallow Method
networks Method
over O
image O
pyramids O
to O
detect O
faces O
across O
scales O
. O
Deep Method
ConvNet Method
object Method
detectors Method
. O
With O
the O
development O
of O
modern O
deep Method
ConvNets Method
[ O
reference O
] O
, O
object Method
detectors Method
like O
OverFeat Method
[ O
reference O
] O
and O
R Method
- Method
CNN Method
[ O
reference O
] O
showed O
dramatic O
improvements O
in O
accuracy Metric
. O
OverFeat O
adopted O
a O
strategy O
similar O
to O
early O
neural Method
network Method
face Method
detectors Method
by O
applying O
a O
ConvNet Method
as O
a O
sliding Method
window Method
detector Method
on O
an O
image O
pyramid O
. O
R Method
- Method
CNN Method
adopted O
a O
region Method
proposal Method
- Method
based Method
strategy Method
[ O
reference O
] O
in O
which O
each O
proposal O
was O
scale O
- O
normalized O
before O
classifying O
with O
a O
ConvNet Method
. O
SPPnet Method
[ O
reference O
] O
demonstrated O
that O
such O
region Method
- Method
based Method
detectors Method
could O
be O
applied O
much O
more O
efficiently O
on O
feature O
maps O
extracted O
on O
a O
single O
image O
scale O
. O
Recent O
and O
more O
accurate O
detection Method
methods Method
like O
Fast Method
R Method
- Method
CNN Method
[ O
reference O
] O
and O
Faster O
R Method
- Method
CNN Method
[ O
reference O
] O
advocate O
using O
features O
computed O
from O
a O
single O
scale O
, O
because O
it O
offers O
a O
good O
trade O
- O
off O
between O
accuracy Metric
and O
speed Metric
. O
Multi Task
- Task
scale Task
detection Task
, O
however O
, O
still O
performs O
better O
, O
especially O
for O
small O
objects O
. O
Methods O
using O
multiple O
layers O
. O
A O
number O
of O
recent O
approaches O
improve O
detection Task
and Task
segmentation Task
by O
using O
different O
layers O
in O
a O
ConvNet Method
. O
FCN Method
[ O
reference O
] O
sums O
partial O
scores O
for O
each O
category O
over O
multiple O
scales O
to O
compute O
semantic Task
segmentations Task
. O
Hypercolumns Method
[ O
reference O
] O
uses O
a O
similar O
method O
for O
object Task
instance Task
segmentation Task
. O
Several O
other O
approaches O
( O
HyperNet Method
[ O
reference O
] O
, O
ParseNet Method
[ O
reference O
] O
, O
and O
ION Method
[ O
reference O
] O
) O
concatenate O
features O
of O
multiple O
layers O
before O
computing O
predictions Task
, O
which O
is O
equivalent O
to O
summing O
transformed O
features O
. O
SSD Method
[ O
reference O
] O
and O
MS Method
- Method
CNN Method
[ O
reference O
] O
predict O
objects O
at O
multiple O
layers O
of O
the O
feature O
hierarchy O
without O
combining O
features O
or O
scores O
. O
There O
are O
recent O
methods O
exploiting O
lateral O
/ O
skip O
connections O
that O
associate O
low O
- O
level O
feature O
maps O
across O
resolutions O
and O
semantic O
levels O
, O
including O
U Method
- Method
Net Method
[ O
reference O
] O
and O
SharpMask Method
[ O
reference O
] O
for O
segmentation Task
, O
Recombinator Method
networks Method
[ O
reference O
] O
for O
face Task
detection Task
, O
and O
Stacked Method
Hourglass Method
networks Method
[ O
reference O
] O
for O
keypoint Task
estimation Task
. O
Ghiasi O
et O
al O
. O
[ O
reference O
] O
present O
a O
Laplacian Method
pyramid Method
presentation Method
for O
FCNs Method
to O
progressively O
refine O
segmentation Task
. O
Although O
these O
methods O
adopt O
architectures O
with O
pyramidal O
shapes O
, O
they O
are O
unlike O
featurized Method
image Method
pyramids Method
[ O
reference O
][ O
reference O
][ O
reference O
] O
where O
predictions O
are O
made O
independently O
at O
all O
levels O
, O
see O
Fig O
. O
2 O
. O
In O
fact O
, O
for O
the O
pyramidal O
architecture O
in O
Fig O
. O
2 O
( O
top O
) O
, O
image O
pyramids O
are O
still O
needed O
to O
recognize O
objects O
across O
multiple O
scales O
[ O
reference O
] O
. O
section O
: O
Feature Method
Pyramid Method
Networks Method
Our O
goal O
is O
to O
leverage O
a O
ConvNet O
's O
pyramidal O
feature O
hierarchy O
, O
which O
has O
semantics O
from O
low O
to O
high O
levels O
, O
and O
build O
a O
feature O
pyramid O
with O
high O
- O
level O
semantics O
throughout O
. O
The O
resulting O
Feature Method
Pyramid Method
Network Method
is O
generalpurpose O
and O
in O
this O
paper O
we O
focus O
on O
sliding Method
window Method
proposers Method
( O
Region Method
Proposal Method
Network Method
, O
RPN Method
for O
short O
) O
[ O
reference O
] O
and O
region Method
- Method
based Method
detectors Method
( O
Fast Method
R Method
- Method
CNN Method
) O
[ O
reference O
] O
. O
We O
also O
generalize O
FPNs Method
to O
instance Task
segmentation Task
proposals Task
in O
Sec O
. O
6 O
. O
Our O
method O
takes O
a O
single O
- O
scale O
image O
of O
an O
arbitrary O
size O
as O
input O
, O
and O
outputs O
proportionally O
sized O
feature O
maps O
at O
multiple O
levels O
, O
in O
a O
fully Method
convolutional Method
fashion Method
. O
This O
process O
is O
independent O
of O
the O
backbone Method
convolutional Method
architectures Method
( O
e.g. O
, O
[ O
reference O
][ O
reference O
][ O
reference O
] O
) O
, O
and O
in O
this O
paper O
we O
present O
results O
using O
ResNets Method
[ O
reference O
] O
. O
The O
construction O
of O
our O
pyramid O
involves O
a O
bottom O
- O
up O
pathway O
, O
a O
top O
- O
down O
pathway O
, O
and O
lateral O
connections O
, O
as O
introduced O
in O
the O
following O
. O
Bottom O
- O
up O
pathway O
. O
The O
bottom O
- O
up O
pathway O
is O
the O
feedforward Method
computation Method
of O
the O
backbone Method
ConvNet Method
, O
which O
computes O
a O
feature O
hierarchy O
consisting O
of O
feature O
maps O
at O
several O
scales O
with O
a O
scaling O
step O
of O
2 O
. O
There O
are O
often O
many O
layers O
producing O
output O
maps O
of O
the O
same O
size O
and O
we O
say O
these O
layers O
are O
in O
the O
same O
network O
stage O
. O
For O
our O
feature O
pyramid O
, O
we O
define O
one O
pyramid O
level O
for O
each O
stage O
. O
We O
choose O
the O
output O
of O
the O
last O
layer O
of O
each O
stage O
as O
our O
reference O
set O
of O
feature O
maps O
, O
which O
we O
will O
enrich O
to O
create O
our O
pyramid O
. O
This O
choice O
is O
natural O
since O
the O
deepest O
layer O
of O
each O
stage O
should O
have O
the O
strongest O
features O
. O
Specifically O
, O
for O
ResNets O
[ O
reference O
] O
we O
use O
the O
feature O
activations O
output O
by O
each O
stage O
's O
last O
residual O
block O
. O
We O
denote O
the O
output O
of O
these O
last O
residual O
blocks O
as O
{ O
C O
2 O
, O
C O
3 O
, O
C O
4 O
, O
C O
5 O
} O
for O
conv2 Method
, O
conv3 O
, O
conv4 Method
, O
and O
conv5 O
outputs O
, O
and O
note O
that O
they O
have O
strides O
of O
{ O
4 O
, O
8 O
, O
16 O
, O
32 O
} O
pixels O
with O
respect O
to O
the O
input O
image O
. O
We O
do O
not O
include O
conv1 O
into O
the O
pyramid O
due O
to O
its O
large O
memory O
footprint O
. O
Top O
- O
down O
pathway O
and O
lateral O
connections O
. O
The O
topdown Method
pathway Method
hallucinates O
higher O
resolution O
features O
by O
upsampling O
spatially O
coarser O
, O
but O
semantically O
stronger O
, O
feature O
maps O
from O
higher O
pyramid O
levels O
. O
These O
features O
are O
then O
enhanced O
with O
features O
from O
the O
bottom Method
- Method
up Method
pathway Method
via O
lateral Method
connections Method
. O
Each O
lateral O
connection O
merges O
feature O
maps O
of O
the O
same O
spatial O
size O
from O
the O
bottom O
- O
up O
pathway O
and O
the O
top O
- O
down O
pathway O
. O
The O
bottom Method
- Method
up Method
feature Method
map Method
is O
of O
lower O
- O
level O
semantics O
, O
but O
its O
activations O
are O
more O
accurately O
localized O
as O
it O
was O
subsampled O
fewer O
times O
. O
Fig O
. O
3 O
shows O
the O
building O
block O
that O
constructs O
our O
topdown Method
feature Method
maps Method
. O
With O
a O
coarser O
- O
resolution O
feature O
map O
, O
we O
upsample O
the O
spatial O
resolution O
by O
a O
factor O
of O
2 O
( O
using O
nearest Method
neighbor Method
upsampling Method
for O
simplicity O
) O
. O
The O
upsam Method
- Method
pled Method
map Method
is O
then O
merged O
with O
the O
corresponding O
bottom O
- O
up O
map O
( O
which O
undergoes O
a O
1×1 Method
convolutional Method
layer Method
to O
reduce O
channel O
dimensions O
) O
by O
element O
- O
wise O
addition O
. O
This O
process O
is O
iterated O
until O
the O
finest O
resolution O
map O
is O
generated O
. O
To O
start O
the O
iteration O
, O
we O
simply O
attach O
a O
1×1 Method
convolutional Method
layer Method
on O
C O
5 O
to O
produce O
the O
coarsest O
resolution O
map O
. O
Finally O
, O
we O
append O
a O
3×3 Method
convolution Method
on O
each O
merged O
map O
to O
generate O
the O
final O
feature O
map O
, O
which O
is O
to O
reduce O
the O
aliasing O
effect O
of O
upsampling O
. O
This O
final O
set O
of O
feature O
maps O
is O
called O
{ O
P O
2 O
, O
P O
3 O
, O
P O
4 O
, O
P O
5 O
} O
, O
corresponding O
to O
{ O
C O
2 O
, O
C O
3 O
, O
C O
4 O
, O
C O
5 O
} O
that O
are O
respectively O
of O
the O
same O
spatial O
sizes O
. O
Because O
all O
levels O
of O
the O
pyramid O
use O
shared Method
classifiers Method
/ Method
regressors Method
as O
in O
a O
traditional O
featurized Method
image Method
pyramid Method
, O
we O
fix O
the O
feature O
dimension O
( O
numbers O
of O
channels O
, O
denoted O
as O
d O
) O
in O
all O
the O
feature O
maps O
. O
We O
set O
d O
= O
256 O
in O
this O
paper O
and O
thus O
all O
extra O
convolutional Method
layers Method
have O
256 O
- O
channel O
outputs O
. O
There O
are O
no O
non O
- O
linearities O
in O
these O
extra O
layers O
, O
which O
we O
have O
empirically O
found O
to O
have O
minor O
impacts O
. O
Simplicity O
is O
central O
to O
our O
design O
and O
we O
have O
found O
that O
our O
model O
is O
robust O
to O
many O
design O
choices O
. O
We O
have O
experimented O
with O
more O
sophisticated O
blocks O
( O
e.g. O
, O
using O
multilayer O
residual O
blocks O
[ O
reference O
] O
as O
the O
connections O
) O
and O
observed O
marginally O
better O
results O
. O
Designing O
better O
connection O
modules O
is O
not O
the O
focus O
of O
this O
paper O
, O
so O
we O
opt O
for O
the O
simple O
design O
described O
above O
. O
section O
: O
Applications O
Our O
method O
is O
a O
generic O
solution O
for O
building O
feature Task
pyramids Task
inside O
deep Task
ConvNets Task
. O
In O
the O
following O
we O
adopt O
our O
method O
in O
RPN Method
[ O
reference O
] O
for O
bounding Task
box Task
proposal Task
generation Task
and O
in O
Fast Method
R Method
- Method
CNN Method
[ O
reference O
] O
for O
object Task
detection Task
. O
To O
demonstrate O
the O
simplicity O
and O
effectiveness O
of O
our O
method O
, O
we O
make O
minimal O
modifications O
to O
the O
original O
systems O
of O
[ O
reference O
][ O
reference O
] O
when O
adapting O
them O
to O
our O
feature Method
pyramid Method
. O
section O
: O
Feature Method
Pyramid Method
Networks Method
for O
RPN Method
RPN Method
[ O
reference O
] O
is O
a O
sliding Method
- Method
window Method
class Method
- Method
agnostic Method
object Method
detector Method
. O
In O
the O
original O
RPN Method
design O
, O
a O
small O
subnetwork O
is O
evaluated O
on O
dense O
3×3 O
sliding O
windows O
, O
on O
top O
of O
a O
singlescale Method
convolutional Method
feature Method
map Method
, O
performing O
object O
/ O
nonobject O
binary O
classification Method
and O
bounding Method
box Method
regression Method
. O
This O
is O
realized O
by O
a O
3×3 Method
convolutional Method
layer Method
followed O
by O
two O
sibling Method
1×1 Method
convolutions Method
for O
classification Method
and O
regression Task
, O
which O
we O
refer O
to O
as O
a O
network O
head O
. O
The O
object Task
/ Task
nonobject Task
criterion Task
and O
bounding O
box O
regression O
target O
are O
defined O
with O
respect O
to O
a O
set O
of O
reference O
boxes O
called O
anchors O
[ O
reference O
] O
. O
The O
anchors O
are O
of O
multiple O
pre O
- O
defined O
scales O
and O
aspect O
ratios O
in O
order O
to O
cover O
objects O
of O
different O
shapes O
. O
We O
adapt O
RPN Method
by O
replacing O
the O
single Method
- Method
scale Method
feature Method
map Method
with O
our O
FPN Method
. O
We O
attach O
a O
head O
of O
the O
same O
design O
( O
3×3 O
conv O
and O
two O
sibling O
1×1 O
convs O
) O
to O
each O
level O
on O
our O
feature O
pyramid O
. O
Because O
the O
head O
slides O
densely O
over O
all O
locations O
in O
all O
pyramid O
levels O
, O
it O
is O
not O
necessary O
to O
have O
multi O
- O
scale O
anchors O
on O
a O
specific O
level O
. O
Instead O
, O
we O
assign O
anchors O
of O
a O
single O
scale O
to O
each O
level O
. O
Formally O
, O
we O
define O
the O
anchors O
to O
have O
areas O
of O
{ O
32 O
2 O
, O
64 O
2 O
, O
128 O
2 O
, O
256 O
2 O
, O
512 O
2 O
} O
pixels O
on O
{ O
P O
2 O
, O
P O
3 O
, O
P O
4 O
, O
P O
5 O
, O
P O
6 O
} O
respectively O
. O
[ O
reference O
] O
As O
in O
[ O
reference O
] O
we O
also O
use O
anchors O
of O
multiple O
aspect O
ratios O
{ O
1:2 O
, O
1:1 O
, O
2:1 O
} O
at O
each O
level O
. O
So O
in O
total O
there O
are O
15 O
anchors O
over O
the O
pyramid O
. O
We O
assign O
training O
labels O
to O
the O
anchors O
based O
on O
their O
Intersection Metric
- Metric
over Metric
- Metric
Union Metric
( O
IoU Metric
) O
ratios O
with O
ground O
- O
truth O
bounding O
boxes O
as O
in O
[ O
reference O
] O
. O
Formally O
, O
an O
anchor O
is O
assigned O
a O
positive O
label O
if O
it O
has O
the O
highest O
IoU Metric
for O
a O
given O
groundtruth O
box O
or O
an O
IoU Metric
over O
0.7 O
with O
any O
ground O
- O
truth O
box O
, O
and O
a O
negative O
label O
if O
it O
has O
IoU Metric
lower O
than O
0.3 O
for O
all O
ground O
- O
truth O
boxes O
. O
Note O
that O
scales O
of O
ground O
- O
truth O
boxes O
are O
not O
explicitly O
used O
to O
assign O
them O
to O
the O
levels O
of O
the O
pyramid O
; O
instead O
, O
ground O
- O
truth O
boxes O
are O
associated O
with O
anchors O
, O
which O
have O
been O
assigned O
to O
pyramid O
levels O
. O
As O
such O
, O
we O
introduce O
no O
extra O
rules O
in O
addition O
to O
those O
in O
[ O
reference O
] O
. O
We O
note O
that O
the O
parameters O
of O
the O
heads O
are O
shared O
across O
all O
feature O
pyramid O
levels O
; O
we O
have O
also O
evaluated O
the O
alternative O
without O
sharing O
parameters O
and O
observed O
similar O
accuracy Metric
. O
The O
good O
performance O
of O
sharing O
parameters O
indicates O
that O
all O
levels O
of O
our O
pyramid O
share O
similar O
semantic O
levels O
. O
This O
advantage O
is O
analogous O
to O
that O
of O
using O
a O
featurized Method
image Method
pyramid Method
, O
where O
a O
common Method
head Method
classifier Method
can O
be O
applied O
to O
features O
computed O
at O
any O
image O
scale O
. O
With O
the O
above O
adaptations O
, O
RPN Method
can O
be O
naturally O
trained O
and O
tested O
with O
our O
FPN Method
, O
in O
the O
same O
fashion O
as O
in O
[ O
reference O
] O
. O
We O
elaborate O
on O
the O
implementation O
details O
in O
the O
experiments O
. O
section O
: O
Feature Method
Pyramid Method
Networks Method
for O
Fast Method
R Method
- Method
CNN Method
Fast Method
R Method
- Method
CNN Method
[ O
reference O
] O
is O
a O
region Method
- Method
based Method
object Method
detector Method
in O
which O
Region Method
- Method
of Method
- Method
Interest Method
( O
RoI Method
) O
pooling O
is O
used O
to O
extract O
features O
. O
Fast Method
R Method
- Method
CNN Method
is O
most O
commonly O
performed O
on O
a O
single O
- O
scale O
feature O
map O
. O
To O
use O
it O
with O
our O
FPN Method
, O
we O
need O
to O
assign O
RoIs O
of O
different O
scales O
to O
the O
pyramid O
levels O
. O
We O
view O
our O
feature Method
pyramid Method
as O
if O
it O
were O
produced O
from O
an O
image Method
pyramid Method
. O
Thus O
we O
can O
adapt O
the O
assignment Method
strategy Method
of O
region Method
- Method
based Method
detectors Method
[ O
reference O
][ O
reference O
] O
in O
the O
case O
when O
they O
are O
run O
on O
image O
pyramids O
. O
Formally O
, O
we O
assign O
an O
RoI Method
of O
width O
w O
and O
height O
h O
( O
on O
the O
input O
image O
to O
the O
network O
) O
to O
the O
level O
P O
k O
of O
our O
feature Method
pyramid Method
by O
: O
Here O
224 O
is O
the O
canonical Material
ImageNet Material
pre Material
- Material
training Material
size Material
, O
and O
k O
0 O
is O
the O
target O
level O
on O
which O
an O
RoI Method
with O
w O
× O
h O
= O
224 O
2 O
should O
be O
mapped O
into O
. O
Analogous O
to O
the O
ResNet O
- O
based O
Faster Method
R Method
- Method
CNN Method
system O
[ O
reference O
] O
that O
uses O
C O
4 O
as O
the O
single O
- O
scale O
feature O
map O
, O
we O
set O
k O
0 O
to O
4 O
. O
Intuitively O
, O
Eqn O
. O
( O
1 O
) O
means O
that O
if O
the O
RoI Method
's O
scale O
becomes O
smaller O
( O
say O
, O
1 O
/ O
2 O
of O
224 O
) O
, O
it O
should O
be O
mapped O
into O
a O
finer O
- O
resolution O
level O
( O
say O
, O
k O
= O
3 O
) O
. O
We O
attach O
predictor O
heads O
( O
in O
Fast Method
R Method
- Method
CNN Method
the O
heads O
are O
class Method
- Method
specific Method
classifiers Method
and O
bounding Method
box Method
regressors Method
) O
to O
all O
RoIs O
of O
all O
levels O
. O
Again O
, O
the O
heads O
all O
share O
parameters O
, O
regardless O
of O
their O
levels O
. O
In O
[ O
reference O
] O
, O
a O
ResNet O
's O
conv5 O
layers O
( O
a O
9 Method
- Method
layer Method
deep Method
subnetwork Method
) O
are O
adopted O
as O
the O
head O
on O
top O
of O
the O
conv4 O
features O
, O
but O
our O
method O
has O
already O
harnessed O
conv5 Method
to O
construct O
the O
feature O
pyramid O
. O
So O
unlike O
[ O
reference O
] O
, O
we O
simply O
adopt O
RoI Method
pooling O
to O
extract O
7×7 O
features O
, O
and O
attach O
two O
hidden O
1 O
, O
024 O
- O
d O
fully Method
- Method
connected Method
( O
fc Method
) O
layers O
( O
each O
followed O
by O
ReLU Method
) O
before O
the O
final O
classification Method
and O
bounding Method
box Method
regression Method
layers Method
. O
These O
layers O
are O
randomly O
initialized O
, O
as O
there O
are O
no O
pre O
- O
trained O
fc Method
layers O
available O
in O
ResNets Material
. O
Note O
that O
compared O
to O
the O
standard O
conv5 Method
head Method
, O
our O
2 O
- O
fc Method
MLP O
head O
is O
lighter O
weight O
and O
faster O
. O
Based O
on O
these O
adaptations O
, O
we O
can O
train O
and O
test O
Fast Method
R Method
- Method
CNN Method
on O
top O
of O
the O
feature O
pyramid O
. O
Implementation O
details O
are O
given O
in O
the O
experimental O
section O
. O
section O
: O
Experiments O
on O
Object Task
Detection Task
We O
perform O
experiments O
on O
the O
80 O
category O
COCO Material
detection O
dataset O
[ O
reference O
] O
. O
We O
train O
using O
the O
union O
of O
80k O
train O
images O
and O
a O
35k O
subset O
of O
val O
images O
( O
trainval35k O
[ O
reference O
] O
) O
, O
and O
report O
ablations Method
on O
a O
5k O
subset O
of O
val O
images O
( O
minival O
) O
. O
We O
also O
report O
final O
results O
on O
the O
standard O
test O
set O
( O
test O
- O
std O
) O
[ O
reference O
] O
which O
has O
no O
disclosed O
labels O
. O
As O
is O
common O
practice O
[ O
reference O
] O
, O
all O
network Method
backbones Method
are O
pre O
- O
trained O
on O
the O
ImageNet1k O
classification Method
set O
[ O
reference O
] O
and O
then O
fine O
- O
tuned O
on O
the O
detection O
dataset O
. O
We O
use O
the O
pre O
- O
trained O
ResNet Method
- Method
50 Method
and O
ResNet Method
- Method
101 Method
models Method
that O
are O
publicly O
available O
. O
[ O
reference O
] O
Our O
code O
is O
a O
reimplementation O
of O
py Method
- Method
faster Method
- Method
rcnn Method
3 Method
using O
Caffe2 Method
. O
[ O
reference O
] O
section O
: O
Region Method
Proposal Method
with O
RPN Method
We O
evaluate O
the O
COCO Material
- O
style O
Average Metric
Recall Metric
( O
AR Metric
) O
and O
AR Metric
on O
small O
, O
medium O
, O
and O
large O
objects O
( O
AR Metric
s O
, O
AR Metric
m O
, O
and O
AR Metric
l O
) O
following O
the O
definitions O
in O
[ O
reference O
] O
. O
We O
report O
results O
for O
100 O
and O
1000 O
proposals O
per O
images O
( O
AR Metric
100 O
and O
AR Metric
1k O
) O
. O
Implementation O
details O
. O
All O
architectures O
in O
Table O
1 O
are O
trained O
end O
- O
to O
- O
end O
. O
The O
input O
image O
is O
resized O
such O
that O
its O
shorter O
side O
has O
800 O
pixels O
. O
We O
adopt O
synchronized Method
SGD Method
training Method
on O
8 O
GPUs Method
. O
A O
mini O
- O
batch O
involves O
2 O
images O
per O
GPU O
and O
256 O
anchors O
per O
image O
. O
We O
use O
a O
weight O
decay O
of O
0.0001 O
and O
a O
momentum O
of O
0.9 O
. O
The O
learning Metric
rate Metric
is O
0.02 O
for O
the O
first O
30k O
mini O
- O
batches O
and O
0.002 O
for O
the O
next O
10k O
. O
For O
all O
RPN Method
experiments O
( O
including O
baselines O
) O
, O
we O
include O
the O
anchor O
boxes O
that O
are O
outside O
the O
image O
for O
training O
, O
which O
is O
unlike O
[ O
reference O
] O
where O
these O
anchor O
boxes O
are O
ignored O
. O
Other O
implementation O
details O
are O
as O
in O
[ O
reference O
] O
. O
Training O
RPN Method
with O
FPN Method
on O
8 O
GPUs Method
takes O
about O
8 O
hours O
on O
COCO Material
. O
1 O
( O
a O
) O
) O
. O
In O
addition O
, O
the O
performance O
on O
small O
objects O
( O
AR Metric
1k O
s O
) O
is O
boosted O
by O
a O
large O
margin O
of O
12.9 O
points O
. O
Our O
pyramid Method
representation Method
greatly O
improves O
RPN Method
's O
robustness Metric
to O
object O
scale O
variation O
. O
How O
important O
is O
top O
- O
down O
enrichment O
? O
Table O
1 O
( O
d O
) O
shows O
the O
results O
of O
our O
feature Method
pyramid Method
without O
the O
topdown Method
pathway Method
. O
With O
this O
modification O
, O
the O
1×1 O
lateral O
connections O
followed O
by O
3×3 Method
convolutions Method
are O
attached O
to O
the O
bottom O
- O
up O
pyramid O
. O
This O
architecture O
simulates O
the O
effect O
of O
reusing O
the O
pyramidal O
feature O
hierarchy O
( O
Fig O
. O
1 O
( O
b O
) O
) O
. O
The O
results O
in O
Table O
1 O
( O
d O
) O
are O
just O
on O
par O
with O
the O
RPN Method
baseline O
and O
lag O
far O
behind O
ours O
. O
We O
conjecture O
that O
this O
is O
because O
there O
are O
large O
semantic O
gaps O
between O
different O
levels O
on O
the O
bottom O
- O
up O
pyramid O
( O
Fig O
. O
1 O
( O
b O
) O
) O
, O
especially O
for O
very O
deep Task
ResNets Task
. O
We O
have O
also O
evaluated O
a O
variant O
of O
Table Method
1 Method
( Method
d Method
) O
without O
sharing O
the O
parameters O
of O
the O
heads O
, O
but O
observed O
similarly O
degraded O
performance O
. O
This O
issue O
can O
not O
be O
simply O
remedied O
by O
level O
- O
specific O
heads O
. O
How O
important O
are O
lateral O
connections O
? O
Table O
1 O
( O
e O
) O
shows O
the O
ablation O
results O
of O
a O
top Method
- Method
down Method
feature Method
pyramid Method
without O
the O
1×1 O
lateral O
connections O
. O
This O
top Method
- Method
down Method
pyramid Method
has O
strong O
semantic O
features O
and O
fine O
resolutions O
. O
But O
we O
argue O
that O
the O
locations O
of O
these O
features O
are O
not O
precise O
, O
because O
these O
maps O
have O
been O
downsampled O
and O
upsampled O
several O
times O
. O
More O
precise O
locations O
of O
features O
can O
be O
directly O
passed O
from O
the O
finer O
levels O
of O
the O
bottom O
- O
up O
maps O
via O
the O
lateral O
connections O
to O
the O
top O
- O
down O
maps O
. O
As O
a O
results O
, O
FPN Method
has O
an O
AR Metric
1k O
score O
10 O
points O
higher O
than O
Table O
1 O
section O
: O
( O
e O
) O
. O
How O
important O
are O
pyramid Method
representations Method
? O
Instead O
of O
resorting O
to O
pyramid Method
representations Method
, O
one O
can O
attach O
the O
head O
to O
the O
highest O
- O
resolution O
, O
strongly O
semantic O
feature O
maps O
of O
P O
2 O
( O
i.e. O
, O
the O
finest O
level O
in O
our O
pyramids O
) O
. O
Similar O
to O
the O
single O
- O
scale Method
baselines Method
, O
we O
assign O
all O
anchors O
to O
the O
P O
2 O
feature O
map O
. O
This O
variant O
( O
Table O
1 O
( O
f O
) O
) O
is O
better O
than O
the O
baseline O
but O
inferior O
to O
our O
approach O
. O
RPN Method
is O
a O
sliding Method
window Method
detector Method
with O
a O
fixed O
window O
size O
, O
so O
scanning O
over O
pyramid O
levels O
can O
increase O
its O
robustness Metric
to O
scale O
variance O
. O
In O
addition O
, O
we O
note O
that O
using O
P Method
2 Method
alone O
leads O
to O
more O
anchors O
( O
750k O
, O
Table O
1 O
. O
Bounding Method
box Method
proposal Method
results O
using O
RPN Method
[ O
reference O
] O
, O
evaluated O
on O
the O
COCO Material
minival O
set O
. O
All O
models O
are O
trained O
on O
trainval35k O
. O
The O
columns O
" O
lateral O
" O
and O
" O
top O
- O
down O
" O
denote O
the O
presence O
of O
lateral O
and O
top O
- O
down O
connections O
, O
respectively O
. O
The O
column O
" O
feature O
" O
denotes O
the O
feature O
maps O
on O
which O
the O
heads O
are O
attached O
. O
All O
results O
are O
based O
on O
ResNet Method
- Method
50 Method
and O
share O
the O
same O
hyper O
- O
parameters O
. O
section O
: O
Object Task
Detection Task
with O
Fast Method
/ O
Faster Method
R Method
- Method
CNN Method
Next O
we O
investigate O
FPN Method
for O
region Method
- Method
based Method
( Method
non Method
- Method
sliding Method
window Method
) Method
detectors Method
. O
We O
evaluate O
object Task
detection Task
by O
the O
COCO Metric
- Metric
style Metric
Average Metric
Precision Metric
( O
AP Metric
) O
and O
PASCAL O
- O
style O
AP Metric
( O
at O
a O
single O
IoU Metric
threshold O
of O
0.5 O
) O
. O
We O
also O
report O
COCO Metric
AP Metric
on O
objects O
of O
small O
, O
medium O
, O
and O
large O
sizes O
( O
namely O
, O
AP Metric
s O
, O
AP Metric
m O
, O
and O
AP Metric
l O
) O
following O
the O
definitions O
in O
[ O
reference O
] O
. O
Implementation O
details O
. O
The O
input O
image O
is O
resized O
such O
that O
its O
shorter O
side O
has O
800 O
pixels O
. O
Synchronized Method
SGD Method
is O
used O
to O
train O
the O
model O
on O
8 O
GPUs O
. O
Each O
mini O
- O
batch O
involves O
2 O
image O
per O
GPU O
and O
512 O
RoIs O
per O
image O
. O
We O
use O
a O
weight O
decay O
of O
0.0001 O
and O
a O
momentum O
of O
0.9 O
. O
The O
learning Metric
rate Metric
is O
0.02 O
for O
the O
first O
60k O
mini O
- O
batches O
and O
0.002 O
for O
the O
next O
20k O
. O
We O
use O
2000 O
RoIs O
per O
image O
for O
training O
and O
1000 O
for O
testing O
. O
Training O
Fast Method
R Method
- Method
CNN Method
with O
FPN Method
takes O
about O
10 O
hours O
on O
the O
COCO Material
dataset O
. O
section O
: O
Fast Method
R Method
- Method
CNN Method
( O
on O
fixed O
proposals O
) O
To O
better O
investigate O
FPN Method
's O
effects O
on O
the O
region Method
- Method
based Method
detector Method
alone O
, O
we O
conduct O
ablations O
of O
Fast Method
R Method
- Method
CNN Method
on O
a O
fixed O
set O
of O
proposals O
. O
We O
choose O
to O
freeze O
the O
proposals O
as O
computed O
by O
RPN Method
on O
FPN Method
( O
Table O
1 O
( O
c O
) O
) O
, O
because O
it O
has O
good O
performance O
on O
small O
objects O
that O
are O
to O
be O
recognized O
by O
the O
detector O
. O
For O
simplicity O
we O
do O
not O
share O
features O
between O
Fast Method
R Method
- Method
CNN Method
and O
RPN Method
, O
except O
when O
specified O
. O
As O
a O
ResNet O
- O
based O
Fast Method
R Method
- Method
CNN Method
baseline O
, O
following O
[ O
reference O
] O
, O
we O
adopt O
RoI Method
pooling O
with O
an O
output O
size O
of O
14×14 O
and O
attach O
all O
conv5 Method
layers Method
as O
the O
hidden O
layers O
of O
the O
head O
. O
This O
gives O
an O
AP Metric
of O
31.9 O
in O
Table O
2 O
( O
a O
) O
. O
Table O
2 O
( O
b O
) O
is O
a O
baseline O
exploiting O
an O
MLP Method
head Method
with O
2 O
hidden O
fc Method
layers O
, O
similar O
to O
the O
head O
in O
our O
architecture O
. O
It O
gets O
an O
AP Metric
of O
28.8 O
, O
indicating O
that O
the O
2 O
- O
fc Method
head O
does O
not O
give O
us O
any O
orthogonal O
advantage O
over O
the O
baseline O
in O
Table O
2 O
( O
a O
) O
. O
Table O
2 O
( O
c O
) O
shows O
the O
results O
of O
our O
FPN Method
in O
Fast Method
R Method
- Method
CNN Method
. O
Comparing O
with O
the O
baseline O
in O
Table O
2 O
( O
a O
) O
, O
our O
method O
improves O
AP Metric
by O
2.0 O
points O
and O
small O
object O
AP Metric
by O
2.1 O
points O
. O
Comparing O
with O
the O
baseline O
that O
also O
adopts O
a O
2fc O
head O
( O
Table O
2 O
( O
b O
) O
) O
, O
our O
method O
improves O
AP Metric
by O
5.1 O
points O
. O
[ O
reference O
] O
These O
comparisons O
indicate O
that O
our O
feature Method
pyramid Method
is O
superior O
to O
single Method
- Method
scale Method
features Method
for O
a O
region Method
- Method
based Method
object Method
detector Method
. O
nections O
or O
removing O
lateral O
connections O
leads O
to O
inferior O
results O
, O
similar O
to O
what O
we O
have O
observed O
in O
the O
above O
subsection O
for O
RPN Method
. O
It O
is O
noteworthy O
that O
removing O
top O
- O
down O
connections O
( O
Table O
2 O
( O
d O
) O
) O
significantly O
degrades O
the O
accuracy Metric
, O
suggesting O
that O
Fast Method
R Method
- Method
CNN Method
suffers O
from O
using O
the O
low O
- O
level O
features O
at O
the O
high O
- O
resolution O
maps O
. O
In O
Table O
2 O
( O
f O
) O
, O
we O
adopt O
Fast Method
R Method
- Method
CNN Method
on O
the O
single O
finest O
scale O
feature O
map O
of O
P O
2 O
. O
Its O
result O
( O
33.4 O
AP Metric
) O
is O
marginally O
worse O
than O
that O
of O
using O
all O
pyramid O
levels O
( O
33.9 O
AP Metric
, O
Table O
2 O
( O
c O
) O
) O
. O
We O
argue O
that O
this O
is O
because O
RoI Method
pooling O
is O
a O
warping Method
- Method
like Method
operation Method
, O
which O
is O
less O
sensitive O
to O
the O
region O
's O
scales O
. O
Despite O
the O
good O
accuracy Metric
of O
this O
variant O
, O
it O
is O
based O
on O
the O
RPN Method
proposals O
of O
{ O
P O
k O
} O
and O
has O
thus O
already O
benefited O
from O
the O
pyramid Method
representation Method
. O
section O
: O
Faster Method
R Method
- Method
CNN Method
( O
on O
consistent O
proposals O
) O
In O
the O
above O
we O
used O
a O
fixed O
set O
of O
proposals O
to O
investigate O
the O
detectors O
. O
But O
in O
a O
Faster Method
R Method
- Method
CNN Method
system Method
[ O
reference O
] O
, O
the O
RPN Method
and O
Fast Method
R Method
- Method
CNN Method
must O
use O
the O
same O
network O
backbone O
in O
order O
to O
make O
feature Task
sharing Task
possible O
. O
Table O
3 O
shows O
the O
comparisons O
between O
our O
method O
and O
two O
baselines O
, O
all O
using O
consistent Method
backbone Method
architectures Method
for O
RPN Method
and O
Fast Method
R Method
- Method
CNN Method
. O
Table O
3 O
( O
a O
) O
shows O
our O
reproduction O
of O
the O
baseline O
Faster Method
R Method
- Method
CNN Method
system O
as O
described O
in O
[ O
reference O
] O
. O
Under O
controlled O
settings O
, O
our O
FPN Method
( O
Table O
3 O
( O
c O
) O
) O
is O
better O
than O
this O
strong O
baseline O
by O
2.3 O
points O
AP Metric
and O
3.8 O
points O
AP@0.5 O
. O
Note O
that O
Table O
3 O
( O
a O
) O
and O
( O
b O
) O
are O
baselines O
that O
are O
much O
stronger O
than O
the O
baseline O
provided O
by O
He O
et O
al O
. O
[ O
reference O
] O
in O
Table O
3 O
( O
* O
) O
. O
We O
find O
the O
following O
implementations O
contribute O
to O
the O
gap O
: O
( O
i O
) O
We O
use O
an O
image O
scale O
of O
800 O
pixels O
instead O
of O
600 O
in O
[ O
reference O
][ O
reference O
] O
; O
( O
ii O
) O
We O
train O
with O
512 O
RoIs O
per O
image O
which O
accelerate O
convergence Task
, O
in O
contrast O
to O
64 O
RoIs O
in O
[ O
reference O
][ O
reference O
] O
; O
( O
iii O
) O
We O
use O
5 O
scale O
anchors O
instead O
of O
4 O
in O
[ O
reference O
] O
( O
adding O
32 O
2 O
) O
; O
( O
iv O
) O
At O
test O
time O
we O
use O
1000 O
proposals O
per O
image O
instead O
of O
300 O
in O
[ O
reference O
] O
. O
So O
comparing O
with O
He O
et O
al O
. O
's O
ResNet Method
- Method
50 Method
Faster Method
R Method
- Method
CNN Method
baseline Method
in O
Table O
3 O
( O
* O
) O
, O
our O
method O
improves O
AP Metric
by O
7.6 O
points O
and O
AP@0.5 O
by O
9.6 O
points O
. O
Sharing O
features O
. O
In O
the O
above O
, O
for O
simplicity O
we O
do O
not O
share O
the O
features O
between O
RPN Method
and O
Fast Method
R Method
- Method
CNN Method
. O
In O
Ta O
- O
Table O
5 O
. O
More O
object Task
detection Task
results O
using O
Faster Method
R Method
- Method
CNN Method
and O
our O
FPNs Method
, O
evaluated O
on O
minival Material
. O
Sharing O
features O
increases O
train Metric
time Metric
by O
1.5× O
( O
using O
4 Method
- Method
step Method
training Method
[ O
reference O
] O
) O
, O
but O
reduces O
test Metric
time Metric
. O
ble O
5 O
, O
we O
evaluate O
sharing O
features O
following O
the O
4 Method
- Method
step Method
training Method
described O
in O
[ O
reference O
] O
. O
Similar O
to O
[ O
reference O
] O
, O
we O
find O
that O
sharing O
features O
improves O
accuracy Metric
by O
a O
small O
margin O
. O
Feature Method
sharing Method
also O
reduces O
the O
testing Metric
time Metric
. O
Running Metric
time Metric
. O
With O
feature Method
sharing Method
, O
our O
FPN Method
- O
based O
Faster Method
R Method
- Method
CNN Method
system O
has O
inference Metric
time Metric
of O
0.148 O
seconds O
per O
image O
on O
a O
single O
NVIDIA O
M40 O
GPU O
for O
ResNet Method
- Method
50 Method
, O
and O
0.172 O
seconds O
for O
ResNet Task
- Task
101 Task
. O
[ O
reference O
] O
As O
a O
comparison O
, O
the O
single O
- O
scale O
ResNet Method
- Method
50 Method
baseline O
in O
Table O
3 O
( O
a O
) O
runs O
at O
0.32 O
seconds O
. O
Our O
method O
introduces O
small O
extra O
cost O
by O
the O
extra O
layers O
in O
the O
FPN Method
, O
but O
has O
a O
lighter O
weight O
head O
. O
Overall O
our O
system O
is O
faster O
than O
the O
ResNet O
- O
based O
Faster Method
R Method
- Method
CNN Method
counterpart O
. O
We O
believe O
the O
efficiency O
and O
simplicity O
of O
our O
method O
will O
benefit O
future O
research O
and O
applications O
. O
section O
: O
Comparing O
with O
COCO Material
Competition O
Winners O
We O
find O
that O
our O
ResNet Method
- Method
101 Method
model Method
in O
Table O
5 O
is O
not O
sufficiently O
trained O
with O
the O
default Metric
learning Metric
rate Metric
schedule Metric
. O
So O
we O
increase O
the O
number O
of O
mini O
- O
batches O
by O
2× O
at O
each O
learning Metric
rate Metric
when O
training O
the O
Fast Method
R Method
- Method
CNN Method
step O
. O
This O
increases O
AP Metric
on O
minival O
to O
35.6 O
, O
without O
sharing O
features O
. O
This O
model O
is O
the O
one O
we O
submitted O
to O
the O
COCO Material
detection O
leaderboard O
, O
shown O
in O
Table O
4 O
. O
We O
have O
not O
evaluated O
its O
feature Method
- Method
sharing Method
version Method
due O
to O
limited O
time O
, O
which O
should O
be O
slightly O
better O
as O
implied O
by O
Table O
5 O
. O
Table O
4 O
compares O
our O
method O
with O
the O
single O
- O
model O
results O
of O
the O
COCO Material
competition O
winners O
, O
including O
the O
2016 O
winner O
G Method
- Method
RMI Method
and O
the O
2015 O
winner O
Faster O
R Method
- Method
CNN Method
+++ Method
. O
Without O
adding O
bells O
and O
whistles O
, O
our O
single O
- O
model O
entry O
has O
surpassed O
these O
strong O
, O
heavily O
engineered O
competitors O
. O
On O
the O
test O
- O
dev O
set O
, O
our O
method O
increases O
over O
the O
existing O
best O
results O
by O
0.5 O
points O
of O
AP Metric
( O
36.2 O
vs. O
35.7 O
) O
and O
3.4 O
points O
of O
AP@0.5 O
( O
59.1 O
vs. O
55.7 O
) O
. O
It O
is O
worth O
noting O
that O
our O
method O
does O
not O
rely O
on O
image Method
pyramids Method
and O
only O
uses O
a O
single O
input O
image O
scale O
, O
but O
still O
has O
outstanding O
AP Metric
on O
small O
- O
scale O
objects O
. O
This O
could O
only O
be O
achieved O
by O
highresolution O
image O
inputs O
with O
previous O
methods O
. O
Moreover O
, O
our O
method O
does O
not O
exploit O
many O
popular O
improvements O
, O
such O
as O
iterative Method
regression Method
[ O
reference O
] O
, O
hard Method
negative Method
mining Method
[ O
reference O
] O
, O
context Method
modeling Method
[ O
reference O
] O
, O
stronger O
data Method
augmentation Method
[ O
reference O
] O
, O
etc O
. O
These O
improvements O
are O
complementary O
to O
FPNs Method
and O
should O
boost O
accuracy Metric
further O
. O
Recently O
, O
FPN Method
has O
enabled O
new O
top O
results O
in O
all O
tracks O
of O
the O
COCO Material
competition O
, O
including O
detection Task
, O
instance Task
segmentation Task
, O
and O
keypoint Task
estimation Task
. O
See O
[ O
reference O
] O
for O
details O
. O
section O
: O
Extensions O
: O
Segmentation Task
Proposals Task
Our O
method O
is O
a O
generic Method
pyramid Method
representation Method
and O
can O
be O
used O
in O
applications O
other O
than O
object Task
detection Task
. O
In O
this O
section O
we O
use O
FPNs Method
to O
generate O
segmentation Task
proposals Task
, O
following O
the O
DeepMask O
/ O
SharpMask Method
framework O
[ O
reference O
][ O
reference O
] O
. O
DeepMask O
/ O
SharpMask Method
were O
trained O
on O
image O
crops O
for O
predicting Task
instance Task
segments Task
and O
object Task
/ Task
non Task
- Task
object Task
scores Task
. O
At O
inference O
time O
, O
these O
models O
are O
run O
convolutionally Method
to O
generate O
dense Task
proposals Task
in O
an O
image O
. O
To O
generate O
segments O
at O
multiple O
scales O
, O
image O
pyramids O
are O
necessary O
[ O
reference O
][ O
reference O
] O
. O
It O
is O
easy O
to O
adapt O
FPN Method
to O
generate O
mask O
proposals O
. O
We O
use O
a O
fully Method
convolutional Method
setup Method
for O
both O
training Task
and O
inference Task
. O
We O
construct O
our O
feature Method
pyramid Method
as O
in O
Sec O
. O
5.1 O
and O
set O
d O
= O
128 O
. O
On O
top O
of O
each O
level O
of O
the O
feature O
pyramid O
, O
we O
apply O
a O
small O
5×5 Method
MLP Method
to O
predict O
14×14 O
masks O
and O
object O
scores O
in O
a O
fully Method
convolutional Method
fashion Method
, O
see O
Fig O
. O
4 O
. O
Additionally O
, O
motivated O
by O
the O
use O
of O
2 O
scales O
per O
octave O
in O
the O
image O
pyramid O
of O
[ O
reference O
][ O
reference O
] O
, O
we O
use O
a O
second O
MLP Method
of O
input O
size O
7×7 O
to O
handle O
half O
octaves O
. O
The O
two O
MLPs Method
play O
a O
similar O
role O
as O
anchors O
in O
RPN Method
. O
The O
architecture O
is O
trained O
end O
- O
to O
- O
end O
; O
full O
implementation O
details O
are O
given O
in O
the O
appendix O
. O
section O
: O
Segmentation O
Proposal O
Results O
Results O
are O
shown O
in O
Table O
6 O
. O
We O
report O
segment O
AR Metric
and O
segment O
AR Metric
on O
small O
, O
medium O
, O
and O
large O
objects O
, O
always O
for O
1000 O
proposals O
. O
Our O
baseline O
FPN Method
model O
with O
a O
single O
5×5 Method
MLP Method
achieves O
an O
AR Metric
of O
43.4 O
. O
Switching O
to O
a O
slightly O
larger O
7×7 O
MLP Method
leaves O
accuracy Metric
largely O
unchanged O
. O
Using O
both O
MLPs Method
together O
increases O
accuracy Metric
to O
45.7 O
AR Metric
. O
Increasing O
mask O
output O
size O
from O
14×14 O
to O
28×28 O
increases O
AR Metric
another O
point O
( O
larger O
sizes O
begin O
to O
degrade O
accuracy Metric
) O
. O
Finally O
, O
doubling O
the O
training O
iterations O
increases O
AR Metric
to O
48.1 O
. O
We O
also O
report O
comparisons O
to O
DeepMask Method
[ O
reference O
] O
, O
SharpMask Method
[ O
reference O
] O
, O
and O
InstanceFCN Method
[ O
reference O
] O
, O
the O
previous O
state O
of O
the O
art O
methods O
in O
mask Task
proposal Task
generation Task
. O
We O
outperform O
the O
accuracy Metric
of O
these O
approaches O
by O
over O
8.3 O
points O
AR Metric
. O
In O
particular O
, O
we O
nearly O
double O
the O
accuracy Metric
on O
small O
objects O
. O
Existing O
mask Method
proposal Method
methods Method
[ O
reference O
][ O
reference O
][ O
reference O
] O
are O
based O
on O
densely O
sampled O
image O
pyramids O
( O
e.g. O
, O
scaled O
by O
2 O
{ O
−2:0.5:1 O
} O
in O
[ O
reference O
][ O
reference O
] O
) O
, O
making O
them O
computationally O
expensive O
. O
Our O
approach O
, O
based O
on O
FPNs Method
, O
is O
substantially O
faster O
( O
our O
models O
run O
at O
6 O
to O
7 O
FPS Metric
) O
. O
These O
results O
demonstrate O
that O
our O
model O
is O
a O
generic Method
feature Method
extractor Method
and O
can O
replace O
image Method
pyramids Method
for O
other O
multi Task
- Task
scale Task
detection Task
problems Task
. O
section O
: O
Conclusion O
We O
have O
presented O
a O
clean O
and O
simple O
framework O
for O
building O
feature Task
pyramids Task
inside O
ConvNets Method
. O
Our O
method O
shows O
significant O
improvements O
over O
several O
strong O
baselines O
and O
competition O
winners O
. O
Thus O
, O
it O
provides O
a O
practical O
solution O
for O
research Task
and Task
applications Task
of Task
feature Task
pyramids Task
, O
without O
the O
need O
of O
computing O
image O
pyramids O
. O
Finally O
, O
our O
study O
suggests O
that O
despite O
the O
strong O
representational O
power O
of O
deep Method
ConvNets Method
and O
their O
implicit O
robustness O
to O
scale O
variation O
, O
it O
is O
still O
critical O
to O
explicitly O
address O
multiscale Task
problems Task
using O
pyramid Method
representations Method
. O
section O
: O
A. O
Implementation O
of O
Segmentation Task
Proposals Task
We O
use O
our O
feature Method
pyramid Method
networks Method
to O
efficiently O
generate O
object Task
segment Task
proposals Task
, O
adopting O
an O
image Method
- Method
centric Method
training Method
strategy Method
popular O
for O
object Task
detection Task
[ O
reference O
][ O
reference O
] O
. O
Our O
FPN Method
mask O
generation O
model O
inherits O
many O
of O
the O
ideas O
and O
motivations O
from O
DeepMask O
/ O
SharpMask Method
[ O
reference O
][ O
reference O
] O
. O
However O
, O
in O
contrast O
to O
these O
models O
, O
which O
were O
trained O
on O
image O
crops O
and O
used O
a O
densely O
sampled O
image O
pyramid O
for O
inference Task
, O
we O
perform O
fully Method
- Method
convolutional Method
training Method
for O
mask Task
prediction Task
on O
a O
feature O
pyramid O
. O
While O
this O
requires O
changing O
many O
of O
the O
specifics O
, O
our O
implementation O
remains O
similar O
in O
spirit O
to O
DeepMask Method
. O
Specifically O
, O
to O
define O
the O
label O
of O
a O
mask O
instance O
at O
each O
sliding O
window O
, O
we O
think O
of O
this O
window O
as O
being O
a O
crop O
on O
the O
input O
image O
, O
allowing O
us O
to O
inherit O
definitions O
of O
positives O
/ O
negatives O
from O
DeepMask Method
. O
We O
give O
more O
details O
next O
, O
see O
also O
Fig O
. O
4 O
for O
a O
visualization O
. O
We O
construct O
the O
feature O
pyramid O
with O
P O
2−6 O
using O
the O
same O
architecture O
as O
described O
in O
Sec O
. O
5.1 O
. O
We O
set O
d O
= O
128 O
. O
Each O
level O
of O
our O
feature Method
pyramid Method
is O
used O
for O
predicting O
masks O
at O
a O
different O
scale O
. O
As O
in O
DeepMask Method
, O
we O
define O
the O
scale O
of O
a O
mask O
as O
the O
max O
of O
its O
width O
and O
height O
. O
Masks O
with O
scales O
of O
{ O
32 O
, O
64 O
, O
128 O
, O
256 O
, O
512 O
} O
pixels O
map O
to O
{ O
P O
2 O
, O
P O
3 O
, O
P O
4 O
, O
P O
5 O
, O
P O
6 O
} O
, O
respectively O
, O
and O
are O
handled O
by O
a O
5×5 O
MLP Method
. O
As O
DeepMask Method
uses O
a O
pyramid O
with O
half O
octaves O
, O
we O
use O
a O
second O
slightly O
larger O
MLP Method
of O
size O
7×7 O
( O
7 O
≈ O
5 O
√ O
2 O
) O
to O
handle O
half O
- O
octaves O
in O
our O
model O
( O
e.g. O
, O
a O
128 O
√ O
2 O
scale O
mask O
is O
predicted O
by O
the O
7×7 O
MLP Method
on O
P O
4 O
) O
. O
Objects O
at O
intermediate O
scales O
are O
mapped O
to O
the O
nearest O
scale O
in O
log O
space O
. O
As O
the O
MLP Method
must O
predict O
objects O
at O
a O
range O
of O
scales O
for O
each O
pyramid O
level O
( O
specifically O
a O
half O
octave O
range O
) O
, O
some O
padding O
must O
be O
given O
around O
the O
canonical O
object O
size O
. O
We O
use O
25 O
% O
padding Method
. O
This O
means O
that O
the O
mask O
output O
over O
{ O
P O
2 O
, O
P O
3 O
, O
P O
4 O
, O
P O
5 O
, O
P O
6 O
} O
maps O
to O
{ O
40 O
, O
80 O
, O
160 O
, O
320 O
, O
640 O
} O
sized O
image O
regions O
for O
the O
5×5 O
MLP Method
( O
and O
to O
√ O
2 O
larger O
corresponding O
sizes O
for O
the O
7×7 Method
MLP Method
) O
. O
Each O
spatial O
position O
in O
the O
feature O
map O
is O
used O
to O
predict O
a O
mask O
at O
a O
different O
location O
. O
Specifically O
, O
at O
scale O
P O
k O
, O
each O
spatial O
position O
in O
the O
feature O
map O
is O
used O
to O
predict O
the O
mask O
whose O
center O
falls O
within O
2 O
k O
pixels O
of O
that O
location O
( O
corresponding O
to O
±1 O
cell O
offset O
in O
the O
feature O
map O
) O
. O
If O
no O
object O
center O
falls O
within O
this O
range O
, O
the O
location O
is O
considered O
a O
negative O
, O
and O
, O
as O
in O
DeepMask Method
, O
is O
used O
only O
for O
training O
the O
score O
branch O
and O
not O
the O
mask O
branch O
. O
The O
MLP Method
we O
use O
for O
predicting O
the O
mask Metric
and Metric
score Metric
is O
fairly O
simple O
. O
We O
apply O
a O
5×5 Method
kernel Method
with O
512 O
outputs O
, O
followed O
by O
sibling O
fully Method
connected Method
layers Method
to O
predict O
a O
14×14 O
mask O
( O
14 O
2 O
outputs O
) O
and O
object O
score O
( O
1 O
output O
) O
. O
The O
model O
is O
implemented O
in O
a O
fully Method
convolutional Method
manner Method
( O
using O
1×1 Method
convolutions Method
in O
place O
of O
fully Method
connected Method
layers Method
) O
. O
The O
7×7 Method
MLP Method
for O
handling O
objects O
at O
half O
octave O
scales O
is O
identical O
to O
the O
5×5 O
MLP Method
except O
for O
its O
larger O
input O
region O
. O
During O
training Task
, O
we O
randomly O
sample O
2048 O
examples O
per O
mini O
- O
batch O
( O
128 O
examples O
per O
image O
from O
16 O
images O
) O
with O
a O
positive O
/ O
negative O
sampling O
ratio O
of O
1:3 O
. O
The O
mask O
loss O
is O
given O
10× O
higher O
weight O
than O
the O
score Metric
loss Metric
. O
This O
model O
is O
trained O
end O
- O
to O
- O
end O
on O
8 O
GPUs Method
using O
synchronized Method
SGD Method
( O
2 O
images O
per O
GPU O
) O
. O
We O
start O
with O
a O
learning Metric
rate Metric
of O
0.03 O
and O
train O
for O
80k O
mini O
- O
batches O
, O
dividing O
the O
learning Metric
rate Metric
by O
10 O
after O
60k O
mini O
- O
batches O
. O
The O
image O
scale O
is O
set O
to O
800 O
pixels O
during O
training O
and O
testing O
( O
we O
do O
not O
use O
scale O
jitter O
) O
. O
During O
inference Task
our O
fully Method
- Method
convolutional Method
model Method
predicts O
scores O
at O
all O
positions O
and O
scales O
and O
masks O
at O
the O
1000 O
highest O
scoring O
locations O
. O
We O
do O
not O
perform O
any O
non O
- O
maximum Method
suppression Method
or O
post Task
- Task
processing Task
. O
section O
: O
