document O
: O
Dependency O
or O
Span O
, O
End O
- O
to O
- O
End O
Uniform O
Semantic Task
Role Task
Labeling Task
Semantic Task
role Task
labeling Task
( O
SRL Task
) O
aims O
to O
discover O
the O
predicate O
- O
argument O
structure O
of O
a O
sentence O
. O
End O
- O
to O
- O
end O
SRL Task
without O
syntactic O
input O
has O
received O
great O
attention O
. O
However O
, O
most O
of O
them O
focus O
on O
either O
span Task
- O
based O
or O
dependency Task
- O
based O
semantic O
representation O
form O
and O
only O
show O
specific O
model Method
optimization Method
respectively O
. O
Meanwhile O
, O
handling O
these O
two O
SRL Task
tasks Task
uniformly O
was O
less O
successful O
. O
This O
paper O
presents O
an O
end Method
- Method
to Method
- Method
end Method
model Method
for O
both O
dependency Task
and O
span Task
SRL Task
with O
a O
unified Method
argument Method
representation Method
to O
deal O
with O
two O
different O
types O
of O
argument O
annotations O
in O
a O
uniform O
fashion O
. O
Furthermore O
, O
we O
jointly O
predict O
all O
predicates O
and O
arguments O
, O
especially O
including O
long Task
- Task
term Task
ignored Task
predicate Task
identification Task
subtask Task
. O
Our O
single O
model O
achieves O
new O
state O
- O
of O
- O
the O
- O
art O
results O
on O
both O
span Task
( O
CoNLL Material
2005 Material
, O
2012 O
) O
and O
dependency Task
( O
CoNLL O
2008 O
, O
2009 O
) O
SRL Task
benchmarks O
. O
section O
: O
Introduction O
The O
purpose O
of O
semantic Task
role Task
labeling O
( O
SRL Task
) O
is O
to O
derive O
the O
meaning Method
representation Method
for O
a O
sentence O
, O
which O
is O
beneficial O
to O
a O
wide O
range O
of O
natural Task
language Task
processing Task
( O
NLP Task
) O
tasks O
. O
SRL Task
can O
be O
formed O
as O
four O
subtasks O
, O
including O
predicate Task
detection Task
, O
predicate Task
disambiguation Task
, O
argument Task
identification Task
and O
argument Task
classification Task
. O
For O
argument Task
annotation Task
, O
there O
are O
two O
formulizations O
. O
One O
is O
based O
on O
text O
spans O
, O
namely O
span Task
- O
based O
SRL Task
. O
The O
other O
is O
dependency Task
- O
based O
SRL Task
, O
which O
annotates O
the O
syntactic O
head O
of O
argument O
rather O
than O
entire O
argument O
span Task
. O
Figure O
[ O
reference O
] O
shows O
example O
annotations O
. O
Great O
progress O
has O
been O
made O
in O
syntactic Task
parsing Task
. O
Most O
traditional O
SRL Task
methods O
rely O
heavily O
on O
syntactic O
features O
. O
To O
alleviate O
the O
inconvenience O
, O
recent O
works O
propose O
end Method
- Method
to Method
- Method
end Method
models Method
for O
SRL Task
, O
putting O
syntax O
aside O
and O
still O
achieving O
favorable O
results O
. O
However O
, O
these O
systems O
focus O
on O
either O
span Task
or O
dependency Task
SRL Task
, O
which O
motivates O
us O
to O
explore O
a O
uniform O
approach O
. O
Both O
span Task
and O
dependency Task
are O
effective O
formal Method
representations Method
for O
semantics O
, O
though O
for O
a O
long O
time O
it O
has O
been O
kept O
unknown O
which O
form O
, O
span Task
or O
dependency Task
, O
would O
be O
better O
for O
the O
convenience O
and O
effectiveness O
of O
semantic Task
machine Task
learning Task
and O
later Task
applications Task
. O
Furthermore O
, O
researchers O
are O
interested O
in O
two O
forms O
of O
SRL Task
models O
that O
may O
benefit O
from O
each O
other O
rather O
than O
their O
separated O
development O
. O
This O
topic O
has O
been O
roughly O
discussed O
in O
, O
who O
concluded O
that O
the O
( O
best O
) O
dependency Task
SRL Task
system O
at O
then O
clearly O
outperformed O
the O
span Task
- O
based O
( O
best O
) O
system O
through O
gold Method
syntactic Method
structure Method
transformation Method
. O
However O
, O
johansson2008EMNLP O
johansson2008EMNLP O
like O
all O
other O
traditional O
SRL Task
models O
themselves O
had O
to O
adopt O
rich O
syntactic O
features O
, O
and O
their O
comparison O
was O
done O
between O
two O
systems O
in O
quite O
different O
building O
styles O
. O
Instead O
, O
this O
work O
will O
develop O
full O
syntax O
- O
agnostic O
SRL Task
systems O
with O
the O
same O
fashion O
for O
both O
span Task
and O
dependency Task
representation O
, O
so O
that O
we O
can O
revisit O
this O
issue O
under O
a O
more O
solid O
empirical O
basis O
. O
In O
addition O
, O
most O
efforts O
focus O
on O
argument Task
identification Task
and O
classification Task
since O
span Task
and O
dependency Task
SRL Task
corpora O
have O
already O
marked O
predicate O
positions O
. O
Although O
no O
predicate Method
identification Method
is O
needed O
, O
it O
is O
not O
available O
in O
many O
downstream Task
applications Task
. O
Therefore O
, O
predicate Task
identification Task
should O
be O
carefully O
handled O
in O
a O
complete O
practical O
SRL Task
system O
. O
To O
address O
this O
problem O
, O
he2018jointly O
he2018jointly O
proposed O
an O
end O
- O
to O
- O
end Method
approach Method
for O
jointly Task
predicting Task
predicates Task
and Task
arguments Task
for O
span Task
SRL Task
. O
Likewise O
, O
cai2018full O
cai2018full O
introduced O
an O
end Method
- Method
to Method
- Method
end Method
model Method
to O
naturally O
cover O
all O
predicate Task
/ Task
argument Task
identification Task
and Task
classification Task
subtasks Task
for O
dependency Task
SRL Task
. O
To O
jointly O
predict O
predicates O
and O
arguments O
, O
we O
present O
an O
end Method
- Method
to Method
- Method
end Method
framework Method
for O
both O
span Task
and O
dependency Task
SRL Task
. O
Our O
model O
extends O
the O
span Task
SRL Task
model O
of O
he2018jointly O
he2018jointly O
, O
directly O
regarding O
all O
words O
in O
a O
sentence O
as O
possible O
predicates O
, O
considering O
all O
spans O
or O
words O
as O
potential O
arguments O
and O
learning O
distributions O
over O
possible O
predicates O
. O
However O
, O
we O
differ O
by O
( O
1 O
) O
introducing O
unified Method
argument Method
representation Method
to O
handle O
two O
different O
types O
of O
SRL Task
tasks Task
, O
and O
( O
2 O
) O
employing O
biaffine Method
scorer Method
to O
make O
decisions O
for O
predicate Task
- Task
argument Task
relationship Task
. O
The O
proposed O
models O
are O
evaluated O
on O
span Task
SRL Task
datasets O
: O
CoNLL Material
2005 Material
and O
2012 O
data O
, O
as O
well O
as O
the O
dependency Task
SRL Task
dataset O
of O
CoNLL O
2008 O
and O
2009 O
shared O
tasks O
. O
For O
span Task
SRL Task
, O
our O
single O
model O
outperforms O
the O
previous O
best O
results O
by O
0.3 O
% O
and O
0.5 O
% O
F Metric
- Metric
score Metric
on O
CoNLL Material
2005 Material
and O
2012 O
test O
sets O
respectively O
. O
For O
dependency Task
SRL Task
, O
we O
achieve O
new O
state O
- O
of O
- O
the O
- O
art O
of O
85.3 O
% O
F Metric
and O
90.4 O
% O
F Metric
on O
CoNLL O
2008 O
and O
2009 O
benchmarks O
respectively O
. O
section O
: O
Background O
SRL Task
is O
pioneered O
by O
gildea2002 O
gildea2002 O
, O
which O
uses O
the O
PropBank O
conventions O
. O
Conventionally O
, O
span Task
SRL Task
consists O
of O
two O
subtasks O
, O
argument Task
identification Task
and O
classification Task
. O
The O
former O
identifies O
the O
arguments O
of O
a O
predicate O
, O
and O
the O
latter O
assigns O
them O
semantic Task
role Task
labels O
, O
namely O
, O
determining O
the O
relation O
between O
arguments O
and O
predicates O
. O
The O
PropBank Method
defines O
a O
set O
of O
semantic O
roles O
to O
label O
arguments O
, O
falling O
into O
two O
categories O
: O
core O
and O
non O
- O
core O
roles O
. O
The O
core O
roles O
( O
A0 O
- O
A5 O
and O
AA O
) O
indicate O
different O
semantics O
in O
predicate O
- O
argument O
structure O
, O
while O
the O
non O
- O
core O
roles O
are O
modifiers O
( O
AM O
- O
adj O
) O
where O
adj O
specifies O
the O
adjunct O
type O
, O
such O
as O
temporal O
( O
AM O
- O
TMP O
) O
and O
locative O
( O
AM O
- O
LOC O
) O
adjuncts O
. O
For O
example O
shown O
in O
Figure O
[ O
reference O
] O
, O
A0 O
is O
a O
proto O
- O
agent O
, O
representing O
the O
borrower O
. O
Slightly O
different O
from O
span Task
SRL Task
in O
argument Task
annotation Task
, O
dependency Task
SRL Task
labels O
the O
syntactic O
heads O
of O
arguments O
rather O
than O
phrasal O
arguments O
, O
which O
was O
popularized O
by O
CoNLL O
- O
2008 O
and O
CoNLL O
- O
2009 O
shared O
tasks O
. O
Furthermore O
, O
when O
no O
predicate O
is O
given O
, O
two O
other O
indispensable O
subtasks O
of O
dependency Task
SRL Task
are O
predicate Task
identification Task
and O
disambiguation Task
. O
One O
is O
to O
identify O
all O
predicates O
in O
a O
sentence O
, O
and O
the O
other O
is O
to O
determine O
the O
senses O
of O
predicates O
. O
As O
the O
example O
shown O
in O
Figure O
[ O
reference O
] O
, O
01 O
indicates O
the O
first O
sense O
from O
the O
PropBank O
sense O
repository O
for O
predicate O
borrowed O
in O
the O
sentence O
. O
subsection O
: O
Related O
Work O
The O
traditional O
approaches O
on O
SRL Task
were O
mostly O
about O
designing O
hand O
- O
crafted O
feature O
templates O
and O
then O
employ O
linear Method
classifiers Method
such O
as O
. O
Even O
though O
neural Method
models Method
were O
introduced O
, O
early O
work O
still O
paid O
more O
attention O
on O
syntactic O
features O
. O
For O
example O
, O
Fitzgerald2015 O
Fitzgerald2015 O
integrated O
syntactic O
information O
into O
neural Method
networks Method
with O
embedded O
lexicalized O
features O
, O
while O
roth2016 O
roth2016 O
embedded O
syntactic O
dependency Task
paths O
between O
predicates O
and O
arguments O
. O
Similarly O
, O
marcheggianiEMNLP2017 O
marcheggianiEMNLP2017 O
leveraged O
the O
graph Method
convolutional Method
network Method
to O
encode O
syntax O
for O
dependency Task
SRL Task
. O
Recently O
, O
Strubell2018 O
Strubell2018 O
presented O
a O
multi Method
- Method
task Method
neural Method
model Method
to O
incorporate O
auxiliary O
syntactic O
information O
for O
SRL Task
, O
li2018unified O
li2018unified O
adopted O
several O
kinds O
of O
syntactic Method
encoder Method
for O
syntax Task
encoding Task
while O
he:2018Syntax O
he:2018Syntax O
used O
syntactic O
tree O
for O
argument Task
pruning Task
. O
However O
, O
using O
syntax O
may O
be O
quite O
inconvenient O
sometimes O
, O
recent O
studies O
thus O
have O
attempted O
to O
build O
SRL Task
systems O
without O
or O
with O
little O
syntactic O
guideline O
. O
zhou O
- O
xu2015 O
zhou O
- O
xu2015 O
proposed O
the O
first O
syntax Method
- Method
agnostic Method
model Method
for O
span Task
SRL Task
using O
LSTM Method
sequence Method
labeling Method
, O
while O
he O
- O
acl2017 O
he O
- O
acl2017 O
further O
enhanced O
their O
model O
using O
highway Method
bidirectional Method
LSTMs Method
with O
constrained Method
decoding Method
. O
Later O
, O
selfatt2018 O
selfatt2018 O
presented O
a O
deep Method
attentional Method
neural Method
network Method
for O
applying O
self Task
- Task
attention Task
to O
span Task
SRL Task
task Task
. O
Likewise O
for O
dependency Task
SRL Task
, O
marcheggiani2017 O
marcheggiani2017 O
proposed O
a O
syntax Method
- Method
agnostic Method
model Method
with O
effective O
word Method
representation Method
and O
obtained O
favorable O
results O
. O
cai2018full O
cai2018full O
built O
a O
full O
end Method
- Method
to Method
- Method
end Method
model Method
with O
biaffine Method
attention Method
and O
outperformed O
the O
previous O
state O
- O
of O
- O
the O
- O
art O
. O
More O
recently O
, O
joint Task
predicting Task
both Task
predicates Task
and Task
arguments Task
has O
attracted O
extensive O
interest O
on O
account O
of O
the O
importance O
of O
predicate Task
identification Task
, O
including O
and O
this O
work O
. O
In O
our O
preliminary O
experiments O
, O
we O
tried O
to O
integrate O
the O
self Method
- Method
attention Method
into O
our O
model O
, O
but O
it O
does O
not O
provide O
any O
significant O
performance O
gain O
on O
span Task
or O
dependency Task
SRL Task
, O
which O
is O
not O
consistent O
with O
the O
conclusion O
in O
and O
lets O
us O
exclude O
it O
from O
this O
work O
. O
Generally O
, O
the O
above O
work O
is O
summarized O
in O
Table O
[ O
reference O
] O
. O
Considering O
motivation O
, O
our O
work O
is O
most O
closely O
related O
to O
the O
work O
of O
Fitzgerald2015 O
Fitzgerald2015 O
, O
which O
also O
tackles O
span Task
and O
dependency Task
SRL Task
in O
a O
uniform O
fashion O
. O
The O
essential O
difference O
is O
that O
their O
model O
employs O
the O
syntactic O
features O
and O
takes O
pre O
- O
identified O
predicates O
as O
inputs O
, O
while O
our O
model O
puts O
syntax O
aside O
and O
jointly O
learns O
and O
predicts O
predicates O
and O
arguments O
. O
section O
: O
Uniform O
End Method
- Method
to Method
- Method
End Method
Model Method
subsection O
: O
Overview O
Given O
a O
sentence O
, O
we O
attempt O
to O
predict O
a O
set O
of O
predicate O
- O
argument O
- O
relation O
tuples O
, O
where O
is O
the O
set O
of O
all O
possible O
predicate O
tokens O
, O
includes O
all O
the O
candidate O
argument O
spans O
or O
dependencies O
, O
and O
is O
the O
set O
of O
the O
semantic O
roles O
. O
To O
simplify O
the O
task O
, O
we O
introduce O
a O
null O
label O
to O
indicate O
no O
relation O
between O
arbitrary O
predicate O
- O
argument O
pair O
following O
he2018jointly O
he2018jointly O
. O
As O
shown O
in O
Figure O
[ O
reference O
] O
, O
our O
uniform O
SRL Task
model O
includes O
four O
main O
modules O
: O
token Method
representation Method
component Method
to O
build O
token Method
representation Method
from O
word O
, O
a O
BiHLSTM Method
encoder Method
that O
directly O
takes O
sequential O
inputs O
, O
predicate Method
and Method
argument Method
representation Method
module Method
to O
learn O
candidate Method
representations Method
, O
a O
biaffine Method
scorer Method
which O
takes O
the O
candidate Method
representations Method
as O
input O
and O
predicts O
semantic O
roles O
. O
subsection O
: O
Token Method
Representation Method
We O
follow O
the O
bi Method
- Method
directional Method
LSTM Method
- Method
CNN Method
architecture Method
, O
where O
convolutional Method
neural Method
networks Method
( O
CNNs Method
) O
encode O
characters O
inside O
a O
word O
into O
character Method
- Method
level Method
representation Method
then O
concatenated O
with O
its O
word O
- O
level O
into O
context Method
- Method
independent Method
representation Method
. O
To O
further O
enhance O
the O
word Method
representation Method
, O
we O
leverage O
an O
external Method
representation Method
from O
pretrained Method
ELMo Method
( O
Embeddings Method
from Method
Language Method
Models Method
) O
layers O
according O
to O
ELMo Method
ELMo Method
. O
Eventually O
, O
the O
resulting O
token Method
representation Method
is O
concatenated O
as O
subsection O
: O
Deep Method
Encoder Method
The O
encoder O
in O
our O
model O
adopts O
the O
bidirectional Method
LSTM Method
with Method
highway Method
connections Method
( O
BiHLSTM Method
) Method
to O
contextualize O
the O
representation O
into O
task Task
- Task
specific Task
representation Task
: O
, O
where O
the O
gated O
highway O
connections O
is O
used O
to O
alleviate O
the O
vanishing Task
gradient Task
problem Task
when O
training O
very O
deep Task
BiLSTMs Task
. O
subsection O
: O
Predicate Method
and Method
Argument Method
Representation Method
We O
employ O
contextualized Method
representations Method
for O
all O
candidate O
arguments O
and O
predicates O
. O
As O
referred O
in O
, O
applying O
a O
multi Method
- Method
layer Method
perceptron Method
( O
MLP Method
) O
to O
the O
recurrent O
output O
states O
before O
the O
classifier Method
has O
the O
advantage O
of O
stripping O
away O
irrelevant O
information O
for O
the O
current O
decision O
. O
Therefore O
, O
to O
distinguish O
the O
currently O
considered O
predicate O
from O
its O
candidate O
arguments O
in O
SRL Task
context Task
, O
we O
add O
an O
MLP Method
layer O
to O
contextualized Method
representations Method
for O
argument O
and O
predicate Method
candidates Method
specific Method
representations Method
respectively O
with O
ReLU Method
as O
its O
activation O
function O
: O
To O
perform O
uniform Task
SRL Task
, O
we O
introduce O
unified Method
argument Method
representation Method
. O
For O
dependency Task
SRL Task
, O
we O
assume O
single O
word O
argument O
span Task
by O
limiting O
the O
length O
of O
candidate O
argument O
to O
be O
1 O
, O
so O
our O
model O
uses O
the O
as O
the O
final O
argument Method
representation Method
directly O
. O
While O
for O
span Task
SRL Task
, O
we O
utilize O
the O
approach O
of O
span Task
representation O
from O
lee2017end O
lee2017end O
. O
Each O
candidate O
span Task
representation O
is O
built O
by O
where O
and O
are O
boundary Method
representations Method
, O
indicates O
a O
span Task
, O
is O
a O
feature O
vector O
encoding O
the O
size O
of O
span Task
, O
and O
is O
the O
specific O
notion O
of O
headedness O
which O
is O
learned O
by O
attention Method
mechanism Method
over O
words O
in O
each O
span Task
( O
where O
is O
the O
position O
inside O
span Task
) O
as O
follows O
: O
subsection O
: O
Scorers O
For O
predicate O
and O
arguments O
, O
we O
introduce O
two O
unary O
scores O
on O
their O
candidates O
: O
For O
semantic Task
role Task
, O
we O
adopt O
a O
relation Method
scorer Method
with O
biaffine O
attention O
: O
where O
and O
respectively O
denote O
the O
weight O
matrix O
of O
the O
bi O
- O
linear O
and O
the O
linear O
terms O
and O
b O
is O
the O
bias O
item O
. O
The O
biaffine Method
scorer Method
differs O
from O
feed Method
- Method
forward Method
networks Method
scorer Method
in O
bilinear Method
transformation Method
. O
Since O
SRL Task
can O
be O
regarded O
as O
a O
classification Task
task Task
, O
the O
distribution O
of O
classes O
is O
uneven O
and O
the O
problem O
comes O
worse O
after O
the O
null O
labels O
are O
introduced O
. O
The O
output O
layer O
of O
the O
model O
normally O
includes O
a O
bias Method
term Method
designed O
to O
capture O
the O
prior O
probability O
of O
each O
class O
, O
with O
the O
rest O
of O
the O
model O
focusing O
on O
learning O
the O
likelihood O
of O
every O
classes O
occurring O
in O
data O
. O
The O
biaffine O
attention O
as O
Dozat O
and O
Manning O
( O
2017 O
) O
in O
our O
model O
directly O
assigns O
a O
score O
for O
each O
specific O
semantic Task
role Task
and O
would O
be O
helpful O
for O
semantic Task
role Task
prediction O
. O
Actually O
, O
( O
He O
et O
al O
. O
, O
2018a O
) O
used O
a O
scorer O
as O
Equation O
( O
2 O
) O
, O
which O
is O
only O
a O
part O
of O
our O
scorer O
including O
both O
Equations O
( O
[ O
reference O
] O
) O
and O
( O
[ O
reference O
] O
) O
. O
Therefore O
, O
our O
scorer O
would O
be O
more O
informative O
than O
previous O
models O
such O
as O
. O
subsection O
: O
Training Metric
Objective Metric
The O
model O
is O
trained O
to O
optimize O
the O
probability O
of O
the O
predicate O
- O
argument O
- O
relation O
tuples O
given O
the O
sentence O
, O
which O
can O
be O
factorized O
as O
: O
where O
represents O
the O
model O
parameters O
, O
and O
, O
is O
the O
score O
for O
the O
predicate O
- O
argument O
- O
relation O
tuple O
, O
including O
predicate Metric
score Metric
, O
argument O
score O
and O
relation O
score O
. O
Our O
model O
adopts O
a O
biaffine Method
scorer Method
for O
semantic Task
role Task
label O
prediction O
, O
which O
is O
implemented O
as O
cross Metric
- Metric
entropy Metric
loss Metric
. O
Moreover O
, O
our O
model O
is O
trained O
to O
minimize O
the O
negative O
likehood O
of O
the O
golden O
structure O
: O
. O
The O
score O
of O
null O
labels O
are O
enforced O
into O
. O
For O
predicates O
and O
arguments Task
prediction Task
, O
we O
train O
separated Method
scorers Method
( O
and O
) O
in O
parallel O
fed O
to O
the O
biaffine Method
scorer Method
for O
predicate Task
and Task
argument Task
predication Task
respectively O
, O
which O
helps O
to O
reduce O
the O
chance O
of O
error Metric
propagation Metric
. O
subsection O
: O
Candidates Task
Pruning Task
The O
number O
of O
candidate O
arguments O
for O
a O
sentence O
of O
length O
is O
for O
span Task
SRL Task
, O
and O
for O
dependency Task
. O
As O
the O
model O
deals O
with O
possible O
predicates O
, O
the O
computational Metric
complexity Metric
is O
for O
span Task
, O
for O
dependency Task
, O
which O
is O
too O
computationally O
expensive O
. O
To O
address O
this O
issue O
, O
we O
attempt O
to O
prune O
candidates O
using O
two O
beams O
for O
storing O
the O
candidate O
arguments O
and O
predicates O
with O
size O
and O
inspired O
by O
he2018jointly O
he2018jointly O
, O
where O
and O
are O
two O
manually O
setting O
thresholds O
. O
First O
, O
the O
predicate O
and O
argument O
candidates O
are O
ranked O
according O
to O
their O
predicted O
score O
( O
and O
) O
respectively O
, O
and O
then O
we O
reduce O
the O
predicate O
and O
argument O
candidates O
with O
defined O
beams O
. O
Finally O
, O
we O
take O
the O
candidates O
from O
the O
beams O
to O
participate O
the O
label Task
prediction Task
. O
Such O
pruning Method
will O
reduce O
the O
overall O
number O
of O
candidate O
tuples O
to O
for O
both O
types O
of O
tasks O
. O
Furthermore O
, O
for O
span Task
SRL Task
, O
we O
set O
the O
maximum O
length O
of O
candidate O
arguments O
to O
, O
which O
may O
decrease O
the O
number O
of O
candidate O
arguments O
to O
. O
subsection O
: O
SRL Task
Constraints O
According O
to O
PropBank O
semantic O
convention O
, O
predicate O
- O
argument O
structure O
has O
to O
follow O
a O
few O
of O
global O
constraints O
, O
we O
thus O
incorporate O
constraints O
on O
the O
output O
structure O
with O
a O
dynamic Method
programing Method
decoder Method
during O
inference Task
. O
These O
constraints O
are O
described O
as O
follows O
: O
Unique O
core O
roles O
( O
U O
) O
: O
Each O
core O
role O
( O
A0 O
- O
A5 O
, O
AA O
) O
should O
appear O
at O
most O
once O
for O
each O
predicate O
. O
Continuation O
roles O
( O
C O
) O
: O
A O
continuation O
role O
C O
- O
X O
can O
exist O
only O
when O
its O
base O
role O
X O
is O
realized O
before O
it O
. O
Reference O
roles O
( O
R O
) O
: O
A O
reference O
role O
R O
- O
X O
can O
exist O
only O
when O
its O
base O
role O
X O
is O
realized O
( O
not O
necessarily O
before O
R O
- O
X O
) O
. O
Non O
- O
overlapping O
( O
O O
) O
: O
The O
semantic O
arguments O
for O
the O
same O
predicate O
do O
not O
overlap O
in O
span Task
SRL Task
. O
As O
C O
and O
R O
constraints O
lead O
to O
worse O
performance O
in O
our O
models O
from O
our O
preliminary O
experiments O
, O
we O
only O
enforce O
U O
and O
O O
constraints O
on O
span Task
SRL Task
and O
U O
constraints O
on O
dependency Task
SRL Task
. O
section O
: O
Experiments O
Our O
models O
are O
evaluated O
on O
two O
PropBank Task
- Task
style Task
SRL Task
tasks Task
: O
span Task
and O
dependency Task
. O
For O
span Task
SRL Task
, O
we O
test O
model O
on O
the O
common O
span Task
SRL Task
datasets O
from O
CoNLL Material
- Material
2005 Material
and O
CoNLL O
- O
2012 O
shared O
tasks O
. O
For O
dependency Task
SRL Task
, O
we O
experiment O
on O
CoNLL O
2008 O
and O
2009 O
benchmarks O
. O
As O
for O
the O
predicate Task
disambiguation Task
in O
dependency Task
SRL Task
task Task
, O
we O
follow O
the O
previous O
work O
. O
We O
consider O
two O
SRL Task
setups O
: O
end O
- O
to O
- O
end O
and O
pre O
- O
identified O
predicates O
. O
For O
the O
former O
setup O
, O
our O
system O
jointly O
predicts O
all O
the O
predicates O
and O
their O
arguments O
in O
one O
shot O
, O
which O
turns O
into O
CoNLL O
- O
2008 O
setting O
for O
dependency Task
SRL Task
. O
In O
order O
to O
compare O
with O
previous O
models O
, O
we O
also O
report O
results O
with O
pre O
- O
identified O
predicates O
, O
where O
predicates O
have O
been O
beforehand O
identified O
in O
corpora O
. O
Therefore O
, O
the O
experimental O
results O
fall O
into O
two O
categories O
: O
end O
- O
to O
- O
end O
results O
and O
results O
with O
pre O
- O
identified O
predicates O
. O
subsection O
: O
Datasets O
CoNLL Material
2005 Material
and O
2012 O
The O
CoNLL Material
- Material
2005 Material
shared O
task O
focused O
on O
verbal O
predicates O
only O
for O
English O
. O
The O
CoNLL Material
- Material
2005 Material
dataset O
takes O
section O
2 O
- O
21 O
of O
Wall O
Street O
Journal O
( O
WSJ O
) O
data O
as O
training O
set O
, O
and O
section O
24 O
as O
development O
set O
. O
The O
test O
set O
consists O
of O
section O
23 O
of O
WSJ O
for O
in Task
- Task
domain Task
evaluation Task
together O
with O
3 O
sections O
from O
Brown O
corpus O
for O
out Task
- Task
of Task
- Task
domain Task
evaluation Task
. O
The O
larger O
CoNLL O
- O
2012 O
dataset O
is O
extracted O
from O
OntoNotes Material
v5.0 O
corpus O
, O
which O
contains O
both O
verbal O
and O
nominal O
predicates O
. O
CoNLL O
2008 O
and O
2009 O
CoNLL O
- O
2008 O
and O
the O
English O
part O
of O
CoNLL O
- O
2009 O
shared O
tasks O
use O
the O
same O
English O
corpus O
, O
which O
merges O
two O
treebanks O
, O
PropBank O
and O
NomBank O
. O
NomBank O
is O
a O
complement O
to O
PropBank O
with O
similar O
semantic O
convention O
for O
nominal Task
predicate Task
- Task
argument Task
structure Task
annotation Task
. O
Besides O
, O
the O
training O
, O
development Task
and Task
test Task
splits Task
of O
English O
data O
are O
identical O
to O
that O
of O
CoNLL Material
- Material
2005 Material
. O
subsection O
: O
Setup O
paragraph O
: O
Hyperparameters O
In O
our O
experiments O
, O
the O
word O
embeddings O
are O
300 O
- O
dimensional O
GloVe O
vectors O
. O
The O
character Method
representations Method
with O
dimension O
8 O
randomly O
initialized O
. O
In O
the O
character Method
CNN Method
, O
the O
convolutions Method
have O
window O
sizes O
of O
3 O
, O
4 O
, O
and O
5 O
, O
each O
consisting O
of O
50 O
filters O
. O
Moreover O
, O
we O
use O
3 O
stacked Method
bidirectional Method
LSTMs Method
with O
200 O
dimensional O
hidden O
states O
. O
The O
outputs O
of O
BiLSTM Method
employs O
two O
300 O
- O
dimensional O
MLP Method
layers O
with O
the O
ReLU Method
as O
activation O
function O
. O
Besides O
, O
we O
use O
two O
150 O
- O
dimensional O
hidden O
MLP Method
layers O
with O
ReLU Method
to O
score O
predicates O
and O
arguments O
respectively O
. O
For O
candidates Task
pruning Task
, O
we O
follow O
the O
settings O
of O
he2018jointly O
he2018jointly O
, O
modeling O
spans O
up O
to O
length O
for O
span Task
SRL Task
and O
for O
dependency Task
SRL Task
, O
using O
for O
pruning O
predicates O
and O
for O
pruning O
arguments O
. O
Training O
Details O
During O
training O
, O
we O
use O
the O
categorical Metric
cross Metric
- Metric
entropy Metric
as O
objective Metric
, O
with O
Adam Metric
optimizer Metric
initial Metric
learning Metric
rate Metric
0.001 O
. O
We O
apply O
0.5 Method
dropout Method
to O
the O
word O
embeddings O
and O
character O
CNN O
outputs O
and O
0.2 Method
dropout Method
to O
all O
hidden O
layers O
and O
feature O
embeddings O
. O
In O
the O
LSTMs Method
, O
we O
employ O
variational Method
dropout Method
masks Method
that O
are O
shared O
across O
timesteps O
, O
with O
0.4 O
dropout Metric
rate Metric
. O
All O
models O
are O
trained O
for O
up O
to O
600 O
epochs O
with O
batch O
size O
40 O
on O
a O
single O
NVIDIA O
GeForce O
GTX O
1080Ti O
GPU O
, O
which O
occupies O
8 O
GB O
graphic O
memory O
and O
takes O
12 O
to O
36 O
hours O
. O
subsection O
: O
End O
- O
to O
- O
end O
Results O
We O
present O
all O
results O
using O
the O
official Metric
evaluation Metric
script Metric
from O
the O
CoNLL Material
- Material
2005 Material
and O
CoNLL O
- O
2009 O
shared O
tasks O
, O
and O
compare O
our O
model O
with O
previous O
state O
- O
of O
- O
the O
- O
art O
models O
. O
Span Task
SRL Task
Table O
[ O
reference O
] O
shows O
results O
on O
CoNLL Material
- Material
2005 Material
in O
- O
domain O
( O
WSJ O
) O
and O
out O
- O
of O
- O
domain O
( O
Brown O
) O
test O
sets O
, O
as O
well O
as O
the O
CoNLL O
- O
2012 O
test O
set O
( O
OntoNotes Material
) O
. O
The O
upper O
part O
of O
table O
presents O
results O
from O
single O
models O
. O
Our O
model O
outperforms O
the O
previous O
models O
with O
absolute O
improvements O
in O
F Metric
- Metric
score Metric
of O
0.3 O
% O
on O
CoNLL Material
- Material
2005 Material
benchmark O
. O
Besides O
, O
our O
single O
model O
performs O
even O
much O
better O
than O
all O
previous O
ensemble Method
systems Method
. O
Dependency O
SRL Task
Table O
[ O
reference O
] O
presents O
the O
results O
on O
CoNLL O
- O
2008 O
. O
J O
& O
N O
( O
2008b O
) O
was O
the O
highest O
ranked O
system O
in O
CoNLL Task
- Task
2008 Task
shared Task
task Task
. O
We O
obtain O
comparable O
results O
with O
the O
recent O
state O
- O
of O
- O
the O
- O
art O
method O
, O
and O
our O
model O
surpasses O
the O
model O
by O
2 O
% O
in O
F Metric
- Metric
score Metric
. O
subsection O
: O
Results O
with O
Pre O
- O
identified O
Predicates O
To O
compare O
with O
to O
previous O
systems O
with O
pre O
- O
identified O
predicates O
, O
we O
report O
results O
from O
our O
models O
as O
well O
. O
Span O
SRL Task
Table O
[ O
reference O
] O
shows O
that O
our O
model O
outperforms O
all O
published O
systems O
, O
even O
the O
ensemble Method
model Method
, O
achieving O
the O
best O
results O
of O
87.7 O
% O
, O
80.5 O
% O
and O
86.0 O
% O
in O
F Metric
- Metric
score Metric
respectively O
. O
Dependency O
SRL Task
Table O
[ O
reference O
] O
compares O
the O
results O
of O
dependency Task
SRL Task
on O
CoNLL O
- O
2009 O
English O
data O
. O
Our O
single O
model O
gives O
a O
new O
state O
- O
of O
- O
the O
- O
art O
result O
of O
90.4 O
% O
F Metric
on O
WSJ O
. O
For O
Brown O
data O
, O
the O
proposed O
syntax Method
- Method
agnostic Method
model Method
yields O
a O
performance O
gain O
of O
1.7 O
% O
F Metric
over O
the O
syntax Method
- Method
aware Method
model Method
. O
subsection O
: O
Ablation Task
To O
investigate O
the O
contributions O
of O
ELMo Method
representations Method
and O
biaffine Method
scorer Method
in O
our O
end O
- O
to O
- O
end Method
model Method
, O
we O
conduct O
a O
series O
of O
ablation Task
studies Task
on O
the O
CoNLL Material
- Material
2005 Material
and O
CoNLL O
- O
2008 O
WSJ O
test O
sets O
, O
unless O
otherwise O
stated O
. O
Table O
[ O
reference O
] O
compares O
F Metric
scores Metric
of O
he2018jointly O
he2018jointly O
and O
our O
model O
without O
ELMo Method
representations Method
. O
We O
observe O
that O
effect O
of O
ELMo Method
is O
somewhat O
surprising O
, O
where O
removal O
of O
the O
ELMo Method
dramatically O
declines O
the O
performance O
by O
3.3 O
- O
3.5 O
F Metric
on O
CoNLL Material
- Material
2005 Material
WSJ O
. O
However O
, O
our O
model O
gives O
quite O
stable O
performance O
for O
dependency Task
SRL Task
regardless O
of O
whether O
ELMo Method
is O
concatenated O
or O
not O
. O
The O
results O
indicate O
that O
ELMo Method
is O
more O
beneficial O
to O
span Task
SRL Task
. O
In O
order O
to O
better O
understand O
how O
the O
biaffine O
scorer O
influences O
our O
model O
performance O
, O
we O
train O
our O
model O
with O
different O
scoring O
functions O
. O
To O
ensure O
a O
fair O
comparison O
with O
the O
model O
, O
we O
replace O
the O
biaffine Method
scorer Method
with O
their O
scoring Method
functions Method
implemented O
with O
feed Method
- Method
forward Method
networks Method
, O
and O
the O
results O
of O
removing O
biaffine Method
scorer Method
are O
also O
presented O
in O
Table O
[ O
reference O
] O
. O
We O
can O
see O
0.5 O
% O
and O
1.6 O
% O
F Metric
performance Metric
degradation Metric
on O
CoNLL Material
2005 Material
and O
2008 O
WSJ O
respectively O
. O
The O
comparison O
shows O
that O
the O
biaffine Method
scorer Method
is O
more O
effective O
for O
scoring O
the O
relations O
between O
predicates O
and O
arguments O
. O
Furthermore O
, O
these O
results O
show O
that O
biaffine Method
attention Method
mechanism Method
is O
applicable O
to O
span Task
SRL Task
. O
subsection O
: O
Dependency O
or O
Span O
? O
It O
is O
very O
hard O
to O
say O
which O
style O
of O
semantic Method
formal Method
representation Method
, O
dependency Task
or O
span Task
, O
would O
be O
more O
convenient O
for O
machine Method
learning Method
as O
they O
adopt O
incomparable Metric
evaluation Metric
metric Metric
. O
Recent O
researches O
have O
proposed O
to O
learn O
semantic Method
parsers Method
from O
multiple O
datasets O
in O
Framenet O
style O
semantics O
, O
while O
our O
goal O
is O
to O
compare O
the O
quality O
of O
different O
models O
in O
the O
span Task
and O
dependency Task
SRL Task
for O
Propbank O
style O
semantics O
. O
Following O
johansson2008EMNLP O
johansson2008EMNLP O
, O
we O
choose O
to O
directly O
compare O
their O
performance O
in O
terms O
of O
dependency Task
- O
style O
metric O
through O
a O
transformation O
way O
. O
Using O
the O
head Method
- Method
finding Method
algorithm Method
in O
which O
used O
gold O
- O
standard O
syntax O
, O
we O
may O
determine O
a O
set O
of O
head O
nodes O
for O
each O
span Task
. O
This O
process O
will O
output O
an O
upper Metric
bound Metric
performance Metric
measure Metric
about O
the O
span Task
conversion O
due O
to O
the O
use O
of O
gold O
syntax O
. O
We O
do O
not O
train O
new O
models O
for O
the O
conversion Task
and O
the O
resulted O
comparison O
. O
Instead O
, O
we O
do O
the O
job O
on O
span Task
- O
style O
CoNLL Material
2005 Material
test O
set O
and O
dependency Task
- O
style O
CoNLL O
2009 O
test O
set O
( O
WSJ O
and O
Brown O
) O
, O
considering O
these O
two O
test O
sets O
share O
the O
same O
text O
content O
. O
As O
the O
former O
only O
contains O
verbal O
predicate O
- O
argument O
structures O
, O
for O
the O
latter O
, O
we O
discard O
all O
nomial O
predicate O
- O
argument O
related O
results O
and O
predicate O
disambiguation O
results O
during O
performance O
statistics O
. O
Table O
[ O
reference O
] O
shows O
the O
comparison O
. O
On O
a O
more O
strict O
setting O
basis O
, O
the O
results O
from O
our O
same O
model O
for O
span Task
and O
dependency Task
SRL Task
verify O
the O
same O
conclusion O
of O
johansson2008EMNLP O
johansson2008EMNLP O
, O
namely O
, O
dependency Task
form O
is O
in O
a O
favor O
of O
machine Metric
learning Metric
effectiveness Metric
for O
SRL Task
even O
compared O
to O
the O
conversion Metric
upper Metric
bound Metric
of O
span Task
form O
. O
section O
: O
Conclusion O
This O
paper O
presents O
an O
end Method
- Method
to Method
- Method
end Method
neural Method
model Method
for O
both O
span Task
and O
dependency Task
SRL Task
, O
which O
may O
jointly O
learn O
and O
predict O
all O
predicates O
and O
arguments O
. O
We O
extend O
existing O
model O
and O
introduce O
unified Method
argument Method
representation Method
with O
biaffine Method
scorer Method
to O
the O
uniform Task
SRL Task
for O
both O
span Task
and O
dependency Task
representation O
forms O
. O
Our O
model O
achieves O
new O
state O
- O
of O
- O
the O
- O
art O
results O
on O
the O
CoNLL Material
2005 Material
, O
2012 O
and O
CoNLL O
2008 O
, O
2009 O
benchmarks O
. O
Our O
results O
show O
that O
span Task
and O
dependency Task
SRL Task
can O
be O
effectively O
handled O
in O
a O
uniform O
fashion O
, O
which O
for O
the O
first O
time O
enables O
us O
to O
conveniently O
explore O
the O
useful O
connection O
between O
two O
types O
of O
semantic O
representation O
forms O
. O
bibliography O
: O
References O
