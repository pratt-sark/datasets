document O
: O
Image Task
Reconstruction Task
with O
Predictive Method
Filter Method
Flow Method
We O
propose O
a O
simple O
, O
interpretable Method
framework Method
for O
solving O
a O
wide O
range O
of O
image Task
reconstruction Task
problems Task
such O
as O
denoising Task
and Task
deconvolution Task
. O
Given O
a O
corrupted O
input O
image O
, O
the O
model O
synthesizes O
a O
spatially Method
varying Method
linear Method
filter Method
which O
, O
when O
applied O
to O
the O
input O
image O
, O
reconstructs O
the O
desired O
output O
. O
The O
model O
parameters O
are O
learned O
using O
supervised Method
or Method
self Method
- Method
supervised Method
training Method
. O
We O
test O
this O
model O
on O
three O
tasks O
: O
non Task
- Task
uniform Task
motion Task
blur Task
removal Task
, O
lossy Task
- Task
compression Task
artifact Task
reduction Task
and O
single Task
image Task
super Task
resolution Task
. O
We O
demonstrate O
that O
our O
model O
substantially O
outperforms O
state O
- O
of O
- O
the O
- O
art O
methods O
on O
all O
these O
tasks O
and O
is O
significantly O
faster O
than O
optimization Method
- Method
based Method
approaches Method
to O
deconvolution Task
. O
Unlike O
models O
that O
directly O
predict O
output O
pixel O
values O
, O
the O
predicted O
filter O
flow O
is O
controllable O
and O
interpretable O
, O
which O
we O
demonstrate O
by O
visualizing O
the O
space O
of O
predicted O
filters O
for O
different O
tasks O
. O
section O
: O
Introduction O
Real O
- O
world O
images O
are O
seldom O
perfect O
. O
Practical O
engineering O
trade O
- O
offs O
entail O
that O
consumer O
photos O
are O
often O
blurry O
due O
to O
low O
- O
light O
, O
camera O
shake O
or O
object O
motion O
, O
limited O
in O
resolution O
and O
further O
degraded O
by O
image O
compression O
artifacts O
introduced O
for O
the O
sake O
of O
affordable O
transmission Task
and Task
storage Task
. O
Scientific Task
applications Task
such O
as O
microscopy Task
or O
astronomy Task
, O
which O
push O
the O
fundamental O
physical O
limitations O
of O
light O
, O
lenses O
and O
sensors O
, O
face O
similar O
challenges O
. O
Recovering Task
high Task
- Task
quality Task
images Task
from O
degraded O
measurements O
has O
been O
a O
long O
- O
standing O
problem O
for O
image Task
analysis Task
and O
spans O
a O
range O
of O
tasks O
such O
as O
blind Task
- Task
image Task
deblurring Task
, O
compression Task
artifact Task
reduction Task
, O
and O
single Task
image Task
super Task
- Task
resolution Task
. O
Such O
image Task
reconstruction Task
tasks Task
can O
be O
viewed O
mathematically O
as O
inverse Task
problems Task
, O
which O
are O
typically O
ill O
- O
posed O
and O
massively O
under O
- O
constrained O
. O
Many O
contemporary O
techniques O
to O
inverse Task
problems Task
have O
focused O
on O
regularization Method
techniques Method
which O
are O
amenable O
to O
computational Task
optimization Task
. O
While O
such O
approaches O
are O
interpretable O
as O
Bayesian Method
estimators Method
with O
particular O
choice O
of O
priors O
, O
they O
are O
often O
computationally O
expensive O
in O
practice O
. O
Alternately O
, O
data Method
- Method
driven Method
methods Method
based O
on O
training O
deep Method
convolutional Method
neural Method
networks Method
yield O
fast O
inference Task
but O
lack O
interpretability O
and O
guarantees O
of O
robustness Metric
. O
In O
this O
paper O
, O
we O
propose O
a O
new O
framework O
called O
Predictive Method
Filter Method
Flow Method
that O
retains O
interpretability O
and O
control O
over O
the O
resulting O
reconstruction Task
while O
allowing O
fast Task
inference Task
. O
The O
proposed O
framework O
is O
directly O
applicable O
to O
a O
variety O
of O
low Task
- Task
level Task
computer Task
vision Task
problems Task
involving O
local Task
pixel Task
transformations Task
. O
As O
the O
name O
suggests O
, O
our O
approach O
is O
built O
on O
the O
notion O
of O
filter Method
flow Method
introduced O
by O
Seitz O
and O
Baker O
. O
In O
filter Method
flow Method
pixels O
in O
a O
local O
neighborhood O
of O
the O
input O
image O
are O
linearly O
combined O
to O
reconstruct O
the O
pixel O
centered O
at O
the O
same O
location O
in O
the O
output O
image O
. O
However O
, O
unlike O
convolution Method
, O
the O
filter O
weights O
are O
allowed O
to O
vary O
from O
one O
spatial O
location O
to O
the O
next O
. O
Filter Method
flows Method
are O
a O
flexible O
class O
of O
image Method
transformations Method
that O
can O
model O
a O
wide O
range O
of O
imaging O
effects O
( O
including O
optical O
flow O
, O
lighting O
changes O
, O
non O
- O
uniform O
blur O
, O
non O
- O
parametric O
distortion O
) O
. O
The O
original O
work O
on O
filter Method
flow Method
focused O
on O
the O
problem O
of O
estimating O
an O
appropriately O
regularized Task
/ Task
constrained Task
flow Task
between O
a O
given O
pair O
of O
images O
. O
This O
yielded O
convex O
but O
impractically O
large O
optimization Task
problems Task
( O
e.g. O
, O
hours O
of O
computation O
to O
compute O
a O
single O
flow O
) O
. O
Instead O
of O
solving O
for O
an O
optimal Method
filter Method
flow Method
, O
we O
propose O
to O
directly O
predict O
a O
filter Method
flow Method
given O
an O
input O
image O
using O
a O
convolutional Method
neural Method
net Method
( O
CNN Method
) O
to O
regress O
the O
filter O
weights O
. O
Using O
a O
CNN Method
to O
directly O
predict O
a O
well Method
regularized Method
solution Method
is O
orders O
of O
magnitude O
faster O
than O
expensive O
iterative Method
optimization Method
. O
Fig O
. O
[ O
reference O
] O
provides O
an O
illustration O
of O
our O
overall O
framework O
. O
Instead O
of O
estimating O
the O
flow O
between O
a O
pair O
of O
input O
images O
, O
we O
focus O
on O
applications O
where O
the O
model O
predicts O
both O
the O
flow O
and O
the O
transformed O
image O
. O
This O
can O
be O
viewed O
as O
“ O
blind Task
” Task
filter Task
flow Task
estimation Task
, O
in O
analogy O
with O
blind Task
deconvolution Task
. O
During O
training Task
, O
we O
use O
a O
loss O
defined O
over O
the O
transformed O
image O
( O
rather O
than O
the O
predicted O
flow O
) O
. O
This O
is O
closely O
related O
to O
so O
- O
called O
self Method
- Method
supervised Method
techniques Method
that O
learn O
to O
predict O
optical Method
flow Method
and O
depth Method
from O
unlabeled O
video O
data O
. O
Specifically O
, O
for O
the O
reconstruction Task
tasks Task
we O
consider O
such O
as O
image Task
super Task
- Task
resolution Task
, O
the O
forward Method
degradation Method
process Method
can O
be O
easily O
simulated O
to O
generate O
a O
large O
quantity O
of O
training O
data O
without O
manual O
collection O
or O
annotation O
. O
The O
lack O
of O
interpretability O
in O
deep Method
image Method
- Method
to Method
- Method
image Method
regression Method
models Method
makes O
it O
hard O
to O
provide O
guarantees O
of O
robustness Metric
in O
the O
presence O
of O
adversarial O
input O
, O
and O
confer O
reliability Metric
needed O
for O
researchers O
in O
biology Task
and O
medical O
science O
. O
Predictive Method
filter Method
flow Method
differs O
from O
other O
CNN Method
- Method
based Method
approaches Method
in O
this O
regard O
since O
the O
intermediate Method
filter Method
flows Method
are O
interpretable O
and O
transparent O
, O
providing O
an O
explicit O
description O
of O
how O
the O
input O
is O
transformed O
into O
output O
. O
It O
is O
also O
straightforward O
to O
inject O
constraints O
on O
the O
reconstruction Task
( O
e.g. O
, O
local O
brightness O
conservation O
) O
which O
would O
be O
nearly O
impossible O
to O
guarantee O
for O
deep O
image Method
- Method
to Method
- Method
image Method
regression Method
models Method
. O
To O
evaluate O
our O
model O
, O
we O
carry O
out O
extensive O
experiments O
on O
three O
different O
low Task
- Task
level Task
vision Task
tasks Task
, O
non Task
- Task
uniform Task
motion Task
blur Task
removal Task
, O
JPEG Task
compression Task
artifact Task
reduction Task
and O
single Task
image Task
super Task
- Task
resolution Task
. O
We O
show O
that O
our O
model O
surpasses O
all O
the O
state O
- O
of O
- O
the O
- O
art O
methods O
on O
all O
the O
three O
tasks O
. O
We O
also O
visualize O
the O
predicted Method
filters Method
which O
reveals O
filtering Method
operators Method
reminiscent O
of O
classic O
unsharp Method
masking Method
filters Method
and O
anisotropic Method
diffusion Method
along O
boundaries O
. O
To O
summarize O
our O
contribution O
: O
( O
1 O
) O
we O
propose O
a O
novel O
, O
end Method
- Method
to Method
- Method
end Method
trainable Method
, Method
learning Method
framework Method
for O
solving O
various O
low Task
- Task
level Task
image Task
reconstruction Task
tasks Task
; O
( O
2 O
) O
we O
show O
this O
framework O
is O
highly O
interpretable O
and O
controllable O
, O
enabling O
direct O
post Task
- Task
hoc Task
analysis Task
of O
how O
the O
reconstructed O
image O
is O
generated O
from O
the O
degraded O
input O
; O
( O
3 O
) O
we O
show O
experimentally O
that O
predictive Method
filter Method
flow Method
outperforms O
the O
state O
- O
of O
- O
the O
- O
art O
methods O
remarkably O
on O
the O
three O
different O
tasks O
, O
non Task
- Task
uniform Task
motion Task
blur Task
removal Task
, O
compression Task
artifact Task
reduction Task
and O
single Task
image Task
super Task
- Task
resolution Task
. O
section O
: O
Related O
Work O
Our O
work O
is O
inspired O
by O
filter Method
flow Method
, O
which O
is O
an O
optimization Method
based Method
method Method
for O
finding O
a O
linear O
transformation O
relating O
nearby O
pixel O
values O
in O
a O
pair O
of O
images O
. O
By O
imposing O
additional O
constraints O
on O
certain O
structural O
properties O
of O
these O
filters O
, O
it O
serves O
as O
a O
general O
framework O
for O
understanding O
a O
wide O
variety O
of O
low Task
- Task
level Task
vision Task
problems Task
. O
However O
, O
filter Method
flow Method
as O
originally O
formulated O
has O
some O
obvious O
shortcomings O
. O
First O
, O
it O
requires O
prior O
knowledge O
to O
specify O
a O
set O
of O
constraints O
needed O
to O
produce O
good O
results O
. O
It O
is O
not O
always O
straightforward O
to O
model O
or O
even O
come O
up O
with O
such O
knowledge O
- O
based O
constraints O
. O
Second O
, O
solving O
for O
an O
optimal Method
filter Method
flow Method
is O
compute O
intensive O
; O
it O
may O
take O
up O
to O
20 O
hours O
to O
compute O
over O
a O
pair O
of O
500 O
500 O
images O
. O
We O
address O
these O
by O
directly O
predicting Task
flows Task
from O
image O
data O
. O
We O
leverage O
predictive Method
filter Method
flow Method
for O
targeting O
three O
specific O
image Task
reconstruction Task
tasks Task
which O
can O
be O
framed O
as O
performing O
spatially Method
variant Method
filtering Method
over O
local O
image O
patches O
. O
Non Task
- Task
Uniform Task
Blind Task
Motion Task
Blur Task
Removal Task
is O
an O
extremely O
challenging O
yet O
practically O
significant O
task O
of O
removing Task
blur Task
caused O
by O
object O
motion O
or O
camera O
shake O
on O
a O
blurry O
photo O
. O
The O
blur O
kernel O
is O
unknown O
and O
may O
vary O
over O
the O
image O
. O
Recent O
methods O
estimate O
blur O
kernels O
locally O
at O
patch O
level O
, O
and O
adopt O
an O
optimization Method
method Method
for O
deblurring O
the O
patches O
. O
leverage O
prior O
information O
about O
smooth O
motion O
by O
selecting O
from O
a O
predefine O
discretized O
set O
of O
linear O
blur O
kernels O
. O
These O
methods O
are O
computationally O
expensive O
as O
an O
iterative Method
solver Method
is O
required O
for O
deconvolution Task
after O
estimating O
the O
blur Method
kernel Method
; O
and O
the O
deep Method
learning Method
approach Method
can O
not O
generalize O
well O
to O
novel O
motion O
kernels O
. O
Compression Task
Artifact Task
Reduction Task
is O
of O
significance O
as O
lossy Task
image Task
compression Task
is O
ubiquitous O
for O
reducing O
the O
size O
of O
images O
transmitted O
over O
the O
web O
and O
recorded O
on O
data O
storage O
media O
. O
However O
, O
high O
compression Metric
rates Metric
come O
with O
visual O
artifacts O
that O
degrade O
the O
image Metric
quality Metric
and O
thus O
user O
experience O
. O
Among O
various O
compression Method
algorithms Method
, O
JPEG Method
has O
become O
the O
most O
widely O
accepted O
standard O
in O
lossy Task
image Task
compression Task
with O
several O
( O
non O
- O
invertible O
) O
transforms O
, O
i.e. O
, O
downsampling O
and O
DCT Method
quantization Method
. O
Removing Task
artifacts Task
from O
jpeg Task
compression Task
can O
be O
viewed O
as O
a O
practical O
variant O
of O
natural Task
image Task
denoising Task
problems Task
. O
Recent O
methods O
based O
on O
deep Method
convolutional Method
neural Method
networks Method
trained O
to O
take O
as O
input O
the O
compressed O
image O
and O
output O
the O
denoised O
image O
directly O
achieve O
good O
performance O
. O
Single Task
Image Task
Super Task
- Task
Resolution Task
aims O
at O
recovering O
a O
high O
- O
resolution O
image O
from O
a O
single O
low O
- O
resolution O
image O
. O
This O
problem O
is O
inherently O
ill O
- O
posed O
as O
a O
multiplicity O
of O
solutions O
exists O
for O
any O
given O
low O
- O
resolution O
input O
. O
Many O
methods O
adopt O
an O
example Method
- Method
based Method
strategy Method
requiring O
an O
optimization Method
solver Method
, O
others O
are O
based O
on O
deep Method
convolutional Method
neural Method
nets Method
which O
achieve O
the O
state O
- O
of O
- O
the O
- O
art O
and O
real Metric
- Metric
time Metric
performance Metric
. O
The O
deep Method
learning Method
methods Method
take O
as O
input O
the O
low O
- O
resolution O
image O
( O
usually O
4 O
upsampled O
one O
using O
bicubic Method
interpolation Method
) O
, O
and O
output O
the O
high O
- O
resolution O
image O
directly O
. O
section O
: O
Predictive Method
Filter Method
Flow Method
Filter Method
flow Method
models O
image Task
transformations Task
as O
a O
linear Method
mapping Method
where O
each O
output O
pixel O
only O
depends O
on O
a O
local O
neighborhood O
of O
the O
input O
. O
Find O
such O
a O
flow O
can O
be O
framed O
as O
solving O
a O
constrained Method
linear Method
system Method
where O
is O
a O
matrix O
whose O
rows O
act O
separately O
on O
a O
vectorized Method
version Method
of O
the O
source O
image O
. O
For O
the O
model O
[ O
reference O
] O
to O
make O
sense O
, O
must O
serve O
as O
a O
placeholder O
for O
the O
entire O
set O
of O
additional O
constraints O
on O
the O
operator O
which O
enables O
a O
unique O
solution O
that O
satisfies O
our O
expectations O
for O
particular O
problems O
of O
interest O
. O
For O
example O
, O
standard O
convolution Method
corresponds O
to O
being O
a O
circulant Method
matrix Method
whose O
rows O
are O
cyclic O
permutations O
of O
a O
single O
set O
of O
filter O
weights O
which O
are O
typically O
constrained O
to O
have O
compact O
localized O
non O
- O
zero O
support O
. O
For O
a O
theoretical O
perspective O
, O
Filter Method
Flow Method
model Method
[ O
reference O
] O
is O
simple O
and O
elegant O
, O
but O
directly O
solving O
Eq O
. O
[ O
reference O
] O
is O
intractable O
for O
image O
sizes O
we O
typically O
encounter O
in O
practice O
, O
particularly O
when O
the O
filters Method
are O
allowed O
to O
vary O
spatially O
. O
subsection O
: O
Learning O
to O
predict Task
flows Task
Instead O
of O
optimizing O
over O
directly O
, O
we O
seek O
for O
a O
learnable O
function O
parameterized O
by O
that O
predicts O
the O
transformation O
specific O
to O
image O
taken O
as O
input O
: O
We O
call O
this O
model O
Predictive Method
Filter Method
Flow Method
. O
Manually O
designing O
such O
a O
function O
is O
n’t O
feasible O
in O
general O
, O
therefore O
we O
learn O
a O
specific O
under O
the O
assumption O
that O
are O
drawn O
from O
some O
fixed O
joint O
distribution O
. O
Given O
sampled O
image O
pairs O
, O
, O
where O
, O
we O
seek O
parameters O
that O
minimize O
the O
difference O
between O
a O
recovered O
image O
and O
the O
real O
one O
measured O
by O
some O
loss O
. O
Note O
that O
constraints O
on O
are O
different O
from O
constraints O
used O
in O
Filter Method
Flow Method
. O
In O
practice O
, O
we O
enforce O
hard O
constraints O
via O
our O
choice O
of O
the O
architecture O
/ O
functional O
form O
of O
along O
with O
soft O
- O
constraints O
via O
additional O
regularization O
term O
. O
We O
also O
adopt O
commonly O
used O
regularization O
on O
to O
reduce O
overfitting O
. O
There O
are O
a O
range O
of O
possible O
choices O
for O
measuring O
the O
difference O
between O
two O
images O
. O
In O
our O
experiments O
, O
we O
simply O
use O
the O
robust Method
norm Method
to O
measure O
the O
pixel O
- O
level O
difference O
. O
paragraph O
: O
Filter Method
locality Method
In O
principle O
, O
each O
pixel O
output O
in O
Eq O
. O
[ O
reference O
] O
can O
depend O
on O
all O
input O
pixels O
. O
We O
introduce O
the O
structural O
constraint O
that O
each O
output O
pixel O
only O
depends O
on O
a O
corresponding O
local O
neighborhood O
of O
the O
input O
. O
The O
size O
of O
this O
neighborhood O
is O
thus O
a O
hyper O
- O
parameter O
of O
the O
model O
. O
We O
note O
that O
while O
the O
predicted O
filter O
flow O
acts O
locally O
, O
the O
estimation O
of O
the O
correct O
local O
flow O
within O
a O
patch O
can O
depend O
on O
global O
context O
captured O
by O
large O
receptive O
fields O
in O
the O
predictor O
. O
In O
practice O
, O
this O
constraint O
is O
implemented O
by O
using O
the O
“ O
im2col Method
” Method
operation Method
to O
vectorize O
the O
local O
neighborhood O
patch O
centered O
at O
each O
pixel O
and O
compute O
the O
inner O
product O
of O
this O
vector O
with O
the O
corresponding O
predicted Method
filter Method
. O
This O
operation O
is O
highly O
optimized O
for O
available O
hardware O
architectures O
in O
most O
deep Method
learning Method
libraries Method
and O
has O
time Metric
and O
space Metric
cost Metric
similar O
to O
computing O
a O
single O
convolution Method
. O
For O
example O
, O
if O
the O
filter O
size O
is O
20 O
20 O
, O
the O
last O
layer O
of O
the O
CNN Method
model Method
outputs O
a O
three O
- O
dimensional O
array O
with O
a O
channel O
dimension O
of O
, O
which O
is O
comparable O
to O
feature O
activations O
at O
a O
single O
layer O
of O
typical O
CNN Method
architectures Method
. O
paragraph O
: O
Other O
filter O
constraints O
Various O
priori O
constraints O
on O
the O
filter Method
flow Method
can O
be O
added O
easily O
to O
enable O
better O
model Task
training Task
. O
For O
example O
, O
if O
smoothness O
is O
desired O
, O
an O
regularization Method
on O
the O
( O
1st O
order O
or O
2nd O
order O
) O
derivative O
of O
the O
filter O
flow O
maps O
can O
be O
inserted O
during O
training Task
; O
if O
sparsity O
is O
desired O
, O
an O
regularization Method
on O
the O
filter Method
flows Method
can O
be O
added O
easily O
. O
In O
our O
work O
, O
we O
add O
sum O
- O
to O
- O
one O
and O
non O
- O
negative O
constraints O
on O
the O
filters O
for O
the O
task O
of O
non Task
- Task
uniform Task
motion Task
blur Task
removal Task
, O
meaning O
that O
the O
values O
in O
each O
filter O
should O
be O
non O
- O
negative O
and O
sum O
- O
to O
- O
one O
by O
assuming O
there O
is O
no O
lighting O
change O
. O
This O
can O
be O
easily O
done O
by O
inserting O
a O
softmax Method
transform Method
across O
channels O
of O
the O
predicted O
filter O
weights O
. O
For O
other O
tasks O
, O
we O
simply O
let O
the O
model Method
output Method
free Method
- Method
form Method
filters Method
with O
no O
further O
constraints O
on O
the O
weights O
. O
paragraph O
: O
Self O
- O
Supervision O
Though O
the O
proposed O
framework O
for O
training O
Predictive Method
Filter Method
Flow Method
requires O
paired O
inputs O
and O
target O
outputs O
, O
we O
note O
that O
generating O
training O
data O
for O
many O
reconstruction Task
tasks Task
can O
be O
accomplished O
automatically O
without O
manual Task
labeling Task
. O
Given O
a O
pool O
of O
high O
quality O
images O
, O
we O
can O
automatically O
generate O
low O
- O
resolution O
, O
blurred O
or O
JPEG O
degraded O
counterparts O
to O
use O
in O
training O
( O
see O
Section O
[ O
reference O
] O
) O
. O
This O
can O
also O
be O
generalized O
to O
so O
- O
called O
self Method
- Method
supervised Method
training Method
for O
predicting Task
flows Task
between Task
video Task
frames Task
or O
stereo O
pairs O
. O
subsection O
: O
Model Method
Architecture Method
and O
Training O
Our O
basic O
framework O
is O
largely O
agnostic O
to O
the O
choice O
of O
architectures O
, O
learning Method
method Method
, O
and O
loss O
functions O
. O
In O
our O
experiments O
, O
we O
utilize O
to O
a O
two Method
- Method
stream Method
architecture Method
as O
shown O
in O
Fig O
. O
[ O
reference O
] O
. O
The O
first O
stream O
is O
a O
simple O
18 Method
- Method
layer Method
network Method
with O
3 O
3 Method
convolutional Method
layers Method
, O
skip O
connections O
, O
pooling Method
layers Method
and O
upsampling Method
layers Method
; O
the O
second O
stream O
is O
a O
shallow Method
but Method
full Method
- Method
resolution Method
network Method
with O
no O
pooling Method
. O
The O
first O
stream O
has O
larger O
receptive O
fields O
for O
estimating O
per Task
- Task
pixel Task
filters Task
by O
considering O
long O
- O
range O
contextual O
information O
, O
while O
the O
second O
stream O
keeps O
original O
resolution O
as O
input O
image O
without O
inducing O
spatial O
information O
loss O
. O
Batch Method
normalization Method
is O
also O
inserted O
between O
a O
convolution Method
layer Method
and O
ReLU Method
layer Method
. O
The O
Predictive Method
Filter Method
Flow Method
is O
self O
- O
supervised O
so O
we O
could O
generate O
an O
unlimited O
amount O
of O
image O
pairs O
for O
training O
very O
large O
models O
. O
However O
, O
we O
find O
a O
light Method
- Method
weight Method
architecture Method
trained O
over O
moderate O
- O
scale O
training O
set O
performs O
quite O
well O
. O
Since O
our O
architecture O
is O
different O
from O
other O
feed Method
- Method
forward Method
image Method
- Method
to Method
- Method
image Method
regression Method
CNNs Method
, O
we O
also O
report O
the O
baseline O
performance O
of O
the O
two Method
- Method
stream Method
architecture Method
trained O
to O
directly O
predict O
the O
reconstructed O
image O
rather O
than O
the O
filter O
coefficients O
. O
For O
training O
, O
we O
crop O
64 O
64 O
- O
resolution O
patches O
to O
form O
a O
batch O
of O
size O
56 O
. O
Since O
the O
model O
adapts O
to O
patch O
boundary O
effects O
seen O
during O
training O
, O
at O
test O
time O
we O
apply O
it O
to O
non O
- O
overlapping O
tiles O
of O
the O
input O
image O
. O
However O
, O
we O
note O
that O
the O
model O
is O
fully O
convolutional Method
so O
it O
could O
be O
trained O
over O
larger O
patches O
to O
avoid O
boundary O
effects O
and O
applied O
to O
arbitrary O
size O
inputs O
. O
We O
use O
ADAM Method
optimization Method
method Method
during O
training O
, O
with O
initial O
learning O
0.0005 O
and O
coefficients O
0.9 O
and O
0.999 O
for O
computing O
running Metric
averages Metric
of Metric
gradient Metric
and O
its O
square O
. O
As O
for O
the O
training Task
loss Task
, O
we O
simply O
use O
the O
- Method
norm Method
loss Method
measuring O
absolute Metric
difference Metric
over Metric
pixel Metric
intensities Metric
. O
We O
train O
our O
model O
from O
scratch O
on O
a O
single O
NVIDIA Method
TITAN Method
X Method
GPU Method
, O
and O
terminate O
after O
several O
hundred O
epochs O
. O
section O
: O
Experiments O
We O
evaluate O
the O
proposed O
Predictive Method
Filter Method
Flow Method
framework O
( O
PFF Method
) O
on O
three O
low Task
- Task
level Task
vision Task
tasks Task
: O
non Task
- Task
uniform Task
motion Task
blur Task
removal Task
, O
JPEG Task
compression Task
artifact Task
reduction Task
and O
single Task
image Task
super Task
- Task
resolution Task
. O
We O
first O
describe O
the O
datasets O
and O
evaluation Metric
metrics Metric
, O
and O
then O
compare O
with O
state O
- O
of O
- O
the O
- O
art O
methods O
on O
the O
three O
tasks O
in O
separate O
subsections O
, O
respectively O
. O
subsection O
: O
Datasets O
and O
Metrics O
We O
use O
the O
high O
- O
resolution O
images O
in O
DIV2 O
K O
dataset O
and O
BSDS500 O
training O
set O
for O
training O
all O
our O
models O
on O
the O
three O
tasks O
. O
This O
results O
into O
a O
total O
of O
1 O
, O
200 O
training O
images O
. O
We O
evaluate O
each O
model O
over O
different O
datasets O
specific O
to O
the O
task O
. O
Concretely O
, O
we O
test O
our O
model O
for O
non Task
- Task
uniform Task
motion Task
blur Task
removal Task
over O
the O
dataset O
introduced O
in O
, O
which O
contains O
large O
motion O
blur O
up O
to O
38 O
pixels O
. O
We O
evaluate O
over O
the O
classic O
LIVE1 O
dataset O
for O
JPEG Task
compression Task
artifacts Task
reduction Task
, O
and O
Set5 Material
and O
Set14 Material
for O
single Task
image Task
super Task
- Task
resolution Task
. O
To O
quantitatively O
measure O
performance O
, O
we O
use O
Peak Metric
- Metric
Signal Metric
- Metric
to Metric
- Metric
Noise Metric
- Metric
Ratio Metric
( O
PSNR Metric
) O
and O
Structural Metric
Similarity Metric
Index Metric
( O
SSIM Metric
) O
over O
the O
Y O
channel O
in O
YCbCr O
color O
space O
between O
the O
output O
quality O
image O
and O
the O
original O
image O
. O
This O
is O
a O
standard O
practice O
in O
literature O
for O
quantitatively O
measuring O
the O
recovered Metric
image Metric
quality Metric
. O
subsection O
: O
Non Task
- Task
Uniform Task
Motion Task
Blur Task
Removal Task
To O
train O
models O
for O
non Task
- Task
uniform Task
motion Task
blur Task
removal Task
, O
we O
generate O
the O
64 O
64 O
- O
resolution O
blurry O
patches O
from O
clear O
ones O
using O
random Method
linear Method
kernels Method
, O
which O
are O
of O
size O
30 O
30 O
and O
have O
motion O
vector O
with O
random O
orientation O
in O
degrees O
and O
random O
length O
in O
pixels O
. O
We O
set O
the O
predicted O
filter O
size O
to O
be O
17 O
17 O
so O
the O
model O
outputs O
17 O
17 O
289 O
filter O
weights O
at O
each O
image O
location O
. O
Note O
that O
we O
generate O
training O
pairs O
on O
the O
fly O
during O
training O
, O
so O
our O
model O
can O
deal O
with O
a O
wide O
range O
of O
motion O
blurs O
. O
This O
is O
advantageous O
over O
methods O
in O
which O
require O
a O
predefined O
set O
of O
blur O
kernels O
used O
for O
deconvolution Task
through O
some O
offline Method
algorithm Method
. O
In O
Table O
[ O
reference O
] O
, O
we O
list O
the O
comparison O
with O
the O
state O
- O
of O
- O
the O
- O
art O
methods O
over O
the O
released O
test O
set O
by O
. O
There O
are O
two O
subsets O
in O
the O
dataset O
, O
one O
with O
moderate O
motion O
blur O
and O
the O
other O
with O
large O
blur O
. O
We O
also O
report O
our O
CNN Method
models Method
based O
on O
the O
proposed O
two Method
- Method
stream Method
architecture Method
that O
outputs O
the O
quality O
images O
directly O
by O
taking O
as O
input O
the O
blurry O
ones O
. O
Our O
CNN Method
model Method
outperforms O
the O
one O
in O
which O
trains O
a O
CNN Method
for O
predicting O
the O
blur O
kernel O
over O
a O
patch O
, O
but O
carries O
out O
non Method
- Method
blind Method
deconvolution Method
with O
the O
estimated Method
kernel Method
for O
the O
final O
quality O
image O
. O
We O
attribute O
our O
better O
performance O
to O
two O
reasons O
. O
First O
, O
our O
CNN Method
model Method
learns O
a O
direct O
inverse Method
mapping Method
from O
blurry O
patch O
to O
its O
clear O
counterpart O
based O
on O
the O
learned O
image O
distribution O
, O
whereas O
only O
estimates O
the O
blur O
kernel O
for O
the O
patch O
and O
uses O
an O
offline Method
optimization Method
for O
non Task
- Task
blind Task
deblurring Task
, O
resulting O
in O
some O
artifacts O
such O
as O
ringing O
. O
Second O
, O
our O
CNN Method
architecture Method
is O
higher O
fidelity O
than O
the O
one O
used O
in O
, O
as O
ours O
outputs O
full O
- O
resolution O
result O
and O
learns O
internally O
to O
minimize O
artifacts O
, O
e.g. O
, O
aliasing O
and O
ringing O
effect O
. O
From O
the O
table O
, O
we O
can O
see O
our O
PFF Method
model Method
outperforms O
all O
the O
other O
methods O
by O
a O
fair O
margin O
. O
To O
understand O
where O
our O
model O
performs O
better O
, O
we O
visualize O
the O
qualitative O
results O
in O
Fig O
. O
[ O
reference O
] O
, O
along O
with O
the O
filter Method
flow Method
maps Method
as O
output O
from O
PFF Method
. O
We O
ca O
n’t O
easily O
visualize O
the O
289 Method
dimensional Method
filters Method
. O
However O
, O
since O
the O
predicted O
weights O
are O
positive O
and O
normalized O
, O
we O
can O
treat O
them O
as O
a O
distribution O
which O
we O
summarize O
by O
computing O
the O
expected O
flow O
vector O
where O
is O
a O
particular O
output O
pixel O
and O
indexes O
the O
input O
pixels O
. O
This O
can O
be O
interpreted O
as O
the O
optical O
flow O
( O
delta Method
filter Method
) O
which O
most O
closely O
approximates O
the O
predicted O
filter O
flow O
. O
We O
use O
the O
the O
color O
legend O
shown O
in O
top O
- O
left O
of O
Fig O
. O
[ O
reference O
] O
. O
The O
last O
two O
rows O
of O
Fig O
. O
[ O
reference O
] O
show O
the O
results O
over O
real O
- O
world O
blurry O
images O
for O
which O
there O
is O
no O
“ O
blur O
- O
free O
” O
ground O
- O
truth O
. O
We O
can O
clearly O
see O
that O
images O
produced O
by O
PFF Method
have O
less O
artifacts O
such O
as O
ringing O
artifacts O
around O
sharp O
edges O
. O
Interestingly O
, O
from O
the O
filter Method
flow Method
maps Method
, O
we O
can O
see O
that O
the O
expected O
flow O
vectors O
are O
large O
near O
high O
contrast O
boundaries O
and O
smaller O
in O
regions O
that O
are O
already O
in O
sharp O
focus O
or O
which O
are O
uniform O
in O
color O
. O
Although O
we O
define O
the O
filter O
size O
as O
17 O
17 O
, O
which O
is O
much O
smaller O
than O
the O
maximum O
shift O
in O
the O
largest O
blur O
( O
up O
to O
30 O
pixels O
) O
, O
our O
model O
still O
handles O
large O
motion O
blur O
and O
performs O
better O
than O
. O
We O
assume O
it O
should O
be O
possible O
to O
utilize O
larger O
filter O
sizes O
but O
we O
did O
not O
observe O
further O
improvements O
when O
training O
models O
to O
synthesize O
larger O
per O
- O
pixel O
kernels O
. O
This O
suggests O
that O
a O
larger O
blurry O
dataset O
is O
needed O
to O
validate O
this O
point O
in O
future O
work O
. O
We O
also O
considered O
an O
iterative Method
variant Method
of O
our O
model O
in O
which O
we O
feed O
the O
resulting O
deblurred O
image O
back O
as O
input O
to O
the O
model O
. O
However O
, O
we O
found O
relatively O
little O
improvement O
with O
additional O
iterations O
( O
results O
shown O
in O
the O
appendix O
) O
. O
We O
conjecture O
that O
, O
although O
the O
model O
was O
trained O
with O
a O
wide O
range O
of O
blurred O
examples O
, O
the O
statistics O
of O
the O
transformed O
image O
from O
the O
first O
iteration O
are O
sufficiently O
different O
than O
the O
blurred O
training O
inputs O
. O
One O
solution O
could O
be O
inserting O
adversarial O
loss O
to O
push O
the O
model O
to O
generate O
more O
fine O
- O
grained O
textures O
( O
as O
done O
in O
for O
image Task
super Task
- Task
resolution Task
) O
. O
subsection O
: O
JPEG Task
Compression Task
Artifact Task
Reduction Task
Similar O
to O
training O
for O
image Task
deblurring Task
, O
we O
generate O
JPEG O
compressed O
image O
patches O
from O
original O
non O
- O
compressed O
ones O
on O
the O
fly O
during O
training O
. O
This O
can O
be O
easily O
done O
using O
JPEG Method
compression Method
function Method
by O
varying O
the O
quality O
factor O
( O
QF O
) O
of O
interest O
. O
In O
Table O
[ O
reference O
] O
, O
we O
list O
the O
performance O
of O
our O
model O
and O
compare O
to O
the O
state O
- O
of O
- O
the O
- O
art O
methods O
. O
We O
note O
that O
our O
final O
PFF Method
achieves O
the O
best O
among O
all O
the O
methods O
. O
Our O
CNN Method
baseline Method
model Method
also O
achieves O
on O
- O
par O
performance O
with O
state O
- O
of O
- O
the O
- O
art O
, O
though O
we O
do O
not O
show O
in O
the O
table O
, O
we O
draw O
the O
performance O
under O
the O
ablation O
study O
in O
Fig O
. O
[ O
reference O
] O
. O
Specifically O
, O
we O
study O
how O
our O
model O
trained O
with O
single O
or O
a O
mixed O
QFs O
affect O
the O
performance O
when O
tested O
on O
image O
compressed O
with O
a O
range O
of O
different O
QFs O
. O
We O
plot O
the O
detailed O
performances O
of O
our O
CNN Method
and O
PFF Method
in O
terms O
of O
absolute Metric
measurements Metric
by O
PSNR Metric
and O
SSIM Metric
, O
and O
the O
increase O
in O
PSNR Metric
between O
the O
reconstructed O
and O
JPEG O
compressed O
image O
. O
We O
can O
see O
that O
, O
though O
a O
model O
trained O
with O
QF=10 Method
overfits O
the O
dataset O
, O
all O
the O
other O
models O
achieve O
generalizable O
and O
stable O
performance O
. O
Basically O
, O
a O
model O
trained O
on O
a O
single O
QF Method
brings O
the O
largest O
performance O
gain O
over O
images O
compressed O
with O
the O
same O
QF O
. O
Moreover O
, O
when O
our O
model O
is O
trained O
with O
mixed O
quality O
factors O
, O
its O
performance O
is O
quite O
stable O
and O
competitive O
with O
quality Method
- Method
specific Method
models Method
across O
different O
compression Metric
quality Metric
factors Metric
. O
This O
indicates O
that O
our O
model O
is O
of O
practical O
value O
in O
real Task
- Task
world Task
applications Task
. O
In O
Fig O
. O
[ O
reference O
] O
, O
we O
demonstrate O
qualitative O
comparison O
between O
CNN Method
and O
PFF Method
. O
The O
output O
filter Method
flow Method
maps Method
indicate O
from O
the O
colorful O
edges O
how O
the O
pixels O
are O
warped O
from O
the O
neighborhood O
in O
the O
input O
image O
. O
This O
also O
clearly O
shows O
where O
the O
JPEG O
image O
degrades O
most O
, O
e.g. O
, O
the O
large O
sky O
region O
is O
quantized O
by O
JPEG Method
compression Method
. O
Though O
CNN Method
makes O
the O
block O
effect O
smooth O
to O
some O
extent O
, O
our O
PFF Method
produces O
the O
best O
visual Metric
quality Metric
, O
smoothing O
the O
block O
artifact O
while O
maintaining O
both O
high O
- O
and O
low O
- O
frequency O
details O
. O
PSNR Metric
improvements O
. O
SSIM Metric
improvements Metric
. O
subsection O
: O
Single Task
Image Task
Super Task
- Task
Resolution Task
In O
this O
work O
, O
we O
only O
generate O
pairs O
to O
super O
- O
resolve O
images O
4 O
larger O
. O
To O
generate O
training O
pairs O
, O
for O
each O
original O
image O
, O
we O
downsample O
and O
upsample O
4 O
again O
using O
bicubic Method
interpolation Method
( O
with O
anti O
- O
aliasing O
) O
. O
The O
4 O
upsampled O
image O
from O
the O
low O
- O
resolution O
is O
the O
input O
to O
our O
model O
. O
Therefore O
, O
a O
super Method
- Method
resolution Method
model Method
is O
expected O
to O
be O
learned O
for O
sharpening O
the O
input O
image O
. O
In O
Table O
[ O
reference O
] O
, O
we O
compare O
our O
PFF Method
model Method
quantitatively O
with O
other O
methods O
. O
We O
can O
see O
that O
our O
model O
outperforms O
the O
others O
on O
both O
test O
sets O
. O
In O
Fig O
. O
[ O
reference O
] O
, O
we O
compare O
visually O
over O
bicubic Method
interpolation Method
, O
CNN Method
and O
PFF Method
. O
We O
can O
see O
from O
the O
zoom O
- O
in O
regions O
that O
our O
PFF Method
generates O
sharper O
boundaries O
and O
delivers O
an O
anti O
- O
aliasing O
functionality O
. O
The O
filter Method
flow Method
maps Method
once O
again O
act O
as O
a O
guide O
, O
illustrating O
where O
the O
smoothing Task
happens O
and O
where O
sharpening O
happens O
. O
Especially O
, O
the O
filter Method
maps Method
demonstrate O
from O
the O
strong O
colorful O
edges O
where O
the O
pixels O
undergo O
larger O
transforms O
. O
In O
next O
section O
, O
we O
visualize O
the O
per O
- O
pixel O
kernels O
to O
have O
an O
in O
- O
depth O
understanding O
. O
Set5 Material
Set14 Material
section O
: O
Visualization Task
and O
Analysis O
We O
explored O
a O
number O
of O
techniques O
to O
visualize O
the O
predicted O
filter O
flows O
for O
different O
tasks O
. O
First O
, O
we O
ran O
k Method
- Method
means Method
on O
predicted Method
filters Method
from O
the O
set O
of O
test O
images O
for O
each O
the O
three O
tasks O
, O
respectively O
, O
to O
cluster O
the O
kernels O
into O
= O
400 O
groups O
. O
Then O
we O
run O
t Method
- Method
SNE Method
over O
the O
400 O
mean Method
filters Method
to O
display O
them O
in O
the O
image O
plane O
, O
shown O
by O
the O
scatter O
plots O
in O
top O
row O
of O
Fig O
. O
[ O
reference O
] O
. O
Qualitative O
inspection O
shows O
filters O
that O
can O
be O
interpreted O
as O
performing O
translation O
or O
integration O
along O
lines O
of O
different O
orientation O
( O
non O
- O
uniform O
blur O
) O
, O
filling O
in O
high O
- O
frequency O
detail O
( O
jpeg Task
artifact Task
reduction Task
) O
and O
deformed Method
Laplacian Method
- Method
like Method
filters Method
( O
super Method
- Method
resolution Method
) O
. O
We O
also O
examined O
the O
top O
10 O
principal O
components O
of O
the O
predicted O
filters O
( O
shown O
in O
the O
second O
row O
grid O
in O
Fig O
. O
[ O
reference O
] O
) O
. O
The O
10D Method
principal Method
subspace Method
capture O
99.65 O
% O
, O
99.99 O
% O
and O
99.99 O
% O
of O
the O
filter O
energy O
for O
non Task
- Task
uniform Task
blur Task
, O
artifact Task
removal Task
and O
super Task
resolution Task
respectively O
. O
PCA Method
reveals O
smooth O
, O
symmetric O
harmonic O
structure O
for O
super Task
- Task
resolution Task
with O
some O
intriguing O
vertical O
and O
horizontal O
features O
. O
Finally O
, O
in O
order O
to O
summarize O
the O
spatially O
varying O
structure O
of O
the O
filters O
, O
we O
use O
the O
2D Method
t Method
- Method
SNE Method
embedding Method
to O
assign O
a O
color O
to O
each O
centroid O
( O
as O
given O
by O
the O
reference O
color O
chart O
shown O
top O
- O
left O
) O
, O
and O
visualize O
the O
nearest O
centroid O
for O
the O
filter O
at O
each O
filter O
location O
in O
the O
third O
row O
grid O
in O
Fig O
. O
[ O
reference O
] O
. O
This O
visualization O
demonstrates O
the O
filters O
as O
output O
by O
our O
model O
generally O
vary O
smoothly O
over O
the O
image O
with O
discontinuities O
along O
salient O
edges O
and O
textured O
regions O
reminiscent O
of O
anisotropic Method
diffusion Method
or O
bilateral Method
filtering Method
. O
In O
summary O
, O
these O
visualizations O
provide O
a O
transparent O
view O
of O
how O
each O
reconstructed O
pixel O
is O
assembled O
from O
the O
degraded O
input O
image O
. O
We O
view O
this O
as O
a O
notable O
advantage O
over O
other O
CNN Method
- Method
based Method
models Method
which O
simply O
perform O
image Task
- Task
to Task
- Task
image Task
regression Task
. O
Unlike O
activations O
of O
intermediate O
layers O
of O
a O
CNN Method
, O
linear Method
filter Method
weights Method
have O
a O
well O
defined O
semantics O
that O
can O
be O
visualized O
and O
analyzed O
using O
well O
developed O
tools O
of O
linear Method
signal Method
processing Method
. O
section O
: O
Conclusion O
and O
Future O
Work O
We O
propose O
a O
general O
, O
elegant O
and O
simple O
framework O
called O
Predictive Method
Filter Method
Flow Method
, O
which O
has O
direct O
applications O
to O
a O
broad O
range O
of O
image Task
reconstruction Task
tasks Task
. O
Our O
framework O
generates O
space Method
- Method
variant Method
per Method
- Method
pixel Method
filters Method
which O
are O
easy O
to O
interpret O
and O
fast O
to O
compute O
at O
test O
time O
. O
Through O
extensive O
experiments O
over O
three O
different O
low Task
- Task
level Task
vision Task
tasks Task
, O
we O
demonstrate O
this O
approach O
outperforms O
the O
state O
- O
of O
- O
the O
- O
art O
methods O
. O
In O
our O
experiments O
here O
, O
we O
only O
train O
light Method
- Method
weight Method
models Method
over O
patches O
, O
However O
, O
we O
believe O
global O
image O
context O
is O
also O
important O
for O
these O
tasks O
and O
is O
an O
obvious O
direction O
for O
future O
work O
. O
For O
example O
, O
the O
global O
blur O
structure O
conveys O
information O
about O
camera O
shake O
; O
super Task
- Task
resolution Task
and O
compression Task
reduction Task
can O
benefit O
from O
long O
- O
range O
interactions O
to O
reconstruct O
high O
- O
frequency O
detail O
( O
as O
in O
non O
- O
local O
means O
) O
. O
Moreover O
, O
we O
expect O
that O
the O
interpretability O
of O
the O
output O
will O
be O
particularly O
appealing O
for O
interactive Task
and Task
scientific Task
applications Task
such O
as O
medical Task
imaging Task
and O
biological Task
microscopy Task
where O
predicted Task
filters Task
could O
be O
directly O
compared O
to O
physical Method
models Method
of Method
the Method
imaging Method
process Method
. O
section O
: O
Acknowledgement O
This O
project O
is O
supported O
by O
NSF O
grants O
IIS O
- O
1618806 O
, O
IIS O
- O
1253538 O
, O
DBI O
- O
1262547 O
and O
a O
hardware O
donation O
from O
NVIDIA O
. O
bibliography O
: O
References O
Appendix O
In O
the O
supplementary O
material O
, O
we O
first O
show O
more O
visualizations O
to O
understand O
the O
predicted O
filter O
flows O
, O
then O
show O
if O
it O
is O
possible O
to O
refine O
the O
results O
by O
iteratively O
feeding O
deblurred O
image O
to O
the O
same O
model O
for O
the O
task O
of O
non Task
- Task
uniform Task
motion Task
blur Task
removal Task
. O
We O
finally O
present O
more O
qualitative O
results O
for O
all O
the O
three O
tasks O
studied O
in O
this O
paper O
. O
section O
: O
Visualization O
of O
Per O
- O
Pixel O
Loading O
Factors O
As O
a O
supplementary O
visualization O
to O
the O
principal Method
components Method
by O
PCA Method
shown O
in O
the O
main O
paper O
, O
we O
can O
also O
visualize O
the O
per O
- O
pixel O
loading O
factors O
corresponding O
to O
each O
principal Method
component Method
. O
We O
run O
PCA Method
over O
testing O
set O
and O
show O
the O
first O
six O
principal O
components O
and O
the O
corresponding O
per O
- O
pixel O
loading O
factors O
as O
a O
heatmap O
in O
Figure O
[ O
reference O
] O
. O
With O
this O
visualization Method
technique Method
, O
we O
can O
know O
what O
region O
has O
higher O
response O
to O
which O
component O
kernels O
. O
Moreover O
, O
given O
that O
the O
first O
ten O
principal Method
components Method
capture O
filter O
energy O
( O
stated O
in O
the O
main O
paper O
) O
, O
we O
expect O
future O
work O
to O
predict O
compact O
per Method
- Method
pixel Method
filters Method
using O
low Method
- Method
rank Method
technique Method
, O
which O
allows O
for O
incorporating O
long O
- O
range O
pixels O
through O
large O
predictive Method
filters Method
while O
with O
compact O
features O
( O
thus O
memory O
consumption O
is O
reduced O
largely O
) O
. O
section O
: O
Iteratively Task
Removing Task
Motion Task
Blur Task
As O
the O
deblurred O
images O
are O
still O
not O
perfect O
, O
we O
are O
interested O
in O
studying O
if O
we O
can O
improve O
performance O
by O
iteratively O
running O
the O
model O
, O
i.e. O
, O
feeding O
the O
deblurred O
image O
as O
input O
to O
the O
same O
model O
one O
more O
time O
to O
get O
the O
result O
. O
We O
denote O
this O
method O
as O
PFF Method
+ Method
1 Method
. O
Not O
much O
surprisingly O
, O
we O
do O
not O
observe O
further O
improvement O
as O
listed O
in O
Figure O
[ O
reference O
] O
, O
instead O
, O
such O
a O
practice O
even O
hurts O
performance O
slightly O
. O
The O
qualitative O
results O
are O
shown O
in O
Figure O
[ O
reference O
] O
, O
from O
which O
we O
can O
see O
the O
second O
run O
does O
not O
generate O
much O
change O
through O
the O
filter Method
flow Method
maps Method
. O
We O
believe O
the O
reason O
is O
that O
, O
the O
deblurred O
images O
have O
different O
statistics O
from O
the O
original O
blurry O
input O
, O
and O
the O
model O
is O
not O
trained O
with O
such O
deblurred O
images O
. O
Therefore O
, O
it O
suggests O
two O
natural O
directions O
as O
future O
work O
for O
improving O
the O
results O
, O
1 O
) O
training O
explicitly O
with O
recurrent Method
loops Method
with O
multiple O
losses O
to O
improve O
the O
performance O
, O
similar O
to O
, O
or O
2 O
) O
simultaneously O
inserting O
an O
adversarial O
loss O
to O
force O
the O
model O
to O
hallucinate O
details O
for O
realistic O
output O
, O
which O
can O
be O
useful O
in O
practice O
as O
done O
in O
. O
section O
: O
More O
Qualitative O
Results O
In O
Figure O
[ O
reference O
] O
, O
[ O
reference O
] O
and O
[ O
reference O
] O
, O
we O
show O
more O
qualitative O
results O
for O
non Task
- Task
uniform Task
motion Task
blur Task
removal Task
, O
JPEG Task
compression Task
artifact Task
reduction Task
and O
single Task
image Task
super Task
- Task
resolution Task
, O
respectively O
. O
From O
these O
comparisons O
and O
with O
the O
guide O
of O
filter O
flow O
maps O
, O
we O
can O
see O
at O
what O
regions O
our O
PFF Method
pays O
attention O
to O
and O
how O
it O
outperforms O
the O
other O
methods O
. O
