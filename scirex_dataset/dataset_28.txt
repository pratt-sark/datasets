GhostVLAD Method
for O
set O
- O
based O
face Task
recognition Task
section O
: O
Abstract O
. O
The O
objective O
of O
this O
paper O
is O
to O
learn O
a O
compact Method
representation Method
of Method
image Method
sets Method
for O
template O
- O
based O
face Task
recognition Task
. O
We O
make O
the O
following O
contributions O
: O
first O
, O
we O
propose O
a O
network Method
architecture Method
which O
aggregates O
and O
embeds O
the O
face O
descriptors O
produced O
by O
deep Method
convolutional Method
neural Method
networks Method
into O
a O
compact O
fixed Method
- Method
length Method
representation Method
. O
This O
compact Method
representation Method
requires O
minimal O
memory O
storage O
and O
enables O
efficient O
similarity Task
computation Task
. O
Second O
, O
we O
propose O
a O
novel O
GhostVLAD Method
layer O
that O
includes O
ghost O
clusters O
, O
that O
do O
not O
contribute O
to O
the O
aggregation Task
. O
We O
show O
that O
a O
quality O
weighting O
on O
the O
input O
faces O
emerges O
automatically O
such O
that O
informative O
images O
contribute O
more O
than O
those O
with O
low O
quality O
, O
and O
that O
the O
ghost O
clusters O
enhance O
the O
network O
's O
ability O
to O
deal O
with O
poor O
quality O
images O
. O
Third O
, O
we O
explore O
how O
input O
feature O
dimension O
, O
number O
of O
clusters O
and O
different O
training Method
techniques Method
affect O
the O
recognition Task
performance O
. O
Given O
this O
analysis O
, O
we O
train O
a O
network O
that O
far O
exceeds O
the O
state O
- O
of O
- O
the O
- O
art O
on O
the O
IJB Material
- Material
B Material
face Material
recognition Material
dataset Material
. O
This O
is O
currently O
one O
of O
the O
most O
challenging O
public O
benchmarks O
, O
and O
we O
surpass O
the O
state O
- O
of O
- O
the O
- O
art O
on O
both O
the O
identification O
and O
verification Task
protocols O
. O
section O
: O
Introduction O
While O
most O
research O
on O
face Task
recognition Task
has O
focused O
on O
recognition Task
from O
a O
singleimage O
, O
template O
based O
face Task
recognition Task
, O
where O
a O
set O
of O
faces O
of O
the O
same O
subject O
is O
available O
, O
is O
now O
gaining O
attention O
. O
In O
the O
unconstrained Task
scenario Task
considered O
here O
, O
this O
can O
be O
a O
challenging O
task O
as O
face O
images O
may O
have O
various O
poses O
, O
expression O
, O
illumination O
, O
and O
may O
also O
be O
of O
quite O
varying O
quality O
. O
A O
straightforward O
method O
to O
tackle O
multiple O
images O
per O
subject O
is O
to O
store O
per O
- O
image O
descriptors O
extracted O
from O
each O
face O
image O
( O
or O
frame O
in O
a O
video O
) O
, O
and O
compare O
every O
pair O
of O
images O
between O
sets O
at O
query O
time O
[ O
reference O
][ O
reference O
] O
. O
However O
, O
this O
type O
of O
approach O
can O
be O
memory O
- O
consuming O
and O
prohibitively O
slow O
, O
especially O
for O
searching Task
tasks Task
in O
large O
- O
scale O
datasets O
. O
Therefore O
, O
an O
aggregation Method
method Method
that O
can O
produce O
a O
compact O
template Method
representation Method
is O
desired O
. O
Furthermore O
, O
this O
representation O
should O
support O
efficient O
computation Task
of Task
similarity Task
and O
require O
minimal O
memory O
storage O
. O
More O
importantly O
, O
the O
representation O
obtained O
from O
image O
sets O
should O
be O
discriminative O
i.e. O
template O
descriptors O
of O
the O
same O
subject O
should O
be O
close O
to O
each O
other O
in O
the O
descriptor O
space O
, O
whereas O
those O
of O
different O
subjects O
should O
be O
far O
apart O
. O
Although O
common O
aggregation Method
strategies Method
, O
such O
as O
average Method
pooling Method
and O
max Method
- Method
pooling Method
, O
are O
able O
to O
aggregate O
face O
descriptors O
to O
produce O
a O
compact O
template Method
representation Method
[ O
reference O
][ O
reference O
][ O
reference O
] O
and O
currently O
achieves O
the O
state O
- O
of O
- O
the O
- O
art O
results O
[ O
reference O
] O
, O
we O
seek O
a O
better O
solution O
in O
this O
paper O
. O
As O
revealed O
by O
[ O
reference O
] O
, O
image Method
retrieval Method
encoding Method
methods Method
like O
Fisher Method
Vector Method
encoding Method
and O
T Method
- Method
embedding Method
increase O
the O
separation O
between O
descriptors O
extracted O
from O
related O
and O
unrelated O
image O
patches O
. O
We O
therefore O
expect O
a O
similar O
encoding O
to O
be O
beneficial O
for O
face Task
recognition Task
, O
including O
both O
verification Task
and O
identification Task
tasks Task
. O
This O
insight O
inspires O
us O
to O
include O
a O
similar O
encoding O
, O
NetVLAD Method
[ O
reference O
] O
, O
in O
the O
design O
of O
our O
network O
. O
In O
this O
paper O
, O
we O
propose O
a O
convolutional Method
neural Method
network Method
( O
Fig O
. O
1 O
) O
that O
satisfies O
all O
the O
desired O
properties O
mentioned O
above O
: O
it O
can O
take O
any O
number O
of O
input O
faces O
and O
produce O
a O
compact O
fixed Method
- Method
length Method
descriptor Method
to O
represent O
the O
image O
set O
. O
Moreover O
, O
this O
network O
embeds O
face O
descriptors O
such O
that O
the O
resultant O
template O
- O
descriptors O
are O
more O
discriminative O
than O
the O
original O
descriptors O
. O
The O
representation O
is O
efficient O
in O
both O
memory Metric
and Metric
query Metric
speed Metric
aspects Metric
, O
i.e. O
it O
only O
stores O
one O
compact Method
descriptor Method
per O
template O
, O
regardless O
of O
the O
number O
of O
face O
images O
in O
a O
template O
, O
and O
the O
similarity O
between O
two O
templates O
is O
simply O
measured O
as O
the O
scalar O
product O
( O
i.e. O
cosine O
similarity O
) O
of O
two O
template Method
descriptors Method
. O
However O
, O
one O
of O
the O
key O
problems O
in O
unconstrained Task
real Task
- Task
world Task
situations Task
is O
that O
some O
faces O
in O
a O
template O
may O
be O
of O
low O
quality O
- O
for O
example O
, O
low O
resolution O
, O
or O
blurred O
, O
or O
partially O
occluded O
. O
These O
low O
- O
quality O
images O
are O
distractors O
and O
are O
likely O
to O
hurt O
the O
performance O
of O
the O
face Task
recognition Task
system O
if O
given O
equal O
weight O
as O
the O
other O
( O
good O
quality O
) O
faces O
. O
Therefore O
, O
a O
sophisticated O
network O
should O
be O
able O
to O
reduce O
the O
impact O
of O
such O
distracting O
images O
and O
focus O
on O
the O
informative O
ones O
. O
To O
this O
end O
, O
we O
extend O
the O
NetVLAD Method
architecture Method
to O
include O
ghost O
clusters O
. O
These O
are O
clusters O
that O
face O
descriptors O
can O
be O
soft O
assigned O
to O
, O
but O
are O
excluded O
from O
the O
aggregation Task
. O
They O
provide O
a O
mechanism O
for O
the O
network O
to O
handle O
low O
quality O
faces O
, O
by O
mainly O
assigning O
them O
to O
the O
ghost O
clusters O
. O
Interestingly O
, O
although O
we O
do O
not O
explicitly O
learn O
any O
importance O
weightings O
between O
faces O
in O
each O
template O
, O
such O
property O
emerges O
automatically O
from O
our O
network O
. O
Specifically O
, O
low O
quality O
faces O
generally O
contribute O
less O
to O
the O
final O
template Method
representation Method
than O
the O
high O
- O
quality O
ones O
. O
The O
networks O
are O
trained O
in O
an O
end O
- O
to O
- O
end O
fashion O
with O
only O
identity O
- O
level O
labels O
. O
They O
outperform O
state O
- O
of O
- O
the O
- O
art O
methods O
by O
a O
large O
margin O
on O
the O
public Material
IJB Material
- Material
A Material
[ O
reference O
] O
and O
IJB Material
- Material
B Material
[ O
reference O
] O
face Task
recognition Task
benchmarks O
. O
These O
datasets O
are O
currently O
the O
most O
challenging O
in O
the O
community O
, O
and O
we O
evaluate O
on O
these O
in O
this O
paper O
. O
This O
paper O
is O
organized O
as O
following O
: O
Sec O
. O
2 O
reviews O
some O
related O
work O
on O
face Task
recognition Task
based O
on O
image O
sets O
or O
videos O
; O
the O
proposed O
network O
and O
implementation O
details O
are O
introduced O
in O
Sec O
. O
3 O
, O
followed O
by O
experimental O
results O
reported O
in O
Sec O
. O
4 O
. O
Finally O
a O
conclusion O
is O
drawn O
in O
Sec O
. O
5 O
. O
section O
: O
Related O
work O
Early O
face Task
recognition Task
approaches O
which O
make O
use O
of O
sets O
of O
face O
examples O
( O
extracted O
from O
different O
images O
or O
video O
frames O
) O
aim O
to O
represent O
image O
sets O
as O
manifolds O
[ O
reference O
][ O
reference O
][ O
reference O
][ O
reference O
][ O
reference O
][ O
reference O
][ O
reference O
] O
, O
convex O
hulls O
[ O
reference O
] O
, O
Gaussian Method
Mixture Method
Models Method
[ O
reference O
] O
, O
or O
set O
covariance O
matrices O
[ O
reference O
] O
, O
and O
measure O
the O
dissimilarity O
between O
image O
sets O
as O
distance O
between O
these O
spaces O
. O
Later O
methods O
represent O
face O
sets O
more O
efficiently O
using O
a O
single O
fixed Method
- Method
length Method
descriptor Method
. O
For O
example O
, O
[ O
reference O
] O
aggregates O
local O
descriptors O
( O
RootSIFT O
[ O
reference O
] O
) O
extracted O
from O
face O
crops O
using O
Fisher Method
Vector Method
[ O
reference O
] O
( O
FV Method
) Method
encoding Method
to O
obtain O
a O
single O
descriptor O
per O
face Task
track Task
. O
Since O
the O
success O
of O
deep Method
learning Method
in O
image O
- O
based O
face Task
recognition Task
[ O
reference O
][ O
reference O
][ O
reference O
][ O
reference O
][ O
reference O
][ O
reference O
][ O
reference O
] O
, O
simple O
strategies O
for O
face Task
descriptor Task
aggregation Task
prevailed O
, O
such O
as O
average Method
- Method
and Method
max Method
- Method
pooling Method
[ O
reference O
][ O
reference O
] O
. O
However O
, O
none O
of O
these O
strategies O
are O
trained O
end O
- O
to O
- O
end O
for O
face Task
recognition Task
as O
typically O
only O
the O
face O
descriptors O
are O
learnt O
, O
while O
aggregation Task
is O
performed O
post O
hoc O
. O
A O
few O
methods O
go O
beyond O
simple O
pooling Method
by O
computing O
a O
weighted Method
average Method
of Method
face Method
descriptors Method
based O
on O
some O
measure O
of O
per Metric
- Metric
face Metric
example Metric
importance Metric
. O
For O
example O
, O
[ O
reference O
] O
train O
a O
module O
to O
predict O
human O
judgement O
on O
how O
memorable O
a O
face O
is O
, O
and O
use O
this O
memorability O
score O
as O
the O
weight O
. O
In O
[ O
reference O
] O
, O
an O
attention Method
mechanism Method
is O
used O
to O
compute O
face O
example O
weights O
, O
so O
that O
the O
contribution O
of O
low O
quality O
images O
to O
the O
final O
set Method
representation Method
is O
down O
- O
weighted O
. O
However O
, O
these O
methods O
rely O
on O
pretrained O
face O
descriptors O
and O
do O
not O
learn O
them O
jointly O
with O
the O
weighting Method
functions Method
, O
unlike O
our O
method O
where O
the O
entire O
system O
is O
trained O
end O
- O
to O
- O
end O
for O
face Task
recognition Task
. O
Two O
other O
recent O
papers O
are O
quite O
related O
in O
that O
they O
explicitly O
take O
account O
of O
image Metric
quality Metric
: O
[ O
reference O
] O
first O
bins O
face O
images O
of O
similar O
quality O
and O
pose O
before O
aggregation Task
; O
whilst O
[ O
reference O
] O
introduces O
a O
fully O
end O
- O
to O
- O
end Method
trainable Method
method Method
which O
automatically O
learns O
to O
down O
- O
weight O
low O
quality O
images O
. O
As O
will O
be O
seen O
in O
the O
sequel O
, O
we O
achieve O
similar O
functionality O
implicitly O
due O
to O
the O
network Method
architecture Method
, O
and O
also O
exceed O
the O
performance O
of O
both O
these O
methods O
( O
see O
Sec O
. O
4.4 O
) O
. O
As O
an O
interesting O
yet O
different O
method O
which O
can O
also O
filter O
low O
- O
quality O
images O
, O
[ O
reference O
] O
learns O
to O
aggregate O
the O
raw O
face O
images O
and O
then O
computes O
a O
descriptor Method
. O
Our O
aggregation Method
approach Method
is O
inspired O
by O
the O
image Task
retrieval Task
literature Task
on O
aggregating Task
local Task
descriptors Task
[ O
reference O
][ O
reference O
] O
. O
Namely O
, O
Jégou O
and O
Zisserman O
[ O
reference O
] O
find O
that O
, O
compared O
to O
simple O
average Method
- Method
pooling Method
, O
Fisher Method
Vector Method
encoding Method
and O
T Method
- Method
embedding Method
increase O
the O
contrast O
between O
the O
similarity O
scores O
of O
matching O
and O
mismatching O
local O
descriptors O
. O
Motivated O
by O
this O
fact O
, O
we O
make O
use O
of O
a O
trainable Method
aggregation Method
layer Method
, O
NetVLAD Method
[ O
reference O
] O
, O
and O
improve O
it O
for O
the O
face Task
recognition Task
task O
. O
section O
: O
Set O
- O
based O
face Task
recognition Task
We O
aim O
to O
learn O
a O
compact Method
representation Method
of Method
a Method
face Method
. O
Namely O
, O
we O
train O
a O
network O
which O
digests O
a O
set O
of O
example O
face O
images O
of O
a O
person O
, O
and O
produces O
a O
fixedlength Method
template Method
representation Method
useful O
for O
face Task
recognition Task
. O
The O
network O
should O
satisfy O
the O
following O
properties O
: O
. O
. O
. O
. O
. O
. O
Fig O
. O
1 O
: O
Network Method
architecture Method
. O
Input O
images O
in O
each O
template O
are O
first O
passed O
through O
a O
convolutional Method
neural Method
network Method
( O
e.g. O
ResNet Method
- Method
50 Method
or O
SENet Method
- Method
50 Method
with O
an O
additional O
FC Method
layer Method
and O
L2 Method
- Method
normalization Method
) O
to O
produce O
a O
face Method
descriptor Method
per O
image O
. O
The O
descriptors O
are O
aggregated O
into O
a O
single O
fixed O
- O
length O
vector O
using O
the O
GhostVLAD Method
layer O
. O
The O
final O
D Method
- Method
dimensional Method
template Method
descriptor Method
is O
obtained O
by O
reducing O
dimensionality O
using O
a O
fully Method
- Method
connected Method
layer Method
, O
followed O
by O
batch Method
normalization Method
( O
BN Method
) O
and O
L2 Method
- Method
normalization Method
. O
( O
1 O
) O
Take O
any O
number O
of O
images O
as O
input O
, O
and O
output O
a O
fixed Method
- Method
length Method
template Method
descriptor Method
to O
represent O
the O
input O
image O
set O
. O
( O
2 O
) O
The O
output O
template Method
descriptor Method
should O
be O
compact O
( O
i.e. O
low O
- O
dimensional O
) O
in O
order O
to O
require O
little O
memory O
and O
facilitate O
fast O
template O
comparisons O
. O
( O
3 O
) O
The O
output O
template Method
descriptor Method
should O
be O
discriminative O
, O
such O
that O
the O
similarity O
of O
templates O
of O
the O
same O
subject O
is O
much O
larger O
than O
that O
of O
different O
subjects O
. O
We O
propose O
a O
convolutional Method
neural Method
network Method
that O
fulfils O
all O
three O
objectives O
. O
( O
1 O
) O
is O
achieved O
by O
aggregating Method
face Method
descriptors Method
using O
a O
modified O
NetVLAD Method
[ Method
reference Method
] Method
layer Method
, O
GhostVLAD Method
. O
Compact Method
template Method
descriptors Method
( O
2 O
) O
are O
produced O
by O
a O
trained Method
layer Method
which O
performs O
dimensionality Task
reduction Task
. O
Discriminative Method
representations Method
( O
3 O
) O
emerge O
because O
the O
entire O
network O
is O
trained O
end O
- O
to O
- O
end O
for O
face Task
recognition Task
, O
and O
since O
our O
GhostVLAD Method
layer O
is O
able O
to O
down O
- O
weight O
the O
contribution O
of O
lowquality O
images O
, O
which O
is O
important O
for O
good O
performance O
[ O
reference O
][ O
reference O
][ O
reference O
] O
. O
The O
network Method
architecture Method
and O
the O
new O
GhostVLAD Method
layer O
are O
described O
in O
Sec O
. O
3.1 O
and O
Sec O
. O
3.2 O
, O
respectively O
, O
followed O
by O
the O
network Method
training Method
procedure Method
( O
Sec O
. O
3.3 O
) O
and O
implementation O
details O
( O
Sec O
. O
3.4 O
) O
. O
section O
: O
Network Method
architecture Method
As O
shown O
in O
Fig O
. O
1 O
, O
the O
network O
consists O
of O
two O
parts O
: O
feature Method
extraction Method
, O
which O
computes O
a O
face Method
descriptor Method
for O
each O
input O
face O
image O
, O
and O
aggregation Method
, O
which O
aggregates O
all O
face Method
descriptors Method
into O
a O
single O
compact Method
template Method
representation Method
of O
the O
input O
image O
set O
. O
Feature Task
extraction Task
. O
A O
neural Method
network Method
is O
used O
to O
extract O
a O
face Method
descriptor Method
for O
each O
input O
face O
image O
. O
Any O
network O
can O
be O
used O
in O
our O
learning Method
framework Method
, O
but O
in O
this O
paper O
we O
opt O
for O
ResNet O
- O
50 O
[ O
reference O
] O
or O
SENet O
- O
50 O
[ O
reference O
] O
. O
Both O
networks O
are O
cropped O
after O
the O
global Method
average Method
pooling Method
layer Method
, O
and O
an O
extra O
FC Method
layer Method
is O
added O
to O
reduce O
the O
output O
dimension O
to O
D O
F O
. O
We O
typically O
pick O
D O
F O
to O
be O
low O
- O
dimensional O
( O
e.g. O
128 O
or O
256 O
) O
, O
and O
do O
not O
see O
a O
significant O
drop O
in O
face Task
recognition Task
performance O
compared O
to O
using O
the O
original O
2048 Method
- Method
D Method
descriptors Method
. O
Finally O
, O
the O
individual O
face Method
descriptors Method
are O
L2 Method
normalized Method
. O
Aggregation Task
. O
The O
second O
part O
uses O
GhostVLAD Method
( O
Sec O
. O
3.2 O
) O
to O
aggregate O
multiple O
face O
descriptors O
into O
a O
single O
D O
F O
× O
K O
vector O
( O
where O
K O
is O
a O
parameter O
of O
the O
method O
) O
. O
To O
keep O
computational O
and O
memory O
requirements O
low O
, O
dimensionality Task
reduction Task
is O
performed O
via O
an O
FC Method
layer Method
, O
where O
we O
pick O
the O
output O
dimensionality O
D O
to O
be O
128 O
. O
The O
compact O
D Method
- Method
dimensional Method
descriptor Method
is O
then O
passed O
to O
a O
batch Method
- Method
normalization Method
layer Method
[ O
reference O
] O
and O
L2 O
- O
normalized O
to O
form O
the O
final O
template Method
representation Method
x Method
template Method
. O
section O
: O
GhostVLAD Method
: O
NetVLAD Method
with O
ghost Method
clusters Method
The O
key O
component O
of O
the O
aggregation Method
block Method
is O
our O
GhostVLAD Method
trainable Method
aggregation Method
layer Method
, O
which O
given O
N O
D O
F O
- O
dimensional O
face O
descriptors O
computes O
a O
single O
It O
is O
based O
on O
the O
NetVLAD Method
[ Method
reference Method
] Method
layer Method
which O
implements O
an O
encoding O
similar O
to O
VLAD Method
encoding Method
[ O
reference O
] O
, O
while O
being O
differentiable O
and O
thus O
fully O
- O
trainable O
. O
NetVLAD Method
has O
been O
shown O
to O
outperform O
average Method
and Method
max Method
pooling Method
for O
the O
same O
vector O
dimensionality O
, O
which O
makes O
it O
perfectly O
suited O
for O
our O
task O
. O
Here O
we O
provide O
a O
brief O
overview O
of O
NetVLAD Method
( O
for O
full O
details O
please O
refer O
to O
[ O
reference O
] O
) O
, O
followed O
by O
our O
improvement O
, O
GhostVLAD Method
. O
NetVLAD Method
. O
For O
N O
D O
F O
- O
dimensional O
input O
descriptors O
{ O
x O
i O
} O
and O
a O
chosen O
number O
of O
clusters O
K O
, O
NetVLAD Method
pooling Method
produces O
a O
single O
D O
F O
× O
K O
vector O
V O
( O
for O
convenience O
written O
as O
a O
D O
F O
× O
K O
matrix O
) O
according O
to O
the O
following O
equation O
: O
where O
{ O
a O
k O
} O
, O
{ O
b O
k O
} O
and O
{ O
c O
k O
} O
are O
trainable O
parameters O
, O
with O
k O
∈ O
[ O
1 O
, O
2 O
, O
. O
. O
. O
, O
K O
] O
. O
The O
first O
term O
corresponds O
to O
the O
soft O
- O
assignment O
weight O
of O
the O
input O
vector O
x O
i O
for O
cluster O
k O
, O
while O
the O
second O
term O
computes O
the O
residual O
between O
the O
vector O
and O
the O
cluster O
centre O
. O
The O
final O
output O
is O
obtained O
by O
performing O
L2 Method
normalization Method
. O
GhostVLAD Method
. O
We O
extend O
NetVLAD Method
with O
" O
ghost O
" O
clusters O
to O
form O
GhostVLAD Method
, O
as O
shown O
in O
Fig O
. O
2 O
. O
Namely O
, O
we O
add O
further O
G O
" O
ghost O
" O
clusters O
which O
contribute O
to O
the O
soft O
assignments O
in O
the O
same O
manner O
as O
the O
original O
K O
clusters O
, O
but O
residuals O
between O
input O
vectors O
and O
the O
ghost O
cluster O
centres O
are O
ignored O
and O
do O
not O
contribute O
to O
the O
final O
output O
. O
In O
other O
words O
, O
the O
summation O
in O
the O
denominator O
of O
eq O
. O
1 O
instead O
of O
to O
K O
goes O
to O
K O
+ O
G O
, O
while O
the O
output O
is O
still O
D O
F O
× O
K O
dimensional O
; O
this O
means O
{ O
a O
k O
} O
and O
{ O
b O
k O
} O
have O
K O
+ O
G O
elements O
each O
, O
while O
{ O
c O
k O
} O
still O
has O
K. O
Another O
view O
is O
that O
we O
are O
computing O
NetVLAD Method
with O
K O
+ O
G O
clusters O
, O
followed O
by O
removing O
the O
elements O
that O
correspond O
to O
the O
G O
ghost O
clusters O
. O
Note O
that O
GhostVLAD Method
is O
a O
generalization Method
of Method
NetVLAD Method
as O
with O
G O
= O
0 O
the O
two O
are O
equivalent O
. O
As O
with O
NetVLAD Method
, O
GhostVLAD Method
can O
be O
implemented O
efficiently O
using O
For O
each O
input O
descriptor O
, O
NetVLAD Method
performs O
softassignment O
into O
K O
cluster O
centres O
, O
computed O
as O
a O
linear Method
transformation Method
followed O
by O
a O
soft Method
- Method
max Method
. O
It O
then O
, O
for O
each O
cluster O
centre O
, O
aggregates O
all O
residuals O
between O
input O
descriptors O
and O
the O
cluster O
centre O
, O
weighted O
with O
the O
soft O
- O
assignment O
values O
. O
The O
final O
vector O
is O
produced O
as O
a O
concatenation O
of O
the O
per Method
- Method
cluster Method
aggregated Method
residuals Method
; O
for O
more O
details O
see O
eq O
. O
1 O
and O
[ O
reference O
] O
. O
We O
introduce O
G O
" O
ghost O
" O
clusters O
in O
the O
soft Task
- Task
assignment Task
stage Task
, O
where O
the O
" O
ghost O
" O
assignment O
weight O
is O
illustrated O
with O
a O
dotted O
red O
bar O
( O
here O
we O
show O
only O
G O
= O
1 O
ghost O
cluster O
) O
. O
The O
ghost O
assignments O
are O
then O
eliminated O
and O
residual Task
aggregation Task
proceeds O
as O
with O
NetVLAD Method
. O
This O
mechanism O
enables O
the O
network O
to O
assign O
uninformative O
descriptors O
to O
ghost O
clusters O
thus O
decreasing O
their O
soft O
- O
assignment O
weights O
for O
non O
- O
ghost O
clusters O
, O
and O
therefore O
reducing O
their O
contribution O
to O
the O
final O
template Method
representation Method
. O
standard O
convolutional Method
neural Method
network Method
building Method
blocks Method
, O
e.g. O
the O
soft Task
- Task
assignment Task
can O
be O
done O
by O
stacking O
input O
descriptors O
and O
applying O
a O
convolution Method
operation Method
, O
followed O
by O
a O
convolutional Method
soft Method
- Method
max Method
; O
for O
details O
see O
[ O
reference O
] O
. O
The O
intuition O
behind O
the O
incorporation O
of O
ghost O
clusters O
is O
to O
make O
it O
easier O
for O
the O
network O
to O
adjust O
the O
contribution O
of O
each O
face O
example O
to O
the O
template Method
representation Method
by O
assigning O
examples O
to O
be O
ignored O
to O
the O
ghost O
clusters O
. O
For O
example O
, O
in O
an O
ideal O
case O
, O
a O
highly O
blurry O
face O
image O
would O
be O
strongly O
assigned O
to O
a O
ghost O
cluster O
, O
making O
the O
assignment O
weights O
to O
non O
- O
ghost O
clusters O
close O
to O
zero O
, O
thus O
causing O
its O
contribution O
to O
the O
template Method
representation Method
to O
be O
negligible O
; O
in O
Sec O
. O
4.5 O
we O
qualitatively O
validate O
this O
intuition O
. O
However O
, O
note O
that O
we O
do O
not O
explicitly O
force O
low O
- O
quality O
images O
to O
get O
assigned O
to O
ghost O
clusters O
, O
but O
instead O
let O
the O
network O
discover O
the O
optimal O
behaviour O
through O
end Task
- Task
to Task
- Task
end Task
training Task
for O
face Task
recognition Task
. O
section O
: O
Network Method
training Method
In O
this O
section O
we O
describe O
how O
to O
train O
the O
network O
for O
face Task
recognition Task
, O
but O
note O
that O
GhostVLAD Method
is O
a O
general O
layer O
which O
can O
also O
be O
used O
for O
other O
tasks O
. O
Training Metric
loss Metric
. O
Just O
for O
training O
purposes O
, O
we O
append O
the O
network O
with O
a O
fullyconnected Method
" Method
classification Method
" Method
layer Method
of O
size O
D O
×T O
, O
where O
D O
is O
the O
size O
of O
the O
template Method
representation Method
and O
T O
is O
the O
number O
of O
identities O
available O
in O
the O
training O
set O
. O
We O
use O
the O
one Method
- Method
versus Method
- Method
all Method
logistic Method
regression Method
loss Method
as O
empirically O
we O
found O
that O
it O
converges O
faster O
and O
outperforms O
cross Metric
- Metric
entropy Metric
loss Metric
. O
The O
classification Method
layer Method
is O
discarded O
after O
training O
and O
the O
trained Method
network Method
is O
used O
to O
extract O
a O
single O
fixed Method
- Method
length Method
template Method
representation Method
for O
the O
input O
face O
images O
. O
Training O
with O
degraded O
images O
. O
For O
unconstrained O
face Task
recognition Task
, O
it O
is O
important O
to O
be O
able O
to O
handle O
images O
of O
varying O
quality O
that O
typically O
occur O
in O
the O
wild O
. O
The O
motivation O
behind O
our O
network Method
architecture Method
, O
namely O
the O
GhostVLAD Method
layer O
, O
is O
to O
enable O
it O
to O
down O
- O
weight O
the O
influence O
of O
these O
images O
on O
the O
template Method
representation Method
. O
However O
, O
since O
our O
training O
dataset O
only O
contains O
good O
quality O
images O
, O
it O
is O
necessary O
to O
perform O
data Task
augmentation Task
in O
the O
form O
of O
image O
degradation O
, O
such O
as O
blurring O
or O
compression O
( O
see O
Sec O
. O
3.4 O
for O
details O
) O
, O
in O
order O
to O
more O
closely O
match O
the O
varying O
image Metric
quality Metric
encountered O
at O
test O
time O
. O
section O
: O
Implementation O
details O
This O
section O
discusses O
full O
details O
of O
the O
training Method
process Method
, O
including O
training O
data O
, O
data Task
augmentation Task
, O
network Task
initialization Task
, O
etc O
. O
Training O
data O
. O
We O
use O
face O
images O
from O
the O
training O
set O
of O
the O
VGGFace2 O
dataset O
[ O
reference O
] O
to O
train O
the O
network O
. O
It O
consists O
of O
around O
3 O
million O
images O
, O
covering O
8631 O
identities O
. O
For O
each O
identity O
, O
there O
are O
on O
average O
360 O
face O
images O
across O
different O
ages O
and O
poses O
. O
To O
perform O
set Task
- Task
based Task
training Task
, O
we O
form O
image O
sets O
on O
- O
the O
- O
fly O
by O
repeatedly O
sampling O
a O
fixed O
number O
of O
images O
belonging O
to O
the O
same O
identity O
. O
Data Task
augmentation Task
. O
Training O
images O
are O
resized O
such O
that O
the O
smallest O
dimension O
is O
256 O
and O
random O
crops O
of O
size O
224 O
× O
224 O
are O
used O
as O
inputs O
to O
the O
network O
. O
Further O
augmentations O
include O
random Method
horizontal Method
flipping Method
and O
a O
random O
rotation O
of O
no O
greater O
than O
10 O
degrees O
. O
We O
adopt O
four O
methods O
to O
degrade O
images O
for O
training Task
: O
isotropic O
blur O
, O
motion O
blur O
, O
decreased O
resolution O
and O
JPEG Method
compression Method
. O
Each O
degradation Method
method Method
has O
a O
probability O
of O
0.1 O
to O
be O
applied O
to O
a O
training O
image O
, O
where O
, O
to O
prevent O
overdegradation O
, O
a O
maximum O
of O
two O
transformations O
per O
image O
is O
allowed O
. O
Isotropic Task
blur Task
is O
implemented O
using O
a O
Gaussian Method
filter Method
where O
the O
standard O
deviation O
is O
uniformly O
sampled O
between O
6 O
and O
16 O
. O
For O
motion Task
blur Task
, O
the O
angle O
of O
motion O
is O
uniformly O
sampled O
between O
0 O
and O
359 O
degrees O
, O
and O
the O
motion O
length O
is O
fixed O
to O
11 O
. O
Resolution Task
decrease Task
is O
simulated O
by O
downscaling O
the O
image O
by O
a O
factor O
of O
10 O
and O
scaling O
it O
back O
up O
to O
the O
original O
size O
. O
Finally O
, O
we O
add O
JPEG O
compression O
artefacts O
by O
randomly O
compressing O
the O
images O
to O
one O
of O
three O
compression Metric
ratios Metric
: O
0.01 O
, O
0.05 O
and O
0.09 O
. O
Training O
procedure O
. O
The O
network O
can O
be O
trained O
end O
- O
to O
- O
end O
in O
one O
go O
, O
but O
, O
to O
make O
the O
training O
faster O
and O
more O
stable O
, O
we O
divide O
it O
into O
three O
stages O
; O
all O
stages O
only O
use O
the O
VGGFace2 Method
[ O
reference O
] O
dataset O
. O
In O
the O
first O
two O
stages O
, O
parts O
of O
the O
network O
are O
trained O
for O
single Task
- Task
image Task
face Task
classification Task
( O
i.e. O
the O
input O
image O
set O
consists O
of O
a O
single O
image O
) O
, O
and O
image O
degradation O
is O
not O
performed O
. O
Firstly O
, O
the O
feature Method
extractor Method
network Method
is O
pre O
- O
trained O
for O
single Task
- Task
image Task
face Task
classification Task
by O
temporarily O
( O
just O
for O
this O
stage O
) O
appending O
a O
classification Method
FC Method
layer Method
on O
top O
of O
it O
, O
and O
training O
the O
network O
with O
the O
cross Metric
- Metric
entropy Metric
loss Metric
. O
Secondly O
, O
we O
train O
the O
whole O
network O
end O
- O
to O
- O
end O
for O
single Task
- Task
image Task
classification Task
with O
one O
- O
versus O
- O
all O
logistic Method
regression Method
loss Method
, O
but O
exclude O
the O
ghost O
clusters O
from O
GhostVLAD Method
because O
training O
images O
are O
not O
degraded O
in O
this O
stage O
. O
Finally O
, O
we O
add O
ghost O
clusters O
and O
enable O
image O
degradation O
, O
and O
train O
the O
whole O
network O
using O
image O
sets O
with O
one O
- O
versus Method
- Method
all Method
logistic Method
regression Method
loss Method
. O
Parameter Task
initialization Task
. O
The O
non O
- O
ghost O
clusters O
of O
GhostVLAD Method
are O
initialized O
as O
in O
NetVLAD Method
[ O
reference O
] O
by O
clustering O
its O
input O
features O
with O
k Method
- Method
means Method
into O
K O
clusters O
, O
where O
only O
non O
- O
degraded O
images O
are O
used O
. O
The O
G O
ghost O
clusters O
are O
initialized O
similarly O
, O
but O
using O
degraded O
images O
for O
the O
clustering Task
; O
note O
that O
for O
G O
= O
1 O
( O
a O
setting O
we O
often O
use O
) O
k Method
- Method
means Method
simplifies O
to O
computing O
the O
mean O
over O
the O
features O
. O
The O
FC Method
following O
GhostVLAD Method
which O
performs O
dimensionality Task
reduction Task
is O
then O
initialized O
using O
the O
PCA O
transformation O
matrix O
computed O
on O
the O
GhostVLAD Method
output O
features O
. O
Training O
details O
. O
The O
network O
is O
trained O
using O
stochastic Method
gradient Method
descend Method
with O
momentum Method
, O
implemented O
in O
MatConvNet Method
[ O
reference O
] O
. O
The O
mini O
- O
batch O
consists O
of O
84 O
face O
images O
, O
i.e. O
if O
we O
train O
with O
image O
sets O
of O
size O
two O
, O
a O
batch O
contains O
42 O
image O
sets O
, O
one O
per O
identity O
. O
When O
one Method
- Method
versus Method
- Method
all Method
logistic Method
regression Method
loss Method
is O
used O
, O
for O
each O
image O
set O
, O
we O
update O
the O
network O
weights O
based O
on O
the O
positive O
class O
and O
only O
20 O
negative O
classes O
( O
instead O
of O
8631 O
) O
that O
obtain O
the O
highest O
classification Metric
scores Metric
. O
The O
initial O
learning Metric
rate Metric
of O
0.0001 O
is O
used O
for O
all O
parameters O
apart O
from O
GhostVLAD Method
's O
assignment O
parameters O
and O
the O
classification O
FC O
weights O
, O
for O
which O
we O
use O
0.1 O
and O
1 O
, O
respectively O
. O
The O
learning Metric
rates Metric
are O
divided O
by O
10 O
when O
validation Metric
error Metric
stagnates O
, O
while O
weight O
decay O
and O
momentum O
are O
fixed O
to O
0.0005 O
and O
0.9 O
, O
respectively O
. O
section O
: O
Experiments O
In O
this O
section O
, O
we O
describe O
the O
experimental O
setup O
, O
investigate O
the O
impact O
of O
our O
design O
choices O
, O
and O
compare O
results O
with O
the O
state O
- O
of O
- O
the O
- O
art O
. O
section O
: O
Benchmark O
datasets O
and O
evaluation O
protocol O
Standard O
and O
most O
challenging O
public O
face Task
recognition Task
datasets O
IJB Material
- Material
A Material
[ O
reference O
] O
and O
IJB Material
- Material
B Material
[ O
reference O
] O
are O
used O
for O
evaluation O
. O
In O
contrast O
to O
single O
- O
image O
based O
face O
datasets O
such O
as O
[ O
reference O
][ O
reference O
][ O
reference O
][ O
reference O
] O
, O
IJB Material
- Material
A Material
and O
IJB Material
- Material
B Material
are O
intended O
for O
template O
- O
based O
face Task
recognition Task
, O
which O
is O
exactly O
the O
task O
we O
consider O
in O
this O
work O
. O
The O
IJB Material
- Material
A Material
dataset Material
contains O
5 O
, O
712 O
images O
and O
2 O
, O
085 O
videos O
, O
covering O
500 O
subjects O
; O
thus O
the O
average O
number O
of O
images O
and O
videos O
per O
subject O
are O
11.4 O
and O
4.2 O
videos O
, O
respectively O
. O
The O
IJB Material
- Material
B Material
dataset Material
is O
an O
extension O
of O
IJB Material
- Material
A Material
with O
a O
total O
of O
11 O
, O
754 O
images O
and O
7 O
, O
011 O
videos O
from O
1 O
, O
845 O
subjects O
, O
as O
well O
as O
10 O
, O
044 O
non O
- O
face O
images O
. O
There O
is O
no O
overlap O
between O
subjects O
in O
VGGFace2 O
, O
which O
we O
use O
for O
training O
, O
and O
the O
test O
datasets O
. O
Faces O
are O
detected O
from O
images O
and O
all O
video O
frames O
using O
MTCNN Method
[ O
reference O
] O
, O
the O
face O
crops O
are O
then O
resized O
such O
that O
the O
smallest O
dimension O
is O
224 O
and O
the O
central O
224 O
× O
224 O
crop O
is O
used O
as O
the O
face O
example O
. O
Evaluation Metric
protocol Metric
. O
We O
follow O
the O
standard O
benchmark O
procedure O
for O
IJB Material
- Material
A Material
and O
IJB Material
- Material
B Material
, O
and O
evaluate O
on O
" O
1:1 O
face O
verification Task
" O
and O
" O
1:N Task
face Task
identification Task
" O
. O
The O
goal O
of O
1:1 O
verification Task
is O
to O
make O
a O
decision O
whether O
two O
templates O
belong O
to O
the O
same O
person O
, O
done O
by O
thresholding O
the O
similarity O
between O
the O
templates O
. O
Verification Metric
performance Metric
is O
assessed O
via O
the O
receiver Metric
operating Metric
characteristic Metric
( O
ROC Metric
) Metric
curve Metric
, O
i.e. O
by O
measuring O
the O
trade O
- O
off O
between O
the O
true Metric
accept Metric
rates Metric
( O
TAR Metric
) O
vs O
false Metric
accept Metric
rates Metric
( O
FAR Metric
) O
. O
For O
1:N Task
identification Task
, O
templates O
from O
the O
probe O
set O
are O
used O
to O
rank O
all O
templates O
in O
a O
given O
gallery O
. O
The O
performance O
is O
measured O
using O
the O
true Metric
positive Metric
identification Metric
rate Metric
( Metric
TPIR Metric
) O
vs O
false Metric
positive Metric
identification Metric
rate Metric
( O
FPIR Metric
) O
( O
i.e. O
the O
decision Metric
error Metric
trade Metric
- Metric
off Metric
( Metric
DET Metric
) Metric
curve Metric
) O
and O
vs O
Rank Metric
- Metric
N Metric
( O
i.e. O
the O
cumulative Metric
match Metric
characteristic Metric
( Metric
CMC Metric
) Metric
curve Metric
) O
. O
Evaluation Metric
protocols Metric
are O
the O
same O
for O
both O
benchmark O
datasets O
, O
apart O
from O
the O
fact O
that O
IJB Material
- Material
A Material
defines O
10 O
test O
splits O
, O
while O
IJB Material
- Material
B Material
only O
has O
one O
split O
for O
verification Task
and O
two O
galleries O
for O
identification Task
. O
For O
IJB Material
- Material
A Material
and O
for O
IJB Material
- Material
B Material
identification Material
, O
we O
report O
, O
as O
per O
standard O
, O
the O
mean O
and O
standard O
deviation O
of O
the O
performance Metric
measures Metric
. O
section O
: O
Networks O
, O
deployment O
and O
baselines O
Our O
networks O
. O
As O
explained O
earlier O
in O
Sec O
. O
3.1 O
, O
we O
use O
two O
different O
architectures O
as O
backbone Method
feature Method
extractors Method
: O
ResNet Method
- Method
50 Method
[ O
reference O
] O
and O
SENet O
- O
50 O
[ O
reference O
] O
. O
They O
are O
cropped O
after O
global Method
average Method
- Method
pooling Method
which O
produces O
a O
D O
F O
= O
2048 O
dimensional Method
face Method
descriptor Method
, O
while O
we O
also O
experiment O
with O
reducing O
the O
dimensionality O
via O
an O
additional O
FC Method
, O
down O
to O
D O
F O
= O
256 O
or O
D O
F O
= O
128 O
. O
To O
disambiguate O
various O
network O
configurations O
, O
we O
name O
the O
networks O
as O
Ext Method
- Method
GV Method
- Method
S Method
(- Method
gG Method
) O
, O
where O
Ext Method
is O
the O
feature Method
extractor Method
network Method
( O
Res O
for O
ResNet O
- O
50 O
or O
SE O
for O
SENet O
- O
50 O
) O
, O
S O
is O
the O
size O
of O
image O
sets O
used O
during O
training O
, O
and O
G O
is O
the O
number O
of O
ghost O
clusters O
( O
if O
zero O
, O
the O
suffix O
is O
dropped O
) O
. O
For O
example O
, O
SE Method
- Method
GV Method
- Method
3 Method
- O
g2 O
denotes O
a O
network O
which O
uses O
the O
SENet Method
- Method
50 Method
as O
the O
feature Method
extractor Method
, O
training O
image O
sets O
of O
size O
3 O
, O
and O
2 O
ghost O
clusters O
. O
Network Task
deployment Task
. O
In O
the O
IJB Material
- Material
A Material
and O
IJB Material
- Material
B Material
datasets Material
, O
there O
are O
images O
and O
videos O
available O
for O
each O
subject O
. O
Here O
we O
follow O
the O
established O
approach O
of O
[ O
reference O
][ O
reference O
] O
to O
balance O
the O
contributions O
of O
face O
examples O
from O
different O
sources O
, O
as O
otherwise O
a O
single O
very O
long O
video O
could O
completely O
dominate O
the O
representation O
. O
In O
more O
detail O
, O
face O
examples O
are O
extracted O
from O
all O
video O
frames O
, O
and O
their O
additive O
contributions O
to O
the O
GhostVLAD Method
representation O
are O
down O
- O
weighed O
by O
the O
number O
of O
frames O
in O
the O
video O
. O
The O
similarity O
between O
two O
templates O
is O
measured O
as O
the O
scalar O
product O
between O
the O
template Method
representations Method
; O
recall O
that O
they O
have O
unit O
norm O
( O
Fig O
. O
1 O
) O
. O
Baselines O
. O
Our O
network O
is O
compared O
with O
several O
average Method
- Method
pooling Method
baselines Method
. O
The O
baseline O
architecture O
consists O
of O
a O
feature Method
extractor Method
network Method
which O
produces O
a O
face Method
descriptor Method
for O
each O
input O
example O
, O
and O
the O
template Method
representation Method
is O
performed O
by O
average Method
- Method
pooling Method
the Method
face Method
descriptors Method
( O
with O
source Method
balancing Method
) O
, O
followed O
by O
L2 Method
normalization Method
. O
The O
same O
feature Method
extractor Method
networks Method
are O
used O
as O
for O
our O
method O
, O
ResNet O
- O
50 O
or O
SENet O
- O
50 O
, O
abbreviated O
as O
Res O
and O
SE O
, O
respectively O
, O
with O
an O
optionally O
added O
FC Method
layer Method
to O
perform O
dimensionality Task
reduction Task
down O
to O
128 O
- O
D O
or O
256 O
- O
D. O
These O
networks O
are O
trained O
for O
single Task
- Task
image Task
face Task
classification Task
, O
which O
is O
equivalent O
to O
stage O
1 O
of O
our O
training O
procedure O
from O
Sec O
. O
3.4 O
, O
and O
also O
corresponds O
to O
the O
current O
state O
- O
of O
- O
the O
- O
art O
approach O
[ O
reference O
] O
( O
albeit O
with O
more O
training O
data O
- O
see O
Sec O
. O
4.4 O
for O
details O
and O
comparisons O
) O
. O
No O
image O
degradation O
is O
performed O
as O
it O
decreases O
performance O
when O
combined O
with O
single Method
- Method
image Method
classification Method
training Method
. O
In O
addition O
, O
we O
train O
the O
baseline Method
architecture Method
SENet Method
- Method
50 Method
with O
average Method
- Method
pooling Method
using O
our O
training O
procedure O
( O
Sec O
. O
3.3 O
) O
, O
i.e. O
with O
image O
sets O
of O
size O
2 O
and O
degraded O
images O
, O
and O
refer O
to O
it O
as O
SE Method
- Method
2 Method
. O
section O
: O
Ablation Task
studies Task
on O
IJB Material
- Material
B Material
Here O
we O
evaluate O
various O
design O
choices O
of O
our O
architecture O
and O
compare O
it O
to O
baselines O
on O
the O
IJB Material
- Material
B Material
dataset Material
, O
as O
it O
is O
larger O
and O
more O
challenging O
than O
IJB Material
- Material
A Material
; O
results O
on O
verification Task
and O
identification Task
are O
shown O
in O
Tables O
1 O
and O
Table O
2 O
, O
respectively O
. O
Feature Method
extractor Method
and O
dimensionality Task
reduction Task
. O
Comparing O
rows O
1 O
vs O
2 O
of O
the O
two O
tables O
shows O
that O
reducing O
the O
dimensionality O
of O
the O
face O
features O
from O
2048 O
- O
D O
to O
128 O
- O
D O
does O
not O
affect O
the O
performance O
much O
, O
and O
in O
fact O
sometimes O
improves O
it O
due O
to O
added O
parameters O
in O
the O
form O
of O
the O
dimensionality Method
reduction Method
FC Method
. O
As O
the O
feature Method
extractor Method
backbone Method
, O
SENet Method
- Method
50 Method
consistently O
beats O
ResNet Method
- Method
50 Method
, O
as O
summarized O
in O
rows O
2 O
vs O
3 O
. O
Training O
for O
set O
- O
based O
face Task
recognition Task
. O
The O
currently O
adopted O
set O
- O
based O
face Task
recognition Task
approach O
of O
training O
with O
single O
- O
image O
examples O
and O
performing O
aggregation O
post O
hoc O
( O
SE O
, O
row O
4 O
) O
is O
clearly O
inferior O
to O
our O
training Method
procedure Method
which O
is O
aware O
of O
image O
sets O
( O
SE O
- O
2 O
, O
row O
5 O
) O
. O
Learnt O
GhostVLAD Method
aggregation O
. O
Using O
the O
GhostVLAD Method
aggregation O
layer O
( O
with O
G O
= O
0 O
i.e. O
equivalent O
to O
NetVLAD Method
) O
together O
with O
our O
set Method
- Method
based Method
training Method
framework Method
strongly O
outperforms O
the O
standard O
average Method
- Method
pooling Method
approach Method
, O
regardless O
of O
whether O
training Task
is O
done O
with O
non O
- O
degraded O
images O
( O
SE O
- O
GV O
- O
2 O
, O
row O
8 O
vs O
SE O
, O
rows O
3 O
and O
4 O
) O
, O
degraded O
images O
( O
SE O
- O
GV O
- O
2 O
, O
row O
9 O
vs O
SE O
- O
2 O
, O
row O
5 O
) O
, O
or O
if O
a O
different O
feature Method
extractor Method
architecture Method
( O
ResNet Method
- Method
50 Method
) O
is O
used O
( O
Res O
- O
GV O
- O
2 O
, O
row O
6 O
vs O
Res O
, O
row O
2 O
) O
. O
Using O
256 O
- O
D O
vs O
128 O
- O
D O
face O
descriptors O
as O
inputs O
to O
GhostVLAD Method
, O
while O
keeping O
the O
same O
dimensionality O
of O
the O
final O
template Method
representation Method
( O
128 O
- O
D O
) O
, O
achieves O
better O
results O
( O
rows O
9 O
vs O
7 O
) O
, O
so O
we O
use O
256 O
- O
D O
in O
all O
latter O
experiments O
. O
Training O
with O
degraded O
images O
. O
When O
using O
our O
set Method
- Method
based Method
training Method
procedure Method
, O
training O
with O
degraded O
images O
brings O
a O
consistent O
boost O
, O
as O
shown O
in O
rows O
9 O
vs O
8 O
, O
since O
it O
better O
matches O
the O
test O
- O
time O
scenario O
which O
contains O
images O
of O
varying O
quality O
. O
Number O
of O
clusters O
K. O
GhostVLAD Method
( O
and O
NetVLAD Method
) O
have O
a O
hyperparameter O
K O
- O
the O
number O
of O
non O
- O
ghost O
clusters O
- O
which O
we O
vary O
between O
4 O
and O
16 O
( O
rows O
9 O
to O
11 O
) O
to O
study O
its O
effect O
on O
face Task
recognition Task
performance O
. O
It O
is O
expected O
that O
K O
should O
n't O
be O
too O
small O
so O
that O
underfitting O
is O
avoided O
( O
e.g. O
K O
= O
1 O
is O
similar O
to O
average Method
- Method
pooling Method
) O
nor O
too O
large O
in O
order O
to O
prevent O
over O
- O
quantization O
and O
overfitting O
. O
As O
in O
traditional O
image Task
retrieval Task
[ O
reference O
] O
, O
we O
find O
that O
a O
wide O
range O
of O
K O
achieves O
good O
performance O
, O
with O
K O
= O
8 O
being O
the O
best O
. O
Ghost O
clusters O
. O
Introducing O
a O
single O
ghost O
cluster O
( O
G O
= O
1 O
) O
brings O
significant O
improvement O
over O
the O
vanilla Method
NetVLAD Method
, O
as O
shown O
by O
comparing O
SE Method
- Method
GV Method
- Method
3 Method
- O
g1 O
vs O
SE Method
- Method
GV Method
- Method
3 Method
( O
rows O
14 O
vs O
12 O
) O
and O
SE Method
- Method
GV Method
- Method
4 Method
- Method
g1 Method
vs O
SE O
- O
GV O
- O
4 O
( O
rows O
15 O
vs O
13 O
) O
. O
Using O
one O
ghost O
cluster O
is O
sufficient O
as O
increasing O
the O
number O
of O
ghost O
clusters O
to O
two O
does O
not O
result O
in O
significant O
differences O
( O
row O
16 O
vs O
row O
14 O
) O
. O
Ghost O
clusters O
enable O
the O
system O
to O
automatically O
down O
- O
weight O
the O
contribution O
of O
low O
quality O
images O
, O
as O
will O
be O
shown O
in O
Sec O
. O
4.5 O
, O
which O
improves O
the O
template Method
representations Method
and O
benefits O
face Task
recognition Task
. O
Set O
size O
used O
during O
training O
. O
To O
perform O
set Method
- Method
based Method
training Method
, O
as O
described O
in O
Sec O
. O
3.4 O
, O
image O
sets O
are O
created O
by O
sampling O
a O
fixed O
number O
of O
faces O
for O
a O
subject O
; O
the O
number O
of O
sampled O
faces O
is O
another O
parameter O
of O
the O
method O
. O
Increasing O
the O
set O
size O
from O
2 O
to O
3 O
consistently O
improves O
results O
( O
rows O
9 O
vs O
12 O
) O
, O
while O
there O
is O
no O
clear O
winner O
between O
using O
3 O
or O
4 O
face O
examples O
( O
worse O
for O
G O
= O
0 O
, O
rows O
12 O
vs O
13 O
, O
better O
for O
G O
= O
1 O
, O
rows O
15 O
vs O
14 O
) O
. O
Output O
dimensionality O
. O
Comparisons O
are O
also O
made O
between O
networks O
with O
128 O
- O
D O
output O
features O
and O
those O
with O
256 O
- O
D O
( O
i.e. O
row O
13 O
vs O
17 O
and O
row O
15 O
vs O
18 O
) O
, O
and O
we O
can O
see O
that O
networks O
with O
128 O
- O
D O
output O
achieve O
better O
performance O
while O
being O
more O
memory O
- O
efficient O
. O
section O
: O
Comparison O
with O
state O
- O
of O
- O
the O
- O
art O
In O
this O
section O
, O
our O
best O
networks O
, O
SE Method
- Method
GV Method
- Method
3 Method
and O
SE Method
- Method
GV Method
- Method
4 Method
- Method
g1 Method
, O
are O
compared O
against O
the O
state O
- O
of O
- O
the O
- O
art O
on O
the O
IJB Material
- Material
A Material
and O
IJB Material
- Material
B Material
datasets Material
. O
The O
currently O
best O
performing O
method O
[ O
reference O
] O
is O
the O
same O
as O
our O
SE Method
baseline Method
( O
i.e. O
average Method
- Method
pooling Method
of Method
SENet Method
- Method
50 Method
features Method
trained O
for O
single Task
- Task
image Task
classification Task
) O
but O
trained O
on O
a O
much O
larger O
training O
set O
, O
MS O
- O
Celeb O
- O
1 O
M O
dataset O
[ O
reference O
] O
, O
and O
then O
fine O
- O
tuned O
on O
VGGFace2 Method
. O
From O
Tables O
3 O
and O
4 O
, O
and O
Figure O
3 O
, O
it O
is O
clear O
our O
GhostVLAD Method
network O
( O
SE Method
- Method
GV Method
- Method
4 Method
- Method
g1 Method
) O
convincingly O
outperforms O
previous O
methods O
and O
sets O
the O
new O
state O
- O
ofthe O
- O
art O
for O
both O
identification Task
and O
verification Task
on O
both O
IJB Material
- Material
A Material
and O
IJB Material
- Material
B Material
datasets Material
. O
In O
particular O
, O
it O
surpasses O
[ O
reference O
] O
marginally O
on O
the O
IJB O
- O
A O
verification Task
task O
, O
despite O
the O
fact O
that O
[ O
reference O
] O
uses O
a O
deeper O
ResNet Method
and O
performs O
an O
exhaustive O
scoring O
using O
each O
face O
image O
in O
the O
templates O
. O
The O
only O
points O
for O
which O
the O
GhostVLAD Method
network O
does O
n't O
beat O
the O
state O
- O
of O
- O
the O
- O
art O
, O
though O
it O
is O
on O
par O
with O
it O
, O
is O
in O
TPIR Metric
at O
Rank O
- O
1 O
to O
Rank O
- O
10 O
for O
identification Task
on O
IJB Material
- Material
A Material
; O
but O
this O
is O
because O
IJB Material
- Material
A Material
is O
not O
challenging O
enough O
and O
the O
TPIR Metric
values O
have O
saturated O
to O
a O
99 O
% O
mark O
. O
For O
the O
same O
measures O
on O
the O
more O
challenging O
IJB Material
- Material
B Material
benchmark Material
, O
our O
network O
achieves O
the O
best O
TAR Metric
at O
FAR=1E Metric
− O
5 O
and O
FAR=1E Metric
− O
4 O
, O
and O
is O
only O
lower O
than O
a O
concurrent O
work O
[ O
reference O
] O
at O
FAR=1E Metric
− O
3 O
and O
FAR=1E Metric
− O
2 O
. O
Furthermore O
, O
our O
networks O
produce O
much O
smaller O
template O
descriptors O
than O
the O
previous O
stateof O
- O
the O
- O
art O
networks O
( O
128 O
- O
D O
vs O
2048 O
- O
D O
) O
, O
making O
them O
more O
useful O
in O
real O
- O
world O
[ O
reference O
] O
( O
priv1 O
) O
and O
[ O
reference O
] O
( O
priv2 O
) O
. O
' O
512 O
- O
pi O
' O
means O
that O
a O
512 Method
- Method
D Method
descriptor Method
is O
used O
per O
image O
. O
' O
* O
' O
denotes O
the O
value O
given O
by O
the O
author O
. O
Our O
best O
network O
, O
SE Method
- Method
GV Method
- Method
4 Method
- Method
g1 Method
, O
sets O
the O
state O
- O
of O
- O
the O
- O
art O
by O
a O
significant O
margin O
on O
both O
datasets O
( O
except O
for O
concurrent O
work O
[ O
reference O
] O
) O
. O
applications O
due O
to O
smaller O
memory O
requirements O
and O
faster O
template O
comparisons O
. O
The O
results O
are O
especially O
impressive O
as O
we O
only O
train O
using O
VGGFace2 Method
[ O
reference O
] O
and O
beat Method
methods Method
which O
train O
with O
much O
more O
data O
, O
such O
as O
[ O
reference O
] O
which O
combine O
VGGFace2 Method
and O
MS Method
- O
Celeb O
- O
1 O
M O
[ O
reference O
] O
, O
e.g. O
TAR Metric
at O
FAR=1E Metric
− O
5 O
of O
0.762 O
vs O
0.705 O
for O
verification Task
on O
IJB Material
- Material
B Material
, O
and O
TPIR Metric
at O
FPIR=0.01 Metric
of O
0.776 O
vs O
0.743 O
for O
identification Task
on O
IJB Material
- Material
B. Material
When O
considering O
only O
methods O
trained O
on O
the O
same O
data O
( O
VGGFace2 Method
) O
, O
our O
improvement O
over O
the O
state O
- O
of O
- O
the O
- O
art O
is O
even O
larger O
: O
TAR Metric
at O
FAR=1E Metric
−5 O
of O
0.762 O
vs O
0.671 O
for O
verification Task
on O
IJB Material
- Material
B Material
, O
and O
TPIR Metric
at O
FPIR=0.01 Metric
of O
0.776 O
vs O
0.706 O
for O
verification Task
on O
IJB Material
- Material
B. Material
section O
: O
Analysis Task
of Task
ghost Task
clusters Task
Addition O
of O
ghost O
clusters O
was O
motivated O
by O
the O
intuition O
that O
it O
enables O
our O
network O
to O
learn O
to O
ignore O
uninformative O
low O
- O
quality O
images O
by O
assigning O
them O
to O
the O
discarded O
ghost O
clusters O
. O
Here O
we O
evaluate O
this O
hypothesis O
qualitatively O
. O
Recall O
that O
GhostVLAD Method
computes O
a O
template Method
representation Method
by O
aggregating O
residual O
vectors O
of O
input O
descriptors O
, O
where O
a O
residual O
vector O
is O
a O
concatenation O
of O
per O
non O
- O
ghost O
cluster O
residuals O
weighted O
by O
their O
non O
- O
ghost O
assignment O
weights O
( O
Sec O
. O
3.2 O
) O
. O
Therefore O
, O
the O
contribution O
of O
a O
specific O
example O
image O
towards O
the O
template Method
representation Method
can O
be O
measured O
as O
the O
norm O
of O
the O
residual O
. O
Figure O
4 O
show O
that O
our O
intuition O
is O
correct O
- O
the O
network O
automatically O
learns O
to O
dramatically O
down O
- O
weight O
blurry O
and O
low O
- O
resolution O
images O
, O
thus O
improving O
the O
signal Metric
- Metric
to Metric
- Metric
noise Metric
ratio Metric
. O
Note O
that O
this O
behaviour O
emerges O
completely O
automatically O
without O
ever O
explicitly O
teaching O
the O
network O
to O
down O
- O
weight O
low O
- O
quality O
images O
. O
section O
: O
Conclusions O
We O
introduced O
a O
neural Method
network Method
architecture Method
and O
training Method
procedure Method
for O
learning O
compact Task
representations Task
of Task
image Task
sets Task
for O
template O
- O
based O
face Task
recognition Task
. O
Due O
to O
the O
novel O
GhostVLAD Method
layer O
, O
the O
network O
is O
able O
to O
automatically O
learn O
to O
weight O
face O
descriptors O
depending O
on O
their O
information O
content O
. O
Our O
template Method
representations Method
outperform O
the O
state O
- O
of O
- O
the O
- O
art O
on O
the O
challenging O
IJB Material
- Material
A Material
and O
IJB Material
- Material
B Material
benchmarks O
by O
a O
large O
margin O
. O
The O
network Method
architecture Method
proposed O
here O
could O
also O
be O
applied O
to O
other O
imageset Task
tasks Task
such O
as O
person Task
re Task
- Task
identification Task
, O
and O
set Task
- Task
based Task
retrieval Task
. O
More O
generally O
, O
the O
idea O
of O
having O
a O
' O
null O
' O
vector O
available O
for O
assignments O
could O
have O
applicability O
in O
many O
situations O
where O
it O
is O
advantageous O
to O
have O
a O
mechanism O
to O
remove O
noisy O
or O
corrupted O
data O
. O
section O
: O
section O
: O
Acknowledgements O
We O
thank O
Weidi O
Xie O
for O
his O
useful O
advice O
, O
and O
we O
thank O
Li O
Shen O
for O
providing O
pre O
- O
trained O
networks O
. O
This O
work O
was O
funded O
by O
an O
EPSRC O
studentship O
and O
EPSRC O
Programme O
Grant O
Seebibyte O
EP O
/ O
M013774 O
/ O
1 O
. O
section O
: O
Bibliography O
section O
: O
