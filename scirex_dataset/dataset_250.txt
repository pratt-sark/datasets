document O
: O
Training O
with O
Exploration Task
Improves O
a O
Greedy Method
Stack Method
LSTM Method
Parser Method
We O
adapt O
the O
greedy Method
stack Method
LSTM Method
dependency Method
parser Method
of O
lstmacl15 O
to O
support O
a O
training Task
- Task
with Task
- Task
exploration Task
procedure Task
using O
dynamic O
oracles O
instead O
of O
assuming O
an O
error O
- O
free O
action O
history O
. O
This O
form O
of O
training O
, O
which O
accounts O
for O
model Task
predictions Task
at O
training O
time O
, O
improves O
parsing Metric
accuracies Metric
. O
We O
discuss O
some O
modifications O
needed O
in O
order O
to O
get O
training O
with O
exploration Task
to O
work O
well O
for O
a O
probabilistic Method
neural Method
network Method
dependency Method
parser Method
. O
section O
: O
Introduction O
Natural O
language O
parsing Task
can O
be O
formulated O
as O
a O
series O
of O
decisions O
that O
read O
words O
in O
sequence O
and O
incrementally O
combine O
them O
to O
form O
syntactic O
structures O
; O
this O
formalization O
is O
known O
as O
transition O
- O
based O
parsing Task
, O
and O
is O
often O
coupled O
with O
a O
greedy Method
search Method
procedure Method
. O
The O
literature O
on O
transition O
- O
based O
parsing Task
is O
vast O
, O
but O
all O
works O
share O
in O
common O
a O
classification Method
component Method
that O
takes O
into O
account O
features O
of O
the O
current O
parser O
state O
and O
predicts O
the O
next O
action O
to O
take O
conditioned O
on O
the O
state O
. O
The O
state O
is O
of O
unbounded O
size O
. O
Dyer O
et O
al O
. O
lstmacl15 Method
presented O
a O
parser Method
in O
which O
the O
parser O
’s O
unbounded O
state O
is O
embedded O
in O
a O
fixed O
- O
dimensional O
continuous O
space O
using O
recurrent Method
neural Method
networks Method
. O
Coupled O
with O
a O
recursive Method
tree Method
composition Method
function Method
, O
the O
feature Method
representation Method
is O
able O
to O
capture O
information O
from O
the O
entirety O
of O
the O
state O
, O
without O
resorting O
to O
locality O
assumptions O
that O
were O
common O
in O
most O
other O
transition Method
- Method
based Method
parsers Method
. O
The O
use O
of O
a O
novel O
stack Method
LSTM Method
data Method
structure Method
allows O
the O
parser Method
to O
maintain O
a O
constant O
time O
per O
- O
state O
update O
, O
and O
retain O
an O
overall O
linear O
parsing Task
time O
. O
The O
Dyer O
et O
al O
. O
parser Method
was O
trained O
to O
maximize O
the O
likelihood O
of O
gold O
- O
standard O
transition O
sequences O
, O
given O
words O
. O
At O
test O
time O
, O
the O
parser Method
makes O
greedy O
decisions O
according O
to O
the O
learned O
model O
. O
Although O
this O
setup O
obtains O
very O
good O
performance O
, O
the O
training O
and O
testing O
conditions O
are O
mismatched O
in O
the O
following O
way O
: O
at O
training O
time O
the O
historical O
context O
of O
an O
action O
is O
always O
derived O
from O
the O
gold O
standard O
( O
i.e. O
, O
perfectly O
correct O
past O
actions O
) O
, O
but O
at O
test O
time O
, O
it O
will O
be O
a O
model Method
prediction Method
. O
In O
this O
work O
, O
we O
adapt O
the O
training O
criterion O
so O
as O
to O
explore O
parser O
states O
drawn O
not O
only O
from O
the O
training O
data O
, O
but O
also O
from O
the O
model O
as O
it O
is O
being O
learned O
. O
To O
do O
so O
, O
we O
use O
the O
method O
of O
Goldberg O
and O
Nivre O
goldberg12dynamic O
, O
goldberg2013training O
to O
dynamically O
chose O
an O
optimal O
( O
relative O
to O
the O
final O
attachment Metric
accuracy Metric
) O
action O
given O
an O
imperfect O
history O
. O
By O
interpolating O
between O
algorithm O
states O
sampled O
from O
the O
model O
and O
those O
sampled O
from O
the O
training O
data O
, O
more O
robust O
predictions O
at O
test O
time O
can O
be O
made O
. O
We O
show O
that O
the O
technique O
can O
be O
used O
to O
improve O
the O
strong O
parser O
of O
Dyer O
et O
al O
. O
section O
: O
Parsing Method
Model Method
and O
Parameter Method
Learning Method
Our O
departure O
point O
is O
the O
parsing Task
model O
described O
by O
lstmacl15 O
. O
We O
do O
not O
describe O
the O
model O
in O
detail O
, O
and O
refer O
the O
reader O
to O
the O
original O
work O
. O
At O
each O
stage O
of O
the O
parsing Task
process O
, O
the O
parser O
state O
is O
encoded O
into O
a O
vector O
, O
which O
is O
used O
to O
compute O
the O
probability O
of O
the O
parser O
action O
at O
time O
as O
: O
where O
is O
a O
column O
vector O
representing O
the O
( O
output O
) O
embedding O
of O
the O
parser O
action O
, O
and O
is O
a O
bias O
term O
for O
action O
. O
The O
set O
represents O
the O
valid O
transition O
actions O
that O
may O
be O
taken O
in O
the O
current O
state O
. O
Since O
encodes O
information O
about O
all O
previous O
decisions O
made O
by O
the O
parser Method
, O
the O
chain Method
rule Method
gives O
the O
probability O
of O
any O
valid O
sequence O
of O
parse O
transitions O
conditional O
on O
the O
input O
: O
The O
parser Method
is O
trained O
to O
maximize O
the O
conditional O
probability O
of O
taking O
a O
“ O
correct O
” O
action O
at O
each O
parsing Task
state O
. O
The O
definition O
of O
what O
constitutes O
a O
“ O
correct O
” O
action O
is O
the O
major O
difference O
between O
a O
static O
oracle O
as O
used O
by O
lstmacl15 O
and O
the O
dynamic Method
oracle Method
explored O
here O
. O
Regardless O
of O
the O
oracle O
, O
our O
training Method
implementation Method
constructs O
a O
computation O
graph O
( O
nodes O
that O
represent O
values O
, O
linked O
by O
directed O
edges O
from O
each O
function O
’s O
inputs O
to O
its O
outputs O
) O
for O
the O
negative O
log O
probability O
for O
the O
oracle O
transition O
sequence O
as O
a O
function O
of O
the O
current O
model O
parameters O
and O
uses O
forward Method
- Method
and O
backpropagation Method
to O
obtain O
the O
gradients O
respect O
to O
the O
model O
parameters O
. O
subsection O
: O
Training O
with O
Static O
Oracles O
With O
a O
static O
oracle O
, O
the O
training Method
procedure Method
computes O
a O
canonical O
reference O
series O
of O
transitions O
for O
each O
gold O
parse O
tree O
. O
It O
then O
runs O
the O
parser Method
through O
this O
canonical O
sequence O
of O
transitions O
, O
while O
keeping O
track O
of O
the O
state Method
representation Method
at O
each O
step O
, O
as O
well O
as O
the O
distribution O
over O
transitions O
which O
is O
predicted O
by O
the O
current O
classifier Method
for O
the O
state Method
representation Method
. O
Once O
the O
end O
of O
the O
sentence O
is O
reached O
, O
the O
parameters O
are O
updated O
towards O
maximizing O
the O
likelihood O
of O
the O
reference O
transition O
sequence O
( O
Equation O
[ O
reference O
] O
) O
, O
which O
equates O
to O
maximizing O
the O
probability O
of O
the O
correct O
transition O
, O
, O
at O
each O
state O
along O
the O
path O
. O
subsection O
: O
Training O
with O
Dynamic Method
Oracles Method
In O
the O
static Task
oracle Task
case Task
, O
the O
parser Method
is O
trained O
to O
predict O
the O
best O
transition O
to O
take O
at O
each O
parsing Task
step O
, O
assuming O
all O
previous O
transitions O
were O
correct O
. O
Since O
the O
parser Method
is O
likely O
to O
make O
mistakes O
at O
test O
time O
and O
encounter O
states O
it O
has O
not O
seen O
during O
training O
, O
this O
training O
criterion O
is O
problematic O
. O
Instead O
, O
we O
would O
prefer O
to O
train O
the O
parser Method
to O
behave O
optimally O
even O
after O
making O
a O
mistake O
( O
under O
the O
constraint O
that O
it O
can O
not O
backtrack O
or O
fix O
any O
previous O
decision O
) O
. O
We O
thus O
need O
to O
include O
in O
the O
training O
examples O
states O
that O
result O
from O
wrong O
parsing Task
decisions O
, O
together O
with O
the O
optimal O
transitions O
to O
take O
in O
these O
states O
. O
To O
this O
end O
we O
reconsider O
which O
training O
examples O
to O
show O
, O
and O
what O
it O
means O
to O
behave O
optimally O
on O
these O
training O
examples O
. O
The O
framework O
of O
training O
with O
exploration Task
using O
dynamic O
oracles O
suggested O
by O
Goldberg O
and O
Nivre O
goldberg12dynamic O
, O
goldberg2013training O
provides O
answers O
to O
these O
questions O
. O
While O
the O
application O
of O
dynamic Method
oracle Method
training Method
is O
relatively O
straightforward O
, O
some O
adaptations O
were O
needed O
to O
accommodate O
the O
probabilistic Task
training Task
objective Task
. O
These O
adaptations O
mostly O
follow O
Goldberg O
goldberg2013calibrated O
. O
paragraph O
: O
Dynamic O
Oracles O
. O
A O
dynamic Method
oracle Method
is O
the O
component O
that O
, O
given O
a O
gold O
parse O
tree O
, O
provides O
the O
optimal O
set O
of O
possible O
actions O
to O
take O
for O
any O
valid O
parser O
state O
. O
In O
contrast O
to O
static Method
oracles Method
that O
derive O
a O
canonical O
state O
sequence O
for O
each O
gold O
parse O
tree O
and O
say O
nothing O
about O
states O
that O
deviate O
from O
this O
canonical O
path O
, O
the O
dynamic Method
oracle Method
is O
well O
defined O
for O
states O
that O
result O
from O
parsing Task
mistakes O
, O
and O
they O
may O
produce O
more O
than O
a O
single O
gold O
action O
for O
a O
given O
state O
. O
Under O
the O
dynamic Method
oracle Method
framework Method
, O
an O
action O
is O
said O
to O
be O
optimal O
for O
a O
state O
if O
the O
best O
tree O
that O
can O
be O
reached O
after O
taking O
the O
action O
is O
no O
worse O
( O
in O
terms O
of O
accuracy Metric
with O
respect O
to O
the O
gold O
tree O
) O
than O
the O
best O
tree O
that O
could O
be O
reached O
prior O
to O
taking O
that O
action O
. O
Goldberg O
and O
Nivre O
goldberg2013training O
define O
the O
arc Method
- Method
decomposition Method
property Method
of Method
transition Method
systems Method
, O
and O
show O
how O
to O
derive O
efficient O
dynamic Method
oracles Method
for O
transition Method
systems Method
that O
are O
arc O
- O
decomposable O
. O
Unfortunately O
, O
the O
arc Method
- Method
standard Method
transition Method
system Method
does O
not O
have O
this O
property O
. O
While O
it O
is O
possible O
to O
compute O
dynamic O
oracles O
for O
the O
arc Method
- Method
standard Method
system Method
, O
the O
computation O
relies O
on O
a O
dynamic Method
programming Method
algorithm Method
which O
is O
polynomial O
in O
the O
length O
of O
the O
stack O
. O
As O
the O
dynamic Method
oracle Method
has O
to O
be O
queried O
for O
each O
parser O
state O
seen O
during O
training O
, O
the O
use O
of O
this O
dynamic Method
oracle Method
will O
make O
the O
training O
runtime O
several O
times O
longer O
. O
We O
chose O
instead O
to O
switch O
to O
the O
arc Method
- Method
hybrid Method
transition O
system O
, O
which O
is O
very O
similar O
to O
the O
arc Method
- Method
standard Method
system Method
but O
is O
arc O
- O
decomposable O
and O
hence O
admits O
an O
efficient O
dynamic Method
oracle Method
, O
resulting O
in O
only O
negligible O
increase O
to O
training Metric
runtime Metric
. O
We O
implemented O
the O
dynamic Method
oracle Method
to O
the O
arc Method
- Method
hybrid Method
system O
as O
described O
by O
Goldberg O
goldberg2013training O
. O
paragraph O
: O
Training O
with O
Exploration O
. O
In O
order O
to O
expose O
the O
parser Method
to O
configurations O
that O
are O
likely O
to O
result O
from O
incorrect O
parsing Task
decisions O
, O
we O
make O
use O
of O
the O
probabilistic O
nature O
of O
the O
classifier Method
. O
During O
training O
, O
instead O
of O
following O
the O
gold O
action O
, O
we O
sample O
the O
next O
transition O
according O
to O
the O
output O
distribution O
the O
classifier Method
assigns O
to O
the O
current O
configuration O
. O
Another O
option O
, O
taken O
by O
Goldberg O
and O
Nivre O
, O
is O
to O
follow O
the O
one O
- O
best O
action O
predicted O
by O
the O
classifier Method
. O
However O
, O
initial O
experiments O
showed O
that O
the O
one O
- O
best O
approach O
did O
not O
work O
well O
. O
Because O
the O
neural Method
network Method
classifier Method
becomes O
accurate O
early O
on O
in O
the O
training O
process O
, O
the O
one O
- O
best O
action O
is O
likely O
to O
be O
correct O
, O
and O
the O
parser Method
is O
then O
exposed O
to O
very O
few O
error O
states O
in O
its O
training O
process O
. O
By O
sampling O
from O
the O
predicted O
distribution O
, O
we O
are O
effectively O
increasing O
the O
chance O
of O
straying O
from O
the O
gold O
path O
during O
training O
, O
while O
still O
focusing O
on O
mistakes O
that O
receive O
relatively O
high O
parser Metric
scores Metric
. O
We O
believe O
further O
formal O
analysis O
of O
this O
method O
will O
reveal O
connections O
to O
reinforcement Task
learning Task
and O
, O
perhaps O
, O
other O
methods O
for O
learning Task
complex Task
policies Task
. O
Taking O
this O
idea O
further O
, O
we O
could O
increase O
the O
number O
of O
error O
- O
states O
observed O
in O
the O
training Method
process Method
by O
changing O
the O
sampling O
distribution O
so O
as O
to O
bias O
it O
toward O
more O
low O
- O
probability O
states O
. O
We O
do O
this O
by O
raising O
each O
probability O
to O
the O
power O
of O
( O
) O
and O
re O
- O
normalizing O
. O
This O
transformation O
keeps O
the O
relative O
ordering O
of O
the O
events O
, O
while O
shifting O
probability O
mass O
towards O
less O
frequent O
events O
. O
As O
we O
show O
below O
, O
this O
turns O
out O
to O
be O
very O
beneficial O
for O
the O
configurations O
that O
make O
use O
of O
external O
embeddings O
. O
Indeed O
, O
these O
configurations O
achieve O
high O
accuracies Metric
and O
sharp O
class O
distributions O
early O
on O
in O
the O
training O
process O
. O
The O
parser Method
is O
trained O
to O
maximize O
the O
likelihood O
of O
a O
correct O
action O
at O
each O
parsing Task
state O
according O
to O
Equation O
[ O
reference O
] O
. O
When O
using O
the O
dynamic O
oracle O
, O
a O
state O
may O
admit O
multiple O
correct O
actions O
. O
Our O
objective O
in O
such O
cases O
is O
the O
marginal O
likelihood O
of O
all O
correct O
actions O
, O
section O
: O
Experiments O
Following O
the O
same O
settings O
of O
Chen O
and O
Manning O
chen:2014 O
and O
Dyer O
et O
al O
lstmacl15 O
we O
report O
results O
in O
the O
English Material
PTB Material
and O
Chinese Material
CTB Material
- Material
5 Material
. O
Table O
[ O
reference O
] O
shows O
the O
results O
of O
the O
parser Method
in O
its O
different O
configurations O
. O
The O
table O
also O
shows O
the O
best O
result O
obtained O
with O
the O
static O
oracle O
( O
obtained O
by O
rerunning O
Dyer O
et O
al O
. O
parser Method
) O
for O
the O
sake O
of O
comparison O
between O
static Method
and Method
dynamic Method
training Method
strategies Method
. O
The O
score O
achieved O
by O
the O
dynamic Method
oracle Method
for O
English Material
is O
93.56 O
UAS Metric
. O
This O
is O
remarkable O
given O
that O
the O
parser Method
uses O
a O
completely O
greedy Method
search Method
procedure Method
. O
Moreover O
, O
the O
Chinese Material
score O
establishes O
the O
state O
- O
of O
- O
the O
- O
art O
, O
using O
the O
same O
settings O
as O
chen:2014 O
. O
The O
error Method
- Method
exploring Method
dynamic Method
- Method
oracle Method
training Method
always O
improves O
over O
static Method
oracle Method
training Method
controlling O
for O
the O
transition Task
system Task
, O
but O
the O
arc Method
- Method
hybrid Method
system O
slightly O
under O
- O
performs O
the O
arc Method
- Method
standard Method
system Method
when O
trained O
with O
static O
oracle O
. O
Flattening O
the O
sampling O
distribution O
( O
) O
is O
especially O
beneficial O
when O
training O
with O
pretrained Task
word Task
embeddings Task
. O
In O
order O
to O
be O
able O
to O
compare O
with O
similar O
greedy Method
parsers Method
we O
report O
the O
performance O
of O
the O
parser Method
on O
the O
multilingual O
treebanks O
of O
the O
CoNLL Material
2009 Material
shared Material
task Material
. O
Since O
some O
of O
the O
treebanks O
contain O
nonprojective O
sentences O
and O
arc Method
- Method
hybrid Method
does O
not O
allow O
nonprojective O
trees O
, O
we O
use O
the O
pseudo Method
- Method
projective Method
approach Method
. O
We O
used O
predicted O
part O
- O
of O
- O
speech O
tags O
provided O
by O
the O
CoNLL Task
2009 Task
shared Task
task Task
organizers Task
. O
We O
also O
include O
results O
with O
pretrained O
word O
embeddings O
for O
English Material
, O
Chinese Material
, O
German Material
, O
and O
Spanish Material
following O
the O
same O
training O
setup O
as O
Dyer O
et O
al O
. O
( O
2015 O
) O
; O
for O
English Material
and O
Chinese Material
we O
used O
the O
same O
pretrained O
word O
embeddings O
as O
in O
Table O
[ O
reference O
] O
, O
for O
German Material
we O
used O
the O
monolingual O
training O
data O
from O
the O
WMT Material
2015 Material
dataset Material
and O
for O
Spanish Material
we O
used O
the O
Spanish Material
Gigaword Material
version O
3 O
. O
See O
Table O
[ O
reference O
] O
. O
section O
: O
Related O
Work O
Training O
greedy Method
parsers Method
on O
non O
- O
gold O
outcomes O
, O
facilitated O
by O
dynamic Method
oracles Method
, O
has O
been O
explored O
by O
several O
researchers O
in O
different O
ways O
. O
More O
generally O
, O
training O
greedy Method
search Method
systems Method
by O
paying O
attention O
to O
the O
expected O
classifier O
behavior O
during O
test O
time O
has O
been O
explored O
under O
the O
imitation Method
learning Method
and O
learning Method
- Method
to Method
- Method
search Method
frameworks Method
. O
Directly O
modeling O
the O
probability O
of O
making O
a O
mistake O
has O
also O
been O
explored O
for O
parsing Task
. O
Generally O
, O
the O
use O
of O
RNNs Method
to O
conditionally Task
predict Task
actions Task
in O
sequence O
given O
a O
history O
is O
spurring O
increased O
interest O
in O
training O
regimens O
that O
make O
the O
learned O
model O
more O
robust O
to O
test O
- O
time O
prediction O
errors O
. O
Solutions O
based O
on O
curriculum Method
learning Method
, O
expected Method
loss Method
training Method
, O
and O
reinforcement Method
learning Method
have O
been O
proposed O
. O
Finally O
, O
abandoning O
greedy Method
search Method
in O
favor O
of O
approximate Method
global Method
search Method
offers O
an O
alternative O
solution O
to O
the O
problems O
with O
greedy Method
search Method
, O
and O
has O
been O
analyzed O
as O
well O
, O
including O
for O
parsing Task
. O
section O
: O
Conclusions O
lstmacl15 O
presented O
stack Method
LSTMs Method
and O
used O
them O
to O
implement O
a O
transition Method
- Method
based Method
dependency Method
parser Method
. O
The O
parser Method
uses O
a O
greedy Method
learning Method
strategy Method
which O
potentially O
provides O
very O
high O
parsing Task
speed O
while O
still O
achieving O
state O
- O
of O
- O
the O
- O
art O
results O
. O
We O
have O
demonstrated O
that O
improvement O
by O
training O
the O
greedy Method
parser Method
on O
non O
- O
gold O
outcomes O
; O
dynamic Method
oracles Method
improve O
the O
stack Method
LSTM Method
parser Method
, O
achieving O
93.56 O
UAS Metric
for O
English Material
, O
maintaining O
greedy Method
search Method
. O
section O
: O
Acknowledgments O
This O
work O
was O
sponsored O
in O
part O
by O
the O
U. O
S. O
Army O
Research O
Laboratory O
and O
the O
U. O
S. O
Army O
Research O
Office O
under O
contract O
/ O
grant O
number O
W911NF O
- O
10 O
- O
1 O
- O
0533 O
, O
and O
in O
part O
by O
NSF O
CAREER O
grant O
IIS O
- O
1054319 O
. O
Miguel O
Ballesteros O
was O
supported O
by O
the O
European O
Commission O
under O
the O
contract O
numbers O
FP7 O
- O
ICT O
- O
610411 O
( O
project O
MULTISENSOR O
) O
and O
H2020 O
- O
RIA O
- O
645012 O
( O
project O
KRISTINA O
) O
. O
Yoav O
Goldberg O
is O
supported O
by O
the O
Intel O
Collaborative O
Research O
Institute O
for O
Computational Task
Intelligence Task
( O
ICRI O
- O
CI O
) O
, O
a O
Google O
Research O
Award O
and O
the O
Israeli O
Science O
Foundation O
( O
grant O
number O
1555 O
/ O
15 O
) O
. O
bibliography O
: O
References O
