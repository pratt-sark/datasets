document O
: O
Multi Task
- Task
Task Task
Graph Task
Autoencoders Task
section O
: O
Autoencoder Method
Architecture Method
for O
Link Task
Prediction Task
and O
Node Task
Classification Task
As O
the O
world O
is O
becoming O
increasingly O
interconnected O
, O
relational O
data O
are O
also O
growing O
in O
ubiquity O
. O
In O
this O
work O
, O
we O
examine O
the O
task O
of O
learning Task
to O
make O
predictions Task
on Task
graphs Task
for O
a O
broad O
range O
of O
real Task
- Task
world Task
applications Task
. O
Specifically O
, O
we O
study O
two O
canonical Task
subtasks Task
associated O
with O
relational O
, O
graph O
- O
structured O
datasets O
: O
link Task
prediction Task
and O
node Task
classification Task
( O
LPNC Task
) O
. O
A O
graph O
is O
a O
partially O
observed O
set O
of O
edges O
and O
nodes O
( O
or O
vertices O
) O
, O
and O
the O
learning Task
task Task
is O
to O
predict O
the O
labels O
for O
edges O
and O
nodes O
. O
In O
real Task
- Task
world Task
applications Task
, O
the O
input O
graph O
is O
a O
network O
with O
nodes O
representing O
unique O
entities O
and O
edges O
representing O
relationships O
( O
or O
links O
) O
between O
entities O
. O
Further O
, O
the O
labels O
of O
nodes O
and O
edges O
in O
a O
graph O
are O
often O
correlated O
, O
exhibiting O
complex O
relational O
structures O
that O
violate O
the O
general O
assumption O
of O
independent Method
and Method
identical Method
distribution Method
fundamental O
in O
traditional O
machine Method
learning Method
. O
Therefore O
, O
models O
capable O
of O
exploiting O
topological O
structures O
of O
graphs O
have O
been O
shown O
to O
achieve O
superior O
predictive Task
performances O
on O
many O
LPNC Task
tasks Task
. O
We O
introduce O
the O
Multi Method
- Method
Task Method
Graph Method
Autoencoder Method
( O
MTGAE Method
) O
architecture O
, O
schematically O
depicted O
in O
Figure O
[ O
reference O
] O
, O
capable O
of O
learning O
a O
shared Method
representation Method
of Method
latent Method
node Method
embeddings Method
from O
local O
graph O
topology O
and O
available O
explicit O
node O
features O
for O
LPNC Method
. O
Our O
simple O
, O
yet O
effective O
and O
versatile O
model O
is O
efficiently O
trained O
end O
- O
to O
- O
end O
for O
the O
joint O
, O
simultaneous O
multi Task
- Task
task Task
learning Task
( O
MTL Task
) O
of O
unsupervised Task
link Task
prediction Task
and O
semi Task
- Task
supervised Task
node Task
classification Task
in O
a O
single O
stage O
, O
whereas O
previous O
related O
deep Method
graph Method
embedding Method
methods Method
require O
multiple O
training O
steps O
that O
are O
difficult O
to O
optimize O
. O
We O
present O
an O
empirical O
evaluation O
of O
the O
MTGAE Method
model O
on O
five O
challenging O
benchmark O
graph O
- O
structured O
datasets O
and O
show O
significant O
improvement O
in O
predictive Metric
performance O
over O
three O
strong O
baselines O
designed O
specifically O
for O
LPNC Method
. O
Reference O
code O
and O
data O
are O
available O
at O
. O
Problem Task
Formulation Task
and O
Notation O
The O
input O
to O
the O
MTGAE Method
model O
is O
a O
graph O
of O
nodes O
. O
Graph Method
is O
represented O
by O
its O
adjacency O
matrix O
paired O
with O
a O
unique O
ordering O
of O
vertices O
. O
For O
a O
partially O
observed O
graph O
, O
, O
where O
denotes O
a O
known O
positive O
edge O
, O
denotes O
a O
known O
negative O
edge O
, O
and O
unk O
denotes O
an O
unknown O
status O
( O
missing O
or O
unobserved O
) O
edge O
. O
In O
general O
, O
the O
input O
to O
the O
model O
can O
be O
directed O
or O
undirected O
, O
weighted O
or O
unweighted O
, O
and O
/ O
or O
bipartite O
graphs O
. O
Optionally O
, O
we O
are O
given O
a O
matrix O
of O
available O
node O
features O
, O
i.e. O
side O
information O
. O
The O
aim O
of O
the O
MTGAE Method
model O
is O
to O
learn O
a O
set O
of O
low O
- O
dimensional O
latent O
variables O
for O
the O
nodes O
that O
can O
produce O
an O
approximate O
reconstruction O
output O
such O
that O
the O
empirical Metric
error Metric
between O
and O
is O
minimized O
, O
thereby O
preserving O
the O
global O
graph O
structure O
. O
In O
this O
paper O
, O
we O
use O
capital O
variables O
( O
e.g. O
, O
) O
to O
denote O
matrices O
and O
lower O
- O
case O
variables O
( O
e.g. O
, O
) O
to O
denote O
row O
vectors O
. O
For O
example O
, O
we O
use O
to O
mean O
the O
th O
row O
of O
the O
matrix O
. O
Unsupervised O
Link Task
Prediction Task
Let O
be O
an O
adjacency O
vector O
of O
that O
contains O
the O
local O
neighborhood O
of O
the O
th O
node O
. O
Our O
proposed O
MTGAE Method
architecture O
comprises O
a O
set O
of O
non Method
- Method
linear Method
transformations Method
on O
summarized O
in O
two O
component O
parts O
: O
encoder Method
and O
decoder Method
. O
We O
stack O
two O
layers O
of O
the O
encoder Method
part Method
to O
derive O
- O
dimensional O
latent Method
feature Method
representation Method
of O
the O
th O
node O
, O
and O
then O
stack O
two O
layers O
of O
the O
decoder Method
part Method
to O
obtain O
an O
approximate O
reconstruction O
output O
, O
resulting O
in O
a O
four Method
- Method
layer Method
autoencoder Method
architecture Method
. O
Note O
that O
is O
highly O
sparse O
, O
with O
up O
to O
80 O
percent O
of O
the O
edges O
missing O
at O
random O
in O
some O
of O
our O
experiments O
, O
and O
the O
dense O
reconstructed O
output O
contains O
the O
predictions O
for O
the O
missing O
edges O
. O
The O
hidden Method
representations Method
for O
the O
encoder O
and O
decoder O
parts O
are O
computed O
as O
follows O
: O
The O
choice O
of O
non Method
- Method
linear Method
, Method
element Method
- Method
wise Method
activation Method
function Method
is O
the O
rectified Method
linear Method
unit Method
. O
The O
last O
decoder Method
layer Method
computes O
a O
linear Method
transformation Method
to O
score O
the O
missing O
links O
as O
part O
of O
the O
reconstruction Task
. O
We O
constrain O
the O
MTGAE Method
architecture O
to O
be O
symmetrical O
with O
shared O
parameters O
for O
between O
the O
encoder O
and O
decoder O
parts O
, O
resulting O
in O
almost O
fewer O
parameters O
than O
an O
unconstrained Method
architecture Method
. O
Parameter Method
sharing Method
is O
a O
powerful O
form O
of O
regularization Method
that O
helps O
improve O
learning Task
and O
generalization Task
, O
and O
is O
also O
the O
main O
motivation O
behind O
MTL Task
. O
Notice O
the O
bias O
units O
do O
not O
share O
parameters O
, O
and O
are O
transposed O
copies O
of O
. O
For O
brevity O
of O
notation O
, O
we O
summarize O
the O
parameters O
to O
be O
learned O
in O
. O
Optionally O
, O
if O
a O
matrix O
of O
node O
features O
is O
available O
, O
then O
we O
concatenate O
to O
obtain O
an O
augmented O
adjacency O
matrix O
and O
perform O
the O
above O
encoder Method
- Method
decoder Method
transformations Method
on O
for O
unsupervised Task
link Task
prediction Task
. O
The O
intuition O
behind O
the O
concatenation O
of O
node O
features O
is O
to O
enable O
a O
shared O
representation O
of O
both O
graph O
and O
node O
features O
throughout O
the O
autoencoding O
transformations O
by O
way O
of O
the O
tied O
parameters O
. O
During O
the O
forward Method
pass Method
, O
or O
inference Task
, O
the O
model O
takes O
as O
input O
an O
adjacency O
vector O
and O
computes O
its O
reconstructed O
output O
for O
unsupervised Task
link Task
prediction Task
. O
During O
the O
backward O
pass O
, O
we O
learn O
by O
minimizing O
the O
Masked Metric
Balanced Metric
Cross Metric
- Metric
Entropy Metric
( O
MBCE Metric
) O
loss O
, O
which O
allows O
only O
the O
contributions O
of O
those O
parameters O
associated O
with O
observed O
edges O
, O
as O
in O
. O
We O
handle O
class Task
imbalance Task
in O
link Task
prediction Task
by O
defining O
a O
weighting O
factor O
to O
be O
used O
as O
a O
multiplier O
for O
the O
positive O
class O
in O
the O
cross Method
- Method
entropy Method
loss Method
formulation Method
. O
For O
a O
single O
example O
and O
its O
reconstructed O
output O
, O
we O
compute O
the O
MBCE Metric
loss O
as O
follows O
: O
Here O
, O
is O
the O
balanced O
binary O
cross O
- O
entropy O
loss O
with O
weighting O
factor O
, O
is O
the O
sigmoid O
function O
, O
is O
the O
Hadamard O
( O
element O
- O
wise O
) O
product O
, O
and O
is O
the O
Boolean O
mask O
: O
if O
, O
else O
. O
Semi Task
- Task
Supervised Task
Node Task
Classification Task
The O
MTGAE Method
model O
can O
also O
be O
used O
to O
perform O
efficient O
information Task
propagation Task
on O
graphs Task
for O
the O
task O
of O
semi Task
- Task
supervised Task
node Task
classification Task
. O
For O
a O
given O
augmented O
adjacency O
vector O
, O
the O
model O
learns O
the O
corresponding O
node Method
embedding Method
to O
obtain O
an O
optimal Task
reconstruction Task
. O
Intuitively O
, O
encodes O
a O
vector O
of O
latent O
features O
derived O
from O
the O
concatenation O
of O
both O
graph O
and O
node O
features O
, O
and O
can O
be O
used O
to O
predict O
the O
label O
of O
the O
th O
node O
. O
For O
multi Task
- Task
class Task
classification Task
, O
we O
decode O
using O
the O
softmax Method
activation Method
function Method
to O
produce O
a O
probability O
distribution O
over O
node O
labels O
. O
More O
precisely O
, O
we O
predict O
node O
labels O
via O
the O
following O
transformation O
: O
, O
where O
and O
. O
Multi Task
- Task
Task Task
Learning Task
In O
many O
applications O
, O
such O
as O
knowledge Task
base Task
completion Task
and O
network Task
analysis Task
, O
the O
input O
graph O
is O
partially O
observed O
with O
an O
incomplete O
set O
of O
edges O
and O
a O
small O
fraction O
of O
labeled O
nodes O
. O
Thus O
, O
it O
is O
desirable O
for O
a O
model O
to O
predict O
the O
labels O
of O
missing O
links O
and O
nodes O
simultaneously O
in O
a O
multi Task
- Task
task Task
learning Task
setting O
. O
We O
achieve O
multi Task
- Task
task Task
learning Task
on O
graphs O
by O
training O
the O
MTGAE Method
model O
using O
a O
joint Method
loss Method
function Method
that O
combines O
the O
masked Method
categorical Method
cross Method
- Method
entropy Method
loss Method
for O
semi Task
- Task
supervised Task
node Task
classification Task
with O
the O
MBCE Metric
loss O
for O
unsupervised Task
link Task
prediction Task
: O
where O
is O
the O
set O
of O
node O
labels O
, O
is O
the O
binary O
indicator O
if O
node O
belongs O
to O
class O
, O
is O
the O
softmax O
probability O
that O
node O
belongs O
to O
class O
, O
is O
the O
loss Metric
defined O
for O
unsupervised Task
link Task
prediction Task
, O
and O
is O
the O
Boolean O
variable O
: O
if O
node O
has O
a O
label O
, O
else O
. O
The O
training Metric
complexity Metric
of O
the O
MTGAE Method
model O
is O
, O
where O
is O
the O
number O
of O
nodes O
, O
is O
the O
dimensionality O
of O
node O
features O
, O
is O
the O
size O
of O
the O
hidden O
layer O
, O
and O
is O
the O
number O
of O
iterations O
. O
In O
practice O
, O
, O
, O
and O
are O
independent O
of O
. O
Thus O
, O
the O
overall O
complexity Metric
of O
MTGAE Method
is O
, O
linear O
in O
the O
number O
of O
nodes O
. O
section O
: O
Empirical O
Evaluation O
width=0.95 O
width= O
Implementation O
Details O
We O
closely O
follow O
the O
experimental O
protocols O
described O
in O
to O
train O
and O
evaluate O
our O
MTGAE Method
model O
for O
LPNC Method
. O
For O
link Task
prediction Task
, O
we O
form O
disjoint O
test O
, O
and O
validation Metric
, O
sets O
containing O
10 O
, O
and O
5 O
, O
percent O
of O
randomly O
sampled O
positive O
links O
and O
the O
same O
number O
of O
negative O
links O
, O
respectively O
, O
while O
utilizing O
all O
node O
features O
. O
For O
node Task
classification Task
, O
we O
split O
the O
data O
into O
disjoint O
test O
, O
and O
validation O
, O
sets O
of O
1 O
, O
000 O
, O
and O
500 O
, O
examples O
, O
respectively O
and O
use O
only O
20 O
examples O
per O
class O
for O
semi Task
- Task
supervised Task
learning Task
. O
In O
comparison O
to O
the O
baselines O
, O
we O
evaluate O
our O
MTGAE Method
model O
on O
the O
same O
data O
splits O
over O
10 O
runs O
with O
random Method
weight Method
initialization Method
and O
report O
mean Metric
AUC Metric
/ Metric
AP Metric
scores Metric
for O
link Metric
prediction Metric
and O
accuracy Metric
scores Metric
for O
node Task
classification Task
. O
We O
also O
compare O
the O
representation Metric
capacity Metric
of O
our O
MTGAE Method
model O
against O
the O
related O
autoencoder Method
- Method
based Method
SDNE Method
model Method
on O
the O
network Task
reconstruction Task
task Task
. O
We O
use O
the O
ranking Metric
metric Metric
precision@ Metric
to O
evaluate O
the O
model O
’s O
ability O
to O
retrieve O
positive O
edges O
as O
part O
of O
the O
reconstruction Task
. O
Hyper Method
- Method
parameter Method
tuning Method
is O
performed O
on O
the O
validation O
set O
. O
Key O
hyper O
- O
parameters O
include O
mini O
- O
batch O
size O
, O
dimensionality O
of O
the O
hidden O
layers O
, O
and O
the O
percentage O
of O
dropout Method
regularization Method
. O
In O
all O
experiments O
, O
the O
dimensionality O
of O
the O
hidden O
layers O
in O
the O
MTGAE Method
architecture O
is O
fixed O
at O
- O
256 O
- O
128 O
- O
256 O
- O
. O
We O
train O
for O
100 O
epochs O
using O
Adam Method
gradient Method
descent Method
with O
a O
fixed O
learning Metric
rate Metric
of O
on O
mini O
- O
batches O
of O
64 O
examples O
. O
We O
implement O
the O
MTGAE Method
architecture O
using O
Keras Method
on O
top O
of O
the O
GPU Method
- Method
enabled Method
TensorFlow Method
backend Method
. O
The O
diagonal O
elements O
of O
the O
adjacency O
matrix O
are O
set O
to O
with O
the O
interpretation O
that O
every O
node O
is O
connected O
to O
itself O
. O
We O
apply O
mean Method
- Method
variance Method
normalization Method
after O
each O
ReLU Method
activation Method
layer Method
to O
help O
improve O
link Task
prediction Task
performance O
, O
where O
it O
compensates O
for O
noise O
between O
train O
and O
test O
instances O
by O
normalizing O
the O
activations O
to O
have O
zero O
mean O
and O
unit O
variance O
. O
During O
training Task
, O
we O
implement O
several O
regularization Method
techniques Method
to O
mitigate O
overfitting O
, O
including O
dropout Method
for O
highly O
sparse O
graphs O
and O
early Task
stopping Task
as O
a O
form O
of O
regularization O
in O
time O
when O
the O
model O
shows O
signs O
of O
overfitting O
on O
the O
validation O
set O
. O
We O
initialize O
weights O
according O
to O
the O
Glorot Method
scheme Method
described O
in O
. O
We O
do O
not O
apply O
weight Method
decay Method
regularization Method
. O
Results O
and O
Analysis O
Results O
of O
the O
reconstruction Task
task Task
for O
the O
Arxiv Material
- Material
GRQC Material
and O
BlogCatalog Material
network O
datasets O
are O
illustrated O
in O
Figure O
[ O
reference O
] O
. O
In O
comparison O
to O
SDNE Method
, O
we O
show O
that O
our O
MTGAE Method
model O
achieves O
better O
precision@ Metric
performance O
for O
all O
values O
, O
up O
to O
for O
Arxiv Material
- Material
GRQC Material
and O
for O
BlogCatalog Material
, O
when O
trained O
on O
the O
complete O
datasets O
. O
We O
also O
systematically O
test O
the O
capacity O
of O
the O
MTGAE Method
model O
to O
reconstruct O
the O
original O
networks O
when O
up O
to O
80 O
percent O
of O
the O
edges O
are O
randomly O
removed O
, O
akin O
to O
the O
link Task
prediction Task
task Task
. O
We O
show O
that O
the O
MTGAE Method
model O
only O
gets O
worse O
precision@ Metric
performance O
than O
SDNE Method
on O
the O
Arxiv Material
- Material
GRQC Material
dataset O
when O
more O
than O
40 O
percent O
of O
the O
edges O
are O
missing O
. O
On O
the O
BlogCatalog Material
dataset O
, O
the O
MTGAE Method
model O
achieves O
better O
precision@ Metric
performance O
than O
SDNE Method
for O
large O
values O
even O
when O
80 O
percent O
of O
the O
edges O
are O
missing O
at O
random O
. O
This O
experiment O
demonstrates O
the O
superior O
representation Metric
capacity Metric
of O
our O
MTGAE Method
model O
when O
compared O
to O
SDNE Method
, O
which O
is O
attributed O
to O
parameter O
sharing O
in O
the O
architecture O
. O
Lastly O
, O
we O
report O
LPNC Method
results O
obtained O
by O
our O
MTGAE Method
model O
in O
the O
MTL Task
scenario O
. O
The O
model O
takes O
as O
input O
an O
incomplete O
graph O
with O
10 O
percent O
of O
the O
positive O
edges O
, O
and O
the O
same O
number O
of O
negative O
edges O
, O
missing O
at O
random O
and O
all O
available O
node O
features O
to O
simultaneously O
predict O
labels O
for O
the O
nodes O
and O
missing O
edges O
. O
Table O
[ O
reference O
] O
shows O
the O
efficacy O
of O
the O
MTGAE Method
model O
for O
MTL Task
when O
compared O
against O
recent O
state O
- O
of O
- O
the O
- O
art O
task Method
- Method
specific Method
link Method
prediction Method
and O
node Method
classification Method
models Method
, O
which O
require O
the O
complete O
adjacency O
matrix O
as O
input O
. O
For O
link Task
prediction Task
, O
MTGAE Method
significantly O
outperforms O
the O
best O
VGAE Method
model Method
on O
Cora Material
and O
Citeseer Material
. O
For O
node Task
classification Task
, O
MTGAE Method
is O
the O
best O
performing O
model O
on O
the O
Citeseer Material
and O
Pubmed Material
datasets O
, O
which O
have O
very O
low O
node Metric
label Metric
rates Metric
. O
width=0.5 O
Future O
Work O
Further O
research O
will O
explore O
inductive Task
reasoning Task
on O
out Task
- Task
of Task
- Task
network Task
nodes Task
and O
mitigate O
complexity O
for O
improved O
scalability O
on O
large Task
, Task
dynamic Task
graphs Task
. O
bibliography O
: O
References O
