Fast Method
R Method
- Method
CNN Method
section O
: O
Abstract O
This O
paper O
proposes O
a O
Fast Method
Region Method
- Method
based Method
Convolutional Method
Network Method
method Method
( O
Fast Method
R Method
- Method
CNN Method
) O
for O
object Task
detection Task
. O
Fast Method
R Method
- Method
CNN Method
builds O
on O
previous O
work O
to O
efficiently O
classify O
object Task
proposals Task
using O
deep Method
convolutional Method
networks Method
. O
Compared O
to O
previous O
work O
, O
Fast Method
R Method
- Method
CNN Method
employs O
several O
innovations O
to O
improve O
training Metric
and Metric
testing Metric
speed Metric
while O
also O
increasing O
detection Metric
accuracy Metric
. O
Fast Method
R Method
- Method
CNN Method
trains O
the O
very O
deep Method
VGG16 Method
network Method
9× O
faster O
than O
R Method
- Method
CNN Method
, O
is O
213× O
faster O
at O
test Metric
- Metric
time Metric
, O
and O
achieves O
a O
higher O
mAP Metric
on O
PASCAL Material
VOC Material
2012 Material
. O
Compared O
to O
SPPnet Method
, O
Fast Method
R Method
- Method
CNN Method
trains O
VGG16 Method
3× O
faster O
, O
tests O
10× O
faster O
, O
and O
is O
more O
accurate O
. O
Fast Method
R Method
- Method
CNN Method
is O
implemented O
in O
Python Method
and O
C O
++ O
( O
using O
Caffe Method
) O
and O
is O
available O
under O
the O
open O
- O
source O
MIT O
License O
at O
https O
: O
// O
github.com O
/ O
rbgirshick O
/ O
fast Method
- Method
rcnn Method
. O
section O
: O
Introduction O
Recently O
, O
deep Method
ConvNets Method
[ O
reference O
][ O
reference O
] O
have O
significantly O
improved O
image Task
classification Task
[ O
reference O
] O
and O
object Task
detection Task
[ O
reference O
][ O
reference O
] O
accuracy Metric
. O
Compared O
to O
image Task
classification Task
, O
object Task
detection Task
is O
a O
more O
challenging O
task O
that O
requires O
more O
complex O
methods O
to O
solve O
. O
Due O
to O
this O
complexity O
, O
current O
approaches O
( O
e.g. O
, O
[ O
reference O
][ O
reference O
][ O
reference O
][ O
reference O
] O
) O
train O
models O
in O
multi Method
- Method
stage Method
pipelines Method
that O
are O
slow O
and O
inelegant O
. O
Complexity Task
arises O
because O
detection Task
requires O
the O
accurate Task
localization Task
of Task
objects Task
, O
creating O
two O
primary O
challenges O
. O
First O
, O
numerous O
candidate O
object O
locations O
( O
often O
called O
" O
proposals O
" O
) O
must O
be O
processed O
. O
Second O
, O
these O
candidates O
provide O
only O
rough Task
localization Task
that O
must O
be O
refined O
to O
achieve O
precise Task
localization Task
. O
Solutions O
to O
these O
problems O
often O
compromise O
speed Metric
, O
accuracy Metric
, O
or O
simplicity Metric
. O
In O
this O
paper O
, O
we O
streamline O
the O
training Task
process Task
for O
stateof O
- O
the O
- O
art O
ConvNet Method
- Method
based Method
object Method
detectors Method
[ O
reference O
][ O
reference O
] O
. O
We O
propose O
a O
single Method
- Method
stage Method
training Method
algorithm Method
that O
jointly O
learns O
to O
classify O
object O
proposals O
and O
refine O
their O
spatial O
locations O
. O
The O
resulting O
method O
can O
train O
a O
very O
deep Method
detection Method
network Method
( O
VGG16 Method
[ O
reference O
] O
) O
9× O
faster O
than O
R Method
- Method
CNN Method
[ O
reference O
] O
and O
3× O
faster O
than O
SPPnet Method
[ O
reference O
] O
. O
At O
runtime O
, O
the O
detection Method
network Method
processes O
images O
in O
0.3s O
( O
excluding O
object Metric
proposal Metric
time Metric
) O
while O
achieving O
top O
accuracy Metric
on O
PASCAL Material
VOC Material
2012 Material
[ O
reference O
] O
with O
a O
mAP Metric
of O
66 O
% O
( O
vs. O
62 O
% O
for O
R Method
- Method
CNN Method
) O
. O
[ O
reference O
] O
section O
: O
R Method
- Method
CNN Method
and O
SPPnet Method
The O
Region Method
- Method
based Method
Convolutional Method
Network Method
method Method
( O
R Method
- Method
CNN Method
) O
[ O
reference O
] O
achieves O
excellent O
object Task
detection Task
accuracy O
by O
using O
a O
deep Method
ConvNet Method
to O
classify O
object O
proposals O
. O
R Method
- Method
CNN Method
, O
however O
, O
has O
notable O
drawbacks O
: O
1 O
. O
Training Method
is O
a O
multi Method
- Method
stage Method
pipeline Method
. O
R Method
- Method
CNN Method
first O
finetunes O
a O
ConvNet Method
on O
object Task
proposals Task
using O
log Method
loss Method
. O
Then O
, O
it O
fits O
SVMs Method
to O
ConvNet O
features O
. O
These O
SVMs Method
act O
as O
object Method
detectors Method
, O
replacing O
the O
softmax Method
classifier Method
learnt O
by O
fine Method
- Method
tuning Method
. O
In O
the O
third O
training O
stage O
, O
bounding Method
- Method
box Method
regressors Method
are O
learned O
. O
section O
: O
2 O
. O
Training Method
is O
expensive O
in O
space O
and O
time O
. O
For O
SVM Method
and O
bounding Task
- Task
box Task
regressor Task
training Task
, O
features O
are O
extracted O
from O
each O
object O
proposal O
in O
each O
image O
and O
written O
to O
disk O
. O
With O
very O
deep Method
networks Method
, O
such O
as O
VGG16 Method
, O
this O
process O
takes O
2.5 O
GPU O
- O
days O
for O
the O
5k O
images O
of O
the O
VOC07 Material
trainval Material
set Material
. O
These O
features O
require O
hundreds O
of O
gigabytes O
of O
storage O
. O
3 O
. O
Object Task
detection Task
is O
slow O
. O
At O
test O
- O
time O
, O
features O
are O
extracted O
from O
each O
object O
proposal O
in O
each O
test O
image O
. O
Detection Task
with O
VGG16 Method
takes O
47s O
/ O
image O
( O
on O
a O
GPU O
) O
. O
R Method
- Method
CNN Method
is O
slow O
because O
it O
performs O
a O
ConvNet Method
forward Method
pass Method
for O
each O
object O
proposal O
, O
without O
sharing O
computation O
. O
Spatial Method
pyramid Method
pooling Method
networks Method
( O
SPPnets Method
) O
[ O
reference O
] O
were O
proposed O
to O
speed O
up O
R Method
- Method
CNN Method
by O
sharing O
computation O
. O
The O
SPPnet Method
method Method
computes O
a O
convolutional Method
feature Method
map Method
for O
the O
entire O
input O
image O
and O
then O
classifies O
each O
object O
proposal O
using O
a O
feature O
vector O
extracted O
from O
the O
shared O
feature O
map O
. O
Features O
are O
extracted O
for O
a O
proposal O
by O
maxpooling O
the O
portion O
of O
the O
feature O
map O
inside O
the O
proposal O
into O
a O
fixed O
- O
size O
output O
( O
e.g. O
, O
6 O
× O
6 O
) O
. O
Multiple O
output O
sizes O
are O
pooled O
and O
then O
concatenated O
as O
in O
spatial Method
pyramid Method
pooling Method
[ O
reference O
] O
. O
SPPnet Method
accelerates O
R Method
- Method
CNN Method
by O
10 O
to O
100× O
at O
test O
time O
. O
Training Metric
time Metric
is O
also O
reduced O
by O
3× O
due O
to O
faster O
proposal Task
feature Task
extraction Task
. O
SPPnet Method
also O
has O
notable O
drawbacks O
. O
Like O
R Method
- Method
CNN Method
, O
training Method
is O
a O
multi Method
- Method
stage Method
pipeline Method
that O
involves O
extracting O
features O
, O
fine O
- O
tuning O
a O
network O
with O
log Method
loss Method
, O
training O
SVMs Method
, O
and O
finally O
fitting O
bounding Method
- Method
box Method
regressors Method
. O
Features O
are O
also O
written O
to O
disk O
. O
But O
unlike O
R Method
- Method
CNN Method
, O
the O
fine Method
- Method
tuning Method
algorithm Method
proposed O
in O
[ O
reference O
] O
can O
not O
update O
the O
convolutional Method
layers Method
that O
precede O
the O
spatial Method
pyramid Method
pooling Method
. O
Unsurprisingly O
, O
this O
limitation O
( O
fixed Method
convolutional Method
layers Method
) O
limits O
the O
accuracy Metric
of O
very O
deep Method
networks Method
. O
section O
: O
Contributions O
We O
propose O
a O
new O
training Method
algorithm Method
that O
fixes O
the O
disadvantages O
of O
R Method
- Method
CNN Method
and O
SPPnet Method
, O
while O
improving O
on O
their O
speed O
and O
accuracy Metric
. O
We O
call O
this O
method O
Fast Method
R Method
- Method
CNN Method
because O
it O
's O
comparatively O
fast O
to O
train O
and O
test O
. O
The O
Fast Method
R Method
- Method
CNN Method
method O
has O
several O
advantages O
: O
1 O
. O
Higher O
detection Metric
quality Metric
( O
mAP Metric
) O
than O
R Method
- Method
CNN Method
, O
SPPnet Method
2 O
. O
Training Method
is O
single O
- O
stage O
, O
using O
a O
multi Task
- Task
task Task
loss Task
3 O
. O
Training Method
can O
update O
all O
network O
layers O
4 O
. O
No O
disk O
storage O
is O
required O
for O
feature Task
caching Task
Fast Method
R Method
- Method
CNN Method
is O
written O
in O
Python Method
and O
C O
++ O
( O
Caffe O
[ O
reference O
] O
) O
and O
is O
available O
under O
the O
open O
- O
source O
MIT O
License O
at O
https: O
// O
github.com O
/ O
rbgirshick O
/ O
fast Method
- Method
rcnn Method
. O
Fig O
. O
1 O
illustrates O
the O
Fast Method
R Method
- Method
CNN Method
architecture O
. O
A O
Fast Method
R Method
- Method
CNN Method
network O
takes O
as O
input O
an O
entire O
image O
and O
a O
set O
of O
object O
proposals O
. O
The O
network O
first O
processes O
the O
whole O
image O
with O
several O
convolutional Method
( Method
conv Method
) Method
and Method
max Method
pooling Method
layers Method
to O
produce O
a O
conv O
feature O
map O
. O
Then O
, O
for O
each O
object O
proposal O
a O
region O
of O
interest O
( O
RoI Method
) Method
pooling Method
layer Method
extracts O
a O
fixed O
- O
length O
feature O
vector O
from O
the O
feature O
map O
. O
Each O
feature O
vector O
is O
fed O
into O
a O
sequence O
of O
fully Method
connected Method
( Method
fc Method
) Method
layers Method
that O
finally O
branch O
into O
two O
sibling O
output Method
layers Method
: O
one O
that O
produces O
softmax O
probability O
estimates O
over O
K O
object O
classes O
plus O
a O
catch O
- O
all O
" O
background O
" O
class O
and O
another O
layer O
that O
outputs O
four O
real O
- O
valued O
numbers O
for O
each O
of O
the O
K O
object O
classes O
. O
Each O
set O
of O
4 O
values O
encodes O
refined O
bounding O
- O
box O
positions O
for O
one O
of O
the O
K O
classes O
. O
section O
: O
Fast Method
R Method
- Method
CNN Method
architecture O
and O
training O
section O
: O
The O
RoI Method
pooling Method
layer Method
The O
RoI Method
pooling Method
layer Method
uses O
max Method
pooling Method
to O
convert O
the O
features O
inside O
any O
valid O
region O
of O
interest O
into O
a O
small O
feature O
map O
with O
a O
fixed O
spatial O
extent O
of O
H O
× O
W O
( O
e.g. O
, O
7 O
× O
7 O
) O
, O
where O
H O
and O
W O
are O
layer O
hyper O
- O
parameters O
that O
are O
independent O
of O
any O
particular O
RoI. O
In O
this O
paper O
, O
an O
RoI O
is O
a O
rectangular O
window O
into O
a O
conv O
feature O
map O
. O
Each O
RoI O
is O
defined O
by O
a O
four O
- O
tuple O
( O
r O
, O
c O
, O
h O
, O
w O
) O
that O
specifies O
its O
top O
- O
left O
corner O
( O
r O
, O
c O
) O
and O
its O
height O
and O
width O
( O
h O
, O
w O
) O
. O
RoI Method
max Method
pooling Method
works O
by O
dividing O
the O
h O
× O
w O
RoI O
window O
into O
an O
H O
× O
W O
grid O
of O
sub O
- O
windows O
of O
approximate O
size O
h O
/ O
H O
× O
w O
/ O
W O
and O
then O
max O
- O
pooling O
the O
values O
in O
each O
sub O
- O
window O
into O
the O
corresponding O
output O
grid O
cell O
. O
Pooling Method
is O
applied O
independently O
to O
each O
feature O
map O
channel O
, O
as O
in O
standard O
max Method
pooling Method
. O
The O
RoI Method
layer Method
is O
simply O
the O
special O
- O
case O
of O
the O
spatial Method
pyramid Method
pooling Method
layer Method
used O
in O
SPPnets Method
[ O
reference O
] O
in O
which O
there O
is O
only O
one O
pyramid O
level O
. O
We O
use O
the O
pooling Method
sub Method
- Method
window Method
calculation Method
given O
in O
[ O
reference O
] O
. O
section O
: O
Initializing O
from O
pre Method
- Method
trained Method
networks Method
We O
experiment O
with O
three O
pre O
- O
trained O
ImageNet Method
[ Method
reference Method
] Method
networks Method
, O
each O
with O
five O
max Method
pooling Method
layers Method
and O
between O
five O
and O
thirteen O
conv Method
layers Method
( O
see O
Section O
4.1 O
for O
network O
details O
) O
. O
When O
a O
pre Method
- Method
trained Method
network Method
initializes O
a O
Fast Method
R Method
- Method
CNN Method
network O
, O
it O
undergoes O
three O
transformations O
. O
First O
, O
the O
last O
max Method
pooling Method
layer Method
is O
replaced O
by O
a O
RoI Method
pooling Method
layer Method
that O
is O
configured O
by O
setting O
H O
and O
W O
to O
be O
compatible O
with O
the O
net O
's O
first O
fully O
connected O
layer O
( O
e.g. O
, O
H O
= O
W O
= O
7 O
for O
VGG16 Method
) O
. O
Second O
, O
the O
network O
's O
last O
fully O
connected O
layer O
and O
softmax Method
( O
which O
were O
trained O
for O
1000 Task
- Task
way Task
ImageNet Task
classification Task
) O
are O
replaced O
with O
the O
two O
sibling Method
layers Method
described O
earlier O
( O
a O
fully Method
connected Method
layer Method
and O
softmax O
over O
K O
+ O
1 O
categories O
and O
category O
- O
specific O
bounding O
- O
box O
regressors O
) O
. O
Third O
, O
the O
network O
is O
modified O
to O
take O
two O
data O
inputs O
: O
a O
list O
of O
images O
and O
a O
list O
of O
RoIs O
in O
those O
images O
. O
section O
: O
Fine Task
- Task
tuning Task
for O
detection Task
Training O
all O
network Method
weights Method
with O
back Method
- Method
propagation Method
is O
an O
important O
capability O
of O
Fast Method
R Method
- Method
CNN Method
. O
First O
, O
let O
's O
elucidate O
why O
SPPnet Method
is O
unable O
to O
update O
weights O
below O
the O
spatial Method
pyramid Method
pooling Method
layer Method
. O
The O
root O
cause O
is O
that O
back Method
- Method
propagation Method
through O
the O
SPP Method
layer Method
is O
highly O
inefficient O
when O
each O
training O
sample O
( O
i.e. O
RoI O
) O
comes O
from O
a O
different O
image O
, O
which O
is O
exactly O
how O
R Method
- Method
CNN Method
and Method
SPPnet Method
networks Method
are O
trained O
. O
The O
inefficiency O
stems O
from O
the O
fact O
that O
each O
RoI O
may O
have O
a O
very O
large O
receptive O
field O
, O
often O
spanning O
the O
entire O
input O
image O
. O
Since O
the O
forward Method
pass Method
must O
process O
the O
entire O
receptive O
field O
, O
the O
training O
inputs O
are O
large O
( O
often O
the O
entire O
image O
) O
. O
We O
propose O
a O
more O
efficient O
training Method
method Method
that O
takes O
advantage O
of O
feature Method
sharing Method
during O
training Task
. O
In O
Fast Method
R Method
- Method
CNN Method
training O
, O
stochastic Method
gradient Method
descent Method
( Method
SGD Method
) Method
minibatches Method
are O
sampled O
hierarchically O
, O
first O
by O
sampling O
N O
images O
and O
then O
by O
sampling O
R O
/ O
N O
RoIs O
from O
each O
image O
. O
Critically O
, O
RoIs O
from O
the O
same O
image O
share O
computation O
and O
memory O
in O
the O
forward O
and O
backward O
passes O
. O
Making O
N O
small O
decreases O
mini Task
- Task
batch Task
computation Task
. O
For O
example O
, O
when O
using O
N O
= O
2 O
and O
R O
= O
128 O
, O
the O
proposed O
training Method
scheme Method
is O
roughly O
64× O
faster O
than O
sampling O
one O
RoI O
from O
128 O
different O
images O
( O
i.e. O
, O
the O
R Method
- Method
CNN Method
and Method
SPPnet Method
strategy Method
) O
. O
One O
concern O
over O
this O
strategy O
is O
it O
may O
cause O
slow Task
training Task
convergence Task
because O
RoIs O
from O
the O
same O
image O
are O
correlated O
. O
This O
concern O
does O
not O
appear O
to O
be O
a O
practical O
issue O
and O
we O
achieve O
good O
results O
with O
N O
= O
2 O
and O
R O
= O
128 O
using O
fewer O
SGD Method
iterations Method
than O
R Method
- Method
CNN Method
. O
In O
addition O
to O
hierarchical Method
sampling Method
, O
Fast Method
R Method
- Method
CNN Method
uses O
a O
streamlined Method
training Method
process Method
with O
one O
fine Method
- Method
tuning Method
stage Method
that O
jointly O
optimizes O
a O
softmax Method
classifier Method
and O
bounding Method
- Method
box Method
regressors Method
, O
rather O
than O
training O
a O
softmax Method
classifier Method
, O
SVMs Method
, O
and O
regressors Method
in O
three O
separate O
stages O
[ O
reference O
][ O
reference O
] O
. O
The O
components O
of O
this O
procedure O
( O
the O
loss Method
, O
mini Method
- Method
batch Method
sampling Method
strategy Method
, O
back Method
- Method
propagation Method
through O
RoI Method
pooling Method
layers Method
, O
and O
SGD Method
hyper Method
- Method
parameters Method
) O
are O
described O
below O
. O
Multi Task
- Task
task Task
loss Task
. O
A O
Fast Method
R Method
- Method
CNN Method
network O
has O
two O
sibling Method
output Method
layers Method
. O
The O
first O
outputs O
a O
discrete O
probability O
distribution O
( O
per O
RoI O
) O
, O
p O
= O
( O
p O
0 O
, O
. O
. O
. O
, O
p O
K O
) O
, O
over O
K O
+ O
1 O
categories O
. O
As O
usual O
, O
p O
is O
computed O
by O
a O
softmax Method
over O
the O
K O
+ O
1 O
outputs O
of O
a O
fully Method
connected Method
layer Method
. O
The O
second O
sibling O
layer O
outputs O
bounding O
- O
box O
regression O
offsets O
, O
h O
, O
for O
each O
of O
the O
K O
object O
classes O
, O
indexed O
by O
k. O
We O
use O
the O
parameterization O
for O
t O
k O
given O
in O
[ O
reference O
] O
, O
in O
which O
t O
k O
specifies O
a O
scale O
- O
invariant O
translation O
and O
log O
- O
space O
height O
/ O
width O
shift O
relative O
to O
an O
object O
proposal O
. O
Each O
training O
RoI O
is O
labeled O
with O
a O
ground O
- O
truth O
class O
u O
and O
a O
ground O
- O
truth O
bounding O
- O
box O
regression O
target O
v. O
We O
use O
a O
multi Method
- Method
task Method
loss Method
L Method
on O
each O
labeled O
RoI O
to O
jointly O
train O
for O
classification Task
and Task
bounding Task
- Task
box Task
regression Task
: O
in O
which O
L O
cls O
( O
p O
, O
u O
) O
= O
− O
log O
p O
u O
is O
log O
loss O
for O
true O
class O
u. O
The O
second O
task Metric
loss Metric
, O
L Metric
loc Metric
, O
is O
defined O
over O
a O
tuple O
of O
true O
bounding O
- O
box O
regression O
targets O
for O
class O
u O
, O
v O
= O
( O
v O
x O
, O
v O
y O
, O
v O
w O
, O
v O
h O
) O
, O
and O
a O
predicted O
tuple O
t O
u O
= O
( O
t O
in O
which O
is O
a O
robust Metric
L Metric
1 Metric
loss Metric
that O
is O
less O
sensitive O
to O
outliers O
than O
the O
L O
2 O
loss O
used O
in O
R Method
- Method
CNN Method
and O
SPPnet Method
. O
When O
the O
regression O
targets O
are O
unbounded O
, O
training O
with O
L Method
2 Method
loss Method
can O
require O
careful O
tuning O
of O
learning Metric
rates Metric
in O
order O
to O
prevent O
exploding O
gradients O
. O
Eq O
. O
3 O
eliminates O
this O
sensitivity O
. O
The O
hyper O
- O
parameter O
λ O
in O
Eq O
. O
1 O
controls O
the O
balance O
between O
the O
two O
task O
losses O
. O
We O
normalize O
the O
ground O
- O
truth O
regression O
targets O
v O
i O
to O
have O
zero O
mean O
and O
unit O
variance O
. O
All O
experiments O
use O
λ O
= O
1 O
. O
We O
note O
that O
[ O
reference O
] O
uses O
a O
related O
loss Method
to O
train O
a O
classagnostic Method
object Method
proposal Method
network Method
. O
Different O
from O
our O
approach O
, O
[ O
reference O
] O
advocates O
for O
a O
two Method
- Method
network Method
system Method
that O
separates O
localization Task
and Task
classification Task
. O
OverFeat Method
[ O
reference O
] O
, O
R Method
- Method
CNN Method
[ O
reference O
] O
, O
and O
SPPnet Method
[ O
reference O
] O
also O
train O
classifiers Method
and O
bounding Method
- Method
box Method
localizers Method
, O
however O
these O
methods O
use O
stage Method
- Method
wise Method
training Method
, O
which O
we O
show O
is O
suboptimal O
for O
Fast Method
R Method
- Method
CNN Method
( O
Section O
5.1 O
) O
. O
Mini Method
- Method
batch Method
sampling Method
. O
During O
fine Task
- Task
tuning Task
, O
each O
SGD Method
mini Method
- Method
batch Method
is O
constructed O
from O
N O
= O
2 O
images O
, O
chosen O
uniformly O
at O
random O
( O
as O
is O
common O
practice O
, O
we O
actually O
iterate O
over O
permutations O
of O
the O
dataset O
) O
. O
We O
use O
mini O
- O
batches O
of O
size O
R O
= O
128 O
, O
sampling O
64 O
RoIs O
from O
each O
image O
. O
As O
in O
[ O
reference O
] O
, O
we O
take O
25 O
% O
of O
the O
RoIs O
from O
object O
proposals O
that O
have O
intersection O
over O
union O
( O
IoU O
) O
overlap O
with O
a O
groundtruth O
bounding O
box O
of O
at O
least O
0.5 O
. O
These O
RoIs O
comprise O
the O
examples O
labeled O
with O
a O
foreground O
object O
class O
, O
i.e. O
u O
≥ O
1 O
. O
The O
remaining O
RoIs O
are O
sampled O
from O
object O
proposals O
that O
have O
a O
maximum O
IoU O
with O
ground O
truth O
in O
the O
interval O
[ O
0.1 O
, O
0.5 O
) O
, O
following O
[ O
reference O
] O
. O
These O
are O
the O
background O
examples O
and O
are O
labeled O
with O
u O
= O
0 O
. O
The O
lower O
threshold O
of O
0.1 O
appears O
to O
act O
as O
a O
heuristic O
for O
hard O
example O
mining Task
[ O
reference O
] O
. O
During O
training O
, O
images O
are O
horizontally O
flipped O
with O
probability O
0.5 O
. O
No O
other O
data Method
augmentation Method
is O
used O
. O
Back Method
- Method
propagation Method
through O
RoI Method
pooling Method
layers Method
. O
Backpropagation O
routes O
derivatives O
through O
the O
RoI Method
pooling Method
layer Method
. O
For O
clarity O
, O
we O
assume O
only O
one O
image O
per O
mini O
- O
batch O
( O
N O
= O
1 O
) O
, O
though O
the O
extension O
to O
N O
> O
1 O
is O
straightforward O
because O
the O
forward Method
pass Method
treats O
all O
images O
independently O
. O
Let O
x O
i O
∈ O
R O
be O
the O
i O
- O
th O
activation O
input O
into O
the O
RoI Method
pooling Method
layer Method
and O
let O
y O
rj O
be O
the O
layer O
's O
j O
- O
th O
output O
from O
the O
rth O
RoI. O
The O
RoI Method
pooling Method
layer Method
computes O
y O
rj O
= O
x O
i O
* O
( O
r O
, O
j O
) O
, O
in O
which O
i O
* O
( O
r O
, O
j O
) O
= O
argmax O
i O
∈R O
( O
r O
, O
j O
) O
x O
i O
. O
R O
( O
r O
, O
j O
) O
is O
the O
index O
set O
of O
inputs O
in O
the O
sub O
- O
window O
over O
which O
the O
output O
unit O
y O
rj O
max O
pools O
. O
A O
single O
x O
i O
may O
be O
assigned O
to O
several O
different O
outputs O
y O
rj O
. O
The O
RoI Method
pooling Method
layer Method
's Method
backwards Method
function Method
computes O
partial O
derivative O
of O
the O
loss O
function O
with O
respect O
to O
each O
input O
variable O
x O
i O
by O
following O
the O
argmax O
switches O
: O
In O
words O
, O
for O
each O
mini O
- O
batch O
RoI O
r O
and O
for O
each O
pooling O
output O
unit O
y O
rj O
, O
the O
partial O
derivative O
∂L O
/ O
∂y O
rj O
is O
accumulated O
if O
i O
is O
the O
argmax O
selected O
for O
y O
rj O
by O
max Method
pooling Method
. O
In O
back Method
- Method
propagation Method
, O
the O
partial O
derivatives O
∂L O
/ O
∂y O
rj O
are O
already O
computed O
by O
the O
backwards O
function O
of O
the O
layer O
on O
top O
of O
the O
RoI Method
pooling Method
layer Method
. O
SGD Method
hyper Method
- Method
parameters Method
. O
The O
fully Method
connected Method
layers Method
used O
for O
softmax Task
classification Task
and O
bounding Method
- Method
box Method
regression Method
are O
initialized O
from O
zero Method
- Method
mean Method
Gaussian Method
distributions Method
with O
standard O
deviations O
0.01 O
and O
0.001 O
, O
respectively O
. O
Biases O
are O
initialized O
to O
0 O
. O
All O
layers O
use O
a O
per O
- O
layer Metric
learning Metric
rate Metric
of O
1 O
for O
weights O
and O
2 O
for O
biases O
and O
a O
global Metric
learning Metric
rate Metric
of O
0.001 O
. O
When O
training O
on O
VOC07 Material
or O
VOC12 Material
trainval O
we O
run O
SGD Method
for O
30k O
mini O
- O
batch O
iterations O
, O
and O
then O
lower O
the O
learning Metric
rate Metric
to O
0.0001 O
and O
train O
for O
another O
10k O
iterations O
. O
When O
we O
train O
on O
larger O
datasets O
, O
we O
run O
SGD Method
for O
more O
iterations O
, O
as O
described O
later O
. O
A O
momentum O
of O
0.9 O
and O
parameter O
decay O
of O
0.0005 O
( O
on O
weights O
and O
biases O
) O
are O
used O
. O
section O
: O
Scale O
invariance O
We O
explore O
two O
ways O
of O
achieving O
scale O
invariant O
object Task
detection Task
: O
( O
1 O
) O
via O
" Method
brute Method
force Method
" Method
learning Method
and O
( O
2 O
) O
by O
using O
image Method
pyramids Method
. O
These O
strategies O
follow O
the O
two O
approaches O
in O
[ O
reference O
] O
. O
In O
the O
brute Method
- Method
force Method
approach Method
, O
each O
image O
is O
processed O
at O
a O
pre O
- O
defined O
pixel O
size O
during O
both O
training O
and O
testing O
. O
The O
network O
must O
directly O
learn O
scale O
- O
invariant O
object Task
detection Task
from O
the O
training O
data O
. O
The O
multi Method
- Method
scale Method
approach Method
, O
in O
contrast O
, O
provides O
approximate O
scale O
- O
invariance O
to O
the O
network O
through O
an O
image O
pyramid O
. O
At O
test O
- O
time O
, O
the O
image O
pyramid O
is O
used O
to O
approximately O
scale O
- O
normalize O
each O
object O
proposal O
. O
During O
multi Task
- Task
scale Task
training Task
, O
we O
randomly O
sample O
a O
pyramid O
scale O
each O
time O
an O
image O
is O
sampled O
, O
following O
[ O
reference O
] O
, O
as O
a O
form O
of O
data Task
augmentation Task
. O
We O
experiment O
with O
multi Task
- Task
scale Task
training Task
for O
smaller Task
networks Task
only O
, O
due O
to O
GPU O
memory O
limits O
. O
section O
: O
Fast Method
R Method
- Method
CNN Method
detection O
Once O
a O
Fast Method
R Method
- Method
CNN Method
network O
is O
fine O
- O
tuned O
, O
detection Task
amounts O
to O
little O
more O
than O
running O
a O
forward Method
pass Method
( O
assuming O
object O
proposals O
are O
pre O
- O
computed O
) O
. O
The O
network O
takes O
as O
input O
an O
image O
( O
or O
an O
image O
pyramid O
, O
encoded O
as O
a O
list O
of O
images O
) O
and O
a O
list O
of O
R O
object O
proposals O
to O
score O
. O
At O
test O
- O
time O
, O
R O
is O
typically O
around O
2000 O
, O
although O
we O
will O
consider O
cases O
in O
which O
it O
is O
larger O
( O
≈ O
45k O
) O
. O
When O
using O
an O
image O
pyramid O
, O
each O
RoI O
is O
assigned O
to O
the O
scale O
such O
that O
the O
scaled O
RoI O
is O
closest O
to O
224 O
2 O
pixels O
in O
area O
[ O
reference O
] O
. O
For O
each O
test O
RoI O
r O
, O
the O
forward O
pass O
outputs O
a O
class Method
posterior Method
probability Method
distribution Method
p Method
and O
a O
set O
of O
predicted O
bounding O
- O
box O
offsets O
relative O
to O
r O
( O
each O
of O
the O
K O
classes O
gets O
its O
own O
refined O
bounding Method
- Method
box Method
prediction Method
) O
. O
We O
assign O
a O
detection O
confidence O
to O
r O
for O
each O
object O
class O
k O
using O
the O
estimated O
probability O
Pr O
( O
class O
= O
k O
| O
r O
) O
∆ O
= O
p O
k O
. O
We O
then O
perform O
non Method
- Method
maximum Method
suppression Method
independently O
for O
each O
class O
using O
the O
algorithm O
and O
settings O
from O
R Method
- Method
CNN Method
[ O
reference O
] O
. O
section O
: O
Truncated Method
SVD Method
for O
faster Task
detection Task
For O
whole Task
- Task
image Task
classification Task
, O
the O
time O
spent O
computing O
the O
fully O
connected O
layers O
is O
small O
compared O
to O
the O
conv O
layers O
. O
On O
the O
contrary O
, O
for O
detection Task
the O
number O
of O
RoIs O
to O
process O
is O
large O
and O
nearly O
half O
of O
the O
forward Metric
pass Metric
time Metric
is O
spent O
computing O
the O
fully O
connected O
layers O
( O
see O
Fig O
. O
2 O
) O
. O
Large O
fully O
connected O
layers O
are O
easily O
accelerated O
by O
compressing O
them O
with O
truncated Method
SVD Method
[ O
reference O
][ O
reference O
] O
. O
In O
this O
technique O
, O
a O
layer O
parameterized O
by O
the O
u O
× O
v O
weight O
matrix O
W O
is O
approximately O
factorized O
as O
using O
SVD Method
. O
In O
this O
factorization O
, O
U O
is O
a O
u O
× O
t O
matrix O
comprising O
the O
first O
t O
left O
- O
singular O
vectors O
of O
W O
, O
Σ O
t O
is O
a O
t O
× O
t O
diagonal O
matrix O
containing O
the O
top O
t O
singular O
values O
of O
W O
, O
and O
V O
is O
v O
× O
t O
matrix O
comprising O
the O
first O
t O
right O
- O
singular O
vectors O
of O
W O
. O
Truncated Method
SVD Method
reduces O
the O
parameter O
count O
from O
uv O
to O
t O
( O
u O
+ O
v O
) O
, O
which O
can O
be O
significant O
if O
t O
is O
much O
smaller O
than O
min O
( O
u O
, O
v O
) O
. O
To O
compress O
a O
network O
, O
the O
single O
fully O
connected O
layer O
corresponding O
to O
W O
is O
replaced O
by O
two O
fully O
connected O
layers O
, O
without O
a O
non O
- O
linearity O
between O
them O
. O
The O
first O
of O
these O
layers O
uses O
the O
weight O
matrix O
Σ O
t O
V O
T O
( O
and O
no O
biases O
) O
and O
the O
second O
uses O
U O
( O
with O
the O
original O
biases O
associated O
with O
W O
) O
. O
This O
simple O
compression Method
method Method
gives O
good O
speedups O
when O
the O
number O
of O
RoIs O
is O
large O
. O
section O
: O
Main O
results O
Three O
main O
results O
support O
this O
paper O
's O
contributions O
: O
section O
: O
Experimental O
setup O
Our O
experiments O
use O
three O
pre O
- O
trained O
ImageNet Method
models Method
that O
are O
available O
online O
. O
[ O
reference O
] O
The O
first O
is O
the O
CaffeNet Method
( O
essentially O
AlexNet Method
[ O
reference O
] O
) O
from O
R Method
- Method
CNN Method
[ O
reference O
] O
. O
We O
alternatively O
refer O
method O
train O
set O
aero O
bike O
bird O
boat O
bottle O
bus O
car O
cat O
chair O
cow O
Table O
3 O
. O
VOC Metric
2012 Metric
test Metric
detection Metric
average Metric
precision Metric
( O
% O
) O
. O
BabyLearning Method
and O
NUS Method
NIN Method
c2000 Method
use O
networks Method
based O
on O
[ O
reference O
] O
. O
All O
other O
methods O
use O
VGG16 Method
. O
Training O
set O
key O
: O
see O
Table O
2 O
, O
Unk O
. O
: O
unknown O
. O
to O
this O
CaffeNet Method
as O
model O
S O
, O
for O
" O
small O
. O
" O
The O
second O
network O
is O
VGG Method
CNN Method
M Method
1024 Method
from O
[ O
reference O
] O
, O
which O
has O
the O
same O
depth O
as O
S O
, O
but O
is O
wider O
. O
We O
call O
this O
network Method
model Method
M O
, O
for O
" O
medium O
. O
" O
The O
final O
network O
is O
the O
very O
deep Method
VGG16 Method
model Method
from O
[ O
reference O
] O
. O
Since O
this O
model O
is O
the O
largest O
, O
we O
call O
it O
model O
L. O
In O
this O
section O
, O
all O
experiments O
use O
single O
- O
scale O
training O
and O
testing Task
( O
s O
= O
600 O
; O
see O
Section O
5.2 O
for O
details O
) O
. O
section O
: O
VOC O
2010 O
and O
2012 O
results O
On O
these O
datasets O
, O
we O
compare O
Fast Method
R Method
- Method
CNN Method
( O
FRCN Method
, O
for O
short O
) O
against O
the O
top O
methods O
on O
the O
comp4 O
( O
outside O
data O
) O
track O
from O
the O
public O
leaderboard O
( O
Table O
2 O
, O
Table O
3 O
) O
. O
[ O
reference O
] O
For O
the O
NUS Method
NIN Method
c2000 Method
and Method
BabyLearning Method
methods Method
, O
there O
are O
no O
associated O
publications O
at O
this O
time O
and O
we O
could O
not O
find O
exact O
information O
on O
the O
ConvNet Method
architectures Method
used O
; O
they O
are O
variants O
of O
the O
Network Method
- Method
in Method
- Method
Network Method
design Method
[ O
reference O
] O
. O
All O
other O
methods O
are O
initialized O
from O
the O
same O
pre Method
- Method
trained Method
VGG16 Method
network Method
. O
Fast Method
R Method
- Method
CNN Method
achieves O
the O
top O
result O
on O
VOC12 Material
with O
a O
mAP Metric
of O
65.7 O
% O
( O
and O
68.4 O
% O
with O
extra O
data O
) O
. O
It O
is O
also O
two O
orders O
of O
magnitude O
faster O
than O
the O
other O
methods O
, O
which O
are O
all O
based O
on O
the O
" O
slow Method
" Method
R Method
- Method
CNN Method
pipeline Method
. O
On O
VOC10 Material
, O
SegDeepM Method
[ O
reference O
] O
achieves O
a O
higher O
mAP Metric
than O
Fast Method
R Method
- Method
CNN Method
( O
67.2 O
% O
vs. O
66.1 O
% O
) O
. O
SegDeepM Method
is O
trained O
on O
VOC12 Material
trainval O
plus O
segmentation O
annotations O
; O
it O
is O
designed O
to O
boost O
R Metric
- Metric
CNN Metric
accuracy Metric
by O
using O
a O
Markov Method
random Method
field Method
to O
reason O
over O
R Method
- Method
CNN Method
detections Method
and O
segmentations O
from O
the O
O O
2 O
P O
[ O
1 O
] O
semantic Method
- Method
segmentation Method
method Method
. O
Fast Method
R Method
- Method
CNN Method
can O
be O
swapped O
into O
SegDeepM Method
in O
place O
of O
R Method
- Method
CNN Method
, O
which O
may O
lead O
to O
better O
results O
. O
When O
using O
the O
enlarged O
07 O
++ O
12 O
training O
set O
( O
see O
Table O
2 O
caption O
) O
, O
Fast Metric
R Metric
- Metric
CNN Metric
's Metric
mAP Metric
increases O
to O
68.8 O
% O
, O
surpassing O
SegDeepM. Method
section O
: O
VOC Material
2007 Material
results O
On O
VOC07 Material
, O
we O
compare O
Fast Method
R Method
- Method
CNN Method
to O
R Method
- Method
CNN Method
and O
SPPnet Method
. O
All O
methods O
start O
from O
the O
same O
pre Method
- Method
trained Method
VGG16 Method
network Method
and O
use O
bounding Method
- Method
box Method
regression Method
. O
The O
VGG16 Method
SPPnet Method
results O
were O
computed O
by O
the O
authors O
of O
[ O
reference O
] O
. O
SPPnet Method
uses O
five O
scales O
during O
both O
training O
and O
testing O
. O
The O
improvement O
of O
Fast Method
R Method
- Method
CNN Method
over O
SPPnet Method
illustrates O
that O
even O
though O
Fast Method
R Method
- Method
CNN Method
uses O
single Method
- Method
scale Method
training Method
and O
testing Task
, O
fine O
- O
tuning O
the O
conv Method
layers Method
provides O
a O
large O
improvement O
in O
mAP Metric
( O
from O
63.1 O
% O
to O
66.9 O
% O
) O
. O
R Method
- Method
CNN Method
achieves O
a O
mAP Metric
of O
66.0 O
% O
. O
As O
a O
minor O
point O
, O
SPPnet Method
was O
trained O
without O
examples O
marked O
as O
" O
difficult O
" O
in O
PASCAL Material
. O
Removing O
these O
examples O
improves O
Fast O
R Metric
- Metric
CNN Metric
mAP Metric
to O
68.1 O
% O
. O
All O
other O
experiments O
use O
" O
difficult O
" O
examples O
. O
section O
: O
Training Metric
and Metric
testing Metric
time Metric
Fast Metric
training Metric
and Metric
testing Metric
times Metric
are O
our O
second O
main O
result O
. O
Table O
4 O
compares O
training Metric
time Metric
( O
hours O
) O
, O
testing Metric
rate Metric
( O
seconds O
per O
image O
) O
, O
and O
mAP Metric
on O
VOC07 Material
between O
Fast Method
R Method
- Method
CNN Method
, O
R Method
- Method
CNN Method
, O
and O
SPPnet Method
. O
For O
VGG16 Method
, O
Fast Method
R Method
- Method
CNN Method
processes O
images O
146× O
faster O
than O
R Method
- Method
CNN Method
without O
truncated Method
SVD Method
and O
213× O
faster O
with O
it O
. O
Training Metric
time Metric
is O
reduced O
by O
9× O
, O
from O
84 O
hours O
to O
9.5 O
. O
Compared O
to O
SPPnet Method
, O
Fast Method
R Method
- Method
CNN Method
trains O
VGG16 Method
2.7× O
faster O
( O
in O
9.5 O
vs. O
25.5 O
hours O
) O
and O
tests O
7× O
faster O
without O
truncated Method
SVD Method
or O
10× O
faster O
with O
it O
. O
Fast Method
R Method
- Method
CNN Method
also O
eliminates O
hundreds O
of O
gigabytes O
of O
disk O
storage O
, O
because O
it O
does O
not O
cache O
features O
. O
Table O
4 O
. O
Runtime Metric
comparison O
between O
the O
same O
models O
in O
Fast Method
R Method
- Method
CNN Method
, O
R Method
- Method
CNN Method
, O
and O
SPPnet Method
. O
Fast Method
R Method
- Method
CNN Method
uses O
single Method
- Method
scale Method
mode Method
. O
SPPnet Method
uses O
the O
five O
scales O
specified O
in O
[ O
reference O
] O
. O
† O
Timing O
provided O
by O
the O
authors O
of O
[ O
reference O
] O
. O
Times O
were O
measured O
on O
an O
Nvidia Method
K40 Method
GPU Method
. O
Truncated Method
SVD Method
. O
Truncated Method
SVD Method
can O
reduce O
detection Metric
time Metric
by O
more O
than O
30 O
% O
with O
only O
a O
small O
( O
0.3 O
percentage O
point O
) O
drop O
in O
mAP Metric
and O
without O
needing O
to O
perform O
additional O
fine Method
- Method
tuning Method
after O
model Method
compression Method
. O
Forward Method
pass Method
timing Method
( O
SVD Method
) O
mAP Metric
66.6 O
% O
@ O
223ms O
/ O
image O
Figure O
2 O
. O
Timing O
for O
VGG16 O
before O
and O
after O
truncated Method
SVD Method
. O
Before O
SVD Method
, O
fully Method
connected Method
layers Method
fc6 Method
and O
fc7 Method
take O
45 O
% O
of O
the O
time O
. O
section O
: O
Which O
layers O
to O
fine O
- O
tune O
? O
For O
the O
less O
deep Method
networks Method
considered O
in O
the O
SPPnet O
paper O
[ O
reference O
] O
, O
fine O
- O
tuning O
only O
the O
fully O
connected O
layers O
appeared O
to O
be O
sufficient O
for O
good O
accuracy Metric
. O
We O
hypothesized O
that O
this O
result O
would O
not O
hold O
for O
very O
deep Task
networks Task
. O
To O
validate O
that O
fine O
- O
tuning O
the O
conv Method
layers Method
is O
important O
for O
VGG16 Task
, O
we O
use O
Fast Method
R Method
- Method
CNN Method
to O
fine O
- O
tune O
, O
but O
freeze O
the O
thirteen O
conv Method
layers Method
so O
that O
only O
the O
fully O
connected O
layers O
learn O
. O
This O
ablation O
emulates O
single Method
- Method
scale Method
SPPnet Method
training Method
and O
decreases O
mAP Metric
from O
66.9 O
% O
to O
61.4 O
% O
( O
Table O
5 O
) O
. O
This O
experiment O
verifies O
our O
hypothesis O
: O
training O
through O
the O
RoI Method
pooling Method
layer Method
is O
important O
for O
very O
deep Method
nets Method
. O
Table O
5 O
. O
Effect O
of O
restricting O
which O
layers O
are O
fine O
- O
tuned O
for O
VGG16 Method
. O
Fine Method
- Method
tuning Method
≥ O
fc6 Method
emulates O
the O
SPPnet Method
training Method
algorithm Method
[ O
reference O
] O
, O
but O
using O
a O
single O
scale O
. O
SPPnet Method
L Method
results O
were O
obtained O
using O
five O
scales O
, O
at O
a O
significant O
( O
7× O
) O
speed Metric
cost Metric
. O
Does O
this O
mean O
that O
all O
conv O
layers O
should O
be O
fine O
- O
tuned O
? O
In O
short O
, O
no O
. O
In O
the O
smaller O
networks O
( O
S O
and O
M O
) O
we O
find O
that O
conv1 Method
is O
generic O
and O
task O
independent O
( O
a O
well O
- O
known O
fact O
[ O
reference O
] O
) O
. O
Allowing O
conv1 O
to O
learn O
, O
or O
not O
, O
has O
no O
meaningful O
effect O
on O
mAP Metric
. O
For O
VGG16 Method
, O
we O
found O
it O
only O
necessary O
to O
update O
layers O
from O
conv3 O
1 O
and O
up O
( O
9 O
of O
the O
13 O
conv O
layers O
) O
. O
This O
observation O
is O
pragmatic O
: O
( O
1 O
) O
updating O
from O
conv2 Method
1 Method
slows O
training Task
by O
1.3× O
( O
12.5 O
vs. O
9.5 O
hours O
) O
compared O
to O
learning O
from O
conv3 O
1 O
; O
and O
( O
2 O
) O
updating O
from O
conv1 O
1 O
over O
- O
runs O
GPU O
memory O
. O
The O
difference O
in O
mAP Metric
when O
learning O
from O
conv2 O
1 O
up O
was O
only O
+ O
0.3 O
points O
( O
Table O
5 O
, O
last O
column O
) O
. O
All O
Fast Method
R Method
- Method
CNN Method
results O
in O
this O
paper O
using O
VGG16 Method
fine O
- O
tune O
layers O
conv3 O
1 O
and O
up O
; O
all O
experiments O
with O
models O
S O
and O
M O
fine O
- O
tune O
layers Method
conv2 Method
and O
up O
. O
section O
: O
Design O
evaluation O
We O
conducted O
experiments O
to O
understand O
how O
Fast Method
R Method
- Method
CNN Method
compares O
to O
R Method
- Method
CNN Method
and O
SPPnet Method
, O
as O
well O
as O
to O
evaluate O
design O
decisions O
. O
Following O
best O
practices O
, O
we O
performed O
these O
experiments O
on O
the O
PASCAL O
VOC07 Material
dataset O
. O
section O
: O
Does O
multi Task
- Task
task Task
training Task
help O
? O
Multi Task
- Task
task Task
training Task
is O
convenient O
because O
it O
avoids O
managing O
a O
pipeline Task
of Task
sequentially Task
- Task
trained Task
tasks Task
. O
But O
it O
also O
has O
the O
potential O
to O
improve O
results O
because O
the O
tasks O
influence O
each O
other O
through O
a O
shared Method
representation Method
( O
the O
ConvNet Method
) O
[ O
reference O
] O
. O
Does O
multi Method
- Method
task Method
training Method
improve O
object Task
detection Task
accuracy O
in O
Fast Method
R Method
- Method
CNN Method
? O
To O
test O
this O
question O
, O
we O
train O
baseline Method
networks Method
that O
use O
only O
the O
classification O
loss O
, O
L O
cls O
, O
in O
Eq O
. O
1 O
( O
i.e. O
, O
setting O
Table O
6 O
. O
Multi Method
- Method
task Method
training Method
( O
forth O
column O
per O
group O
) O
improves O
mAP Metric
over O
piecewise Method
training Method
( O
third O
column O
per O
group O
) O
. O
λ O
= O
0 O
) O
. O
These O
baselines O
are O
printed O
for O
models O
S O
, O
M O
, O
and O
L O
in O
the O
first O
column O
of O
each O
group O
in O
Table O
6 O
. O
Note O
that O
these O
models O
do O
not O
have O
bounding Method
- Method
box Method
regressors Method
. O
Next O
( O
second O
column O
per O
group O
) O
, O
we O
take O
networks O
that O
were O
trained O
with O
the O
multi O
- O
task O
loss O
( O
Eq O
. O
1 O
, O
λ O
= O
1 O
) O
, O
but O
we O
disable O
boundingbox Method
regression Method
at O
test O
time O
. O
This O
isolates O
the O
networks O
' O
classification Metric
accuracy Metric
and O
allows O
an O
apples O
- O
to O
- O
apples O
comparison O
with O
the O
baseline O
networks O
. O
Across O
all O
three O
networks O
we O
observe O
that O
multi Method
- Method
task Method
training Method
improves O
pure Metric
classification Metric
accuracy Metric
relative O
to O
training O
for O
classification Task
alone O
. O
The O
improvement O
ranges O
from O
+ O
0.8 O
to O
+ O
1.1 O
mAP Metric
points O
, O
showing O
a O
consistent O
positive O
effect O
from O
multi Method
- Method
task Method
learning Method
. O
Finally O
, O
we O
take O
the O
baseline O
models O
( O
trained O
with O
only O
the O
classification O
loss O
) O
, O
tack O
on O
the O
bounding Method
- Method
box Method
regression Method
layer Method
, O
and O
train O
them O
with O
L Method
loc Method
while O
keeping O
all O
other O
network O
parameters O
frozen O
. O
The O
third O
column O
in O
each O
group O
shows O
the O
results O
of O
this O
stage Method
- Method
wise Method
training Method
scheme Method
: O
mAP Metric
improves O
over O
column O
one O
, O
but O
stage Method
- Method
wise Method
training Method
underperforms O
multi Method
- Method
task Method
training Method
( O
forth O
column O
per O
group O
) O
. O
section O
: O
Scale Task
invariance Task
: O
to O
brute O
force O
or O
finesse O
? O
We O
compare O
two O
strategies O
for O
achieving O
scale O
- O
invariant O
object Task
detection Task
: O
brute Method
- Method
force Method
learning Method
( O
single O
scale O
) O
and O
image Method
pyramids Method
( O
multi O
- O
scale O
) O
. O
In O
either O
case O
, O
we O
define O
the O
scale O
s O
of O
an O
image O
to O
be O
the O
length O
of O
its O
shortest O
side O
. O
All O
single O
- O
scale O
experiments O
use O
s O
= O
600 O
pixels O
; O
s O
may O
be O
less O
than O
600 O
for O
some O
images O
as O
we O
cap O
the O
longest O
image O
side O
at O
1000 O
pixels O
and O
maintain O
the O
image O
's O
aspect O
ratio O
. O
These O
values O
were O
selected O
so O
that O
VGG16 Method
fits O
in O
GPU O
memory O
during O
fine Task
- Task
tuning Task
. O
The O
smaller O
models O
are O
not O
memory O
bound O
and O
can O
benefit O
from O
larger O
values O
of O
s O
; O
however O
, O
optimizing O
s O
for O
each O
model O
is O
not O
our O
main O
concern O
. O
We O
note O
that O
PASCAL Material
images Material
are O
384 O
× O
473 O
pixels O
on O
average O
and O
thus O
the O
single O
- O
scale Method
setting Method
typically O
upsamples O
images O
by O
a O
factor O
of O
1.6 O
. O
The O
average O
effective O
stride O
at O
the O
RoI Method
pooling Method
layer Method
is O
thus O
≈ O
10 O
pixels O
. O
In O
the O
multi Task
- Task
scale Task
setting Task
, O
we O
use O
the O
same O
five O
scales O
specified O
in O
[ O
reference O
] O
( O
s O
∈ O
{ O
480 O
, O
576 O
, O
688 O
, O
864 O
, O
1200 O
} O
) O
to O
facilitate O
comparison O
with O
SPPnet Method
. O
However O
, O
we O
cap O
the O
longest O
side O
at O
2000 O
pixels O
to O
avoid O
exceeding O
GPU O
memory O
. O
Table O
7 O
shows O
models O
S O
and O
M O
when O
trained O
and O
tested O
with O
either O
one O
or O
five O
scales O
. O
Perhaps O
the O
most O
surprising O
result O
in O
[ O
reference O
] O
was O
that O
single O
- O
scale Method
detection Method
performs O
almost O
as O
well O
as O
multi Method
- Method
scale Method
detection Method
. O
Our O
findings O
con O
- O
Table O
7 O
. O
Multi O
- O
scale O
vs. O
single O
scale O
. O
SPPnet Method
ZF Method
( O
similar O
to O
model O
S O
) O
results O
are O
from O
[ O
reference O
] O
. O
Larger O
networks O
with O
a O
single O
- O
scale O
offer O
the O
best O
speed Metric
/ Metric
accuracy Metric
tradeoff Metric
. O
( O
L O
can O
not O
use O
multi O
- O
scale O
in O
our O
implementation O
due O
to O
GPU O
memory O
constraints O
. O
) O
firm O
their O
result O
: O
deep Method
ConvNets Method
are O
adept O
at O
directly O
learning Task
scale Task
invariance Task
. O
The O
multi Method
- Method
scale Method
approach Method
offers O
only O
a O
small O
increase O
in O
mAP Metric
at O
a O
large O
cost O
in O
compute Metric
time Metric
( O
Table O
7 O
) O
. O
In O
the O
case O
of O
VGG16 Method
( O
model O
L O
) O
, O
we O
are O
limited O
to O
using O
a O
single O
scale O
by O
implementation O
details O
. O
Yet O
it O
achieves O
a O
mAP Metric
of O
66.9 O
% O
, O
which O
is O
slightly O
higher O
than O
the O
66.0 O
% O
reported O
for O
R Method
- Method
CNN Method
[ O
reference O
] O
, O
even O
though O
R Method
- Method
CNN Method
uses O
" O
infinite O
" O
scales O
in O
the O
sense O
that O
each O
proposal O
is O
warped O
to O
a O
canonical O
size O
. O
Since O
single Method
- Method
scale Method
processing Method
offers O
the O
best O
tradeoff O
between O
speed Metric
and O
accuracy Metric
, O
especially O
for O
very O
deep Method
models Method
, O
all O
experiments O
outside O
of O
this O
sub O
- O
section O
use O
single O
- O
scale Method
training Method
and O
testing O
with O
s O
= O
600 O
pixels O
. O
section O
: O
Do O
we O
need O
more O
training O
data O
? O
A O
good O
object Method
detector Method
should O
improve O
when O
supplied O
with O
more O
training O
data O
. O
Zhu O
et O
al O
. O
[ O
reference O
] O
found O
that O
DPM Method
[ O
reference O
] O
mAP Metric
saturates O
after O
only O
a O
few O
hundred O
to O
thousand O
training O
examples O
. O
Here O
we O
augment O
the O
VOC07 Material
trainval Material
set Material
with O
the O
VOC12 Material
trainval O
set O
, O
roughly O
tripling O
the O
number O
of O
images O
to O
16.5k O
, O
to O
evaluate O
Fast Method
R Method
- Method
CNN Method
. O
Enlarging O
the O
training O
set O
improves O
mAP Metric
on O
VOC07 Material
test Material
from O
66.9 O
% O
to O
70.0 O
% O
( O
Table O
1 O
) O
. O
When O
training O
on O
this O
dataset O
we O
use O
60k O
mini O
- O
batch O
iterations O
instead O
of O
40k O
. O
We O
perform O
similar O
experiments O
for O
VOC10 Material
and O
2012 Material
, O
for O
which O
we O
construct O
a O
dataset O
of O
21.5k O
images O
from O
the O
union Material
of Material
VOC07 Material
trainval Material
, O
test Material
, O
and O
VOC12 Material
trainval O
. O
When O
training O
on O
this O
dataset O
, O
we O
use O
100k O
SGD Method
iterations Method
and O
lower O
the O
learning Metric
rate Metric
by O
0.1× O
each O
40k O
iterations O
( O
instead O
of O
each O
30k O
) O
. O
For O
VOC10 Material
and O
2012 O
, O
mAP Metric
improves O
from O
66.1 O
% O
to O
68.8 O
% O
and O
from O
65.7 O
% O
to O
68.4 O
% O
, O
respectively O
. O
section O
: O
Do O
SVMs Method
outperform O
softmax Method
? O
Fast Method
R Method
- Method
CNN Method
uses O
the O
softmax Method
classifier Method
learnt O
during O
fine Method
- Method
tuning Method
instead O
of O
training O
one Method
- Method
vs Method
- Method
rest Method
linear Method
SVMs Method
post O
- O
hoc O
, O
as O
was O
done O
in O
R Method
- Method
CNN Method
and O
SPPnet Method
. O
To O
understand O
the O
impact O
of O
this O
choice O
, O
we O
implemented O
post Method
- Method
hoc Method
SVM Method
training Method
with O
hard Method
negative Method
mining Method
in O
Fast Method
R Method
- Method
CNN Method
. O
We O
use O
the O
same O
training Method
algorithm Method
and O
hyper O
- O
parameters O
as O
in O
R Method
- Method
CNN Method
. O
Table O
8 O
shows O
softmax Method
slightly O
outperforming O
SVM Method
for O
all O
three O
networks O
, O
by O
+ O
0.1 O
to O
+ O
0.8 O
mAP Metric
points O
. O
This O
effect O
is O
small O
, O
but O
it O
demonstrates O
that O
" O
one Method
- Method
shot Method
" Method
fine Method
- Method
tuning Method
is O
sufficient O
compared O
to O
previous O
multi Method
- Method
stage Method
training Method
approaches Method
. O
We O
note O
that O
softmax Method
, O
unlike O
one Method
- Method
vs Method
- Method
rest Method
SVMs Method
, O
introduces O
competition O
between O
classes O
when O
scoring O
a O
RoI. O
section O
: O
Are O
more O
proposals O
always O
better O
? O
There O
are O
( O
broadly O
) O
two O
types O
of O
object Method
detectors Method
: O
those O
that O
use O
a O
sparse O
set O
of O
object O
proposals O
( O
e.g. O
, O
selective Method
search Method
[ O
reference O
] O
) O
and O
those O
that O
use O
a O
dense O
set O
( O
e.g. O
, O
DPM Method
[ O
reference O
] O
) O
. O
Classifying Task
sparse Task
proposals Task
is O
a O
type O
of O
cascade Method
[ O
reference O
] O
in O
which O
the O
proposal Method
mechanism Method
first O
rejects O
a O
vast O
number O
of O
candidates O
leaving O
the O
classifier Method
with O
a O
small O
set O
to O
evaluate O
. O
This O
cascade O
improves O
detection Metric
accuracy Metric
when O
applied O
to O
DPM Task
detections Task
[ O
reference O
] O
. O
We O
find O
evidence O
that O
the O
proposalclassifier Method
cascade Method
also O
improves O
Fast Metric
R Metric
- Metric
CNN Metric
accuracy Metric
. O
Using O
selective Method
search Method
's O
quality O
mode O
, O
we O
sweep O
from O
1k O
to O
10k O
proposals O
per O
image O
, O
each O
time O
re O
- O
training O
and O
retesting Method
model Method
M. O
If O
proposals O
serve O
a O
purely O
computational O
role O
, O
increasing O
the O
number O
of O
proposals O
per O
image O
should O
not O
harm O
mAP Metric
. O
We O
find O
that O
mAP Metric
rises O
and O
then O
falls O
slightly O
as O
the O
proposal O
count O
increases O
( O
Fig O
. O
3 O
, O
solid O
blue O
line O
) O
. O
This O
experiment O
shows O
that O
swamping O
the O
deep Method
classifier Method
with O
more O
proposals O
does O
not O
help O
, O
and O
even O
slightly O
hurts O
, O
accuracy Metric
. O
This O
result O
is O
difficult O
to O
predict O
without O
actually O
running O
the O
experiment O
. O
The O
state O
- O
of O
- O
the O
- O
art O
for O
measuring O
object Metric
proposal Metric
quality Metric
is O
Average Metric
Recall Metric
( O
AR Metric
) O
[ O
reference O
] O
. O
AR Metric
correlates O
well O
with O
mAP Metric
for O
several O
proposal Method
methods Method
using O
R Method
- Method
CNN Method
, O
when O
using O
a O
fixed O
number O
of O
proposals O
per O
image O
. O
Fig O
. O
3 O
shows O
that O
AR Metric
( O
solid O
red O
line O
) O
does O
not O
correlate O
well O
with O
mAP Metric
as O
the O
number O
of O
proposals O
per O
image O
is O
varied O
. O
AR Metric
must O
be O
used O
with O
care O
; O
higher O
AR Metric
due O
to O
more O
proposals O
does O
not O
imply O
that O
mAP Metric
will O
increase O
. O
Fortunately O
, O
training O
and O
testing O
with O
model Method
M Method
takes O
less O
than O
2.5 O
hours O
. O
Fast Method
R Method
- Method
CNN Method
thus O
enables O
efficient O
, O
direct Metric
evaluation Metric
of Metric
object Metric
proposal Metric
mAP Metric
, O
which O
is O
preferable O
to O
proxy Metric
metrics Metric
. O
We O
also O
investigate O
Fast Method
R Method
- Method
CNN Method
when O
using O
densely O
generated O
boxes O
( O
over O
scale O
, O
position O
, O
and O
aspect O
ratio O
) O
, O
at O
a O
rate O
of O
about O
45k O
boxes O
/ O
image O
. O
This O
dense O
set O
is O
rich O
enough O
that O
when O
each O
selective O
search O
box O
is O
replaced O
by O
its O
closest O
( O
in O
IoU O
) O
dense O
box O
, O
mAP Metric
drops O
only O
1 O
point O
( O
to O
57.7 O
% O
, O
Fig O
. O
3 O
, O
blue O
triangle O
) O
. O
The O
statistics O
of O
the O
dense O
boxes O
differ O
from O
those O
of O
selective O
search O
boxes O
. O
Starting O
with O
2k O
selective O
search O
boxes O
, O
we O
test O
mAP Metric
when O
adding O
a O
random O
sample O
of O
1000 O
× O
{ O
2 O
, O
4 O
, O
6 O
, O
8 O
, O
10 O
, O
32 O
, O
45 O
} O
dense O
boxes O
. O
For O
each O
experiment O
we O
re O
- O
train O
and O
re O
- O
test O
model O
M. O
When O
these O
dense O
boxes O
are O
added O
, O
mAP Metric
falls O
more O
strongly O
than O
when O
adding O
more O
selective O
search O
boxes O
, O
eventually O
reaching O
53.0 O
% O
. O
We O
also O
train O
and O
test O
Fast Method
R Method
- Method
CNN Method
using O
only O
dense O
boxes O
( O
45k O
/ O
image O
) O
. O
This O
setting O
yields O
a O
mAP Metric
of O
52.9 O
% O
( O
blue O
diamond O
) O
. O
Finally O
, O
we O
check O
if O
SVMs Method
with O
hard Method
negative Method
mining Method
are O
needed O
to O
cope O
with O
the O
dense O
box O
distribution O
. O
SVMs Method
do O
even O
worse O
: O
49.3 O
% O
( O
blue O
circle O
) O
. O
section O
: O
Preliminary O
MS Material
COCO Material
results O
We O
applied O
Fast Method
R Method
- Method
CNN Method
( O
with O
VGG16 Method
) O
to O
the O
MS Material
COCO Material
dataset Material
[ O
reference O
] O
to O
establish O
a O
preliminary O
baseline O
. O
We O
trained O
on O
the O
80k O
image O
training O
set O
for O
240k O
iterations O
and O
evaluated O
on O
the O
" O
test O
- O
dev O
" O
set O
using O
the O
evaluation O
server O
. O
The O
PASCAL Metric
- Metric
style Metric
mAP Metric
is O
35.9 O
% O
; O
the O
new O
COCO Method
- Method
style Method
AP Method
, O
which O
also O
averages O
over O
IoU O
thresholds O
, O
is O
19.7 O
% O
. O
section O
: O
Conclusion O
This O
paper O
proposes O
Fast Method
R Method
- Method
CNN Method
, O
a O
clean O
and O
fast O
update O
to O
R Method
- Method
CNN Method
and O
SPPnet Method
. O
In O
addition O
to O
reporting O
state O
- O
of O
- O
theart O
detection Task
results O
, O
we O
present O
detailed O
experiments O
that O
we O
hope O
provide O
new O
insights O
. O
Of O
particular O
note O
, O
sparse O
object O
proposals O
appear O
to O
improve O
detector Metric
quality Metric
. O
This O
issue O
was O
too O
costly O
( O
in O
time O
) O
to O
probe O
in O
the O
past O
, O
but O
becomes O
practical O
with O
Fast Method
R Method
- Method
CNN Method
. O
Of O
course O
, O
there O
may O
exist O
yet O
undiscovered O
techniques O
that O
allow O
dense O
boxes O
to O
perform O
as O
well O
as O
sparse O
proposals O
. O
Such O
methods O
, O
if O
developed O
, O
may O
help O
further O
accelerate O
object Task
detection Task
. O
section O
: O
section O
: O
Acknowledgements O
. O
I O
thank O
Kaiming O
He O
, O
Larry O
Zitnick O
, O
and O
Piotr O
Dollár O
for O
helpful O
discussions O
and O
encouragement O
. O
section O
: O
