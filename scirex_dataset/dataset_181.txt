document	O
:	O
Random	Method
Erasing	Method
Data	O
Augmentation	O
In	O
this	O
paper	O
,	O
we	O
introduce	O
Random	Method
Erasing	Method
,	O
a	O
new	O
data	Method
augmentation	Method
method	Method
for	O
training	O
the	O
convolutional	Method
neural	Method
network	Method
(	O
CNN	Method
)	O
.	O
In	O
training	O
,	O
Random	Method
Erasing	Method
randomly	O
selects	O
a	O
rectangle	O
region	O
in	O
an	O
image	O
and	O
erases	O
its	O
pixels	O
with	O
random	O
values	O
.	O
In	O
this	O
process	O
,	O
training	O
images	O
with	O
various	O
levels	O
of	O
occlusion	O
are	O
generated	O
,	O
which	O
reduces	O
the	O
risk	O
of	O
over	Task
-	Task
fitting	Task
and	O
makes	O
the	O
model	O
robust	O
to	O
occlusion	O
.	O
Random	Method
Erasing	Method
is	O
parameter	Method
learning	Method
free	O
,	O
easy	O
to	O
implement	O
,	O
and	O
can	O
be	O
integrated	O
with	O
most	O
of	O
the	O
CNN	Method
-	O
based	O
recognition	O
models	O
.	O
Albeit	O
simple	O
,	O
Random	Method
Erasing	Method
is	O
complementary	O
to	O
commonly	O
used	O
data	Method
augmentation	Method
techniques	Method
such	O
as	O
random	Method
cropping	Method
and	O
flipping	Method
,	O
and	O
yields	O
consistent	O
improvement	O
over	O
strong	O
baselines	O
in	O
image	Task
classification	Task
,	O
object	Task
detection	Task
and	O
person	Task
re	Task
-	Task
identification	Task
.	O
Code	O
is	O
available	O
at	O
:	O
.	O
section	O
:	O
Introduction	O
The	O
ability	O
to	O
generalize	O
is	O
a	O
research	O
focus	O
for	O
the	O
convolutional	Method
neural	Method
network	Method
(	O
CNN	Method
)	O
.	O
When	O
a	O
model	O
is	O
excessively	O
complex	O
,	O
such	O
as	O
having	O
too	O
many	O
parameters	O
compared	O
to	O
the	O
number	O
of	O
training	O
samples	O
,	O
over	O
-	O
fitting	O
might	O
happen	O
and	O
weaken	O
its	O
generalization	Metric
ability	Metric
.	O
A	O
learned	Method
model	Method
may	O
describe	O
random	O
error	O
or	O
noise	O
instead	O
of	O
the	O
underlying	O
data	O
distribution	O
.	O
In	O
bad	O
cases	O
,	O
the	O
CNN	Method
model	O
may	O
exhibit	O
good	O
performance	O
on	O
the	O
training	O
data	O
,	O
but	O
fail	O
drastically	O
when	O
predicting	O
new	O
data	O
.	O
To	O
improve	O
the	O
generalization	Metric
ability	Metric
of	O
CNNs	Method
,	O
many	O
data	Method
augmentation	Method
and	O
regularization	Method
approaches	Method
have	O
been	O
proposed	O
,	O
such	O
as	O
random	Method
cropping	Method
,	O
flipping	Method
,	O
dropout	Method
,	O
and	O
batch	Method
normalization	Method
.	O
Occlusion	Method
is	O
a	O
critical	O
influencing	O
factor	O
on	O
the	O
generalization	Metric
ability	Metric
of	O
CNNs	Method
.	O
It	O
is	O
desirable	O
that	O
invariance	O
to	O
various	O
levels	O
of	O
occlusion	O
is	O
achieved	O
.	O
When	O
some	O
parts	O
of	O
an	O
object	O
are	O
occluded	O
,	O
a	O
strong	O
classification	Method
model	Method
should	O
be	O
able	O
to	O
recognize	O
its	O
category	O
from	O
the	O
overall	O
object	O
structure	O
.	O
However	O
,	O
the	O
collected	O
training	O
samples	O
usually	O
exhibit	O
limited	O
variance	O
in	O
occlusion	O
.	O
In	O
an	O
extreme	O
case	O
when	O
all	O
the	O
training	O
objects	O
are	O
clearly	O
visible	O
,	O
i.e.	O
,	O
no	O
occlusion	O
happens	O
,	O
the	O
learned	O
CNN	Method
will	O
probably	O
work	O
well	O
on	O
testing	O
images	O
without	O
occlusion	O
,	O
but	O
,	O
due	O
to	O
the	O
limited	O
generalization	Metric
ability	Metric
of	O
the	O
CNN	Method
model	O
,	O
may	O
fail	O
to	O
recognize	O
objects	O
which	O
are	O
partially	O
occluded	O
.	O
While	O
we	O
can	O
manually	O
add	O
occluded	O
natural	O
images	O
to	O
the	O
training	O
set	O
,	O
it	O
is	O
costly	O
and	O
the	O
levels	O
of	O
occlusion	O
might	O
be	O
limited	O
.	O
To	O
address	O
the	O
occlusion	Task
problem	Task
and	O
improve	O
the	O
generalization	Metric
ability	Metric
of	O
CNNs	Method
,	O
this	O
paper	O
introduces	O
a	O
new	O
data	Method
augmentation	Method
approach	Method
,	O
Random	Method
Erasing	Method
.	O
It	O
can	O
be	O
easily	O
implemented	O
in	O
most	O
existing	O
CNN	Method
models	O
.	O
In	O
the	O
training	O
phase	O
,	O
an	O
image	O
within	O
a	O
mini	O
-	O
batch	O
randomly	O
undergoes	O
either	O
of	O
the	O
two	O
operations	O
:	O
1	O
)	O
kept	O
unchanged	O
;	O
2	O
)	O
we	O
randomly	O
choose	O
a	O
rectangle	O
region	O
of	O
an	O
arbitrary	O
size	O
,	O
and	O
assign	O
the	O
pixels	O
within	O
the	O
selected	O
region	O
with	O
random	O
values	O
(	O
or	O
the	O
ImageNet	O
mean	O
pixel	O
value	O
)	O
.	O
During	O
Operation	O
2	O
)	O
,	O
an	O
image	O
is	O
partially	O
occluded	O
in	O
a	O
random	O
position	O
with	O
a	O
random	O
-	O
sized	O
mask	O
.	O
In	O
this	O
manner	O
,	O
augmented	O
images	O
with	O
various	O
occlusion	O
levels	O
can	O
be	O
generated	O
.	O
Examples	O
of	O
Random	Method
Erasing	Method
are	O
shown	O
in	O
Fig	O
.	O
[	O
reference	O
]	O
.	O
Two	O
commonly	O
used	O
data	Method
augmentation	Method
approaches	O
,	O
i.e.	O
,	O
random	Method
flipping	Method
and	O
random	Method
cropping	Method
,	O
also	O
work	O
on	O
the	O
image	O
level	O
and	O
are	O
closely	O
related	O
to	O
Random	Method
Erasing	Method
.	O
Both	O
techniques	O
have	O
demonstrated	O
the	O
ability	O
to	O
improve	O
the	O
image	Metric
recognition	Metric
accuracy	Metric
.	O
In	O
comparison	O
with	O
Random	Method
Erasing	Method
,	O
random	Method
flipping	Method
does	O
not	O
incur	O
information	O
loss	O
during	O
augmentation	Task
.	O
Different	O
from	O
random	Method
cropping	Method
,	O
in	O
Random	Method
Erasing	Method
,	O
1	O
)	O
only	O
part	O
of	O
the	O
object	O
is	O
occluded	O
and	O
the	O
overall	O
object	O
structure	O
is	O
preserved	O
,	O
2	O
)	O
pixels	O
of	O
the	O
erased	O
region	O
are	O
re	O
-	O
assigned	O
with	O
random	O
values	O
,	O
which	O
can	O
be	O
viewed	O
as	O
adding	O
block	O
noise	O
to	O
the	O
image	O
.	O
Working	O
primarily	O
on	O
the	O
fully	Method
connected	Method
(	O
FC	Method
)	O
layer	O
,	O
Dropout	Method
is	O
also	O
related	O
to	O
our	O
method	O
.	O
It	O
prevents	O
over	Task
-	Task
fitting	Task
by	O
discarding	O
(	O
both	O
hidden	O
and	O
visible	O
)	O
units	O
of	O
the	O
CNN	Method
with	O
a	O
probability	O
.	O
Random	Method
Erasing	Method
is	O
somewhat	O
similar	O
to	O
performing	O
Dropout	Method
on	O
the	O
image	O
level	O
.	O
The	O
difference	O
is	O
that	O
in	O
Random	Method
Erasing	Method
,	O
1	O
)	O
we	O
operate	O
on	O
a	O
continuous	O
rectangular	O
region	O
,	O
2	O
)	O
no	O
pixels	O
(	O
units	O
)	O
are	O
discarded	O
,	O
and	O
3	O
)	O
we	O
focus	O
on	O
making	O
the	O
model	O
more	O
robust	O
to	O
noise	O
and	O
occlusion	O
.	O
The	O
recent	O
A	O
-	O
Fast	Method
-	Method
RCNN	Method
proposes	O
an	O
occlusion	Method
invariant	Method
object	Method
detector	Method
by	O
training	O
an	O
adversarial	Method
network	Method
that	O
generates	O
examples	O
with	O
occlusion	O
.	O
Comparison	O
with	O
A	O
-	O
Fast	Method
-	Method
RCNN	Method
,	O
Random	Method
Erasing	Method
does	O
not	O
require	O
any	O
parameter	Method
learning	Method
,	O
can	O
be	O
easily	O
applied	O
to	O
other	O
CNN	Method
-	O
based	O
recognition	O
tasks	O
and	O
still	O
yields	O
competitive	O
accuracy	Metric
with	O
A	O
-	O
Fast	Method
-	Method
RCNN	Method
in	O
object	Task
detection	Task
.	O
To	O
summarize	O
,	O
Random	Method
Erasing	Method
has	O
the	O
following	O
advantages	O
:	O
A	O
lightweight	O
method	O
that	O
does	O
not	O
require	O
any	O
extra	O
parameter	Method
learning	Method
or	O
memory	O
consumption	O
.	O
It	O
can	O
be	O
integrated	O
with	O
various	O
CNN	Method
models	O
without	O
changing	O
the	O
learning	Method
strategy	Method
.	O
A	O
complementary	O
method	O
to	O
existing	O
data	Method
augmentation	Method
and	O
regularization	Method
approaches	Method
.	O
When	O
combined	O
,	O
Random	Method
Erasing	Method
further	O
improves	O
the	O
recognition	Task
performance	O
.	O
Consistently	O
improving	O
the	O
performance	O
of	O
recent	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
deep	Method
models	Method
on	O
image	Task
classification	Task
,	O
object	Task
detection	Task
,	O
and	O
person	O
re	Task
-	Task
ID	Task
.	O
Improving	O
the	O
robustness	Metric
of	O
CNNs	Method
to	O
partially	O
occluded	O
samples	O
.	O
When	O
we	O
randomly	O
adding	O
occlusion	O
to	O
the	O
CIFAR	Material
-	Material
10	Material
testing	O
dataset	O
,	O
Random	Method
Erasing	Method
significantly	O
outperforms	O
the	O
baseline	O
model	O
.	O
section	O
:	O
Related	O
Work	O
Regularization	Method
is	O
a	O
key	O
component	O
in	O
preventing	O
over	Task
-	Task
fitting	Task
in	O
the	O
training	O
of	O
CNN	Method
models	O
.	O
Various	O
regularization	Method
methods	Method
have	O
been	O
proposed	O
.	O
Dropout	Method
randomly	O
discards	O
(	O
setting	O
to	O
zero	O
)	O
the	O
output	O
of	O
each	O
hidden	O
neuron	O
with	O
a	O
probability	O
during	O
the	O
training	O
and	O
only	O
considers	O
the	O
contribution	O
of	O
the	O
remaining	O
weights	O
in	O
forward	Method
pass	Method
and	O
back	Method
-	Method
propagation	Method
.	O
Latter	O
,	O
Wan	O
et	O
al	O
.	O
propose	O
a	O
generalization	Method
of	Method
dropout	Method
approach	Method
,	O
DropConect	Method
,	O
which	O
instead	O
randomly	O
selects	O
weights	O
to	O
zero	O
during	O
training	O
.	O
In	O
addition	O
,	O
Adaptive	Method
dropout	Method
is	O
proposed	O
where	O
the	O
dropout	O
probability	O
for	O
each	O
hidden	O
neuron	O
is	O
estimated	O
through	O
a	O
binary	Method
belief	Method
network	Method
.	O
Stochastic	Method
Pooling	Method
randomly	O
selects	O
activation	O
from	O
a	O
multinomial	Method
distribution	Method
during	O
training	O
,	O
which	O
is	O
parameter	O
free	O
and	O
can	O
be	O
applied	O
with	O
other	O
regularization	Method
techniques	Method
.	O
Recently	O
,	O
a	O
regularization	Method
method	Method
named	O
“	O
DisturbLabel	Method
”	Method
is	O
introduced	O
by	O
adding	O
noise	O
at	O
the	O
loss	O
layer	O
.	O
DisturbLabel	O
randomly	O
changes	O
the	O
labels	O
of	O
small	O
part	O
of	O
samples	O
to	O
incorrect	O
values	O
during	O
each	O
training	O
iteration	O
.	O
PatchShuffle	O
randomly	O
shuffles	O
the	O
pixels	O
within	O
each	O
local	O
patch	O
while	O
maintaining	O
nearly	O
the	O
same	O
global	O
structures	O
with	O
the	O
original	O
ones	O
,	O
it	O
yields	O
rich	O
local	O
variations	O
for	O
training	O
of	O
CNN	Method
.	O
Data	Task
augmentation	Task
is	O
an	O
explicit	O
form	O
of	O
regularization	Method
that	O
is	O
also	O
widely	O
used	O
in	O
the	O
training	O
of	O
deep	O
CNN	Method
.	O
It	O
aims	O
at	O
artificially	O
enlarging	O
the	O
training	O
dataset	O
from	O
existing	O
data	O
using	O
various	O
translations	O
,	O
such	O
as	O
,	O
translation	O
,	O
rotation	O
,	O
flipping	O
,	O
cropping	O
,	O
adding	O
noises	O
,	O
etc	O
.	O
The	O
two	O
most	O
popular	O
and	O
effective	O
data	Method
augmentation	Method
methods	O
in	O
training	Task
of	O
deep	O
CNN	Method
are	O
random	Method
flipping	Method
and	O
random	Method
cropping	Method
.	O
Random	Task
flipping	Task
randomly	O
flips	O
the	O
input	O
image	O
horizontally	O
,	O
while	O
random	Method
cropping	Method
extracts	O
random	O
sub	O
-	O
patch	O
from	O
the	O
input	O
image	O
.	O
As	O
an	O
analogous	O
choice	O
,	O
Random	Method
Erasing	Method
may	O
discard	O
some	O
parts	O
of	O
the	O
object	O
.	O
For	O
random	Method
cropping	Method
,	O
it	O
may	O
crop	O
off	O
the	O
corners	O
of	O
the	O
object	O
,	O
while	O
Random	Method
Erasing	Method
may	O
occlude	O
some	O
parts	O
of	O
the	O
object	O
.	O
Random	Method
Erasing	Method
maintains	O
the	O
global	O
structure	O
of	O
object	O
.	O
Moreover	O
,	O
it	O
can	O
be	O
viewed	O
as	O
adding	O
noise	O
to	O
the	O
image	O
.	O
The	O
combination	O
of	O
random	Method
cropping	Method
and	O
Random	Method
Erasing	Method
can	O
produce	O
more	O
various	O
training	O
data	O
.	O
Recently	O
,	O
Wang	O
et	O
al	O
.	O
learn	O
an	O
adversary	Method
with	O
Fast	Method
-	Method
RCNN	Method
detection	Method
to	O
create	O
hard	O
examples	O
on	O
the	O
fly	O
by	O
blocking	O
some	O
feature	O
maps	O
spatially	O
.	O
Instead	O
of	O
generating	O
occlusion	O
examples	O
in	O
feature	O
space	O
,	O
Random	Method
Erasing	Method
generates	O
images	O
from	O
the	O
original	O
images	O
with	O
very	O
little	O
computation	O
which	O
is	O
in	O
effect	O
,	O
computationally	O
free	O
and	O
does	O
not	O
require	O
any	O
extra	O
parameters	O
learning	O
.	O
section	O
:	O
Datasets	O
For	O
image	Task
classification	Task
,	O
we	O
evaluate	O
on	O
three	O
image	Task
classification	Task
datasets	O
,	O
including	O
two	O
well	O
-	O
known	O
datasets	O
,	O
CIFAR	Material
-	Material
10	Material
and	O
CIFAR	Material
-	Material
100	Material
,	O
and	O
a	O
new	O
dataset	O
Fashion	Material
-	Material
MNIST	Material
.	O
CIFAR	Material
-	Material
10	Material
and	O
CIFAR	Material
-	Material
100	Material
contain	O
50	O
,	O
000	O
training	O
and	O
10	O
,	O
000	O
testing	O
32	O
32	O
color	O
images	O
drawn	O
from	O
10	O
and	O
100	O
classes	O
,	O
respectively	O
.	O
Fashion	Material
-	Material
MNIST	Material
consists	O
of	O
60	O
,	O
000	O
training	O
and	O
10	O
,	O
000	O
testing	O
28x28	O
gray	O
-	O
scale	O
images	O
.	O
Each	O
image	O
is	O
associated	O
with	O
a	O
label	O
from	O
10	O
classes	O
.	O
We	O
evaluate	O
top	Metric
-	Metric
1	Metric
error	Metric
rates	Metric
in	O
the	O
format	O
“	O
mean	Metric
std	Metric
”	Metric
based	O
on	O
5	O
runs	O
.	O
For	O
object	Task
detection	Task
,	O
we	O
use	O
the	O
PASCAL	Material
VOC	Material
2007	Material
dataset	Material
which	O
contains	O
9	O
,	O
963	O
images	O
of	O
24	O
,	O
640	O
annotated	O
objects	O
in	O
training	O
/	O
validation	O
and	O
testing	O
sets	O
.	O
We	O
use	O
the	O
“	O
trainval	O
”	O
set	O
for	O
training	O
and	O
“	O
test	O
”	O
set	O
for	O
testing	O
.	O
For	O
person	Task
re	Task
-	Task
identification	Task
(	O
re	Task
-	Task
ID	Task
)	O
,	O
the	O
Market	Material
-	Material
1501	Material
dataset	O
contains	O
32	O
,	O
668	O
labeled	O
bounding	O
boxes	O
of	O
1	O
,	O
501	O
identities	O
captured	O
from	O
6	O
different	O
cameras	O
.	O
The	O
dataset	O
is	O
split	O
into	O
two	O
parts	O
:	O
12	O
,	O
936	O
images	O
with	O
751	O
identities	O
for	O
training	O
and	O
19	O
,	O
732	O
images	O
with	O
750	O
identities	O
for	O
testing	O
.	O
In	O
testing	O
,	O
3	O
,	O
368	O
hand	O
-	O
drawn	O
images	O
with	O
750	O
identities	O
are	O
used	O
as	O
probe	O
set	O
to	O
identify	O
the	O
correct	O
identities	O
on	O
the	O
testing	O
set	O
.	O
DukeMTMC	Material
-	Material
reID	Material
contains	O
36	O
,	O
411	O
images	O
of	O
1	O
,	O
812	O
identities	O
shot	O
by	O
8	O
high	O
-	O
resolution	O
cameras	O
.	O
Similar	O
to	O
Market	Material
-	Material
1501	Material
,	O
it	O
contains	O
16	O
,	O
522	O
training	O
images	O
of	O
702	O
identities	O
,	O
2	O
,	O
228	O
query	O
images	O
of	O
the	O
other	O
702	O
identities	O
and	O
17	O
,	O
661	O
gallery	O
images	O
.	O
CUHK03	Material
contains	O
14	O
,	O
096	O
images	O
of	O
1	O
,	O
467	O
identities	O
.	O
We	O
use	O
the	O
new	O
training	Method
/	Method
testing	Method
protocol	Method
proposed	O
in	O
to	O
evaluate	O
the	O
multi	O
-	O
shot	O
re	Task
-	Task
ID	Task
performance	O
.	O
There	O
are	O
767	O
identities	O
in	O
the	O
training	O
set	O
and	O
700	O
identities	O
in	O
the	O
testing	O
set	O
.	O
We	O
conduct	O
experiment	O
on	O
both	O
“	O
detected	O
”	O
and	O
“	O
labeled	O
”	O
sets	O
.	O
We	O
evaluate	O
using	O
rank	Metric
-	Metric
1	Metric
accuracy	Metric
and	O
mean	Metric
average	Metric
precision	Metric
(	O
mAP	Metric
)	O
on	O
these	O
three	O
datasets	O
.	O
section	O
:	O
Our	O
Approach	O
This	O
section	O
presents	O
the	O
Random	Method
Erasing	Method
data	Method
augmentation	Method
method	O
for	O
training	O
the	O
convolutional	Method
neural	Method
network	Method
(	O
CNN	Method
)	O
.	O
We	O
first	O
describe	O
the	O
detailed	O
procedure	O
of	O
Random	Method
Erasing	Method
.	O
Next	O
,	O
the	O
implementation	O
of	O
Random	Method
Erasing	Method
in	O
different	O
tasks	O
is	O
introduced	O
.	O
Finally	O
,	O
we	O
analyze	O
the	O
differences	O
between	O
Random	Method
Erasing	Method
and	O
random	Method
cropping	Method
.	O
subsection	O
:	O
Random	Method
Erasing	Method
In	O
training	Task
,	O
Random	Method
Erasing	Method
is	O
conducted	O
with	O
a	O
certain	O
probability	O
.	O
For	O
an	O
image	O
in	O
a	O
mini	O
-	O
batch	O
,	O
the	O
probability	O
of	O
it	O
undergoing	O
Random	Method
Erasing	Method
is	O
,	O
and	O
the	O
probability	O
of	O
it	O
being	O
kept	O
unchanged	O
is	O
.	O
In	O
this	O
process	O
,	O
training	O
images	O
with	O
various	O
levels	O
of	O
occlusion	O
are	O
generated	O
.	O
Random	Method
Erasing	Method
randomly	O
selects	O
a	O
rectangle	O
region	O
in	O
an	O
image	O
,	O
and	O
erases	O
its	O
pixels	O
with	O
random	O
values	O
.	O
Assume	O
that	O
the	O
size	O
of	O
the	O
training	O
image	O
is	O
.	O
The	O
area	O
of	O
the	O
image	O
is	O
.	O
We	O
randomly	O
initialize	O
the	O
area	O
of	O
erasing	O
rectangle	O
region	O
to	O
,	O
where	O
is	O
in	O
range	O
specified	O
by	O
minimum	O
and	O
maximum	O
.	O
The	O
aspect	O
ratio	O
of	O
erasing	O
rectangle	O
region	O
is	O
randomly	O
initialized	O
between	O
and	O
,	O
we	O
set	O
it	O
to	O
.	O
The	O
size	O
of	O
is	O
and	O
.	O
Then	O
,	O
we	O
randomly	O
initialize	O
a	O
point	O
in	O
.	O
If	O
and	O
,	O
we	O
set	O
the	O
region	O
,	O
,	O
as	O
the	O
selected	O
rectangle	O
region	O
.	O
Otherwise	O
repeat	O
the	O
above	O
process	O
until	O
an	O
appropriate	O
is	O
selected	O
.	O
With	O
the	O
selected	O
erasing	O
region	O
,	O
each	O
pixel	O
in	O
is	O
assigned	O
to	O
a	O
random	O
value	O
in	O
[	O
0	O
,	O
255	O
]	O
,	O
respectively	O
.	O
The	O
procedure	O
of	O
selecting	O
the	O
rectangle	O
area	O
and	O
erasing	O
this	O
area	O
is	O
shown	O
in	O
Alg	O
.	O
[	O
reference	O
]	O
.	O
[	O
t	O
]	O
InputInput	O
OutputOutput	O
InitializationInitialization	O
Random	Method
Erasing	Method
Procedure	O
Input	O
image	O
;	O
Image	O
size	O
and	O
;	O
Area	O
of	O
image	O
;	O
Erasing	O
probability	O
;	O
Erasing	O
area	O
ratio	O
range	O
and	O
;	O
Erasing	O
aspect	O
ratio	O
range	O
and	O
.	O
Erased	O
image	O
.	O
Rand	O
(	O
0	O
,	O
1	O
)	O
.	O
;	O
.	O
True	O
Rand	O
;	O
Rand	O
;	O
,	O
;	O
Rand	O
,	O
Rand	O
;	O
and	O
;	O
Rand	O
(	O
0	O
,	O
255	O
)	O
;	O
;	O
.	O
subsection	O
:	O
Random	Method
Erasing	Method
for	O
Image	Task
Classification	Task
and	O
Person	Task
Re	Task
-	Task
identification	Task
In	O
image	Task
classification	Task
,	O
an	O
image	O
is	O
classified	O
according	O
to	O
its	O
visual	O
content	O
.	O
In	O
general	O
,	O
training	O
data	O
does	O
not	O
provide	O
the	O
location	O
of	O
the	O
object	O
,	O
so	O
we	O
could	O
not	O
know	O
where	O
the	O
object	O
is	O
.	O
In	O
this	O
case	O
,	O
we	O
perform	O
Random	Method
Erasing	Method
on	O
the	O
whole	O
image	O
according	O
to	O
Alg	O
.	O
[	O
reference	O
]	O
.	O
Recently	O
,	O
the	O
person	O
re	Task
-	Task
ID	Task
model	O
is	O
usually	O
trained	O
in	O
a	O
classification	Method
network	Method
for	O
embedding	Task
learning	Task
.	O
In	O
this	O
task	O
,	O
since	O
pedestrians	O
are	O
confined	O
with	O
detected	O
bounding	O
boxes	O
,	O
persons	O
are	O
roughly	O
in	O
the	O
same	O
position	O
and	O
take	O
up	O
the	O
most	O
area	O
of	O
the	O
image	O
.	O
In	O
this	O
scenario	O
,	O
we	O
adopt	O
the	O
same	O
strategy	O
as	O
image	Task
classification	Task
,	O
as	O
in	O
practice	O
,	O
the	O
pedestrian	O
can	O
be	O
occluded	O
in	O
any	O
position	O
.	O
We	O
randomly	O
select	O
rectangle	O
regions	O
on	O
the	O
whole	O
pedestrian	O
image	O
and	O
erase	O
it	O
.	O
Examples	O
of	O
Random	Method
Erasing	Method
for	O
image	Task
classification	Task
and	O
person	Task
re	Task
-	Task
ID	Task
are	O
shown	O
in	O
Fig	O
.	O
[	O
reference	O
]	O
.	O
subsection	O
:	O
Random	Method
Erasing	Method
for	O
Object	Task
Detection	Task
Object	Task
detection	Task
aims	O
at	O
detecting	O
instances	Task
of	Task
semantic	Task
objects	Task
of	O
a	O
certain	O
class	O
in	O
images	O
.	O
Since	O
the	O
location	O
of	O
each	O
object	O
in	O
the	O
training	O
image	O
is	O
known	O
,	O
we	O
implement	O
Random	Method
Erasing	Method
with	O
three	O
schemes:1	O
)	O
Image	Task
-	Task
aware	Task
Random	Method
Erasing	Method
(	O
IRE	Method
)	O
:	O
selecting	O
erasing	O
regions	O
on	O
the	O
whole	O
image	O
,	O
the	O
same	O
as	O
image	Task
classification	Task
and	O
person	Task
re	Task
-	Task
identification	Task
;	O
2	O
)	O
Object	Task
-	Task
aware	Task
Random	Method
Erasing	Method
(	O
ORE	O
)	O
:	O
selecting	O
erasing	O
regions	O
in	O
the	O
bounding	O
box	O
of	O
each	O
object	O
.	O
In	O
the	O
latter	O
,	O
if	O
there	O
are	O
multiple	O
objects	O
in	O
the	O
image	O
,	O
Random	Method
Erasing	Method
is	O
applied	O
on	O
each	O
object	O
separately	O
.	O
3	O
)	O
Image	Task
and	Task
object	Task
-	Task
aware	Task
Random	Method
Erasing	Method
(	O
I	O
+	O
ORE	O
)	O
:	O
selecting	O
erasing	O
regions	O
in	O
both	O
the	O
whole	O
image	O
and	O
each	O
object	O
bounding	O
box	O
.	O
Examples	O
of	O
Random	Method
Erasing	Method
for	O
object	Task
detection	Task
with	O
the	O
three	O
schemes	O
are	O
shown	O
in	O
Fig	O
.	O
[	O
reference	O
]	O
.	O
subsection	O
:	O
Comparison	O
with	O
Random	Method
Cropping	Method
Random	Method
cropping	Method
is	O
an	O
effective	O
data	Method
augmentation	Method
approach	Method
,	O
it	O
reduces	O
the	O
contribution	O
of	O
the	O
background	O
in	O
the	O
CNN	Method
decision	O
,	O
and	O
can	O
base	O
learning	Method
models	Method
on	O
the	O
presence	O
of	O
parts	O
of	O
the	O
object	O
instead	O
of	O
focusing	O
on	O
the	O
whole	O
object	O
.	O
In	O
comparison	O
to	O
random	Method
cropping	Method
,	O
Random	Method
Erasing	Method
retains	O
the	O
overall	O
structure	O
of	O
the	O
object	O
,	O
only	O
occluding	O
some	O
parts	O
of	O
object	O
.	O
In	O
addition	O
,	O
the	O
pixels	O
of	O
erased	O
region	O
are	O
re	O
-	O
assigned	O
with	O
random	O
values	O
,	O
which	O
can	O
be	O
viewed	O
as	O
adding	O
noise	O
to	O
the	O
image	O
.	O
In	O
our	O
experiment	O
(	O
Section	O
[	O
reference	O
]	O
)	O
,	O
we	O
show	O
that	O
these	O
two	O
methods	O
are	O
complementary	O
to	O
each	O
other	O
for	O
data	Method
augmentation	Method
.	O
The	O
examples	O
of	O
Random	Method
Erasing	Method
,	O
random	Method
cropping	Method
,	O
and	O
the	O
combination	O
of	O
them	O
are	O
shown	O
in	O
Fig	O
.	O
[	O
reference	O
]	O
.	O
section	O
:	O
Experiment	O
subsection	O
:	O
Image	Task
Classification	Task
subsubsection	O
:	O
Experiment	O
Settings	O
In	O
all	O
of	O
our	O
experiment	O
,	O
we	O
compare	O
the	O
CNN	Method
models	O
trained	O
with	O
or	O
without	O
Random	Method
Erasing	Method
.	O
For	O
the	O
same	O
deep	Method
architecture	Method
,	O
all	O
the	O
models	O
are	O
trained	O
from	O
the	O
same	O
weight	Method
initialization	Method
.	O
Note	O
that	O
some	O
popular	O
regularization	Method
techniques	Method
(	O
,	O
weight	Method
decay	Method
,	O
batch	Method
normalization	Method
and	O
dropout	Method
)	O
and	O
various	O
data	Method
augmentations	Method
(	O
,	O
flipping	O
,	O
padding	O
and	O
cropping	O
)	O
are	O
employed	O
.	O
The	O
compared	O
CNN	Method
architectures	O
are	O
summarized	O
as	O
below	O
:	O
Architectures	O
.	O
Four	O
architectures	O
are	O
adopted	O
on	O
CIFAR	Material
-	Material
10	Material
,	O
CIFAR	Material
-	Material
100	Material
and	O
Fashion	Material
-	Material
MNIST	Material
:	O
ResNet	Method
,	O
pre	O
-	O
activation	O
ResNet	Method
,	O
ResNeXt	Method
,	O
and	O
Wide	Method
Residual	Method
Networks	Method
.	O
We	O
use	O
the	O
20	O
,	O
32	O
,	O
44	O
,	O
56	O
,	O
110	Method
-	Method
layer	Method
network	Method
for	O
ResNet	Method
and	O
pre	O
-	O
activation	O
ResNet	Method
.	O
The	O
18	Method
-	Method
layer	Method
network	Method
is	O
also	O
adopted	O
for	O
pre	O
-	O
activation	O
ResNet	Method
.	O
We	O
use	O
ResNeXt	O
-	O
29	O
-	O
8	O
64	O
and	O
WRN	O
-	O
28	O
-	O
10	O
in	O
the	O
same	O
way	O
as	O
and	O
,	O
respectively	O
.	O
The	O
training	O
procedure	O
follows	O
.	O
Specially	O
,	O
the	O
learning	Metric
rate	Metric
starts	O
from	O
0.1	O
and	O
is	O
divided	O
by	O
10	O
after	O
the	O
150th	O
and	O
225th	O
epoch	O
.	O
We	O
stop	O
training	O
by	O
the	O
300th	O
epoch	O
.	O
If	O
not	O
specified	O
,	O
all	O
models	O
are	O
trained	O
with	O
data	Method
augmentation	Method
:	O
randomly	O
performs	O
horizontal	O
flips	O
,	O
and	O
takes	O
a	O
random	O
crop	O
with	O
32	O
32	O
for	O
CIFAR	Material
-	Material
10	Material
and	O
CIFAR	Material
-	Material
100	Material
(	O
28	O
28	O
for	O
Fashion	Material
-	Material
MNIST	Material
)	O
from	O
images	O
padded	O
by	O
4	O
pixels	O
on	O
each	O
side	O
.	O
subsubsection	O
:	O
Classification	Task
Evaluation	Task
Classification	Metric
accuracy	Metric
on	O
different	O
datasets	O
.	O
The	O
results	O
of	O
applying	O
Random	Method
Erasing	Method
on	O
CIFAR	Material
-	Material
10	Material
,	O
CIFAR	Material
-	Material
100	Material
and	O
Fashion	Material
-	Material
MNIST	Material
with	O
different	O
architectures	O
are	O
shown	O
in	O
Table	O
[	O
reference	O
]	O
.	O
We	O
set	O
,	O
,	O
,	O
and	O
.	O
Results	O
indicate	O
that	O
models	O
trained	O
with	O
Random	Method
Erasing	Method
have	O
significant	O
improvement	O
,	O
demonstrating	O
that	O
our	O
method	O
is	O
applicable	O
to	O
various	O
CNN	Method
architectures	O
.	O
For	O
CIFAR	Material
-	Material
10	Material
,	O
our	O
method	O
improves	O
the	O
accuracy	Metric
by	O
0.49	O
%	O
and	O
0.33	O
%	O
using	O
ResNet	Method
-	O
110	O
and	O
ResNet	Method
-	O
110	O
-	O
PreAct	O
,	O
respectively	O
.	O
In	O
particular	O
,	O
our	O
approach	O
obtains	O
3.08	O
%	O
error	Metric
rate	Metric
using	O
WRN	Metric
-	Metric
28	Metric
-	Metric
10	Metric
,	O
which	O
improves	O
the	O
accuracy	Metric
by	O
0.72	O
%	O
and	O
achieves	O
new	O
state	O
of	O
the	O
art	O
.	O
For	O
CIFAR	Material
-	Material
100	Material
,	O
our	O
method	O
obtains	O
17.73	O
%	O
error	Metric
rate	Metric
which	O
gains	O
0.76	O
%	O
than	O
the	O
WRN	Metric
-	Metric
28	Metric
-	Metric
10	Metric
baseline	Metric
.	O
Our	O
method	O
also	O
works	O
well	O
for	O
gray	O
-	O
scale	O
images	O
:	O
Random	Method
erasing	Method
improves	O
WRN	Metric
-	Metric
28	Metric
-	O
10	O
from	O
4.01	O
%	O
to	O
3.65	O
%	O
in	O
top	Metric
-	Metric
1	Metric
error	Metric
on	O
Fashion	Material
-	Material
MNIST	Material
.	O
The	O
impact	O
of	O
hyper	O
-	O
parameters	O
.	O
When	O
implementing	O
Random	Method
Erasing	Method
on	O
CNN	Method
training	O
,	O
we	O
have	O
three	O
hyper	O
-	O
parameters	O
to	O
evaluate	O
,	O
i.e.	O
,	O
the	O
erasing	O
probability	O
,	O
the	O
area	O
ratio	O
range	O
of	O
erasing	O
region	O
and	O
,	O
and	O
the	O
aspect	O
ratio	O
range	O
of	O
erasing	O
region	O
and	O
.	O
To	O
demonstrate	O
the	O
impact	O
of	O
these	O
hyper	O
-	O
parameters	O
on	O
the	O
model	O
performance	O
,	O
we	O
conduct	O
experiment	O
on	O
CIFAR	Material
-	Material
10	Material
based	O
on	O
ResNet18	Method
(	O
pre	Method
-	Method
act	Method
)	O
under	O
varying	O
hyper	O
-	O
parameter	O
settings	O
.	O
To	O
simplify	O
experiment	O
,	O
we	O
fix	O
to	O
0.02	O
,	O
and	O
evaluate	O
,	O
,	O
and	O
.	O
We	O
set	O
,	O
and	O
as	O
the	O
base	O
setting	O
.	O
When	O
evaluating	O
one	O
of	O
the	O
parameters	O
,	O
we	O
fixed	O
the	O
other	O
two	O
parameters	O
.	O
Results	O
are	O
shown	O
in	O
Fig	O
.	O
[	O
reference	O
]	O
.	O
Notably	O
,	O
Random	Method
Erasing	Method
consistently	O
outperforms	O
the	O
ResNet18	Method
(	O
pre	Method
-	Method
act	Method
)	O
baseline	O
under	O
all	O
parameter	O
settings	O
.	O
For	O
example	O
,	O
when	O
and	O
,	O
the	O
average	O
classification	O
error	Metric
rate	Metric
is	O
,	O
outperforming	O
the	O
baseline	O
method	O
(	O
)	O
by	O
a	O
large	O
margin	O
.	O
Random	Method
Erasing	Method
is	O
also	O
robust	O
to	O
the	O
aspect	O
ratios	O
of	O
the	O
erasing	O
region	O
.	O
Specifically	O
,	O
our	O
best	O
result	O
(	O
when	O
,	O
error	Metric
rate	Metric
=	O
)	O
reduces	O
the	O
classification	O
error	Metric
rate	Metric
by	O
0.86	O
%	O
compared	O
with	O
the	O
baseline	O
.	O
In	O
the	O
following	O
experiment	O
for	O
image	Task
classification	Task
,	O
we	O
set	O
,	O
,	O
,	O
and	O
,	O
if	O
not	O
specified	O
.	O
Four	O
types	O
of	O
random	O
values	O
for	O
erasing	Task
.	O
We	O
evaluate	O
Random	Method
Erasing	Method
when	O
pixels	O
in	O
the	O
selected	O
region	O
are	O
erased	O
in	O
four	O
ways	O
:	O
1	O
)	O
each	O
pixel	O
is	O
assigned	O
with	O
a	O
random	O
value	O
ranging	O
in	O
[	O
0	O
,	O
255	O
]	O
,	O
denoted	O
as	O
RE	O
-	O
R	O
;	O
2	O
)	O
all	O
pixels	O
are	O
assign	O
with	O
the	O
mean	O
ImageNet	O
pixel	O
value	O
i.e.	O
,	O
[	O
125	O
,	O
122	O
,	O
114	O
]	O
,	O
denoted	O
as	O
RE	O
-	O
M	O
;	O
3	O
)	O
all	O
pixels	O
are	O
assigned	O
with	O
0	O
,	O
denoted	O
as	O
RE	O
-	O
0	O
;	O
4	O
)	O
all	O
pixels	O
are	O
assigned	O
with	O
255	O
,	O
denoted	O
as	O
RE	O
-	O
255	O
.	O
Table	O
[	O
reference	O
]	O
presents	O
the	O
result	O
with	O
different	O
erasing	O
values	O
on	O
CIFAR10	Material
using	O
ResNet18	Method
(	O
pre	Method
-	Method
act	Method
)	O
.	O
We	O
observe	O
that	O
,	O
1	O
)	O
all	O
erasing	Method
schemes	Method
outperform	O
the	O
baseline	O
,	O
2	O
)	O
RE	Method
-	Method
R	Method
achieves	O
approximately	O
equal	O
performance	O
to	O
RE	O
-	O
M	O
,	O
and	O
3	O
)	O
both	O
RE	Method
-	Method
R	Method
and	O
RE	Method
-	Method
M	Method
are	O
superior	O
to	O
RE	Method
-	Method
0	Method
and	O
RE	Method
-	Method
255	Method
.	O
If	O
not	O
specified	O
,	O
we	O
use	O
RE	Method
-	Method
R	Method
in	O
the	O
following	O
experiment	O
.	O
Comparison	O
with	O
Dropout	Method
and	Method
random	Method
noise	Method
.	O
We	O
compare	O
Random	Method
Erasing	Method
with	O
two	O
variant	O
methods	O
applied	O
on	O
image	O
layer	O
.	O
1	O
)	O
Dropout	Method
:	O
we	O
apply	O
dropout	Method
on	O
image	O
layer	O
with	O
probability	O
.	O
2	O
)	O
Random	O
noise	O
:	O
we	O
add	O
different	O
levels	O
of	O
noise	O
on	O
the	O
input	O
image	O
by	O
changing	O
the	O
pixel	O
to	O
a	O
random	O
value	O
in	O
[	O
0	O
,	O
255	O
]	O
with	O
probability	O
.	O
The	O
probability	O
of	O
whether	O
an	O
image	O
undergoes	O
dropout	O
or	O
random	O
noise	O
is	O
set	O
to	O
0.5	O
as	O
Random	Method
Erasing	Method
.	O
Results	O
are	O
presented	O
in	O
Table	O
[	O
reference	O
]	O
.	O
It	O
is	O
clear	O
that	O
applying	O
dropout	Method
or	O
adding	O
random	O
noise	O
at	O
the	O
image	O
layer	O
fails	O
to	O
improve	O
the	O
accuracy	Metric
.	O
As	O
the	O
probability	O
and	O
increase	O
,	O
performance	O
drops	O
quickly	O
.	O
When	O
,	O
the	O
number	O
of	O
noise	O
pixels	O
for	O
random	O
noise	O
is	O
approximately	O
equal	O
to	O
the	O
number	O
of	O
erasing	O
pixels	O
for	O
Random	Method
Erasing	Method
,	O
the	O
error	Metric
rate	Metric
of	O
random	Metric
noise	Metric
increases	O
from	O
5.17	O
%	O
to	O
6.52	O
%	O
,	O
while	O
Random	Method
Erasing	Method
reduces	O
the	O
error	Metric
rate	Metric
to	O
4.31	O
%	O
.	O
Comparing	O
with	O
data	Method
augmentation	Method
methods	O
.	O
We	O
compare	O
our	O
method	O
with	O
random	O
flipping	O
and	O
random	Method
cropping	Method
in	O
Table	O
[	O
reference	O
]	O
.	O
When	O
applied	O
alone	O
,	O
random	Method
cropping	Method
(	O
6.33	O
%	O
)	O
outperforms	O
the	O
other	O
two	O
methods	O
.	O
Importantly	O
,	O
Random	Method
Erasing	Method
and	O
the	O
two	O
competing	O
techniques	O
are	O
complementary	O
.	O
Particularly	O
,	O
combining	O
these	O
three	O
methods	O
achieves	O
4.31	O
%	O
error	Metric
rate	Metric
,	O
a	O
7	O
%	O
improvement	O
over	O
the	O
baseline	O
without	O
any	O
augmentation	Method
.	O
Robustness	Metric
to	O
occlusion	O
.	O
Last	O
,	O
we	O
show	O
the	O
robustness	Metric
of	O
Random	Method
Erasing	Method
against	O
occlusion	O
.	O
In	O
this	O
experiment	O
,	O
we	O
add	O
different	O
levels	O
of	O
occlusion	O
to	O
the	O
CIFAR	Material
-	Material
10	Material
dataset	O
in	O
testing	O
.	O
We	O
randomly	O
select	O
a	O
region	O
of	O
area	O
and	O
fill	O
it	O
with	O
random	O
values	O
.	O
The	O
aspect	O
ratio	O
of	O
the	O
region	O
is	O
randomly	O
chosen	O
from	O
the	O
range	O
of	O
[	O
0.3	O
,	O
3.33	O
]	O
.	O
Results	O
as	O
shown	O
in	O
Fig	O
.	O
[	O
reference	O
]	O
.	O
Obviously	O
,	O
the	O
baseline	O
performance	O
drops	O
quickly	O
when	O
increasing	O
the	O
occlusion	O
level	O
.	O
In	O
comparison	O
,	O
the	O
performance	O
of	O
the	O
model	Method
training	Method
with	O
Random	Method
Erasing	Method
decreases	O
slowly	O
.	O
Our	O
approach	O
achieves	O
56.36	O
%	O
error	Metric
rate	Metric
when	O
the	O
occluded	O
area	O
is	O
half	O
of	O
the	O
image	O
(	O
)	O
,	O
while	O
the	O
baseline	O
rapidly	O
drops	O
to	O
75.04	O
%	O
.	O
It	O
demonstrates	O
that	O
Random	Method
Erasing	Method
improves	O
the	O
robustness	Metric
of	O
CNNs	Method
against	O
occlusion	O
.	O
subsection	O
:	O
Object	Task
Detection	Task
subsubsection	O
:	O
Experiment	O
Settings	O
Experiment	O
is	O
conducted	O
based	O
on	O
the	O
Fast	Method
-	Method
RCNN	Method
detector	Method
.	O
The	O
model	O
is	O
initialized	O
by	O
the	O
ImageNet	Method
classification	Method
models	Method
,	O
and	O
then	O
fine	O
-	O
tuned	O
on	O
the	O
object	Task
detection	Task
data	O
.	O
We	O
experiment	O
with	O
VGG16	Method
architecture	Method
.	O
We	O
follow	O
A	O
-	O
Fast	Method
-	Method
RCNN	Method
for	O
training	Task
.	O
We	O
apply	O
SGD	Method
for	O
80	O
K	O
to	O
train	O
all	O
models	O
.	O
The	O
training	Metric
rate	Metric
starts	O
with	O
0.001	O
and	O
decreases	O
to	O
0.0001	O
after	O
60	O
K	O
iterations	O
.	O
With	O
this	O
training	O
procedure	O
,	O
the	O
baseline	O
mAP	Metric
is	O
slightly	O
better	O
than	O
the	O
report	O
mAP	Metric
in	O
.	O
We	O
use	O
the	O
selective	O
search	O
proposals	O
during	O
training	O
.	O
For	O
Random	Method
Erasing	Method
,	O
we	O
set	O
,	O
,	O
,	O
and	O
.	O
subsubsection	O
:	O
Detection	Task
Evaluation	Task
We	O
report	O
results	O
with	O
using	O
IRE	Method
,	O
ORE	Method
and	O
I	Method
+	Method
ORE	Method
during	O
training	O
Fast	Method
-	Method
RCNN	Method
in	O
Table	O
[	O
reference	O
]	O
.	O
The	O
detector	O
is	O
trained	O
with	O
two	O
training	O
set	O
,	O
VOC07	Material
trainval	O
and	O
union	O
of	O
VOC07	Material
and	O
VOC12	Material
trainval	O
.	O
When	O
training	O
with	O
VOC07	Material
trainval	O
,	O
the	O
baseline	O
is	O
69.1	O
%	O
mAP	Metric
.	O
The	O
detector	Method
learned	O
with	O
IRE	Method
scheme	Method
achieves	O
an	O
improvement	O
to	O
70.5	O
%	O
mAP	Metric
and	O
the	O
ORE	Method
scheme	Method
obtains	O
71.0	O
%	O
mAP	Metric
.	O
The	O
ORE	Method
performs	O
slightly	O
better	O
than	O
IRE	Method
.	O
When	O
implementing	O
Random	Method
Erasing	Method
on	O
overall	O
image	O
and	O
objects	O
,	O
the	O
detector	Method
training	Method
with	O
I	Method
+	Method
ORE	Method
obtains	O
further	O
improved	O
in	O
performance	O
with	O
71.5	O
%	O
mAP	Metric
.	O
Our	O
approach	O
(	O
I	Method
+	Method
ORE	Method
)	O
outperforms	O
A	O
-	O
Fast	Method
-	Method
RCNN	Method
by	O
0.5	O
%	O
in	O
mAP	Metric
.	O
Moreover	O
,	O
our	O
method	O
does	O
not	O
require	O
any	O
parameter	Method
learning	Method
and	O
is	O
easy	O
to	O
implement	O
.	O
When	O
using	O
the	O
enlarged	O
07	O
+	O
12	O
training	O
set	O
,	O
the	O
baseline	O
is	O
74.8	O
%	O
which	O
is	O
much	O
better	O
than	O
only	O
using	O
07	O
training	O
set	O
.	O
The	O
IRE	Method
and	Method
ORE	Method
schemes	Method
give	O
similar	O
results	O
,	O
in	O
which	O
the	O
mAP	Metric
of	O
IRE	Method
is	O
improved	O
by	O
0.8	O
%	O
and	O
ORE	Method
is	O
improved	O
by	O
1.0	O
%	O
.	O
When	O
applying	O
I	Method
+	Method
ORE	Method
during	O
training	Task
,	O
the	O
mAP	Metric
of	O
Fast	O
-	O
RCNN	O
increases	O
to	O
76.2	O
%	O
,	O
surpassing	O
the	O
baseline	O
by	O
1.4	O
%	O
.	O
subsection	O
:	O
Person	Task
Re	Task
-	Task
identification	Task
subsubsection	O
:	O
Experiment	O
Settings	O
Three	O
baselines	O
are	O
used	O
in	O
person	O
re	Task
-	Task
ID	Task
,	O
,	O
the	O
ID	Method
-	Method
discriminative	Method
Embedding	Method
(	Method
IDE	Method
)	Method
,	O
TriNet	Method
,	O
and	O
SVDNet	Method
.	O
IDE	Method
and	O
SVDNet	Method
are	O
trained	O
with	O
the	O
Softmax	O
loss	O
,	O
while	O
TriNet	Method
is	O
trained	O
with	O
the	O
triplet	O
loss	O
.	O
The	O
input	O
images	O
are	O
resized	O
to	O
256	O
128	O
.	O
For	O
IDE	Task
,	O
we	O
basically	O
follow	O
the	O
training	Method
strategy	Method
in	O
.	O
We	O
further	O
add	O
a	O
fully	Method
connected	Method
layer	O
with	O
128	O
units	O
after	O
the	O
Pool5	Method
layer	Method
,	O
followed	O
by	O
batch	Method
normalization	Method
,	O
ReLU	Method
and	O
Dropout	Method
.	O
The	O
Dropout	O
probability	O
is	O
set	O
to	O
0.5	O
.	O
We	O
use	O
SGD	Method
to	O
train	O
IDE	Task
.	O
The	O
learning	Metric
rate	Metric
starts	O
with	O
0.01	O
and	O
is	O
divided	O
by	O
10	O
after	O
each	O
40	O
epochs	O
.	O
We	O
train	O
100	O
epochs	O
in	O
total	O
.	O
In	O
testing	O
,	O
we	O
extract	O
the	O
output	O
of	O
Pool5	O
as	O
feature	O
for	O
Market	Material
-	Material
1501	Material
and	O
DukeMTMC	Material
-	Material
reID	Material
datasets	Material
,	O
and	O
the	O
fully	Method
connected	Method
layer	O
with	O
128	O
units	O
as	O
feature	O
for	O
CUHK03	Material
.	O
For	O
TriNet	Material
and	O
SVDNet	Material
,	O
we	O
use	O
the	O
same	O
model	O
as	O
proposed	O
in	O
and	O
,	O
respectively	O
,	O
and	O
follow	O
the	O
same	O
training	Method
strategy	Method
.	O
In	O
testing	O
,	O
we	O
extract	O
the	O
last	O
fully	Method
connected	Method
layer	O
with	O
128	O
units	O
as	O
feature	O
for	O
TriNet	Material
and	O
extract	O
the	O
output	O
of	O
Pool5	O
for	O
SVDNet	Method
.	O
Note	O
that	O
,	O
we	O
use	O
256	O
128	O
as	O
the	O
input	O
size	O
to	O
train	O
SVDNet	Method
which	O
achieves	O
higher	O
performance	O
than	O
the	O
original	O
paper	O
using	O
size	O
224	O
224	O
.	O
We	O
use	O
the	O
ResNet	Method
-	O
18	O
,	O
ResNet	Method
-	O
34	O
,	O
and	O
ResNet	Method
-	O
50	O
architectures	O
for	O
IDE	Method
and	O
TriNet	Material
,	O
and	O
ResNet	Method
-	Method
50	Method
for	O
SVDNet	Method
.	O
We	O
fine	O
-	O
tune	O
them	O
on	O
the	O
model	O
pre	O
-	O
trained	O
on	O
ImageNet	Material
.	O
We	O
also	O
perform	O
random	Method
cropping	Method
and	O
random	O
horizontal	O
flipping	O
during	O
training	O
.	O
For	O
Random	Method
Erasing	Method
,	O
we	O
set	O
,	O
,	O
,	O
and	O
.	O
subsubsection	O
:	O
Person	Task
Re	Task
-	Task
identification	Task
Performance	O
Baseline	O
Evaluation	O
.	O
The	O
results	O
of	O
Random	Method
Erasing	Method
on	O
Market	Material
-	Material
1501	Material
,	O
DukeMTMC	Material
-	Material
reID	Material
,	O
and	O
CUHK03	Material
with	O
different	O
baselines	O
and	O
architectures	O
are	O
shown	O
in	O
Table	O
[	O
reference	O
]	O
.	O
For	O
Market	Material
-	Material
1501	Material
and	O
DukeMTMC	Material
-	Material
reID	Material
,	O
the	O
IDE	Method
and	Method
SVDNet	Method
baselines	Method
outperform	O
the	O
TriNet	Method
baseline	Method
.	O
Since	O
there	O
exists	O
plenty	O
of	O
samples	O
in	O
each	O
ID	O
,	O
the	O
models	O
with	O
using	O
the	O
Softmax	O
loss	O
can	O
learn	O
better	O
features	O
.	O
Specially	O
,	O
the	O
IDE	Method
achieves	O
83.14	O
%	O
and	O
71.99	O
%	O
rank	Metric
-	Metric
1	Metric
accuracy	Metric
on	O
Market	Material
-	Material
1501	Material
and	O
DukeMTMC	Material
-	Material
reID	Material
with	O
using	O
ResNet	Method
-	Method
50	Method
,	O
respectively	O
.	O
SVDNet	Method
gives	O
rank	Metric
-	Metric
1	Metric
accuracy	Metric
of	O
84.41	O
%	O
and	O
76.82	O
%	O
on	O
Market	Material
-	Material
1501	Material
and	O
DukeMTMC	Material
-	Material
reID	Material
with	O
ResNet	Method
-	Method
50	Method
,	O
respectively	O
.	O
This	O
is	O
1.81	O
%	O
higher	O
for	O
Market	Material
-	Material
1501	Material
and	O
4.38	O
%	O
higher	O
for	O
DukeMTMC	Material
-	Material
reID	Material
than	O
the	O
TriNet	Method
with	O
ResNet	Method
-	Method
50	Method
.	O
However	O
,	O
on	O
CUHK03	Material
,	O
the	O
performance	O
of	O
TriNet	Method
is	O
higher	O
than	O
IDE	Method
and	O
SVDNet	Method
,	O
since	O
the	O
lack	O
of	O
training	O
samples	O
compromises	O
the	O
Softmax	O
loss	O
.	O
TriNet	Method
obtains	O
49.86	O
%	O
rank	Metric
-	Metric
1	Metric
accuracy	Metric
and	O
46.74	O
%	O
mAP	Metric
on	O
CUHK03	Material
for	O
the	O
labeled	O
setting	O
with	O
ResNet	Method
-	Method
50	Method
.	O
Random	Method
Erasing	Method
improves	O
different	O
baseline	O
models	O
.	O
When	O
implementing	O
Random	Method
Erasing	Method
in	O
these	O
baseline	O
models	O
,	O
we	O
can	O
observe	O
that	O
,	O
Random	Method
Erasing	Method
consistently	O
improves	O
the	O
rank	Metric
-	Metric
1	Metric
accuracy	Metric
and	O
mAP	Metric
.	O
Specifically	O
,	O
for	O
Market	Material
-	Material
1501	Material
,	O
Random	Method
Erasing	Method
improves	O
the	O
rank	Metric
-	Metric
1	Metric
by	O
3.10	O
%	O
and	O
2.67	O
%	O
for	O
IDE	Method
and	O
SVDNet	Method
with	O
using	O
ResNet	Method
-	Method
50	Method
.	O
For	O
DukeMTMC	Material
-	Material
reID	Material
,	O
Random	Method
Erasing	Method
increases	O
the	O
rank	Metric
-	Metric
1	Metric
accuracy	Metric
from	O
71.99	O
%	O
to	O
74.24	O
%	O
for	O
IDE	Method
(	O
ResNet	Method
-	O
50	O
)	O
and	O
from	O
76.82	O
%	O
to	O
79.31	O
%	O
for	O
SVDNet	Method
(	O
ResNet	Method
-	O
50	O
)	O
.	O
For	O
CUHK03	Material
,	O
TriNet	Method
gains	O
8.28	O
%	O
and	O
5.0	O
%	O
in	O
rank	Metric
-	Metric
1	Metric
accuracy	Metric
when	O
applying	O
Random	Method
Erasing	Method
on	O
the	O
labeled	O
and	O
detected	O
settings	O
with	O
ResNet	Method
-	O
50	O
,	O
respectively	O
.	O
We	O
note	O
that	O
,	O
due	O
to	O
lack	O
of	O
adequate	O
training	Material
data	Material
,	O
over	O
-	O
fitting	O
tend	O
to	O
occur	O
on	O
CUHK03	Material
.	O
For	O
example	O
,	O
a	O
deeper	Method
architecture	Method
,	O
such	O
as	O
ResNet	Method
-	Method
50	Method
,	O
achieves	O
lower	O
performance	O
than	O
ResNet	Method
-	O
34	O
when	O
using	O
the	O
IDE	Method
mode	Method
on	O
the	O
detected	O
subset	O
.	O
However	O
,	O
with	O
our	O
method	O
,	O
IDE	Method
(	O
ResNet	Method
-	Method
50	Method
)	O
outperforms	O
IDE	Method
(	O
ResNet	Method
-	O
34	O
)	O
.	O
This	O
indicates	O
that	O
our	O
method	O
can	O
reduce	O
the	O
risk	O
of	O
over	Task
-	Task
fitting	Task
and	O
improves	O
the	O
re	Task
-	Task
ID	Task
performance	O
.	O
Comparison	O
with	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
methods	O
.	O
We	O
compare	O
our	O
method	O
with	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
methods	O
on	O
Market	Material
-	Material
1501	Material
,	O
DukeMTMC	Material
-	Material
reID	Material
,	O
and	O
CUHK03	Material
in	O
Table	O
[	O
reference	O
]	O
,	O
Table	O
[	O
reference	O
]	O
,	O
and	O
Table	O
[	O
reference	O
]	O
,	O
respectively	O
.	O
Our	O
method	O
achieves	O
competitive	O
results	O
with	O
the	O
state	O
of	O
the	O
art	O
.	O
Specifically	O
,	O
based	O
on	O
SVDNet	Method
,	O
our	O
method	O
obtains	O
rank	Metric
-	Metric
1	Metric
accuracy	Metric
=	O
87.08	O
%	O
for	O
Market	Material
-	Material
1501	Material
,	O
and	O
rank	Metric
-	Metric
1	Metric
accuracy	Metric
=	O
79.31	O
%	O
for	O
DukeMTMC	Material
-	Material
reID	Material
.	O
On	O
CUHK03	Material
,	O
based	O
on	O
TriNet	Method
,	O
our	O
method	O
achieves	O
rank	Metric
-	Metric
1	Metric
accuracy	Metric
=	O
58.14	O
%	O
for	O
the	O
labeled	O
setting	O
,	O
and	O
rank	Metric
-	Metric
1	Metric
accuracy	Metric
=	O
55.50	O
%	O
for	O
the	O
detected	O
setting	O
.	O
When	O
we	O
further	O
combine	O
our	O
system	O
with	O
re	Task
-	Task
ranking	Task
,	O
the	O
final	O
rank	Metric
-	Metric
1	Metric
performance	Metric
arrives	O
at	O
89.13	O
%	O
for	O
Market	Material
-	Material
1501	Material
,	O
84.02	O
%	O
for	O
DukeMTMC	Material
-	Material
reID	Material
,	O
and	O
64.43	O
%	O
for	O
CUHK03	Material
under	O
the	O
detected	O
setting	O
.	O
section	O
:	O
Conclusion	O
In	O
this	O
paper	O
,	O
we	O
propose	O
a	O
new	O
data	Method
augmentation	Method
approach	Method
named	O
“	O
Random	Method
Erasing	Method
”	O
for	O
training	O
the	O
convolutional	Method
neural	Method
network	Method
(	O
CNN	Method
)	O
.	O
It	O
is	O
easy	O
to	O
implemented	O
:	O
Random	Method
Erasing	Method
randomly	O
occludes	O
an	O
arbitrary	O
region	O
of	O
the	O
input	O
image	O
during	O
each	O
training	O
iteration	O
.	O
Experiment	O
conducted	O
on	O
CIFAR10	Material
,	O
CIFAR100	Material
,	O
and	O
Fashion	Material
-	Material
MNIST	Material
with	O
various	O
architectures	O
validate	O
the	O
effectiveness	O
of	O
our	O
method	O
.	O
Moreover	O
,	O
we	O
obtain	O
reasonable	O
improvement	O
on	O
object	Task
detection	Task
and	O
person	Task
re	Task
-	Task
identification	Task
,	O
demonstrating	O
that	O
our	O
method	O
has	O
good	O
performance	O
on	O
various	O
recognition	Task
tasks	Task
.	O
In	O
the	O
future	O
work	O
,	O
we	O
will	O
apply	O
our	O
approach	O
to	O
other	O
CNN	Method
recognition	O
tasks	O
,	O
such	O
as	O
,	O
image	Task
retrieval	Task
and	O
face	Task
recognition	Task
.	O
bibliography	O
:	O
References	O
