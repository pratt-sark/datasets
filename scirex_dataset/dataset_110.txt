document	O
:	O
Practical	O
Text	Task
Classification	Task
With	O
Large	O
Pre	O
-	O
Trained	O
Language	Method
Models	Method
Multi	O
-	O
emotion	O
sentiment	Task
classification	O
is	O
a	O
natural	Task
language	Task
processing	Task
(	O
NLP	Task
)	O
problem	O
with	O
valuable	O
use	O
cases	O
on	O
real	O
-	O
world	O
data	O
.	O
We	O
demonstrate	O
that	O
large	O
-	O
scale	O
unsupervised	Method
language	Method
modeling	Method
combined	O
with	O
finetuning	Method
offers	O
a	O
practical	O
solution	O
to	O
this	O
task	O
on	O
difficult	O
datasets	O
,	O
including	O
those	O
with	O
label	O
class	O
imbalance	O
and	O
domain	O
-	O
specific	O
context	O
.	O
By	O
training	O
an	O
attention	O
-	O
based	O
Transformer	Method
network	O
on	O
40	O
GB	O
of	O
text	O
(	O
Amazon	O
reviews	O
)	O
and	O
fine	O
-	O
tuning	O
on	O
the	O
training	O
set	O
,	O
our	O
model	O
achieves	O
a	O
0.69	O
F1	Metric
score	Metric
on	O
the	O
SemEval	Material
Task	O
1:E	O
-	O
c	O
multidimensional	Task
emotion	Task
classification	Task
problem	O
,	O
based	O
on	O
the	O
Plutchik	O
wheel	O
of	O
emotions	O
.	O
These	O
results	O
are	O
competitive	O
with	O
state	O
of	O
the	O
art	O
models	O
,	O
including	O
strong	O
F1	Metric
scores	Metric
on	O
difficult	O
(	O
emotion	O
)	O
categories	O
such	O
as	O
Fear	O
(	O
0.73	O
)	O
,	O
Disgust	O
(	O
0.77	O
)	O
and	O
Anger	O
(	O
0.78	O
)	O
,	O
as	O
well	O
as	O
competitive	O
results	O
on	O
rare	O
categories	O
such	O
as	O
Anticipation	O
(	O
0.42	O
)	O
and	O
Surprise	O
(	O
0.37	O
)	O
.	O
Furthermore	O
,	O
we	O
demonstrate	O
our	O
application	O
on	O
a	O
real	Task
world	Task
text	Task
classification	Task
task	Task
.	O
We	O
create	O
a	O
narrowly	O
collected	O
text	O
dataset	O
of	O
real	O
tweets	O
on	O
several	O
topics	O
,	O
and	O
show	O
that	O
our	O
finetuned	Method
model	Method
outperforms	O
general	O
purpose	O
commercially	O
available	O
APIs	O
for	O
sentiment	Task
and	O
multidimensional	Task
emotion	Task
classification	Task
on	O
this	O
dataset	O
by	O
a	O
significant	O
margin	O
.	O
We	O
also	O
perform	O
a	O
variety	O
of	O
additional	O
studies	O
,	O
investigating	O
properties	O
of	O
deep	Method
learning	Method
architectures	Method
,	O
datasets	O
and	O
algorithms	O
for	O
achieving	O
practical	O
multidimensional	O
sentiment	Task
classification	O
.	O
Overall	O
,	O
we	O
find	O
that	O
unsupervised	Method
language	Method
modeling	Method
and	O
finetuning	Method
is	O
a	O
simple	O
framework	O
for	O
achieving	O
high	O
quality	O
results	O
on	O
real	O
-	O
world	O
sentiment	Task
classification	O
.	O
section	O
:	O
Introduction	O
Recent	O
work	O
has	O
shown	O
that	O
language	Method
models	Method
–	O
both	O
RNN	Method
variants	O
like	O
the	O
multiplicative	Method
LSTM	Method
(	O
mLSTM	Method
)	O
,	O
as	O
well	O
as	O
the	O
attention	O
-	O
based	O
Transformer	Method
network	O
–	O
can	O
be	O
trained	O
efficiently	O
over	O
very	O
large	O
datasets	O
,	O
and	O
that	O
the	O
resulting	O
models	O
can	O
be	O
transferred	O
to	O
downstream	Task
language	Task
understanding	Task
problems	Task
,	O
often	O
matching	O
or	O
exceeding	O
the	O
previous	O
state	O
of	O
the	O
art	O
approaches	O
on	O
academic	O
datasets	O
.	O
However	O
,	O
how	O
well	O
do	O
these	O
models	O
perform	O
on	O
practical	O
text	Task
classification	Task
problems	Task
,	O
with	O
real	O
world	O
data	O
?	O
In	O
this	O
work	O
,	O
we	O
train	O
both	O
mLSTM	Method
and	O
Transformer	Method
language	O
models	O
on	O
a	O
large	O
40	O
GB	O
text	O
dataset	O
,	O
then	O
transfer	O
those	O
models	O
to	O
two	O
text	Task
classification	Task
problems	Task
:	O
binary	O
sentiment	Task
(	O
including	O
Neutral	O
labels	O
)	O
,	O
and	O
multidimensional	Task
emotion	Task
classification	Task
based	O
on	O
the	O
Plutchik	O
wheel	O
of	O
emotions	O
.	O
We	O
examine	O
our	O
performance	O
on	O
these	O
tasks	O
,	O
both	O
against	O
large	O
academic	O
datasets	O
,	O
and	O
on	O
an	O
original	O
text	O
dataset	O
that	O
we	O
compiled	O
from	O
social	O
media	O
messages	O
about	O
several	O
specific	O
topics	O
,	O
such	O
as	O
video	O
games	O
.	O
We	O
demonstrate	O
that	O
our	O
approach	O
matches	O
the	O
state	O
of	O
the	O
art	O
on	O
the	O
academic	O
datasets	O
without	O
domain	O
-	O
specific	O
training	O
and	O
without	O
excessive	O
hyper	Method
-	Method
parameter	Method
tuning	Method
.	O
Meanwhile	O
on	O
the	O
social	O
media	O
dataset	O
,	O
our	O
approach	O
outperforms	O
commercially	O
available	O
APIs	O
by	O
significant	O
margins	O
,	O
even	O
when	O
those	O
models	O
are	O
re	O
-	O
calibrated	O
to	O
the	O
test	O
set	O
.	O
Furthermore	O
,	O
we	O
notice	O
that	O
1	O
)	O
the	O
Transformer	Method
model	O
generally	O
out	O
-	O
performs	O
the	O
mLSTM	Method
model	O
,	O
especially	O
when	O
fine	Task
-	Task
tuning	Task
on	O
multidimensional	Task
emotion	Task
classification	Task
,	O
and	O
2	O
)	O
fine	O
-	O
tuning	O
the	O
model	O
significantly	O
improves	O
performance	O
on	O
the	O
emotion	Task
tasks	Task
,	O
both	O
for	O
the	O
mLSTM	Method
and	O
the	O
Transformer	Method
model	O
.	O
We	O
suggest	O
that	O
our	O
approach	O
creates	O
models	O
with	O
good	O
generalization	Task
to	O
increasingly	O
difficult	O
text	Task
classification	Task
problems	Task
,	O
and	O
we	O
offer	O
ablation	O
studies	O
to	O
demonstrate	O
that	O
effect	O
.	O
It	O
is	O
difficult	O
to	O
fit	O
a	O
single	O
model	O
for	O
text	Task
classification	Task
across	O
domains	O
,	O
due	O
to	O
unknown	O
words	O
,	O
specialized	O
context	O
,	O
colloquial	O
language	O
,	O
and	O
other	O
differences	O
between	O
domains	O
.	O
For	O
example	O
,	O
words	O
such	O
as	O
war	O
and	O
sick	O
are	O
not	O
necessarily	O
negative	O
in	O
the	O
context	O
of	O
video	O
games	O
,	O
which	O
are	O
significantly	O
represented	O
in	O
our	O
dataset	O
.	O
By	O
training	O
a	O
language	Method
model	Method
across	O
a	O
large	O
text	O
dataset	O
,	O
we	O
expose	O
our	O
model	O
to	O
many	O
contexts	O
.	O
Perhaps	O
a	O
small	O
amount	O
of	O
downstream	Task
transfer	Task
is	O
enough	O
to	O
choose	O
the	O
right	O
context	O
features	O
for	O
emotion	Task
classification	Task
in	O
the	O
appropriate	O
setting	O
.	O
Our	O
work	O
shows	O
that	O
unsupervised	Method
language	Method
modeling	Method
combined	O
with	O
finetuning	Method
offers	O
a	O
practical	O
solution	O
to	O
specialized	O
text	Task
classification	Task
problems	Task
,	O
including	O
those	O
with	O
large	O
category	O
class	O
imbalance	O
,	O
and	O
significant	O
human	O
label	O
disagreement	O
.	O
section	O
:	O
Background	O
Supervised	Method
learning	Method
is	O
difficult	O
to	O
apply	O
to	O
NLP	Task
problems	O
because	O
labels	O
are	O
expensive	O
.	O
Following	O
,	O
and	O
,	O
we	O
train	O
unsupervised	Method
text	Method
models	Method
on	O
large	O
amounts	O
of	O
unlabelled	O
text	O
data	O
,	O
and	O
transfer	O
the	O
model	O
features	O
to	O
small	O
supervised	Task
text	Task
problems	Task
.	O
The	O
supervised	Task
text	Task
classification	Task
problem	Task
used	O
for	O
transfer	Task
is	O
binary	O
sentiment	Task
on	O
the	O
Stanford	Material
Sentiment	Material
Treebank	Material
(	O
SST	Material
)	O
.	O
Some	O
of	O
these	O
binary	O
text	O
examples	O
are	O
subtle	O
.	O
Prior	O
works	O
show	O
that	O
unsupervised	Method
language	Method
models	Method
can	O
learn	O
nuanced	O
features	O
of	O
text	O
,	O
such	O
as	O
word	O
ordering	O
and	O
double	O
negation	O
,	O
just	O
from	O
the	O
underlying	O
task	O
of	O
next	Task
-	Task
word	Task
prediction	Task
.	O
However	O
,	O
while	O
this	O
includes	O
difficult	O
examples	O
,	O
it	O
does	O
not	O
necessarily	O
represent	O
sentiment	Task
on	O
practical	O
text	Task
problems	Task
.	O
The	O
source	O
material	O
(	O
professionally	O
written	O
movie	O
reviews	O
)	O
does	O
not	O
include	O
colloquial	O
language	O
.	O
The	O
dataset	O
excludes	O
Neutral	O
sentiment	Task
texts	O
and	O
those	O
with	O
weak	O
directional	O
sentiment	Task
.	O
The	O
dataset	O
does	O
not	O
include	O
dimensions	O
of	O
sentiment	Task
apart	O
from	O
Positive	O
and	O
Negative	O
.	O
TweetWatsonSadJoyFearGCLOursBinaryBinaryBinaryEncouraging	O
collaboration	O
among	O
players	O
in	O
Sea	O
of	O
Thieves	O
<	O
url>	O
-	O
0.3020.2290.1940.150	O
-	O
0.80Posgot	O
my	O
first	O
kill	O
on	O
Fortnite	O
all	O
by	O
myself	O
I	O
’	O
m	O
geeked	O
<	O
emoji	O
>	O
perioddddd.	O
-	O
0.8470.0030.6660.225	O
+	O
0.60NeuFar	O
Cry	O
5	O
”	O
Lost	O
On	O
Mars	O
”	O
Gameplay	O
Walkthrough	O
-	O
DLC2	O
:	O
<	O
url	O
>	O
via	O
@YouTube	O
-	O
0.9090.0470.0150.873	O
+	O
0.00NeuNEW	O
SUBMACHINE	Task
GUN	Task
IS	O
INSANE	O
!	O
—	O
Fortnite	O
Best	O
Moments	O
39	O
(	O
Fortnite	O
Funny	O
Fails	O
&	O
WTF	O
Moments	O
)	O
<	O
url>	O
-	O
0.9360.8210.1780.056	O
-	O
0.10Pos	O
paragraph	O
:	O
Plutchik	O
’s	O
Wheel	O
of	O
Emotions	O
We	O
focus	O
our	O
multi	Task
-	Task
dimension	Task
emotion	Task
classification	Task
on	O
Plutchik	Task
’s	Task
wheel	Task
of	Task
emotions	Task
.	O
This	O
taxonomy	O
,	O
in	O
use	O
since	O
1979	O
,	O
aims	O
to	O
classify	O
human	O
emotions	O
as	O
a	O
combination	O
of	O
four	O
dualities	O
:	O
Joy	O
-	O
Sadness	O
,	O
Anger	O
-	O
Fear	O
,	O
Trust	O
-	O
Disgust	O
,	O
and	O
Surprise	O
-	O
Anticipation	O
.	O
According	O
to	O
the	O
basic	O
emotion	Method
model	Method
,	O
while	O
humans	O
experience	O
hundreds	O
of	O
emotions	O
,	O
some	O
emotions	O
are	O
more	O
fundamental	O
than	O
others	O
.	O
The	O
commercial	O
general	Task
purpose	Task
emotion	Task
classification	Task
API	Task
that	O
we	O
compare	O
against	O
,	O
IBM	O
’s	O
Watson	Method
,	O
offers	O
classification	Metric
scores	Metric
for	O
the	O
Joy	O
,	O
Sadness	O
,	O
Fear	O
,	O
Disgust	O
and	O
Anger	O
emotions	O
–	O
all	O
present	O
in	O
Plutchik	Method
’s	Method
wheel	Method
(	O
Fig	O
.	O
[	O
reference	O
]	O
)	O
.	O
paragraph	O
:	O
SemEval	Material
Multidimension	Material
Emotion	Material
Dataset	Material
The	O
SemEval	Material
Task	O
1:E	O
-	O
c	O
problem	O
offers	O
a	O
training	O
set	O
of	O
6	O
,	O
857	O
tweets	O
,	O
with	O
binary	O
labels	O
for	O
the	O
eight	O
Plutchik	O
categories	O
,	O
plus	O
Optimism	O
,	O
Pessimism	O
,	O
and	O
Love	O
.	O
This	O
dataset	O
was	O
created	O
through	O
a	O
process	O
of	O
text	Task
selection	Task
and	O
human	Task
labeling	Task
.	O
We	O
show	O
our	O
results	O
on	O
this	O
dataset	O
and	O
compare	O
it	O
to	O
the	O
current	O
state	O
of	O
the	O
art	O
performance	O
.	O
While	O
it	O
is	O
not	O
possible	O
to	O
report	O
rater	O
agreement	O
on	O
these	O
categories	O
for	O
the	O
compilation	O
of	O
the	O
dataset	O
,	O
the	O
authors	O
note	O
that	O
2	O
out	O
of	O
7	O
raters	O
had	O
to	O
agree	O
for	O
a	O
positive	O
label	O
to	O
be	O
applied	O
,	O
as	O
requiring	O
larger	O
agreement	O
caused	O
a	O
scarcity	O
of	O
labels	O
for	O
some	O
categories	O
.	O
This	O
indicates	O
that	O
some	O
of	O
the	O
categories	O
had	O
significant	O
rater	O
disagreement	O
between	O
the	O
human	O
raters	O
.	O
The	O
dataset	O
also	O
included	O
a	O
substantial	O
degree	O
of	O
label	O
class	O
imbalance	O
,	O
with	O
some	O
categories	O
like	O
Anger	O
(	O
37	O
%	O
)	O
,	O
Disgust	O
(	O
38	O
%	O
)	O
,	O
Joy	O
(	O
36	O
%	O
)	O
and	O
Sadness	O
(	O
29	O
%	O
)	O
represented	O
often	O
in	O
the	O
dataset	O
,	O
while	O
others	O
like	O
Trust	O
(	O
5	O
%	O
)	O
and	O
Surprise	O
(	O
5	O
%	O
)	O
present	O
much	O
less	O
frequently	O
(	O
Fig	O
.	O
[	O
reference	O
]	O
)	O
.	O
This	O
class	Metric
imbalance	Metric
and	O
human	Metric
rater	Metric
disagreement	Metric
is	O
not	O
uncommon	O
for	O
real	Task
world	Task
text	Task
classification	Task
problems	Task
.	O
SizeAngerAnticipationDisgustFearJoySadSurpriseTrustAve	O
/	O
NoneSemEval6	O
,	O
85837.214.338.018.236.229.45.35.223.0	O
/	O
2.9	O
(	O
Random	O
)	O
4	O
,	O
0217.814.75.21.721.93.44.36.68.2	O
/	O
52.1	O
(	O
Active	O
)	O
5	O
,	O
02422.010.212.35.619.76.37.16.511.2	O
/	O
35.6	O
(	O
All	O
)	O
13	O
,	O
32611.712.96.82.920.64.25.07.68.9	O
/	O
47.0	O
paragraph	O
:	O
Company	O
Tweet	O
Dataset	O
In	O
addition	O
to	O
the	O
SemEval	Material
tweet	O
dataset	O
,	O
we	O
wanted	O
to	O
see	O
how	O
our	O
model	O
would	O
perform	O
on	O
a	O
similar	O
but	O
domain	Task
-	Task
specific	Task
task	Task
:	O
Plutchik	Task
emotion	Task
classification	Task
on	O
tweets	O
relevant	O
to	O
a	O
particular	O
company	O
.	O
We	O
collected	O
tweets	O
on	O
a	O
variety	O
of	O
topics	O
,	O
including	O
:	O
Video	O
game	O
tweets	O
Tweets	O
about	O
the	O
company	O
stock	O
We	O
submitted	O
the	O
first	O
batch	O
of	O
4	O
,	O
000	O
tweets	O
to	O
human	O
raters	O
on	O
the	O
FigureEight	Method
platform	Method
,	O
with	O
rules	O
similar	O
to	O
those	O
used	O
by	O
SemEval	Material
,	O
which	O
also	O
used	O
the	O
FigureEight	Method
platform	Method
for	O
human	Task
labeling	Task
.	O
Specifically	O
,	O
we	O
verified	O
that	O
raters	O
passed	O
our	O
golden	O
set	O
(	O
answering	O
70	O
%	O
of	O
test	O
questions	O
correctly	O
)	O
.	O
We	O
applied	O
positive	O
labels	O
for	O
each	O
category	O
where	O
2	O
out	O
of	O
5	O
raters	O
agreed	O
.	O
This	O
is	O
slightly	O
less	O
permissive	O
than	O
the	O
2	O
out	O
of	O
7	O
raters	O
used	O
by	O
SemEval	Material
,	O
because	O
we	O
did	O
not	O
have	O
a	O
budget	O
for	O
7	O
raters	O
per	O
tweet	O
.	O
After	O
the	O
first	O
pass	O
,	O
we	O
noticed	O
that	O
random	Method
sampling	Method
led	O
to	O
some	O
categories	O
being	O
severely	O
under	O
-	O
sampled	O
,	O
below	O
5	O
%	O
of	O
tweets	O
.	O
Thus	O
we	O
employed	O
a	O
bootstrapping	Method
technique	Method
to	O
pre	O
-	O
classify	O
tweets	O
by	O
category	O
using	O
our	O
current	O
model	O
,	O
and	O
choose	O
tweets	O
with	O
more	O
likely	O
emotion	O
tweets	O
for	O
classification	Task
.	O
See	O
Active	Method
Learning	Method
section	O
for	O
details	O
.	O
We	O
also	O
sampled	O
5	O
,	O
000	O
tweets	O
balanced	O
by	O
source	O
category	O
,	O
since	O
video	O
game	O
tweets	O
have	O
much	O
more	O
emotion	O
,	O
thus	O
dominated	O
the	O
bootstrapped	O
selections	O
.	O
Henceforth	O
,	O
we	O
refer	O
to	O
the	O
combined	O
company	O
tweets	O
dataset	O
consisting	O
of	O
:	O
4	O
,	O
021	O
random	O
tweets	O
5	O
,	O
024	O
tweets	O
selected	O
for	O
higher	O
emotion	O
content	O
4	O
,	O
281	O
tweets	O
selected	O
for	O
source	O
category	O
balance	O
DatasetJudgmentsBinaryPlutchik	O
(	O
3	O
choices	O
)(	O
8	O
choices	O
)	O
SemEval20	O
,	O
51477.3%61.1%Company	O
(	O
random	O
)	O
20	O
,	O
00580.7%67.3%Company	O
(	O
active	O
)	O
25	O
,	O
01779.0%52.3%Company	O
(	O
balanced	O
)	O
23	O
,	O
81280.0%71.0	O
%	O
paragraph	O
:	O
Finetuning	O
Recent	O
work	O
has	O
shown	O
promising	O
results	O
using	O
unsupervised	Task
language	Task
modeling	Task
,	O
followed	O
by	O
transfer	Method
learning	Method
to	O
natural	Task
language	Task
tasks	Task
,	O
.	O
Furthermore	O
,	O
these	O
models	O
benefit	O
when	O
the	O
entire	O
model	O
is	O
fine	O
-	O
tuned	O
on	O
the	O
transfer	Task
task	Task
,	O
as	O
demonstrated	O
in	O
.	O
Specifically	O
,	O
these	O
methods	O
have	O
beaten	O
the	O
state	O
of	O
the	O
art	O
on	O
binary	O
sentiment	Task
classification	O
.	O
These	O
models	O
have	O
also	O
attained	O
the	O
best	O
overall	O
score	O
on	O
the	O
GLUE	O
Benchmark	O
,	O
comprised	O
of	O
a	O
variety	O
of	O
text	Task
understanding	Task
tasks	Task
,	O
including	O
entailment	Task
and	Task
question	Task
answering	Task
.	O
section	O
:	O
Methodology	O
We	O
use	O
a	O
larger	O
batch	O
size	O
with	O
shorter	O
sequence	O
length	O
,	O
specifically	O
a	O
global	O
batch	O
of	O
512	O
and	O
sequence	O
length	O
64	O
tokens	O
(	O
tokenized	O
with	O
a	O
32	O
,	O
000	O
BPE	O
vocabulary	O
,	O
as	O
detailed	O
in	O
Characters	O
and	O
Subword	O
Units	O
.	O
The	O
shorter	O
sequence	O
length	O
works	O
well	O
because	O
the	O
transfer	O
target	O
are	O
tweets	O
,	O
which	O
are	O
short	O
pieces	O
of	O
text	O
.	O
We	O
trained	O
our	O
language	Method
model	Method
on	O
the	O
Amazon	O
Reviews	O
dataset	O
rather	O
than	O
other	O
large	O
datasets	O
like	O
BooksCorpus	O
,	O
because	O
reviews	O
are	O
rich	O
in	O
emotional	O
context	O
.	O
We	O
also	O
train	O
an	O
mLSTM	Method
network	O
on	O
the	O
same	O
dataset	O
,	O
based	O
on	O
the	O
model	O
from	O
.	O
We	O
chose	O
to	O
compare	O
these	O
particular	O
models	O
because	O
they	O
work	O
in	O
fundamentally	O
different	O
ways	O
and	O
because	O
they	O
collectively	O
hold	O
state	O
of	O
the	O
art	O
results	O
on	O
many	O
significant	O
academic	O
NLP	Task
benchmarks	O
.	O
We	O
wanted	O
to	O
test	O
these	O
models	O
on	O
difficult	O
classification	Task
problems	Task
with	O
real	O
-	O
world	O
data	O
.	O
paragraph	O
:	O
Unsupervised	Task
Pretraining	Task
.	O
The	O
language	Task
modeling	Task
objective	Task
can	O
be	O
summarized	O
as	O
a	O
maximum	Task
likelihood	Task
estimation	Task
problem	Task
for	O
a	O
sequence	O
of	O
tokens	O
.	O
We	O
treat	O
our	O
model	O
as	O
a	O
function	O
with	O
two	O
parts	O
:	O
an	O
encoder	Method
and	Method
decoder	Method
.	O
The	O
encoder	Method
forms	O
the	O
bulk	O
of	O
the	O
model	O
,	O
including	O
the	O
token	Method
embedding	Method
dictionary	Method
as	O
the	O
first	O
module	O
.	O
The	O
decoder	Method
is	O
simply	O
a	O
softmax	Method
linear	Method
layer	Method
that	O
projects	O
the	O
encoder	O
output	O
into	O
the	O
dimension	O
equal	O
to	O
the	O
vocabulary	O
size	O
.	O
The	O
objective	O
to	O
maximize	O
is	O
as	O
follows	O
.	O
where	O
is	O
a	O
hidden	O
layer	O
activation	O
in	O
the	O
final	O
layer	O
of	O
,	O
indexed	O
for	O
timestep	O
.	O
The	O
model	O
is	O
tasked	O
with	O
predicting	O
the	O
next	O
token	O
given	O
all	O
of	O
the	O
ones	O
prior	O
by	O
outputting	O
a	O
probability	O
distribution	O
over	O
the	O
vocabulary	O
of	O
tokens	O
.	O
Doing	O
this	O
for	O
each	O
timestep	O
produces	O
each	O
term	O
in	O
the	O
sum	O
of	O
the	O
log	Method
-	Method
likelihood	Method
formulation	Method
,	O
and	O
so	O
maximizing	O
the	O
correct	O
probabilities	O
is	O
a	O
way	O
to	O
understand	O
the	O
joint	O
probability	O
distribution	O
of	O
sequences	O
in	O
this	O
corpus	O
of	O
text	O
.	O
paragraph	O
:	O
Characters	O
and	O
Subword	O
Units	O
.	O
While	O
,	O
and	O
have	O
shown	O
state	O
of	O
the	O
art	O
results	O
for	O
language	Task
modeling	Task
and	O
task	Task
transfer	Task
with	O
character	O
-	O
level	O
mLSTM	Method
models	O
,	O
we	O
found	O
that	O
our	O
Transformer	Method
model	O
benefits	O
from	O
modeling	O
language	O
through	O
subword	O
units	O
.	O
Using	O
a	O
byte	Method
-	Method
pair	Method
-	Method
encoding	Method
(	O
BPE	Method
)	O
of	O
various	O
sized	O
we	O
notice	O
that	O
a	O
32	O
,	O
000	O
word	O
-	O
piece	O
vocabulary	O
achieves	O
a	O
better	O
bits	Metric
per	Metric
character	Metric
(	O
BPC	Metric
)	O
loss	O
over	O
one	O
epoch	O
of	O
the	O
Amazon	O
Reviews	O
dataset	O
than	O
a	O
small	O
vocabulary	O
.	O
We	O
compute	O
the	O
BPC	Method
equivalent	Method
over	O
word	O
pieces	O
,	O
following	O
.	O
For	O
the	O
remainder	O
of	O
this	O
work	O
,	O
our	O
Transformer	Method
models	O
use	O
32	O
,	O
000	O
word	O
pieces	O
.	O
Recent	O
work	O
has	O
shown	O
that	O
it	O
is	O
possible	O
to	O
train	O
a	O
character	O
level	O
Transformer	Method
that	O
is	O
up	O
to	O
64	O
layers	O
deep	O
and	O
which	O
beat	O
state	O
of	O
the	O
art	O
BPC	Method
over	O
large	O
text	O
datasets	O
.	O
However	O
this	O
requires	O
intermediate	O
layer	O
losses	O
,	O
and	O
other	O
auxiliary	O
losses	O
for	O
optimal	Task
convergence	Task
.	O
By	O
comparison	O
,	O
uses	O
a	O
bytepair	Method
encoding	Method
vocabulary	Method
with	O
40	O
,	O
000	O
word	O
pieces	O
for	O
their	O
state	O
of	O
the	O
art	O
results	O
on	O
language	Task
transfer	Task
tasks	Task
with	O
a	O
Transformer	Method
model	O
.	O
Our	O
work	O
closely	O
follows	O
their	O
model	O
.	O
paragraph	O
:	O
Supervised	Task
Finetuning	Task
.	O
After	O
the	O
pretraining	O
,	O
we	O
initialize	O
a	O
new	O
decoder	Method
to	O
be	O
exclusively	O
trained	O
on	O
the	O
supervised	Task
problem	Task
.	O
Depending	O
on	O
the	O
task	O
,	O
this	O
decoder	O
may	O
be	O
a	O
single	O
linear	Method
layer	Method
with	O
activation	Method
or	O
an	O
MLP	Method
.	O
We	O
also	O
retain	O
the	O
original	O
decoder	O
and	O
continue	O
to	O
train	O
it	O
by	O
using	O
language	Method
modeling	Method
as	O
an	O
auxiliary	O
loss	O
when	O
finetuning	Method
on	O
the	O
new	O
corpus	O
.	O
Error	O
signals	O
from	O
both	O
decoders	O
are	O
backpropagated	O
into	O
the	O
language	Method
model	Method
.	O
The	O
differences	O
between	O
the	O
hyperparameters	Method
for	O
finetuning	Method
and	O
language	Task
modeling	Task
are	O
described	O
in	O
Table	O
[	O
reference	O
]	O
.	O
Language	O
ModelingFinetuningglobal	O
batch	O
size512	O
(	O
size	O
64	O
on	O
8	O
GPUs	O
)	O
32sequence	O
length64	O
-	O
kept	O
short	O
because	O
targeting	O
tweet	O
applicationmax	O
(	O
batch	O
)	O
optimizerADAM⁢lr	O
(	O
schedule	O
)	O
×210	O
-	O
4	O
(	O
cosine	O
decay	O
after	O
linear	O
warmup	O
on	O
2000	O
iterations	O
)	O
×110	O
-	O
5	O
(	O
constant	O
after	O
1	O
/	O
2	O
epoch	O
linear	O
warmup	O
)	O
Decoder	O
moduleR×dh32000Binary	O
:	O
MLP	O
(	O
1024	O
→	O
nc	O
)	O
with	O
PReLU	O
and	O
0.3	O
dropoutMulticlass	O
:	O
MLP	O
(	O
4096	O
→	O
2048	O
→	O
1024	O
→	O
nc	O
)	O
with	O
PReLU	Method
and	O
0.3	O
dropout	O
#	O
Epochs15LossL⁢LM	O
=	O
Softmax	O
Cross	O
EntropySigmoid	O
Binary	O
Cross	O
Entropy	O
+	O
⋅0.02L⁢LM	O
paragraph	O
:	O
ELMo	O
Baseline	O
We	O
also	O
compare	O
our	O
language	Method
models	Method
to	O
ELMo	Method
,	O
a	O
contextualized	Method
word	Method
representation	Method
based	O
on	O
a	O
deep	Method
bidirectional	Method
language	Method
model	Method
,	O
trained	O
on	O
large	O
text	O
corpus	O
.	O
We	O
use	O
a	O
publicly	O
available	O
pretrained	Method
ELMo	Method
model	Method
from	O
the	O
authors	O
.	O
During	O
finetuning	Method
,	O
text	O
is	O
embedded	O
with	O
ELMo	Method
before	O
being	O
passed	O
into	O
a	O
decoder	Method
.	O
Error	O
signals	O
are	O
backpropagated	O
into	O
the	O
ELMo	Method
language	Method
model	Method
.	O
Unlike	O
our	O
other	O
models	O
,	O
we	O
do	O
not	O
use	O
an	O
auxiliary	O
language	O
modeling	O
loss	O
during	O
finetuning	Method
,	O
as	O
the	O
ELMo	Method
language	Method
model	Method
is	O
bidirectional	O
.	O
Finetuning	O
the	O
ELMo	Method
model	Method
substantially	O
improves	O
accuracy	Metric
on	O
our	O
tasks	O
,	O
thus	O
we	O
include	O
only	O
finetuned	O
ELMo	O
results	O
.	O
paragraph	O
:	O
Multihead	O
vs.	O
Single	Method
Head	Method
Finetuning	Method
Decoders	Method
The	O
tweet	O
datasets	O
are	O
an	O
example	O
of	O
a	O
multilabel	Task
classification	Task
problem	Task
.	O
We	O
can	O
formulate	O
the	O
problem	O
for	O
the	O
finetuning	Method
decoder	O
,	O
as	O
either	O
a	O
collection	O
of	O
single	O
binary	Task
problems	Task
or	O
multiple	O
problems	O
put	O
together	O
.	O
The	O
single	O
binary	Method
problem	Method
formulation	Method
allows	O
for	O
a	O
focus	O
on	O
one	O
class	O
and	O
end	Task
-	Task
to	Task
-	Task
end	Task
optimization	Task
will	O
only	O
have	O
one	O
error	O
signal	O
.	O
However	O
,	O
because	O
the	O
label	O
classes	O
are	O
imbalanced	O
in	O
all	O
categories	O
,	O
this	O
may	O
lead	O
to	O
a	O
sparse	O
gradient	O
signal	O
for	O
the	O
positive	O
label	O
,	O
which	O
may	O
impact	O
recall	Metric
and	O
precision	Metric
.	O
Increasing	O
the	O
size	O
of	O
to	O
more	O
than	O
one	O
linear	Method
layer	Method
leads	O
to	O
rapid	O
overfitting	O
and	O
lower	O
validation	Metric
performance	Metric
.	O
The	O
combined	O
binary	Method
problems	Method
formulation	Method
(	O
henceforth	O
described	O
as	O
multihead	O
)	O
allows	O
for	O
a	O
richer	O
error	O
signal	O
that	O
propagates	O
more	O
information	O
through	O
the	O
encoder	Method
and	O
sentiment	Task
representation	O
in	O
.	O
In	O
this	O
setup	O
,	O
constructing	O
a	O
Multilayer	Method
network	Method
is	O
far	O
more	O
useful	O
,	O
and	O
can	O
be	O
thought	O
of	O
as	O
specifically	O
creating	O
sentiment	Task
features	O
to	O
be	O
used	O
at	O
the	O
final	O
layer	O
to	O
predict	O
the	O
presence	O
of	O
the	O
individual	O
emotions	O
.	O
We	O
find	O
that	O
the	O
inclusion	O
of	O
easier	O
,	O
more	O
balanced	O
label	O
categories	O
improves	O
performance	O
on	O
harder	O
ones	O
in	O
Table	O
[	O
reference	O
]	O
.	O
However	O
,	O
the	O
easier	O
categories	O
have	O
slightly	O
lower	O
performance	O
because	O
the	O
network	O
is	O
not	O
being	O
optimized	O
for	O
only	O
those	O
categories	O
.	O
paragraph	O
:	O
Thresholding	O
Supervised	O
Results	O
For	O
both	O
the	O
multihead	Method
MLP	Method
and	O
the	O
single	Method
linear	Method
layer	Method
instantiating	Method
of	Method
,	O
we	O
found	O
that	O
thresholding	O
predictions	O
produced	O
noticeably	O
better	O
results	O
than	O
using	O
a	O
fixed	O
threshold	O
value	O
such	O
as	O
.	O
This	O
makes	O
sense	O
since	O
the	O
label	O
classes	O
for	O
most	O
categories	O
are	O
very	O
imbalanced	O
.	O
For	O
thresholding	Task
,	O
we	O
take	O
a	O
dataset	O
of	O
tweets	O
and	O
split	O
it	O
into	O
training	O
(	O
70	O
%	O
)	O
,	O
thresholding	Method
(	O
10	O
%	O
)	O
and	O
validation	Metric
(	O
20	O
%	O
)	O
sets	O
.	O
At	O
each	O
epoch	O
of	O
finetuning	Method
on	O
the	O
training	O
set	O
,	O
we	O
calculate	O
validation	Metric
accuracy	Metric
and	O
save	O
predictions	O
on	O
the	O
threshold	O
set	O
on	O
the	O
epoch	O
for	O
which	O
this	O
is	O
maximized	O
.	O
To	O
threshold	O
,	O
we	O
search	O
the	O
discretized	O
version	O
of	O
[	O
0	O
,	O
1	O
]	O
:	O
the	O
linear	O
space	O
for	O
the	O
positive	O
label	O
threshold	O
for	O
each	O
category	O
.	O
We	O
denoted	O
the	O
threshold	O
which	O
gave	O
the	O
best	O
score	O
on	O
the	O
threshold	O
set	O
as	O
.	O
IBM	O
Watson	Method
and	O
Google	O
NLP	Task
both	O
offer	O
commercial	O
APIs	O
for	O
binary	O
sentiment	Task
analysis	O
,	O
producing	O
scalar	O
values	O
that	O
correspond	O
to	O
a	O
continuous	O
[	O
-	O
1	O
,+	O
1	O
]	O
sentiment	Task
score	O
.	O
We	O
applied	O
our	O
thresholding	Method
procedure	Method
to	O
these	O
scores	O
.	O
In	O
the	O
case	O
of	O
classification	Task
with	O
neutrals	O
we	O
create	O
two	O
thresholds	O
which	O
we	O
individually	O
optimized	O
jointly	O
over	O
as	O
well	O
.	O
With	O
the	O
finetuning	Method
procedure	O
,	O
we	O
found	O
success	O
with	O
a	O
decoder	Method
,	O
whose	O
two	O
output	O
units	O
are	O
probability	O
estimates	O
of	O
the	O
positive	O
and	O
negative	O
labels	O
.	O
These	O
units	O
both	O
have	O
sigmoid	O
activations	O
,	O
since	O
we	O
denote	O
a	O
neutral	O
as	O
.	O
To	O
threshold	O
these	O
predictions	O
,	O
we	O
searched	O
the	O
cartesian	O
product	O
to	O
determine	O
.	O
paragraph	O
:	O
Active	Method
Learning	Method
We	O
hypothesized	O
that	O
we	O
could	O
achieve	O
greater	O
precision	Metric
and	O
recall	Metric
on	O
our	O
datasets	O
if	O
our	O
class	O
label	O
were	O
more	O
equally	O
balanced	O
.	O
To	O
this	O
end	O
,	O
we	O
employed	O
an	O
active	Method
learning	Method
procedure	Method
to	O
select	O
unlabeled	O
tweets	O
to	O
be	O
labeled	O
.	O
The	O
algorithm	O
consisted	O
of	O
first	O
finetuning	Method
a	O
language	Method
model	Method
on	O
labeled	O
tweets	O
for	O
5	O
epochs	O
.	O
At	O
peak	O
validation	Metric
accuracy	Metric
,	O
we	O
obtain	O
predictions	O
,	O
for	O
Plutchik	O
sentiment	Task
on	O
the	O
unlabeled	O
tweets	O
.	O
From	O
the	O
labeled	O
dataset	O
,	O
we	O
calculate	O
the	O
negative	O
class	O
percentage	O
for	O
each	O
category	O
.	O
Then	O
we	O
obtain	O
category	O
a	O
weighting	O
parameter	O
so	O
that	O
for	O
Then	O
,	O
we	O
get	O
scores	O
for	O
each	O
unlabeled	O
point	O
as	O
weighted	O
features	O
:	O
.	O
This	O
way	O
,	O
positive	O
predictions	O
for	O
sentiment	Task
categories	O
are	O
weighted	O
by	O
how	O
much	O
they	O
would	O
contribute	O
towards	O
balancing	O
all	O
of	O
the	O
class	O
distributions	O
.	O
The	O
scores	O
are	O
used	O
as	O
weights	O
in	O
a	O
weighted	Method
uniform	Method
random	Method
sampler	Method
,	O
and	O
from	O
this	O
,	O
we	O
sampled	O
5	O
,	O
000	O
tweets	O
to	O
be	O
labeled	O
.	O
We	O
found	O
that	O
overall	O
,	O
the	O
method	O
produced	O
tweets	O
with	O
more	O
emotion	O
.	O
Not	O
only	O
was	O
the	O
positive	O
class	O
balance	O
averaged	O
across	O
label	O
categories	O
higher	O
(	O
11.2	O
%	O
compared	O
to	O
8.2	O
%	O
for	O
random	Method
sampling	Method
)	O
,	O
but	O
the	O
percentage	O
of	O
tweets	O
which	O
had	O
no	O
emotion	O
was	O
dramatically	O
lower	O
:	O
35.6	O
%	O
compared	O
to	O
52.1	O
%	O
for	O
random	Method
sampling	Method
(	O
Table	O
[	O
reference	O
]	O
)	O
.	O
We	O
hence	O
achieved	O
better	O
class	O
balance	O
than	O
the	O
dataset	O
prior	O
to	O
the	O
augmentation	Task
.	O
SST	Material
(	O
acc	O
)	O
Company	O
-/	O
=	O
/+	O
Transformer	Method
(	O
finetune	O
)	O
90.9%81.2%88.2	O
/	O
73.5	O
/	O
81.9mLSTM	O
(	O
finetune	O
)	O
90.4%78.2%87.0	O
/	O
69.3	O
/	O
78.38k	O
mLSTM	Method
[]	O
93.8%77.3%86.0	O
/	O
67.4	O
/	O
78.6	O
[]	O
93.1%	O
--	O
ELMo	O
(	O
finetuned	O
)	O
79.9%71.4%81.7	O
/	O
60.1	O
/	O
72.4ELMo	O
+	O
BiLSTM	O
+	O
Attn	O
[	O
]	O
91.6%	O
--	O
Watson	Method
API84.4%56.7%42.9	O
/	O
54.0	O
/	O
73.3Google	Method
Sentiment	Method
(	O
GCL	Method
)	O
API81.3%62.5%69.6	O
/	O
54.0	O
/	O
63.8Class	O
Balance50.0	O
/	O
50.0	O
-	O
22.4	O
/	O
46.0	O
/	O
31.6	O
AccuracyMicro	O
F1Macro	O
F1	O
(	O
Jaccard	O
)	O
Transformer	Method
(	O
ours	O
)	O
0.5770.6900.561	O
[]	O
0.5950.7090.542	O
[]	O
0.5820.6940.534	O
AngerAnticipationDisgustFearJoySadnessSurpriseTrustAverageCompanyTransformer	O
(	O
MH	O
)	O
.684.486.441.400.634.333.269.300.443Transformer	O
(	O
SH	O
)	O
.679.491.371.400.675.286.210.279.424mLSTM	O
(	O
SH	O
)	O
.636.426.319.232.609.260.201.284.371ELMo	O
(	O
MH	O
)	O
.515.306.325.086.489.182.161.182.281Watson.358	O
-	O
.179.086.520.096	O
-	O
--	O
SemevalTransformer	O
(	O
MH	O
)	O
.779.413.769.723.850.712.360.240.606Transformer	O
(	O
SH	O
)	O
.774.425.765.735.832.699.373.247.606mLSTM	O
(	O
SH	O
)	O
.668.189.691.535.763.557.103.000.438ELMo	O
(	O
MH	O
)	O
.506.215.351.172.540.348.164.239.317Watson.498	O
-	O
.331.149.684.359	O
-	O
--	O
section	O
:	O
Results	O
subsection	O
:	O
Binary	Material
Sentiment	Material
Tweets	Material
For	O
binary	O
sentiment	Task
,	O
we	O
compare	O
our	O
model	O
on	O
two	O
tasks	O
:	O
the	O
academic	Material
SST	Material
dataset	Material
,	O
which	O
consists	O
of	O
a	O
balanced	O
set	O
of	O
Positive	O
and	O
Negative	O
labels	O
,	O
and	O
the	O
company	O
tweets	O
dataset	O
,	O
which	O
consists	O
of	O
a	O
balance	O
between	O
Positive	O
,	O
Neutral	O
and	O
Negative	O
labels	O
.	O
See	O
Table	O
[	O
reference	O
]	O
.	O
While	O
the	O
Transformer	Method
gets	O
close	O
but	O
does	O
not	O
exceed	O
the	O
state	O
of	O
the	O
art	O
on	O
the	O
SST	Material
dataset	Material
,	O
it	O
exceeds	O
both	O
the	O
mLSTM	Method
and	O
ELMo	Method
baseline	Method
as	O
well	O
as	O
both	O
Watson	Method
and	O
Google	Method
Sentiment	Method
APIs	Method
on	O
the	O
company	O
tweets	O
.	O
This	O
is	O
despite	O
optimally	O
calibrating	O
the	O
API	O
results	O
on	O
the	O
test	O
set	O
.	O
subsection	O
:	O
Multi	O
-	O
Label	O
Emotion	O
Tweets	O
The	O
IBM	O
Watson	Method
API	O
offers	O
multi	O
-	O
label	Task
emotion	Task
predictions	Task
for	O
five	O
categories	O
:	O
Anger	O
,	O
Disgust	O
,	O
Fear	O
,	O
Joy	O
and	O
Sadness	O
.	O
We	O
compare	O
our	O
models	O
to	O
Watson	Method
on	O
these	O
categories	O
for	O
both	O
the	O
SemEval	Material
dataset	O
and	O
the	O
company	O
tweets	O
in	O
Table	O
[	O
reference	O
]	O
.	O
We	O
find	O
that	O
our	O
models	O
outperform	O
Watson	Method
on	O
every	O
emotion	O
category	O
.	O
paragraph	O
:	O
SemEval	Material
Tweets	O
We	O
submitted	O
our	O
finetuned	O
Transformer	Method
model	O
to	O
the	O
SemEval	Material
Task1:E	O
-	O
C	O
challenge	O
,	O
as	O
seen	O
in	O
Table	O
[	O
reference	O
]	O
.	O
These	O
results	O
were	O
computed	O
by	O
the	O
organizers	O
on	O
a	O
golden	O
test	O
set	O
,	O
for	O
which	O
we	O
do	O
not	O
have	O
access	O
to	O
the	O
truth	O
labels	O
.	O
Our	O
model	O
achieved	O
the	O
top	O
macro	Metric
-	O
averaged	O
F1	O
score	O
among	O
all	O
submission	O
,	O
with	O
competitive	O
but	O
lower	O
scores	O
for	O
the	O
micro	Metric
-	O
average	O
F1	O
an	O
the	O
Jaccard	Metric
Index	Metric
accuracy	Metric
.	O
This	O
suggests	O
that	O
our	O
model	O
out	O
-	O
performs	O
the	O
other	O
top	O
submission	O
on	O
rare	O
and	O
difficult	O
categories	O
,	O
since	O
macro	Metric
-	Metric
average	Metric
weighs	O
performance	O
on	O
all	O
classes	O
equally	O
,	O
and	O
the	O
most	O
common	O
categories	O
of	O
Joy	O
,	O
Anger	O
,	O
Disgust	O
and	O
Optimism	O
get	O
relatively	O
higher	O
F1	Metric
scores	Metric
across	O
all	O
models	O
.	O
We	O
also	O
compare	O
the	O
deep	Method
learning	Method
architectures	Method
of	O
the	O
Transformer	Method
and	O
mLSTM	Method
on	O
this	O
dataset	O
in	O
Table	O
[	O
reference	O
]	O
and	O
find	O
that	O
the	O
Transformer	Method
outperforms	O
the	O
mLSTM	Method
across	O
Plutchik	O
categories	O
.	O
The	O
winner	O
of	O
the	O
Task1:E	O
-	O
c	O
challenge	O
trained	O
a	O
bidirectional	Method
LSTM	Method
with	O
an	O
800	O
,	O
000	O
word	O
embedding	O
vocabulary	O
derived	O
from	O
training	O
word	O
vectors	O
on	O
a	O
dataset	O
of	O
550	O
million	O
tweets	O
.	O
Similarly	O
,	O
the	O
second	O
place	O
winner	O
of	O
the	O
SemEval	Material
leaderboard	Material
trained	O
a	O
word	Method
-	Method
level	Method
bidirectional	Method
LSTM	Method
with	O
attention	Method
,	O
as	O
well	O
as	O
including	O
non	O
-	O
deep	O
learning	O
features	O
into	O
their	O
ensemble	O
.	O
Both	O
submissions	O
used	O
training	O
data	O
across	O
SemEval	Material
tasks	O
,	O
as	O
well	O
as	O
additional	O
training	O
data	O
outside	O
of	O
the	O
training	O
set	O
.	O
In	O
comparison	O
,	O
we	O
demonstrate	O
that	O
finetuning	Method
can	O
be	O
as	O
effective	O
on	O
this	O
task	O
,	O
despite	O
training	O
only	O
on	O
7	O
,	O
000	O
tweets	O
.	O
Furthermore	O
,	O
out	Method
language	Method
modeling	Method
took	O
place	O
on	O
the	O
Amazon	O
Reviews	O
dataset	O
,	O
which	O
does	O
not	O
contain	O
emoji	O
,	O
hashtags	O
or	O
usernames	O
.	O
We	O
would	O
expect	O
to	O
see	O
improvements	O
if	O
our	O
unsupervised	O
dataset	O
contained	O
emoji	O
,	O
for	O
example	O
.	O
paragraph	O
:	O
Plutchik	O
on	O
Company	O
Tweets	O
Our	O
models	O
gets	O
lower	O
F1	Metric
scores	Metric
on	O
the	O
company	O
tweets	O
dataset	O
than	O
on	O
equivalent	O
SemEval	Material
categories	O
.	O
As	O
with	O
the	O
SemEval	Material
challenge	O
tweets	O
,	O
the	O
Transformer	Method
outperformed	O
the	O
mLSTM	Method
.	O
These	O
results	O
are	O
shown	O
in	O
Table	O
[	O
reference	O
]	O
.	O
Both	O
models	O
performed	O
significantly	O
better	O
than	O
the	O
Watson	Method
API	O
on	O
all	O
categories	O
for	O
which	O
Watson	Method
supplies	O
predictions	O
.	O
We	O
could	O
not	O
conclusively	O
determine	O
whether	O
the	O
singlehead	O
or	O
the	O
multihead	O
Transformer	Method
will	O
perform	O
better	O
on	O
a	O
given	O
task	O
.	O
Thus	O
we	O
recommend	O
trying	O
both	O
methods	O
on	O
a	O
new	O
dataset	O
.	O
section	O
:	O
Analysis	O
paragraph	O
:	O
Classification	Task
Performance	O
by	O
Dataset	O
Size	O
We	O
would	O
have	O
liked	O
to	O
label	O
more	O
data	O
for	O
the	O
company	O
tweets	O
dataset	O
,	O
and	O
thus	O
looked	O
into	O
how	O
much	O
extra	O
labeling	O
contributes	O
to	O
finetuned	O
model	Metric
performance	Metric
accuracy	Metric
.	O
First	O
,	O
let	O
us	O
explain	O
the	O
difference	O
between	O
micro	Metric
and	O
macro	Metric
averaging	Metric
of	Metric
the	Metric
F1	Metric
scores	Metric
.	O
We	O
can	O
summarize	O
the	O
F1	Metric
scores	Metric
of	O
categories	O
(	O
or	O
any	O
other	O
metric	O
)	O
through	O
macro	Metric
and	Metric
micro	Metric
averaging	Metric
to	O
obtain	O
.	O
The	O
macro	Metric
method	O
weights	O
each	O
class	O
equally	O
by	O
averaging	O
the	O
metric	O
calculated	O
on	O
each	O
individual	O
class	O
.	O
The	O
micro	Metric
method	O
accounts	O
for	O
the	O
class	O
imbalances	O
in	O
each	O
category	O
by	O
aggregating	O
all	O
of	O
the	O
true	O
/	O
false	O
positives	O
/	O
negatives	O
first	O
,	O
and	O
then	O
calculating	O
an	O
overall	Metric
metric	Metric
.	O
In	O
one	O
experiment	O
,	O
we	O
decreased	O
the	O
size	O
of	O
the	O
training	O
dataset	O
and	O
observed	O
the	O
resulting	O
macro	Metric
and	O
micro	Metric
averaged	Metric
F1	Metric
scores	Metric
across	O
all	O
categories	O
on	O
company	O
tweets	O
.	O
The	O
results	O
are	O
shown	O
in	O
Fig	O
.	O
[	O
reference	O
]	O
.	O
We	O
observe	O
that	O
the	O
macro	Metric
average	O
is	O
more	O
sensitive	O
to	O
dataset	O
size	O
and	O
falls	O
more	O
quickly	O
than	O
the	O
micro	Metric
average	O
.	O
The	O
interpretation	O
of	O
this	O
is	O
that	O
categories	O
with	O
worse	O
class	O
imbalance	O
(	O
which	O
consequently	O
influence	O
macro	Metric
more	O
than	O
micro	Metric
average	O
)	O
benefit	O
more	O
from	O
having	O
a	O
larger	O
training	O
dataset	O
size	O
.	O
This	O
suggests	O
that	O
we	O
may	O
obtain	O
substantially	O
better	O
results	O
with	O
more	O
data	O
in	O
the	O
harder	O
categories	O
.	O
We	O
conducted	O
a	O
related	O
experiment	O
that	O
focused	O
on	O
the	O
difference	O
in	O
category	Metric
performance	Metric
when	O
using	O
a	O
single	O
head	O
versus	O
a	O
multihead	Method
decoder	Method
.	O
We	O
apply	O
the	O
two	O
architectures	O
at	O
different	O
training	O
dataset	O
sizes	O
for	O
three	O
different	O
label	O
categories	O
:	O
Anger	O
,	O
Anticipation	O
and	O
Trust	O
,	O
which	O
we	O
categorize	O
as	O
low	O
,	O
medium	O
and	O
high	O
difficulty	O
,	O
respectively	O
.	O
As	O
seen	O
in	O
Fig	O
.	O
[	O
reference	O
]	O
it	O
appears	O
that	O
the	O
difference	O
between	O
the	O
single	O
and	O
multihead	O
becomes	O
more	O
pronounced	O
for	O
more	O
difficult	O
categories	O
,	O
as	O
well	O
as	O
for	O
smaller	O
dataset	O
sizes	O
.	O
We	O
do	O
not	O
have	O
enough	O
data	O
to	O
make	O
a	O
firm	O
conclusion	O
,	O
but	O
this	O
study	O
suggests	O
that	O
we	O
could	O
get	O
more	O
out	O
of	O
the	O
labeled	O
data	O
that	O
we	O
have	O
,	O
by	O
studying	O
which	O
categories	O
benefit	O
from	O
single	Method
head	Method
and	Method
multihead	Method
decoders	Method
.	O
All	O
categories	O
benefit	O
from	O
more	O
training	O
data	O
,	O
but	O
some	O
categories	O
benefit	O
from	O
from	O
marginal	O
labeled	O
data	O
than	O
others	O
.	O
This	O
suggests	O
further	O
and	O
more	O
rigorous	O
study	O
of	O
the	O
boostrapping	Method
methods	Method
we	O
used	O
to	O
select	O
tweets	O
for	O
our	O
human	Task
labeling	Task
budget	Task
,	O
as	O
described	O
in	O
the	O
Active	Task
Learning	Task
section	O
.	O
[	O
t	O
]	O
0.263	O
[	O
t	O
]	O
0.717	O
paragraph	O
:	O
Dataset	Metric
Quality	Metric
and	O
Human	Metric
Rater	Metric
Agreement	Metric
The	O
SemEval	Material
dataset	O
applies	O
a	O
positive	O
label	O
for	O
every	O
category	O
where	O
2	O
out	O
of	O
7	O
vetted	O
raters	O
agree	O
.	O
The	O
reason	O
is	O
for	O
the	O
dataset	O
to	O
contain	O
difficult	O
and	O
subtle	O
examples	O
of	O
sentiments	O
,	O
not	O
just	O
those	O
examples	O
where	O
everyone	O
agrees	O
.	O
The	O
raters	O
also	O
have	O
a	O
tendency	O
to	O
under	O
-	O
label	O
categories	O
,	O
especially	O
when	O
presented	O
multiple	O
options	O
.	O
Following	O
a	O
similar	O
process	O
,	O
we	O
required	O
2	O
out	O
of	O
5	O
raters	O
for	O
a	O
positive	O
label	O
,	O
and	O
in	O
the	O
case	O
of	O
binary	O
sentiment	Task
labels	O
(	O
Positive	O
,	O
Neutral	O
,	O
Negative	O
)	O
,	O
we	O
rounded	O
toward	O
polarized	O
sentiment	Task
and	O
away	O
from	O
Neutral	O
labels	O
in	O
the	O
case	O
of	O
a	O
2	O
/	O
3	O
split	O
.	O
Applying	O
the	O
SemEval	Material
-	O
trained	O
Transformer	Method
directly	O
to	O
our	O
company	O
tweets	O
dataset	O
gets	O
reasonably	O
good	O
results	O
(	O
0.338	O
macro	Metric
average	O
)	O
,	O
also	O
validating	O
that	O
our	O
labeling	Method
technique	Method
is	O
similar	O
to	O
that	O
of	O
SemEval	Material
.	O
Looking	O
at	O
rater	Metric
agreement	Metric
by	O
dataset	O
(	O
Fig	O
.	O
[	O
reference	O
]	O
)	O
,	O
we	O
see	O
that	O
Plutchik	O
category	O
labels	O
contain	O
large	O
rater	O
disagreement	O
,	O
even	O
among	O
vetted	O
raters	O
who	O
passed	O
the	O
golden	O
set	O
test	O
.	O
Furthermore	O
,	O
datasets	O
with	O
more	O
emotions	O
(	O
the	O
SemEval	Material
dataset	O
and	O
our	O
active	O
learning	O
sampled	O
company	O
tweets	O
)	O
contain	O
higher	O
Plutchik	O
disagreement	O
than	O
random	O
company	O
tweets	O
.	O
This	O
is	O
likely	O
because	O
raters	O
tend	O
to	O
apply	O
the	O
”	O
No	O
Emotion	O
”	O
label	O
when	O
they	O
are	O
not	O
sure	O
about	O
a	O
category	O
.	O
As	O
Table	O
[	O
reference	O
]	O
shows	O
,	O
the	O
SemEval	Material
and	O
active	O
company	O
tweets	O
datasets	O
contain	O
fewer	O
no	O
-	O
emotion	O
tweets	O
than	O
other	O
datsets	O
.	O
It	O
would	O
be	O
interesting	O
to	O
analyze	O
rater	O
disagreement	O
by	O
category	O
,	O
how	O
much	O
this	O
effects	O
classifier	Task
convergence	Task
,	O
whether	O
getting	O
7	O
+	O
ratings	O
per	O
tweet	O
helps	O
classifier	Task
convergence	Task
,	O
and	O
also	O
whether	O
this	O
work	O
could	O
benefit	O
from	O
estimating	O
rater	Metric
quality	Metric
via	O
agreement	O
with	O
the	O
crowd	O
,	O
as	O
proposed	O
in	O
.	O
However	O
this	O
analysis	O
is	O
not	O
straightforward	O
,	O
as	O
the	O
truth	O
data	O
is	O
itself	O
collected	O
through	O
human	Task
labeling	Task
.	O
Alongside	O
classifier	Metric
convergence	Metric
by	O
dataset	O
size	O
(	O
Fig	O
.	O
[	O
reference	O
]	O
)	O
,	O
we	O
think	O
that	O
this	O
could	O
be	O
an	O
interesting	O
area	O
a	O
future	O
research	O
.	O
paragraph	O
:	O
Difficult	O
tweets	O
and	O
challenging	O
contexts	O
.	O
There	O
is	O
not	O
sufficient	O
space	O
for	O
a	O
thorough	O
analysis	O
,	O
but	O
we	O
wanted	O
to	O
suggest	O
why	O
general	Method
purpose	Method
APIs	Method
may	O
not	O
work	O
well	O
on	O
our	O
company	O
tweets	O
dataset	O
.	O
Table	O
[	O
reference	O
]	O
samples	O
the	O
largest	O
binary	O
sentiment	Task
disagreements	O
between	O
human	O
raters	O
and	O
the	O
Watson	Method
API	O
.	O
For	O
simplicity	O
,	O
we	O
restrict	O
examples	O
to	O
video	O
game	O
tweets	O
,	O
which	O
comprise	O
19.1	O
%	O
of	O
our	O
test	O
set	O
.	O
As	O
we	O
can	O
see	O
,	O
all	O
of	O
these	O
examples	O
appear	O
to	O
ascribe	O
negative	O
emotion	O
to	O
generally	O
negative	O
terms	O
which	O
,	O
in	O
a	O
video	O
game	O
context	O
,	O
do	O
not	O
indicate	O
negative	O
sentiment	Task
.	O
Our	O
purpose	O
is	O
not	O
to	O
castigate	O
the	O
Watson	Method
or	O
the	O
GCL	O
APIs	O
.	O
Rather	O
,	O
we	O
propose	O
that	O
it	O
may	O
not	O
be	O
possible	O
to	O
provide	O
context	O
-	O
independent	O
emotion	Method
classification	Method
scores	Method
that	O
work	O
well	O
across	O
text	O
contexts	O
.	O
It	O
may	O
work	O
better	O
in	O
practice	O
,	O
on	O
some	O
tasks	O
,	O
to	O
train	O
a	O
large	O
unsupervised	Method
model	Method
and	O
to	O
use	O
a	O
small	O
amount	O
of	O
labeled	O
data	O
to	O
finetune	O
on	O
the	O
context	O
present	O
in	O
the	O
specific	O
dataset	O
.	O
We	O
would	O
like	O
to	O
quantify	O
this	O
further	O
in	O
future	O
work	O
.	O
Recent	O
work	O
shows	O
that	O
training	O
an	O
RNN	Method
with	O
multiple	O
softmax	O
outputs	O
leads	O
to	O
a	O
much	O
improved	O
BPC	Method
on	O
language	Task
modeling	Task
,	O
especially	O
for	O
diverse	O
datasets	O
and	O
models	O
with	O
large	O
vocabularies	O
.	O
This	O
is	O
because	O
the	O
multiple	O
softmaxes	Method
are	O
able	O
to	O
capture	O
a	O
larger	O
number	O
of	O
distinct	O
contexts	O
in	O
the	O
text	O
than	O
a	O
single	O
output	O
.	O
Perhaps	O
our	O
Transformer	Method
also	O
captures	O
the	O
features	O
relevant	O
to	O
a	O
large	O
number	O
of	O
distinct	O
contexts	O
,	O
and	O
the	O
finetuning	Method
is	O
able	O
to	O
select	O
the	O
most	O
significant	O
of	O
these	O
features	O
,	O
while	O
ignoring	O
those	O
features	O
that	O
–	O
while	O
adding	O
value	O
in	O
general	O
–	O
are	O
not	O
appropriate	O
in	O
a	O
video	Task
game	Task
setting	Task
.	O
section	O
:	O
Conclusion	O
In	O
this	O
work	O
we	O
demonstrate	O
that	O
unsupervised	Task
pretraining	Task
and	O
finetuning	Method
provides	O
a	O
flexible	O
framework	O
that	O
is	O
effective	O
for	O
difficult	O
text	Task
classification	Task
tasks	Task
.	O
We	O
noticed	O
that	O
the	O
finetuning	Method
was	O
especially	O
effective	O
with	O
the	O
Transformer	Method
network	O
,	O
when	O
transferring	O
to	O
downstream	Task
tasks	Task
with	O
noisy	O
labels	O
and	O
specialized	O
context	O
.	O
We	O
think	O
that	O
this	O
framework	O
makes	O
it	O
easy	O
to	O
customize	O
a	O
text	Method
classification	Method
model	Method
on	O
niche	Task
tasks	Task
.	O
Unsupervised	Method
language	Method
modeling	Method
can	O
be	O
done	O
on	O
general	O
text	O
datasets	O
,	O
and	O
requires	O
no	O
labels	O
.	O
Meanwhile	O
downstream	Task
task	Task
transfer	Task
works	O
well	O
enough	O
,	O
even	O
on	O
small	O
amounts	O
of	O
domain	O
-	O
specific	O
labelled	O
data	O
,	O
to	O
be	O
accessible	O
to	O
most	O
academics	O
and	O
small	O
organization	O
.	O
It	O
would	O
be	O
great	O
to	O
see	O
this	O
approach	O
applied	O
to	O
a	O
variety	O
of	O
practical	O
text	Task
classification	Task
problems	Task
,	O
much	O
as	O
and	O
have	O
applied	O
language	Method
modeling	Method
and	O
transfer	Task
to	O
a	O
variety	O
of	O
academic	Task
text	Task
understanding	Task
problems	Task
on	O
the	O
GLUE	O
Benchmark	O
.	O
bibliography	O
:	O
References	O
