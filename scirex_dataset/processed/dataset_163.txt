document	O
:	O
Stacked	Method
Attention	Method
Networks	Method
for	O
Image	Task
Question	Task
Answering	Task
This	O
paper	O
presents	O
stacked	Method
attention	Method
networks	Method
(	O
SANs	Method
)	O
that	O
learn	O
to	O
answer	O
natural	O
language	O
questions	O
from	O
images	O
.	O

SANs	O
use	O
semantic	Method
representation	Method
of	O
a	O
question	O
as	O
query	O
to	O
search	O
for	O
the	O
regions	O
in	O
an	O
image	O
that	O
are	O
related	O
to	O
the	O
answer	O
.	O

We	O
argue	O
that	O
image	Task
question	Task
answering	Task
(	O
QA	Task
)	O
often	O
requires	O
multiple	O
steps	O
of	O
reasoning	Task
.	O

Thus	O
,	O
we	O
develop	O
a	O
multiple	O
-	O
layer	O
SAN	Method
in	O
which	O
we	O
query	O
an	O
image	O
multiple	O
times	O
to	O
infer	O
the	O
answer	O
progressively	O
.	O

Experiments	O
conducted	O
on	O
four	O
image	Task
QA	Task
data	O
sets	O
demonstrate	O
that	O
the	O
proposed	O
SANs	Method
significantly	O
outperform	O
previous	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
approaches	O
.	O

The	O
visualization	O
of	O
the	O
attention	O
layers	O
illustrates	O
the	O
progress	O
that	O
the	O
SAN	Method
locates	O
the	O
relevant	O
visual	Method
clues	O
that	O
lead	O
to	O
the	O
answer	O
of	O
the	O
question	O
layer	O
-	O
by	O
-	O
layer	O
.	O

section	O
:	O
Introduction	O
With	O
the	O
recent	O
advancement	O
in	O
computer	Task
vision	Task
and	O
in	O
natural	Task
language	Task
processing	Task
(	O
NLP	Task
)	O
,	O
image	Task
question	Task
answering	Task
(	O
QA	Task
)	O
becomes	O
one	O
of	O
the	O
most	O
active	O
research	O
areas	O
.	O

Unlike	O
pure	Method
language	Method
based	Method
QA	Method
systems	Method
that	O
have	O
been	O
studied	O
extensively	O
in	O
the	O
NLP	Task
community	O
,	O
image	Task
QA	Task
systems	O
are	O
designed	O
to	O
automatically	O
answer	O
natural	O
language	O
questions	O
according	O
to	O
the	O
content	O
of	O
a	O
reference	O
image	O
.	O

[	O
t	O
]	O
1.0	O
[	O
t	O
]	O
1.0	O
Most	O
of	O
the	O
recently	O
proposed	O
image	Task
QA	Task
models	O
are	O
based	O
on	O
neural	Method
networks	Method
.	O

A	O
commonly	O
used	O
approach	O
was	O
to	O
extract	O
a	O
global	O
image	O
feature	O
vector	O
using	O
a	O
convolution	Method
neural	Method
network	Method
(	O
CNN	Method
)	O
and	O
encode	O
the	O
corresponding	O
question	O
as	O
a	O
feature	O
vector	O
using	O
a	O
long	Method
short	Method
-	Method
term	Method
memory	Method
network	Method
(	O
LSTM	Method
)	O
and	O
then	O
combine	O
them	O
to	O
infer	O
the	O
answer	O
.	O

Though	O
impressive	O
results	O
have	O
been	O
reported	O
,	O
these	O
models	O
often	O
fail	O
to	O
give	O
precise	O
answers	O
when	O
such	O
answers	O
are	O
related	O
to	O
a	O
set	O
of	O
fine	O
-	O
grained	O
regions	O
in	O
an	O
image	O
.	O

By	O
examining	O
the	O
image	Task
QA	Task
data	O
sets	O
,	O
we	O
find	O
that	O
it	O
is	O
often	O
that	O
case	O
that	O
answering	O
a	O
question	O
from	O
an	O
image	O
requires	O
multi	Method
-	Method
step	Method
reasoning	Method
.	O

Take	O
the	O
question	O
and	O
image	O
in	O
Fig	O
.	O

[	O
reference	O
]	O
as	O
an	O
example	O
.	O

There	O
are	O
several	O
objects	O
in	O
the	O
image	O
:	O
bicycles	O
,	O
window	O
,	O
street	O
,	O
baskets	O
and	O
dogs	O
.	O

To	O
answer	O
the	O
question	O
what	O
are	O
sitting	O
in	O
the	O
basket	O
on	O
a	O
bicycle	O
,	O
we	O
need	O
to	O
first	O
locate	O
those	O
objects	O
(	O
e.g.	O
basket	O
,	O
bicycle	O
)	O
and	O
concepts	O
(	O
e.g.	O
,	O
sitting	O
in	O
)	O
referred	O
in	O
the	O
question	O
,	O
then	O
gradually	O
rule	O
out	O
irrelevant	O
objects	O
,	O
and	O
finally	O
pinpoint	O
to	O
the	O
region	O
that	O
are	O
most	O
indicative	O
to	O
infer	O
the	O
answer	O
(	O
i.e.	O
,	O
dogs	O
in	O
the	O
example	O
)	O
.	O

In	O
this	O
paper	O
,	O
we	O
propose	O
stacked	Method
attention	Method
networks	Method
(	O
SANs	Method
)	O
that	O
allow	O
multi	Method
-	Method
step	Method
reasoning	Method
for	O
image	Task
QA	Task
.	O

SANs	Method
can	O
be	O
viewed	O
as	O
an	O
extension	O
of	O
the	O
attention	Method
mechanism	Method
that	O
has	O
been	O
successfully	O
applied	O
in	O
image	Task
captioning	Task
and	O
machine	Task
translation	Task
.	O

The	O
overall	O
architecture	O
of	O
SAN	Method
is	O
illustrated	O
in	O
Fig	O
.	O

[	O
reference	O
]	O
.	O

The	O
SAN	Method
consists	O
of	O
three	O
major	O
components	O
:	O
(	O
1	O
)	O
the	O
image	Method
model	Method
,	O
which	O
uses	O
a	O
CNN	Method
to	O
extract	O
high	O
level	O
image	O
representations	O
,	O
e.g.	O
one	O
vector	O
for	O
each	O
region	O
of	O
the	O
image	O
;	O
(	O
2	Method
)	O
the	O
question	Method
model	Method
,	O
which	O
uses	O
a	O
CNN	Method
or	O
a	O
LSTM	Method
to	O
extract	O
a	O
semantic	O
vector	O
of	O
the	O
question	O
and	O
(	O
3	O
)	O
the	O
stacked	Method
attention	Method
model	Method
,	O
which	O
locates	O
,	O
via	O
multi	Method
-	Method
step	Method
reasoning	Method
,	O
the	O
image	O
regions	O
that	O
are	O
relevant	O
to	O
the	O
question	O
for	O
answer	Task
prediction	Task
.	O

As	O
illustrated	O
in	O
Fig	O
.	O

[	O
reference	O
]	O
,	O
the	O
SAN	Method
first	O
uses	O
the	O
question	O
vector	O
to	O
query	O
the	O
image	O
vectors	O
in	O
the	O
first	O
visual	Method
attention	O
layer	O
,	O
then	O
combine	O
the	O
question	O
vector	O
and	O
the	O
retrieved	O
image	O
vectors	O
to	O
form	O
a	O
refined	O
query	O
vector	O
to	O
query	O
the	O
image	O
vectors	O
again	O
in	O
the	O
second	O
attention	Method
layer	Method
.	O

The	O
higher	O
-	O
level	O
attention	Method
layer	Method
gives	O
a	O
sharper	O
attention	O
distribution	O
focusing	O
on	O
the	O
regions	O
that	O
are	O
more	O
relevant	O
to	O
the	O
answer	O
.	O

Finally	O
,	O
we	O
combine	O
the	O
image	O
features	O
from	O
the	O
highest	O
attention	Method
layer	Method
with	O
the	O
last	O
query	O
vector	O
to	O
predict	O
the	O
answer	O
.	O

The	O
main	O
contributions	O
of	O
our	O
work	O
are	O
three	O
-	O
fold	O
.	O

First	O
,	O
we	O
propose	O
a	O
stacked	Method
attention	Method
network	Method
for	O
image	Task
QA	Task
tasks	Task
.	O

Second	O
,	O
we	O
perform	O
comprehensive	O
evaluations	O
on	O
four	O
image	Task
QA	Task
benchmarks	Task
,	O
demonstrating	O
that	O
the	O
proposed	O
multiple	O
-	O
layer	O
SAN	Method
outperforms	O
previous	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
approaches	O
by	O
a	O
substantial	O
margin	O
.	O

Third	O
,	O
we	O
perform	O
a	O
detailed	O
analysis	O
where	O
we	O
visualize	O
the	O
outputs	O
of	O
different	O
attention	Method
layers	Method
of	O
the	O
SAN	Method
and	O
demonstrate	O
the	O
process	O
that	O
the	O
SAN	Method
takes	O
multiple	O
steps	O
to	O
progressively	O
focus	O
the	O
attention	O
on	O
the	O
relevant	O
visual	Method
clues	O
that	O
lead	O
to	O
the	O
answer	O
.	O

section	O
:	O
Related	O
Work	O
Image	Task
QA	Task
is	O
closely	O
related	O
to	O
image	Task
captioning	Task
.	O

In	O
,	O
the	O
system	O
first	O
extracted	O
a	O
high	O
level	O
image	O
feature	O
vector	O
from	O
GoogleNet	Method
and	O
then	O
fed	O
it	O
into	O
a	O
LSTM	Method
to	O
generate	O
captions	Task
.	O

The	O
method	O
proposed	O
in	O
went	O
one	O
step	O
further	O
to	O
use	O
an	O
attention	Method
mechanism	Method
in	O
the	O
caption	Task
generation	Task
process	Task
.	O

Different	O
from	O
,	O
the	O
approach	O
proposed	O
in	O
first	O
used	O
a	O
CNN	Method
to	O
detect	O
words	O
given	O
the	O
images	O
,	O
then	O
used	O
a	O
maximum	Method
entropy	Method
language	Method
model	Method
to	O
generate	O
a	O
list	O
of	O
caption	O
candidates	O
,	O
and	O
finally	O
used	O
a	O
deep	Method
multimodal	Method
similarity	Method
model	Method
(	O
DMSM	Method
)	O
to	O
re	O
-	O
rank	O
the	O
candidates	O
.	O

Instead	O
of	O
using	O
a	O
RNN	Method
or	O
a	O
LSTM	Method
,	O
the	O
DMSM	Method
uses	O
a	O
CNN	Method
to	O
model	O
the	O
semantics	Task
of	Task
captions	Task
.	O

Unlike	O
image	Task
captioning	Task
,	O
in	O
image	Task
QA	Task
,	O
the	O
question	O
is	O
given	O
and	O
the	O
task	O
is	O
to	O
learn	O
the	O
relevant	O
visual	Method
and	O
text	Method
representation	Method
to	O
infer	O
the	O
answer	O
.	O

In	O
order	O
to	O
facilitate	O
the	O
research	O
of	O
image	Task
QA	Task
,	O
several	O
data	O
sets	O
have	O
been	O
constructed	O
in	O
either	O
through	O
automatic	Task
generation	Task
based	O
on	O
image	O
caption	O
data	O
or	O
by	O
human	Method
labeling	Method
of	O
questions	O
and	O
answers	O
given	O
images	O
.	O

Among	O
them	O
,	O
the	O
image	Task
QA	Task
data	O
set	O
in	O
is	O
generated	O
based	O
on	O
the	O
COCO	Material
caption	Material
data	Material
set	Material
.	O

Given	O
a	O
sentence	O
that	O
describes	O
an	O
image	O
,	O
the	O
authors	O
first	O
used	O
a	O
parser	Method
to	O
parse	O
the	O
sentence	O
,	O
then	O
replaced	O
the	O
key	O
word	O
in	O
the	O
sentence	O
using	O
question	O
words	O
and	O
the	O
key	O
word	O
became	O
the	O
answer	O
.	O

created	O
an	O
image	Task
QA	Task
data	O
set	O
through	O
human	Task
labeling	Task
.	O

The	O
initial	O
version	O
was	O
in	O
Chinese	O
and	O
then	O
was	O
translated	O
to	O
English	O
.	O

also	O
created	O
an	O
image	Task
QA	Task
data	O
set	O
through	O
human	Task
labeling	Task
.	O

They	O
collected	O
questions	O
and	O
answers	O
not	O
only	O
for	O
real	O
images	O
,	O
but	O
also	O
for	O
abstract	O
scenes	O
.	O

Several	O
image	Task
QA	Task
models	O
were	O
proposed	O
in	O
the	O
literature	O
.	O

used	O
semantic	Method
parsers	Method
and	O
image	Method
segmentation	Method
methods	Method
to	O
predict	O
answers	O
based	O
on	O
images	O
and	O
questions	O
.	O

both	O
used	O
encoder	Method
-	Method
decoder	Method
framework	Method
to	O
generate	O
answers	O
given	O
images	O
and	O
questions	O
.	O

They	O
first	O
used	O
a	O
LSTM	Method
to	O
encoder	O
the	O
images	O
and	O
questions	O
and	O
then	O
used	O
another	O
LSTM	Method
to	O
decode	O
the	O
answers	O
.	O

They	O
both	O
fed	O
the	O
image	O
feature	O
to	O
every	O
LSTM	Method
cell	Method
.	O

proposed	O
several	O
neural	Method
network	Method
based	Method
models	Method
,	O
including	O
the	O
encoder	Method
-	Method
decoder	Method
based	Method
models	Method
that	O
use	O
single	O
direction	O
LSTMs	Method
and	O
bi	O
-	O
direction	O
LSTMs	Method
,	O
respectively	O
.	O

However	O
,	O
the	O
authors	O
found	O
the	O
concatenation	O
of	O
image	O
features	O
and	O
bag	Method
of	Method
words	Method
features	Method
worked	O
the	O
best	O
.	O

first	O
encoded	O
questions	O
with	O
LSTMs	Method
and	O
then	O
combined	O
question	O
vectors	O
with	O
image	O
vectors	O
by	O
element	Method
wise	Method
multiplication	Method
.	O

used	O
a	O
CNN	Method
for	O
question	Task
modeling	Task
and	O
used	O
convolution	Method
operations	Method
to	O
combine	O
question	O
vectors	O
and	O
image	O
feature	O
vectors	O
.	O

We	O
compare	O
the	O
SAN	Method
with	O
these	O
models	O
in	O
Sec	O
.	O

[	O
reference	O
]	O
.	O

To	O
the	O
best	O
of	O
our	O
knowledge	O
,	O
the	O
attention	Method
mechanism	Method
,	O
which	O
has	O
been	O
proved	O
very	O
successful	O
in	O
image	Task
captioning	Task
,	O
has	O
not	O
been	O
explored	O
for	O
image	Task
QA	Task
.	O

The	O
SAN	Method
adapt	O
the	O
attention	Method
mechanism	Method
to	O
image	Task
QA	Task
,	O
and	O
can	O
be	O
viewed	O
as	O
a	O
significant	O
extension	O
to	O
previous	O
models	O
in	O
that	O
multiple	O
attention	Method
layers	Method
are	O
used	O
to	O
support	O
multi	Method
-	Method
step	Method
reasoning	Method
for	O
the	O
image	Task
QA	Task
task	O
.	O

section	O
:	O
Stacked	Method
Attention	Method
Networks	Method
(	O
SANs	Method
)	O
The	O
overall	O
architecture	O
of	O
the	O
SAN	Method
is	O
shown	O
in	O
Fig	O
.	O

[	O
reference	O
]	O
.	O

We	O
describe	O
the	O
three	O
major	O
components	O
of	O
SAN	Method
in	O
this	O
section	O
:	O
the	O
image	Method
model	Method
,	O
the	O
question	Method
model	Method
,	O
and	O
the	O
stacked	Method
attention	Method
model	Method
.	O

subsection	O
:	O
Image	Method
Model	Method
The	O
image	Method
model	Method
uses	O
a	O
CNN	Method
to	O
get	O
the	O
representation	Task
of	Task
images	Task
.	O

Specifically	O
,	O
the	O
VGGNet	Method
is	O
used	O
to	O
extract	O
the	O
image	O
feature	O
map	O
from	O
a	O
raw	O
image	O
:	O
Unlike	O
previous	O
studies	O
that	O
use	O
features	O
from	O
the	O
last	O
inner	Method
product	Method
layer	Method
,	O
we	O
choose	O
the	O
features	O
from	O
the	O
last	Method
pooling	Method
layer	Method
,	O
which	O
retains	O
spatial	O
information	O
of	O
the	O
original	O
images	O
.	O

We	O
first	O
rescale	O
the	O
images	O
to	O
be	O
pixels	O
,	O
and	O
then	O
take	O
the	O
features	O
from	O
the	O
last	O
pooling	Method
layer	Method
,	O
which	O
therefore	O
have	O
a	O
dimension	O
of	O
,	O
as	O
shown	O
in	O
Fig	O
.	O

[	O
reference	O
]	O
.	O

is	O
the	O
number	O
of	O
regions	O
in	O
the	O
image	O
and	O
is	O
the	O
dimension	O
of	O
the	O
feature	O
vector	O
for	O
each	O
region	O
.	O

Accordingly	O
,	O
each	O
feature	O
vector	O
in	O
corresponds	O
to	O
a	O
pixel	O
region	O
of	O
the	O
input	O
images	O
.	O

We	O
denote	O
by	O
the	O
feature	O
vector	O
of	O
each	O
image	O
region	O
.	O

Then	O
for	O
modeling	O
convenience	O
,	O
we	O
use	O
a	O
single	Method
layer	Method
perceptron	Method
to	O
transform	O
each	O
feature	O
vector	O
to	O
a	O
new	O
vector	O
that	O
has	O
the	O
same	O
dimension	O
as	O
the	O
question	O
vector	O
(	O
described	O
in	O
Sec	O
.	O

[	O
reference	O
]	O
)	O
:	O
where	O
is	O
a	O
matrix	O
and	O
its	O
i	O
-	O
th	O
column	O
is	O
the	O
visual	Method
feature	O
vector	O
for	O
the	O
region	O
indexed	O
by	O
.	O

subsection	O
:	O
Question	Method
Model	Method
As	O
show	O
that	O
LSTMs	Method
and	O
CNNs	Method
are	O
powerful	O
to	O
capture	O
the	O
semantic	O
meaning	O
of	O
texts	O
,	O
we	O
explore	O
both	O
models	O
for	O
question	Task
representations	Task
in	O
this	O
study	O
.	O

subsubsection	O
:	O
LSTM	Method
based	Method
question	Method
model	Method
The	O
essential	O
structure	O
of	O
a	O
LSTM	Method
unit	Method
is	O
a	O
memory	Method
cell	Method
which	O
reserves	O
the	O
state	O
of	O
a	O
sequence	O
.	O

At	O
each	O
step	O
,	O
the	O
LSTM	Method
unit	Method
takes	O
one	O
input	O
vector	O
(	O
word	O
vector	O
in	O
our	O
case	O
)	O
and	O
updates	O
the	O
memory	O
cell	O
,	O
then	O
output	O
a	O
hidden	O
state	O
.	O

The	O
update	Method
process	Method
uses	O
the	O
gate	Method
mechanism	Method
.	O

A	O
forget	O
gate	O
controls	O
how	O
much	O
information	O
from	O
past	O
state	O
is	O
preserved	O
.	O

An	O
input	O
gate	O
controls	O
how	O
much	O
the	O
current	O
input	O
updates	O
the	O
memory	O
cell	O
.	O

An	O
output	O
gate	O
controls	O
how	O
much	O
information	O
of	O
the	O
memory	O
is	O
fed	O
to	O
the	O
output	O
as	O
hidden	O
state	O
.	O

The	O
detailed	O
update	Method
process	Method
is	O
as	O
follows	O
:	O
where	O
are	O
input	O
gate	O
,	O
forget	O
gate	O
,	O
output	O
gate	O
and	O
memory	O
cell	O
,	O
respectively	O
.	O

The	O
weight	O
matrix	O
and	O
bias	O
are	O
parameters	O
of	O
the	O
LSTM	Method
and	O
are	O
learned	O
on	O
training	O
data	O
.	O

Given	O
the	O
question	O
,	O
where	O
is	O
the	O
one	O
hot	O
vector	Method
representation	Method
of	O
word	O
at	O
position	O
,	O
we	O
first	O
embed	O
the	O
words	O
to	O
a	O
vector	O
space	O
through	O
an	O
embedding	Method
matrix	Method
.	O

Then	O
for	O
every	O
time	O
step	O
,	O
we	O
feed	O
the	O
embedding	O
vector	O
of	O
words	O
in	O
the	O
question	O
to	O
LSTM	Method
:	O
As	O
shown	O
in	O
Fig	O
.	O

[	O
reference	O
]	O
,	O
the	O
question	O
what	O
are	O
sitting	O
in	O
the	O
basket	O
on	O
a	O
bicycle	O
is	O
fed	O
into	O
the	O
LSTM	Method
.	O

Then	O
the	O
final	O
hidden	O
layer	O
is	O
taken	O
as	O
the	O
representation	O
vector	O
for	O
the	O
question	O
,	O
i.e.	O
,	O
.	O

subsubsection	Method
:	O
CNN	Method
based	O
question	O
model	O
In	O
this	O
study	O
,	O
we	O
also	O
explore	O
to	O
use	O
a	O
CNN	Method
similar	O
to	O
for	O
question	Task
representation	Task
.	O

Similar	O
to	O
the	O
LSTM	Method
-	Method
based	Method
question	Method
model	Method
,	O
we	O
first	O
embed	O
words	O
to	O
vectors	O
and	O
get	O
the	O
question	O
vector	O
by	O
concatenating	O
the	O
word	O
vectors	O
:	O
Then	O
we	O
apply	O
convolution	Method
operation	Method
on	O
the	O
word	O
embedding	O
vectors	O
.	O

We	O
use	O
three	O
convolution	Method
filters	Method
,	O
which	O
have	O
the	O
size	O
of	O
one	O
(	O
unigram	O
)	O
,	O
two	O
(	O
bigram	O
)	O
and	O
three	O
(	O
trigram	O
)	O
respectively	O
.	O

The	O
-	O
th	O
convolution	O
output	O
using	O
window	O
size	O
is	O
given	O
by	O
:	O
The	O
filter	Method
is	O
applied	O
only	O
to	O
window	O
of	O
size	O
.	O

is	O
the	O
convolution	O
weight	O
and	O
is	O
the	O
bias	O
.	O

The	O
feature	O
map	O
of	O
the	O
filter	Method
with	O
convolution	O
size	O
is	O
given	O
by	O
:	O
Then	O
we	O
apply	O
max	Method
-	Method
pooling	Method
over	O
the	O
feature	O
maps	O
of	O
the	O
convolution	O
size	O
and	O
denote	O
it	O
as	O
The	O
max	Method
-	Method
pooling	Method
over	O
these	O
vectors	O
is	O
a	O
coordinate	Method
-	Method
wise	Method
max	Method
operation	Method
.	O

For	O
convolution	O
feature	O
maps	O
of	O
different	O
sizes	O
,	O
we	O
concatenate	O
them	O
to	O
form	O
the	O
feature	Method
representation	Method
vector	Method
of	O
the	O
whole	O
question	O
sentence	O
:	O
hence	O
is	O
the	O
CNN	Method
based	O
question	O
vector	O
.	O

The	O
diagram	O
of	O
CNN	Method
model	O
for	O
question	Task
is	O
shown	O
in	O
Fig	O
.	O

[	O
reference	O
]	O
.	O

The	O
convolutional	Method
and	Method
pooling	Method
layers	Method
for	O
unigrams	O
,	O
bigrams	O
and	O
trigrams	O
are	O
drawn	O
in	O
red	O
,	O
blue	O
and	O
orange	O
,	O
respectively	O
.	O

subsection	O
:	O
Stacked	Method
Attention	Method
Networks	Method
Given	O
the	O
image	O
feature	O
matrix	O
and	O
the	O
question	O
feature	O
vector	O
,	O
SAN	Method
predicts	O
the	O
answer	O
via	O
multi	Method
-	Method
step	Method
reasoning	Method
.	O

In	O
many	O
cases	O
,	O
an	O
answer	O
only	O
related	O
to	O
a	O
small	O
region	O
of	O
an	O
image	O
.	O

For	O
example	O
,	O
in	O
Fig	O
.	O

[	O
reference	O
]	O
,	O
although	O
there	O
are	O
multiple	O
objects	O
in	O
the	O
image	O
:	O
bicycles	O
,	O
baskets	O
,	O
window	O
,	O
street	O
and	O
dogs	O
and	O
the	O
answer	O
to	O
the	O
question	O
only	O
relates	O
to	O
dogs	O
.	O

Therefore	O
,	O
using	O
the	O
one	O
global	O
image	O
feature	O
vector	O
to	O
predict	O
the	O
answer	O
could	O
lead	O
to	O
sub	O
-	O
optimal	O
results	O
due	O
to	O
the	O
noises	O
introduced	O
from	O
regions	O
that	O
are	O
irrelevant	O
to	O
the	O
potential	O
answer	O
.	O

Instead	O
,	O
reasoning	O
via	O
multiple	O
attention	O
layers	O
progressively	O
,	O
the	O
SAN	Method
are	O
able	O
to	O
gradually	O
filter	O
out	O
noises	O
and	O
pinpoint	O
the	O
regions	O
that	O
are	O
highly	O
relevant	O
to	O
the	O
answer	O
.	O

Given	O
the	O
image	O
feature	O
matrix	O
and	O
the	O
question	O
vector	O
,	O
we	O
first	O
feed	O
them	O
through	O
a	O
single	Method
layer	Method
neural	Method
network	Method
and	O
then	O
a	O
softmax	Method
function	Method
to	O
generate	O
the	O
attention	O
distribution	O
over	O
the	O
regions	O
of	O
the	O
image	O
:	O
where	O
,	O
is	O
the	O
image	O
representation	O
dimension	O
and	O
is	O
the	O
number	O
of	O
image	O
regions	O
,	O
is	O
a	O
dimensional	O
vector	O
.	O

Suppose	O
and	O
,	O
then	O
is	O
an	O
dimensional	O
vector	O
,	O
which	O
corresponds	O
to	O
the	O
attention	O
probability	O
of	O
each	O
image	O
region	O
given	O
.	O

Note	O
that	O
we	O
denote	O
by	O
the	O
addition	O
of	O
a	O
matrix	O
and	O
a	O
vector	O
.	O

Since	O
and	O
both	O
are	O
vectors	O
,	O
the	O
addition	O
between	O
a	O
matrix	O
and	O
a	O
vector	O
is	O
performed	O
by	O
adding	O
each	O
column	O
of	O
the	O
matrix	O
by	O
the	O
vector	O
.	O

Based	O
on	O
the	O
attention	O
distribution	O
,	O
we	O
calculate	O
the	O
weighted	O
sum	O
of	O
the	O
image	O
vectors	O
,	O
each	O
from	O
a	O
region	O
,	O
as	O
in	O
Eq	O
.	O

[	O
reference	O
]	O
.	O

We	O
then	O
combine	O
with	O
the	O
question	O
vector	O
to	O
form	O
a	O
refined	O
query	O
vector	O
as	O
in	O
Eq	O
.	O

[	O
reference	O
]	O
.	O

is	O
regarded	O
as	O
a	O
refined	O
query	O
since	O
it	O
encodes	O
both	O
question	O
information	O
and	O
the	O
visual	Method
information	O
that	O
is	O
relevant	O
to	O
the	O
potential	O
answer	O
:	O
Compared	O
to	O
models	O
that	O
simply	O
combine	O
the	O
question	O
vector	O
and	O
the	O
global	O
image	O
vector	O
,	O
attention	Method
models	Method
construct	O
a	O
more	O
informative	O
since	O
higher	O
weights	O
are	O
put	O
on	O
the	O
visual	Method
regions	O
that	O
are	O
more	O
relevant	O
to	O
the	O
question	O
.	O

However	O
,	O
for	O
complicated	O
questions	O
,	O
a	O
single	O
attention	Method
layer	Method
is	O
not	O
sufficient	O
to	O
locate	O
the	O
correct	O
region	O
for	O
answer	Task
prediction	Task
.	O

For	O
example	O
,	O
the	O
question	O
in	O
Fig	O
.	O

[	O
reference	O
]	O
what	O
are	O
sitting	O
in	O
the	O
basket	O
on	O
a	O
bicycle	O
refers	O
to	O
some	O
subtle	O
relationships	O
among	O
multiple	O
objects	O
in	O
an	O
image	O
.	O

Therefore	O
,	O
we	O
iterate	O
the	O
above	O
query	Method
-	Method
attention	Method
process	Method
using	O
multiple	O
attention	Method
layers	Method
,	O
each	O
extracting	O
more	O
fine	O
-	O
grained	O
visual	Method
attention	O
information	O
for	O
answer	Task
prediction	Task
.	O

Formally	O
,	O
the	O
SANs	O
take	O
the	O
following	O
formula	O
:	O
for	O
the	O
-	O
th	O
attention	O
layer	O
,	O
we	O
compute	O
:	O
where	O
is	O
initialized	O
to	O
be	O
.	O

Then	O
the	O
aggregated	O
image	O
feature	O
vector	O
is	O
added	O
to	O
the	O
previous	O
query	O
vector	O
to	O
form	O
a	O
new	O
query	O
vector	O
:	O
That	O
is	O
,	O
in	O
every	O
layer	O
,	O
we	O
use	O
the	O
combined	O
question	O
and	O
image	O
vector	O
as	O
the	O
query	O
for	O
the	O
image	O
.	O

After	O
the	O
image	O
region	O
is	O
picked	O
,	O
we	O
update	O
the	O
new	O
query	O
vector	O
as	O
.	O

We	O
repeat	O
this	O
times	O
and	O
then	O
use	O
the	O
final	O
to	O
infer	O
the	O
answer	O
:	O
Fig	O
.	O

[	O
reference	O
]	O
illustrates	O
the	O
reasoning	O
process	O
by	O
an	O
example	O
.	O

In	O
the	O
first	O
attention	Method
layer	Method
,	O
the	O
model	O
identifies	O
roughly	O
the	O
area	O
that	O
are	O
relevant	O
to	O
basket	O
,	O
bicycle	O
,	O
and	O
sitting	O
in	O
.	O

In	O
the	O
second	O
attention	Method
layer	Method
,	O
the	O
model	O
focuses	O
more	O
sharply	O
on	O
the	O
region	O
that	O
corresponds	O
to	O
the	O
answer	O
dogs	O
.	O

More	O
examples	O
can	O
be	O
found	O
in	O
Sec	O
.	O

[	O
reference	O
]	O
.	O

section	O
:	O
Experiments	O
subsection	O
:	O
Data	O
sets	O
We	O
evaluate	O
the	O
SAN	Method
on	O
four	O
image	Task
QA	Task
data	O
sets	O
.	O

DAQUAR	Material
-	Material
ALL	Material
is	O
proposed	O
in	O
.	O

There	O
are	O
training	O
questions	O
and	O
test	O
questions	O
.	O

These	O
questions	O
are	O
generated	O
on	O
and	O
images	O
respectively	O
.	O

The	O
images	O
are	O
mainly	O
indoor	O
scenes	O
.	O

The	O
questions	O
are	O
categorized	O
into	O
three	O
types	O
including	O
Object	O
,	O
Color	O
and	O
Number	O
.	O

Most	O
of	O
the	O
answers	O
are	O
single	O
words	O
.	O

Following	O
the	O
setting	O
in	O
,	O
we	O
exclude	O
data	O
samples	O
that	O
have	O
multiple	O
words	O
answers	O
.	O

The	O
remaining	O
data	O
set	O
covers	O
of	O
the	O
original	O
data	O
set	O
.	O

DAQUAR	Material
-	Material
REDUCED	Material
is	O
a	O
reduced	O
version	O
of	O
DAQUAR	Material
-	Material
ALL	Material
.	O

There	O
are	O
training	O
samples	O
and	O
test	O
samples	O
.	O

This	O
data	O
set	O
is	O
constrained	O
to	O
object	O
categories	O
and	O
uses	O
only	O
test	O
images	O
.	O

The	O
single	O
word	O
answers	O
data	O
set	O
covers	O
of	O
the	O
original	O
data	O
set	O
.	O

COCO	Material
-	Material
QA	Material
is	O
proposed	O
in	O
.	O

Based	O
on	O
the	O
Microsoft	Material
COCO	Material
data	Material
set	Material
,	O
the	O
authors	O
first	O
parse	O
the	O
caption	O
of	O
the	O
image	O
with	O
an	O
off	O
-	O
the	O
-	O
shelf	Method
parser	Method
,	O
then	O
replace	O
the	O
key	O
components	O
in	O
the	O
caption	O
with	O
question	O
words	O
for	O
form	O
questions	O
.	O

There	O
are	O
training	O
samples	O
and	O
test	O
samples	O
in	O
the	O
data	O
set	O
.	O

These	O
questions	O
are	O
based	O
on	O
and	O
images	O
respectively	O
.	O

There	O
are	O
four	O
types	O
of	O
questions	O
including	O
Object	O
,	O
Number	O
,	O
Color	O
,	O
and	O
Location	O
.	O

Each	O
type	O
takes	O
,	O
and	O
of	O
the	O
whole	O
data	O
set	O
,	O
respectively	O
.	O

All	O
answers	O
in	O
this	O
data	O
set	O
are	O
single	O
word	O
.	O

VQA	Material
is	O
created	O
through	O
human	Task
labeling	Task
.	O

The	O
data	O
set	O
uses	O
images	O
in	O
the	O
COCO	Material
image	Material
caption	Material
data	Material
set	Material
.	O

Unlike	O
the	O
other	O
data	O
sets	O
,	O
for	O
each	O
image	O
,	O
there	O
are	O
three	O
questions	O
and	O
for	O
each	O
question	O
,	O
there	O
are	O
ten	O
answers	O
labeled	O
by	O
human	O
annotators	O
.	O

There	O
are	O
training	O
questions	O
and	O
validation	O
questions	O
in	O
the	O
data	O
set	O
.	O

Following	O
,	O
we	O
use	O
the	O
top	O
most	O
frequent	O
answer	O
as	O
possible	O
outputs	O
and	O
this	O
set	O
of	O
answers	O
covers	O
of	O
all	O
answers	O
.	O

We	O
first	O
studied	O
the	O
performance	O
of	O
the	O
proposed	O
model	O
on	O
the	O
validation	O
set	O
.	O

Following	O
,	O
we	O
split	O
the	O
validation	O
data	O
set	O
into	O
two	O
halves	O
,	O
val1	O
and	O
val2	O
.	O

We	O
use	O
training	O
set	O
and	O
val1	O
to	O
train	O
and	O
validate	O
and	O
val2	O
to	O
test	O
locally	O
.	O

The	O
results	O
on	O
the	O
val2	O
set	O
are	O
reported	O
in	O
Table	O
.	O

[	O
reference	O
]	O
.	O

We	O
also	O
evaluated	O
the	O
best	O
model	O
,	O
SAN	Method
(	O
2	Method
,	O
CNN	Method
)	O
,	O
on	O
the	O
standard	O
test	O
server	O
as	O
provided	O
in	O
and	O
report	O
the	O
results	O
in	O
Table	O
.	O

[	O
reference	O
]	O
.	O

subsection	O
:	O
Baselines	O
and	O
evaluation	O
methods	O
We	O
compare	O
our	O
models	O
with	O
a	O
set	O
of	O
baselines	O
proposed	O
recently	O
on	O
image	Task
QA	Task
.	O

Since	O
the	O
results	O
of	O
these	O
baselines	O
are	O
reported	O
on	O
different	O
data	O
sets	O
in	O
different	O
literature	O
,	O
we	O
present	O
the	O
experimental	O
results	O
on	O
different	O
data	O
sets	O
in	O
different	O
tables	O
.	O

For	O
all	O
four	O
data	O
sets	O
,	O
we	O
formulate	O
image	Task
QA	Task
as	O
a	O
classification	Task
problem	Task
since	O
most	O
of	O
answers	O
are	O
single	O
words	O
.	O

We	O
evaluate	O
the	O
model	O
using	O
classification	Metric
accuracy	Metric
as	O
reported	O
in	O
.	O

The	O
reference	O
models	O
also	O
report	O
the	O
Wu	Metric
-	Metric
Palmer	Metric
similarity	Metric
(	O
WUPS	Metric
)	Metric
measure	Metric
.	O

The	O
WUPS	Method
measure	Method
calculates	O
the	O
similarity	O
between	O
two	O
words	O
based	O
on	O
their	O
longest	O
common	O
subsequence	O
in	O
the	O
taxonomy	O
tree	O
.	O

We	O
can	O
set	O
a	O
threshold	O
for	O
WUPS	O
,	O
if	O
the	O
similarity	O
is	O
less	O
than	O
the	O
threshold	O
,	O
then	O
it	O
is	O
zeroed	O
out	O
.	O

Following	O
the	O
reference	O
models	O
,	O
we	O
use	O
WUPS0.9	Method
and	O
WUPS0.0	Method
as	O
evaluation	Metric
metrics	Metric
besides	O
the	O
classification	Metric
accuracy	Metric
.	O

The	O
evaluation	O
on	O
the	O
VQA	Material
data	Material
set	Material
is	O
different	O
from	O
other	O
three	O
data	O
sets	O
,	O
since	O
for	O
each	O
question	O
there	O
are	O
ten	O
answer	O
labels	O
that	O
may	O
or	O
may	O
not	O
be	O
the	O
same	O
.	O

We	O
follow	O
to	O
use	O
the	O
following	O
metric	O
:	O
,	O
which	O
basically	O
gives	O
full	O
credit	O
to	O
the	O
answer	O
when	O
three	O
or	O
more	O
of	O
the	O
ten	O
human	O
labels	O
match	O
the	O
answer	O
and	O
gives	O
partial	O
credit	O
if	O
there	O
are	O
less	O
matches	O
.	O

subsection	O
:	O
Model	Method
configuration	Method
and	O
training	O
For	O
the	O
image	Method
model	Method
,	O
we	O
use	O
the	O
VGGNet	Method
to	O
extract	O
features	O
.	O

When	O
training	O
the	O
SAN	Method
,	O
the	O
parameter	O
set	O
of	O
the	O
CNN	Method
of	O
the	O
VGGNet	Method
is	O
fixed	O
.	O

We	O
take	O
the	O
output	O
from	O
the	O
last	O
pooling	Method
layer	Method
as	O
our	O
image	O
feature	O
which	O
has	O
a	O
dimension	O
of	O
.	O

For	O
DAQUAR	Material
and	O
COCO	Material
-	Material
QA	Material
,	O
we	O
set	O
the	O
word	O
embedding	O
dimension	O
and	O
LSTM	O
’s	O
dimension	O
to	O
be	O
in	O
the	O
question	Method
model	Method
.	O

For	O
the	O
CNN	Method
based	O
question	O
model	O
,	O
we	O
set	O
the	O
unigram	O
,	O
bigram	O
and	O
trigram	O
convolution	O
filter	O
size	O
to	O
be	O
,	O
,	O
respectively	O
.	O

The	O
combination	O
of	O
these	O
filters	O
makes	O
the	O
question	O
vector	O
size	O
to	O
be	O
.	O

For	O
VQA	Material
dataset	Material
,	O
since	O
it	O
is	O
larger	O
than	O
other	O
data	O
sets	O
,	O
we	O
double	O
the	O
model	Metric
size	Metric
of	O
the	O
LSTM	Method
and	O
the	O
CNN	Method
to	O
accommodate	O
the	O
large	O
data	O
set	O
and	O
the	O
large	O
number	O
of	O
classes	O
.	O

In	O
evaluation	O
,	O
we	O
experiment	O
with	O
SAN	Method
with	O
one	O
and	O
two	O
attention	Method
layers	Method
.	O

We	O
find	O
that	O
using	O
three	O
or	O
more	O
attention	O
layers	O
does	O
not	O
further	O
improve	O
the	O
performance	O
.	O

In	O
our	O
experiments	O
,	O
all	O
the	O
models	O
are	O
trained	O
using	O
stochastic	Method
gradient	Method
descent	Method
with	O
momentum	Method
.	O

The	O
batch	O
size	O
is	O
fixed	O
to	O
be	O
.	O

The	O
best	O
learning	Metric
rate	Metric
is	O
picked	O
using	O
grid	Method
search	Method
.	O

Gradient	Method
clipping	Method
technique	Method
and	O
dropout	Method
are	O
used	O
.	O

subsection	O
:	O
Results	O
and	O
analysis	O
The	O
experimental	O
results	O
on	O
DAQUAR	Material
-	Material
ALL	Material
,	O
DAQUAR	Material
-	Material
REDUCED	Material
,	O
COCO	Material
-	Material
QA	Material
and	O
VQA	Material
are	O
presented	O
in	O
Table	O
.	O

[	O
reference	O
]	O
to	O
[	O
reference	O
]	O
respectively	O
.	O

Our	O
model	O
names	O
explain	O
their	O
settings	O
:	O
SAN	Method
is	O
short	O
for	O
the	O
proposed	O
stacked	Method
attention	Method
networks	Method
,	O
the	O
value	O
1	O
or	O
2	Method
in	O
the	O
brackets	O
refer	O
to	O
using	O
one	O
or	O
two	O
attention	O
layers	O
,	O
respectively	O
.	O

The	O
keyword	O
LSTM	O
or	O
CNN	Method
refers	O
to	O
the	O
question	Method
model	Method
that	O
SANs	O
use	O
.	O

Yes	O
/	O
No	O
36	O
%	O
Number	O
10	O
%	O
Other	O
54	O
%	O
The	O
experimental	O
results	O
in	O
Table	O
.	O

[	O
reference	O
]	O
to	O
[	O
reference	O
]	O
show	O
that	O
the	O
two	O
-	O
layer	O
SAN	Method
gives	O
the	O
best	O
results	O
across	O
all	O
data	O
sets	O
and	O
the	O
two	O
kinds	O
of	O
question	Method
models	Method
in	O
the	O
SAN	Method
,	O
LSTM	O
and	O
CNN	Method
,	O
give	O
similar	O
performance	O
.	O

For	O
example	O
,	O
on	O
DAQUAR	Material
-	O
ALL	O
(	O
Table	O
.	O

[	O
reference	O
]	O
)	O
,	O
both	O
of	O
the	O
proposed	O
two	Method
-	Method
layer	Method
SANs	Method
outperform	O
the	O
two	O
best	O
baselines	O
,	O
the	O
IMG	O
-	O
CNN	Method
in	O
and	O
the	O
Ask	Method
-	Method
Your	Method
-	Method
Neuron	Method
in	Method
,	O
by	O
and	O
absolute	O
in	O
accuracy	Metric
,	O
respectively	O
.	O

Similar	O
range	O
of	O
improvements	O
are	O
observed	O
in	O
metrics	Metric
of	O
WUPS0.9	Method
and	O
WUPS0.0	Method
.	O

We	O
also	O
observe	O
significant	O
improvements	O
on	O
DAQUAR	Material
-	Material
REDUCED	Material
(	O
Table	O
.	O

[	O
reference	O
]	O
)	O
,	O
i.e.	O
,	O
our	O
SAN	Method
(	O
2	Method
,	O
LSTM	O
)	O
outperforms	O
the	O
IMG	O
-	O
CNN	Method
,	O
the	O
2	Method
-	O
VIS	O
+	O
BLSTM	O
,	O
the	O
Ask	Method
-	Method
Your	Method
-	Method
Neurons	Method
approach	Method
and	O
the	O
Multi	O
-	O
World	O
by	O
,	O
,	O
and	O
absolute	O
in	O
accuracy	Metric
,	O
respectively	O
.	O

On	O
the	O
larger	O
COCO	Material
-	Material
QA	Material
data	O
set	O
,	O
the	O
proposed	O
two	Method
-	Method
layer	Method
SANs	Method
significantly	O
outperform	O
the	O
best	O
baselines	O
from	O
(	O
IMG	O
-	O
CNN	Method
)	O
and	O
(	O
IMG	Method
+	Method
BOW	Method
and	O
2	Method
-	O
VIS	O
+	O
BLSTM	O
)	O
by	O
5.1	O
%	O
and	O
6.6	O
%	O
in	O
accuracy	Metric
(	O
Table	O
.	O

[	O
reference	O
]	O
)	O
.	O

Table	O
.	O

[	O
reference	O
]	O
summarizes	O
the	O
performance	O
of	O
various	O
models	O
on	O
VQA	Material
,	O
which	O
is	O
the	O
largest	O
among	O
the	O
four	O
data	O
sets	O
.	O

The	O
overall	O
results	O
show	O
that	O
our	O
best	O
model	O
,	O
SAN	Method
(	O
2	Method
,	O
CNN	Method
)	O
,	O
outperforms	O
the	O
LSTM	Method
Q	Method
+	Method
I	Method
model	O
,	O
the	O
best	O
baseline	O
from	O
,	O
by	O
4.8	O
%	O
absolute	O
.	O

The	O
superior	O
performance	O
of	O
the	O
SANs	Method
across	O
all	O
four	O
benchmarks	O
demonstrate	O
the	O
effectiveness	O
of	O
using	O
multiple	O
layers	O
of	O
attention	O
.	O

In	O
order	O
to	O
study	O
the	O
strength	O
and	O
weakness	O
of	O
the	O
SAN	Method
in	O
detail	O
,	O
we	O
report	O
performance	O
at	O
the	O
question	O
-	O
type	O
level	O
on	O
the	O
two	O
large	O
data	O
sets	O
,	O
COCO	Material
-	Material
QA	Material
and	O
VQA	Material
,	O
in	O
Table	O
.	O

[	O
reference	O
]	O
and	O
[	O
reference	O
]	O
,	O
respectively	O
.	O

We	O
observe	O
that	O
on	O
COCO	Material
-	Material
QA	Material
,	O
compared	O
to	O
the	O
two	O
best	O
baselines	O
,	O
IMG	Method
+	Method
BOW	Method
and	O
2	Method
-	O
VIS	O
+	O
BLSTM	O
,	O
out	O
best	O
model	O
SAN	Method
(	O
2	Method
,	O
CNN	Method
)	O
improves	O
7.2	O
%	O
in	O
the	O
question	Metric
type	Metric
of	Metric
Color	Metric
,	O
followed	O
by	O
6.1	O
%	O
in	O
Objects	O
,	O
5.7	O
%	O
in	O
Location	O
and	O
4.2	O
%	O
in	O
Number	O
.	O

We	O
observe	O
similar	O
trend	O
of	O
improvements	O
on	O
VQA	Material
.	O

As	O
shown	O
in	O
Table	O
.	O

[	O
reference	O
]	O
,	O
compared	O
to	O
the	O
best	O
baseline	O
LSTM	Method
Q	Method
+	Method
I	Method
,	O
the	O
biggest	O
improvement	O
of	O
SAN	Method
(	O
2	Method
,	O
CNN	Method
)	O
is	O
in	O
the	O
Other	O
type	O
,	O
9.7	O
%	O
,	O
followed	O
by	O
the	O
1.4	O
%	O
improvement	O
in	O
Number	Metric
and	O
0.4	O
%	O
improvement	O
in	O
Yes	Metric
/	Metric
No	Metric
.	O

Note	O
that	O
the	O
Other	O
type	O
in	O
VQA	Material
refers	O
to	O
questions	O
that	O
usually	O
have	O
the	O
form	O
of	O
“	O
what	O
color	O
,	O
what	O
kind	O
,	O
what	O
are	O
,	O
what	O
type	O
,	O
where	O
”	O
etc	O
.	O

,	O
which	O
are	O
similar	O
to	O
question	O
types	O
of	O
Color	O
,	O
Objects	O
and	O
Location	O
in	O
COCO	Material
-	Material
QA	Material
.	O

The	O
VQA	Material
data	Material
set	Material
has	O
a	O
special	O
Yes	O
/	O
No	O
type	O
of	O
questions	O
.	O

The	O
SAN	Method
only	O
improves	O
the	O
performance	O
of	O
this	O
type	O
of	O
questions	O
slightly	O
.	O

This	O
could	O
due	O
to	O
that	O
the	O
answer	O
for	O
a	O
Yes	O
/	O
No	O
question	O
is	O
very	O
question	O
dependent	O
,	O
so	O
better	O
modeling	O
of	O
the	O
visual	Method
information	O
does	O
not	O
provide	O
much	O
additional	O
gains	O
.	O

This	O
also	O
confirms	O
the	O
similar	O
observation	O
reported	O
in	O
,	O
e.g.	O
,	O
using	O
additional	O
image	O
information	O
only	O
slightly	O
improves	O
the	O
performance	O
in	O
Yes	O
/	O
No	O
,	O
as	O
shown	O
in	O
Table	O
.	O

[	O
reference	O
]	O
,	O
Q	O
+	O
I	O
vs	O
Question	O
,	O
and	O
LSTM	Method
Q	Method
+	Method
I	Method
vs	O
LSTM	Method
Q.	Method
Our	O
results	O
demonstrate	O
clearly	O
the	O
positive	O
impact	O
of	O
using	O
multiple	Method
attention	Method
layers	Method
.	O

In	O
all	O
four	O
data	O
sets	O
,	O
two	O
-	O
layer	Method
SANs	Method
always	O
perform	O
better	O
than	O
the	O
one	O
-	O
layer	O
SAN	Method
.	O

Specifically	O
,	O
on	O
COCO	Material
-	Material
QA	Material
,	O
on	O
average	O
the	O
two	Method
-	Method
layer	Method
SANs	Method
outperform	O
the	O
one	Method
-	Method
layer	Method
SANs	Method
by	O
2.2	O
%	O
in	O
the	O
type	O
of	O
Color	O
,	O
followed	O
by	O
1.3	O
%	O
and	O
1.0	O
%	O
in	O
the	O
Location	O
and	O
Objects	O
categories	O
,	O
and	O
then	O
0.4	O
%	O
in	O
Number	O
.	O

This	O
aligns	O
to	O
the	O
order	O
of	O
the	O
improvements	O
of	O
the	O
SAN	Method
over	O
baselines	O
.	O

Similar	O
trends	O
are	O
observed	O
on	O
VQA	Material
(	O
Table	O
.	O

[	O
reference	O
]	O
)	O
,	O
e.g.	O
,	O
the	O
two	O
-	O
layer	O
SAN	Method
improve	O
over	O
the	O
one	O
-	O
layer	O
SAN	Method
by	O
1.4	O
%	O
for	O
the	O
Other	O
type	O
of	O
question	O
,	O
followed	O
by	O
0.2	O
%	O
improvement	O
for	O
Number	O
,	O
and	O
flat	O
for	O
Yes	O
/	O
No	O
.	O

subsection	O
:	O
Visualization	Task
of	Task
attention	Task
layers	Task
In	O
this	O
section	O
,	O
we	O
present	O
analysis	O
to	O
demonstrate	O
that	O
using	O
multiple	O
attention	O
layers	O
to	O
perform	O
multi	Method
-	Method
step	Method
reasoning	Method
leads	O
to	O
more	O
fine	O
-	O
grained	O
attention	O
layer	O
-	O
by	O
-	O
layer	O
in	O
locating	O
the	O
regions	O
that	O
are	O
relevant	O
to	O
the	O
potential	O
answers	O
.	O

We	O
do	O
so	O
by	O
visualizing	O
the	O
outputs	O
of	O
the	O
attention	Method
layers	Method
of	O
a	O
sample	O
set	O
of	O
images	O
from	O
the	O
COCO	Material
-	Material
QA	Material
test	Material
set	Material
.	O

Note	O
the	O
attention	O
probability	O
distribution	O
is	O
of	O
size	O
and	O
the	O
original	O
image	O
is	O
,	O
we	O
up	O
-	O
sample	O
the	O
attention	O
probability	O
distribution	O
and	O
apply	O
a	O
Gaussian	Method
filter	Method
to	O
make	O
it	O
the	O
same	O
size	O
as	O
the	O
original	O
image	O
.	O

Fig	O
.	O

[	O
reference	O
]	O
presents	O
six	O
examples	O
.	O

More	O
examples	O
are	O
presented	O
in	O
the	O
appendix	O
.	O

They	O
cover	O
types	O
as	O
broad	O
as	O
Object	O
,	O
Numbers	O
,	O
Color	O
and	O
Location	O
.	O

For	O
each	O
example	O
,	O
the	O
three	O
images	O
from	O
left	O
to	O
right	O
are	O
the	O
original	O
image	O
,	O
the	O
output	O
of	O
the	O
first	O
attention	Method
layer	Method
and	O
the	O
output	O
of	O
the	O
second	O
attention	Method
layer	Method
,	O
respectively	O
.	O

The	O
bright	O
part	O
of	O
the	O
image	O
is	O
the	O
detected	O
attention	O
.	O

Across	O
all	O
those	O
examples	O
,	O
we	O
see	O
that	O
in	O
the	O
first	O
attention	Method
layer	Method
,	O
the	O
attention	O
is	O
scattered	O
on	O
many	O
objects	O
in	O
the	O
image	O
,	O
largely	O
corresponds	O
to	O
the	O
objects	O
and	O
concepts	O
referred	O
in	O
the	O
question	O
,	O
whereas	O
in	O
the	O
second	O
layer	O
,	O
the	O
attention	O
is	O
far	O
more	O
focused	O
on	O
the	O
regions	O
that	O
lead	O
to	O
the	O
correct	O
answer	O
.	O

For	O
example	O
,	O
consider	O
the	O
question	O
what	O
is	O
the	O
color	O
of	O
the	O
horns	O
,	O
which	O
asks	O
the	O
color	O
of	O
the	O
horn	O
on	O
the	O
woman	O
’s	O
head	O
in	O
Fig	O
.	O

[	O
reference	O
]	O
(	O
f	O
)	O
.	O

In	O
the	O
output	O
of	O
the	O
first	O
attention	Method
layer	Method
,	O
the	O
model	O
first	O
recognizes	O
a	O
woman	O
in	O
the	O
image	O
.	O

In	O
the	O
output	O
of	O
the	O
second	O
attention	Method
layer	Method
,	O
the	O
attention	O
is	O
focused	O
on	O
the	O
head	O
of	O
the	O
woman	O
,	O
which	O
leads	O
to	O
the	O
answer	O
of	O
the	O
question	O
:	O
the	O
color	O
of	O
the	O
horn	O
is	O
red	O
.	O

subsection	O
:	O
Errors	O
analysis	O
We	O
randomly	O
sample	O
100	O
images	O
from	O
the	O
COCO	Material
-	Material
QA	Material
test	Material
set	Material
that	O
the	O
SAN	Method
make	O
mistakes	O
.	O

We	O
group	O
the	O
errors	O
into	O
four	O
categories	O
:	O
(	O
i	O
)	O
the	O
SANs	O
focus	O
the	O
attention	O
on	O
the	O
wrong	O
regions	O
(	O
22	O
%	O
)	O
,	O
e.g.	O
,	O
the	O
example	O
in	O
Fig	O
.	O

[	O
reference	O
]	O
(	O
a	O
)	O
;	O
(	O
ii	O
)	O
the	O
SANs	O
focus	O
on	O
the	O
right	O
region	O
but	O
predict	O
a	O
wrong	O
answer	O
(	O
42	O
%	O
)	O
,	O
e.g.	O
,	O
the	O
examples	O
in	O
Fig	O
.	O

[	O
reference	O
]	O
(	O
b	O
)(	O
c	O
)(	O
d	O
)	O
;	O
(	O
iii	O
)	O
the	O
answer	O
is	O
ambiguous	O
,	O
the	O
SANs	O
give	O
answers	O
that	O
are	O
different	O
from	O
labels	O
,	O
but	O
might	O
be	O
acceptable	O
(	O
31	O
%	O
)	O
.	O

E.g.	O
,	O
in	O
Fig	O
.	O

[	O
reference	O
]	O
(	O
e	O
)	O
,	O
the	O
answer	O
label	O
is	O
pot	O
,	O
but	O
out	O
model	O
predicts	O
vase	O
,	O
which	O
is	O
also	O
visually	O
reasonable	O
;	O
(	O
iv	O
)	O
the	O
labels	O
are	O
clearly	O
wrong	O
(	O
5	O
%	O
)	O
.	O

E.g.	O
,	O
in	O
Fig	O
.	O

[	O
reference	O
]	O
(	O
f	O
)	O
,	O
our	O
model	O
gives	O
the	O
correct	O
answer	O
trains	O
while	O
the	O
label	O
cars	O
is	O
wrong	O
.	O

section	O
:	O
Conclusion	O
In	O
this	O
paper	O
,	O
we	O
propose	O
a	O
new	O
stacked	Method
attention	Method
network	Method
(	O
SAN	Method
)	O
for	O
image	Task
QA	Task
.	O

SAN	Method
uses	O
a	O
multiple	Method
-	Method
layer	Method
attention	Method
mechanism	Method
that	O
queries	O
an	O
image	O
multiple	O
times	O
to	O
locate	O
the	O
relevant	O
visual	Method
region	O
and	O
to	O
infer	O
the	O
answer	O
progressively	O
.	O

Experimental	O
results	O
demonstrate	O
that	O
the	O
proposed	O
SAN	Method
significantly	O
outperforms	O
previous	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
approaches	O
by	O
a	O
substantial	O
margin	O
on	O
all	O
four	O
image	Task
QA	Task
data	O
sets	O
.	O

The	O
visualization	O
of	O
the	O
attention	O
layers	O
further	O
illustrates	O
the	O
process	O
that	O
the	O
SAN	Method
focuses	O
the	O
attention	O
to	O
the	O
relevant	O
visual	Method
clues	O
that	O
lead	O
to	O
the	O
answer	O
of	O
the	O
question	O
layer	O
-	O
by	O
-	O
layer	O
.	O

bibliography	O
:	O
References	O
