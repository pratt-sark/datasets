document	O
:	O
ParseNet	Method
:	O
Looking	O
Wider	O
to	O
See	O
Better	O
We	O
present	O
a	O
technique	O
for	O
adding	O
global	Task
context	Task
to	O
fully	Method
convolutional	Method
networks	Method
for	O
semantic	Task
segmentation	Task
.	O

The	O
approach	O
is	O
simple	O
,	O
using	O
the	O
average	O
feature	O
for	O
a	O
layer	O
to	O
augment	O
the	O
features	O
at	O
each	O
location	O
.	O

In	O
addition	O
,	O
we	O
study	O
several	O
idiosyncrasies	O
of	O
training	Task
,	O
significantly	O
increasing	O
the	O
performance	O
of	O
baseline	O
networks	O
(	O
e.g.	O
from	O
FCN	Method
)	O
.	O

When	O
we	O
add	O
our	O
proposed	O
global	O
feature	O
,	O
and	O
a	O
technique	O
for	O
learning	O
normalization	O
parameters	O
,	O
accuracy	Metric
increases	O
consistently	O
even	O
over	O
our	O
improved	O
versions	O
of	O
the	O
baselines	O
.	O

Our	O
proposed	O
approach	O
,	O
ParseNet	Method
,	O
achieves	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
performance	O
on	O
SiftFlow	Material
and	O
PASCAL	Material
-	Material
Context	Material
with	O
small	O
additional	O
computational	Metric
cost	Metric
over	O
baselines	O
,	O
and	O
near	O
current	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
performance	O
on	O
PASCAL	O
VOC	O
2012	O
semantic	Task
segmentation	Task
with	O
a	O
simple	O
approach	O
.	O

Code	O
is	O
available	O
at	O
.	O

section	O
:	O
Introduction	O
Semantic	O
segmentation	Task
,	O
largely	O
studied	O
in	O
the	O
last	O
10	O
years	O
,	O
merges	O
image	Task
segmentation	Task
with	O
object	Task
recognition	Task
to	O
produce	O
per	Task
-	Task
pixel	Task
labeling	Task
of	Task
image	Task
content	Task
.	O

The	O
currently	O
most	O
successful	O
techniques	O
for	O
semantic	Task
segmentation	Task
are	O
based	O
on	O
fully	Method
convolution	Method
networks	Method
(	O
FCN	Method
)	O
.	O

These	O
are	O
adapted	O
from	O
networks	O
designed	O
to	O
classify	O
whole	O
images	O
,	O
and	O
have	O
demonstrated	O
impressive	O
level	O
of	O
performance	O
.	O

The	O
FCN	Method
approach	Method
can	O
be	O
thought	O
of	O
as	O
sliding	O
an	O
classification	Method
network	Method
around	O
an	O
input	O
image	O
,	O
and	O
processes	O
each	O
sliding	O
window	O
area	O
independently	O
.	O

In	O
particular	O
,	O
FCN	Method
disregards	O
global	O
information	O
about	O
an	O
image	O
,	O
thus	O
ignoring	O
potentially	O
useful	O
scene	O
-	O
level	O
semantic	O
context	O
.	O

In	O
order	O
to	O
integrate	O
more	O
context	O
,	O
several	O
approaches	O
,	O
propose	O
using	O
techniques	O
from	O
graphical	Method
models	Method
such	O
as	O
conditional	Method
random	Method
field	Method
(	Method
CRF	Method
)	O
,	O
to	O
introduce	O
global	O
context	O
and	O
structured	O
information	O
into	O
a	O
FCN	Method
.	O

Although	O
powerful	O
,	O
these	O
architectures	O
can	O
be	O
complex	O
,	O
combining	O
both	O
the	O
challenges	O
of	O
tuning	O
a	O
deep	Method
neural	Method
network	Method
and	O
a	O
CRF	Method
,	O
and	O
require	O
a	O
fair	O
amount	O
of	O
experience	O
in	O
managing	O
the	O
idiosyncrasies	O
of	O
training	O
methodology	O
and	O
parameters	O
.	O

At	O
the	O
least	O
,	O
this	O
leads	O
to	O
time	O
-	O
consuming	O
training	Task
and	O
inference	Task
.	O

In	O
this	O
work	O
,	O
we	O
propose	O
ParseNet	Method
,	O
an	O
end	O
-	O
to	O
-	O
end	O
simple	O
and	O
effective	O
convolutional	Method
neural	Method
network	Method
,	O
for	O
semantic	Task
segmentation	Task
.	O

One	O
of	O
our	O
main	O
contributions	O
,	O
as	O
shown	O
in	O
Fig	O
.	O

[	O
reference	O
]	O
,	O
is	O
to	O
use	O
global	O
context	O
to	O
help	O
clarify	O
local	O
confusions	O
.	O

Looking	O
back	O
at	O
previous	O
work	O
,	O
adding	O
global	O
context	O
for	O
semantic	Task
segmentation	Task
is	O
not	O
a	O
new	O
idea	O
,	O
but	O
has	O
so	O
far	O
been	O
pursued	O
in	O
patch	Method
-	Method
based	Method
frameworks	Method
.	O

Such	O
patch	Method
-	Method
based	Method
approaches	Method
have	O
much	O
in	O
common	O
with	O
detection	Task
and	O
segmentation	Task
work	O
that	O
have	O
also	O
shown	O
benefits	O
from	O
integrating	O
global	O
context	O
into	O
classifying	O
regions	O
or	O
objects	O
in	O
an	O
image	O
.	O

Our	O
approach	O
allows	O
integrating	O
global	O
context	O
in	O
an	O
end	O
-	O
to	O
-	O
end	Method
fully	Method
convolutional	Method
network	Method
(	O
as	O
opposed	O
to	O
a	O
patch	Method
-	Method
based	Method
approach	Method
)	O
for	O
semantic	Task
segmentation	Task
with	O
small	O
computational	Metric
overhead	Metric
.	O

In	O
our	O
setting	O
,	O
the	O
image	O
is	O
not	O
divided	O
into	O
regions	O
or	O
objects	O
,	O
instead	O
the	O
network	O
makes	O
a	O
joint	Method
prediction	Method
of	O
all	O
pixel	O
values	O
.	O

Previous	O
work	O
on	O
fully	Method
convolutional	Method
networks	Method
did	O
not	O
include	O
global	O
features	O
,	O
and	O
there	O
were	O
limits	O
in	O
the	O
pixel	O
distance	O
across	O
which	O
consistency	O
in	O
labeling	Task
was	O
maintained	O
.	O

[	O
b	O
]	O
0.109	O
[	O
b	O
]	O
0.112	O
[	O
b	O
]	O
0.112	O
[	O
b	O
]	O
0.113	O
[	O
b	O
]	O
0.52	O
The	O
key	O
”	O
widget	O
”	O
that	O
allows	O
adding	O
global	O
context	O
to	O
the	O
FCN	Method
framework	Method
is	O
simple	O
,	O
but	O
has	O
several	O
important	O
consequences	O
in	O
addition	O
to	O
improving	O
the	O
accuracy	Metric
of	O
FCN	Method
.	O

First	O
,	O
the	O
entire	O
end	O
-	O
to	O
-	O
end	Task
process	Task
is	O
a	O
single	O
deep	Method
network	Method
,	O
making	O
training	Task
relatively	O
straightforward	O
compared	O
to	O
combining	O
deep	Method
networks	Method
and	O
CRFs	Method
.	O

In	O
addition	O
,	O
the	O
way	O
we	O
add	O
global	O
context	O
does	O
not	O
introduce	O
much	O
computational	Metric
overhead	Metric
versus	O
training	O
and	O
evaluating	O
a	O
standard	O
FCN	Method
,	O
while	O
improving	O
performance	O
significantly	O
.	O

In	O
our	O
approach	O
,	O
the	O
feature	O
map	O
for	O
a	O
layer	O
is	O
pooled	O
over	O
the	O
whole	O
image	O
to	O
result	O
in	O
a	O
context	O
vector	O
.	O

This	O
is	O
appended	O
to	O
each	O
of	O
the	O
features	O
sent	O
on	O
to	O
the	O
subsequent	O
layer	O
of	O
the	O
network	O
.	O

In	O
implementation	O
,	O
this	O
is	O
accomplished	O
by	O
unpooling	O
the	O
context	O
vector	O
and	O
appending	O
the	O
resulting	O
feature	Method
map	Method
with	O
the	O
standard	O
feature	Method
map	Method
.	O

The	O
process	O
is	O
shown	O
in	O
Fig	O
.	O

[	O
reference	O
]	O
.	O

This	O
technique	O
can	O
be	O
applied	O
selectively	O
to	O
feature	O
maps	O
within	O
a	O
network	O
,	O
and	O
can	O
be	O
used	O
to	O
combine	O
information	O
from	O
multiple	O
feature	O
maps	O
,	O
as	O
desired	O
.	O

Notice	O
that	O
the	O
scale	O
of	O
features	O
from	O
different	O
layers	O
may	O
be	O
quite	O
different	O
,	O
making	O
it	O
difficult	O
to	O
directly	O
combine	O
them	O
for	O
prediction	Task
.	O

We	O
find	O
that	O
normalizing	O
features	O
for	O
each	O
layer	O
and	O
combining	O
them	O
using	O
a	O
scaling	O
factor	O
learned	O
through	O
backpropagation	Method
works	O
well	O
to	O
address	O
this	O
potential	O
difficulty	O
.	O

In	O
section	O
[	O
reference	O
]	O
,	O
we	O
demonstrate	O
that	O
these	O
operations	O
,	O
appending	O
global	O
context	O
pooled	O
from	O
a	O
feature	O
map	O
along	O
with	O
an	O
appropriate	O
scaling	O
,	O
are	O
sufficient	O
to	O
significantly	O
improve	O
performance	O
over	O
the	O
basic	O
FCN	Method
,	O
resulting	O
in	O
accuracy	Metric
on	O
par	O
with	O
the	O
method	O
of	O
that	O
uses	O
detailed	O
structure	O
information	O
for	O
post	Task
processing	Task
.	O

That	O
said	O
,	O
we	O
do	O
not	O
advocate	O
ignoring	O
the	O
structure	O
information	O
.	O

Instead	O
,	O
we	O
posit	O
that	O
adding	O
the	O
global	O
feature	O
is	O
a	O
simple	O
and	O
robust	O
method	O
to	O
improve	O
FCN	Task
performance	O
by	O
considering	O
contextual	O
information	O
.	O

In	O
fact	O
,	O
our	O
network	O
can	O
be	O
combined	O
with	O
explicit	Method
structure	Method
output	Method
prediction	Method
,	O
e.g.	O
a	O
CRF	Method
,	O
to	O
potentially	O
further	O
increase	O
performance	O
.	O

The	O
rest	O
of	O
the	O
paper	O
is	O
organized	O
as	O
follows	O
.	O

In	O
Section	O
[	O
reference	O
]	O
we	O
review	O
the	O
related	O
work	O
.	O

Our	O
proposed	O
approach	O
is	O
described	O
in	O
Section	O
[	O
reference	O
]	O
followed	O
by	O
extensive	O
experimental	O
validation	O
in	O
Section	O
[	O
reference	O
]	O
.	O

We	O
conclude	O
our	O
work	O
and	O
describe	O
future	O
directions	O
in	O
Section	O
[	O
reference	O
]	O
.	O

section	O
:	O
Related	O
Work	O
Deep	Method
convolutional	Method
neural	Method
networks	Method
(	O
CNN	Method
)	O
have	O
become	O
powerful	O
tools	O
not	O
only	O
for	O
whole	Task
image	Task
classification	Task
,	O
but	O
also	O
for	O
object	O
detection	Task
and	O
semantic	Task
segmentation	Task
.	O

This	O
success	O
has	O
been	O
attributed	O
to	O
both	O
the	O
large	O
capacity	O
and	O
effective	O
training	O
of	O
the	O
CNN	Method
.	O

Following	O
the	O
proposal	Method
+	Method
post	Method
-	Method
classification	Method
scheme	Method
,	O
CNNs	Method
achieve	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
results	O
on	O
object	O
detection	Task
and	O
segmentation	Task
tasks	O
.	O

As	O
a	O
caveat	O
,	O
even	O
though	O
a	O
single	O
pass	O
through	O
the	O
networks	O
used	O
in	O
these	O
systems	O
is	O
approaching	O
or	O
already	O
past	O
video	Metric
frame	Metric
rate	Metric
for	O
individual	O
patch	O
,	O
these	O
approaches	O
require	O
classifying	O
hundreds	O
or	O
thousands	O
of	O
patches	O
per	O
image	O
,	O
and	O
thus	O
are	O
still	O
slow	O
.	O

improve	O
the	O
computation	O
by	O
applying	O
convolution	Method
to	O
the	O
whole	O
image	O
once	O
,	O
and	O
then	O
pool	O
features	O
from	O
the	O
final	O
feature	O
map	O
of	O
the	O
network	O
for	O
each	O
region	O
proposal	O
or	O
pixel	O
to	O
achieve	O
comparable	O
or	O
even	O
better	O
results	O
.	O

Yet	O
,	O
these	O
methods	O
still	O
fall	O
short	O
of	O
including	O
whole	O
image	O
context	O
and	O
only	O
classify	O
patches	O
or	O
pixels	O
locally	O
.	O

Our	O
ParseNet	Method
is	O
built	O
upon	O
the	O
fully	Method
convolutional	Method
network	Method
architecture	Method
with	O
a	O
strong	O
emphasis	O
on	O
including	O
contextual	O
information	O
in	O
a	O
simple	O
approach	O
.	O

For	O
semantic	Task
segmentation	Task
,	O
using	O
context	O
information	O
from	O
the	O
whole	O
image	O
can	O
significantly	O
help	O
classifying	O
local	O
patches	O
.	O

shows	O
that	O
by	O
concatenating	O
features	O
from	O
the	O
whole	O
image	O
to	O
the	O
local	O
patch	O
,	O
the	O
inclusion	O
of	O
post	Task
processing	Task
(	O
i.e.	O
CRF	Method
smoothing	Method
)	O
becomes	O
unnecessary	O
because	O
the	O
image	O
level	O
features	O
already	O
encode	O
the	O
smoothness	O
.	O

demonstrate	O
that	O
by	O
using	O
the	O
”	O
zoom	O
-	O
out	O
”	O
features	O
,	O
which	O
is	O
a	O
combination	O
of	O
features	O
for	O
each	O
super	O
pixel	O
,	O
region	O
surrounding	O
it	O
,	O
and	O
the	O
whole	O
image	O
,	O
they	O
can	O
achieve	O
impressive	O
performance	O
for	O
the	O
semantic	Task
segmentation	Task
task	O
.	O

These	O
approaches	O
pool	O
features	O
differently	O
for	O
local	O
patches	O
and	O
the	O
whole	O
image	O
,	O
making	O
it	O
difficult	O
to	O
train	O
the	O
whole	O
system	O
end	O
-	O
to	O
-	O
end	O
.	O

Exploiting	O
the	O
FCN	Method
architecture	Method
,	O
ParsetNet	Method
can	O
directly	O
use	O
global	Method
average	Method
pooling	Method
from	O
the	O
final	O
(	O
or	O
any	O
)	O
feature	O
map	O
,	O
resulting	O
in	O
the	O
feature	O
of	O
the	O
whole	O
image	O
,	O
and	O
use	O
it	O
as	O
context	O
.	O

Experiments	O
results	O
confirm	O
that	O
ParseNet	Method
can	O
capture	O
the	O
context	O
of	O
the	O
image	O
and	O
thus	O
improve	O
local	Task
patch	Task
prediction	Task
results	O
.	O

There	O
is	O
another	O
line	O
of	O
work	O
that	O
attempts	O
to	O
combine	O
graphical	Method
models	Method
with	O
CNNs	Method
to	O
incorporate	O
both	O
context	O
and	O
smoothness	O
priors	O
.	O

first	O
uses	O
a	O
FCN	Method
to	O
estimate	O
the	O
unary	O
potential	O
,	O
then	O
applies	O
a	O
fully	Method
connected	Method
CRF	Method
to	O
smooth	O
the	O
predictions	O
spatially	O
.	O

As	O
this	O
approach	O
consists	O
of	O
two	O
decoupled	O
stages	O
,	O
it	O
is	O
difficult	O
to	O
train	O
the	O
FCN	Method
properly	O
to	O
minimize	O
the	O
final	O
objective	O
of	O
smooth	Task
and	Task
accurate	Task
semantic	Task
segments	Task
.	O

A	O
more	O
unified	O
and	O
principled	O
approach	O
is	O
to	O
incorporate	O
the	O
structure	O
information	O
during	O
training	O
directly	O
.	O

propagates	O
the	O
marginals	O
computed	O
from	O
the	O
structured	O
loss	O
to	O
update	O
the	O
network	O
parameters	O
,	O
uses	O
piece	Method
-	Method
wise	Method
training	Method
to	O
make	O
learning	Task
more	O
efficient	O
by	O
adding	O
a	O
few	O
extra	O
piece	O
-	O
wise	Method
networks	Method
,	O
while	O
convert	O
CRF	Method
learning	Method
to	O
recurrent	Method
neural	Method
network	Method
(	O
RNN	Method
)	O
and	O
use	O
message	Method
passing	Method
to	O
do	O
the	O
learning	Task
and	Task
inference	Task
.	O

However	O
,	O
we	O
show	O
that	O
our	O
method	O
can	O
achieve	O
comparable	O
accuracy	Metric
,	O
with	O
a	O
simpler	O
–	O
hence	O
more	O
robust	O
–	O
structure	O
,	O
while	O
requiring	O
only	O
a	O
small	O
amount	O
of	O
additional	O
training	Metric
/	Metric
inference	Metric
time	Metric
.	O

[	O
b	O
]	O
0.2	O
[	O
b	O
]	O
0.2	O
[	O
b	O
]	O
0.2	O
[	O
b	O
]	O
0.2	O
section	O
:	O
ParseNet	Method
subsection	O
:	O
Global	O
Context	O
Context	O
is	O
known	O
to	O
be	O
very	O
useful	O
for	O
improving	O
performance	O
on	O
detection	Task
and	O
segmentation	Task
tasks	O
using	O
deep	Method
learning	Method
.	O

and	O
references	O
therein	O
illustrate	O
how	O
context	O
can	O
be	O
used	O
to	O
help	O
in	O
different	O
tasks	O
.	O

As	O
for	O
semantic	Task
segmentation	Task
,	O
per	Task
pixel	Task
classification	Task
,	O
is	O
often	O
ambiguous	O
in	O
the	O
presence	O
of	O
only	O
local	O
information	O
.	O

However	O
,	O
the	O
task	O
becomes	O
much	O
simpler	O
if	O
contextual	O
information	O
,	O
from	O
the	O
whole	O
image	O
,	O
is	O
available	O
.	O

Although	O
theoretically	O
,	O
features	O
from	O
the	O
top	O
layers	O
of	O
a	O
network	O
have	O
very	O
large	O
receptive	O
fields	O
(	O
e.g.	O
fc7	O
in	O
FCN	Method
with	O
VGG	Method
has	O
a	O
pixels	O
receptive	O
field	O
)	O
,	O
we	O
argue	O
that	O
in	O
practice	O
,	O
the	O
empirical	O
size	O
of	O
the	O
receptive	O
fields	O
is	O
much	O
smaller	O
,	O
and	O
is	O
not	O
enough	O
to	O
capture	O
the	O
global	O
context	O
.	O

To	O
identify	O
the	O
effective	O
receptive	O
field	O
,	O
we	O
slide	O
a	O
small	O
patch	O
of	O
random	O
noise	O
across	O
the	O
input	O
image	O
,	O
and	O
measure	O
the	O
change	O
in	O
the	O
activation	O
of	O
the	O
desired	O
layer	O
.	O

If	O
the	O
activation	O
does	O
not	O
vary	O
significantly	O
,	O
that	O
suggests	O
the	O
given	O
random	O
patch	O
is	O
outside	O
of	O
the	O
empirical	O
receptive	O
field	O
,	O
as	O
shown	O
in	O
Figure	O
[	O
reference	O
]	O
.	O

The	O
effective	O
receptive	O
field	O
at	O
the	O
last	O
layer	O
of	O
this	O
network	O
barely	O
covers	O
of	O
the	O
entire	O
image	O
.	O

Such	O
an	O
effect	O
of	O
difference	O
between	O
empirical	O
and	O
theoretical	O
receptive	O
field	O
sizes	O
was	O
also	O
observed	O
in	O
.	O

Fortunately	O
,	O
it	O
is	O
rather	O
straightforward	O
to	O
get	O
the	O
context	O
within	O
the	O
FCN	Method
architecture	Method
.	O

Specifically	O
,	O
we	O
use	O
global	Method
average	Method
pooling	Method
and	O
pool	O
the	O
context	O
features	O
from	O
the	O
last	O
layer	O
or	O
any	O
layer	O
if	O
that	O
is	O
desired	O
.	O

The	O
quality	Metric
of	O
semantic	Task
segmentation	Task
is	O
greatly	O
improved	O
by	O
adding	O
the	O
global	O
feature	O
to	O
local	O
feature	O
map	O
,	O
either	O
with	O
early	Method
fusion	Method
or	O
late	Method
fusion	Method
as	O
discussed	O
in	O
Sec	O
.	O

[	O
reference	O
]	O
.	O

For	O
example	O
,	O
Fig	O
[	O
reference	O
]	O
has	O
misclassified	O
a	O
large	O
portion	O
of	O
the	O
image	O
as	O
bird	O
since	O
it	O
only	O
used	O
local	O
information	O
,	O
however	O
,	O
adding	O
contextual	O
information	O
in	O
the	O
loop	O
,	O
which	O
might	O
contain	O
strong	O
signal	O
of	O
cat	O
,	O
corrects	O
the	O
mistake	O
.	O

Experiment	O
results	O
on	O
VOC2012	Material
and	O
PASCAL	Material
-	Material
Context	Material
dataset	Material
also	O
verify	O
our	O
assumption	O
.	O

Compared	O
with	O
,	O
the	O
improvement	O
is	O
similar	O
as	O
of	O
using	O
CRF	Method
to	O
post	O
-	O
process	O
the	O
output	O
of	O
FCN	Method
.	O

In	O
addition	O
,	O
we	O
also	O
tried	O
to	O
follow	O
the	O
spatial	Method
pyramid	Method
idea	Method
to	O
pool	O
features	O
from	O
increasingly	O
finer	O
sub	O
-	O
regions	O
and	O
attach	O
them	O
to	O
local	O
features	O
in	O
the	O
sub	O
-	O
regions	O
,	O
however	O
,	O
we	O
did	O
not	O
observe	O
significant	O
improvements	O
.	O

We	O
conjecture	O
that	O
it	O
is	O
because	O
the	O
(	O
empirical	O
)	O
receptive	O
field	O
of	O
high	O
-	O
level	O
feature	O
maps	O
is	O
larger	O
than	O
or	O
similar	O
as	O
those	O
sub	O
-	O
regions	O
.	O

However	O
features	O
pooled	O
from	O
the	O
whole	O
image	O
are	O
still	O
beneficial	O
.	O

subsection	O
:	O
Early	Task
Fusion	Task
and	O
Late	Task
Fusion	Task
Once	O
we	O
get	O
the	O
global	O
context	O
feature	O
,	O
there	O
are	O
two	O
general	O
standard	O
paradigms	O
of	O
using	O
it	O
with	O
the	O
local	O
feature	O
map	O
.	O

First	O
,	O
the	O
early	O
fusion	O
,	O
illustrated	O
in	O
in	O
Fig	O
.	O

[	O
reference	O
]	O
where	O
we	O
unpool	O
(	O
replicate	O
)	O
global	O
feature	O
to	O
the	O
same	O
size	O
as	O
of	O
local	O
feature	O
map	O
spatially	O
and	O
then	O
concatenate	O
them	O
,	O
and	O
use	O
the	O
combined	O
feature	O
to	O
learn	O
the	O
classifier	Method
.	O

The	O
alternative	O
approach	O
,	O
is	O
late	Task
fusion	Task
,	O
where	O
each	O
feature	O
is	O
used	O
to	O
learn	O
its	O
own	O
classifier	Method
,	O
followed	O
by	O
merging	O
the	O
two	O
predictions	O
into	O
a	O
single	O
classification	Metric
score	Metric
.	O

There	O
are	O
cons	O
and	O
pros	O
for	O
both	O
fusion	Method
methods	Method
.	O

If	O
there	O
is	O
no	O
additional	O
processing	O
on	O
combined	O
features	O
,	O
early	Method
fusion	Method
is	O
quite	O
similar	O
to	O
late	Method
fusion	Method
as	O
pointed	O
out	O
in	O
.	O

With	O
late	Task
fusion	Task
,	O
there	O
might	O
be	O
a	O
case	O
where	O
individual	O
features	O
can	O
not	O
recognize	O
something	O
but	O
combining	O
them	O
may	O
and	O
there	O
is	O
no	O
way	O
to	O
recover	O
from	O
independent	O
predictions	O
.	O

Our	O
experiments	O
show	O
that	O
both	O
method	O
works	O
more	O
or	O
less	O
the	O
same	O
if	O
we	O
normalize	O
the	O
feature	O
properly	O
for	O
early	Task
fusion	Task
case	Task
.	O

When	O
merging	O
the	O
features	O
,	O
one	O
must	O
be	O
careful	O
to	O
normalize	O
each	O
individual	O
feature	O
to	O
make	O
the	O
combined	O
feature	O
work	O
well	O
;	O
in	O
classical	Task
computer	Task
vision	Task
this	O
is	O
referred	O
as	O
the	O
cue	Task
combination	Task
problem	Task
.	O

As	O
shown	O
in	O
Fig	O
.	O

[	O
reference	O
]	O
,	O
we	O
extract	O
a	O
feature	O
vector	O
at	O
a	O
position	O
combined	O
from	O
increasing	O
higher	O
level	O
layers	O
(	O
from	O
left	O
to	O
right	O
)	O
,	O
with	O
lower	O
level	O
feature	O
having	O
a	O
significantly	O
larger	O
scale	O
than	O
higher	O
level	O
layers	O
.	O

As	O
we	O
show	O
in	O
Sec	O
.	O

[	O
reference	O
]	O
,	O
by	O
naively	O
combining	O
features	O
,	O
the	O
resultant	O
feature	O
will	O
not	O
be	O
discriminative	O
,	O
and	O
heavy	O
parameter	Method
tuning	Method
will	O
be	O
required	O
to	O
achieve	O
sufficient	O
accuracy	Metric
.	O

Instead	O
,	O
we	O
can	O
first	O
normalize	O
each	O
feature	O
and	O
also	O
possibly	O
learn	O
the	O
scale	O
parameter	O
,	O
which	O
makes	O
the	O
learning	O
more	O
stable	O
.	O

We	O
will	O
describe	O
more	O
details	O
in	O
Sec	O
.	O

[	O
reference	O
]	O
.	O

subsection	O
:	O
Normalization	Method
Layer	Method
As	O
discussed	O
above	O
and	O
shown	O
in	O
Fig	O
.	O

[	O
reference	O
]	O
,	O
we	O
need	O
to	O
combine	O
two	O
(	O
or	O
more	O
)	O
feature	O
vectors	O
,	O
which	O
generally	O
have	O
different	O
scale	O
and	O
norm	O
.	O

Naively	O
concatenating	O
features	O
leads	O
to	O
poor	O
performance	O
as	O
the	O
”	O
larger	O
”	O
features	O
dominate	O
the	O
”	O
smaller	O
”	O
ones	O
.	O

Although	O
during	O
training	O
,	O
the	O
weight	O
might	O
adjust	O
accordingly	O
,	O
it	O
requires	O
very	O
careful	O
tuning	O
of	O
parameters	O
and	O
depends	O
on	O
dataset	O
,	O
thus	O
goes	O
against	O
the	O
robust	O
principle	O
.	O

We	O
find	O
that	O
by	O
normalizing	O
each	O
individual	O
feature	O
first	O
,	O
and	O
also	O
learn	O
to	O
scale	O
each	O
differently	O
,	O
it	O
makes	O
the	O
training	O
more	O
stable	O
and	O
improves	O
performance	O
.	O

norm	Method
layer	Method
is	O
not	O
only	O
useful	O
for	O
feature	Task
combination	Task
.	O

As	O
was	O
pointed	O
out	O
above	O
,	O
in	O
some	O
cases	O
late	Task
fusion	Task
also	O
works	O
equally	O
well	O
,	O
but	O
only	O
with	O
the	O
help	O
of	O
normalization	O
.	O

For	O
example	O
,	O
if	O
we	O
want	O
to	O
use	O
lower	O
level	O
feature	O
to	O
learn	O
classifier	Method
,	O
as	O
demonstrated	O
in	O
Fig	O
.	O

[	O
reference	O
]	O
,	O
some	O
of	O
the	O
features	O
will	O
have	O
very	O
large	O
norm	O
.	O

It	O
is	O
not	O
trivial	O
to	O
learn	O
with	O
it	O
without	O
careful	O
weight	Method
initialization	Method
and	O
parameter	Method
tuning	Method
.	O

A	O
work	O
around	O
strategy	O
is	O
to	O
apply	O
an	O
additional	O
convolutional	Method
layer	Method
and	O
use	O
several	O
stages	O
of	O
finetuning	Method
with	O
much	O
lower	O
learning	Metric
rate	Metric
for	O
lower	O
layer	O
.	O

This	O
again	O
goes	O
against	O
the	O
principle	O
of	O
simply	O
and	O
robustness	Metric
.	O

In	O
our	O
work	O
,	O
we	O
apply	O
-	O
norm	O
and	O
learn	O
the	O
scale	O
parameter	O
for	O
each	O
channel	O
before	O
using	O
the	O
feature	O
for	O
classification	Task
,	O
which	O
leads	O
to	O
more	O
stable	O
training	O
.	O

Formally	O
,	O
let	O
be	O
the	O
loss	O
we	O
want	O
to	O
minimize	O
.	O

Here	O
we	O
use	O
the	O
summed	O
softmax	O
loss	O
.	O

For	O
a	O
layer	O
with	O
-	O
dimensional	O
input	O
,	O
we	O
will	O
normalize	O
it	O
using	O
-	O
norm	O
with	O
where	O
is	O
the	O
norm	O
of	O
.	O

Note	O
that	O
simply	O
normalizing	O
each	O
input	O
of	O
a	O
layer	O
changes	O
the	O
scale	O
of	O
the	O
layer	O
and	O
will	O
slow	O
down	O
the	O
learning	Task
if	O
we	O
do	O
not	O
scale	O
it	O
accordingly	O
.	O

For	O
example	O
,	O
we	O
tried	O
to	O
normalize	O
a	O
feature	O
s.t	O
.	O

-	O
norm	O
is	O
1	O
,	O
yet	O
we	O
can	O
hardly	O
train	O
the	O
network	O
because	O
the	O
features	O
become	O
very	O
small	O
.	O

However	O
,	O
if	O
we	O
normalize	O
it	O
to	O
e.g.	O
or	O
,	O
the	O
network	O
begins	O
to	O
learn	O
well	O
.	O

Motivated	O
by	O
batch	Method
normalization	Method
and	O
PReLU	Method
,	O
we	O
introduce	O
a	O
scaling	O
parameter	O
,	O
for	O
each	O
channel	O
,	O
which	O
scales	O
the	O
normalized	O
value	O
by	O
.	O

The	O
number	O
of	O
extra	O
parameters	O
is	O
equal	O
to	O
total	O
number	O
of	O
channels	O
,	O
and	O
are	O
negligible	O
and	O
can	O
be	O
learned	O
with	O
backprogation	O
.	O

Indeed	O
,	O
by	O
setting	O
,	O
we	O
could	O
recover	O
the	O
normalized	O
feature	O
,	O
if	O
that	O
was	O
optimal	O
.	O

Notice	O
that	O
this	O
is	O
simple	O
to	O
implement	O
as	O
the	O
normalization	Method
and	Method
scale	Method
parameter	Method
learning	Method
only	O
depend	O
on	O
each	O
input	O
feature	O
vector	O
and	O
do	O
not	O
need	O
to	O
aggregate	O
information	O
from	O
other	O
samples	O
as	O
batch	Method
normalization	Method
does	O
.	O

During	O
training	Task
,	O
we	O
use	O
backpropagation	Method
and	Method
chain	Method
rule	Method
to	O
compute	O
derivatives	O
with	O
respect	O
to	O
scaling	O
factor	O
and	O
input	O
data	O
For	O
our	O
case	O
,	O
we	O
need	O
to	O
do	O
-	O
norm	O
per	O
each	O
pixel	O
in	O
a	O
feature	O
map	O
instead	O
of	O
the	O
whole	O
.	O

We	O
can	O
easily	O
extend	O
the	O
equations	O
by	O
doing	O
it	O
elemental	O
wise	O
as	O
it	O
is	O
efficient	O
.	O

section	O
:	O
Experiments	O
In	O
this	O
section	O
,	O
we	O
mainly	O
report	O
results	O
on	O
three	O
benchmark	O
datasets	O
:	O
VOC2012	Material
and	O
PASCAL	Material
-	Material
Context	Material
.	O

VOC2012	Material
has	O
20	O
object	O
classes	O
and	O
one	O
background	O
class	O
.	O

Following	O
,	O
we	O
augment	O
it	O
with	O
extra	O
annotations	O
from	O
Hariharan	O
et	O
al	O
let@tokeneonedot	O
that	O
leads	O
to	O
10	O
,	O
582	O
,	O
1	O
,	O
449	O
,	O
and	O
1	O
,	O
456	O
images	O
for	O
training	O
,	O
validation	Task
,	O
and	O
testing	O
.	O

PASCAL	Material
-	Material
Context	Material
fully	O
labeled	O
all	O
scene	O
classes	O
appeared	O
in	O
VOC2010	Material
.	O

We	O
follow	O
the	O
same	O
training	O
+	O
validation	O
split	O
as	O
defined	O
and	O
used	O
in	O
,	O
resulting	O
in	O
59	O
object	O
+	O
stuff	O
classes	O
and	O
one	O
background	O
classes	O
with	O
4	O
,	O
998	O
and	O
5105	O
training	O
and	O
validation	O
images	O
.	O

All	O
the	O
results	O
we	O
describe	O
below	O
use	O
the	O
training	O
images	O
to	O
train	O
,	O
and	O
most	O
of	O
the	O
results	O
are	O
on	O
the	O
validation	O
set	O
.	O

We	O
also	O
report	O
results	O
on	O
VOC2012	Material
test	O
set	O
.	O

We	O
use	O
Caffe	Method
and	O
fine	O
-	O
tune	O
ParseNet	Method
from	O
VGG	Method
-	Method
16	Method
network	Method
for	O
different	O
dataset	O
.	O

subsection	O
:	O
Best	O
practice	O
of	O
finetuning	Task
As	O
we	O
know	O
parameters	O
are	O
important	O
for	O
training	Task
/	Task
finetuning	Task
network	Task
,	O
we	O
try	O
to	O
reproduce	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
systems	O
’	O
results	O
by	O
exploring	O
the	O
parameter	O
space	O
and	O
achieve	O
better	O
baseline	O
performance	O
.	O

PASCAL	Material
-	Material
Context	Material
We	O
start	O
from	O
the	O
public	O
system	O
FCN	O
-	O
32s	O
PASCAL	Material
-	Material
Context	Material
.	O

Notice	O
that	O
it	O
uses	O
the	O
accumulated	O
gradient	O
and	O
affine	O
transformation	O
tricks	O
that	O
were	O
introduced	O
in	O
.	O

As	O
such	O
,	O
it	O
can	O
deal	O
with	O
any	O
input	O
image	O
of	O
various	O
sizes	O
without	O
warping	O
or	O
cropping	O
it	O
to	O
fixed	O
size	O
,	O
which	O
can	O
distort	O
the	O
image	O
and	O
affect	O
the	O
final	O
segmentation	Task
result	O
.	O

Table	O
[	O
reference	O
]	O
shows	O
our	O
different	O
versions	O
of	O
reproduced	O
baseline	O
results	O
.	O

Baseline	O
A	O
uses	O
the	O
exactly	O
same	O
protocol	O
,	O
and	O
our	O
result	O
is	O
1.5	O
%	O
lower	O
.	O

In	O
Baseline	O
B	O
,	O
we	O
tried	O
more	O
iteration	O
(	O
160k	O
vs.	O
80k	O
)	O
of	O
finetuning	Method
and	O
achieved	O
similar	O
performance	O
to	O
the	O
reported	O
one	O
.	O

Then	O
,	O
we	O
modified	O
the	O
network	O
a	O
bit	O
,	O
i.e.	O
we	O
used	O
”	O
xavier	O
”	O
initialization	O
,	O
higher	O
base	Metric
learning	Metric
rate	Metric
(	O
1e	O
-	O
9	O
vs.	O
1e	O
-	O
10	O
)	O
,	O
and	O
lower	O
momentum	O
(	O
0.9	O
vs.	O
0.99	O
)	O
,	O
and	O
we	O
achieved	O
higher	O
accuracy	Metric
as	O
shown	O
in	O
Baseline	O
C.	O
What	O
’s	O
more	O
,	O
we	O
also	O
remove	O
the	O
100	O
padding	O
in	O
the	O
first	O
convolution	Method
layer	Method
and	O
observed	O
no	O
significant	O
difference	O
but	O
network	O
trained	O
slightly	O
faster	O
.	O

Furthermore	O
,	O
we	O
also	O
used	O
”	O
poly	Method
”	Method
learning	Method
rate	Method
policy	Method
(	O
,	O
where	O
power	O
is	O
set	O
to	O
0.9	O
.	O

)	O
as	O
it	O
is	O
proved	O
to	O
converge	O
faster	O
than	O
normal	O
”	Method
step	Method
”	Method
policy	Method
,	O
and	O
thus	O
can	O
achieve	O
better	O
performance	O
with	O
the	O
same	O
iterations	O
(	O
80k	O
)	O
.	O

All	O
experimental	O
results	O
on	O
PASCAL	Material
-	Material
Context	Material
are	O
shown	O
in	O
table	O
[	O
reference	O
]	O
.	O

PASCAL	O
VOC2012	Material
We	O
carry	O
over	O
the	O
parameters	O
we	O
found	O
on	O
PASCAL	Material
-	Material
Context	Material
to	O
VOC2012	Material
.	O

We	O
tried	O
both	O
FCN	Method
-	Method
32s	Method
and	O
DeepLab	Method
-	Method
LargeFOV	Method
.	O

Table	O
[	O
reference	O
]	O
shows	O
the	O
reproduced	O
baseline	O
results	O
.	O

DeepLab	Method
is	O
very	O
similar	O
to	O
FCN	Method
-	Method
32s	Method
,	O
and	O
our	O
reproduced	O
result	O
is	O
5	O
%	O
better	O
(	O
64.96	O
vs.	O
59.80	O
)	O
using	O
the	O
parameters	O
we	O
found	O
in	O
PASCAL	Material
-	Material
Context	Material
.	O

DeepLab	Method
-	Method
LargeFOV	Method
uses	O
the	O
filter	Method
rarefication	Method
technique	Method
(	O
atrous	Method
algorithm	Method
)	O
that	O
has	O
much	O
less	O
parameters	O
and	O
is	O
faster	O
.	O

We	O
also	O
use	O
the	O
same	O
parameters	O
on	O
this	O
architecture	O
and	O
can	O
achieve	O
3.5	O
%	O
improvements	O
.	O

The	O
gap	O
between	O
these	O
two	O
models	O
is	O
not	O
significant	O
anymore	O
as	O
reported	O
in	O
.	O

Later	O
on	O
,	O
we	O
renamed	O
DeepLab	Method
-	Method
LargeFOV	Method
Baseline	Method
as	O
ParseNet	Method
Baseline	O
,	O
and	O
ParseNet	Method
is	O
ParseNet	Method
Baseline	O
plus	O
global	O
context	O
.	O

Until	O
now	O
,	O
we	O
see	O
that	O
parameters	O
and	O
details	O
are	O
important	O
to	O
get	O
best	O
performance	O
using	O
FCN	Method
models	Method
.	O

Below	O
,	O
we	O
report	O
all	O
our	O
results	O
with	O
the	O
reproduced	O
baseline	O
networks	O
.	O

subsection	O
:	O
Combining	O
Local	O
and	O
Global	O
Features	O
In	O
this	O
section	O
,	O
we	O
report	O
results	O
of	O
combining	O
global	O
and	O
local	O
feature	O
on	O
three	O
dataset	O
:	O
SiftFlow	Material
,	O
PASCAL	Material
-	Material
Context	Material
,	O
and	O
PASCAL	O
VOC2012	Material
.	O

For	O
simplicity	O
,	O
we	O
use	O
pool6	O
as	O
the	O
global	O
context	O
feature	O
,	O
conv5	O
as	O
conv5_3	Method
,	O
conv4	Method
as	O
conv4_3	Method
,	O
and	O
conv3	Method
as	O
conv3_3	O
through	O
the	O
rest	O
of	O
paper	O
.	O

SiftFlow	Material
is	O
a	O
relatively	O
small	O
dataset	O
that	O
only	O
has	O
2	O
,	O
688	O
images	O
with	O
33	O
semantic	O
categories	O
.	O

We	O
do	O
not	O
use	O
the	O
geometric	O
categories	O
during	O
training	O
.	O

We	O
use	O
the	O
FCN	Method
-	Method
32s	Method
network	Method
with	O
the	O
parameters	O
found	O
in	O
PASCAL	Material
-	Material
Context	Material
.	O

Instead	O
of	O
using	O
two	O
stages	O
of	O
learning	O
as	O
done	O
in	O
,	O
we	O
combine	O
the	O
feature	O
directly	O
from	O
different	O
layers	O
for	O
learning	Task
.	O

As	O
shown	O
in	O
Table	O
[	O
reference	O
]	O
,	O
adding	O
more	O
layers	O
can	O
normally	O
improve	O
the	O
performance	O
as	O
lower	O
level	O
layers	O
have	O
more	O
detailed	O
information	O
.	O

We	O
also	O
notice	O
that	O
adding	O
global	O
context	O
feature	O
does	O
not	O
help	O
much	O
.	O

This	O
is	O
perhaps	O
due	O
to	O
the	O
small	O
image	O
size	O
(	O
)	O
,	O
as	O
we	O
know	O
even	O
the	O
empirical	O
receptive	O
field	O
of	O
fc7	O
(	O
e.g.	O
Fig	O
.	O

[	O
reference	O
]	O
)	O
is	O
similar	O
as	O
if	O
not	O
bigger	O
than	O
that	O
,	O
thus	O
pool6	O
is	O
essentially	O
a	O
noop	O
.	O

PASCAL	Material
-	Material
Context	Material
We	O
then	O
apply	O
the	O
same	O
model	O
on	O
PASCAL	Material
-	Material
Context	Material
by	O
concatenating	O
features	O
from	O
different	O
layers	O
of	O
the	O
network	O
.	O

As	O
shown	O
in	O
Table	O
[	O
reference	O
]	O
,	O
by	O
adding	O
global	O
context	O
pool6	O
,	O
it	O
instantly	O
helps	O
improve	O
by	O
about	O
,	O
which	O
means	O
that	O
context	O
is	O
useful	O
here	O
as	O
opposed	O
to	O
the	O
observation	O
in	O
SiftFlow	Material
.	O

Context	O
becomes	O
more	O
important	O
proportionally	O
to	O
the	O
image	O
size	O
.	O

Another	O
interesting	O
observation	O
from	O
the	O
table	O
is	O
that	O
,	O
without	O
normalization	O
,	O
the	O
performance	O
keep	O
increasing	O
until	O
we	O
add	O
conv5	Method
.	O

However	O
,	O
if	O
we	O
naively	O
keep	O
adding	O
conv4	Method
,	O
it	O
starts	O
decreasing	O
the	O
performance	O
a	O
bit	O
;	O
and	O
if	O
we	O
add	O
conv3	Method
,	O
the	O
network	O
collapses	O
.	O

Interestingly	O
,	O
if	O
we	O
normalize	O
all	O
the	O
features	O
before	O
we	O
combine	O
them	O
,	O
we	O
do	O
n’t	O
see	O
such	O
a	O
drop	O
,	O
instead	O
,	O
adding	O
all	O
the	O
feature	O
together	O
can	O
achieve	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
result	O
on	O
PASCAL	Material
-	Material
Context	Material
as	O
far	O
as	O
we	O
know	O
.	O

PASCAL	O
VOC2012	Material
Since	O
we	O
have	O
reproduced	O
both	O
network	Method
architecture	Method
on	O
VOC2012	Material
,	O
we	O
want	O
to	O
see	O
how	O
does	O
global	O
context	O
,	O
normalization	O
,	O
and	O
early	O
or	O
late	O
fusion	O
affect	O
performance	O
.	O

We	O
start	O
with	O
using	O
DeepLab	Method
Baseline	Method
,	O
and	O
try	O
to	O
add	O
pool6	O
to	O
it	O
.	O

It	O
improves	O
from	O
64.92	O
%	O
to	O
67.49	O
%	O
by	O
adding	O
pool6	Method
with	O
normalization	Method
.	O

Interestingly	O
,	O
without	O
normalizing	Method
fc7	Method
and	O
pool6	Method
,	O
we	O
do	O
n’t	O
see	O
any	O
improvements	O
.	O

As	O
opposed	O
to	O
what	O
we	O
observed	O
from	O
SiftFlow	Material
and	O
PASCAL	Material
-	Material
Context	Material
.	O

We	O
hypothesize	O
this	O
is	O
due	O
to	O
images	O
in	O
VOC2012	Material
mostly	O
have	O
one	O
or	O
two	O
objects	O
in	O
the	O
image	O
versus	O
the	O
other	O
two	O
dataset	O
who	O
have	O
multiple	O
labels	O
per	O
image	O
,	O
and	O
we	O
need	O
to	O
adjust	O
the	O
weight	O
more	O
carefully	O
to	O
make	O
the	O
context	O
feature	O
more	O
useful	O
.	O

ParseNet	Method
Baseline	O
performance	O
is	O
higher	O
than	O
DeepLab	Method
Baseline	Method
and	O
it	O
is	O
faster	O
,	O
thus	O
we	O
switch	O
to	O
use	O
it	O
for	O
most	O
of	O
the	O
experimental	O
comparison	O
for	O
VOC2012	Material
.	O

As	O
shown	O
in	O
Table	O
[	O
reference	O
]	O
,	O
we	O
observe	O
a	O
similar	O
pattern	O
as	O
of	O
DeepLab	Method
Baseline	Method
that	O
if	O
we	O
add	O
pool6	O
,	O
it	O
is	O
helping	O
improve	O
the	O
performance	O
by	O
3.8	O
%	O
.	O

However	O
,	O
we	O
also	O
notice	O
that	O
if	O
we	O
do	O
not	O
normalize	O
them	O
and	O
learn	O
the	O
scaling	O
factors	O
,	O
its	O
effect	O
is	O
diminished	O
.	O

Furthermore	O
,	O
we	O
notice	O
that	O
early	Method
fusion	Method
and	O
late	Method
fusion	Method
both	O
work	O
very	O
similar	O
.	O

Figure	O
[	O
reference	O
]	O
illustrates	O
some	O
examples	O
of	O
how	O
global	O
context	O
helps	O
.	O

We	O
can	O
clearly	O
see	O
that	O
without	O
using	O
context	O
feature	O
,	O
the	O
network	O
will	O
make	O
many	O
mistakes	O
by	O
confusing	O
between	O
similar	O
categories	O
as	O
well	O
as	O
making	O
spurious	O
predictions	O
.	O

Two	O
similar	O
looking	O
patches	O
are	O
indistinguishable	O
by	O
the	O
network	O
if	O
considered	O
in	O
isolation	O
.	O

However	O
,	O
adding	O
context	O
solves	O
this	O
issue	O
as	O
the	O
global	O
context	O
helps	O
discriminate	O
the	O
local	O
patches	O
more	O
accurately	O
.	O

On	O
the	O
other	O
hand	O
,	O
sometimes	O
context	O
also	O
brings	O
confusion	O
for	O
prediction	Task
as	O
shown	O
in	O
Figure	O
[	O
reference	O
]	O
.	O

For	O
example	O
,	O
in	O
the	O
first	O
row	O
,	O
the	O
global	O
context	O
feature	O
definitely	O
captured	O
the	O
spotty	O
dog	O
information	O
that	O
it	O
used	O
to	O
help	O
discriminate	O
sheep	O
from	O
dog	O
.	O

However	O
,	O
it	O
also	O
added	O
bias	O
to	O
classify	O
the	O
spotty	O
horse	O
as	O
a	O
dog	O
.	O

The	O
other	O
three	O
examples	O
have	O
the	O
same	O
issue	O
.	O

Overall	O
,	O
by	O
learning	O
to	O
weight	O
pool6	O
and	O
fc7	O
after	O
normalization	Task
helps	O
improve	O
the	O
performance	O
greatly	O
.	O

We	O
also	O
tried	O
to	O
combine	O
lower	O
level	O
feature	O
as	O
was	O
done	O
with	O
PASCAL	Material
-	Material
Context	Material
and	O
SiftFlow	Material
,	O
but	O
no	O
significant	O
improvements	O
using	O
either	O
early	Method
fusion	Method
or	O
late	Method
fusion	Method
were	O
observed	O
.	O

We	O
believe	O
it	O
is	O
because	O
the	O
fc7	O
of	O
ParseNet	Method
Baseline	O
is	O
the	O
same	O
size	O
as	O
of	O
conv4	O
,	O
and	O
including	O
lower	O
level	O
feature	O
will	O
not	O
help	O
much	O
as	O
they	O
are	O
not	O
sufficiently	O
discriminative	O
.	O

Besides	O
,	O
we	O
also	O
tried	O
the	O
idea	O
similar	O
to	O
spatial	Method
pyramid	Method
pooling	Method
where	O
we	O
pool	O
global	O
feature	O
,	O
subregion	O
feature	O
,	O
and	O
subregion	O
feature	O
,	O
and	O
tried	O
both	O
early	Method
fusion	Method
and	O
late	Method
fusion	Method
.	O

However	O
,	O
we	O
observed	O
no	O
improvements	O
.	O

We	O
conjecture	O
that	O
the	O
receptive	O
field	O
of	O
the	O
high	O
level	O
feature	O
map	O
(	O
e.g.	O
fc7	Method
)	O
is	O
sufficiently	O
large	O
that	O
sub	O
-	O
region	O
global	O
feature	O
does	O
not	O
help	O
much	O
.	O

Finally	O
,	O
we	O
test	O
two	O
models	O
,	O
ParseNet	Method
Baseline	O
and	O
ParseNet	Method
,	O
on	O
VOC2012	Material
test	O
set	O
.	O

As	O
shown	O
in	O
Table	O
[	O
reference	O
]	O
,	O
we	O
can	O
see	O
that	O
our	O
baseline	O
result	O
is	O
already	O
higher	O
than	O
many	O
of	O
the	O
existing	O
methods	O
due	O
to	O
proper	O
finetuning	O
.	O

By	O
adding	O
the	O
global	O
context	O
feature	O
,	O
we	O
achieve	O
performance	O
that	O
is	O
within	O
the	O
standard	O
deviation	O
of	O
the	O
one	O
using	O
fully	Method
connect	Method
CRF	Method
to	O
smooth	O
the	O
outputs	O
and	O
perform	O
better	O
on	O
more	O
than	O
half	O
of	O
categories	O
.	O

Again	O
,	O
our	O
approach	O
is	O
much	O
simpler	O
to	O
implement	O
and	O
train	O
,	O
hence	O
is	O
more	O
robust	O
.	O

Using	O
late	Method
fusion	Method
has	O
almost	O
no	O
extra	O
training	Metric
/	Metric
inference	Metric
cost	Metric
.	O

[	O
subfigure	O
]	O
singlelinecheck	O
=	O
off	O
,	O
justification	O
=	O
raggedright	O
[	O
b	O
]	O
0.24	O
[	O
b	O
]	O
0.24	O
[	O
b	O
]	O
0.24	O
[	O
b	O
]	O
0.24	O
[	O
b	O
]	O
0.24	O
[	O
b	O
]	O
0.24	O
[	O
b	O
]	O
0.24	O
[	O
b	O
]	O
0.24	O
section	O
:	O
Conclusion	O
In	O
this	O
work	O
we	O
presented	O
ParseNet	Method
,	O
a	O
simple	O
fully	Method
convolutional	Method
neural	Method
network	Method
architecture	Method
that	O
allows	O
for	O
direct	Task
inclusion	Task
of	Task
global	Task
context	Task
for	O
the	O
task	O
of	O
semantic	Task
segmentation	Task
.	O

We	O
have	O
explicitly	O
demonstrated	O
that	O
relying	O
on	O
the	O
largest	O
receptive	O
field	O
of	O
FCN	Method
network	Method
does	O
not	O
provide	O
sufficient	O
global	O
context	O
,	O
and	O
the	O
largest	O
empirical	O
receptive	O
field	O
is	O
not	O
sufficient	O
to	O
capture	O
global	O
context	O
–	O
modeling	O
global	O
context	O
directly	O
in	O
required	O
.	O

On	O
PASCAL	O
VOC2012	Material
test	O
set	O
,	O
segmentation	Task
results	O
of	O
ParseNet	Method
are	O
within	O
the	O
standard	O
deviation	O
of	O
the	O
DeepLab	Method
-	Method
LargeFOV	Method
-	Method
CRF	Method
,	O
which	O
suggests	O
that	O
adding	O
a	O
global	O
feature	O
has	O
a	O
similar	O
effect	O
of	O
post	Task
processing	Task
FCN	Task
predictions	Task
with	O
a	O
graphical	Method
model	Method
.	O

As	O
part	O
of	O
developing	O
and	O
analyzing	O
this	O
approach	O
we	O
provided	O
analysis	O
of	O
many	O
architectural	O
choices	O
for	O
the	O
network	O
,	O
discussing	O
best	O
practices	O
for	O
training	Task
,	O
and	O
demonstrated	O
the	O
importance	O
of	O
normalization	O
and	O
learning	O
weights	O
when	O
combining	O
features	O
from	O
multiple	O
layers	O
of	O
a	O
network	O
.	O

By	O
themselves	O
,	O
our	O
practices	O
for	O
training	Task
significantly	O
improve	O
the	O
baselines	O
we	O
use	O
before	O
adding	O
global	O
context	O
.	O

The	O
guiding	O
principle	O
in	O
the	O
design	O
of	O
ParseNet	Method
is	O
simplicity	O
and	O
robustness	Metric
of	O
learning	Task
.	O

Results	O
are	O
presented	O
on	O
three	O
benchmark	O
dataset	O
,	O
and	O
are	O
state	O
of	O
the	O
art	O
on	O
SiftFlow	Material
and	O
PASCAL	Material
-	Material
Context	Material
,	O
and	O
near	O
the	O
state	O
of	O
the	O
art	O
on	O
PASCAL	O
VOC2012	Material
.	O

Given	O
the	O
simplicity	O
and	O
ease	O
of	O
training	O
,	O
we	O
find	O
these	O
results	O
very	O
encouraging	O
.	O

In	O
our	O
on	O
going	O
work	O
,	O
we	O
are	O
exploring	O
combining	O
our	O
technique	O
with	O
structure	Method
training	Method
/	Method
inference	Method
as	O
done	O
in	O
.	O

bibliography	O
:	O
References	O
