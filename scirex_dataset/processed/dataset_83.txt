document	O
:	O
Covariance	Method
Pooling	Method
for	O
Facial	Task
Expression	Task
Recognition	Task
Classifying	Task
facial	Task
expressions	Task
into	O
different	O
categories	O
requires	O
capturing	O
regional	O
distortions	O
of	O
facial	O
landmarks	O
.	O

We	O
believe	O
that	O
second	O
-	O
order	O
statistics	O
such	O
as	O
covariance	Method
is	O
better	O
able	O
to	O
capture	O
such	O
distortions	O
in	O
regional	O
facial	O
features	O
.	O

In	O
this	O
work	O
,	O
we	O
explore	O
the	O
benefits	O
of	O
using	O
a	O
manifold	Method
network	Method
structure	Method
for	O
covariance	Method
pooling	Method
to	O
improve	O
facial	Task
expression	Task
recognition	Task
.	O

In	O
particular	O
,	O
we	O
first	O
employ	O
such	O
kind	O
of	O
manifold	Method
networks	Method
in	O
conjunction	O
with	O
traditional	O
convolutional	Method
networks	Method
for	O
spatial	Method
pooling	O
within	O
individual	O
image	O
feature	O
maps	O
in	O
an	O
end	O
-	O
to	O
-	O
end	O
deep	Method
learning	Method
manner	Method
.	O

By	O
doing	O
so	O
,	O
we	O
are	O
able	O
to	O
achieve	O
a	O
recognition	Metric
accuracy	Metric
of	O
on	O
the	O
validation	O
set	O
of	O
Static	Material
Facial	Material
Expressions	Material
in	O
the	O
Wild	O
(	O
SFEW	Material
2.0	Material
)	O
and	O
on	O
the	O
validation	O
set	O
of	O
Real	Material
-	Material
World	Material
Affective	Material
Faces	Material
(	O
RAF	Material
)	O
Database	O
.	O

Both	O
of	O
these	O
results	O
are	O
the	O
best	O
results	O
we	O
are	O
aware	O
of	O
.	O

Besides	O
,	O
we	O
leverage	O
covariance	Method
pooling	Method
to	O
capture	O
the	O
temporal	O
evolution	O
of	O
per	O
-	O
frame	O
features	O
for	O
video	Task
-	Task
based	Task
facial	Task
expression	Task
recognition	Task
.	O

Our	O
reported	O
results	O
demonstrate	O
the	O
advantage	O
of	O
pooling	O
image	O
-	O
set	O
features	O
temporally	O
by	O
stacking	O
the	O
designed	O
manifold	O
network	O
of	O
covariance	Method
pooling	Method
on	O
top	O
of	O
convolutional	Method
network	Method
layers	Method
.	O

section	O
:	O
Introduction	O
Facial	O
expressions	O
play	O
an	O
important	O
role	O
in	O
communicating	O
the	O
state	O
of	O
our	O
mind	O
.	O

Both	O
humans	O
and	O
computer	Method
algorithms	Method
can	O
greatly	O
benefit	O
from	O
being	O
able	O
to	O
classify	O
facial	O
expressions	O
.	O

Possible	O
applications	O
of	O
automatic	Task
facial	Task
expression	Task
recognition	Task
include	O
better	O
transcription	Task
of	Task
videos	Task
,	O
movie	Task
or	Task
advertisement	Task
recommendations	Task
,	O
detection	Task
of	Task
pain	Task
in	O
telemedicine	Task
etc	O
.	O

Traditional	O
convolutional	Method
neural	Method
networks	Method
(	O
CNNs	Method
)	O
that	O
use	O
convolutional	Method
layers	Method
,	O
max	Method
or	Method
average	Method
pooling	Method
and	O
fully	Method
connected	Method
layers	Method
are	O
considered	O
to	O
capture	O
only	O
first	O
-	O
order	O
statistics	O
.	O

Second	O
-	O
order	O
statistics	O
such	O
as	O
covariance	O
are	O
considered	O
to	O
be	O
better	O
regional	Method
descriptors	Method
than	O
first	Method
-	Method
order	Method
statistics	Method
such	O
as	O
mean	O
or	O
maximum	O
.	O

As	O
shown	O
in	O
Figure	O
[	O
reference	O
]	O
,	O
facial	Task
expression	Task
recognition	Task
is	O
more	O
directly	O
related	O
to	O
how	O
facial	O
landmarks	O
are	O
distorted	O
rather	O
than	O
presence	O
or	O
absence	O
of	O
specific	O
landmarks	O
.	O

We	O
believe	O
that	O
second	Method
-	Method
order	Method
statistics	Method
is	O
more	O
suited	O
to	O
capture	O
such	O
distortions	O
than	O
first	O
-	O
order	O
statistics	O
.	O

To	O
learn	O
second	O
-	O
order	O
information	O
deeply	O
,	O
we	O
introduce	O
covariance	Method
pooling	Method
after	O
final	O
convolutional	Method
layers	Method
.	O

For	O
further	O
dimensionality	Task
reduction	Task
we	O
borrow	O
the	O
concepts	O
from	O
the	O
manifold	Method
network	Method
and	O
train	O
it	O
together	O
with	O
conventional	O
CNNs	Method
in	O
an	O
end	O
-	O
to	O
-	O
end	O
fashion	O
.	O

It	O
is	O
important	O
to	O
point	O
out	O
this	O
is	O
not	O
a	O
first	O
work	O
to	O
introduce	O
second	Method
-	Method
order	Method
pooling	Method
to	O
traditional	O
CNNs	Method
.	O

Covariance	Method
pooling	Method
was	O
initially	O
used	O
in	O
for	O
pooling	O
covariance	O
matrix	O
from	O
the	O
outputs	O
of	O
CNNs	Method
.	O

proposed	O
an	O
alternative	O
to	O
compute	O
second	O
-	O
order	O
statistics	O
in	O
the	O
setting	O
of	O
CNNs	Method
.	O

However	O
,	O
such	O
two	O
works	O
do	O
not	O
use	O
either	O
dimensionality	Method
reduction	Method
layers	Method
or	O
non	Method
-	Method
linear	Method
rectification	Method
layers	Method
for	O
second	O
-	O
order	O
statistics	O
.	O

In	O
this	O
paper	O
,	O
we	O
present	O
a	O
strong	O
motivation	O
for	O
exploring	O
them	O
in	O
the	O
context	O
of	O
facial	Task
expression	Task
recognition	Task
.	O

In	O
addition	O
to	O
being	O
better	O
able	O
to	O
capture	O
distortions	O
in	O
regional	O
facial	O
features	O
,	O
covariance	Method
pooling	Method
can	O
also	O
be	O
used	O
to	O
capture	O
temporal	O
evolution	O
of	O
per	O
-	O
frame	O
features	O
.	O

Covariance	Method
matrix	Method
has	O
been	O
employed	O
before	O
to	O
summarize	O
per	O
-	O
frame	O
features	O
.	O

In	O
this	O
work	O
,	O
we	O
experiment	O
with	O
using	O
manifold	Method
networks	Method
for	O
pooling	Task
per	Task
-	Task
frame	Task
features	Task
.	O

In	O
summary	O
,	O
the	O
contribution	O
of	O
this	O
paper	O
is	O
two	O
-	O
fold	O
:	O
End	O
-	O
to	O
-	O
end	Task
pooling	Task
of	Task
second	Task
-	Task
order	Task
statistics	Task
for	O
both	O
videos	O
and	O
images	O
in	O
the	O
context	O
of	O
facial	Task
expression	Task
recognition	Task
State	O
-	O
of	O
-	O
art	O
result	O
on	O
image	Task
-	Task
based	Task
facial	Task
expression	Task
recognition	Task
section	O
:	O
Related	O
Works	O
Though	O
facial	Task
expression	Task
recognition	Task
from	O
both	O
images	O
and	O
videos	O
are	O
closely	O
related	O
,	O
they	O
each	O
have	O
their	O
own	O
challenges	O
.	O

Videos	O
contain	O
dynamic	O
information	O
which	O
a	O
single	O
image	O
lacks	O
.	O

With	O
this	O
additional	O
dynamic	O
information	O
,	O
we	O
should	O
theoretically	O
be	O
able	O
to	O
improve	O
facial	Metric
expression	Metric
accuracy	Metric
.	O

However	O
,	O
extracting	Task
information	Task
from	O
videos	O
has	O
its	O
own	O
challenges	O
.	O

In	O
following	O
sub	O
-	O
sections	O
,	O
we	O
briefly	O
review	O
standard	O
approaches	O
to	O
facial	Task
expressions	Task
on	O
both	O
image	Method
and	Method
video	Method
-	Method
based	Method
approaches	Method
.	O

subsection	O
:	O
Facial	Task
Expression	Task
Recognition	Task
from	O
Images	O
Most	O
of	O
the	O
recent	O
approaches	O
in	O
facial	Task
expression	Task
recognition	Task
from	O
images	O
use	O
various	O
standard	O
architectures	O
such	O
as	O
VGG	Method
networks	Method
,	O
Inception	Method
networks	Method
,	O
Residual	Method
networks	Method
,	O
Inception	Method
-	Method
Residual	Method
Networks	Method
etc	O
.	O

Many	O
of	O
these	O
works	O
carry	O
out	O
pretraining	Task
on	O
FER	O
-	O
2013	O
,	O
face	O
recognition	O
datasets	O
or	O
similar	O
datasets	O
and	O
either	O
use	O
outputs	O
from	O
fully	O
connected	O
layers	O
as	O
features	O
to	O
train	O
classifiers	Method
or	O
fine	O
-	O
tune	O
the	O
whole	O
network	O
.	O

Use	O
of	O
ensemble	Method
of	Method
multiple	Method
CNNs	Method
and	O
fusion	O
of	O
the	O
predicted	O
scores	O
is	O
also	O
widely	O
used	O
and	O
found	O
to	O
be	O
successful	O
.	O

For	O
example	O
,	O
in	O
Emotiw2015	O
sub	O
challenge	O
on	O
image	Task
-	Task
based	Task
facial	Task
expression	Task
recognition	Task
,	O
both	O
winners	O
and	O
runner	O
up	O
teams	O
employed	O
ensemble	Method
of	Method
CNNs	Method
to	O
achieve	O
the	O
best	O
reported	O
score	O
.	O

There	O
,	O
pre	O
-	O
training	O
was	O
done	O
on	O
FER	O
-	O
2013	O
dataset	O
.	O

Recently	O
,	O
in	O
,	O
authors	O
reported	O
validation	Metric
accuracy	Metric
of	O
which	O
is	O
a	O
state	O
-	O
of	O
-	O
art	O
result	O
for	O
a	O
single	O
network	O
.	O

The	O
accuracy	Metric
was	O
achieved	O
using	O
VGG	Method
-	Method
VD	Method
-	Method
16	Method
.	O

The	O
authors	O
carried	O
out	O
pre	O
-	O
training	O
on	O
VGGFaces	Method
and	O
FER	Method
-	Method
2013	Method
.	O

All	O
such	O
networks	O
discussed	O
above	O
employ	O
traditional	O
neural	Method
network	Method
layers	Method
.	O

These	O
architectures	O
can	O
be	O
considered	O
to	O
capture	O
only	O
first	O
-	O
order	O
statistics	O
.	O

Covariance	Method
pooling	Method
,	O
on	O
the	O
other	O
hand	O
captures	O
second	O
-	O
order	O
statistics	O
.	O

One	O
of	O
the	O
earliest	O
works	O
employing	O
covariance	Method
pooling	Method
for	O
feature	Task
extraction	Task
used	O
it	O
as	O
regional	Method
descriptor	Method
.	O

In	O
,	O
authors	O
propose	O
various	O
architectures	O
based	O
on	O
VGG	Method
network	Method
to	O
employ	O
covariance	Method
pooling	Method
.	O

In	O
,	O
authors	O
present	O
a	O
deep	Method
learning	Method
architecture	Method
for	O
learning	O
on	O
Riemannian	O
manifold	O
which	O
can	O
be	O
employed	O
for	O
covariance	Method
pooling	Method
.	O

subsection	O
:	O
Facial	Task
Expression	Task
Recognition	Task
from	O
Videos	O
Traditionally	O
,	O
video	Task
-	Task
based	Task
recognition	Task
problems	Task
used	O
per	O
-	O
frame	O
features	O
such	O
as	O
SIFT	O
,	O
dense	O
-	O
SIFT	O
,	O
HOG	O
and	O
recently	O
deep	O
features	O
extracted	O
with	O
CNNs	Method
have	O
been	O
used	O
.	O

The	O
per	O
-	O
frame	O
features	O
are	O
then	O
used	O
to	O
assign	O
score	O
to	O
each	O
individual	O
frame	O
.	O

Summary	O
statistics	O
of	O
such	O
per	O
-	O
frame	O
features	O
are	O
then	O
used	O
for	O
facial	Task
expression	Task
recognition	Task
.	O

In	O
,	O
authors	O
propose	O
modification	O
of	O
Inception	Method
architecture	Method
to	O
capture	O
action	O
unit	O
activation	O
which	O
can	O
be	O
beneficial	O
for	O
facial	Task
expression	Task
recognition	Task
.	O

Other	O
works	O
use	O
various	O
techniques	O
to	O
capture	O
the	O
temporal	O
evolution	O
of	O
the	O
per	O
-	O
features	O
.	O

For	O
example	O
,	O
LSTMs	Method
have	O
been	O
successfully	O
employed	O
with	O
various	O
names	O
such	O
as	O
CNN	Method
-	O
RNN	O
,	O
CNN	Method
-	O
BRNN	O
etc	O
.	O

3D	Method
convolutional	Method
neural	Method
networks	Method
have	O
also	O
been	O
used	O
for	O
facial	Task
expression	Task
recognition	Task
.	O

However	O
,	O
performance	O
of	O
a	O
single	O
3D	Method
-	Method
ConvNet	Method
was	O
worse	O
than	O
applying	O
LSTMs	Method
on	O
per	O
-	O
frame	O
features	O
.	O

State	O
-	O
of	O
-	O
art	O
result	O
reported	O
in	O
was	O
obtained	O
by	O
score	Method
fusion	Method
of	O
multiple	Method
models	Method
of	Method
3D	Method
-	Method
ConvNets	Method
and	O
CNN	Method
-	Method
RNNs	Method
.	O

Covariance	Method
matrix	Method
representation	Method
was	O
used	O
as	O
one	O
of	O
the	O
summary	O
statistics	O
of	O
per	O
-	O
frame	O
features	O
in	O
.	O

Kernel	Method
-	Method
based	Method
partial	Method
least	Method
squares	Method
(	O
PLS	Method
)	O
were	O
then	O
used	O
for	O
recognition	Task
.	O

Here	O
,	O
we	O
use	O
the	O
methods	O
in	O
as	O
baseline	O
and	O
use	O
the	O
SPD	Method
Riemannian	Method
networks	Method
instead	O
of	O
kernel	Method
based	Method
PLS	Method
for	O
recognition	Task
and	O
obtain	O
slight	O
improvement	O
.	O

section	O
:	O
Facial	Task
Expression	Task
Recognition	Task
and	O
Covariance	Method
Pooling	Method
subsection	O
:	O
Overview	O
Facial	Task
expression	Task
is	O
localized	O
in	O
the	O
facial	O
region	O
whereas	O
images	O
in	O
the	O
wild	O
contain	O
large	O
irrelevant	O
information	O
.	O

Due	O
to	O
this	O
,	O
face	Task
detection	Task
is	O
performed	O
first	O
and	O
then	O
aligned	O
based	O
on	O
facial	O
landmark	O
locations	O
.	O

Next	O
,	O
we	O
feed	O
the	O
normalized	O
faces	O
into	O
a	O
deep	O
CNN	Method
.	O

To	O
pool	O
the	O
feature	O
maps	O
spatially	O
from	O
the	O
CNN	Method
,	O
we	O
propose	O
to	O
use	O
covariance	Method
pooling	Method
,	O
and	O
then	O
employ	O
the	O
manifold	Method
network	Method
to	O
deeply	O
learn	O
the	O
second	O
-	O
order	O
statistics	O
.	O

The	O
pipeline	O
of	O
our	O
proposed	O
model	O
for	O
image	Task
-	Task
based	Task
facial	Task
expression	Task
recognition	Task
is	O
shown	O
in	O
Figure	O
[	O
reference	O
]	O
.	O

As	O
the	O
case	O
of	O
image	Task
-	Task
based	Task
facial	Task
expression	Task
recognition	Task
,	O
videos	O
in	O
the	O
wild	O
contain	O
large	O
irrelevant	O
information	O
.	O

First	O
,	O
all	O
the	O
frames	O
are	O
extracted	O
from	O
a	O
video	O
.	O

Face	Task
detection	Task
and	O
alignment	Task
is	O
then	O
performed	O
on	O
each	O
individual	O
frame	O
.	O

Depending	O
on	O
the	O
feature	Method
extraction	Method
algorithm	Method
,	O
either	O
image	O
features	O
are	O
extracted	O
from	O
the	O
normalized	O
faces	O
or	O
the	O
normalized	O
faces	O
are	O
concatenated	O
and	O
3d	Method
convolutions	Method
are	O
applied	O
to	O
the	O
concatenated	O
frames	O
.	O

Intuitively	O
,	O
as	O
the	O
temporal	Method
convariance	Method
can	O
capture	O
the	O
useful	O
facial	O
motion	O
pattern	O
,	O
we	O
propose	O
to	O
pool	O
the	O
frames	O
over	O
time	O
.	O

To	O
deeply	O
learn	O
the	O
temporal	O
second	O
-	O
order	O
information	O
,	O
we	O
also	O
employ	O
the	O
manifold	Method
network	Method
for	O
dimensionality	Task
reduction	Task
and	O
non	O
-	O
linearity	O
on	O
covariance	O
matrices	O
.	O

The	O
overview	O
of	O
our	O
presented	O
model	O
for	O
video	Task
-	Task
based	Task
facial	Task
expression	Task
recognition	Task
is	O
illustrated	O
in	O
Figure	O
[	O
reference	O
]	O
.	O

Accordingly	O
,	O
the	O
core	O
techniques	O
of	O
the	O
two	O
proposed	O
models	O
are	O
spatial	Method
/	O
temporal	Method
covariance	Method
pooling	Method
and	O
the	O
manifold	Method
network	Method
for	O
learning	O
the	O
second	O
-	O
order	O
features	O
deeply	O
.	O

In	O
the	O
following	O
we	O
will	O
introduce	O
the	O
two	O
crucial	O
techniques	O
.	O

subsection	O
:	O
Covariance	Method
Pooling	Method
As	O
discussed	O
earlier	O
,	O
traditional	O
CNNs	Method
that	O
consist	O
of	O
fully	Method
connected	Method
layers	Method
,	O
max	Method
or	Method
average	Method
pooling	Method
and	O
convolutional	Method
layers	Method
only	O
capture	O
first	O
-	O
order	O
information	O
.	O

ReLU	Method
introduces	O
non	O
-	O
linearity	O
but	O
does	O
so	O
only	O
at	O
individual	O
pixel	O
level	O
.	O

Covariance	O
matrices	O
computed	O
from	O
features	O
are	O
believed	O
to	O
be	O
better	O
able	O
to	O
capture	O
regional	O
features	O
than	O
first	O
-	O
order	O
statistics	O
.	O

Given	O
a	O
set	O
of	O
features	O
,	O
covariance	O
matrix	O
can	O
be	O
used	O
to	O
compactly	O
summarize	O
the	O
second	O
-	O
order	O
information	O
in	O
the	O
set	O
.	O

If	O
be	O
the	O
set	O
of	O
features	O
,	O
the	O
covariance	O
matrix	O
can	O
be	O
computed	O
as	O
:	O
where	O
.	O

The	O
matrices	O
thus	O
obtained	O
are	O
symmetric	O
positive	O
definite	O
(	O
SPD	Method
)	O
only	O
if	O
number	O
of	O
linearly	O
independent	O
components	O
in	O
is	O
greater	O
than	O
.	O

In	O
order	O
to	O
employ	O
the	O
geometric	Method
structure	Method
preserving	Method
layers	Method
of	O
the	O
SPD	Method
manifold	Method
network	Method
,	O
the	O
covariance	O
matrices	O
are	O
required	O
to	O
be	O
SPD	Method
.	O

However	O
,	O
even	O
if	O
the	O
matrices	O
are	O
only	O
positive	O
semi	O
definite	O
,	O
they	O
can	O
be	O
regularized	O
by	O
adding	O
a	O
multiple	O
of	O
trace	O
to	O
diagonal	O
entries	O
of	O
the	O
covariance	O
matrix	O
:	O
where	O
is	O
a	O
regularization	O
parameter	O
and	O
is	O
identity	O
matrix	O
.	O

paragraph	O
:	O
Covariance	Method
Matrix	Method
for	O
Spatial	Method
Pooling	Method
:	O
In	O
order	O
to	O
apply	O
covariance	Method
pooling	Method
to	O
image	Task
-	Task
based	Task
facial	Task
expression	Task
recognition	Task
problem	Task
,	O
as	O
shown	O
in	O
Figure	O
[	O
reference	O
]	O
,	O
outputs	O
from	O
final	O
convolutional	Method
layers	Method
can	O
be	O
flattened	O
and	O
used	O
to	O
compute	O
covariance	O
matrix	O
.	O

Let	O
be	O
the	O
output	O
obtained	O
after	O
several	O
convolutional	Method
layers	Method
,	O
where	O
stand	O
for	O
width	O
,	O
height	O
and	O
number	O
of	O
channels	O
in	O
the	O
output	O
respectively	O
.	O

can	O
be	O
flattened	O
as	O
an	O
element	O
where	O
.	O

If	O
be	O
columns	O
of	O
,	O
we	O
can	O
capture	O
the	O
variation	O
across	O
channels	O
by	O
computing	O
covariance	O
as	O
in	O
Eqn	O
[	O
reference	O
]	O
and	O
regularizing	O
thus	O
computed	O
matrix	O
using	O
Eqn	O
.	O

[	O
reference	O
]	O
.	O

paragraph	O
:	O
Covariance	Method
Matrix	Method
for	O
Temporal	Task
Pooling	Task
:	O
As	O
illustrated	O
in	O
Figure	O
[	O
reference	O
]	O
,	O
covariance	Method
pooling	Method
can	O
be	O
employed	O
in	O
to	O
pool	O
temporal	O
features	O
.	O

If	O
be	O
per	O
-	O
frame	O
features	O
extracted	O
from	O
images	O
,	O
we	O
can	O
compute	O
covariance	O
matrix	O
using	O
the	O
Eqn	O
.	O

[	O
reference	O
]	O
and	O
regularize	O
it	O
using	O
Eqn	O
.	O

[	O
reference	O
]	O
.	O

subsection	O
:	O
SPD	Method
Manifold	Method
Network	Method
(	O
SPDNet	Method
)	Method
Layers	Method
The	O
covariance	O
matrices	O
thus	O
obtained	O
typically	O
reside	O
on	O
the	O
Riemannian	O
manifold	O
of	O
SPD	O
matrices	O
.	O

Directly	O
flattening	O
and	O
applying	O
fully	O
connected	O
layers	O
directly	O
causes	O
loss	O
of	O
geometric	O
information	O
.	O

Standard	O
methods	O
apply	O
logarithm	O
operation	O
to	O
flatten	O
the	O
Riemannian	O
manifold	O
structure	O
to	O
be	O
able	O
to	O
apply	O
standard	O
loss	O
functions	O
of	O
Euclidean	O
space	O
.	O

The	O
covariance	O
matrices	O
thus	O
obtained	O
are	O
often	O
large	O
and	O
their	O
dimension	O
needs	O
to	O
be	O
reduced	O
without	O
losing	O
geometric	O
structure	O
.	O

In	O
,	O
authors	O
introduce	O
special	O
layers	O
for	O
reducing	O
dimension	O
of	O
SPD	Task
matrices	Task
and	O
to	O
flatten	O
the	O
Riemannian	O
manifold	O
to	O
be	O
able	O
to	O
apply	O
standard	O
loss	Method
functions	Method
.	O

In	O
this	O
subsection	O
,	O
we	O
briefly	O
discuss	O
the	O
layers	O
introduced	O
in	O
for	O
learning	Task
on	Task
Riemannian	Task
Manifold	Task
.	O

paragraph	O
:	O
Bilinear	Method
Mapping	Method
Layer	Method
(	O
BiMap	Method
)	O
Covariance	O
matrices	O
computed	O
from	O
features	O
can	O
be	O
large	O
and	O
it	O
may	O
not	O
be	O
feasible	O
to	O
directly	O
apply	O
fully	Method
connected	Method
layers	Method
after	O
flattening	O
them	O
.	O

Furthermore	O
,	O
it	O
is	O
also	O
important	O
to	O
preserve	O
geometric	O
structure	O
while	O
reducing	O
dimension	O
.	O

The	O
BiMap	Method
layer	Method
accomplishes	O
both	O
of	O
these	O
conditions	O
and	O
plays	O
the	O
same	O
role	O
as	O
traditional	O
fully	O
connected	O
layers	O
.	O

If	O
be	O
input	O
SPD	O
matrix	O
,	O
be	O
weight	O
matrix	O
in	O
the	O
space	O
of	O
full	O
rank	O
matrices	O
and	O
be	O
output	O
matrix	O
,	O
then	O
-	O
th	O
the	O
bilinear	O
mapping	O
is	O
defined	O
as	O
paragraph	O
:	O
Eigenvalue	Method
Rectification	Method
(	O
ReEig	Method
)	O
ReEig	Method
layer	Method
can	O
be	O
used	O
to	O
introduce	O
non	O
-	O
linearity	O
in	O
the	O
similar	O
way	O
as	O
Rectified	Method
Linear	Method
Unit	Method
(	Method
ReLU	Method
)	Method
layers	Method
in	O
traditional	O
neural	Method
networks	Method
.	O

If	O
be	O
input	O
SPD	O
matrix	O
,	O
be	O
output	O
and	O
be	O
eigenvalue	O
rectification	O
threshold	O
,	O
-	O
th	O
ReEig	Method
Layer	Method
is	O
defined	O
as	O
:	O
where	O
and	O
are	O
defined	O
by	O
eigenvalue	Method
decomposition	Method
.	O

The	O
operation	O
is	O
element	O
-	O
wise	Method
matrix	Method
operation	Method
.	O

paragraph	O
:	O
Log	Method
Eigenvalue	Method
Layer	Method
(	O
LogEig	Method
)	O
As	O
discussed	O
earlier	O
,	O
SPD	O
matrices	O
lie	O
on	O
Riemannian	O
manifold	O
.	O

The	O
final	O
LogEig	Method
layer	Method
endows	O
elements	O
in	O
Riemannian	O
manifold	O
with	O
a	O
Lie	O
Group	O
structure	O
so	O
that	O
matrices	O
can	O
be	O
flattened	O
and	O
standard	O
euclidean	O
operations	O
can	O
be	O
applied	O
.	O

If	O
be	O
input	O
matrix	O
,	O
be	O
output	O
matrix	O
,	O
the	O
LogEig	Method
layer	Method
applied	O
in	O
-	O
th	O
layer	O
is	O
defined	O
as	O
where	O
is	O
an	O
eigenvalue	Method
decomposition	Method
and	O
is	O
an	O
element	O
-	O
wise	O
matrix	O
operation	O
.	O

BiMap	O
and	O
ReEig	O
layers	O
can	O
be	O
used	O
together	O
as	O
a	O
block	O
and	O
is	O
abbreviated	O
as	O
BiRe	O
.	O

The	O
architecture	O
of	O
a	O
SPDNet	Method
with	Method
2	Method
-	Method
BiRe	Method
layers	Method
is	O
shown	O
in	O
Figure	O
[	O
reference	O
]	O
.	O

section	O
:	O
Experiments	O
subsection	O
:	O
Benchmark	O
Datasets	O
Datasets	O
that	O
contain	O
samples	O
with	O
either	O
real	O
or	O
acted	O
facial	O
expressions	O
in	O
the	O
wild	O
were	O
chosen	O
.	O

Such	O
datasets	O
are	O
better	O
approximation	O
to	O
the	O
real	O
world	O
scenarios	O
than	O
posed	O
datasets	O
and	O
are	O
also	O
more	O
challenging	O
.	O

paragraph	O
:	O
Image	O
-	O
based	O
Facial	Task
Expression	Task
Recognition	Task
For	O
comparing	O
our	O
deep	Method
learning	Method
architectures	Method
for	O
image	Task
-	Task
based	Task
facial	Task
expression	Task
recognition	Task
against	O
standard	O
results	O
,	O
we	O
use	O
Static	Material
Facial	Material
Expressions	Material
in	Material
the	Material
Wild	Material
(	O
SFEW	Material
)	O
2.0	O
dataset	O
and	O
Real	Material
-	Material
world	Material
Affective	Material
Faces	Material
(	O
RAF	Material
)	Material
dataset	Material
.	O

SFEW	Material
2.0	Material
contains	O
1394	O
images	O
,	O
of	O
which	O
958	O
are	O
to	O
be	O
used	O
for	O
training	O
and	O
436	O
for	O
validation	Task
.	O

This	O
dataset	O
was	O
prepared	O
by	O
selecting	O
frames	O
from	O
videos	O
of	O
AFEW	O
dataset	O
.	O

Facial	O
landmark	O
points	O
provided	O
by	O
the	O
authors	O
were	O
detected	O
using	O
mixture	Method
-	Method
of	Method
-	Method
parts	Method
based	Method
model	Method
.	O

The	O
landmarks	O
thus	O
obtained	O
were	O
then	O
used	O
for	O
alignment	Task
.	O

The	O
RAF	Material
dataset	Material
was	O
prepared	O
by	O
collecting	O
images	O
from	O
various	O
search	O
engines	O
and	O
the	O
facial	O
landmarks	O
were	O
annotated	O
manually	O
by	O
40	O
independent	O
labelers	O
.	O

The	O
dataset	O
contains	O
15331	O
images	O
labeled	O
with	O
seven	O
basic	O
emotion	O
categories	O
of	O
which	O
3068	O
are	O
to	O
be	O
used	O
for	O
validation	Task
and	O
12271	O
for	O
training	O
.	O

It	O
is	O
worth	O
pointing	O
out	O
that	O
there	O
exist	O
several	O
other	O
image	O
-	O
based	O
datasets	O
such	O
as	O
EmotioNet	O
and	O
FER	O
-	O
2013	O
.	O

However	O
,	O
they	O
have	O
their	O
own	O
downsides	O
.	O

Though	O
EmotioNet	O
is	O
the	O
largest	O
existing	O
dataset	O
for	O
facial	Task
expression	Task
recognition	Task
,	O
the	O
images	O
were	O
automatically	O
annotated	O
and	O
the	O
labels	O
are	O
incomplete	O
.	O

FER	O
-	O
2013	O
,	O
contains	O
relatively	O
small	O
image	O
size	O
and	O
does	O
not	O
contain	O
RGB	O
information	O
.	O

Most	O
other	O
databases	O
either	O
contain	O
too	O
few	O
samples	O
or	O
are	O
taken	O
in	O
well	O
posed	O
laboratory	O
setting	O
.	O

paragraph	O
:	O
Video	O
-	O
based	O
Facial	Task
Expression	Task
Recognition	Task
For	O
video	Task
-	Task
based	Task
facial	Task
expression	Task
recognition	Task
,	O
we	O
use	O
Acted	O
Facial	O
Expressions	O
in	O
the	O
Wild	O
(	O
AFEW	O
)	O
dataset	O
to	O
compare	O
our	O
methods	O
with	O
existing	O
methods	O
.	O

This	O
dataset	O
was	O
prepared	O
by	O
selecting	O
videos	O
from	O
movies	O
.	O

It	O
contains	O
about	O
1156	O
publicly	O
available	O
labeled	O
videos	O
of	O
which	O
773	O
videos	O
are	O
used	O
for	O
training	O
and	O
383	O
for	O
validation	Task
.	O

Just	O
as	O
in	O
case	O
of	O
SFEW	Material
2.0	Material
dataset	Material
,	O
the	O
landmarks	O
and	O
aligned	O
images	O
provided	O
by	O
authors	O
were	O
obtained	O
using	O
mixture	Method
-	Method
of	Method
-	Method
parts	Method
based	Method
model	Method
.	O

Though	O
there	O
exist	O
several	O
other	O
facial	O
expression	O
recognition	O
databases	O
for	O
videos	O
such	O
as	O
Cohn	Method
-	Method
Kanade	Method
/	Method
Cohn	Method
-	Method
Kanade	Method
+	Method
(	O
CK	O
/	O
CK	Method
+	Method
)	O
,	O
most	O
of	O
them	O
are	O
either	O
sampled	O
in	O
well	O
controlled	O
laboratory	O
environment	O
or	O
are	O
labeled	O
with	O
action	Method
unit	Method
encoding	Method
rather	O
than	O
seven	O
basic	O
classes	O
of	O
facial	O
expressions	O
.	O

subsection	O
:	O
Face	Task
Detection	Task
and	O
Alignment	Task
Authors	O
of	O
RAF	Material
database	Material
provide	O
manually	O
annotated	O
face	O
landmarks	O
,	O
while	O
those	O
of	O
SFEW	Material
2.0	Material
and	O
AFEW	O
datasets	O
do	O
not	O
and	O
instead	O
provide	O
landmarks	O
and	O
aligned	O
images	O
obtained	O
using	O
mixture	Method
-	Method
of	Method
-	Method
parts	Method
based	Method
model	Method
.	O

Images	O
and	O
videos	O
captured	O
in	O
the	O
wild	O
contain	O
large	O
amount	O
of	O
non	O
-	O
essential	O
information	O
.	O

Face	Task
detection	Task
and	O
alignment	Task
helps	O
remove	O
non	O
-	O
essential	O
information	O
from	O
the	O
data	O
samples	O
.	O

Furthermore	O
,	O
to	O
be	O
able	O
to	O
compare	O
variations	O
in	O
local	O
facial	O
features	O
across	O
images	O
,	O
face	Task
alignment	Task
is	O
important	O
.	O

This	O
serves	O
as	O
normalization	Task
of	Task
data	Task
.	O

While	O
trying	O
to	O
categorize	O
facial	O
expressions	O
from	O
videos	O
,	O
motion	O
of	O
people	O
,	O
change	O
of	O
background	O
etc	O
.	O

also	O
lead	O
to	O
large	O
unwanted	O
variation	O
across	O
image	O
frames	O
.	O

Due	O
to	O
this	O
,	O
training	Method
algorithms	Method
on	O
original	O
unaligned	O
data	O
is	O
not	O
feasible	O
.	O

Face	Task
alignment	Task
additionally	O
helps	O
to	O
capture	O
the	O
dynamic	O
evolution	O
of	O
local	O
facial	O
features	O
across	O
images	O
of	O
the	O
same	O
videos	O
in	O
an	O
effective	O
manner	O
.	O

For	O
face	Task
and	Task
facial	Task
landmark	Task
detection	Task
Multi	Method
-	Method
task	Method
Cascade	Method
Convolutional	Method
Neural	Method
Networks	Method
(	O
MTCNN	Method
)	O
was	O
used	O
.	O

MTCNN	Method
was	O
found	O
to	O
be	O
more	O
accurate	O
and	O
successful	O
for	O
alignment	Task
compared	O
to	O
mixture	Method
-	Method
of	Method
-	Method
parts	Method
based	Method
model	Method
.	O

After	O
successful	O
face	Task
and	Task
facial	Task
landmark	Task
detection	Task
,	O
we	O
use	O
three	O
points	Method
constrained	Method
affine	Method
transformation	Method
for	O
face	Task
alignment	Task
.	O

Coordinates	O
of	O
left	O
eye	O
,	O
right	O
eye	O
and	O
midpoint	O
of	O
corners	O
of	O
the	O
lips	O
were	O
used	O
for	O
alignment	Task
.	O

subsection	O
:	O
Baseline	O
Model	O
and	O
Architectures	O
for	O
Image	Task
-	Task
based	Task
Problem	Task
paragraph	O
:	O
Comparison	O
of	O
Standard	O
Architectures	O
In	O
Table	O
[	O
reference	O
]	O
we	O
present	O
the	O
comparison	O
of	O
accuracies	Metric
of	O
training	O
or	O
finetuning	O
various	O
standard	O
network	Method
architectures	Method
.	O

For	O
a	O
baseline	O
model	O
,	O
we	O
take	O
the	O
network	Method
architecture	Method
presented	O
in	O
.	O

The	O
scores	O
reported	O
on	O
RAF	Material
database	Material
for	O
VGG	Method
network	Method
and	O
AlexNet	Task
in	Task
is	O
less	O
compared	O
to	O
their	O
base	Method
line	Method
model	Method
.	O

So	O
the	O
networks	O
are	O
not	O
trained	O
again	O
here	O
.	O

It	O
is	O
worth	O
pointing	O
out	O
that	O
there	O
,	O
authors	O
report	O
per	O
class	Metric
average	Metric
accuracy	Metric
but	O
we	O
report	O
total	O
accuracy	Metric
only	O
here	O
.	O

Here	O
,	O
we	O
use	O
center	Method
loss	Method
to	O
train	O
the	O
network	O
in	O
all	O
cases	O
rather	O
than	O
locality	Method
preserving	Method
loss	Method
as	O
we	O
do	O
not	O
deal	O
with	O
compound	O
emotions	O
.	O

In	O
all	O
cases	O
,	O
dataset	O
was	O
augmented	O
using	O
standard	O
techniques	O
such	O
as	O
random	O
crop	O
,	O
random	O
rotate	O
and	O
random	O
flip	O
.	O

For	O
SFEW	Material
2.0	Material
,	O
in	O
all	O
cases	O
,	O
output	O
of	O
second	O
to	O
last	O
fully	O
connected	O
layer	O
was	O
used	O
as	O
image	O
features	O
and	O
Support	Method
Vector	Method
Machines	Method
(	O
SVMs	Method
)	O
were	O
trained	O
separately	O
.	O

Note	O
that	O
the	O
models	O
labelled	O
were	O
trained	O
on	O
our	O
own	O
.	O

Inception	Method
-	O
ResnetV1	Method
was	O
both	O
trained	O
from	O
scratch	O
,	O
as	O
well	O
as	O
finetuned	O
on	O
a	O
model	O
pre	O
-	O
trained	O
on	O
subset	O
of	O
MS	O
-	O
Celeb	O
-	O
1	O
M	O
dataset	O
.	O

It	O
is	O
evident	O
from	O
the	O
table	O
that	O
fine	O
-	O
tuning	O
the	O
Inception	Method
-	Method
ResnetV1	Method
trained	O
on	O
face	O
recognition	O
dataset	O
performs	O
better	O
than	O
training	O
from	O
scratch	O
.	O

It	O
should	O
not	O
come	O
as	O
a	O
surprise	O
that	O
a	O
relatively	O
small	O
network	O
outperforms	O
Inception	Method
-	Method
ResNet	Method
model	Method
as	O
there	O
are	O
more	O
parameters	O
to	O
be	O
learned	O
in	O
deeper	Method
models	Method
.	O

For	O
further	O
experiments	O
and	O
to	O
introduce	O
covariance	Method
pooling	Method
,	O
we	O
use	O
the	O
baseline	Method
model	Method
from	O
.	O

paragraph	O
:	O
Incorporation	O
of	O
SPD	Method
Manifold	Method
Network	Method
As	O
discussed	O
above	O
,	O
we	O
introduce	O
covariance	Method
pooling	Method
and	O
subsequently	O
the	O
layers	O
from	O
the	O
SPD	Method
manifold	Method
network	Method
(	O
SPDNet	Method
)	O
after	O
the	O
final	O
convolutional	Method
layer	Method
.	O

While	O
introducing	O
covariance	Method
pooling	Method
,	O
we	O
experimented	O
with	O
various	O
models	O
for	O
the	O
architecture	O
.	O

The	O
details	O
of	O
the	O
various	O
models	O
considered	O
are	O
summarized	O
in	O
Table	O
[	O
reference	O
]	O
.	O

subsection	O
:	O
Results	O
on	O
Image	Task
-	Task
based	Task
Problem	Task
Covariance	Method
pooling	Method
was	O
applied	O
after	O
final	O
convolution	Method
layer	Method
and	O
before	O
fully	Method
connected	Method
layers	Method
.	O

Various	O
models	O
described	O
in	O
Table	O
[	O
reference	O
]	O
and	O
their	O
accuracies	Metric
are	O
listed	O
below	O
in	O
Table	O
[	O
reference	O
]	O
.	O

For	O
the	O
RAF	Material
database	Material
,	O
as	O
stated	O
earlier	O
,	O
the	O
network	O
was	O
trained	O
in	O
end	O
-	O
to	O
-	O
end	O
fashion	O
.	O

However	O
,	O
for	O
SFEW	Material
2.0	Material
dataset	Material
,	O
we	O
use	O
output	O
of	O
penultimate	Method
fully	Method
connected	Method
layer	Method
(	O
which	O
ranges	O
from	O
128	O
to	O
2000	O
dimensional	O
feature	O
depending	O
on	O
the	O
model	O
considered	O
)	O
.	O

It	O
is	O
worth	O
pointing	O
out	O
that	O
for	O
SFEW	Material
2.0	Material
our	O
single	O
model	O
performed	O
better	O
than	O
ensemble	Method
of	Method
convolutional	Method
neural	Method
networks	Method
in	O
and	O
.	O

It	O
could	O
be	O
argued	O
that	O
the	O
datasets	O
used	O
for	O
pre	Task
-	Task
training	Task
were	O
different	O
in	O
our	O
case	O
and	O
in	O
.	O

However	O
,	O
improvement	O
of	O
almost	O
over	O
baseline	O
in	O
the	O
SFEW	Material
2.0	Material
dataset	Material
justifies	O
the	O
use	O
of	O
SPDNet	Method
for	O
facial	Task
expression	Task
recognition	Task
.	O

It	O
is	O
also	O
important	O
to	O
point	O
out	O
that	O
on	O
the	O
SFEW	Material
2.0	Material
and	O
AFEW	O
datasets	O
,	O
face	Task
detection	Task
failed	O
in	O
several	O
images	O
and	O
videos	O
.	O

To	O
report	O
validation	Metric
score	Metric
,	O
we	O
assign	O
random	Metric
uniform	Metric
probability	Metric
of	Metric
success	Metric
(	O
)	O
for	O
correct	O
recognition	Task
to	O
the	O
samples	O
on	O
which	O
face	Task
detection	Task
did	O
not	O
succeed	O
.	O

subsection	O
:	O
Baseline	Method
Model	Method
for	O
Video	Task
-	Task
based	Task
Recognition	Task
Problem	Task
For	O
comparing	O
the	O
benefits	O
of	O
using	O
SPDNet	Method
over	O
existing	O
methods	O
,	O
we	O
use	O
kernel	Method
based	Method
PLS	Method
that	O
used	O
covariance	O
matrices	O
as	O
features	O
in	O
baseline	O
method	O
.	O

128	O
dimensional	O
features	O
were	O
extracted	O
from	O
each	O
image	O
frame	O
of	O
a	O
video	O
and	O
the	O
video	O
was	O
modeled	O
with	O
a	O
covariance	O
matrix	O
.	O

Then	O
either	O
SPDNet	Method
or	Method
kernel	Method
based	Method
SVM	Method
with	O
either	O
RBF	Method
or	Method
Polynomial	Method
kernel	Method
were	O
used	O
for	O
recognition	Task
.	O

The	O
SPDNet	Method
was	O
able	O
to	O
outperform	O
other	O
methods	O
.	O

subsection	O
:	O
Results	O
on	O
Video	Task
-	Task
based	Task
Problem	Task
The	O
results	O
of	O
our	O
proposed	O
methods	O
,	O
baseline	O
method	O
and	O
the	O
accuracies	Metric
of	O
other	O
C3D	O
and	O
CNN	Method
-	O
RNN	O
models	O
from	O
are	O
presented	O
for	O
context	O
.	O

However	O
,	O
datasets	O
used	O
for	O
those	O
pretraining	O
other	O
models	O
are	O
not	O
uniform	O
,	O
and	O
detailed	O
comparison	O
of	O
all	O
existing	O
methods	O
is	O
not	O
within	O
the	O
scope	O
of	O
this	O
work	O
.	O

As	O
seen	O
from	O
Table	O
[	O
reference	O
]	O
,	O
our	O
model	O
was	O
able	O
to	O
slightly	O
surpass	O
the	O
results	O
of	O
the	O
base	Method
line	Method
model	Method
.	O

Our	O
method	O
also	O
performed	O
better	O
than	O
all	O
single	O
models	O
that	O
were	O
trained	O
on	O
publicly	O
available	O
training	O
dataset	O
.	O

The	O
network	O
from	O
was	O
trained	O
on	O
private	O
dataset	O
containing	O
an	O
order	O
of	O
magnitude	O
more	O
samples	O
.	O

As	O
a	O
side	O
experimentation	O
,	O
we	O
also	O
introduced	O
covariance	Method
pooling	Method
to	O
C3D	Method
model	Method
in	O
and	O
did	O
not	O
obtain	O
any	O
improvement	O
.	O

We	O
obtained	O
accuracy	Metric
of	O
.	O

section	O
:	O
Conclusion	O
In	O
this	O
work	O
,	O
we	O
exploit	O
the	O
use	O
of	O
SPDNet	Method
on	O
facial	Task
expression	Task
recognition	Task
problems	Task
.	O

As	O
shown	O
above	O
,	O
SPDNet	Method
applied	O
to	O
covariance	O
of	O
convolutional	O
features	O
can	O
classify	O
facial	O
expressions	O
more	O
efficiently	O
.	O

We	O
study	O
that	O
second	Method
-	Method
order	Method
networks	Method
are	O
better	O
able	O
to	O
capture	O
facial	O
landmark	O
distortions	O
.	O

Similarly	O
,	O
covariance	O
matrix	O
computed	O
from	O
image	O
feature	O
vectors	O
were	O
used	O
as	O
input	O
to	O
SPDNet	Method
for	O
video	Task
-	Task
based	Task
facial	Task
expression	Task
recognition	Task
problem	Task
.	O

We	O
were	O
able	O
to	O
obtain	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
results	O
on	O
image	Task
-	Task
based	Task
facial	Task
expression	Task
recognition	Task
problems	Task
on	O
the	O
SFEW	Material
2.0	Material
and	O
RAF	Material
datasets	Material
.	O

In	O
video	Task
-	Task
based	Task
facial	Task
expression	Task
recognition	Task
,	O
training	O
SPDNet	Method
on	O
image	Method
-	Method
based	Method
features	Method
was	O
able	O
to	O
obtain	O
results	O
comparable	O
to	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
results	O
.	O

In	O
the	O
context	O
of	O
video	Task
-	Task
based	Task
facial	Task
expression	Task
recognition	Task
problem	Task
,	O
architecture	O
presented	O
in	O
Figure	O
[	O
reference	O
]	O
can	O
be	O
trained	O
in	O
end	O
-	O
to	O
-	O
end	Task
training	Task
.	O

Though	O
with	O
brief	O
experimentation	O
,	O
we	O
were	O
able	O
to	O
obtain	O
accuracy	Metric
of	O
only	O
which	O
is	O
worse	O
than	O
the	O
score	O
reported	O
.	O

It	O
is	O
likely	O
to	O
be	O
a	O
result	O
of	O
relatively	O
small	O
size	O
of	O
AFEW	O
dataset	O
compared	O
to	O
parameters	O
in	O
the	O
network	O
.	O

Further	O
work	O
is	O
necessary	O
to	O
see	O
if	O
training	O
end	O
-	O
to	O
-	O
end	O
using	O
joint	Method
convolutional	Method
net	Method
and	O
SPD	Method
net	Method
can	O
improve	O
results	O
.	O

section	O
:	O
Further	O
Works	O
In	O
this	O
work	O
,	O
we	O
leveraged	O
covariance	O
matrix	O
to	O
capture	O
second	O
-	O
order	O
statistics	O
.	O

As	O
studied	O
in	O
,	O
Gaussian	Method
matrix	Method
is	O
able	O
to	O
further	O
improve	O
the	O
effectiveness	O
of	O
second	Metric
-	Metric
order	Metric
statistics	Metric
.	O

Formally	O
,	O
the	O
SPD	Method
form	Method
of	Method
Gaussian	Method
matrix	Method
can	O
be	O
computed	O
by	O
where	O
is	O
the	O
covariance	O
matrix	O
defined	O
in	O
Eqn	O
.	O

[	O
reference	O
]	O
,	O
and	O
is	O
the	O
mean	O
of	O
the	O
samples	O
captures	O
both	O
first	O
-	O
order	O
and	O
second	O
-	O
order	O
statistics	O
.	O

It	O
was	O
also	O
employed	O
in	O
to	O
develop	O
second	Method
-	Method
order	Method
convolutional	Method
neural	Method
networks	Method
.	O

Extending	O
current	O
work	O
from	O
covariance	Method
pooling	Method
to	O
Gaussian	Method
pooling	Method
would	O
be	O
an	O
interesting	O
direction	O
and	O
should	O
theoretically	O
improve	O
results	O
.	O

bibliography	O
:	O
References	O
