Aggregated	Method
Residual	Method
Transformations	Method
for	O
Deep	Method
Neural	Method
Networks	Method
section	O
:	O
Abstract	O
We	O
present	O
a	O
simple	O
,	O
highly	O
modularized	Method
network	Method
architecture	Method
for	O
image	Task
classification	Task
.	O

Our	O
network	O
is	O
constructed	O
by	O
repeating	O
a	O
building	O
block	O
that	O
aggregates	O
a	O
set	O
of	O
transformations	O
with	O
the	O
same	O
topology	O
.	O

Our	O
simple	O
design	O
results	O
in	O
a	O
homogeneous	O
,	O
multi	O
-	O
branch	O
architecture	O
that	O
has	O
only	O
a	O
few	O
hyper	O
-	O
parameters	O
to	O
set	O
.	O

This	O
strategy	O
exposes	O
a	O
new	O
dimension	O
,	O
which	O
we	O
call	O
"	O
cardinality	O
"	O
(	O
the	O
size	O
of	O
the	O
set	O
of	O
transformations	O
)	O
,	O
as	O
an	O
essential	O
factor	O
in	O
addition	O
to	O
the	O
dimensions	O
of	O
depth	O
and	O
width	O
.	O

On	O
the	O
ImageNet	Material
-	Material
1	Material
K	Material
dataset	Material
,	O
we	O
empirically	O
show	O
that	O
even	O
under	O
the	O
restricted	O
condition	O
of	O
maintaining	O
complexity	Metric
,	O
increasing	O
cardinality	O
is	O
able	O
to	O
improve	O
classification	Metric
accuracy	Metric
.	O

Moreover	O
,	O
increasing	O
cardinality	O
is	O
more	O
effective	O
than	O
going	O
deeper	O
or	O
wider	O
when	O
we	O
increase	O
the	O
capacity	O
.	O

Our	O
models	O
,	O
named	O
ResNeXt	Method
,	O
are	O
the	O
foundations	O
of	O
our	O
entry	O
to	O
the	O
ILSVRC	Task
2016	Task
classification	Task
task	Task
in	O
which	O
we	O
secured	O
2nd	O
place	O
.	O

We	O
further	O
investigate	O
ResNeXt	Method
on	O
an	O
ImageNet	Material
-	Material
5	Material
K	Material
set	Material
and	O
the	O
COCO	O
detection	O
set	O
,	O
also	O
showing	O
better	O
results	O
than	O
its	O
ResNet	Method
counterpart	O
.	O

The	O
code	O
and	O
models	O
are	O
publicly	O
available	O
online	O
1	O
.	O

section	O
:	O
Introduction	O
Research	O
on	O
visual	Task
recognition	Task
is	O
undergoing	O
a	O
transition	O
from	O
"	O
feature	Method
engineering	Method
"	O
to	O
"	O
network	Method
engineering	Method
"	O
[	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
.	O

In	O
contrast	O
to	O
traditional	O
handdesigned	O
features	O
(	O
e.g.	O
,	O
SIFT	O
[	O
reference	O
]	O
and	O
HOG	O
[	O
reference	O
]	O
)	O
,	O
features	O
learned	O
by	O
neural	Method
networks	Method
from	O
large	O
-	O
scale	O
data	O
[	O
reference	O
]	O
require	O
minimal	O
human	O
involvement	O
during	O
training	O
,	O
and	O
can	O
be	O
transferred	O
to	O
a	O
variety	O
of	O
recognition	Task
tasks	Task
[	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
.	O

Nevertheless	O
,	O
human	O
effort	O
has	O
been	O
shifted	O
to	O
designing	O
better	O
network	Method
architectures	Method
for	O
learning	Task
representations	Task
.	O

Designing	Method
architectures	Method
becomes	O
increasingly	O
difficult	O
with	O
the	O
growing	O
number	O
of	O
hyper	O
-	O
parameters	O
(	O
width	O
[	O
reference	O
]	O
,	O
filter	O
sizes	O
,	O
strides	O
,	O
etc	O
.	O

)	O
,	O
especially	O
when	O
there	O
are	O
many	O
layers	O
.	O

The	O
VGG	Method
-	Method
nets	Method
[	O
reference	O
]	O
exhibit	O
a	O
simple	O
yet	O
effective	O
strategy	O
of	O
constructing	O
very	O
deep	Method
networks	Method
:	O
stacking	Task
build	O
-	O
1	O
https:	O
//	O
github.com	O
/	O
facebookresearch	O
/	O
ResNeXt	Method
2	O
Width	O
refers	O
to	O
the	O
number	O
of	O
channels	O
in	O
a	O
layer	O
.	O

[	O
reference	O
]	O
.	O

Right	O
:	O
A	O
block	O
of	O
ResNeXt	Method
with	O
cardinality	O
=	O
32	O
,	O
with	O
roughly	O
the	O
same	O
complexity	Metric
.	O

A	O
layer	O
is	O
shown	O
as	O
(	O
#	O
in	O
channels	O
,	O
filter	O
size	O
,	O
#	O
out	O
channels	O
)	O
.	O

ing	O
blocks	O
of	O
the	O
same	O
shape	O
.	O

This	O
strategy	O
is	O
inherited	O
by	O
ResNets	Method
[	O
reference	O
]	O
which	O
stack	O
modules	O
of	O
the	O
same	O
topology	O
.	O

This	O
simple	O
rule	O
reduces	O
the	O
free	O
choices	O
of	O
hyperparameters	O
,	O
and	O
depth	O
is	O
exposed	O
as	O
an	O
essential	O
dimension	O
in	O
neural	Method
networks	Method
.	O

Moreover	O
,	O
we	O
argue	O
that	O
the	O
simplicity	O
of	O
this	O
rule	O
may	O
reduce	O
the	O
risk	O
of	O
over	O
-	O
adapting	O
the	O
hyperparameters	O
to	O
a	O
specific	O
dataset	O
.	O

The	O
robustness	Metric
of	O
VGGnets	Method
and	O
ResNets	Method
has	O
been	O
proven	O
by	O
various	O
visual	Task
recognition	Task
tasks	Task
[	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
and	O
by	O
non	Task
-	Task
visual	Task
tasks	Task
involving	O
speech	O
[	O
reference	O
][	O
reference	O
]	O
and	O
language	O
[	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
.	O

Unlike	O
VGG	Method
-	Method
nets	Method
,	O
the	O
family	O
of	O
Inception	Method
models	Method
[	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
have	O
demonstrated	O
that	O
carefully	O
designed	O
topologies	O
are	O
able	O
to	O
achieve	O
compelling	O
accuracy	Metric
with	O
low	O
theoretical	O
complexity	Metric
.	O

The	O
Inception	Method
models	Method
have	O
evolved	O
over	O
time	O
[	O
reference	O
][	O
reference	O
]	O
,	O
but	O
an	O
important	O
common	O
property	O
is	O
a	O
split	Method
-	Method
transform	Method
-	Method
merge	Method
strategy	Method
.	O

In	O
an	O
Inception	Method
module	Method
,	O
the	O
input	O
is	O
split	O
into	O
a	O
few	O
lower	O
-	O
dimensional	O
embeddings	O
(	O
by	O
1×1	O
convolutions	O
)	O
,	O
transformed	O
by	O
a	O
set	O
of	O
specialized	Method
filters	Method
(	O
3×3	O
,	O
5×5	O
,	O
etc	O
.	O

)	O
,	O
and	O
merged	O
by	O
concatenation	Method
.	O

It	O
can	O
be	O
shown	O
that	O
the	O
solution	O
space	O
of	O
this	O
architecture	O
is	O
a	O
strict	O
subspace	O
of	O
the	O
solution	O
space	O
of	O
a	O
single	O
large	O
layer	O
(	O
e.g.	O
,	O
5×5	O
)	O
operating	O
on	O
a	O
high	Method
-	Method
dimensional	Method
embedding	Method
.	O

The	O
split	Method
-	Method
transform	Method
-	Method
merge	Method
behavior	Method
of	Method
Inception	Method
modules	Method
is	O
expected	O
to	O
approach	O
the	O
representational	O
power	O
of	O
large	O
and	O
dense	O
layers	O
,	O
but	O
at	O
a	O
considerably	O
lower	O
computational	O
complexity	Metric
.	O

Despite	O
good	O
accuracy	Metric
,	O
the	O
realization	O
of	O
Inception	Method
models	Method
has	O
been	O
accompanied	O
with	O
a	O
series	O
of	O
complicating	O
fac	O
-	O
tors	O
-	O
the	O
filter	O
numbers	O
and	O
sizes	O
are	O
tailored	O
for	O
each	O
individual	O
transformation	O
,	O
and	O
the	O
modules	O
are	O
customized	O
stage	O
-	O
by	O
-	O
stage	O
.	O

Although	O
careful	O
combinations	O
of	O
these	O
components	O
yield	O
excellent	O
neural	Method
network	Method
recipes	Method
,	O
it	O
is	O
in	O
general	O
unclear	O
how	O
to	O
adapt	O
the	O
Inception	Method
architectures	Method
to	O
new	O
datasets	O
/	O
tasks	O
,	O
especially	O
when	O
there	O
are	O
many	O
factors	O
and	O
hyper	O
-	O
parameters	O
to	O
be	O
designed	O
.	O

In	O
this	O
paper	O
,	O
we	O
present	O
a	O
simple	O
architecture	O
which	O
adopts	O
VGG	O
/	O
ResNets	Method
'	O
strategy	O
of	O
repeating	O
layers	O
,	O
while	O
exploiting	O
the	O
split	Method
-	Method
transform	Method
-	Method
merge	Method
strategy	Method
in	O
an	O
easy	O
,	O
extensible	O
way	O
.	O

A	O
module	O
in	O
our	O
network	O
performs	O
a	O
set	O
of	O
transformations	O
,	O
each	O
on	O
a	O
low	O
-	O
dimensional	O
embedding	O
,	O
whose	O
outputs	O
are	O
aggregated	O
by	O
summation	Method
.	O

We	O
pursuit	O
a	O
simple	O
realization	O
of	O
this	O
idea	O
-	O
the	O
transformations	O
to	O
be	O
aggregated	O
are	O
all	O
of	O
the	O
same	O
topology	O
(	O
e.g.	O
,	O
Fig	O
.	O

1	O
(	O
right	O
)	O
)	O
.	O

This	O
design	O
allows	O
us	O
to	O
extend	O
to	O
any	O
large	O
number	O
of	O
transformations	O
without	O
specialized	O
designs	O
.	O

Interestingly	O
,	O
under	O
this	O
simplified	O
situation	O
we	O
show	O
that	O
our	O
model	O
has	O
two	O
other	O
equivalent	O
forms	O
(	O
Fig	O
.	O

3	O
)	O
.	O

The	O
reformulation	O
in	O
Fig	O
.	O

3	O
(	O
b	O
)	O
appears	O
similar	O
to	O
the	O
InceptionResNet	Method
module	Method
[	O
reference	O
]	O
in	O
that	O
it	O
concatenates	O
multiple	O
paths	O
;	O
but	O
our	O
module	O
differs	O
from	O
all	O
existing	O
Inception	Method
modules	Method
in	O
that	O
all	O
our	O
paths	O
share	O
the	O
same	O
topology	O
and	O
thus	O
the	O
number	O
of	O
paths	O
can	O
be	O
easily	O
isolated	O
as	O
a	O
factor	O
to	O
be	O
investigated	O
.	O

In	O
a	O
more	O
succinct	O
reformulation	O
,	O
our	O
module	O
can	O
be	O
reshaped	O
by	O
Krizhevsky	O
et	O
al	O
.	O

's	O
grouped	Method
convolutions	Method
[	O
reference	O
]	O
(	O
Fig	O
.	O

3	O
(	O
c	O
)	O
)	O
,	O
which	O
,	O
however	O
,	O
had	O
been	O
developed	O
as	O
an	O
engineering	O
compromise	O
.	O

We	O
empirically	O
demonstrate	O
that	O
our	O
aggregated	Method
transformations	Method
outperform	O
the	O
original	O
ResNet	Method
module	O
,	O
even	O
under	O
the	O
restricted	O
condition	O
of	O
maintaining	O
computational	O
complexity	Metric
and	O
model	Metric
size	Metric
-	O
e.g	O
.	O

,	O
Fig	O
.	O

1	O
(	O
right	O
)	O
is	O
designed	O
to	O
keep	O
the	O
FLOPs	O
complexity	Metric
and	O
number	O
of	O
parameters	O
of	O
Fig	O
.	O

1	O
(	O
left	O
)	O
.	O

We	O
emphasize	O
that	O
while	O
it	O
is	O
relatively	O
easy	O
to	O
increase	O
accuracy	Metric
by	O
increasing	O
capacity	O
(	O
going	O
deeper	O
or	O
wider	O
)	O
,	O
methods	O
that	O
increase	O
accuracy	Metric
while	O
maintaining	O
(	O
or	O
reducing	O
)	O
complexity	Metric
are	O
rare	O
in	O
the	O
literature	O
.	O

Our	O
method	O
indicates	O
that	O
cardinality	O
(	O
the	O
size	O
of	O
the	O
set	O
of	O
transformations	O
)	O
is	O
a	O
concrete	O
,	O
measurable	O
dimension	O
that	O
is	O
of	O
central	O
importance	O
,	O
in	O
addition	O
to	O
the	O
dimensions	O
of	O
width	O
and	O
depth	O
.	O

Experiments	O
demonstrate	O
that	O
increasing	O
cardinality	O
is	O
a	O
more	O
effective	O
way	O
of	O
gaining	O
accuracy	Metric
than	O
going	O
deeper	O
or	O
wider	O
,	O
especially	O
when	O
depth	O
and	O
width	O
starts	O
to	O
give	O
diminishing	O
returns	O
for	O
existing	O
models	O
.	O

Our	O
neural	Method
networks	Method
,	O
named	O
ResNeXt	Method
(	O
suggesting	O
the	O
next	O
dimension	O
)	O
,	O
outperform	O
ResNet	Method
-	Method
101	Method
/	Method
152	Method
[	O
reference	O
]	O
,	O
ResNet	Method
-	O
200	O
[	O
reference	O
]	O
,	O
Inception	O
-	O
v3	O
[	O
reference	O
]	O
,	O
and	O
Inception	O
-	O
ResNet	Method
-	O
v2	O
[	O
reference	O
]	O
on	O
the	O
ImageNet	Material
classification	Material
dataset	Material
.	O

In	O
particular	O
,	O
a	O
101	O
-	O
layer	O
ResNeXt	Method
is	O
able	O
to	O
achieve	O
better	O
accuracy	Metric
than	O
ResNet	Method
-	Method
200	Method
[	O
reference	O
]	O
but	O
has	O
only	O
50	O
%	O
complexity	Metric
.	O

Moreover	O
,	O
ResNeXt	Method
exhibits	O
considerably	O
simpler	O
designs	O
than	O
all	O
Inception	Method
models	Method
.	O

ResNeXt	Method
was	O
the	O
foundation	O
of	O
our	O
submission	O
to	O
the	O
ILSVRC	Task
2016	Task
classification	Task
task	Task
,	O
in	O
which	O
we	O
secured	O
second	O
place	O
.	O

This	O
paper	O
further	O
evaluates	O
ResNeXt	Method
on	O
a	O
larger	O
ImageNet	Material
-	Material
5	Material
K	Material
set	Material
and	O
the	O
COCO	O
object	O
detection	O
dataset	O
[	O
reference	O
]	O
,	O
showing	O
consistently	O
better	O
accuracy	Metric
than	O
its	O
ResNet	Method
counterparts	O
.	O

We	O
expect	O
that	O
ResNeXt	Method
will	O
also	O
generalize	O
well	O
to	O
other	O
visual	Task
(	Task
and	Task
non	Task
-	Task
visual	Task
)	Task
recognition	Task
tasks	Task
.	O

section	O
:	O
Related	O
Work	O
Multi	Method
-	Method
branch	Method
convolutional	Method
networks	Method
.	O

The	O
Inception	Method
models	Method
[	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
are	O
successful	O
multi	Method
-	Method
branch	Method
architectures	Method
where	O
each	O
branch	O
is	O
carefully	O
customized	O
.	O

ResNets	Method
[	O
reference	O
]	O
can	O
be	O
thought	O
of	O
as	O
two	O
-	O
branch	Method
networks	Method
where	O
one	O
branch	O
is	O
the	O
identity	Method
mapping	Method
.	O

Deep	Method
neural	Method
decision	Method
forests	Method
[	O
reference	O
]	O
are	O
tree	Method
-	Method
patterned	Method
multi	Method
-	Method
branch	Method
networks	Method
with	O
learned	O
splitting	O
functions	O
.	O

Grouped	Method
convolutions	Method
.	O

The	O
use	O
of	O
grouped	Method
convolutions	Method
dates	O
back	O
to	O
the	O
AlexNet	O
paper	O
[	O
reference	O
]	O
,	O
if	O
not	O
earlier	O
.	O

The	O
motivation	O
given	O
by	O
Krizhevsky	O
et	O
al	O
.	O

[	O
reference	O
]	O
is	O
for	O
distributing	O
the	O
model	O
over	O
two	O
GPUs	Method
.	O

Grouped	Method
convolutions	Method
are	O
supported	O
by	O
Caffe	Method
[	O
reference	O
]	O
,	O
Torch	Method
[	O
reference	O
]	O
,	O
and	O
other	O
libraries	O
,	O
mainly	O
for	O
compatibility	O
of	O
AlexNet	Method
.	O

To	O
the	O
best	O
of	O
our	O
knowledge	O
,	O
there	O
has	O
been	O
little	O
evidence	O
on	O
exploiting	O
grouped	Method
convolutions	Method
to	O
improve	O
accuracy	Metric
.	O

A	O
special	O
case	O
of	O
grouped	Method
convolutions	Method
is	O
channel	Method
-	Method
wise	Method
convolutions	Method
in	O
which	O
the	O
number	O
of	O
groups	O
is	O
equal	O
to	O
the	O
number	O
of	O
channels	O
.	O

Channel	Method
-	Method
wise	Method
convolutions	Method
are	O
part	O
of	O
the	O
separable	Method
convolutions	Method
in	O
[	O
reference	O
]	O
.	O

Compressing	Method
convolutional	Method
networks	Method
.	O

Decomposition	Method
(	O
at	O
spatial	O
[	O
reference	O
][	O
reference	O
]	O
and	O
/	O
or	O
channel	O
[	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
level	O
)	O
is	O
a	O
widely	O
adopted	O
technique	O
to	O
reduce	O
redundancy	Method
of	Method
deep	Method
convolutional	Method
networks	Method
and	O
accelerate	O
/	O
compress	O
them	O
.	O

Ioannou	O
et	O
al	O
.	O

[	O
reference	O
]	O
present	O
a	O
"	O
root"	Method
-	Method
patterned	Method
network	Method
for	O
reducing	Task
computation	Task
,	O
and	O
branches	O
in	O
the	O
root	O
are	O
realized	O
by	O
grouped	Method
convolutions	Method
.	O

These	O
methods	O
[	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
have	O
shown	O
elegant	O
compromise	O
of	O
accuracy	Metric
with	O
lower	O
complexity	Metric
and	O
smaller	O
model	Metric
sizes	Metric
.	O

Instead	O
of	O
compression	Method
,	O
our	O
method	O
is	O
an	O
architecture	O
that	O
empirically	O
shows	O
stronger	O
representational	O
power	O
.	O

Ensembling	Method
.	O

Averaging	O
a	O
set	O
of	O
independently	Method
trained	Method
networks	Method
is	O
an	O
effective	O
solution	O
to	O
improving	O
accuracy	Metric
[	O
reference	O
]	O
,	O
widely	O
adopted	O
in	O
recognition	Task
competitions	Task
[	O
reference	O
]	O
.	O

Veit	O
et	O
al	O
.	O

[	O
reference	O
]	O
interpret	O
a	O
single	O
ResNet	Method
as	O
an	O
ensemble	Method
of	Method
shallower	Method
networks	Method
,	O
which	O
results	O
from	O
ResNet	Method
's	O
additive	O
behaviors	O
[	O
reference	O
]	O
.	O

Our	O
method	O
harnesses	O
additions	O
to	O
aggregate	O
a	O
set	O
of	O
transformations	O
.	O

But	O
we	O
argue	O
that	O
it	O
is	O
imprecise	O
to	O
view	O
our	O
method	O
as	O
ensembling	Task
,	O
because	O
the	O
members	O
to	O
be	O
aggregated	O
are	O
trained	O
jointly	O
,	O
not	O
independently	O
.	O

section	O
:	O
Method	O
section	O
:	O
Template	O
We	O
adopt	O
a	O
highly	O
modularized	Method
design	Method
following	O
VGG	Method
/	Method
ResNets	Method
.	O

Our	O
network	O
consists	O
of	O
a	O
stack	O
of	O
resid	O
-	O
Fig	O
.	O

3	O
(	O
c	O
)	O
)	O
.	O

Inside	O
the	O
brackets	O
are	O
the	O
shape	O
of	O
a	O
residual	O
block	O
,	O
and	O
outside	O
the	O
brackets	O
is	O
the	O
number	O
of	O
stacked	O
blocks	O
on	O
a	O
stage	O
.	O

"	O
C=32	O
"	O
suggests	O
grouped	Method
convolutions	Method
[	O
reference	O
]	O
with	O
32	O
groups	O
.	O

The	O
numbers	O
of	O
parameters	O
and	O
FLOPs	O
are	O
similar	O
between	O
these	O
two	O
models	O
.	O

ual	O
blocks	O
.	O

These	O
blocks	O
have	O
the	O
same	O
topology	O
,	O
and	O
are	O
subject	O
to	O
two	O
simple	O
rules	O
inspired	O
by	O
VGG	Method
/	Method
ResNets	Method
:	O
(	O
i	O
)	O
if	O
producing	O
spatial	O
maps	O
of	O
the	O
same	O
size	O
,	O
the	O
blocks	O
share	O
the	O
same	O
hyper	O
-	O
parameters	O
(	O
width	O
and	O
filter	O
sizes	O
)	O
,	O
and	O
(	O
ii	O
)	O
each	O
time	O
when	O
the	O
spatial	O
map	O
is	O
downsampled	O
by	O
a	O
factor	O
of	O
2	O
,	O
the	O
width	O
of	O
the	O
blocks	O
is	O
multiplied	O
by	O
a	O
factor	O
of	O
2	O
.	O

The	O
second	O
rule	O
ensures	O
that	O
the	O
computational	O
complexity	Metric
,	O
in	O
terms	O
of	O
FLOPs	O
(	O
floating	O
-	O
point	O
operations	O
,	O
in	O
#	O
of	O
multiply	O
-	O
adds	O
)	O
,	O
is	O
roughly	O
the	O
same	O
for	O
all	O
blocks	O
.	O

With	O
these	O
two	O
rules	O
,	O
we	O
only	O
need	O
to	O
design	O
a	O
template	Method
module	Method
,	O
and	O
all	O
modules	O
in	O
a	O
network	O
can	O
be	O
determined	O
accordingly	O
.	O

So	O
these	O
two	O
rules	O
greatly	O
narrow	O
down	O
the	O
design	O
space	O
and	O
allow	O
us	O
to	O
focus	O
on	O
a	O
few	O
key	O
factors	O
.	O

The	O
networks	O
constructed	O
by	O
these	O
rules	O
are	O
in	O
Table	O
1	O
.	O

section	O
:	O
Revisiting	O
Simple	O
Neurons	O
The	O
simplest	O
neurons	Method
in	O
artificial	Method
neural	Method
networks	Method
perform	O
inner	Method
product	Method
(	O
weighted	Method
sum	Method
)	O
,	O
which	O
is	O
the	O
elementary	O
transformation	O
done	O
by	O
fully	Method
-	Method
connected	Method
and	Method
convolutional	Method
layers	Method
.	O

Inner	O
product	O
can	O
be	O
thought	O
of	O
as	O
a	O
form	O
of	O
aggregating	Method
transformation	Method
:	O
where	O
nel	O
.	O

This	O
operation	O
(	O
usually	O
including	O
some	O
output	O
nonlinearity	O
)	O
is	O
referred	O
to	O
as	O
a	O
"	O
neuron	Method
"	O
.	O

See	O
Fig	O
.	O

2	O
.	O

The	O
above	O
operation	O
can	O
be	O
recast	O
as	O
a	O
combination	O
of	O
splitting	Task
,	O
transforming	Task
,	O
and	O
aggregating	Task
.	O

(	O
i	O
)	O
Splitting	O
:	O
the	O
vector	O
x	O
is	O
sliced	O
as	O
a	O
low	Method
-	Method
dimensional	Method
embedding	Method
,	O
and	O
in	O
the	O
above	O
,	O
it	O
is	O
a	O
single	O
-	O
dimension	O
subspace	O
x	O
i	O
.	O

(	O
ii	O
)	O
Transforming	Task
:	O
the	O
low	Method
-	Method
dimensional	Method
representation	Method
is	O
transformed	O
,	O
and	O
in	O
the	O
above	O
,	O
it	O
is	O
simply	O
scaled	O
:	O
w	O
i	O
x	O
i	O
.	O

(	O
iii	O
)	O
Aggregating	O
:	O
the	O
transformations	O
in	O
all	O
embeddings	O
are	O
aggregated	O
by	O
section	O
:	O
Aggregated	Method
Transformations	Method
Given	O
the	O
above	O
analysis	O
of	O
a	O
simple	O
neuron	O
,	O
we	O
consider	O
replacing	O
the	O
elementary	O
transformation	O
(	O
w	O
i	O
x	O
i	O
)	O
with	O
a	O
more	O
generic	O
function	O
,	O
which	O
in	O
itself	O
can	O
also	O
be	O
a	O
network	O
.	O

In	O
contrast	O
to	O
"	O
Network	Method
-	Method
in	Method
-	Method
Network	Method
"	O
[	O
reference	O
]	O
that	O
turns	O
out	O
to	O
increase	O
the	O
dimension	O
of	O
depth	O
,	O
we	O
show	O
that	O
our	O
"	O
Network	Method
-	Method
in	Method
-	Method
Neuron	Method
"	O
expands	O
along	O
a	O
new	O
dimension	O
.	O

Formally	O
,	O
we	O
present	O
aggregated	Method
transformations	Method
as	O
:	O
where	O
T	O
i	O
(	O
x	O
)	O
can	O
be	O
an	O
arbitrary	O
function	O
.	O

Analogous	O
to	O
a	O
simple	O
neuron	Method
,	O
T	O
i	O
should	O
project	O
x	O
into	O
an	O
(	O
optionally	O
lowdimensional	Method
)	Method
embedding	Method
and	O
then	O
transform	O
it	O
.	O

In	O
Eqn	O
.	O

(	O
2	O
)	O
,	O
C	O
is	O
the	O
size	O
of	O
the	O
set	O
of	O
transformations	O
to	O
be	O
aggregated	O
.	O

We	O
refer	O
to	O
C	O
as	O
cardinality	O
[	O
reference	O
]	O
.	O

In	O
Eqn.	O
(	O
2	O
)	O
C	O
is	O
in	O
a	O
position	O
similar	O
to	O
D	O
in	O
Eqn	O
.	O

(	O
1	O
)	O
,	O
but	O
C	O
need	O
not	O
equal	O
D	O
and	O
can	O
be	O
an	O
arbitrary	O
number	O
.	O

While	O
the	O
dimension	O
of	O
width	O
is	O
related	O
to	O
the	O
number	O
of	O
simple	O
transformations	O
(	O
inner	O
product	O
)	O
,	O
we	O
argue	O
that	O
the	O
dimension	O
of	O
cardinality	Metric
controls	O
the	O
number	O
of	O
more	O
complex	O
transformations	O
.	O

We	O
show	O
by	O
experiments	O
that	O
cardinality	O
is	O
an	O
essential	O
dimension	O
and	O
can	O
be	O
more	O
effective	O
than	O
the	O
dimensions	O
of	O
width	O
and	O
depth	O
.	O

In	O
this	O
paper	O
,	O
we	O
consider	O
a	O
simple	O
way	O
of	O
designing	O
the	O
transformation	O
functions	O
:	O
all	O
T	O
i	O
's	O
have	O
the	O
same	O
topology	O
.	O

This	O
extends	O
the	O
VGG	Method
-	Method
style	Method
strategy	Method
of	O
repeating	O
layers	O
of	O
the	O
same	O
shape	O
,	O
which	O
is	O
helpful	O
for	O
isolating	O
a	O
few	O
factors	O
and	O
extending	O
to	O
any	O
large	O
number	O
of	O
transformations	O
.	O

We	O
set	O
the	O
individual	O
transformation	O
T	O
i	O
to	O
be	O
the	O
bottleneckshaped	Method
architecture	Method
[	O
reference	O
]	O
,	O
as	O
illustrated	O
in	O
Fig	O
.	O

1	O
(	O
right	O
)	O
.	O

In	O
this	O
case	O
,	O
the	O
first	O
1×1	O
layer	O
in	O
each	O
T	O
i	O
produces	O
the	O
lowdimensional	O
embedding	O
.	O

,	O
implemented	O
as	O
grouped	Method
convolutions	Method
[	O
reference	O
]	O
.	O

Notations	O
in	O
bold	O
text	O
highlight	O
the	O
reformulation	O
changes	O
.	O

A	O
layer	O
is	O
denoted	O
as	O
(	O
#	O
input	O
channels	O
,	O
filter	O
size	O
,	O
#	O
output	O
channels	O
)	O
.	O

The	O
aggregated	O
transformation	O
in	O
Eqn	O
.	O

(	O
2	O
)	O
serves	O
as	O
the	O
residual	O
function	O
[	O
reference	O
]	O
(	O
Fig	O
.	O

1	O
right	O
)	O
:	O
where	O
y	O
is	O
the	O
output	O
.	O

Relation	O
to	O
Inception	O
-	O
ResNet	Method
.	O

Some	O
tensor	O
manipulations	O
show	O
that	O
the	O
module	O
in	O
Fig	O
.	O

1	O
(	O
right	O
)	O
(	O
also	O
shown	O
in	O
Fig	O
.	O

3	O
(	O
a	O
)	O
)	O
is	O
equivalent	O
to	O
Fig	O
.	O

3	O
(	O
b	O
)	O
.	O

[	O
reference	O
]	O
Fig	O
.	O

3	O
(	O
b	O
)	O
appears	O
similar	O
to	O
the	O
Inception	O
-	O
ResNet	Method
[	O
reference	O
]	O
block	O
in	O
that	O
it	O
involves	O
branching	O
and	O
concatenating	O
in	O
the	O
residual	O
function	O
.	O

But	O
unlike	O
all	O
Inception	O
or	O
Inception	O
-	O
ResNet	Method
modules	O
,	O
we	O
share	O
the	O
same	O
topology	O
among	O
the	O
multiple	O
paths	O
.	O

Our	O
module	O
requires	O
minimal	O
extra	O
effort	O
designing	O
each	O
path	O
.	O

Relation	O
to	O
Grouped	Method
Convolutions	Method
.	O

The	O
above	O
module	O
becomes	O
more	O
succinct	O
using	O
the	O
notation	O
of	O
grouped	Method
convolutions	Method
[	O
reference	O
]	O
.	O

[	O
reference	O
]	O
This	O
reformulation	O
is	O
illustrated	O
in	O
Fig	O
.	O

3	O
(	O
c	O
)	O
.	O

All	O
the	O
low	O
-	O
dimensional	O
embeddings	O
(	O
the	O
first	O
1×1	O
layers	O
)	O
can	O
be	O
replaced	O
by	O
a	O
single	O
,	O
wider	O
layer	O
(	O
e.g.	O
,	O
1×1	O
,	O
128	O
-	O
d	O
in	O
Fig	O
3	O
(	O
c	O
)	O
)	O
.	O

Splitting	Task
is	O
essentially	O
done	O
by	O
the	O
grouped	Method
convolutional	Method
layer	Method
when	O
it	O
divides	O
its	O
input	O
channels	O
into	O
groups	O
.	O

The	O
grouped	Method
convolutional	Method
layer	Method
in	O
Fig	O
.	O

3	Method
(	Method
c	Method
)	O
performs	O
32	O
groups	O
of	O
convolutions	Method
whose	O
input	O
and	O
output	O
channels	O
are	O
4	O
-	O
dimensional	O
.	O

The	O
grouped	Method
convolutional	Method
layer	Method
concatenates	O
them	O
as	O
the	O
outputs	O
of	O
the	O
layer	O
.	O

The	O
block	O
in	O
Fig	O
.	O

3	O
(	O
c	O
)	O
looks	O
like	O
the	O
original	O
bottleneck	O
residual	O
block	O
in	O
Fig	O
.	O

1	O
(	O
left	O
)	O
,	O
except	O
that	O
Fig	O
.	O

3	O
(	O
c	O
)	O
is	O
a	O
wider	O
but	O
sparsely	O
connected	O
module	O
.	O

[	O
reference	O
]	O
An	O
informal	O
but	O
descriptive	O
proof	O
is	O
as	O
follows	O
.	O

Note	O
the	O
equality	O
:	O
is	O
horizontal	O
concatenation	O
and	O
[	O
;	O
]	O
is	O
vertical	O
concatenation	O
.	O

Let	O
A	O
i	O
be	O
the	O
weight	O
of	O
the	O
last	O
layer	O
and	O
B	O
i	O
be	O
the	O
output	O
response	O
of	O
the	O
second	O
-	O
last	O
layer	O
in	O
the	O
block	O
.	O

In	O
the	O
case	O
of	O
C	O
=	O
2	O
,	O
the	O
element	O
-	O
wise	O
addition	O
in	O
Fig	O
.	O

3	O
(	O
a	O
)	O
is	O
A	O
1	O
B	O
1	O
+	O
A	O
2	O
B	O
2	O
,	O
the	O
weight	O
of	O
the	O
last	O
layer	O
in	O
Fig	O
.	O

3	O
(	O
b	O
)	O
is	O
[	O
A	O
1	O
,	O
A	O
2	O
]	O
,	O
and	O
the	O
concatenation	O
of	O
outputs	O
of	O
second	O
-	O
last	O
layers	O
in	O
Fig	O
.	O

3	O
(	O
b	O
)	O
is	O
[	O
B	O
1	O
;	O
B	O
2	O
]	O
.	O

[	O
reference	O
]	O
In	O
a	O
group	Method
conv	Method
layer	Method
[	O
reference	O
]	O
,	O
input	O
and	O
output	O
channels	O
are	O
divided	O
into	O
C	O
groups	O
,	O
and	O
convolutions	Method
are	O
separately	O
performed	O
within	O
each	O
group	O
.	O

We	O
note	O
that	O
the	O
reformulations	O
produce	O
nontrivial	O
topologies	O
only	O
when	O
the	O
block	O
has	O
depth	O
≥3	O
.	O

If	O
the	O
block	O
has	O
depth	O
=	O
2	O
(	O
e.g.	O
,	O
the	O
basic	O
block	O
in	O
[	O
reference	O
]	O
)	O
,	O
the	O
reformulations	O
lead	O
to	O
trivially	O
a	O
wide	O
,	O
dense	O
module	O
.	O

See	O
the	O
illustration	O
in	O
Fig	O
.	O

4	O
.	O

Discussion	O
.	O

We	O
note	O
that	O
although	O
we	O
present	O
reformulations	O
that	O
exhibit	O
concatenation	O
(	O
Fig	O
.	O

3	O
(	O
b	O
)	O
)	O
or	O
grouped	O
convolutions	O
(	O
Fig	O
.	O

3	O
(	O
c	O
)	O
)	O
,	O
such	O
reformulations	O
are	O
not	O
always	O
applicable	O
for	O
the	O
general	O
form	O
of	O
Eqn	O
.	O

(	O
3	O
)	O
,	O
e.g.	O
,	O
if	O
the	O
transformation	O
T	O
i	O
takes	O
arbitrary	O
forms	O
and	O
are	O
heterogenous	O
.	O

We	O
choose	O
to	O
use	O
homogenous	O
forms	O
in	O
this	O
paper	O
because	O
they	O
are	O
simpler	O
and	O
extensible	O
.	O

Under	O
this	O
simplified	O
case	O
,	O
grouped	O
convolutions	O
in	O
the	O
form	O
of	O
Fig	O
.	O

3	O
(	O
c	O
)	O
are	O
helpful	O
for	O
easing	O
implementation	O
.	O

section	O
:	O
Model	O
Capacity	O
Our	O
experiments	O
in	O
the	O
next	O
section	O
will	O
show	O
that	O
our	O
models	O
improve	O
accuracy	Metric
when	O
maintaining	O
the	O
model	O
complexity	Metric
and	O
number	O
of	O
parameters	O
.	O

This	O
is	O
not	O
only	O
interesting	O
in	O
practice	O
,	O
but	O
more	O
importantly	O
,	O
the	O
complexity	Metric
and	O
number	O
of	O
parameters	O
represent	O
inherent	O
capacity	O
of	O
models	O
and	O
thus	O
are	O
often	O
investigated	O
as	O
fundamental	O
properties	O
of	O
deep	Method
networks	Method
[	O
reference	O
]	O
.	O

When	O
we	O
evaluate	O
different	O
cardinalities	O
C	O
while	O
preserving	O
complexity	Metric
,	O
we	O
want	O
to	O
minimize	O
the	O
modification	O
of	O
other	O
hyper	O
-	O
parameters	O
.	O

We	O
choose	O
to	O
adjust	O
the	O
width	O
of	O
cardinality	O
C	O
the	O
bottleneck	O
(	O
e.g.	O
,	O
4	O
-	O
d	O
in	O
Fig	O
1	O
(	O
right	O
)	O
)	O
,	O
because	O
it	O
can	O
be	O
isolated	O
from	O
the	O
input	O
and	O
output	O
of	O
the	O
block	O
.	O

This	O
strategy	O
introduces	O
no	O
change	O
to	O
other	O
hyper	O
-	O
parameters	O
(	O
depth	O
or	O
input	O
/	O
output	O
width	O
of	O
blocks	O
)	O
,	O
so	O
is	O
helpful	O
for	O
us	O
to	O
focus	O
on	O
the	O
impact	O
of	O
cardinality	O
.	O

In	O
Fig	O
.	O

1	O
(	O
left	O
)	O
,	O
the	O
original	O
ResNet	Method
bottleneck	O
block	O
[	O
reference	O
]	O
Fig	O
.	O

1	O
(	O
right	O
)	O
has	O
:	O
parameters	O
and	O
proportional	Method
FLOPs	Method
.	O

When	O
C	O
=	O
32	O
and	O
d	O
=	O
4	O
,	O
Eqn.	O
(	O
4	O
)	O
≈	O
70k	O
.	O

Table	O
2	O
shows	O
the	O
relationship	O
between	O
cardinality	O
C	O
and	O
bottleneck	O
width	O
d.	O
Because	O
we	O
adopt	O
the	O
two	O
rules	O
in	O
Sec	O
.	O

3.1	O
,	O
the	O
above	O
approximate	O
equality	O
is	O
valid	O
between	O
a	O
ResNet	Method
bottleneck	O
block	O
and	O
our	O
ResNeXt	Method
on	O
all	O
stages	O
(	O
except	O
for	O
the	O
subsampling	O
layers	O
where	O
the	O
feature	O
maps	O
size	O
changes	O
)	O
.	O

Table	O
1	O
compares	O
the	O
original	O
ResNet	Method
-	Method
50	Method
and	O
our	O
ResNeXt	Method
-	Method
50	Method
that	O
is	O
of	O
similar	O
capacity	O
.	O

[	O
reference	O
]	O
We	O
note	O
that	O
the	O
complexity	Metric
can	O
only	O
be	O
preserved	O
approximately	O
,	O
but	O
the	O
difference	O
of	O
the	O
complexity	Metric
is	O
minor	O
and	O
does	O
not	O
bias	O
our	O
results	O
.	O

section	O
:	O
Implementation	O
details	O
Our	O
implementation	O
follows	O
[	O
reference	O
]	O
and	O
the	O
publicly	O
available	O
code	O
of	O
fb.resnet.torch	O
[	O
reference	O
]	O
.	O

On	O
the	O
ImageNet	Material
dataset	Material
,	O
the	O
input	O
image	O
is	O
224×224	O
randomly	O
cropped	O
from	O
a	O
resized	O
image	O
using	O
the	O
scale	Method
and	Method
aspect	Method
ratio	Method
augmentation	Method
of	O
[	O
reference	O
]	O
implemented	O
by	O
[	O
reference	O
]	O
.	O

The	O
shortcuts	O
are	O
identity	O
connections	O
except	O
for	O
those	O
increasing	O
dimensions	O
which	O
are	O
projections	O
(	O
type	O
B	O
in	O
[	O
reference	O
]	O
)	O
.	O

Downsampling	Task
of	Task
conv3	Task
,	O
4	O
,	O
and	O
5	O
is	O
done	O
by	O
stride	Method
-	Method
2	Method
convolutions	Method
in	O
the	O
3×3	O
layer	O
of	O
the	O
first	O
block	O
in	O
each	O
stage	O
,	O
as	O
suggested	O
in	O
[	O
reference	O
]	O
.	O

We	O
use	O
SGD	Method
with	O
a	O
mini	O
-	O
batch	O
size	O
of	O
256	O
on	O
8	O
GPUs	O
(	O
32	O
per	O
GPU	O
)	O
.	O

The	O
weight	O
decay	O
is	O
0.0001	O
and	O
the	O
momentum	O
is	O
0.9	O
.	O

We	O
start	O
from	O
a	O
learning	Metric
rate	Metric
of	O
0.1	O
,	O
and	O
divide	O
it	O
by	O
10	O
for	O
three	O
times	O
using	O
the	O
schedule	O
in	O
[	O
reference	O
]	O
.	O

We	O
adopt	O
the	O
weight	Method
initialization	Method
of	O
[	O
reference	O
]	O
.	O

In	O
all	O
ablation	O
comparisons	O
,	O
we	O
evaluate	O
the	O
error	Metric
on	O
the	O
single	O
224×224	O
center	O
crop	O
from	O
an	O
image	O
whose	O
shorter	O
side	O
is	O
256	O
.	O

Our	O
models	O
are	O
realized	O
by	O
the	O
form	O
of	O
Fig	O
.	O

3	O
(	O
c	O
)	O
.	O

We	O
perform	O
batch	Method
normalization	Method
(	O
BN	Method
)	O
[	O
reference	O
]	O
right	O
after	O
the	O
con	O
-	O
[	O
reference	O
]	O
The	O
marginally	O
smaller	O
number	O
of	O
parameters	O
and	O
marginally	O
higher	O
FLOPs	O
are	O
mainly	O
caused	O
by	O
the	O
blocks	O
where	O
the	O
map	O
sizes	O
change	O
.	O

volutions	O
in	O
Fig	O
.	O

3	O
(	O
c	O
)	O
.	O

[	O
reference	O
]	O
ReLU	Method
is	O
performed	O
right	O
after	O
each	O
BN	O
,	O
expect	O
for	O
the	O
output	O
of	O
the	O
block	O
where	O
ReLU	Method
is	O
performed	O
after	O
the	O
adding	O
to	O
the	O
shortcut	O
,	O
following	O
[	O
reference	O
]	O
.	O

We	O
note	O
that	O
the	O
three	O
forms	O
in	O
Fig	O
.	O

3	O
are	O
strictly	O
equivalent	O
,	O
when	O
BN	Method
and	O
ReLU	Method
are	O
appropriately	O
addressed	O
as	O
mentioned	O
above	O
.	O

We	O
have	O
trained	O
all	O
three	O
forms	O
and	O
obtained	O
the	O
same	O
results	O
.	O

We	O
choose	O
to	O
implement	O
by	O
Fig	O
.	O

3	O
(	O
c	O
)	O
because	O
it	O
is	O
more	O
succinct	O
and	O
faster	O
than	O
the	O
other	O
two	O
forms	O
.	O

section	O
:	O
Experiments	O
section	O
:	O
Experiments	O
on	O
ImageNet	Material
-	Material
1	Material
K	Material
We	O
conduct	O
ablation	O
experiments	O
on	O
the	O
1000	Material
-	Material
class	Material
ImageNet	Material
classification	Material
task	Material
[	O
reference	O
]	O
.	O

We	O
follow	O
[	O
reference	O
]	O
to	O
construct	O
50	Method
-	Method
layer	Method
and	O
101	Method
-	Method
layer	Method
residual	Method
networks	Method
.	O

We	O
simply	O
replace	O
all	O
blocks	O
in	O
ResNet	Method
-	O
50	O
/	O
101	O
with	O
our	O
blocks	O
.	O

Notations	O
.	O

Because	O
we	O
adopt	O
the	O
two	O
rules	O
in	O
Sec	O
.	O

3.1	O
,	O
it	O
is	O
sufficient	O
for	O
us	O
to	O
refer	O
to	O
an	O
architecture	O
by	O
the	O
template	O
.	O

For	O
example	O
,	O
Table	O
1	O
shows	O
a	O
ResNeXt	Method
-	O
50	O
constructed	O
by	O
a	O
template	O
with	O
cardinality	O
=	O
32	O
and	O
bottleneck	O
width	O
=	O
4d	O
(	O
Fig	O
.	O

3	O
)	O
.	O

This	O
network	O
is	O
denoted	O
as	O
ResNeXt	Method
-	O
50	O
(	O
32×4d	O
)	O
for	O
simplicity	O
.	O

We	O
note	O
that	O
the	O
input	O
/	O
output	O
width	O
of	O
the	O
template	O
is	O
fixed	O
as	O
256	O
-	O
d	O
(	O
Fig	O
.	O

3	O
)	O
,	O
and	O
all	O
widths	O
are	O
doubled	O
each	O
time	O
when	O
the	O
feature	O
map	O
is	O
subsampled	O
(	O
see	O
Table	O
1	O
)	O
.	O

Cardinality	O
vs.	O
Width	O
.	O

We	O
first	O
evaluate	O
the	O
trade	O
-	O
off	O
between	O
cardinality	O
C	O
and	O
bottleneck	O
width	O
,	O
under	O
preserved	O
complexity	Metric
as	O
listed	O
in	O
Table	O
2	O
.	O

Table	O
3	O
shows	O
the	O
results	O
and	O
Fig	O
.	O

5	O
shows	O
the	O
curves	O
of	O
error	Metric
vs.	O
epochs	O
.	O

Comparing	O
with	O
ResNet	Method
-	Method
50	Method
(	O
Table	O
3	O
top	O
and	O
Fig	O
.	O

5	O
left	O
)	O
,	O
the	O
32×4d	Method
ResNeXt	Method
-	Method
50	Method
has	O
a	O
validation	Metric
error	Metric
of	O
22.2	O
%	O
,	O
which	O
is	O
1.7	O
%	O
lower	O
than	O
the	O
ResNet	Method
baseline	O
's	O
23.9	O
%	O
.	O

With	O
cardinality	O
C	O
increasing	O
from	O
1	O
to	O
32	O
while	O
keeping	O
complexity	Metric
,	O
the	O
error	Metric
rate	Metric
keeps	O
reducing	O
.	O

Furthermore	O
,	O
the	O
32×4d	O
ResNeXt	Method
also	O
has	O
a	O
much	O
lower	O
training	Metric
error	Metric
than	O
the	O
ResNet	Method
counterpart	O
,	O
suggesting	O
that	O
the	O
gains	O
are	O
not	O
from	O
regularization	Method
but	O
from	O
stronger	O
representations	O
.	O

Similar	O
trends	O
are	O
observed	O
in	O
the	O
case	O
of	O
ResNet	Method
-	O
101	O
(	O
Fig	O
.	O

5	O
right	O
,	O
Table	O
3	O
bottom	O
)	O
,	O
where	O
the	O
32×4d	Method
ResNeXt	Method
-	Method
101	Method
outperforms	O
the	O
ResNet	Method
-	O
101	O
counterpart	O
by	O
0.8	O
%	O
.	O

Although	O
this	O
improvement	O
of	O
validation	Metric
error	Metric
is	O
smaller	O
than	O
that	O
of	O
the	O
50	Method
-	Method
layer	Method
case	O
,	O
the	O
improvement	O
of	O
training	Metric
error	Metric
is	O
still	O
big	O
(	O
20	O
%	O
for	O
ResNet	Method
-	Method
101	Method
and	O
16	O
%	O
for	O
32×4d	O
ResNeXt	Method
-	Method
101	Method
,	O
Fig	O
.	O

5	O
right	O
)	O
.	O

In	O
fact	O
,	O
more	O
training	O
data	O
will	O
enlarge	O
the	O
gap	O
of	O
validation	Metric
error	Metric
,	O
as	O
we	O
show	O
on	O
an	O
ImageNet	Material
-	Material
5	Material
K	Material
set	Material
in	O
the	O
next	O
subsection	O
.	O

Table	O
3	O
also	O
suggests	O
that	O
with	O
complexity	Metric
preserved	O
,	O
increasing	O
cardinality	O
at	O
the	O
price	O
of	O
reducing	O
width	O
starts	O
to	O
show	O
saturating	O
accuracy	Metric
when	O
the	O
bottleneck	O
width	O
is	O
[	O
reference	O
]	O
With	O
BN	O
,	O
for	O
the	O
equivalent	O
form	O
in	O
Fig	O
.	O

3	O
(	O
a	O
)	O
,	O
BN	Method
is	O
employed	O
after	O
aggregating	O
the	O
transformations	O
and	O
before	O
adding	O
to	O
the	O
shortcut	O
.	O

[	O
reference	O
]	O
.	O

(	O
ii	O
)	O
Going	O
wider	O
by	O
increasing	O
the	O
bottleneck	O
width	O
.	O

(	O
iii	O
)	O
Increasing	O
cardinality	O
by	O
doubling	O
C.	O
Table	O
4	O
shows	O
that	O
increasing	O
complexity	Metric
by	O
2×	O
consistently	O
reduces	O
error	Metric
vs.	O
the	O
ResNet	Method
-	O
101	O
baseline	O
(	O
22.0	O
%	O
)	O
.	O

But	O
the	O
improvement	O
is	O
small	O
when	O
going	O
deeper	O
(	O
ResNet	Method
-	O
200	O
,	O
by	O
0.3	O
%	O
)	O
or	O
wider	O
(	O
wider	O
ResNet	Method
-	O
101	O
,	O
by	O
0.7	O
%	O
)	O
.	O

On	O
the	O
contrary	O
,	O
increasing	O
cardinality	O
C	O
shows	O
much	O
better	O
results	O
than	O
going	O
deeper	O
or	O
wider	O
.	O

The	O
2×64d	O
ResNeXt	Method
-	Method
101	Method
(	O
i.e.	O
,	O
doubling	O
C	O
on	O
1×64d	O
ResNet	Method
-	O
101	O
baseline	O
and	O
keeping	O
the	O
width	O
)	O
reduces	O
the	O
top	Metric
-	Metric
1	Metric
error	Metric
by	O
1.3	O
%	O
to	O
20.7	O
%	O
.	O

The	O
64×4d	O
ResNeXt	Method
-	Method
101	Method
(	O
i.e.	O
,	O
doubling	O
C	O
on	O
32×4d	O
ResNeXt	Method
-	Method
101	Method
and	O
keeping	O
the	O
width	O
)	O
reduces	O
the	O
top	Metric
-	Metric
1	Metric
error	Metric
to	O
20.4	O
%	O
.	O

We	O
also	O
note	O
that	O
32×4d	O
ResNet	Method
-	O
101	O
(	O
21.2	O
%	O
)	O
performs	O
better	O
than	O
the	O
deeper	O
ResNet	Method
-	O
200	O
and	O
the	O
wider	O
ResNet	Method
-	O
101	O
,	O
even	O
though	O
it	O
has	O
only	O
∼50	O
%	O
complexity	Metric
.	O

This	O
again	O
shows	O
that	O
cardinality	O
is	O
a	O
more	O
effective	O
dimension	O
than	O
the	O
dimensions	O
of	O
depth	O
and	O
width	O
.	O

Removing	O
shortcuts	O
from	O
the	O
ResNeXt	Method
-	O
50	O
increases	O
the	O
error	Metric
by	O
3.9	O
points	O
to	O
26.1	O
%	O
.	O

Removing	O
shortcuts	O
from	O
its	O
ResNet	Method
-	O
50	O
counterpart	O
is	O
much	O
worse	O
(	O
31.2	O
%	O
)	O
.	O

These	O
comparisons	O
suggest	O
that	O
the	O
residual	O
connections	O
are	O
helpful	O
for	O
optimization	Task
,	O
whereas	O
aggregated	Method
transformations	Method
are	O
stronger	O
representations	O
,	O
as	O
shown	O
by	O
the	O
fact	O
that	O
they	O
perform	O
consistently	O
better	O
than	O
their	O
counterparts	O
with	O
or	O
without	O
residual	O
connections	O
.	O

Performance	O
.	O

For	O
simplicity	O
we	O
use	O
Torch	O
's	O
built	O
-	O
in	O
grouped	Method
convolution	Method
implementation	Method
,	O
without	O
special	O
optimization	O
.	O

We	O
note	O
that	O
this	O
implementation	O
was	O
brute	O
-	O
force	O
and	O
not	O
parallelization	O
-	O
friendly	O
.	O

On	O
8	O
GPUs	O
of	O
NVIDIA	Method
M40	Method
,	O
training	O
32×4d	O
ResNeXt	Method
-	O
101	O
in	O
Table	O
3	O
takes	O
0.95s	O
per	O
mini	O
-	O
batch	O
,	O
vs.	O
0.70s	O
of	O
ResNet	Method
-	O
101	O
baseline	O
that	O
has	O
similar	O
FLOPs	O
.	O

We	O
argue	O
that	O
this	O
is	O
a	O
reasonable	O
overhead	O
.	O

We	O
expect	O
carefully	O
engineered	O
lower	O
-	O
level	O
implementation	O
(	O
e.g.	O
,	O
in	O
CUDA	Method
)	O
will	O
reduce	O
this	O
overhead	O
.	O

We	O
also	O
expect	O
that	O
the	O
inference	Metric
time	Metric
on	O
CPUs	O
will	O
present	O
less	O
overhead	O
.	O

Training	O
the	O
2×complexity	Method
model	Method
(	O
64×4d	O
ResNeXt	Method
-	O
101	O
)	O
takes	O
1.7s	O
per	O
mini	O
-	O
batch	O
and	O
10	O
days	O
total	O
on	O
8	O
GPUs	O
.	O

Comparisons	O
with	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
results	O
.	O

Table	O
5	O
shows	O
more	O
results	O
of	O
single	Task
-	Task
crop	Task
testing	Task
on	O
the	O
ImageNet	Material
validation	Material
set	Material
.	O

In	O
addition	O
to	O
testing	O
a	O
224×224	O
crop	O
,	O
we	O
also	O
evaluate	O
a	O
320×320	O
crop	O
following	O
[	O
reference	O
]	O
.	O

Our	O
results	O
compare	O
favorably	O
with	O
ResNet	Method
,	O
Inception	Method
-	Method
v3	Method
/	Method
v4	Method
,	O
and	O
Inception	O
-	O
ResNet	Method
-	O
v2	O
,	O
achieving	O
a	O
single	O
-	O
crop	O
top	Metric
-	Metric
5	Metric
error	Metric
rate	Metric
of	O
4.4	O
%	O
.	O

In	O
addition	O
,	O
our	O
architecture	Method
design	Method
is	O
much	O
simpler	O
than	O
all	O
Inception	Method
models	Method
,	O
and	O
requires	O
considerably	O
fewer	O
hyper	O
-	O
parameters	O
to	O
be	O
set	O
by	O
hand	O
.	O

ResNeXt	Method
is	O
the	O
foundation	O
of	O
our	O
entries	O
to	O
the	O
ILSVRC	Task
2016	Task
classification	Task
task	Task
,	O
in	O
which	O
we	O
achieved	O
2	O
nd	O
place	O
.	O

We	O
note	O
that	O
many	O
models	O
(	O
including	O
ours	O
)	O
start	O
to	O
get	O
saturated	O
on	O
this	O
dataset	O
after	O
using	O
multi	Method
-	Method
scale	Method
and	Method
/	Method
or	Method
multicrop	Method
testing	Method
.	O

We	O
had	O
a	O
single	O
-	O
model	O
top	O
-	O
1	O
/	O
top	Metric
-	Metric
5	Metric
error	Metric
rates	Metric
of	O
17.7%	O
/	O
3.7	O
%	O
using	O
the	O
multi	O
-	O
scale	O
dense	O
testing	O
in	O
[	O
reference	O
]	O
,	O
on	O
par	O
with	O
Inception	O
-	O
ResNet	Method
-	O
v2	O
's	O
single	O
-	O
model	O
results	O
of	O
17.8%	O
/	O
3.7	O
%	O
that	O
adopts	O
multi	Method
-	Method
scale	Method
,	Method
multi	Method
-	Method
crop	Method
testing	Method
.	O

We	O
had	O
an	O
ensemble	O
result	O
of	O
3.03	O
%	O
top	Metric
-	Metric
5	Metric
error	Metric
on	O
the	O
test	O
set	O
,	O
on	O
par	O
with	O
the	O
winner	O
's	O
2.99	O
%	O
and	O
Inception	O
-	O
v4	O
/	O
InceptionResNet	O
-	O
v2	O
's	O
3.08	O
%	O
[	O
reference	O
]	O
.	O

section	O
:	O
224×224	O
320×320	O
/	O
299×299	O
Table	O
5	O
.	O

State	O
-	O
of	O
-	O
the	O
-	O
art	O
models	O
on	O
the	O
ImageNet	Material
-	Material
1	Material
K	Material
validation	O
set	O
(	O
single	Task
-	Task
crop	Task
testing	Task
)	O
.	O

The	O
test	O
size	O
of	O
ResNet	Method
/	O
ResNeXt	Method
is	O
224×224	O
and	O
320×320	O
as	O
in	O
[	O
reference	O
]	O
and	O
of	O
the	O
Inception	Method
models	Method
is	O
299×299	O
.	O

Table	O
6	O
.	O

Error	Metric
(	O
%	O
)	O
on	O
ImageNet	Material
-	Material
5K.	Material
The	O
models	O
are	O
trained	O
on	O
ImageNet	Material
-	Material
5	Material
K	Material
and	O
tested	O
on	O
the	O
ImageNet	Material
-	Material
1	Material
K	Material
val	O
set	O
,	O
treated	O
as	O
a	O
5	O
K	Task
-	Task
way	Task
classification	Task
task	Task
or	O
a	O
1	O
K	Task
-	Task
way	Task
classification	Task
task	Task
at	O
test	O
time	O
.	O

ResNeXt	Method
and	O
its	O
ResNet	Method
counterpart	O
have	O
similar	O
complexity	Metric
.	O

The	O
error	O
is	O
evaluated	O
on	O
the	O
single	O
crop	O
of	O
224×224	O
pixels	O
.	O

section	O
:	O
Experiments	O
on	O
ImageNet	Material
-	Material
5	Material
K	Material
The	O
performance	O
on	O
ImageNet	Material
-	Material
1	Material
K	Material
appears	O
to	O
saturate	O
.	O

But	O
we	O
argue	O
that	O
this	O
is	O
not	O
because	O
of	O
the	O
capability	O
of	O
the	O
models	O
but	O
because	O
of	O
the	O
complexity	Metric
of	O
the	O
dataset	O
.	O

Next	O
we	O
evaluate	O
our	O
models	O
on	O
a	O
larger	O
ImageNet	Material
subset	Material
that	O
has	O
5000	O
categories	O
.	O

Our	O
5	Material
K	Material
dataset	Material
is	O
a	O
subset	O
of	O
the	O
full	Material
ImageNet	Material
-	Material
22	Material
K	Material
set	Material
[	O
reference	O
]	O
.	O

The	O
5000	O
categories	O
consist	O
of	O
the	O
original	O
ImageNet	Material
-	Material
1	Material
K	Material
categories	O
and	O
additional	O
4000	O
categories	O
that	O
have	O
the	O
largest	O
number	O
of	O
images	O
in	O
the	O
full	O
ImageNet	Material
set	Material
.	O

The	O
5	O
K	O
set	O
has	O
6.8	O
million	O
images	O
,	O
about	O
5×	O
of	O
the	O
1	O
K	O
set	O
.	O

There	O
is	O
no	O
official	O
train	O
/	O
val	O
split	O
available	O
,	O
so	O
we	O
opt	O
to	O
evaluate	O
on	O
the	O
original	O
ImageNet	Material
-	Material
1	Material
K	Material
validation	O
set	O
.	O

On	O
this	O
1	O
K	O
-	O
class	O
val	O
set	O
,	O
the	O
models	O
can	O
be	O
evaluated	O
as	O
a	O
5	O
K	Task
-	Task
way	Task
classification	Task
task	Task
(	O
all	O
labels	O
predicted	O
to	O
be	O
the	O
other	O
4	O
K	O
classes	O
are	O
automatically	O
erroneous	O
)	O
or	O
as	O
a	O
1	O
K	O
-	O
way	O
classification	Task
task	Task
(	O
softmax	Method
is	O
applied	O
only	O
on	O
the	O
1	O
K	O
classes	O
)	O
at	O
test	O
time	O
.	O

The	O
implementation	O
details	O
are	O
the	O
same	O
as	O
in	O
Sec	O
.	O

4	O
.	O

The	O
5	Method
K	Method
-	Method
training	Method
models	Method
are	O
all	O
trained	O
from	O
scratch	O
,	O
and	O
#	O
params	O
CIFAR	O
-	O
10	O
CIFAR	O
-	O
100	O
Wide	O
ResNet	Method
[	O
reference	O
]	O
36	O
are	O
trained	O
for	O
the	O
same	O
number	O
of	O
mini	O
-	O
batches	O
as	O
the	O
1	Method
K	Method
-	Method
training	Method
models	Method
(	O
so	O
1	O
/	O
5×	O
epochs	O
)	O
.	O

Table	O
6	O
and	O
Fig	O
.	O

6	O
show	O
the	O
comparisons	O
under	O
preserved	O
complexity	Metric
.	O

ResNeXt	Method
-	Method
50	Method
reduces	O
the	O
5	O
K	O
-	O
way	O
top	Metric
-	Metric
1	Metric
error	Metric
by	O
3.2	O
%	O
comparing	O
with	O
ResNet	Method
-	Method
50	Method
,	O
and	O
ResNetXt	Method
-	Method
101	Method
reduces	O
the	O
5	Metric
K	Metric
-	Metric
way	Metric
top	Metric
-	Metric
1	Metric
error	Metric
by	O
2.3	O
%	O
comparing	O
with	O
ResNet	Method
-	Method
101	Method
.	O

Similar	O
gaps	O
are	O
observed	O
on	O
the	O
1	Metric
K	Metric
-	Metric
way	Metric
error	Metric
.	O

These	O
demonstrate	O
the	O
stronger	O
representational	O
power	O
of	O
ResNeXt	Method
.	O

Moreover	O
,	O
we	O
find	O
that	O
the	O
models	O
trained	O
on	O
the	O
5	O
K	O
set	O
(	O
with	O
1	Metric
K	Metric
-	Metric
way	Metric
error	Metric
22.2%	O
/	O
5.7	O
%	O
in	O
Table	O
6	O
)	O
perform	O
competitively	O
comparing	O
with	O
those	O
trained	O
on	O
the	O
1	O
K	O
set	O
(	O
21.2%	O
/	O
5.6	O
%	O
in	O
Table	O
3	O
)	O
,	O
evaluated	O
on	O
the	O
same	O
1	O
K	O
-	O
way	O
classification	Task
task	Task
on	O
the	O
validation	O
set	O
.	O

This	O
result	O
is	O
achieved	O
without	O
increasing	O
the	O
training	Metric
time	Metric
(	O
due	O
to	O
the	O
same	O
number	O
of	O
mini	O
-	O
batches	O
)	O
and	O
without	O
fine	Method
-	Method
tuning	Method
.	O

We	O
argue	O
that	O
this	O
is	O
a	O
promising	O
result	O
,	O
given	O
that	O
the	O
training	Task
task	Task
of	O
classifying	Task
5	Task
K	Task
categories	Task
is	O
a	O
more	O
challenging	O
one	O
.	O

section	O
:	O
Experiments	O
on	O
CIFAR	O
We	O
conduct	O
more	O
experiments	O
on	O
CIFAR	O
-	O
10	O
and	O
100	O
datasets	O
[	O
reference	O
]	O
.	O

We	O
use	O
the	O
architectures	O
as	O
in	O
[	O
reference	O
]	O
and	O
replace	O
the	O
basic	O
residual	O
block	O
by	O
the	O
bottleneck	O
template	O
Our	O
networks	O
start	O
with	O
a	O
single	O
3×3	Method
conv	Method
layer	Method
,	O
followed	O
by	O
3	O
stages	O
each	O
having	O
3	O
residual	O
blocks	O
,	O
and	O
end	O
with	O
average	Method
pooling	Method
and	O
a	O
fully	Method
-	Method
connected	Method
classifier	Method
(	O
total	O
29	O
-	O
layer	O
deep	O
)	O
,	O
following	O
[	O
reference	O
]	O
.	O

We	O
adopt	O
the	O
same	O
translation	Method
and	Method
flipping	Method
data	Method
augmentation	Method
as	O
[	O
reference	O
]	O
.	O

Implementation	O
details	O
are	O
in	O
the	O
appendix	O
.	O

We	O
compare	O
two	O
cases	O
of	O
increasing	O
complexity	Metric
based	O
on	O
the	O
above	O
baseline	O
:	O
(	O
i	O
)	O
increase	O
cardinality	O
and	O
fix	O
all	O
widths	O
,	O
or	O
(	O
ii	O
)	O
increase	O
width	O
of	O
the	O
bottleneck	O
and	O
fix	O
cardinality	O
=	O
1	O
.	O

We	O
train	O
and	O
evaluate	O
a	O
series	O
of	O
networks	O
under	O
these	O
changes	O
.	O

Fig	O
.	O

7	O
shows	O
the	O
comparisons	O
of	O
test	Metric
error	Metric
rates	Metric
vs.	O
model	Metric
sizes	Metric
.	O

We	O
find	O
that	O
increasing	O
cardinality	O
is	O
more	O
effective	O
than	O
increasing	O
width	O
,	O
consistent	O
to	O
what	O
we	O
have	O
observed	O
on	O
ImageNet	Material
-	Material
1K.	Material
Table	O
7	O
shows	O
the	O
results	O
and	O
model	O
sizes	O
,	O
comparing	O
with	O
the	O
Wide	O
ResNet	Method
[	O
reference	O
]	O
which	O
is	O
the	O
best	O
published	O
record	O
.	O

Our	O
model	O
with	O
a	O
similar	O
model	O
size	O
(	O
34.4	O
M	O
)	O
shows	O
results	O
better	O
than	O
Wide	Method
ResNet	Method
.	O

Our	O
larger	O
method	O
achieves	O
3.58	O
%	O
test	Metric
error	Metric
(	O
average	O
of	O
10	O
runs	O
)	O
on	O
CIFAR	O
-	O
10	O
and	O
17.31	O
%	O
on	O
CIFAR	O
-	O
100	O
.	O

To	O
the	O
best	O
of	O
our	O
knowledge	O
,	O
these	O
are	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
results	O
(	O
with	O
similar	O
data	O
augmentation	O
)	O
in	O
the	O
literature	O
including	O
unpublished	O
technical	O
reports	O
.	O

section	O
:	O
Experiments	O
on	O
COCO	O
object	O
detection	O
Next	O
we	O
evaluate	O
the	O
generalizability	O
on	O
the	O
COCO	O
object	O
detection	O
set	O
[	O
reference	O
]	O
.	O

We	O
train	O
the	O
models	O
on	O
the	O
80k	O
training	O
set	O
plus	O
a	O
35k	O
val	O
subset	O
and	O
evaluate	O
on	O
a	O
5k	O
val	O
subset	O
(	O
called	O
minival	Method
)	O
,	O
following	O
[	O
reference	O
]	O
.	O

We	O
evaluate	O
the	O
COCOstyle	Metric
Average	Metric
Precision	Metric
(	Metric
AP	Metric
)	O
as	O
well	O
as	O
AP@IoU=0.5	Metric
[	O
reference	O
]	O
.	O

We	O
adopt	O
the	O
basic	O
Faster	Method
R	Method
-	Method
CNN	Method
[	O
reference	O
]	O
and	O
follow	O
[	O
reference	O
]	O
to	O
plug	O
ResNet	Method
/	O
ResNeXt	Method
into	O
it	O
.	O

The	O
models	O
are	O
pre	O
-	O
trained	O
on	O
ImageNet	Material
-	Material
1	Material
K	Material
and	O
fine	O
-	O
tuned	O
on	O
the	O
detection	Task
set	Task
.	O

Implementation	O
details	O
are	O
in	O
the	O
appendix	O
.	O

Table	O
8	O
shows	O
the	O
comparisons	O
.	O

On	O
the	O
50	Method
-	Method
layer	Method
baseline	O
,	O
ResNeXt	Method
improves	O
AP@0.5	Metric
by	O
2.1	O
%	O
and	O
AP	Metric
by	O
1.0	O
%	O
,	O
without	O
increasing	O
complexity	Metric
.	O

ResNeXt	Method
shows	O
smaller	O
improvements	O
on	O
the	O
101	O
-	O
layer	O
baseline	O
.	O

We	O
conjecture	O
that	O
more	O
training	O
data	O
will	O
lead	O
to	O
a	O
larger	O
gap	O
,	O
as	O
observed	O
on	O
the	O
ImageNet	Material
-	Material
5	Material
K	Material
set	Material
.	O

It	O
is	O
also	O
worth	O
noting	O
that	O
recently	O
ResNeXt	Method
has	O
been	O
adopted	O
in	O
Mask	Method
R	Method
-	Method
CNN	Method
[	O
reference	O
]	O
that	O
achieves	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
results	O
on	O
COCO	Task
instance	Task
segmentation	Task
and	O
object	Task
detection	Task
tasks	Task
.	O

section	O
:	O
A.	O
Implementation	O
Details	O
:	O
CIFAR	O
We	O
train	O
the	O
models	O
on	O
the	O
50k	O
training	O
set	O
and	O
evaluate	O
on	O
the	O
10k	O
test	O
set	O
.	O

The	O
input	O
image	O
is	O
32×32	O
randomly	O
cropped	O
from	O
a	O
zero	O
-	O
padded	O
40×40	O
image	O
or	O
its	O
flipping	O
,	O
following	O
[	O
reference	O
]	O
.	O

No	O
other	O
data	Method
augmentation	Method
is	O
used	O
.	O

The	O
first	O
layer	O
is	O
3×3	O
conv	O
with	O
64	O
filters	O
.	O

There	O
are	O
3	O
stages	O
each	O
having	O
3	O
residual	O
blocks	O
,	O
and	O
the	O
output	O
map	O
size	O
is	O
32	O
,	O
16	O
,	O
and	O
8	O
for	O
each	O
stage	O
[	O
reference	O
]	O
.	O

The	O
network	O
ends	O
with	O
a	O
global	Method
average	Method
pooling	Method
and	O
a	O
fully	Method
-	Method
connected	Method
layer	Method
.	O

Width	O
is	O
increased	O
by	O
2×	O
when	O
the	O
stage	O
changes	O
(	O
downsampling	O
)	O
,	O
as	O
in	O
Sec	O
.	O

3.1	O
.	O

The	O
models	O
are	O
trained	O
on	O
8	O
GPUs	Method
with	O
a	O
mini	O
-	O
batch	O
size	O
of	O
128	O
,	O
with	O
a	O
weight	O
decay	O
of	O
0.0005	O
and	O
a	O
momentum	O
of	O
0.9	O
.	O

We	O
start	O
with	O
a	O
learning	Metric
rate	Metric
of	O
0.1	O
and	O
train	O
the	O
models	O
for	O
300	O
epochs	O
,	O
reducing	O
the	O
learning	Metric
rate	Metric
at	O
the	O
150	O
-	O
th	O
and	O
225	O
-	O
th	O
epoch	O
.	O

Other	O
implementation	O
details	O
are	O
as	O
in	O
[	O
reference	O
]	O
.	O

section	O
:	O
B.	O
Implementation	O
Details	O
:	O
Object	Task
Detection	Task
We	O
adopt	O
the	O
Faster	O
R	Method
-	Method
CNN	Method
system	Method
[	O
reference	O
]	O
.	O

For	O
simplicity	O
we	O
do	O
not	O
share	O
the	O
features	O
between	O
RPN	Method
and	O
Fast	Method
R	Method
-	Method
CNN	Method
.	O

In	O
the	O
RPN	Method
step	Method
,	O
we	O
train	O
on	O
8	O
GPUs	Method
with	O
each	O
GPU	O
holding	O
2	O
images	O
per	O
mini	O
-	O
batch	O
and	O
256	O
anchors	O
per	O
image	O
.	O

We	O
train	O
the	O
RPN	Method
step	Method
for	O
120k	O
mini	O
-	O
batches	O
at	O
a	O
learning	Metric
rate	Metric
of	O
0.02	O
and	O
next	O
60k	O
at	O
0.002	O
.	O

In	O
the	O
Fast	Task
R	Task
-	Task
CNN	Task
step	Task
,	O
we	O
train	O
on	O
8	O
GPUs	Method
with	O
each	O
GPU	O
holding	O
1	O
image	O
and	O
64	O
regions	O
per	O
mini	O
-	O
batch	O
.	O

We	O
train	O
the	O
Fast	Method
R	Method
-	Method
CNN	Method
step	Method
for	O
120k	O
mini	O
-	O
batches	O
at	O
a	O
learning	Metric
rate	Metric
of	O
0.005	O
and	O
next	O
60k	O
at	O
0.0005	O
,	O
We	O
use	O
a	O
weight	O
decay	O
of	O
0.0001	O
and	O
a	O
momentum	O
of	O
0.9	O
.	O

Other	O
implementation	O
details	O
are	O
as	O
in	O
https:	O
//	O
github.com	O
/	O
rbgirshick	O
/	O
py	O
-	O
faster	O
-	O
rcnn	O
.	O

section	O
:	O
section	O
:	O
Acknowledgment	O
S.X.	O
and	O
Z.T.	O
's	O
research	O
was	O
partly	O
supported	O
by	O
NSF	O
IIS	O
-	O
1618477	O
.	O

The	O
authors	O
would	O
like	O
to	O
thank	O
Tsung	O
-	O
Yi	O
Lin	O
and	O
Priya	O
Goyal	O
for	O
valuable	O
discussions	O
.	O

section	O
:	O
