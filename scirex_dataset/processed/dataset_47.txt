Machine	Task
reading	Task
comprehension	Task
(	O
MRC	Task
)	O
on	O
real	O
web	O
data	O
usually	O
requires	O
the	O
machine	O
to	O
answer	Task
a	Task
question	Task
by	O
analyzing	O
multiple	O
passages	O
retrieved	O
by	O
search	Method
engine	Method
.	O

Compared	O
with	O
MRC	Task
on	O
a	O
single	O
passage	O
,	O
multi	Task
-	Task
passage	Task
MRC	Task
is	O
more	O
challenging	O
,	O
since	O
we	O
are	O
likely	O
to	O
get	O
multiple	O
confusing	O
answer	O
candidates	O
from	O
different	O
passages	O
.	O

To	O
address	O
this	O
problem	O
,	O
we	O
propose	O
an	O
end	Method
-	Method
to	Method
-	Method
end	Method
neural	Method
model	Method
that	O
enables	O
those	O
answer	O
candidates	O
from	O
different	O
passages	O
to	O
verify	O
each	O
other	O
based	O
on	O
their	O
content	Method
representations	O
.	O

Specifically	O
,	O
we	O
jointly	O
train	O
three	O
modules	O
that	O
can	O
predict	O
the	O
final	O
answer	O
based	O
on	O
three	O
factors	O
:	O
the	O
answer	O
boundary	O
,	O
the	O
answer	O
content	Method
and	O
the	O
cross	Task
-	Task
passage	Task
answer	Task
verification	Task
.	O

The	O
experimental	O
results	O
show	O
that	O
our	O
method	O
outperforms	O
the	O
baseline	O
by	O
a	O
large	O
margin	O
and	O
achieves	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
performance	O
on	O
the	O
English	Material
MS	Material
-	Material
MARCO	Material
dataset	Material
and	O
the	O
Chinese	O
DuReader	O
dataset	O
,	O
both	O
of	O
which	O
are	O
designed	O
for	O
MRC	Task
in	O
real	Task
-	Task
world	Task
settings	Task
.	O

Multi	O
-	O
PassageMachineReadingComprehension	O
withCross	O
-	O
PassageAnswerVerification	O
[	O
1*	O
]	O
YizhongWang	O
*	O
ThisworkwasdonewhilethefirstauthorwasdoinginternshipatBaiduInc.	O
[	O
2	O
]	O
KaiLiu	O
[	O
2	O
]	O
JingLiu	O
[	O
2	O
]	O
WeiHe	O
[	O
2	O
]	O
YajuanLyu	O
[	O
2	O
]	O
HuaWu	O
[	O
1	O
]	O
SujianLi	O
[	O
2	O
]	O
HaifengWang	O
[	O
1	O
]	O
KeyLaboratoryofComputationalLinguistics	O
,	O
PekingUniversity	O
,	O
MOE	O
,	O
China	O
[	O
2	O
]	O
BaiduInc.	O
,	O
Beijing	O
,	O
China	O
[	O
]	O
{	O
yizhong	O
,	O
lisujian	O
}	O
@pku.edu.cn	O
,	O
{	O
liukai20	O
,	O
liujing46	O
,	O
[	O
]	O
hewei06	O
,	O
lvyajuan	O
,	O
wu_hua	O
,	O
wanghaifeng	O
}	O
@baidu.com	O
section	O
:	O
Introduction	O
Machine	Task
reading	Task
comprehension	Task
(	O
MRC	Task
)	O
,	O
empowering	O
computers	O
with	O
the	O
ability	O
to	O
acquire	O
knowledge	O
and	O
answer	O
questions	O
from	O
textual	O
data	O
,	O
is	O
believed	O
to	O
be	O
a	O
crucial	O
step	O
in	O
building	O
a	O
general	O
intelligent	Method
agent	Method
.	O

Recent	O
years	O
have	O
seen	O
rapid	O
growth	O
in	O
the	O
MRC	Task
community	Task
.	O

With	O
the	O
release	O
of	O
various	O
datasets	O
,	O
the	O
MRC	Task
task	Task
has	O
evolved	O
from	O
the	O
early	O
cloze	O
-	O
style	O
test	O
to	O
answer	Task
extraction	Task
from	O
a	O
single	O
passage	O
and	O
to	O
the	O
latest	O
more	O
complex	O
question	Task
answering	Task
on	O
web	O
data	O
.	O

Great	O
efforts	O
have	O
also	O
been	O
made	O
to	O
develop	O
models	O
for	O
these	O
MRC	Task
tasks	Task
,	O
especially	O
for	O
the	O
answer	Task
extraction	Task
on	O
single	O
passage	O
.	O

A	O
significant	O
milestone	O
is	O
that	O
several	O
MRC	Method
models	Method
have	O
exceeded	O
the	O
performance	O
of	O
human	O
annotators	O
on	O
the	O
SQuAD	O
dataset	O
.	O

However	O
,	O
this	O
success	O
on	O
single	O
Wikipedia	O
passage	O
is	O
still	O
not	O
adequate	O
,	O
considering	O
the	O
ultimate	O
goal	O
of	O
reading	O
the	O
whole	O
web	O
.	O

Therefore	O
,	O
several	O
latest	O
datasets	O
attempt	O
to	O
design	O
the	O
MRC	Task
tasks	Task
in	O
more	O
realistic	O
settings	O
by	O
involving	O
search	Method
engines	Method
.	O

For	O
each	O
question	O
,	O
they	O
use	O
the	O
search	Method
engine	Method
to	O
retrieve	O
multiple	O
passages	O
and	O
the	O
MRC	Method
models	Method
are	O
required	O
to	O
read	O
these	O
passages	O
in	O
order	O
to	O
give	O
the	O
final	O
answer	O
.	O

One	O
of	O
the	O
intrinsic	O
challenges	O
for	O
such	O
multi	Task
-	Task
passage	Task
MRC	Task
is	O
that	O
since	O
all	O
the	O
passages	O
are	O
question	O
-	O
related	O
but	O
usually	O
independently	O
written	O
,	O
it	O
’s	O
probable	O
that	O
multiple	O
confusing	O
answer	O
candidates	O
(	O
correct	O
or	O
incorrect	O
)	O
exist	O
.	O

Table	O
[	O
reference	O
]	O
shows	O
an	O
example	O
from	O
MS	Material
-	Material
MARCO	Material
.	O

We	O
can	O
see	O
that	O
all	O
the	O
answer	O
candidates	O
have	O
semantic	O
matching	O
with	O
the	O
question	O
while	O
they	O
are	O
literally	O
different	O
and	O
some	O
of	O
them	O
are	O
even	O
incorrect	O
.	O

As	O
is	O
shown	O
by	O
adversarial	O
-	O
examples	O
,	O
these	O
confusing	O
answer	O
candidates	O
could	O
be	O
quite	O
difficult	O
for	O
MRC	Method
models	Method
to	O
distinguish	O
.	O

Therefore	O
,	O
special	O
consideration	O
is	O
required	O
for	O
such	O
multi	Task
-	Task
passage	Task
MRC	Task
problem	Task
.	O

In	O
this	O
paper	O
,	O
we	O
propose	O
to	O
leverage	O
the	O
answer	O
candidates	O
from	O
different	O
passages	O
to	O
verify	O
the	O
final	O
correct	O
answer	O
and	O
rule	O
out	O
the	O
noisy	O
incorrect	O
answers	O
.	O

Our	O
hypothesis	O
is	O
that	O
the	O
correct	O
answers	O
could	O
occur	O
more	O
frequently	O
in	O
those	O
passages	O
and	O
usually	O
share	O
some	O
commonalities	O
,	O
while	O
incorrect	O
answers	O
are	O
usually	O
different	O
from	O
one	O
another	O
.	O

The	O
example	O
in	O
Table	O
[	O
reference	O
]	O
demonstrates	O
this	O
phenomenon	O
.	O

We	O
can	O
see	O
that	O
the	O
answer	O
candidates	O
extracted	O
from	O
the	O
last	O
four	O
passages	O
are	O
all	O
valid	O
answers	O
to	O
the	O
question	O
and	O
they	O
are	O
semantically	O
similar	O
to	O
each	O
other	O
,	O
while	O
the	O
answer	O
candidates	O
from	O
the	O
other	O
two	O
passages	O
are	O
incorrect	O
and	O
there	O
is	O
no	O
supportive	O
information	O
from	O
other	O
passages	O
.	O

As	O
human	O
beings	O
usually	O
compare	O
the	O
answer	O
candidates	O
from	O
different	O
sources	O
to	O
deduce	O
the	O
final	O
answer	O
,	O
we	O
hope	O
that	O
MRC	Method
model	Method
can	O
also	O
benefit	O
from	O
the	O
cross	Task
-	Task
passage	Task
answer	Task
verification	Task
process	Task
.	O

The	O
overall	O
framework	O
of	O
our	O
model	O
is	O
demonstrated	O
in	O
Figure	O
[	O
reference	O
]	O
,	O
which	O
consists	O
of	O
three	O
modules	O
.	O

First	O
,	O
we	O
follow	O
the	O
boundary	Method
-	Method
based	Method
MRC	Method
models	Method
to	O
find	O
an	O
answer	O
candidate	O
for	O
each	O
passage	O
by	O
identifying	O
the	O
start	O
and	O
end	O
position	O
of	O
the	O
answer	O
(	O
Figure	O
[	O
reference	O
]	O
)	O
.	O

Second	O
,	O
we	O
model	O
the	O
meanings	O
of	O
the	O
answer	O
candidates	O
extracted	O
from	O
those	O
passages	O
and	O
use	O
the	O
content	Method
scores	O
to	O
measure	O
the	O
quality	O
of	O
the	O
candidates	O
from	O
a	O
second	O
perspective	O
.	O

Third	O
,	O
we	O
conduct	O
the	O
answer	Task
verification	Task
by	O
enabling	O
each	O
answer	O
candidate	O
to	O
attend	O
to	O
the	O
other	O
candidates	O
based	O
on	O
their	O
representations	O
.	O

We	O
hope	O
that	O
the	O
answer	O
candidates	O
can	O
collect	O
supportive	O
information	O
from	O
each	O
other	O
according	O
to	O
their	O
semantic	O
similarities	O
and	O
further	O
decide	O
whether	O
each	O
candidate	O
is	O
correct	O
or	O
not	O
.	O

Therefore	O
,	O
the	O
final	O
answer	O
is	O
determined	O
by	O
three	O
factors	O
:	O
the	O
boundary	O
,	O
the	O
content	Method
and	O
the	O
cross	Task
-	Task
passage	Task
answer	Task
verification	Task
.	O

The	O
three	O
steps	O
are	O
modeled	O
using	O
different	O
modules	O
,	O
which	O
can	O
be	O
jointly	O
trained	O
in	O
our	O
end	Method
-	Method
to	Method
-	Method
end	Method
framework	Method
.	O

We	O
conduct	O
extensive	O
experiments	O
on	O
the	O
MS	Material
-	Material
MARCO	Material
and	O
DuReader	O
datasets	O
.	O

The	O
results	O
show	O
that	O
our	O
answer	Method
verification	Method
MRC	Method
model	Method
outperforms	O
the	O
baseline	O
models	O
by	O
a	O
large	O
margin	O
and	O
achieves	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
performance	O
on	O
both	O
datasets	O
.	O

section	O
:	O
Our	O
Approach	O
Figure	O
[	O
reference	O
]	O
gives	O
an	O
overview	O
of	O
our	O
multi	Method
-	Method
passage	Method
MRC	Method
model	Method
which	O
is	O
mainly	O
composed	O
of	O
three	O
modules	O
including	O
answer	Task
boundary	Task
prediction	Task
,	O
answer	O
content	Method
modeling	O
and	O
answer	Task
verification	Task
.	O

First	O
of	O
all	O
,	O
we	O
need	O
to	O
model	O
the	O
question	O
and	O
passages	O
.	O

Following	O
bidaf	Method
,	O
we	O
compute	O
the	O
question	Method
-	Method
aware	Method
representation	Method
for	O
each	O
passage	O
(	O
Section	O
[	O
reference	O
]	O
)	O
.	O

Based	O
on	O
this	O
representation	O
,	O
we	O
employ	O
a	O
Pointer	Method
Network	Method
to	O
predict	O
the	O
start	O
and	O
end	O
position	O
of	O
the	O
answer	O
in	O
the	O
module	O
of	O
answer	Task
boundary	Task
prediction	Task
(	O
Section	O
[	O
reference	O
]	O
)	O
.	O

At	O
the	O
same	O
time	O
,	O
with	O
the	O
answer	O
content	Method
model	O
(	O
Section	O
[	O
reference	O
]	O
)	O
,	O
we	O
estimate	O
whether	O
each	O
word	O
should	O
be	O
included	O
in	O
the	O
answer	O
and	O
thus	O
obtain	O
the	O
answer	Method
representations	Method
.	O

Next	O
,	O
in	O
the	O
answer	Method
verification	Method
module	Method
(	O
Section	O
[	O
reference	O
]	O
)	O
,	O
each	O
answer	O
candidate	O
can	O
attend	O
to	O
the	O
other	O
answer	O
candidates	O
to	O
collect	O
supportive	O
information	O
and	O
we	O
compute	O
one	O
score	O
for	O
each	O
candidate	O
to	O
indicate	O
whether	O
it	O
is	O
correct	O
or	O
not	O
according	O
to	O
the	O
verification	Task
.	O

The	O
final	O
answer	O
is	O
determined	O
by	O
not	O
only	O
the	O
boundary	O
but	O
also	O
the	O
answer	O
content	Method
and	O
its	O
verification	Metric
score	Metric
(	O
Section	O
[	O
reference	O
]	O
)	O
.	O

subsection	O
:	O
Question	Method
and	O
Passage	Method
Modeling	Method
Given	O
a	O
question	O
and	O
a	O
set	O
of	O
passages	O
retrieved	O
by	O
search	Method
engines	Method
,	O
our	O
task	O
is	O
to	O
find	O
the	O
best	O
concise	O
answer	O
to	O
the	O
question	O
.	O

First	O
,	O
we	O
formally	O
present	O
the	O
details	O
of	O
modeling	O
the	O
question	Method
and	O
passages	Method
.	O

paragraph	O
:	O
Encoding	Task
We	O
first	O
map	O
each	O
word	O
into	O
the	O
vector	O
space	O
by	O
concatenating	O
its	O
word	Method
embedding	Method
and	O
sum	O
of	O
its	O
character	Method
embeddings	Method
.	O

Then	O
we	O
employ	O
bi	Method
-	Method
directional	Method
LSTMs	Method
(	O
BiLSTM	Method
)	O
to	O
encode	O
the	O
question	O
and	O
passages	O
as	O
follows	O
:	O
where	O
,	O
,	O
,	O
are	O
the	O
word	O
-	O
level	O
and	O
character	O
-	O
level	O
embeddings	O
of	O
the	O
word	O
.	O

and	O
are	O
the	O
encoding	O
vectors	O
of	O
the	O
words	O
in	O
and	O
respectively	O
.	O

Unlike	O
previous	O
work	O
that	O
simply	O
concatenates	O
all	O
the	O
passages	O
,	O
we	O
process	O
the	O
passages	O
independently	O
at	O
the	O
encoding	Method
and	O
matching	Method
steps	Method
.	O

paragraph	O
:	O
Q	Method
-	Method
P	Method
Matching	Method
One	O
essential	O
step	O
in	O
MRC	Task
is	O
to	O
match	O
the	O
question	O
with	O
passages	O
so	O
that	O
important	O
information	O
can	O
be	O
highlighted	O
.	O

We	O
use	O
the	O
Attention	Method
Flow	Method
Layer	Method
to	O
conduct	O
the	O
Q	Task
-	Task
P	Task
matching	Task
in	O
two	O
directions	O
.	O

The	O
similarity	O
matrix	O
between	O
the	O
question	O
and	O
passage	O
is	O
changed	O
to	O
a	O
simpler	O
version	O
,	O
where	O
the	O
similarity	O
between	O
the	O
word	O
in	O
the	O
question	O
and	O
the	O
word	O
in	O
passage	O
is	O
computed	O
as	O
:	O
Then	O
the	O
context	O
-	O
to	O
-	O
question	O
attention	O
and	O
question	O
-	O
to	O
-	O
context	O
attention	O
is	O
applied	O
strictly	O
following	O
bidaf	O
to	O
obtain	O
the	O
question	Method
-	Method
aware	Method
passage	Method
representation	Method
.	O

We	O
do	O
not	O
give	O
the	O
details	O
here	O
due	O
to	O
space	O
limitation	O
.	O

Next	O
,	O
another	O
BiLSTM	Method
is	O
applied	O
in	O
order	O
to	O
fuse	O
the	O
contextual	O
information	O
and	O
get	O
the	O
new	O
representation	O
for	O
each	O
word	O
in	O
the	O
passage	O
,	O
which	O
is	O
regarded	O
as	O
the	O
match	O
output	O
:	O
Based	O
on	O
the	O
passage	Method
representations	Method
,	O
we	O
introduce	O
the	O
three	O
main	O
modules	O
of	O
our	O
model	O
.	O

subsection	O
:	O
Answer	Task
Boundary	Task
Prediction	Task
To	O
extract	O
the	O
answer	O
span	O
from	O
passages	O
,	O
mainstream	O
studies	O
try	O
to	O
locate	O
the	O
boundary	O
of	O
the	O
answer	O
,	O
which	O
is	O
called	O
boundary	Method
model	Method
.	O

Following	O
,	O
we	O
employ	O
Pointer	Method
Network	Method
to	O
compute	O
the	O
probability	O
of	O
each	O
word	O
to	O
be	O
the	O
start	O
or	O
end	O
position	O
of	O
the	O
span	O
:	O
By	O
utilizing	O
the	O
attention	O
weights	O
,	O
the	O
probability	O
of	O
the	O
word	O
in	O
the	O
passage	O
to	O
be	O
the	O
start	O
and	O
end	O
position	O
of	O
the	O
answer	O
is	O
obtained	O
as	O
and	O
.	O

It	O
should	O
be	O
noted	O
that	O
the	O
pointer	Method
network	Method
is	O
applied	O
to	O
the	O
concatenation	O
of	O
all	O
passages	O
,	O
which	O
is	O
denoted	O
as	O
P	O
so	O
that	O
the	O
probabilities	O
are	O
comparable	O
across	O
passages	O
.	O

This	O
boundary	Method
model	Method
can	O
be	O
trained	O
by	O
minimizing	O
the	O
negative	O
log	O
probabilities	O
of	O
the	O
true	O
start	O
and	O
end	O
indices	O
:	O
where	O
is	O
the	O
number	O
of	O
samples	O
in	O
the	O
dataset	O
and	O
,	O
are	O
the	O
gold	O
start	O
and	O
end	O
positions	O
.	O

subsection	O
:	O
Answer	Method
Content	Method
Modeling	Method
Previous	O
work	O
employs	O
the	O
boundary	Method
model	Method
to	O
find	O
the	O
text	O
span	O
with	O
the	O
maximum	O
boundary	O
score	O
as	O
the	O
final	O
answer	O
.	O

However	O
,	O
in	O
our	O
context	O
,	O
besides	O
locating	O
the	O
answer	O
candidates	O
,	O
we	O
also	O
need	O
to	O
model	O
their	O
meanings	O
in	O
order	O
to	O
conduct	O
the	O
verification	Task
.	O

An	O
intuitive	O
method	O
is	O
to	O
compute	O
the	O
representation	O
of	O
the	O
answer	O
candidates	O
separately	O
after	O
extracting	O
them	O
,	O
but	O
it	O
could	O
be	O
hard	O
to	O
train	O
such	O
model	O
end	O
-	O
to	O
-	O
end	O
.	O

Here	O
,	O
we	O
propose	O
a	O
novel	O
method	O
that	O
can	O
obtain	O
the	O
representation	O
of	O
the	O
answer	O
candidates	O
based	O
on	O
probabilities	O
.	O

Specifically	O
,	O
we	O
change	O
the	O
output	O
layer	O
of	O
the	O
classic	O
MRC	Method
model	Method
.	O

Besides	O
predicting	O
the	O
boundary	O
probabilities	O
for	O
the	O
words	O
in	O
the	O
passages	O
,	O
we	O
also	O
predict	O
whether	O
each	O
word	O
should	O
be	O
included	O
in	O
the	O
content	Method
of	O
the	O
answer	O
.	O

The	O
content	Method
probability	O
of	O
the	O
word	O
is	O
computed	O
as	O
:	O
Training	O
this	O
content	Method
model	O
is	O
also	O
quite	O
intuitive	O
.	O

We	O
transform	O
the	O
boundary	O
labels	O
into	O
a	O
continuous	O
segment	O
,	O
which	O
means	O
the	O
words	O
within	O
the	O
answer	O
span	O
will	O
be	O
labeled	O
as	O
1	O
and	O
other	O
words	O
will	O
be	O
labeled	O
as	O
0	O
.	O

In	O
this	O
way	O
,	O
we	O
define	O
the	O
loss	O
function	O
as	O
the	O
averaged	O
cross	O
entropy	O
:	O
The	O
content	Method
probabilities	O
provide	O
another	O
view	O
to	O
measure	O
the	O
quality	O
of	O
the	O
answer	O
in	O
addition	O
to	O
the	O
boundary	O
.	O

Moreover	O
,	O
with	O
these	O
probabilities	O
,	O
we	O
can	O
represent	O
the	O
answer	O
from	O
passage	O
as	O
a	O
weighted	O
sum	O
of	O
all	O
the	O
word	O
embeddings	O
in	O
this	O
passage	O
:	O
subsection	O
:	O
Cross	Task
-	Task
Passage	Task
Answer	Task
Verification	Task
The	O
boundary	Method
model	Method
and	O
the	O
content	Method
model	O
focus	O
on	O
extracting	O
and	O
modeling	O
the	O
answer	O
within	O
a	O
single	O
passage	O
respectively	O
,	O
with	O
little	O
consideration	O
of	O
the	O
cross	O
-	O
passage	O
information	O
.	O

However	O
,	O
as	O
is	O
discussed	O
in	O
Section	O
[	O
reference	O
]	O
,	O
there	O
could	O
be	O
multiple	O
answer	O
candidates	O
from	O
different	O
passages	O
and	O
some	O
of	O
them	O
may	O
mislead	O
the	O
MRC	Method
model	Method
to	O
make	O
an	O
incorrect	O
prediction	O
.	O

It	O
’s	O
necessary	O
to	O
aggregate	O
the	O
information	O
from	O
different	O
passages	O
and	O
choose	O
the	O
best	O
one	O
from	O
those	O
candidates	O
.	O

Therefore	O
,	O
we	O
propose	O
a	O
method	O
to	O
enable	O
the	O
answer	O
candidates	O
to	O
exchange	O
information	O
and	O
verify	O
each	O
other	O
through	O
the	O
cross	Task
-	Task
passage	Task
answer	Task
verification	Task
process	Task
.	O

Given	O
the	O
representation	O
of	O
the	O
answer	O
candidates	O
from	O
all	O
passages	O
,	O
each	O
answer	O
candidate	O
then	O
attends	O
to	O
other	O
candidates	O
to	O
collect	O
supportive	O
information	O
via	O
attention	Method
mechanism	Method
:	O
Here	O
is	O
the	O
collected	O
verification	O
information	O
from	O
other	O
passages	O
based	O
on	O
the	O
attention	O
weights	O
.	O

Then	O
we	O
pass	O
it	O
together	O
with	O
the	O
original	O
representation	O
to	O
a	O
fully	Method
connected	Method
layer	Method
:	O
We	O
further	O
normalize	O
these	O
scores	O
over	O
all	O
passages	O
to	O
get	O
the	O
verification	Metric
score	Metric
for	O
answer	O
candidate	O
:	O
In	O
order	O
to	O
train	O
this	O
verification	Method
model	Method
,	O
we	O
take	O
the	O
answer	O
from	O
the	O
gold	O
passage	O
as	O
the	O
gold	O
answer	O
.	O

And	O
the	O
loss	O
function	O
can	O
be	O
formulated	O
as	O
the	O
negative	O
log	O
probability	O
of	O
the	O
correct	O
answer	O
:	O
where	O
is	O
the	O
index	O
of	O
the	O
correct	O
answer	O
in	O
all	O
the	O
answer	O
candidates	O
of	O
the	O
instance	O
.	O

subsection	O
:	O
Joint	Task
Training	Task
and	O
Prediction	Task
As	O
is	O
described	O
above	O
,	O
we	O
define	O
three	O
objectives	O
for	O
the	O
reading	Method
comprehension	Method
model	Method
over	O
multiple	O
passages	O
:	O
1	O
.	O

finding	O
the	O
boundary	O
of	O
the	O
answer	O
;	O
2	O
.	O

predicting	O
whether	O
each	O
word	O
should	O
be	O
included	O
in	O
the	O
content	Method
;	O
3	O
.	O

selecting	O
the	O
best	O
answer	O
via	O
cross	Task
-	Task
passage	Task
answer	Task
verification	Task
.	O

According	O
to	O
our	O
design	O
,	O
these	O
three	O
tasks	O
can	O
share	O
the	O
same	O
embedding	O
,	O
encoding	O
and	O
matching	O
layers	O
.	O

Therefore	O
,	O
we	O
propose	O
to	O
train	O
them	O
together	O
as	O
multi	Task
-	Task
task	Task
learning	Task
.	O

The	O
joint	Metric
objective	Metric
function	Metric
is	O
formulated	O
as	O
follows	O
:	O
where	O
and	O
are	O
two	O
hyper	O
-	O
parameters	O
that	O
control	O
the	O
weights	O
of	O
those	O
tasks	O
.	O

When	O
predicting	O
the	O
final	O
answer	O
,	O
we	O
take	O
the	O
boundary	Metric
score	Metric
,	O
content	Method
score	O
and	O
verification	Metric
score	Metric
into	O
consideration	O
.	O

We	O
first	O
extract	O
the	O
answer	O
candidate	O
that	O
has	O
the	O
maximum	O
boundary	O
score	O
from	O
each	O
passage	O
.	O

This	O
boundary	Metric
score	Metric
is	O
computed	O
as	O
the	O
product	O
of	O
the	O
start	O
and	O
end	O
probability	O
of	O
the	O
answer	O
span	O
.	O

Then	O
for	O
each	O
answer	O
candidate	O
,	O
we	O
average	O
the	O
content	Method
probabilities	O
of	O
all	O
its	O
words	O
as	O
the	O
content	Method
score	O
of	O
.	O

And	O
we	O
can	O
also	O
predict	O
the	O
verification	Metric
score	Metric
for	O
using	O
the	O
verification	Method
model	Method
.	O

Therefore	O
,	O
the	O
final	O
answer	O
can	O
be	O
selected	O
from	O
all	O
the	O
answer	O
candidates	O
according	O
to	O
the	O
product	O
of	O
these	O
three	O
scores	O
.	O

section	O
:	O
Experiments	O
To	O
verify	O
the	O
effectiveness	O
of	O
our	O
model	O
on	O
multi	Task
-	Task
passage	Task
machine	Task
reading	Task
comprehension	Task
,	O
we	O
conduct	O
experiments	O
on	O
the	O
MS	Material
-	Material
MARCO	Material
and	O
DuReader	O
datasets	O
.	O

Our	O
method	O
achieves	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
performance	O
on	O
both	O
datasets	O
.	O

subsection	O
:	O
Datasets	O
We	O
choose	O
the	O
MS	Material
-	Material
MARCO	Material
and	O
DuReader	O
datasets	O
to	O
test	O
our	O
method	O
,	O
since	O
both	O
of	O
them	O
are	O
designed	O
from	O
real	Method
-	Method
world	Method
search	Method
engines	Method
and	O
involve	O
a	O
large	O
number	O
of	O
passages	O
retrieved	O
from	O
the	O
web	O
.	O

One	O
difference	O
of	O
these	O
two	O
datasets	O
is	O
that	O
MS	Material
-	Material
MARCO	Material
mainly	O
focuses	O
on	O
the	O
English	O
web	O
data	O
,	O
while	O
DuReader	O
is	O
designed	O
for	O
Chinese	O
MRC	O
.	O

This	O
diversity	O
is	O
expected	O
to	O
reflect	O
the	O
generality	O
of	O
our	O
method	O
.	O

In	O
terms	O
of	O
the	O
data	O
size	O
,	O
MS	Material
-	Material
MARCO	Material
contains	O
102023	O
questions	O
,	O
each	O
of	O
which	O
is	O
paired	O
up	O
with	O
approximately	O
10	O
passages	O
for	O
reading	Task
comprehension	Task
.	O

As	O
for	O
DuReader	O
,	O
it	O
keeps	O
the	O
top	O
-	O
5	O
search	O
results	O
for	O
each	O
question	O
and	O
there	O
are	O
totally	O
201574	O
questions	O
.	O

One	O
prerequisite	O
for	O
answer	Task
verification	Task
is	O
that	O
there	O
should	O
be	O
multiple	O
correct	O
answers	O
so	O
that	O
they	O
can	O
verify	O
each	O
other	O
.	O

Both	O
the	O
MS	Material
-	Material
MARCO	Material
and	O
DuReader	O
datasets	O
require	O
the	O
human	O
annotators	O
to	O
generate	O
multiple	O
answers	O
if	O
possible	O
.	O

Table	O
[	O
reference	O
]	O
shows	O
the	O
proportion	O
of	O
questions	O
that	O
have	O
multiple	O
answers	O
.	O

However	O
,	O
the	O
same	O
answer	O
that	O
occurs	O
many	O
times	O
is	O
treated	O
as	O
one	O
single	O
answer	O
here	O
.	O

Therefore	O
,	O
we	O
also	O
report	O
the	O
proportion	O
of	O
questions	O
that	O
have	O
multiple	O
answer	O
spans	O
to	O
match	O
with	O
the	O
human	O
-	O
generated	O
answers	O
.	O

A	O
span	O
is	O
taken	O
as	O
valid	O
if	O
it	O
can	O
achieve	O
F1	Metric
score	Metric
larger	O
than	O
0.7	O
compared	O
with	O
any	O
reference	O
answer	O
.	O

From	O
these	O
statistics	O
,	O
we	O
can	O
see	O
that	O
the	O
phenomenon	O
of	O
multiple	O
answers	O
is	O
quite	O
common	O
for	O
both	O
MS	Material
-	Material
MARCO	Material
and	O
DuReader	O
.	O

These	O
answers	O
will	O
provide	O
strong	O
signals	O
for	O
answer	Task
verification	Task
if	O
we	O
can	O
leverage	O
them	O
properly	O
.	O

subsection	O
:	O
Implementation	O
Details	O
For	O
MS	Material
-	Material
MARCO	Material
,	O
we	O
preprocess	O
the	O
corpus	O
with	O
the	O
reversible	Method
tokenizer	Method
from	O
Stanford	O
CoreNLP	O
and	O
we	O
choose	O
the	O
span	O
that	O
achieves	O
the	O
highest	O
ROUGE	Metric
-	Metric
L	Metric
score	Metric
with	O
the	O
reference	O
answers	O
as	O
the	O
gold	O
span	O
for	O
training	O
.	O

We	O
employ	O
the	O
300	Method
-	Method
D	Method
pre	Method
-	Method
trained	Method
Glove	Method
embeddings	Method
and	O
keep	O
it	O
fixed	O
during	O
training	O
.	O

The	O
character	O
embeddings	O
are	O
randomly	O
initialized	O
with	O
its	O
dimension	O
as	O
30	O
.	O

For	O
DuReader	O
,	O
we	O
follow	O
the	O
preprocessing	O
described	O
in	O
dureader	Method
.	O

We	O
tune	O
the	O
hyper	O
-	O
parameters	O
according	O
to	O
the	O
validation	O
performance	O
on	O
the	O
MS	Material
-	Material
MARCO	Material
development	Material
set	Material
.	O

The	O
hidden	O
size	O
is	O
set	O
to	O
be	O
150	O
and	O
we	O
apply	O
regularization	Method
with	O
its	O
weight	O
as	O
0.0003	O
.	O

The	O
task	O
weights	O
,	O
are	O
both	O
set	O
to	O
be	O
0.5	O
.	O

To	O
train	O
our	O
model	O
,	O
we	O
employ	O
the	O
Adam	Method
algorithm	Method
with	O
the	O
initial	O
learning	Metric
rate	Metric
as	O
0.0004	O
and	O
the	O
mini	O
-	O
batch	O
size	O
as	O
32	O
.	O

Exponential	Method
moving	Method
average	Method
is	O
applied	O
on	O
all	O
trainable	O
variables	O
with	O
a	O
decay	Metric
rate	Metric
0.9999	O
.	O

Two	O
simple	O
yet	O
effective	O
technologies	O
are	O
employed	O
to	O
improve	O
the	O
final	O
performance	O
on	O
these	O
two	O
datasets	O
respectively	O
.	O

For	O
MS	Material
-	Material
MARCO	Material
,	O
approximately	O
8	O
%	O
questions	O
have	O
the	O
answers	O
as	O
Yes	O
or	O
No	O
,	O
which	O
usually	O
can	O
not	O
be	O
solved	O
by	O
extractive	Method
approach	Method
.	O

We	O
address	O
this	O
problem	O
by	O
training	O
a	O
simple	O
Yes	Method
/	Method
No	Method
classifier	Method
for	O
those	O
questions	O
with	O
certain	O
patterns	O
(	O
e.g.	O
,	O
starting	O
with	O
“	O
is	O
”	O
)	O
.	O

Concretely	O
,	O
we	O
simply	O
change	O
the	O
output	O
layer	O
of	O
the	O
basic	Method
boundary	Method
model	Method
so	O
that	O
it	O
can	O
predict	O
whether	O
the	O
answer	O
is	O
“	O
Yes	O
”	O
or	O
“	O
No	O
”	O
.	O

For	O
DuReader	O
,	O
the	O
retrieved	O
document	O
usually	O
contains	O
a	O
large	O
number	O
of	O
paragraphs	O
that	O
can	O
not	O
be	O
fed	O
into	O
MRC	Method
models	Method
directly	O
.	O

The	O
original	O
paper	O
employs	O
a	O
simple	O
a	O
simple	O
heuristic	Method
strategy	Method
to	O
select	O
a	O
representative	O
paragraph	O
for	O
each	O
document	O
,	O
while	O
we	O
train	O
a	O
paragraph	Method
ranking	Method
model	Method
for	O
this	O
.	O

We	O
will	O
demonstrate	O
the	O
effects	O
of	O
these	O
two	O
technologies	O
later	O
.	O

subsection	O
:	O
Results	O
on	O
MS	Material
-	Material
MARCO	Material
Table	O
[	O
reference	O
]	O
shows	O
the	O
results	O
of	O
our	O
system	O
and	O
other	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
models	O
on	O
the	O
MS	Material
-	Material
MARCO	Material
test	Material
set	Material
.	O

We	O
adopt	O
the	O
official	Metric
evaluation	Metric
metrics	Metric
,	O
including	O
ROUGE	Metric
-	Metric
L	Metric
and	O
BLEU	Metric
-	Metric
1	Metric
.	O

As	O
we	O
can	O
see	O
,	O
for	O
both	O
metrics	O
,	O
our	O
single	O
model	O
outperforms	O
all	O
the	O
other	O
competing	O
models	O
with	O
an	O
evident	O
margin	O
,	O
which	O
is	O
extremely	O
hard	O
considering	O
the	O
near	O
-	O
human	O
performance	O
.	O

If	O
we	O
ensemble	O
the	O
models	O
trained	O
with	O
different	O
random	O
seeds	O
and	O
hyper	O
-	O
parameters	O
,	O
the	O
results	O
can	O
be	O
further	O
improved	O
and	O
outperform	O
the	O
ensemble	Method
model	Method
in	O
snet	Method
,	O
especially	O
in	O
terms	O
of	O
the	O
BLEU	Metric
-	Metric
1	Metric
.	O

subsection	O
:	O
Results	O
on	O
DuReader	O
The	O
results	O
of	O
our	O
model	O
and	O
several	O
baseline	O
systems	O
on	O
the	O
test	O
set	O
of	O
DuReader	O
are	O
shown	O
in	O
Table	O
[	O
reference	O
]	O
.	O

The	O
BiDAF	Method
and	O
Match	Method
-	Method
LSTM	Method
models	Method
are	O
provided	O
as	O
two	O
baseline	O
systems	O
.	O

Based	O
on	O
BiDAF	Method
,	O
as	O
is	O
described	O
in	O
Section	O
[	O
reference	O
]	O
,	O
we	O
tried	O
a	O
new	O
paragraph	Method
selection	Method
strategy	Method
by	O
employing	O
a	O
paragraph	Method
ranking	Method
(	O
PR	Method
)	O
model	O
.	O

We	O
can	O
see	O
that	O
this	O
paragraph	Task
ranking	Task
can	O
boost	O
the	O
BiDAF	Metric
baseline	Metric
significantly	O
.	O

Finally	O
,	O
we	O
implement	O
our	O
system	O
based	O
on	O
this	O
new	O
strategy	O
,	O
and	O
our	O
system	O
(	O
single	O
model	O
)	O
achieves	O
further	O
improvement	O
by	O
a	O
large	O
margin	O
.	O

section	O
:	O
Analysis	O
and	O
Discussion	O
subsection	O
:	O
Ablation	Task
Study	Task
To	O
get	O
better	O
insight	O
into	O
our	O
system	O
,	O
we	O
conduct	O
in	O
-	O
depth	O
ablation	Task
study	Task
on	O
the	O
development	O
set	O
of	O
MS	Material
-	Material
MARCO	Material
,	O
which	O
is	O
shown	O
in	O
Table	O
[	O
reference	O
]	O
.	O

Following	O
snet	Method
,	O
we	O
mainly	O
focus	O
on	O
the	O
ROUGE	Metric
-	Metric
L	Metric
score	Metric
that	O
is	O
averaged	O
case	O
by	O
case	O
.	O

We	O
first	O
evaluate	O
the	O
answer	Task
verification	Task
by	O
ablating	O
the	O
cross	Method
-	Method
passage	Method
verification	Method
model	Method
so	O
that	O
the	O
verification	Metric
loss	Metric
and	O
verification	Metric
score	Metric
will	O
not	O
be	O
used	O
during	O
training	O
and	O
testing	O
.	O

Then	O
we	O
remove	O
the	O
content	Method
model	O
in	O
order	O
to	O
test	O
the	O
necessity	O
of	O
modeling	O
the	O
content	Method
of	O
the	O
answer	O
.	O

Since	O
we	O
do	O
n’t	O
have	O
the	O
content	Method
scores	O
,	O
we	O
use	O
the	O
boundary	O
probabilities	O
instead	O
to	O
compute	O
the	O
answer	Method
representation	Method
for	O
verification	Task
.	O

Next	O
,	O
to	O
show	O
the	O
benefits	O
of	O
joint	Task
training	Task
,	O
we	O
train	O
the	O
boundary	Method
model	Method
separately	O
from	O
the	O
other	O
two	O
models	O
.	O

Finally	O
,	O
we	O
remove	O
the	O
yes	Task
/	Task
no	Task
classification	Task
in	O
order	O
to	O
show	O
the	O
real	O
improvement	O
of	O
our	O
end	Method
-	Method
to	Method
-	Method
end	Method
model	Method
compared	O
with	O
the	O
baseline	O
method	O
that	O
predicts	O
the	O
answer	O
with	O
only	O
the	O
boundary	Method
model	Method
.	O

From	O
Table	O
[	O
reference	O
]	O
,	O
we	O
can	O
see	O
that	O
the	O
answer	Task
verification	Task
makes	O
a	O
great	O
contribution	O
to	O
the	O
overall	O
improvement	O
,	O
which	O
confirms	O
our	O
hypothesis	O
that	O
cross	Task
-	Task
passage	Task
answer	Task
verification	Task
is	O
useful	O
for	O
the	O
multi	Task
-	Task
passage	Task
MRC	Task
.	O

For	O
the	O
ablation	O
of	O
the	O
content	Method
model	O
,	O
we	O
analyze	O
that	O
it	O
will	O
not	O
only	O
affect	O
the	O
content	Method
score	O
itself	O
,	O
but	O
also	O
violate	O
the	O
verification	Method
model	Method
since	O
the	O
content	Method
probabilities	O
are	O
necessary	O
for	O
the	O
answer	Task
representation	Task
,	O
which	O
will	O
be	O
further	O
analyzed	O
in	O
Section	O
[	O
reference	O
]	O
.	O

Another	O
discovery	O
is	O
that	O
jointly	O
training	O
the	O
three	O
models	O
can	O
provide	O
great	O
benefits	O
,	O
which	O
shows	O
that	O
the	O
three	O
tasks	O
are	O
actually	O
closely	O
related	O
and	O
can	O
boost	O
each	O
other	O
with	O
shared	O
representations	O
at	O
bottom	O
layers	O
.	O

At	O
last	O
,	O
comparing	O
our	O
method	O
with	O
the	O
baseline	O
,	O
we	O
achieve	O
an	O
improvement	O
of	O
nearly	O
3	O
points	O
without	O
the	O
yes	Task
/	Task
no	Task
classification	Task
.	O

This	O
significant	O
improvement	O
proves	O
the	O
effectiveness	O
of	O
our	O
approach	O
.	O

subsection	O
:	O
Case	O
Study	O
To	O
demonstrate	O
how	O
each	O
module	O
of	O
our	O
model	O
takes	O
effect	O
when	O
predicting	O
the	O
final	O
answer	O
,	O
we	O
conduct	O
a	O
case	O
study	O
in	O
Table	O
[	O
reference	O
]	O
with	O
the	O
same	O
example	O
that	O
we	O
discussed	O
in	O
Section	O
[	O
reference	O
]	O
.	O

For	O
each	O
answer	O
candidate	O
,	O
we	O
list	O
three	O
scores	O
predicted	O
by	O
the	O
boundary	Method
model	Method
,	O
content	Method
model	O
and	O
verification	Method
model	Method
respectively	O
.	O

On	O
the	O
one	O
hand	O
,	O
we	O
can	O
see	O
that	O
these	O
three	O
scores	O
generally	O
have	O
some	O
relevance	O
.	O

For	O
example	O
,	O
the	O
second	O
candidate	O
is	O
given	O
lowest	O
scores	O
by	O
all	O
the	O
three	O
models	O
.	O

We	O
analyze	O
that	O
this	O
is	O
because	O
the	O
models	O
share	O
the	O
same	O
encoding	O
and	O
matching	O
layers	O
at	O
bottom	O
level	O
and	O
this	O
relevance	O
guarantees	O
that	O
the	O
content	Method
and	O
verification	Method
models	Method
will	O
not	O
violate	O
the	O
boundary	Method
model	Method
too	O
much	O
.	O

On	O
the	O
other	O
hand	O
,	O
we	O
also	O
see	O
that	O
the	O
verification	Metric
score	Metric
can	O
really	O
make	O
a	O
difference	O
here	O
when	O
the	O
boundary	Method
model	Method
makes	O
an	O
incorrect	O
decision	O
among	O
the	O
confusing	O
answer	O
candidates	O
(	O
[	O
1	O
]	O
,	O
[	O
3	O
]	O
,	O
[	O
4	O
]	O
,	O
[	O
6	O
]	O
)	O
.	O

Besides	O
,	O
as	O
we	O
expected	O
,	O
the	O
verification	Method
model	Method
tends	O
to	O
give	O
higher	O
scores	O
for	O
those	O
answers	O
that	O
have	O
semantic	O
commonality	O
with	O
each	O
other	O
(	O
[	O
3	O
]	O
,	O
[	O
4	O
]	O
,	O
[	O
6	O
]	O
)	O
,	O
which	O
are	O
all	O
valid	O
answers	O
in	O
this	O
case	O
.	O

By	O
multiplying	O
the	O
three	O
scores	O
,	O
our	O
model	O
finally	O
predicts	O
the	O
answer	O
correctly	O
.	O

subsection	O
:	O
Necessity	O
of	O
the	O
Content	Method
Model	Method
In	O
our	O
model	O
,	O
we	O
compute	O
the	O
answer	Method
representation	Method
based	O
on	O
the	O
content	Method
probabilities	O
predicted	O
by	O
a	O
separate	O
content	Method
model	O
instead	O
of	O
directly	O
using	O
the	O
boundary	O
probabilities	O
.	O

We	O
argue	O
that	O
this	O
content	Method
model	O
is	O
necessary	O
for	O
our	O
answer	Task
verification	Task
process	Task
.	O

Figure	O
[	O
reference	O
]	O
plots	O
the	O
predicted	O
content	Method
probabilities	O
as	O
well	O
as	O
the	O
boundary	O
probabilities	O
for	O
a	O
passage	O
.	O

We	O
can	O
see	O
that	O
the	O
boundary	O
and	O
content	Method
probabilities	O
capture	O
different	O
aspects	O
of	O
the	O
answer	O
.	O

Since	O
answer	O
candidates	O
usually	O
have	O
similar	O
boundary	O
words	O
,	O
if	O
we	O
compute	O
the	O
answer	Method
representation	Method
based	O
on	O
the	O
boundary	O
probabilities	O
,	O
it	O
’s	O
difficult	O
to	O
model	O
the	O
real	O
difference	O
among	O
different	O
answer	O
candidates	O
.	O

On	O
the	O
contrary	O
,	O
with	O
the	O
content	Method
probabilities	O
,	O
we	O
pay	O
more	O
attention	O
to	O
the	O
content	Method
part	O
of	O
the	O
answer	O
,	O
which	O
can	O
provide	O
more	O
distinguishable	O
information	O
for	O
verifying	O
the	O
correct	O
answer	O
.	O

Furthermore	O
,	O
the	O
content	Method
probabilities	O
can	O
also	O
adjust	O
the	O
weights	O
of	O
the	O
words	O
within	O
the	O
answer	O
span	O
so	O
that	O
unimportant	O
words	O
(	O
e.g.	O
“	O
and	O
”	O
and	O
“	O
.	O

”	O
)	O
get	O
lower	O
weights	O
in	O
the	O
final	O
answer	Method
representation	Method
.	O

We	O
believe	O
that	O
this	O
refined	O
representation	O
is	O
also	O
good	O
for	O
the	O
answer	Task
verification	Task
process	Task
.	O

section	O
:	O
Related	O
Work	O
Machine	Task
reading	Task
comprehension	Task
made	O
rapid	O
progress	O
in	O
recent	O
years	O
,	O
especially	O
for	O
single	Task
-	Task
passage	Task
MRC	Task
task	Task
,	O
such	O
as	O
SQuAD	O
.	O

Mainstream	O
studies	O
treat	O
reading	Task
comprehension	Task
as	O
extracting	O
answer	O
span	O
from	O
the	O
given	O
passage	O
,	O
which	O
is	O
usually	O
achieved	O
by	O
predicting	O
the	O
start	O
and	O
end	O
position	O
of	O
the	O
answer	O
.	O

We	O
implement	O
our	O
boundary	Method
model	Method
similarly	O
by	O
employing	O
the	O
boundary	Method
-	Method
based	Method
pointer	Method
network	Method
.	O

Another	O
inspiring	O
work	O
is	O
from	O
rnet	Method
,	O
where	O
the	O
authors	O
propose	O
to	O
match	O
the	O
passage	O
against	O
itself	O
so	O
that	O
the	O
representation	O
can	O
aggregate	O
evidence	O
from	O
the	O
whole	O
passage	O
.	O

Our	O
verification	Method
model	Method
adopts	O
a	O
similar	O
idea	O
.	O

However	O
,	O
we	O
collect	O
information	O
across	O
passages	O
and	O
our	O
attention	Method
is	O
based	O
on	O
the	O
answer	Method
representation	Method
,	O
which	O
is	O
much	O
more	O
efficient	O
than	O
attention	Method
over	O
all	O
passages	O
.	O

For	O
the	O
model	Task
training	Task
,	O
dcn	Method
+	Method
argues	O
that	O
the	O
boundary	O
loss	O
encourages	O
exact	O
answers	O
at	O
the	O
cost	O
of	O
penalizing	O
overlapping	O
answers	O
.	O

Therefore	O
they	O
propose	O
a	O
mixed	Method
objective	Method
that	O
incorporates	O
rewards	O
derived	O
from	O
word	O
overlap	O
.	O

Our	O
joint	Method
training	Method
approach	Method
has	O
a	O
similar	O
function	O
.	O

By	O
taking	O
the	O
content	Method
and	O
verification	O
loss	O
into	O
consideration	O
,	O
our	O
model	O
will	O
give	O
less	O
loss	O
for	O
overlapping	O
answers	O
than	O
those	O
unmatched	O
answers	O
,	O
and	O
our	O
loss	O
function	O
is	O
totally	O
differentiable	O
.	O

Recently	O
,	O
we	O
also	O
see	O
emerging	O
interests	O
in	O
multi	O
-	O
passage	Task
MRC	Task
from	O
both	O
the	O
academic	O
and	O
industrial	O
community	O
.	O

Early	O
studies	O
usually	O
concat	O
those	O
passages	O
and	O
employ	O
the	O
same	O
models	O
designed	O
for	O
single	Task
-	Task
passage	Task
MRC	Task
.	O

However	O
,	O
more	O
and	O
more	O
latest	O
studies	O
start	O
to	O
design	O
specific	O
methods	O
that	O
can	O
read	O
multiple	O
passages	O
more	O
effectively	O
.	O

In	O
the	O
aspect	O
of	O
passage	Task
selection	Task
,	O
r3	Method
introduced	O
a	O
pipelined	Method
approach	Method
that	O
rank	O
the	O
passages	O
first	O
and	O
then	O
read	O
the	O
selected	O
passages	O
for	O
answering	O
questions	O
.	O

snet	Method
treats	O
the	O
passage	Task
ranking	Task
as	O
an	O
auxiliary	Task
task	Task
that	O
can	O
be	O
trained	O
jointly	O
with	O
the	O
reading	Method
comprehension	Method
model	Method
.	O

Actually	O
,	O
the	O
target	O
of	O
our	O
answer	Task
verification	Task
is	O
very	O
similar	O
to	O
that	O
of	O
the	O
passage	Task
selection	Task
,	O
while	O
we	O
pay	O
more	O
attention	O
to	O
the	O
answer	O
content	Method
and	O
the	O
answer	Task
verification	Task
process	Task
.	O

Speaking	O
of	O
the	O
answer	Task
verification	Task
,	O
evidence_aggregation	Task
has	O
a	O
similar	O
motivation	O
to	O
ours	O
.	O

They	O
attempt	O
to	O
aggregate	O
the	O
evidence	O
from	O
different	O
passages	O
and	O
choose	O
the	O
final	O
answer	O
from	O
n	O
-	O
best	O
candidates	O
.	O

However	O
,	O
they	O
implement	O
their	O
idea	O
as	O
a	O
separate	O
reranking	Task
step	Task
after	O
reading	Task
comprehension	Task
,	O
while	O
our	O
answer	Task
verification	Task
is	O
a	O
component	O
of	O
the	O
whole	O
model	O
that	O
can	O
be	O
trained	O
end	O
-	O
to	O
-	O
end	O
.	O

section	O
:	O
Conclusion	O
In	O
this	O
paper	O
,	O
we	O
propose	O
an	O
end	Method
-	Method
to	Method
-	Method
end	Method
framework	Method
to	O
tackle	O
the	O
multi	Task
-	Task
passage	Task
MRC	Task
task	Task
.	O

We	O
creatively	O
design	O
three	O
different	O
modules	O
in	O
our	O
model	O
,	O
which	O
can	O
find	O
the	O
answer	O
boundary	O
,	O
model	O
the	O
answer	O
content	Method
and	O
conduct	O
cross	Task
-	Task
passage	Task
answer	Task
verification	Task
respectively	O
.	O

All	O
these	O
three	O
modules	O
can	O
be	O
trained	O
with	O
different	O
forms	O
of	O
the	O
answer	O
labels	O
and	O
training	O
them	O
jointly	O
can	O
provide	O
further	O
improvement	O
.	O

The	O
experimental	O
results	O
demonstrate	O
that	O
our	O
model	O
outperforms	O
the	O
baseline	O
models	O
by	O
a	O
large	O
margin	O
and	O
achieves	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
performance	O
on	O
two	O
challenging	O
datasets	O
,	O
both	O
of	O
which	O
are	O
designed	O
for	O
MRC	Task
on	O
real	O
web	O
data	O
.	O

section	O
:	O
Acknowledgments	O
This	O
work	O
is	O
supported	O
by	O
the	O
National	O
Basic	O
Research	O
Program	O
of	O
China	O
(	O
973	O
program	O
,	O
No	O
.	O

2014CB340505	O
)	O
and	O
Baidu	O
-	O
Peking	O
University	O
Joint	O
Project	O
.	O

We	O
thank	O
the	O
Microsoft	O
MSMARCO	O
team	O
for	O
evaluating	O
our	O
results	O
on	O
the	O
anonymous	O
test	O
set	O
.	O

We	O
also	O
thank	O
Ying	O
Chen	O
,	O
Xuan	O
Liu	O
and	O
the	O
anonymous	O
reviewers	O
for	O
their	O
constructive	O
criticism	O
of	O
the	O
manuscript	O
.	O

bibliography	O
:	O
References	O
