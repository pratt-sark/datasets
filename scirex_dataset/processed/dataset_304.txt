document	O
:	O
Brain	Task
Tumor	Task
Segmentation	Task
with	O
Deep	Method
Neural	Method
Networks	Method
ti	O
In	O
this	O
paper	O
,	O
we	O
present	O
a	O
fully	Method
automatic	Method
brain	Method
tumor	Method
segmentation	Method
method	Method
based	O
on	O
Deep	Method
Neural	Method
Networks	Method
(	O
DNNs	Method
)	O
.	O

The	O
proposed	O
networks	O
are	O
tailored	O
to	O
glioblastomas	O
(	O
both	O
low	O
and	O
high	O
grade	O
)	O
pictured	O
in	O
MR	Material
images	Material
.	O

By	O
their	O
very	O
nature	O
,	O
these	O
tumors	O
can	O
appear	O
anywhere	O
in	O
the	O
brain	O
and	O
have	O
almost	O
any	O
kind	O
of	O
shape	O
,	O
size	O
,	O
and	O
contrast	O
.	O

These	O
reasons	O
motivate	O
our	O
exploration	O
of	O
a	O
machine	Method
learning	Method
solution	Method
that	O
exploits	O
a	O
flexible	O
,	O
high	O
capacity	O
DNN	Method
while	O
being	O
extremely	O
efficient	O
.	O

Here	O
,	O
we	O
give	O
a	O
description	O
of	O
different	O
model	O
choices	O
that	O
we	O
’	O
ve	O
found	O
to	O
be	O
necessary	O
for	O
obtaining	O
competitive	O
performance	O
.	O

We	O
explore	O
in	O
particular	O
different	O
architectures	O
based	O
on	O
Convolutional	Method
Neural	Method
Networks	Method
(	O
CNN	Method
)	O
,	O
i.e.	O
DNNs	Method
specifically	O
adapted	O
to	O
image	O
data	O
.	O

We	O
present	O
a	O
novel	O
CNN	Method
architecture	O
which	O
differs	O
from	O
those	O
traditionally	O
used	O
in	O
computer	Task
vision	Task
.	O

Our	O
CNN	Method
exploits	O
both	O
local	O
features	O
as	O
well	O
as	O
more	O
global	O
contextual	O
features	O
simultaneously	O
.	O

Also	O
,	O
different	O
from	O
most	O
traditional	O
uses	O
of	O
CNNs	Method
,	O
our	O
networks	O
use	O
a	O
final	Method
layer	Method
that	O
is	O
a	O
convolutional	Method
implementation	Method
of	O
a	O
fully	Method
connected	Method
layer	Method
which	O
allows	O
a	O
40	O
fold	O
speed	O
up	O
.	O

We	O
also	O
describe	O
a	O
2	Method
-	Method
phase	Method
training	Method
procedure	Method
that	O
allows	O
us	O
to	O
tackle	O
difficulties	O
related	O
to	O
the	O
imbalance	O
of	O
tumor	O
labels	O
.	O

Finally	O
,	O
we	O
explore	O
a	O
cascade	Method
architecture	Method
in	O
which	O
the	O
output	O
of	O
a	O
basic	O
CNN	Method
is	O
treated	O
as	O
an	O
additional	O
source	O
of	O
information	O
for	O
a	O
subsequent	O
CNN	Method
.	O

Results	O
reported	O
on	O
the	O
2013	O
BRATS	Material
test	Material
dataset	Material
reveal	O
that	O
our	O
architecture	O
improves	O
over	O
the	O
currently	O
published	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
while	O
being	O
over	O
30	O
times	O
faster	O
.	O

[	O
t1	O
]	O
Accepted	O
in	O
Medical	Task
Image	Task
Analysis	Task
.	O

[	O
fn1	O
]	O
mohammad.havaei@gmail.com	O
section	O
:	O
Introduction	O
In	O
the	O
United	O
States	O
alone	O
,	O
it	O
is	O
estimated	O
that	O
23	O
,	O
000	O
new	O
cases	O
of	O
brain	Task
cancer	Task
will	O
be	O
diagnosed	O
in	O
2015	O
.	O

While	O
gliomas	O
are	O
the	O
most	O
common	O
brain	O
tumors	O
,	O
they	O
can	O
be	O
less	O
aggressive	O
(	O
i.e.	O
low	O
grade	O
)	O
in	O
a	O
patient	O
with	O
a	O
life	O
expectancy	O
of	O
several	O
years	O
,	O
or	O
more	O
aggressive	O
(	O
i.e.	O
high	O
grade	O
)	O
in	O
a	O
patient	O
with	O
a	O
life	O
expectancy	O
of	O
at	O
most	O
2	O
years	O
.	O

Although	O
surgery	Method
is	O
the	O
most	O
common	O
treatment	O
for	O
brain	Task
tumors	Task
,	O
radiation	O
and	O
chemotherapy	O
may	O
be	O
used	O
to	O
slow	O
the	O
growth	O
of	O
tumors	O
that	O
can	O
not	O
be	O
physically	O
removed	O
.	O

Magnetic	Method
resonance	Method
imaging	Method
(	O
MRI	Method
)	O
provides	O
detailed	O
images	O
of	O
the	O
brain	O
,	O
and	O
is	O
one	O
of	O
the	O
most	O
common	O
tests	O
used	O
to	O
diagnose	O
brain	Task
tumors	Task
.	O

All	O
the	O
more	O
,	O
brain	Task
tumor	Task
segmentation	Task
from	O
MR	Material
images	Material
can	O
have	O
great	O
impact	O
for	O
improved	O
diagnostics	Task
,	O
growth	Task
rate	Task
prediction	Task
and	O
treatment	Task
planning	Task
.	O

While	O
some	O
tumors	O
such	O
as	O
meningiomas	O
can	O
be	O
easily	O
segmented	O
,	O
others	O
like	O
gliomas	O
and	O
glioblastomas	O
are	O
much	O
more	O
difficult	O
to	O
localize	O
.	O

These	O
tumors	O
(	O
together	O
with	O
their	O
surrounding	O
edema	O
)	O
are	O
often	O
diffused	O
,	O
poorly	O
contrasted	O
,	O
and	O
extend	O
tentacle	O
-	O
like	O
structures	O
that	O
make	O
them	O
difficult	O
to	O
segment	O
.	O

Another	O
fundamental	O
difficulty	O
with	O
segmenting	Task
brain	Task
tumors	Task
is	O
that	O
they	O
can	O
appear	O
anywhere	O
in	O
the	O
brain	O
,	O
in	O
almost	O
any	O
shape	O
and	O
size	O
.	O

Furthermore	O
,	O
unlike	O
images	O
derived	O
from	O
X	Material
-	Material
ray	Material
computed	Material
tomography	Material
(	O
CT	Material
)	O
scans	O
,	O
the	O
scale	O
of	O
voxel	O
values	O
in	O
MR	Material
images	Material
is	O
not	O
standardized	O
.	O

Depending	O
on	O
the	O
type	O
of	O
MR	Method
machine	Method
used	O
(	O
1.5	O
,	O
3	O
or	O
7	O
tesla	O
)	O
and	O
the	O
acquisition	Method
protocol	Method
(	O
field	O
of	O
view	O
value	O
,	O
voxel	O
resolution	O
,	O
gradient	O
strength	O
,	O
b0	O
value	O
,	O
etc	O
.	O

)	O
,	O
the	O
same	O
tumorous	O
cells	O
may	O
end	O
up	O
having	O
drastically	O
different	O
grayscale	O
values	O
when	O
pictured	O
in	O
different	O
hospitals	O
.	O

Healthy	O
brains	O
are	O
typically	O
made	O
of	O
3	O
types	O
of	O
tissues	O
:	O
the	O
white	O
matter	O
,	O
the	O
gray	O
matter	O
,	O
and	O
the	O
cerebrospinal	O
fluid	O
.	O

The	O
goal	O
of	O
brain	Task
tumor	Task
segmentation	Task
is	O
to	O
detect	O
the	O
location	O
and	O
extension	O
of	O
the	O
tumor	O
regions	O
,	O
namely	O
active	O
tumorous	O
tissue	O
(	O
vascularized	O
or	O
not	O
)	O
,	O
necrotic	O
tissue	O
,	O
and	O
edema	O
(	O
swelling	O
near	O
the	O
tumor	O
)	O
.	O

This	O
is	O
done	O
by	O
identifying	O
abnormal	O
areas	O
when	O
compared	O
to	O
normal	O
tissue	O
.	O

Since	O
glioblastomas	O
are	O
infiltrative	O
tumors	O
,	O
their	O
borders	O
are	O
often	O
fuzzy	O
and	O
hard	O
to	O
distinguish	O
from	O
healthy	O
tissues	O
.	O

As	O
a	O
solution	O
,	O
more	O
than	O
one	O
MRI	Method
modality	O
is	O
often	O
employed	O
,	O
e.g.	O
T1	O
(	O
spin	O
-	O
lattice	O
relaxation	O
)	O
,	O
T1	O
-	O
contrasted	O
(	O
T1C	O
)	O
,	O
T2	O
(	O
spin	Task
-	Task
spin	Task
relaxation	Task
)	O
,	O
proton	Method
density	Method
(	O
PD	Method
)	O
contrast	O
imaging	O
,	O
diffusion	O
MRI	Method
(	O
dMRI	Method
)	O
,	O
and	O
fluid	Method
attenuation	Method
inversion	Method
recovery	Method
(	O
FLAIR	Method
)	O
pulse	O
sequences	O
.	O

The	O
contrast	O
between	O
these	O
modalities	O
gives	O
almost	O
a	O
unique	O
signature	O
to	O
each	O
tissue	O
type	O
.	O

Most	O
automatic	Method
brain	Method
tumor	Method
segmentation	Method
methods	Method
use	O
hand	O
-	O
designed	O
features	O
.	O

These	O
methods	O
implement	O
a	O
classical	O
machine	Method
learning	Method
pipeline	Method
according	O
to	O
which	O
features	O
are	O
first	O
extracted	O
and	O
then	O
given	O
to	O
a	O
classifier	Method
whose	O
training	O
procedure	O
does	O
not	O
affect	O
the	O
nature	O
of	O
those	O
features	O
.	O

An	O
alternative	O
approach	O
for	O
designing	O
task	Task
-	Task
adapted	Task
feature	Task
representations	Task
is	O
to	O
learn	O
a	O
hierarchy	O
of	O
increasingly	O
complex	O
features	O
directly	O
from	O
in	O
-	O
domain	O
data	O
.	O

Deep	Method
neural	Method
networks	Method
have	O
been	O
shown	O
to	O
excel	O
at	O
learning	O
such	O
feature	O
hierarchies	O
.	O

In	O
this	O
work	O
,	O
we	O
apply	O
this	O
approach	O
to	O
learn	O
feature	Method
hierarchies	Method
adapted	O
specifically	O
to	O
the	O
task	O
of	O
brain	Task
tumor	Task
segmentation	Task
that	O
combine	O
information	O
across	O
MRI	Method
modalities	Method
.	O

Specifically	O
,	O
we	O
investigate	O
several	O
choices	O
for	O
training	O
Convolutional	Method
Neural	Method
Networks	Method
(	O
CNNs	Method
)	O
,	O
which	O
are	O
Deep	Method
Neural	Method
Networks	Method
(	O
DNNs	Method
)	O
adapted	O
to	O
image	O
data	O
.	O

We	O
report	O
their	O
advantages	O
,	O
disadvantages	O
and	O
performance	O
using	O
well	O
established	O
metrics	O
.	O

Although	O
CNNs	Method
first	O
appeared	O
over	O
two	O
decades	O
ago	O
,	O
they	O
have	O
recently	O
become	O
a	O
mainstay	O
of	O
the	O
computer	Task
vision	Task
community	Task
due	O
to	O
their	O
record	O
-	O
shattering	O
performance	O
in	O
the	O
ImageNet	Task
Large	Task
-	Task
Scale	Task
Visual	Task
Recognition	Task
Challenge	Task
.	O

While	O
CNNs	Method
have	O
also	O
been	O
successfully	O
applied	O
to	O
segmentation	Task
problems	Task
,	O
most	O
of	O
the	O
previous	O
work	O
has	O
focused	O
on	O
non	Task
-	Task
medical	Task
tasks	Task
and	O
many	O
involve	O
architectures	O
that	O
are	O
not	O
well	O
suited	O
to	O
medical	Task
imagery	Task
or	O
brain	Task
tumor	Task
segmentation	Task
in	O
particular	O
.	O

Our	O
preliminary	O
work	O
on	O
using	O
convolutional	Method
neural	Method
networks	Method
for	O
brain	Task
tumor	Task
segmentation	Task
together	O
with	O
two	O
other	O
methods	O
using	O
CNNs	Method
was	O
presented	O
in	O
BRATS‘14	Task
workshop	Task
.	O

However	O
,	O
those	O
results	O
were	O
incomplete	O
and	O
required	O
more	O
investigation	O
(	O
More	O
on	O
this	O
in	O
chapter	O
[	O
reference	O
]	O
)	O
.	O

In	O
this	O
paper	O
,	O
we	O
propose	O
a	O
number	O
of	O
specific	O
CNN	Method
architectures	O
for	O
tackling	O
brain	Task
tumor	Task
segmentation	Task
.	O

Our	O
architectures	O
exploit	O
the	O
most	O
recent	O
advances	O
in	O
CNN	Method
design	O
and	O
training	O
techniques	O
,	O
such	O
as	O
Maxout	Method
hidden	Method
units	Method
and	O
Dropout	Method
regularization	Method
.	O

We	O
also	O
investigate	O
several	O
architectures	O
which	O
take	O
into	O
account	O
both	O
the	O
local	O
shape	O
of	O
tumors	O
as	O
well	O
as	O
their	O
context	O
.	O

One	O
problem	O
with	O
many	O
machine	Method
learning	Method
methods	Method
is	O
that	O
they	O
perform	O
pixel	Task
classification	Task
without	O
taking	O
into	O
account	O
the	O
local	O
dependencies	O
of	O
labels	O
(	O
i.e.	O
segmentation	O
labels	O
are	O
conditionally	O
independent	O
given	O
the	O
input	O
image	O
)	O
.	O

To	O
account	O
for	O
this	O
,	O
one	O
can	O
employ	O
structured	Method
output	Method
methods	Method
such	O
as	O
conditional	Method
random	Method
fields	Method
(	O
CRFs	Method
)	O
,	O
for	O
which	O
inference	Task
can	O
be	O
computationally	O
expensive	O
.	O

Alternatively	O
,	O
one	O
can	O
model	O
label	O
dependencies	O
by	O
considering	O
the	O
pixel	O
-	O
wise	O
probability	O
estimates	O
of	O
an	O
initial	O
CNN	Method
as	O
additional	O
input	O
to	O
certain	O
layers	O
of	O
a	O
second	O
DNN	Method
,	O
forming	O
a	O
cascaded	Method
architecture	Method
.	O

Since	O
convolutions	Method
are	O
efficient	O
operations	O
,	O
this	O
approach	O
can	O
be	O
significantly	O
faster	O
than	O
implementing	O
a	O
CRF	Method
.	O

We	O
focus	O
our	O
experimental	O
analysis	O
on	O
the	O
fully	Material
-	Material
annotated	Material
MICCAI	Material
brain	Material
tumor	Material
segmentation	Material
(	O
BRATS	Material
)	O
challenge	O
2013	O
dataset	O
using	O
the	O
well	O
defined	O
training	O
and	O
testing	O
splits	O
,	O
thereby	O
allowing	O
us	O
to	O
compare	O
directly	O
and	O
quantitatively	O
to	O
a	O
wide	O
variety	O
of	O
other	O
methods	O
.	O

Our	O
contributions	O
in	O
this	O
work	O
are	O
four	O
fold	O
:	O
We	O
propose	O
a	O
fully	Method
automatic	Method
method	Method
with	O
results	O
currently	O
ranked	O
second	O
on	O
the	O
BRATS	Material
2013	O
scoreboard	O
;	O
To	O
segment	O
a	O
brain	O
,	O
our	O
method	O
takes	O
between	O
25	O
seconds	O
and	O
3	O
minutes	O
,	O
which	O
is	O
one	O
order	O
of	O
magnitude	O
faster	O
than	O
most	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
methods	O
.	O

Our	O
CNN	Method
implements	O
a	O
novel	O
two	Method
-	Method
pathway	Method
architecture	Method
that	O
learns	O
about	O
the	O
local	O
details	O
of	O
the	O
brain	O
as	O
well	O
as	O
the	O
larger	O
context	O
.	O

We	O
also	O
propose	O
a	O
two	O
-	O
phase	Method
training	Method
procedure	Method
which	O
we	O
have	O
found	O
is	O
critical	O
to	O
deal	O
with	O
imbalanced	O
label	O
distributions	O
.	O

Details	O
of	O
these	O
contributions	O
are	O
described	O
in	O
Sections	O
[	O
reference	O
]	O
and	O
[	O
reference	O
]	O
.	O

We	O
employ	O
a	O
novel	O
cascaded	Method
architecture	Method
as	O
an	O
efficient	O
and	O
conceptually	O
clean	O
alternative	O
to	O
popular	O
structured	Method
output	Method
methods	Method
.	O

Details	O
on	O
those	O
models	O
are	O
presented	O
in	O
Section	O
[	O
reference	O
]	O
.	O

section	O
:	O
Related	O
work	O
As	O
noted	O
by	O
,	O
the	O
number	O
of	O
publications	O
devoted	O
to	O
automated	Task
brain	Task
tumor	Task
segmentation	Task
has	O
grown	O
exponentially	O
in	O
the	O
last	O
several	O
decades	O
.	O

This	O
observation	O
not	O
only	O
underlines	O
the	O
need	O
for	O
automatic	Task
brain	Task
tumor	Task
segmentation	Task
tools	Task
,	O
but	O
also	O
shows	O
that	O
research	O
in	O
that	O
area	O
is	O
still	O
a	O
work	O
in	O
progress	O
.	O

Brain	Method
tumor	Method
segmentation	Method
methods	Method
(	O
especially	O
those	O
devoted	O
to	O
MRI	Method
)	O
can	O
be	O
roughly	O
divided	O
in	O
two	O
categories	O
:	O
those	O
based	O
on	O
generative	Method
models	Method
and	O
those	O
based	O
on	O
discriminative	Method
models	Method
.	O

Generative	Method
models	Method
rely	O
heavily	O
on	O
domain	O
-	O
specific	O
prior	O
knowledge	O
about	O
the	O
appearance	O
of	O
both	O
healthy	O
and	O
tumorous	O
tissues	O
.	O

Tissue	O
appearance	O
is	O
challenging	O
to	O
characterize	O
,	O
and	O
existing	O
generative	Method
models	Method
usually	O
identify	O
a	O
tumor	O
as	O
being	O
a	O
shape	O
or	O
a	O
signal	O
which	O
deviates	O
from	O
a	O
normal	O
(	O
or	O
average	O
)	O
brain	O
.	O

Typically	O
,	O
these	O
methods	O
rely	O
on	O
anatomical	Method
models	Method
obtained	O
after	O
aligning	O
the	O
3D	O
MR	O
image	O
on	O
an	O
atlas	O
or	O
a	O
template	O
computed	O
from	O
several	O
healthy	O
brains	O
.	O

A	O
typical	O
generative	Method
model	Method
of	O
MR	O
brain	O
images	O
can	O
be	O
found	O
in	O
.	O

Given	O
the	O
ICBM	Material
brain	Material
atlas	Material
,	O
the	O
method	O
aligns	O
the	O
brain	O
to	O
the	O
atlas	O
and	O
computes	O
posterior	O
probabilities	O
of	O
healthy	O
tissues	O
(	O
white	O
matter	O
,	O
gray	O
matter	O
and	O
cerebrospinal	O
fluid	O
)	O
.	O

Tumorous	O
regions	O
are	O
then	O
found	O
by	O
localizing	O
voxels	O
whose	O
posterior	O
probability	O
is	O
below	O
a	O
certain	O
threshold	O
.	O

A	O
post	Method
-	Method
processing	Method
step	Method
is	O
then	O
applied	O
to	O
ensure	O
good	O
spatial	O
regularity	O
.	O

also	O
register	O
brain	O
images	O
onto	O
an	O
atlas	O
in	O
order	O
to	O
get	O
a	O
probability	O
map	O
for	O
abnormalities	O
.	O

An	O
active	O
contour	O
is	O
then	O
initialized	O
on	O
this	O
map	O
and	O
iterated	O
until	O
the	O
change	O
in	O
posterior	O
probability	O
is	O
below	O
a	O
certain	O
threshold	O
.	O

Many	O
other	O
active	Method
-	Method
contour	Method
methods	Method
along	O
the	O
same	O
lines	O
have	O
been	O
proposed	O
,	O
all	O
of	O
which	O
depend	O
on	O
left	O
-	O
right	O
brain	O
symmetry	O
features	O
and	O
/	O
or	O
alignment	O
-	O
based	O
features	O
.	O

Note	O
that	O
since	O
aligning	O
a	O
brain	O
with	O
a	O
large	O
tumor	O
onto	O
a	O
template	O
can	O
be	O
challenging	O
,	O
some	O
methods	O
perform	O
registration	Task
and	O
tumor	Task
segmentation	Task
at	O
the	O
same	O
time	O
.	O

Other	O
approaches	O
for	O
brain	Task
tumor	Task
segmentation	Task
employ	O
discriminative	Method
models	Method
.	O

Unlike	O
generative	Method
modeling	Method
approaches	Method
,	O
these	O
approaches	O
exploit	O
little	O
prior	O
knowledge	O
on	O
the	O
brain	O
’s	O
anatomy	O
and	O
instead	O
rely	O
mostly	O
on	O
the	O
extraction	O
of	O
[	O
a	O
large	O
number	O
of	O
]	O
low	O
level	O
image	O
features	O
,	O
directly	O
modeling	O
the	O
relationship	O
between	O
these	O
features	O
and	O
the	O
label	O
of	O
a	O
given	O
voxel	O
.	O

These	O
features	O
may	O
be	O
raw	O
input	O
pixels	O
values	O
,	O
local	O
histograms	O
texture	O
features	O
such	O
as	O
Gabor	Method
filterbanks	Method
,	O
or	O
alignment	Method
-	Method
based	Method
features	Method
such	O
as	O
inter	O
-	O
image	O
gradient	O
,	O
region	O
shape	O
difference	O
,	O
and	O
symmetry	Method
analysis	Method
.	O

Classical	O
discriminative	Method
learning	Method
techniques	Method
such	O
as	O
SVMs	Method
and	O
decision	Method
forests	Method
have	O
also	O
been	O
used	O
.	O

Results	O
from	O
the	O
2012	O
,	O
2013	O
and	O
2014	O
editions	O
of	O
the	O
MICCAI	O
-	O
BRATS	Material
Challenge	O
suggest	O
that	O
methods	O
relying	O
on	O
random	Method
forests	Method
are	O
among	O
the	O
most	O
accurate	O
.	O

One	O
common	O
aspect	O
with	O
discriminative	Method
models	Method
is	O
their	O
implementation	O
of	O
a	O
conventional	O
machine	Method
learning	Method
pipeline	Method
relying	O
on	O
hand	O
-	O
designed	O
features	O
.	O

For	O
these	O
methods	O
,	O
the	O
classifier	Method
is	O
trained	O
to	O
separate	O
healthy	O
from	O
non	O
-	O
heatlthy	O
tissues	O
assuming	O
that	O
the	O
input	O
features	O
have	O
a	O
sufficiently	O
high	O
discriminative	O
power	O
since	O
the	O
behavior	O
the	O
classifier	Method
is	O
independent	O
from	O
nature	O
of	O
those	O
features	O
.	O

One	O
difficulty	O
with	O
methods	O
based	O
on	O
hand	O
-	O
designed	O
features	O
is	O
that	O
they	O
often	O
require	O
the	O
computation	O
of	O
a	O
large	O
number	O
of	O
features	O
in	O
order	O
to	O
be	O
accurate	O
when	O
used	O
with	O
many	O
traditional	O
machine	Method
learning	Method
techniques	Method
.	O

This	O
can	O
make	O
them	O
slow	O
to	O
compute	O
and	O
expensive	O
memory	O
-	O
wise	O
.	O

More	O
efficient	O
techniques	O
employ	O
lower	O
numbers	O
of	O
features	O
,	O
using	O
dimensionality	Method
reduction	Method
or	O
feature	Method
selection	Method
methods	Method
,	O
but	O
the	O
reduction	O
in	O
the	O
number	O
of	O
features	O
is	O
often	O
at	O
the	O
cost	O
of	O
reduced	O
accuracy	Metric
.	O

By	O
their	O
nature	O
,	O
many	O
hand	Method
-	Method
engineered	Method
features	Method
exploit	O
very	O
generic	O
edge	O
-	O
related	O
information	O
,	O
with	O
no	O
specific	O
adaptation	O
to	O
the	O
domain	O
of	O
brain	O
tumors	O
.	O

Ideally	O
,	O
one	O
would	O
like	O
to	O
have	O
features	O
that	O
are	O
composed	O
and	O
refined	O
into	O
higher	O
-	O
level	O
,	O
task	Method
-	Method
adapted	Method
representations	Method
.	O

Recently	O
,	O
preliminary	O
investigations	O
have	O
shown	O
that	O
the	O
use	O
of	O
deep	O
CNNs	Method
for	O
brain	Task
tumor	Task
segmentation	Task
makes	O
for	O
a	O
very	O
promising	O
approach	O
(	O
see	O
the	O
BRATS	Material
2014	Material
challenge	Material
workshop	O
papers	O
of	O
)	O
.	O

All	O
three	O
methods	O
divide	O
the	O
3D	O
MR	O
images	O
into	O
2D	O
or	O
3D	O
patches	O
and	O
train	O
a	O
CNN	Method
to	O
predict	O
its	O
center	O
pixel	O
class	O
.	O

as	O
well	O
as	O
implemented	O
a	O
fairly	O
common	O
CNN	Method
,	O
consisting	O
of	O
a	O
series	O
of	O
convolutional	Method
layers	Method
,	O
a	O
non	Method
-	Method
linear	Method
activation	Method
function	Method
between	O
each	O
layer	O
and	O
a	O
softmax	Method
output	Method
layer	Method
.	O

Our	O
work	O
here	O
extends	O
our	O
preliminary	O
results	O
presented	O
in	O
using	O
a	O
two	Method
-	Method
pathway	Method
architecture	Method
,	O
which	O
we	O
use	O
here	O
as	O
a	O
building	O
block	O
.	O

In	O
computer	Task
vision	Task
,	O
CNN	Method
-	O
based	O
segmentation	O
models	O
have	O
typically	O
been	O
applied	O
to	O
natural	Task
scene	Task
labeling	Task
.	O

For	O
these	O
tasks	O
,	O
the	O
inputs	O
to	O
the	O
model	O
are	O
the	O
RGB	O
channels	O
of	O
a	O
patch	O
from	O
a	O
color	O
image	O
.	O

The	O
work	O
in	O
uses	O
a	O
basic	O
CNN	Method
to	O
make	O
predictions	O
for	O
each	O
pixel	O
and	O
further	O
improves	O
the	O
predictions	O
by	O
using	O
them	O
as	O
extra	O
information	O
in	O
the	O
input	O
of	O
a	O
second	O
CNN	Method
model	O
.	O

Other	O
work	O
involves	O
several	O
distinct	O
CNNs	Method
processing	O
the	O
image	O
at	O
different	O
resolutions	O
.	O

The	O
final	O
per	Task
-	Task
pixel	Task
class	Task
prediction	Task
is	O
made	O
by	O
integrating	O
information	O
learned	O
from	O
all	O
CNNs	Method
.	O

To	O
produce	O
a	O
smooth	Task
segmentation	Task
,	O
these	O
predictions	O
are	O
regularized	O
using	O
a	O
more	O
global	Method
superpixel	Method
segmentation	Method
of	O
the	O
image	O
.	O

Like	O
our	O
work	O
,	O
other	O
recent	O
work	O
has	O
exploited	O
convolution	Method
operations	Method
in	O
the	O
final	O
layer	O
of	O
a	O
network	O
to	O
extend	O
traditional	O
CNN	Method
architectures	O
for	O
semantic	Task
scene	Task
segmentation	Task
.	O

In	O
the	O
medical	Task
imaging	Task
domain	Task
in	O
general	O
there	O
has	O
been	O
comparatively	O
less	O
work	O
using	O
CNNs	Method
for	O
segmentation	Task
.	O

However	O
,	O
some	O
notable	O
recent	O
work	O
by	O
has	O
used	O
CNNs	Method
to	O
predict	O
the	O
boundaries	Task
of	Task
neural	Task
tissue	Task
in	O
electron	O
microscopy	O
images	O
.	O

Here	O
we	O
explore	O
an	O
approach	O
with	O
similarities	O
to	O
the	O
various	O
approaches	O
discussed	O
above	O
,	O
but	O
in	O
the	O
context	O
of	O
brain	Task
tumor	Task
segmentation	Task
.	O

section	O
:	O
Our	O
Convolutional	Method
Neural	Method
Network	Method
Approach	Method
Since	O
the	O
brains	O
in	O
the	O
BRATS	Material
dataset	O
lack	O
resolution	O
in	O
the	O
third	O
dimension	O
,	O
we	O
consider	O
performing	O
the	O
segmentation	Task
slice	O
by	O
slice	O
from	O
the	O
axial	O
view	O
.	O

Thus	O
,	O
our	O
model	O
processes	O
sequentially	O
each	O
2D	O
axial	O
image	O
(	O
slice	O
)	O
where	O
each	O
pixel	O
is	O
associated	O
with	O
different	O
image	O
modalities	O
namely	O
;	O
T1	O
,	O
T2	O
,	O
T1C	O
and	O
FLAIR	Method
.	O

Like	O
most	O
CNN	Method
-	O
based	O
segmentation	O
models	O
,	O
our	O
method	O
predicts	O
the	O
class	O
of	O
a	O
pixel	O
by	O
processing	O
the	O
patch	O
centered	O
on	O
that	O
pixel	O
.	O

The	O
input	O
of	O
our	O
CNN	Method
model	O
is	O
thus	O
an	O
2D	O
patch	O
with	O
several	O
modalities	O
.	O

The	O
main	O
building	O
block	O
used	O
to	O
construct	O
a	O
CNN	Method
architecture	O
is	O
the	O
convolutional	Method
layer	Method
.	O

Several	O
layers	O
can	O
be	O
stacked	O
on	O
top	O
of	O
each	O
other	O
forming	O
a	O
hierarchy	O
of	O
features	O
.	O

Each	O
layer	O
can	O
be	O
understood	O
as	O
extracting	O
features	O
from	O
its	O
preceding	O
layer	O
into	O
the	O
hierarchy	O
to	O
which	O
it	O
is	O
connected	O
.	O

A	O
single	O
convolutional	Method
layer	Method
takes	O
as	O
input	O
a	O
stack	O
of	O
input	O
planes	O
and	O
produces	O
as	O
output	O
some	O
number	O
of	O
output	O
planes	O
or	O
feature	O
maps	O
.	O

Each	O
feature	O
map	O
can	O
be	O
thought	O
of	O
as	O
a	O
topologically	O
arranged	O
map	O
of	O
responses	O
of	O
a	O
particular	O
spatially	Method
local	Method
non	Method
-	Method
linear	Method
feature	Method
extractor	Method
(	O
the	O
parameters	O
of	O
which	O
are	O
learned	O
)	O
,	O
applied	O
identically	O
to	O
each	O
spatial	O
neighborhood	O
of	O
the	O
input	O
planes	O
in	O
a	O
sliding	Method
window	Method
fashion	Method
.	O

In	O
the	O
case	O
of	O
a	O
first	Method
convolutional	Method
layer	Method
,	O
the	O
individual	O
input	O
planes	O
correspond	O
to	O
different	O
MRI	Method
modalities	O
(	O
in	O
typical	O
computer	Task
vision	Task
applications	Task
,	O
the	O
individual	O
input	O
planes	O
correspond	O
to	O
the	O
red	O
,	O
green	O
and	O
blue	O
color	O
channels	O
)	O
.	O

In	O
subsequent	O
layers	O
,	O
the	O
input	O
planes	O
typically	O
consist	O
of	O
the	O
feature	O
maps	O
of	O
the	O
previous	O
layer	O
.	O

Computing	O
a	O
feature	O
map	O
in	O
a	O
convolutional	Method
layer	Method
(	O
see	O
Figure	O
[	O
reference	O
]	O
)	O
consists	O
of	O
the	O
following	O
three	O
steps	O
:	O
Convolution	Method
of	Method
kernels	Method
(	O
filters	Method
)	O
:	O
Each	O
feature	O
map	O
is	O
associated	O
with	O
one	O
kernel	O
(	O
or	O
several	O
,	O
in	O
the	O
case	O
of	O
Maxout	Task
)	O
.	O

The	O
feature	O
map	O
is	O
computed	O
as	O
follows	O
:	O
where	O
is	O
the	O
input	O
channel	O
,	O
is	O
the	O
sub	O
-	O
kernel	O
for	O
that	O
channel	O
,	O
is	O
the	O
convolution	Method
operation	Method
and	O
is	O
a	O
bias	O
term	O
.	O

In	O
other	O
words	O
,	O
the	O
affine	O
operation	O
being	O
performed	O
for	O
each	O
feature	O
map	O
is	O
the	O
sum	O
of	O
the	O
application	O
of	O
different	O
2	Method
-	Method
dimensional	Method
convolution	Method
filters	Method
(	O
one	O
per	O
input	O
channel	O
/	O
modality	O
)	O
,	O
plus	O
a	O
bias	O
term	O
which	O
is	O
added	O
pixel	O
-	O
wise	O
to	O
each	O
resulting	O
spatial	O
position	O
.	O

Though	O
the	O
input	O
to	O
this	O
operation	O
is	O
a	O
3	O
-	O
dimensional	O
tensor	O
,	O
the	O
spatial	O
topology	O
being	O
considered	O
is	O
2	O
-	O
dimensional	O
in	O
the	O
X	O
-	O
Y	O
axial	O
plane	O
of	O
the	O
original	O
brain	O
volume	O
.	O

Whereas	O
traditional	O
image	Method
feature	Method
extraction	Method
methods	Method
rely	O
on	O
a	O
fixed	O
recipe	O
(	O
sometimes	O
taking	O
the	O
form	O
of	O
convolution	Method
with	O
a	O
linear	Method
e.g.	Method
Gabor	Method
filter	Method
bank	Method
)	O
,	O
the	O
key	O
to	O
the	O
success	O
of	O
convolutional	Method
neural	Method
networks	Method
is	O
their	O
ability	O
to	O
learn	O
the	O
weights	O
and	O
biases	O
of	O
individual	O
feature	O
maps	O
,	O
giving	O
rise	O
to	O
data	O
-	O
driven	O
,	O
customized	O
,	O
task	Task
-	Task
specific	Task
dense	Task
feature	Task
extractors	Task
.	O

These	O
parameters	O
are	O
adapted	O
via	O
stochastic	Method
gradient	Method
descent	Method
on	O
a	O
surrogate	Metric
loss	Metric
function	Metric
related	O
to	O
the	O
misclassification	Metric
error	Metric
,	O
with	O
gradients	O
computed	O
efficiently	O
via	O
the	O
backpropagation	Method
algorithm	Method
.	O

Special	O
attention	O
must	O
be	O
paid	O
to	O
the	O
treatment	O
of	O
border	O
pixels	O
by	O
the	O
convolution	Method
operation	Method
.	O

Throughout	O
our	O
architecture	O
,	O
we	O
employ	O
the	O
so	O
-	O
called	O
valid	Method
-	Method
mode	Method
convolution	Method
,	O
meaning	O
that	O
the	O
filter	O
response	O
is	O
not	O
computed	O
for	O
pixel	O
positions	O
that	O
are	O
less	O
than	O
pixels	O
away	O
from	O
the	O
image	O
border	O
.	O

An	O
filter	Method
convolved	O
with	O
an	O
input	O
patch	O
will	O
result	O
in	O
a	O
output	O
,	O
where	O
.	O

In	O
Figure	O
[	O
reference	O
]	O
,	O
,	O
and	O
thus	O
.	O

Note	O
that	O
the	O
size	O
(	O
spatial	O
width	O
and	O
height	O
)	O
of	O
the	O
kernels	O
are	O
hyper	O
-	O
parameters	O
that	O
must	O
be	O
specified	O
by	O
the	O
user	O
.	O

Non	Method
-	Method
linear	Method
activation	Method
function	Method
:	O
To	O
obtain	O
features	O
that	O
are	O
non	O
-	O
linear	O
transformations	O
of	O
the	O
input	O
,	O
an	O
element	Method
-	Method
wise	Method
non	Method
-	Method
linearity	Method
is	O
applied	O
to	O
the	O
result	O
of	O
the	O
kernel	Method
convolution	Method
.	O

There	O
are	O
multiple	O
choices	O
for	O
this	O
non	O
-	O
linearity	O
,	O
such	O
as	O
the	O
sigmoid	O
,	O
hyperbolic	O
tangent	O
and	O
rectified	Method
linear	Method
functions	Method
,	O
.	O

Recently	O
,	O
proposed	O
a	O
Maxout	Method
non	Method
-	Method
linearity	Method
,	O
which	O
has	O
been	O
shown	O
to	O
be	O
particularly	O
effective	O
at	O
modeling	O
useful	O
features	O
.	O

Maxout	O
features	O
are	O
associated	O
with	O
multiple	O
kernels	O
.	O

This	O
implies	O
each	O
Maxout	Method
map	Method
is	O
associated	O
with	O
feature	O
maps	O
:	O
.	O

Note	O
that	O
in	O
Figure	O
[	O
reference	O
]	O
,	O
the	O
Maxout	O
maps	O
are	O
associated	O
with	O
feature	O
maps	O
.	O

Maxout	O
features	O
correspond	O
to	O
taking	O
the	O
max	O
over	O
the	O
feature	O
maps	O
,	O
individually	O
for	O
each	O
spatial	O
position	O
:	O
where	O
are	O
spatial	O
positions	O
.	O

Maxout	O
features	O
are	O
thus	O
equivalent	O
to	O
using	O
a	O
convex	O
activation	O
function	O
,	O
but	O
whose	O
shape	O
is	O
adaptive	O
and	O
depends	O
on	O
the	O
values	O
taken	O
by	O
the	O
kernels	O
.	O

Max	Method
pooling	Method
:	O
This	O
operation	O
consists	O
of	O
taking	O
the	O
maximum	O
feature	O
(	O
neuron	O
)	O
value	O
over	O
sub	O
-	O
windows	O
within	O
each	O
feature	O
map	O
.	O

This	O
can	O
be	O
formalized	O
as	O
follows	O
:	O
where	O
determines	O
the	O
max	O
pooling	O
window	O
size	O
.	O

The	O
sub	O
-	O
windows	O
can	O
be	O
overlapping	O
or	O
not	O
(	O
Figure	O
[	O
reference	O
]	O
shows	O
an	O
overlapping	O
configuration	O
)	O
.	O

The	O
max	Method
-	Method
pooling	Method
operation	Method
shrinks	O
the	O
size	O
of	O
the	O
feature	O
map	O
.	O

This	O
is	O
controlled	O
by	O
the	O
pooling	O
size	O
and	O
the	O
stride	O
hyper	O
-	O
parameter	O
,	O
which	O
corresponds	O
to	O
the	O
horizontal	O
and	O
vertical	O
increments	O
at	O
which	O
pooling	O
sub	O
-	O
windows	O
are	O
positioned	O
.	O

Let	O
be	O
the	O
stride	O
value	O
and	O
be	O
the	O
shape	O
of	O
the	O
feature	Method
map	Method
before	O
max	Method
-	Method
pooling	Method
.	O

The	O
output	O
of	O
the	O
max	Method
-	Method
pooling	Method
operation	Method
would	O
be	O
of	O
size	O
,	O
where	O
.	O

In	O
Figure	O
[	O
reference	O
]	O
,	O
since	O
,	O
the	O
max	Method
-	Method
pooling	Method
operation	Method
results	O
into	O
a	O
output	O
feature	O
map	O
.	O

The	O
motivation	O
for	O
this	O
operation	O
is	O
to	O
introduce	O
invariance	O
to	O
local	O
translations	O
.	O

This	O
subsampling	Method
procedure	Method
has	O
been	O
found	O
beneficial	O
in	O
other	O
applications	O
.	O

Convolutional	Method
networks	Method
have	O
the	O
ability	O
to	O
extract	O
a	O
hierarchy	O
of	O
increasingly	O
complex	O
features	O
which	O
makes	O
them	O
very	O
appealing	O
.	O

This	O
is	O
done	O
by	O
treating	O
the	O
output	O
feature	O
maps	O
of	O
a	O
convolutional	Method
layer	Method
as	O
input	O
channels	O
to	O
the	O
subsequent	O
convolutional	Method
layer	Method
.	O

From	O
the	O
neural	Method
network	Method
perspective	Method
,	O
feature	O
maps	O
correspond	O
to	O
a	O
layer	O
of	O
hidden	O
units	O
or	O
neurons	O
.	O

Specifically	O
,	O
each	O
coordinate	O
within	O
a	O
feature	O
map	O
corresponds	O
to	O
an	O
individual	O
neuron	O
,	O
for	O
which	O
the	O
size	O
of	O
its	O
receptive	O
field	O
corresponds	O
to	O
the	O
kernel	O
’s	O
size	O
.	O

A	O
kernel	O
’s	O
value	O
also	O
represents	O
the	O
weights	O
of	O
the	O
connections	O
between	O
the	O
layer	O
’s	O
neurons	O
and	O
the	O
neurons	O
in	O
the	O
previous	O
layer	O
.	O

It	O
is	O
often	O
found	O
in	O
practice	O
that	O
the	O
learned	O
kernels	Method
resemble	O
edge	Method
detectors	Method
,	O
each	O
kernel	O
being	O
tuned	O
to	O
a	O
different	O
spatial	O
frequency	O
,	O
scale	O
and	O
orientation	O
,	O
as	O
is	O
appropriate	O
for	O
the	O
statistics	O
of	O
the	O
training	O
data	O
.	O

Finally	O
,	O
to	O
perform	O
a	O
prediction	Task
of	Task
the	Task
segmentation	Task
labels	Task
,	O
we	O
connect	O
the	O
last	O
convolutional	O
hidden	O
layer	O
to	O
a	O
convolutional	Method
output	Method
layer	Method
followed	O
by	O
a	O
non	O
-	O
linearity	O
(	O
i.e.	O
no	O
pooling	O
is	O
performed	O
)	O
.	O

It	O
is	O
necessary	O
to	O
note	O
that	O
,	O
for	O
segmentation	Task
purposes	Task
,	O
a	O
conventional	O
CNN	Method
will	O
not	O
yield	O
an	O
efficient	O
test	Metric
time	Metric
since	O
the	O
output	Method
layer	Method
is	O
typically	O
fully	O
connected	O
.	O

By	O
using	O
a	O
convolution	Method
at	O
the	O
end	O
,	O
for	O
which	O
we	O
have	O
an	O
efficient	O
implementation	O
,	O
the	O
prediction	Task
at	O
test	O
time	O
for	O
a	O
whole	O
brain	O
will	O
be	O
45	O
times	O
faster	O
.	O

The	O
convolution	Method
uses	O
as	O
many	O
kernels	O
as	O
there	O
are	O
different	O
segmentation	O
labels	O
(	O
in	O
our	O
case	O
five	O
)	O
.	O

Each	O
kernel	O
thus	O
acts	O
as	O
the	O
ultimate	O
detector	Method
of	Method
tissue	Method
from	O
one	O
of	O
the	O
segmentation	O
labels	O
.	O

We	O
use	O
the	O
softmax	Method
non	Method
-	Method
linearity	Method
which	O
normalizes	O
the	O
result	O
of	O
the	O
kernel	Method
convolutions	Method
into	O
a	O
multinominal	O
distribution	O
over	O
the	O
labels	O
.	O

Specifically	O
,	O
let	O
be	O
the	O
vector	O
of	O
values	O
at	O
a	O
given	O
spatial	O
position	O
,	O
it	O
computes	O
where	O
is	O
a	O
normalization	O
constant	O
.	O

More	O
details	O
will	O
be	O
discussed	O
in	O
Section	O
[	O
reference	O
]	O
.	O

Noting	O
as	O
the	O
segmentation	O
label	O
field	O
over	O
the	O
input	O
patch	O
,	O
we	O
can	O
thus	O
interpret	O
each	O
spatial	O
position	O
of	O
the	O
convolutional	Method
output	Method
layer	Method
as	O
providing	O
a	O
model	O
for	O
the	O
likelihood	O
distribution	O
,	O
where	O
is	O
the	O
label	O
at	O
position	O
.	O

We	O
get	O
the	O
probability	O
of	O
all	O
labels	O
simply	O
by	O
taking	O
the	O
product	O
of	O
each	O
conditional	O
.	O

Our	O
approach	O
thus	O
performs	O
a	O
multiclass	Task
labeling	Task
by	O
assigning	O
to	O
each	O
pixel	O
the	O
label	O
with	O
the	O
largest	O
probability	O
.	O

subsection	O
:	O
The	O
Architectures	O
Our	O
description	O
of	O
CNNs	Method
so	O
far	O
suggests	O
a	O
simple	O
architecture	O
corresponding	O
to	O
a	O
single	O
stack	O
of	O
several	O
convolutional	Method
layers	Method
.	O

This	O
configuration	O
is	O
the	O
most	O
commonly	O
implemented	O
architecture	O
in	O
the	O
computer	Task
vision	Task
literature	Task
.	O

However	O
,	O
one	O
could	O
imagine	O
other	O
architectures	O
that	O
might	O
be	O
more	O
appropriate	O
for	O
the	O
task	O
at	O
hand	O
.	O

In	O
this	O
work	O
,	O
we	O
explore	O
a	O
variety	O
of	O
architectures	O
by	O
using	O
the	O
concatenation	O
of	O
feature	O
maps	O
from	O
different	O
layers	O
as	O
another	O
operation	O
when	O
composing	O
CNNs	Method
.	O

This	O
operation	O
allows	O
us	O
to	O
construct	O
architectures	O
with	O
multiple	O
computational	O
paths	O
,	O
which	O
can	O
each	O
serve	O
a	O
different	O
purpose	O
.	O

We	O
now	O
describe	O
the	O
two	O
types	O
of	O
architectures	O
that	O
we	O
explore	O
in	O
this	O
work	O
.	O

subsubsection	Method
:	O
Two	Method
-	Method
pathway	Method
architecture	Method
This	O
architecture	O
is	O
made	O
of	O
two	O
streams	O
:	O
a	O
pathway	O
with	O
smaller	O
receptive	O
fields	O
and	O
another	O
with	O
larger	O
receptive	O
fields	O
.	O

We	O
refer	O
to	O
these	O
streams	O
as	O
the	O
local	O
pathway	O
and	O
the	O
global	O
pathway	O
,	O
respectively	O
.	O

The	O
motivation	O
for	O
this	O
architectural	O
choice	O
is	O
that	O
we	O
would	O
like	O
the	O
prediction	O
of	O
the	O
label	O
of	O
a	O
pixel	O
to	O
be	O
influenced	O
by	O
two	O
aspects	O
:	O
the	O
visual	O
details	O
of	O
the	O
region	O
around	O
that	O
pixel	O
and	O
its	O
larger	O
“	O
context	O
”	O
,	O
i.e.	O
roughly	O
where	O
the	O
patch	O
is	O
in	O
the	O
brain	O
.	O

The	O
full	O
architecture	O
along	O
with	O
its	O
details	O
is	O
illustrated	O
in	O
Figure	O
[	O
reference	O
]	O
.	O

We	O
refer	O
to	O
this	O
architecture	O
as	O
the	O
TwoPathCNN	O
.	O

To	O
allow	O
for	O
the	O
concatenation	O
of	O
the	O
top	O
hidden	O
layers	O
of	O
both	O
pathways	O
,	O
we	O
use	O
two	O
layers	O
for	O
the	O
local	O
pathway	O
,	O
with	O
kernels	Method
for	O
the	O
second	O
layer	O
.	O

While	O
this	O
implies	O
that	O
the	O
effective	O
receptive	O
field	O
of	O
features	O
in	O
the	O
top	O
layer	O
of	O
each	O
pathway	O
is	O
the	O
same	O
,	O
the	O
global	Method
pathway	Method
’s	O
parametrization	O
more	O
directly	O
and	O
flexibly	O
models	O
features	O
in	O
that	O
same	O
area	O
.	O

The	O
concatenation	O
of	O
the	O
feature	O
maps	O
of	O
both	O
pathways	O
is	O
then	O
fed	O
to	O
the	O
output	Method
layer	Method
.	O

subsubsection	Method
:	O
Cascaded	Method
architectures	Method
One	O
disadvantage	O
of	O
the	O
CNNs	Method
described	O
so	O
far	O
is	O
that	O
they	O
predict	O
each	O
segmentation	O
label	O
separately	O
from	O
each	O
other	O
.	O

This	O
is	O
unlike	O
a	O
large	O
number	O
of	O
segmentation	Method
methods	Method
in	O
the	O
literature	O
,	O
which	O
often	O
propose	O
a	O
joint	Method
model	Method
of	O
the	O
segmentation	O
labels	O
,	O
effectively	O
modeling	O
the	O
direct	O
dependencies	O
between	O
spatially	O
close	O
labels	O
.	O

One	O
approach	O
is	O
to	O
define	O
a	O
conditional	Method
random	Method
field	Method
(	Method
CRF	Method
)	O
over	O
the	O
labels	O
and	O
perform	O
mean	Method
-	Method
field	Method
message	Method
passing	Method
inference	Method
to	O
produce	O
a	O
complete	Task
segmentation	Task
.	O

In	O
this	O
case	O
,	O
the	O
final	O
label	O
at	O
a	O
given	O
position	O
is	O
effectively	O
influenced	O
by	O
the	O
models	O
beliefs	O
about	O
what	O
the	O
label	O
is	O
in	O
the	O
vicinity	O
of	O
that	O
position	O
.	O

On	O
the	O
other	O
hand	O
,	O
inference	Task
in	O
such	O
joint	Method
segmentation	Method
methods	Method
is	O
typically	O
more	O
computationally	O
expensive	O
than	O
a	O
simple	O
feed	Method
-	Method
forward	Method
pass	Method
through	O
a	O
CNN	Method
.	O

This	O
is	O
an	O
important	O
aspect	O
that	O
one	O
should	O
take	O
into	O
account	O
if	O
automatic	Task
brain	Task
tumor	Task
segmentation	Task
is	O
to	O
be	O
used	O
in	O
a	O
day	Task
-	Task
to	Task
-	Task
day	Task
practice	Task
.	O

Here	O
,	O
we	O
describe	O
CNN	Method
architectures	O
that	O
both	O
exploit	O
the	O
efficiency	O
of	O
CNNs	Method
,	O
while	O
also	O
more	O
directly	O
model	O
the	O
dependencies	O
between	O
adjacent	O
labels	O
in	O
the	O
segmentation	Task
.	O

The	O
idea	O
is	O
simple	O
:	O
since	O
we	O
’d	O
like	O
the	O
ultimate	Task
prediction	Task
to	O
be	O
influenced	O
by	O
the	O
model	O
’s	O
beliefs	O
about	O
the	O
value	O
of	O
nearby	O
labels	O
,	O
we	O
propose	O
to	O
feed	O
the	O
output	O
probabilities	O
of	O
a	O
first	O
CNN	Method
as	O
additional	O
inputs	O
to	O
the	O
layers	O
of	O
a	O
second	O
CNN	Method
.	O

Again	O
,	O
we	O
do	O
this	O
by	O
relying	O
on	O
the	O
concatenation	Method
of	Method
convolutional	Method
layers	Method
.	O

In	O
this	O
case	O
,	O
we	O
simply	O
concatenate	O
the	O
output	O
layer	O
of	O
the	O
first	O
CNN	Method
with	O
any	O
of	O
the	O
layers	O
in	O
the	O
second	O
CNN	Method
.	O

Moreover	O
,	O
we	O
use	O
the	O
same	O
two	O
-	O
pathway	O
structure	O
for	O
both	O
CNNs	Method
.	O

This	O
effectively	O
corresponds	O
to	O
a	O
cascade	O
of	O
two	O
CNNs	Method
,	O
thus	O
we	O
refer	O
to	O
such	O
models	O
as	O
cascaded	Method
architectures	Method
.	O

In	O
this	O
work	O
,	O
we	O
investigated	O
three	O
cascaded	Method
architectures	Method
that	O
concatenate	O
the	O
first	O
CNN	Method
’s	O
output	O
at	O
different	O
levels	O
of	O
the	O
second	O
CNN	Method
:	O
Input	Task
concatenation	Task
:	O
In	O
this	O
architecture	O
,	O
we	O
provide	O
the	O
first	O
CNN	Method
’s	O
output	O
directly	O
as	O
input	O
to	O
the	O
second	O
CNN	Method
.	O

They	O
are	O
thus	O
simply	O
treated	O
as	O
additional	O
image	O
channels	O
of	O
the	O
input	O
patch	O
.	O

The	O
details	O
are	O
illustrated	O
in	O
Figure	O
[	O
reference	O
]	O
.	O

We	O
refer	O
to	O
this	O
model	O
as	O
InputCascadeCNN	Method
.	O

Local	Method
pathway	Method
concatenation	Method
:	O
In	O
this	O
architecture	O
,	O
we	O
move	O
up	O
one	O
layer	O
in	O
the	O
local	O
pathway	O
and	O
perform	O
concatenation	Method
to	O
its	O
first	O
hidden	O
layer	O
,	O
in	O
the	O
second	O
CNN	Method
.	O

The	O
details	O
are	O
illustrated	O
in	O
Figure	O
[	O
reference	O
]	O
.	O

We	O
refer	O
to	O
this	O
model	O
as	O
LocalCascadeCNN	Method
.	O

Pre	Method
-	Method
output	Method
concatenation	Method
:	O
In	O
this	O
last	O
architecture	O
,	O
we	O
move	O
to	O
the	O
very	O
end	O
of	O
the	O
second	O
CNN	Method
and	O
perform	O
concatenation	O
right	O
before	O
its	O
output	O
layer	O
.	O

This	O
architecture	O
is	O
interesting	O
,	O
as	O
it	O
is	O
similar	O
to	O
the	O
computations	O
made	O
by	O
one	O
pass	O
of	O
mean	Method
-	Method
field	Method
inference	Method
in	O
a	O
CRF	Method
whose	O
pairwise	O
potential	O
functions	O
are	O
the	O
weights	O
in	O
the	O
output	O
kernels	O
.	O

From	O
this	O
view	O
,	O
the	O
output	O
of	O
the	O
first	O
CNN	Method
is	O
the	O
first	O
iteration	O
of	O
mean	Method
-	Method
field	Method
,	O
while	O
the	O
output	O
of	O
the	O
second	O
CNN	Method
would	O
be	O
the	O
second	O
iteration	O
.	O

The	O
difference	O
with	O
regular	Method
mean	Method
-	Method
field	Method
however	O
is	O
that	O
our	O
CNN	Method
allows	O
the	O
output	O
at	O
one	O
position	O
to	O
be	O
influenced	O
by	O
its	O
previous	O
value	O
,	O
and	O
the	O
convolutional	Method
kernels	Method
are	O
not	O
the	O
same	O
in	O
the	O
first	O
and	O
second	O
CNN	Method
.	O

The	O
details	O
are	O
illustrated	O
in	O
Figure	O
[	O
reference	O
]	O
.	O

We	O
refer	O
to	O
this	O
model	O
as	O
MFCascadeCNN	Method
.	O

[	O
Cascaded	Method
architecture	Method
,	O
using	O
input	Method
concatenation	Method
(	O
InputCascadeCNN	Method
)	O
.	O

]	O
[	O
Cascaded	Method
architecture	Method
,	O
using	O
local	Method
pathway	Method
concatenation	Method
(	O
LocalCascadeCNN	Method
)	O
.	O

]	O
[	O
Cascaded	Method
architecture	Method
,	O
using	O
pre	Method
-	Method
output	Method
concatenation	Method
,	O
which	O
is	O
an	O
architecture	O
with	O
properties	O
similar	O
to	O
that	O
of	O
learning	Task
using	O
a	O
limited	O
number	O
of	O
mean	Method
-	Method
field	Method
inference	Method
iterations	Method
in	O
a	O
CRF	Method
(	O
MFCascadeCNN	Method
)	O
.	O

]	O
subsection	O
:	O
Training	O
paragraph	O
:	O
Gradient	Method
Descent	Method
By	O
interpreting	O
the	O
output	O
of	O
the	O
convolutional	Method
network	Method
as	O
a	O
model	O
for	O
the	O
distribution	Task
over	Task
segmentation	Task
labels	Task
,	O
a	O
natural	O
training	Metric
criteria	Metric
is	O
to	O
maximize	O
the	O
probability	O
of	O
all	O
labels	O
in	O
our	O
training	O
set	O
or	O
,	O
equivalently	O
,	O
to	O
minimize	O
the	O
negative	O
log	O
-	O
probability	O
for	O
each	O
labeled	O
brain	O
.	O

To	O
do	O
this	O
,	O
we	O
follow	O
a	O
stochastic	Method
gradient	Method
descent	Method
approach	Method
by	O
repeatedly	O
selecting	O
labels	O
at	O
a	O
random	O
subset	O
of	O
patches	O
within	O
each	O
brain	O
,	O
computing	O
the	O
average	O
negative	O
log	O
-	O
probabilities	O
for	O
this	O
mini	O
-	O
batch	O
of	O
patches	O
and	O
performing	O
a	O
gradient	Method
descent	Method
step	Method
on	O
the	O
CNNs	Method
parameters	O
(	O
i.e.	O
the	O
kernels	O
at	O
all	O
layers	O
)	O
.	O

Performing	O
updates	O
based	O
only	O
on	O
a	O
small	O
subset	O
of	O
patches	O
allows	O
us	O
to	O
avoid	O
having	O
to	O
process	O
a	O
whole	O
brain	O
for	O
each	O
update	O
,	O
while	O
providing	O
reliable	O
enough	O
updates	O
for	O
learning	Task
.	O

In	O
practice	O
,	O
we	O
implement	O
this	O
approach	O
by	O
creating	O
a	O
dataset	O
of	O
mini	O
-	O
batches	O
of	O
smaller	O
brain	O
image	O
patches	O
,	O
paired	O
with	O
the	O
corresponding	O
center	O
segmentation	O
label	O
as	O
the	O
target	O
.	O

To	O
further	O
improve	O
optimization	Task
,	O
we	O
implemented	O
a	O
so	O
-	O
called	O
momentum	Method
strategy	Method
which	O
has	O
been	O
shown	O
successful	O
in	O
the	O
past	O
.	O

The	O
idea	O
of	O
momentum	O
is	O
to	O
use	O
a	O
temporally	O
averaged	O
gradient	O
in	O
order	O
to	O
damp	O
the	O
optimization	O
velocity	O
:	O
where	O
stands	O
for	O
the	O
CNNs	Method
parameters	O
at	O
iteration	O
,	O
the	O
gradient	O
of	O
the	O
loss	O
function	O
at	O
,	O
V	O
is	O
the	O
integrated	O
velocity	O
initialized	O
at	O
zero	O
,	O
is	O
the	O
learning	Metric
rate	Metric
,	O
and	O
the	O
momentum	O
coefficient	O
.	O

We	O
define	O
a	O
schedule	O
for	O
the	O
momentum	O
where	O
the	O
momentum	O
coefficient	O
is	O
gradually	O
increased	O
during	O
training	O
.	O

In	O
our	O
experiments	O
the	O
initial	O
momentum	O
coefficient	O
was	O
set	O
to	O
and	O
the	O
final	O
value	O
was	O
set	O
to	O
.	O

Also	O
,	O
the	O
learning	Metric
rate	Metric
is	O
decreased	O
by	O
a	O
factor	O
at	O
every	O
epoch	O
.	O

The	O
initial	O
learning	Metric
rate	Metric
was	O
set	O
to	O
and	O
the	O
decay	O
factor	O
to	O
.	O

paragraph	O
:	O
Two	O
-	O
phase	O
training	O
Brain	Task
tumor	Task
segmentation	Task
is	O
a	O
highly	O
data	Task
imbalanced	Task
problem	Task
where	O
the	O
healthy	O
voxels	O
(	O
i.e.	O
label	O
0	O
)	O
comprise	O
98	O
%	O
of	O
total	O
voxels	O
.	O

From	O
the	O
remaining	O
2	O
%	O
pathological	O
voxels	O
,	O
0.18	O
%	O
belongs	O
to	O
necrosis	O
(	O
label	O
1	O
)	O
,	O
1.1	O
%	O
to	O
edema	O
(	O
label	O
2	O
)	O
,	O
0.12	O
%	O
to	O
non	O
-	O
enhanced	O
(	O
label	O
3	O
)	O
and	O
0.38	O
%	O
to	O
enhanced	O
tumor	O
(	O
label	O
4	O
)	O
.	O

Selecting	O
patches	O
from	O
the	O
true	O
distribution	O
would	O
cause	O
the	O
model	O
to	O
be	O
overwhelmed	O
by	O
healthy	O
patches	O
and	O
causing	O
problem	O
when	O
training	O
out	O
CNN	Method
models	O
.	O

Instead	O
,	O
we	O
initially	O
construct	O
our	O
patches	O
dataset	O
such	O
that	O
all	O
labels	O
are	O
equiprobable	O
.	O

This	O
is	O
what	O
we	O
call	O
the	O
first	O
training	O
phase	O
.	O

Then	O
,	O
in	O
a	O
second	O
phase	O
,	O
we	O
account	O
for	O
the	O
un	O
-	O
balanced	O
nature	O
of	O
the	O
data	O
and	O
re	O
-	O
train	O
only	O
the	O
output	O
layer	O
(	O
i.e.	O
keeping	O
the	O
kernels	O
of	O
all	O
other	O
layers	O
fixed	O
)	O
with	O
a	O
more	O
representative	O
distribution	O
of	O
the	O
labels	O
.	O

This	O
way	O
we	O
get	O
the	O
best	O
of	O
both	O
worlds	O
:	O
most	O
of	O
the	O
capacity	O
(	O
the	O
lower	O
layers	O
)	O
is	O
used	O
in	O
a	O
balanced	O
way	O
to	O
account	O
for	O
the	O
diversity	O
in	O
all	O
of	O
the	O
classes	O
,	O
while	O
the	O
output	O
probabilities	O
are	O
calibrated	O
correctly	O
(	O
thanks	O
to	O
the	O
re	O
-	O
training	O
of	O
the	O
output	O
layer	O
with	O
the	O
natural	O
frequencies	O
of	O
classes	O
in	O
the	O
data	O
)	O
.	O

paragraph	O
:	O
Regularization	O
Successful	O
CNNs	Method
tend	O
to	O
be	O
models	O
with	O
a	O
lot	O
of	O
capacity	O
,	O
making	O
them	O
vulnerable	O
to	O
overfitting	O
in	O
a	O
setting	O
like	O
ours	O
where	O
there	O
clearly	O
are	O
not	O
enough	O
training	O
examples	O
.	O

Accordingly	O
,	O
we	O
found	O
that	O
regularization	Method
is	O
important	O
in	O
obtaining	O
good	O
results	O
.	O

Here	O
,	O
regularization	Method
took	O
several	O
forms	O
.	O

First	O
,	O
in	O
all	O
layers	O
,	O
we	O
bounded	O
the	O
absolute	O
value	O
of	O
the	O
kernel	O
weights	O
and	O
applied	O
both	O
L1	Method
and	Method
L2	Method
regularization	Method
to	O
prevent	O
overfitting	O
.	O

This	O
is	O
done	O
by	O
adding	O
the	O
regularization	O
terms	O
to	O
the	O
negative	O
log	O
-	O
probability	O
(	O
i.e.	O
,	O
where	O
and	O
are	O
coefficients	O
for	O
L1	O
and	O
L2	O
regularization	O
terms	O
respectively	O
)	O
.	O

L1	O
and	O
L2	O
affect	O
the	O
parameters	O
of	O
the	O
model	O
in	O
different	O
ways	O
,	O
while	O
L1	O
encourages	O
sparsity	O
,	O
L2	O
encourages	O
small	O
values	O
.	O

We	O
also	O
used	O
a	O
validation	O
set	O
for	O
early	Task
stopping	Task
,	O
i.e.	O
stop	O
training	O
when	O
the	O
validation	Metric
performance	Metric
stopped	O
improving	O
.	O

The	O
validation	O
set	O
was	O
also	O
used	O
to	O
tune	O
the	O
other	O
hyper	O
-	O
parameters	O
of	O
the	O
model	O
.	O

The	O
reader	O
shall	O
note	O
that	O
the	O
hyper	O
-	O
parameters	O
of	O
the	O
model	O
which	O
includes	O
using	O
or	O
not	O
L2	O
and	O
/	O
or	O
L1	O
coefficients	O
were	O
selected	O
by	O
doing	O
a	O
grid	Method
search	Method
over	O
range	O
of	O
parameters	O
.	O

The	O
chosen	O
hyper	O
-	O
parameters	O
were	O
the	O
ones	O
for	O
which	O
the	O
model	O
performed	O
best	O
on	O
a	O
validation	O
set	O
.	O

Moreover	O
,	O
we	O
used	O
Dropout	Method
,	O
a	O
recent	O
regularization	Method
method	Method
that	O
works	O
by	O
stochastically	O
adding	O
noise	O
in	O
the	O
computation	O
of	O
the	O
hidden	O
layers	O
of	O
the	O
CNN	Method
.	O

This	O
is	O
done	O
by	O
multiplying	O
each	O
hidden	O
or	O
input	O
unit	O
by	O
0	O
(	O
i.e.	O
masking	O
)	O
with	O
a	O
certain	O
probability	O
(	O
e.g.	O
0.5	O
)	O
,	O
independently	O
for	O
each	O
unit	O
and	O
training	O
update	O
.	O

This	O
encourages	O
the	O
neural	Method
network	Method
to	O
learn	O
features	O
that	O
are	O
useful	O
“	O
on	O
their	O
own	O
”	O
,	O
since	O
each	O
unit	O
can	O
not	O
assume	O
that	O
other	O
units	O
in	O
the	O
same	O
layer	O
wo	O
n’t	O
be	O
masked	O
as	O
well	O
and	O
co	O
-	O
adapt	O
its	O
behavior	O
.	O

At	O
test	O
time	O
,	O
units	O
are	O
instead	O
multiplied	O
by	O
one	O
minus	O
the	O
probability	O
of	O
being	O
masked	O
.	O

For	O
more	O
details	O
,	O
see	O
.	O

Considering	O
the	O
large	O
number	O
of	O
parameters	O
our	O
model	O
has	O
,	O
one	O
might	O
think	O
that	O
even	O
with	O
our	O
regularization	Method
strategy	Method
,	O
the	O
30	O
training	O
brains	O
from	O
BRATS	Material
2013	Material
are	O
too	O
few	O
to	O
prevent	O
overfitting	O
.	O

But	O
as	O
will	O
be	O
shown	O
in	O
the	O
results	O
section	O
,	O
our	O
model	O
generalizes	O
well	O
and	O
thus	O
do	O
not	O
overfit	O
.	O

One	O
reason	O
for	O
this	O
is	O
the	O
fact	O
that	O
each	O
brain	O
comes	O
with	O
200	O
2d	O
slices	O
and	O
thus	O
,	O
our	O
model	O
has	O
approximately	O
6000	O
2D	O
images	O
to	O
train	O
on	O
.	O

We	O
shall	O
also	O
mention	O
that	O
by	O
their	O
very	O
nature	O
,	O
MRI	Method
images	O
of	O
brains	O
are	O
very	O
similar	O
from	O
one	O
patient	O
to	O
another	O
.	O

Since	O
the	O
variety	O
of	O
those	O
images	O
is	O
much	O
lower	O
than	O
those	O
in	O
real	O
-	O
image	O
datasets	O
such	O
as	O
CIFAR	Material
and	O
ImageNet	Material
,	O
a	O
fewer	O
number	O
of	O
training	O
samples	O
is	O
thus	O
needed	O
.	O

paragraph	O
:	O
Cascaded	Method
Architectures	Method
To	O
train	O
a	O
cascaded	Method
architecture	Method
,	O
we	O
start	O
by	O
training	O
the	O
TwoPathCNN	Method
with	O
the	O
two	Method
phase	Method
stochastic	Method
gradient	Method
descent	Method
procedure	Method
described	O
previously	O
.	O

Then	O
,	O
we	O
fix	O
the	O
parameters	O
of	O
the	O
TwoPathCNN	O
and	O
include	O
it	O
in	O
the	O
cascaded	Method
architecture	Method
(	O
be	O
it	O
the	O
InputCascadeCNN	Method
,	O
the	O
LocalCascadeCNN	Method
,	O
or	O
the	O
MFCascadeCNN	Method
)	O
and	O
move	O
to	O
training	O
the	O
remaining	O
parameters	O
using	O
a	O
similar	O
procedure	O
.	O

It	O
should	O
be	O
noticed	O
however	O
that	O
for	O
the	O
spatial	O
size	O
of	O
the	O
first	O
CNN	Method
’s	O
output	O
and	O
the	O
layer	O
of	O
the	O
second	O
CNN	Method
to	O
match	O
,	O
we	O
must	O
feed	O
to	O
the	O
first	O
CNN	Method
a	O
much	O
larger	O
input	O
.	O

Thus	O
,	O
training	O
of	O
the	O
second	O
CNN	Method
must	O
be	O
performed	O
on	O
larger	O
patches	O
.	O

For	O
example	O
in	O
the	O
InputCascadeCNN	Method
(	O
Figure	O
[	O
reference	O
]	O
)	O
,	O
the	O
input	O
size	O
to	O
the	O
first	O
model	O
is	O
of	O
size	O
which	O
results	O
into	O
an	O
output	O
of	O
size	O
.	O

Only	O
in	O
this	O
case	O
the	O
outputs	O
of	O
the	O
first	O
CNN	Method
can	O
be	O
concatenated	O
with	O
the	O
input	O
channels	O
of	O
the	O
second	O
CNN	Method
.	O

section	O
:	O
Implementation	O
details	O
Our	O
implementation	O
is	O
based	O
on	O
the	O
Pylearn2	Method
library	Method
.	O

Pylearn2	Method
is	O
an	O
open	O
-	O
source	O
machine	Method
learning	Method
library	Method
specializing	O
in	O
deep	Method
learning	Method
algorithms	Method
.	O

It	O
also	O
supports	O
the	O
use	O
of	O
GPUs	Method
,	O
which	O
can	O
greatly	O
accelerate	O
the	O
execution	O
of	O
deep	Method
learning	Method
algorithms	Method
.	O

Since	O
CNN	Method
’s	O
are	O
able	O
to	O
learn	O
useful	O
features	O
from	O
scratch	O
,	O
we	O
applied	O
only	O
minimal	Method
pre	Method
-	Method
processing	Method
.	O

We	O
employed	O
the	O
same	O
pre	Method
-	Method
processing	Method
as	O
Tustison	O
et	O
al	O
.	O

,	O
the	O
winner	O
of	O
the	O
2013	O
BRATS	Material
challenge	O
.	O

The	O
pre	Task
-	Task
processing	Task
follows	O
three	O
steps	O
.	O

First	O
,	O
the	O
1	O
%	O
highest	O
and	O
lowest	O
intensities	O
are	O
removed	O
.	O

Then	O
,	O
we	O
apply	O
an	O
N4ITK	Method
bias	Method
correction	Method
to	O
T1	O
and	O
T1C	O
modalities	O
.	O

The	O
data	O
is	O
then	O
normalized	O
within	O
each	O
input	O
channel	O
by	O
subtracting	O
the	O
channel	O
’s	O
mean	O
and	O
dividing	O
by	O
the	O
channel	O
’s	O
standard	O
deviation	O
.	O

As	O
for	O
post	Task
-	Task
processing	Task
,	O
a	O
simple	O
method	O
based	O
on	O
connected	Method
components	Method
was	O
implemented	O
to	O
remove	O
flat	O
blobs	O
which	O
might	O
appear	O
in	O
the	O
predictions	O
due	O
to	O
bright	O
corners	O
of	O
the	O
brains	O
close	O
to	O
the	O
skull	O
.	O

The	O
hyper	O
-	O
parameters	O
of	O
the	O
different	O
architectures	O
(	O
kernel	O
and	O
max	O
pooling	O
size	O
for	O
each	O
layer	O
and	O
the	O
number	O
of	O
layers	O
)	O
can	O
be	O
seen	O
in	O
Figure	O
[	O
reference	O
]	O
.	O

Hyper	O
-	O
parameters	O
were	O
tuned	O
using	O
grid	Method
search	Method
and	O
cross	Method
-	Method
validation	Method
on	O
a	O
validation	O
set	O
(	O
see	O
)	O
.	O

The	O
chosen	O
hyper	O
-	O
parameters	O
were	O
the	O
ones	O
for	O
which	O
the	O
model	O
performed	O
best	O
on	O
the	O
validation	O
set	O
.	O

For	O
max	Task
pooling	Task
,	O
we	O
always	O
use	O
a	O
stride	O
of	O
1	O
.	O

This	O
is	O
to	O
keep	O
per	O
-	O
pixel	Metric
accuracy	Metric
during	O
full	Task
image	Task
prediction	Task
.	O

We	O
observed	O
in	O
practice	O
that	O
max	Method
pooling	Method
in	O
the	O
global	O
path	O
does	O
not	O
improve	O
accuracy	Metric
.	O

We	O
also	O
found	O
that	O
adding	O
additional	O
layers	O
to	O
the	O
architectures	O
or	O
increasing	O
the	O
capacity	O
of	O
the	O
model	O
by	O
adding	O
additional	O
feature	O
maps	O
to	O
the	O
convolutional	O
blocks	O
do	O
not	O
provide	O
any	O
meaningful	O
performance	O
improvement	O
.	O

Biases	O
are	O
initialized	O
to	O
zero	O
except	O
for	O
the	O
softmax	Method
layer	Method
for	O
which	O
we	O
initialized	O
them	O
to	O
the	O
of	O
the	O
label	O
frequencies	O
.	O

The	O
kernels	O
are	O
randomly	O
initialized	O
from	O
.	O

Training	Task
takes	O
about	O
3	O
minutes	O
per	O
epoch	O
for	O
the	O
TwoPathCNN	Method
model	Method
on	O
an	O
NVIDIA	Method
Titan	Method
black	Method
card	Method
.	O

At	O
test	O
time	O
,	O
we	O
run	O
our	O
code	O
on	O
a	O
GPU	Method
in	O
order	O
to	O
exploit	O
its	O
computational	Metric
speed	Metric
.	O

Moreover	O
,	O
the	O
convolutional	O
nature	O
of	O
the	O
output	Method
layer	Method
allows	O
us	O
to	O
further	O
accelerate	O
computations	O
at	O
test	O
time	O
.	O

This	O
is	O
done	O
by	O
feeding	O
as	O
input	O
a	O
full	O
image	O
and	O
not	O
individual	O
patches	O
.	O

Therefore	O
,	O
convolutions	Method
at	O
all	O
layers	O
can	O
be	O
extended	O
to	O
obtain	O
all	O
label	O
probabilities	O
for	O
the	O
entire	O
image	O
.	O

With	O
this	O
implementation	O
,	O
we	O
are	O
able	O
to	O
produce	O
a	O
segmentation	Task
in	O
25	O
seconds	O
per	O
brain	O
on	O
the	O
Titan	Method
black	Method
card	Method
with	O
the	O
TwoPathCNN	Method
model	Method
.	O

This	O
turns	O
out	O
to	O
be	O
45	O
times	O
faster	O
than	O
when	O
we	O
extracted	O
a	O
patch	O
at	O
each	O
pixel	O
and	O
processed	O
them	O
individually	O
for	O
the	O
entire	O
brain	O
.	O

Predictions	Task
for	O
the	O
MFCascadeCNN	Method
model	Method
,	O
the	O
LocalCascadeCNN	Method
model	Method
,	O
and	O
InputCascadeCNN	Method
model	O
take	O
on	O
average	O
1.5	O
minutes	O
,	O
1.7	O
minutes	O
and	O
3	O
minutes	O
respectively	O
.	O

section	O
:	O
Experiments	O
and	O
Results	O
The	O
experiments	O
were	O
carried	O
out	O
on	O
real	O
patient	O
data	O
obtained	O
from	O
the	O
2013	O
brain	Material
tumor	Material
segmentation	Material
challenge	Material
(	O
BRATS2013	Material
)	O
,	O
as	O
part	O
of	O
the	O
MICCAI	Material
conference	Material
.	O

The	O
BRATS2013	Material
dataset	Material
is	O
comprised	O
of	O
3	O
sub	O
-	O
datasets	O
.	O

The	O
training	O
dataset	O
,	O
which	O
contains	O
30	O
patient	O
subjects	O
all	O
with	O
pixel	O
-	O
accurate	O
ground	O
truth	O
(	O
20	O
high	O
grade	O
and	O
10	O
low	O
grade	O
tumors	O
)	O
;	O
the	O
test	O
dataset	O
which	O
contains	O
10	O
(	O
all	O
high	O
grade	O
tumors	O
)	O
and	O
the	O
leaderboard	O
dataset	O
which	O
contains	O
25	O
patient	O
subjects	O
(	O
21	O
high	O
grade	O
and	O
4	O
low	O
grade	O
tumors	O
)	O
.	O

There	O
is	O
no	O
ground	O
truth	O
provided	O
for	O
the	O
test	O
and	O
leaderboard	O
datasets	O
.	O

All	O
brains	O
in	O
the	O
dataset	O
have	O
the	O
same	O
orientation	O
.	O

For	O
each	O
brain	O
there	O
exists	O
4	O
modalities	O
,	O
namely	O
T1	O
,	O
T1C	O
,	O
T2	O
and	O
Flair	O
which	O
are	O
co	O
-	O
registered	O
.	O

The	O
training	O
brains	O
come	O
with	O
groundtruth	O
for	O
which	O
5	O
segmentation	O
labels	O
are	O
provided	O
,	O
namely	O
non	O
-	O
tumor	O
,	O
necrosis	O
,	O
edema	O
,	O
non	O
-	O
enhancing	O
tumor	O
and	O
enhancing	O
tumor	O
.	O

Figure	O
[	O
reference	O
]	O
shows	O
an	O
example	O
of	O
the	O
data	O
as	O
well	O
as	O
the	O
ground	O
truth	O
.	O

In	O
total	O
,	O
the	O
model	O
iterates	O
over	O
about	O
2.2	O
million	O
examples	O
of	O
tumorous	O
patches	O
(	O
this	O
consists	O
of	O
all	O
the	O
4	O
sub	O
-	O
tumor	O
classes	O
)	O
and	O
goes	O
through	O
3.2	O
million	O
of	O
the	O
healthy	O
patches	O
.	O

As	O
mentioned	O
before	O
during	O
the	O
first	O
phase	O
training	O
,	O
the	O
distribution	O
of	O
examples	O
introduced	O
to	O
the	O
model	O
from	O
all	O
5	O
classes	O
is	O
uniform	O
.	O

Please	O
note	O
that	O
we	O
could	O
not	O
use	O
the	O
BRATS	Material
2014	Material
dataset	Material
due	O
to	O
problems	O
with	O
both	O
the	O
system	O
performing	O
the	O
evaluation	Metric
and	O
the	O
quality	O
of	O
the	O
labeled	O
data	O
.	O

For	O
these	O
reasons	O
the	O
old	O
BRATS	Material
2014	Material
dataset	Material
has	O
been	O
removed	O
from	O
the	O
official	O
website	O
and	O
,	O
at	O
the	O
time	O
of	O
submitting	O
this	O
manuscript	O
,	O
the	O
BRATS	Material
website	O
still	O
showed	O
:	O
“	O
Final	O
data	O
for	O
BRATS	Material
2014	O
to	O
be	O
released	O
soon	O
”	O
.	O

Furthermore	O
,	O
we	O
have	O
even	O
conducted	O
an	O
experiment	O
where	O
we	O
trained	O
our	O
model	O
with	O
the	O
old	O
2014	O
dataset	O
and	O
made	O
predictions	O
on	O
the	O
2013	O
test	O
dataset	O
;	O
however	O
,	O
the	O
performance	O
was	O
worse	O
than	O
our	O
results	O
mentioned	O
in	O
this	O
paper	O
.	O

For	O
these	O
reasons	O
,	O
we	O
decided	O
to	O
focus	O
on	O
the	O
BRATS	Material
2013	O
data	O
.	O

As	O
mentioned	O
in	O
Section	O
[	O
reference	O
]	O
,	O
we	O
work	O
with	O
2D	O
slices	O
due	O
to	O
the	O
fact	O
that	O
the	O
MRI	Method
volumes	O
in	O
the	O
dataset	O
do	O
not	O
posses	O
an	O
isotropic	O
resolution	O
and	O
the	O
spacing	O
in	O
the	O
third	O
dimension	O
is	O
not	O
consistent	O
across	O
the	O
data	O
.	O

We	O
explored	O
the	O
use	O
of	O
3D	O
information	O
(	O
by	O
treating	O
the	O
third	O
dimension	O
as	O
extra	O
input	O
channels	O
or	O
by	O
having	O
an	O
architecture	O
which	O
takes	O
orthogonal	O
slices	O
from	O
each	O
view	O
and	O
makes	O
the	O
prediction	O
on	O
the	O
intersecting	O
center	O
pixel	O
)	O
,	O
but	O
that	O
did	O
n’t	O
improve	O
performance	O
and	O
made	O
our	O
method	O
very	O
slow	O
.	O

Note	O
that	O
as	O
suggested	O
by	O
,	O
we	O
applied	O
data	Task
augmentation	Task
by	O
flipping	O
the	O
input	O
images	O
.	O

Unlike	O
what	O
was	O
reported	O
by	O
,	O
it	O
did	O
not	O
improve	O
the	O
overall	O
accuracy	Metric
of	O
our	O
model	O
.	O

Quantitative	O
evaluation	O
of	O
the	O
models	O
performance	O
on	O
the	O
test	O
set	O
is	O
achieved	O
by	O
uploading	O
the	O
segmentation	Task
results	O
to	O
the	O
online	O
BRATS	Material
evaluation	O
system	O
.	O

The	O
online	Method
system	Method
provides	O
the	O
quantitative	O
results	O
as	O
follows	O
:	O
The	O
tumor	O
structures	O
are	O
grouped	O
in	O
3	O
different	O
tumor	O
regions	O
.	O

This	O
is	O
mainly	O
due	O
to	O
practical	O
clinical	O
applications	O
.	O

As	O
described	O
by	O
,	O
tumor	O
regions	O
are	O
defined	O
as	O
:	O
The	O
complete	O
tumor	O
region	O
(	O
including	O
all	O
four	O
tumor	O
structures	O
)	O
.	O

The	O
core	O
tumor	O
region	O
(	O
including	O
all	O
tumor	O
structures	O
exept	O
“	O
edema	O
”	O
)	O
.	O

The	O
enhancing	O
tumor	O
region	O
(	O
including	O
the	O
“	O
enhanced	O
tumor	O
”	O
structure	O
)	O
.	O

For	O
each	O
tumor	O
region	O
,	O
Dice	Metric
(	O
identical	O
to	O
F	Metric
measure	Metric
)	O
,	O
Sensitivity	Metric
and	O
Specificity	Metric
are	O
computed	O
as	O
follows	O
:	O
where	O
represents	O
the	O
model	Method
predictions	Method
and	O
represents	O
the	O
ground	O
truth	O
labels	O
.	O

We	O
also	O
note	O
as	O
and	O
the	O
subset	O
of	O
voxels	O
predicted	O
as	O
positives	O
and	O
negatives	O
for	O
the	O
tumor	O
region	O
in	O
question	O
.	O

Similarly	O
for	O
and	O
.	O

The	O
online	Method
evaluation	Method
system	Method
also	O
provides	O
a	O
ranking	Task
for	O
every	O
method	O
submitted	O
for	O
evaluation	Task
.	O

This	O
includes	O
methods	O
from	O
the	O
2013	O
BRATS	Material
challenge	O
published	O
in	O
as	O
well	O
as	O
anonymized	O
unpublished	O
methods	O
for	O
which	O
no	O
reference	O
is	O
available	O
.	O

In	O
this	O
section	O
,	O
we	O
report	O
experimental	O
results	O
for	O
our	O
different	O
CNN	Method
architectures	O
.	O

subsection	O
:	O
The	O
TwoPathCNN	Method
architecture	Method
As	O
mentioned	O
previously	O
,	O
unlike	O
conventional	O
CNNs	Method
,	O
the	O
TwoPathCNN	Method
architecture	Method
has	O
two	O
pathways	O
:	O
a	O
“	O
local	O
”	O
path	O
focusing	O
on	O
details	O
and	O
a	O
“	O
global	O
”	O
path	O
more	O
focused	O
on	O
the	O
context	O
.	O

To	O
better	O
understand	O
how	O
joint	O
training	O
of	O
the	O
global	O
and	O
local	O
pathways	O
benefits	O
the	O
performance	O
,	O
we	O
report	O
results	O
on	O
each	O
pathway	O
as	O
well	O
as	O
results	O
on	O
averaging	O
the	O
outputs	O
of	O
each	O
pathway	O
when	O
trained	O
separately	O
.	O

Our	O
method	O
also	O
deals	O
with	O
the	O
unbalanced	O
nature	O
of	O
the	O
problem	O
by	O
training	O
in	O
two	O
phases	O
as	O
discussed	O
in	O
Section	O
[	O
reference	O
]	O
.	O

To	O
see	O
the	O
impact	O
of	O
the	O
two	O
phase	Method
training	Method
,	O
we	O
report	O
results	O
with	O
and	O
without	O
it	O
.	O

We	O
refer	O
to	O
the	O
CNN	Method
model	O
consisting	O
of	O
only	O
the	O
local	O
path	O
(	O
i.e.	O
conventional	O
CNN	Method
architecture	O
)	O
as	O
LocalPathCNN	Method
,	O
the	O
CNN	Method
model	O
consisting	O
of	O
only	O
the	O
global	O
path	O
as	O
GlobalPathCNN	O
,	O
the	O
model	O
averaging	O
the	O
outputs	O
of	O
the	O
local	O
and	O
global	O
paths	O
(	O
i.e.	O
LocalPathCNN	O
and	O
GlobalPathCNN	O
)	O
as	O
AverageCNN	Method
and	O
the	O
two	O
-	O
pathway	O
CNN	Method
architecture	O
as	O
TwoPathCNN	O
.	O

The	O
second	O
training	O
phase	O
is	O
noted	O
by	O
appending	O
‘	O
*	O
’	O
to	O
the	O
architecture	O
name	O
.	O

Since	O
the	O
second	O
phase	O
training	O
has	O
a	O
substantial	O
effect	O
and	O
always	O
improves	O
the	O
performance	O
,	O
we	O
only	O
report	O
results	O
on	O
GlobalPathCNN	Metric
and	O
AverageCNN	Task
with	O
the	O
second	O
phase	O
.	O

Table	O
[	O
reference	O
]	O
presents	O
the	O
quantitative	O
results	O
of	O
these	O
variations	O
.	O

This	O
table	O
contains	O
results	O
for	O
the	O
TwoPathCNN	O
with	O
one	O
and	O
two	O
training	O
phases	O
,	O
the	O
common	O
single	O
path	O
CNN	Method
(	O
i.e.	O
LocalPathCNN	Method
)	O
with	O
one	O
and	O
two	O
training	O
phases	O
,	O
the	O
GlobalPathCNN	Method
*	Method
which	O
is	O
a	O
single	O
path	O
CNN	Method
model	O
following	O
the	O
global	Method
pathway	Method
architecture	Method
and	O
the	O
output	O
average	O
of	O
each	O
of	O
the	O
trained	O
single	Method
-	Method
pathway	Method
models	Method
(	O
AverageCNN	Method
*	Method
)	O
.	O

Without	O
much	O
surprise	O
,	O
the	O
single	O
path	O
with	O
one	O
training	O
phase	O
CNN	Method
was	O
ranked	O
last	O
with	O
the	O
lowest	O
scores	O
on	O
almost	O
every	O
region	O
.	O

Using	O
a	O
second	O
training	O
phase	O
gave	O
a	O
significant	O
boost	O
to	O
that	O
model	O
with	O
a	O
rank	O
that	O
went	O
from	O
15	O
to	O
9	O
.	O

Also	O
,	O
the	O
table	O
shows	O
that	O
joint	O
training	O
of	O
the	O
local	O
and	O
global	O
paths	O
yields	O
better	O
performance	O
compared	O
to	O
when	O
each	O
pathway	O
is	O
trained	O
separately	O
and	O
the	O
outputs	O
are	O
averaged	O
.	O

One	O
likely	O
explanation	O
is	O
that	O
by	O
joint	O
training	O
the	O
local	O
and	O
global	O
paths	O
,	O
the	O
model	O
allows	O
the	O
two	O
pathways	O
to	O
co	O
-	O
adapt	O
.	O

In	O
fact	O
,	O
the	O
AverageCNN	Method
*	Method
performs	O
worse	O
than	O
the	O
LocalPathCNN	Method
*	Method
due	O
to	O
the	O
fact	O
that	O
the	O
GlobalPathCNN	Method
*	Method
performs	O
very	O
badly	O
.	O

The	O
top	O
performing	O
method	O
in	O
the	O
uncascaded	Method
models	Method
is	O
the	O
TwoPathCNN	O
*	O
with	O
a	O
rank	O
of	O
4	O
.	O

Also	O
,	O
in	O
some	O
cases	O
results	O
are	O
less	O
accurate	O
over	O
the	O
Enhancing	O
region	O
than	O
for	O
the	O
Core	O
and	O
Complete	O
regions	O
.	O

There	O
are	O
2	O
main	O
reasons	O
for	O
that	O
.	O

First	O
,	O
borders	O
are	O
usually	O
diffused	O
and	O
there	O
are	O
no	O
clear	O
cut	O
between	O
enhanced	O
tumor	O
and	O
non	O
-	O
enhanced	O
tissues	O
.	O

This	O
creates	O
problems	O
for	O
both	O
user	Task
labeling	Task
,	O
ground	Task
truth	Task
,	O
as	O
well	O
as	O
the	O
model	O
.	O

The	O
second	O
reason	O
is	O
that	O
the	O
model	O
learns	O
what	O
it	O
sees	O
in	O
the	O
ground	O
truth	O
.	O

Since	O
the	O
labels	O
are	O
created	O
by	O
different	O
people	O
and	O
since	O
the	O
borders	O
are	O
not	O
clear	O
,	O
each	O
user	O
has	O
a	O
slightly	O
different	O
interpretation	O
of	O
the	O
borders	O
of	O
the	O
enhanced	O
tumor	O
and	O
so	O
sometimes	O
we	O
see	O
overly	O
thick	O
enhanced	O
tumor	O
in	O
the	O
ground	O
truth	O
.	O

Figure	O
[	O
reference	O
]	O
shows	O
representation	O
of	O
low	O
level	O
features	O
in	O
both	O
local	O
and	O
global	O
paths	O
.	O

As	O
seen	O
from	O
this	O
figure	O
,	O
features	O
in	O
the	O
local	O
path	O
include	O
more	O
edge	O
detectors	O
while	O
the	O
ones	O
in	O
the	O
global	O
path	O
are	O
more	O
localized	O
features	O
.	O

Unfortunately	O
,	O
visualizing	O
the	O
learned	O
mid	O
/	O
high	O
level	O
features	O
of	O
a	O
CNN	Method
is	O
still	O
very	O
much	O
an	O
open	O
research	O
problem	O
.	O

However	O
,	O
we	O
can	O
study	O
the	O
impact	O
these	O
features	O
have	O
on	O
predictions	Task
by	O
visualizing	O
the	O
segmentation	Task
results	O
of	O
different	O
models	O
.	O

The	O
segmentation	Task
results	O
on	O
two	O
subjects	O
from	O
our	O
validation	O
set	O
,	O
produced	O
by	O
different	O
variations	O
of	O
the	O
basic	Method
model	Method
can	O
be	O
viewed	O
in	O
Figure	O
[	O
reference	O
]	O
.	O

As	O
shown	O
in	O
the	O
figure	O
,	O
the	O
two	O
-	O
phase	Method
training	Method
procedure	Method
allows	O
the	O
model	O
to	O
learn	O
from	O
a	O
more	O
realistic	O
distribution	O
of	O
labels	O
and	O
thus	O
removes	O
false	O
positives	O
produced	O
by	O
the	O
model	O
which	O
trains	O
with	O
one	O
training	O
phase	O
.	O

Moreover	O
,	O
by	O
having	O
two	O
pathways	O
,	O
the	O
model	O
can	O
simultaneously	O
learn	O
the	O
global	O
contextual	O
features	O
as	O
well	O
as	O
the	O
local	O
detailed	O
features	O
.	O

This	O
gives	O
the	O
advantage	O
of	O
correcting	O
labels	O
at	O
a	O
global	O
scale	O
as	O
well	O
as	O
recognizing	O
fine	O
details	O
of	O
the	O
tumor	O
at	O
a	O
local	O
scale	O
,	O
yielding	O
a	O
better	O
segmentation	Task
as	O
oppose	O
to	O
a	O
single	O
path	Method
architecture	Method
which	O
results	O
in	O
smoother	O
boundaries	O
.	O

Joint	Method
training	Method
of	O
the	O
two	O
convolutional	Method
pathways	Method
and	O
having	O
two	O
training	O
phases	O
achieves	O
better	O
results	O
.	O

subsection	O
:	O
Cascaded	Method
architectures	Method
We	O
now	O
discuss	O
our	O
experiments	O
with	O
the	O
three	O
cascaded	Method
architectures	Method
namely	O
InputCascadeCNN	Method
,	O
LocalCascadeCNN	Method
and	O
MFCascadeCNN	Method
.	O

Table	O
[	O
reference	O
]	O
provides	O
the	O
quantitative	O
results	O
for	O
each	O
architecture	O
.	O

Figure	O
[	O
reference	O
]	O
also	O
provides	O
visual	O
examples	O
of	O
the	O
segmentation	Task
generated	O
by	O
each	O
architecture	O
.	O

We	O
find	O
that	O
the	O
MFCascadeCNN	Method
*	Method
model	Method
yields	O
smoother	O
boundaries	O
between	O
classes	O
.	O

We	O
hypothesize	O
that	O
,	O
since	O
the	O
neurons	O
in	O
the	O
softmax	Method
output	Method
layer	Method
are	O
directly	O
connected	O
to	O
the	O
previous	O
outputs	O
within	O
each	O
receptive	O
field	O
,	O
these	O
parameters	O
are	O
more	O
likely	O
to	O
learn	O
that	O
the	O
center	O
pixel	O
label	O
should	O
have	O
a	O
similar	O
label	O
to	O
its	O
surroundings	O
.	O

As	O
for	O
the	O
LocalCascadeCNN	Method
*	Method
architecture	Method
,	O
while	O
it	O
resulted	O
in	O
fewer	O
false	Metric
positives	Metric
in	O
the	O
complete	O
tumor	O
category	O
,	O
the	O
performance	O
in	O
other	O
categories	O
(	O
i.e.	O
tumor	O
core	O
and	O
enhanced	O
tumor	O
)	O
did	O
not	O
improve	O
.	O

Figure	O
[	O
reference	O
]	O
shows	O
segmentation	Task
results	O
from	O
the	O
same	O
brains	O
(	O
as	O
in	O
Figure	O
[	O
reference	O
]	O
)	O
in	O
Sagittal	O
and	O
Coronal	O
views	O
.	O

The	O
InputCascadeCNN	Method
*	O
model	O
was	O
used	O
to	O
produce	O
these	O
results	O
.	O

As	O
seen	O
from	O
this	O
figure	O
,	O
although	O
the	O
segmentation	Task
is	O
performed	O
on	O
Axial	O
view	O
but	O
the	O
output	O
is	O
consistent	O
in	O
Coronal	O
and	O
Sagittal	O
views	O
.	O

Although	O
subjects	O
in	O
Figure	O
5	O
and	O
Figure	O
6	O
are	O
from	O
our	O
validation	O
set	O
for	O
which	O
the	O
model	O
is	O
not	O
trained	O
on	O
and	O
the	O
segmentation	Task
results	O
from	O
these	O
subjects	O
can	O
give	O
a	O
good	O
estimate	O
of	O
the	O
models	O
performance	O
on	O
a	O
test	O
set	O
,	O
however	O
,	O
for	O
further	O
clarity	O
we	O
visualise	O
the	O
models	O
performance	O
on	O
two	O
subjects	O
from	O
BRATS	Material
-	O
2013	O
testst	O
.	O

These	O
results	O
are	O
shown	O
in	O
Figure	O
[	O
reference	O
]	O
in	O
Saggital	O
(	O
top	O
)	O
and	O
Axial	O
(	O
bottom	O
)	O
views	O
.	O

To	O
better	O
understand	O
the	O
process	O
for	O
which	O
InputCascadeCNN	Method
*	O
learns	O
features	O
,	O
we	O
present	O
in	O
Figure	O
[	O
reference	O
]	O
the	O
progression	O
of	O
the	O
model	O
by	O
making	O
predictions	O
at	O
every	O
few	O
epochs	O
on	O
a	O
subject	O
from	O
our	O
validation	O
set	O
.	O

Overall	O
,	O
the	O
best	O
performance	O
is	O
reached	O
by	O
the	O
InputCascadeCNN	Method
*	O
model	O
.	O

It	O
improves	O
the	O
Dice	Metric
measure	O
on	O
all	O
tumor	O
regions	O
.	O

With	O
this	O
architecture	O
,	O
we	O
were	O
able	O
to	O
reach	O
the	O
second	O
rank	O
on	O
the	O
BRATS	Material
2013	O
scoreboard	O
.	O

While	O
MFCascadeCNN	Method
*	O
,	O
TwoPathCNN	O
*	O
and	O
LocalCascadeCNN	Method
*	Method
are	O
all	O
ranked	O
,	O
the	O
inner	O
ranking	O
between	O
these	O
three	O
models	O
is	O
noted	O
as	O
4a	O
,	O
4b	O
and	O
4c	O
respectively	O
.	O

Table	O
[	O
reference	O
]	O
shows	O
how	O
our	O
implemented	O
architectures	O
compare	O
with	O
currently	O
published	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
methods	O
as	O
mentioned	O
in	O
.	O

The	O
table	O
shows	O
that	O
InputCascadeCNN	Method
*	O
out	O
performs	O
Tustison	O
et	O
al	O
.	O

the	O
winner	O
of	O
the	O
BRATS	Material
2013	O
challenge	O
and	O
is	O
ranked	O
first	O
in	O
the	O
table	O
.	O

Results	O
from	O
the	O
BRATS	Material
-	O
2013	O
leaderboard	O
presented	O
in	O
Table	O
[	O
reference	O
]	O
shows	O
that	O
our	O
method	O
outperforms	O
other	O
approaches	O
on	O
this	O
dataset	O
.	O

We	O
also	O
compare	O
our	O
top	O
performing	O
method	O
in	O
Table	O
[	O
reference	O
]	O
with	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
methods	O
on	O
BRATS	Material
-	Material
2012	Material
,	O
”	O
4	O
label	O
”	O
test	O
set	O
as	O
mentioned	O
in	O
.	O

As	O
seen	O
from	O
this	O
table	O
,	O
our	O
method	O
out	O
performs	O
other	O
methods	O
in	O
the	O
tumor	Task
Core	Task
category	Task
and	O
gets	O
competitive	O
results	O
on	O
other	O
categories	O
.	O

Let	O
us	O
mention	O
that	O
Tustison	O
’s	O
method	O
takes	O
100	O
minutes	O
to	O
compute	O
predictions	O
per	O
brain	O
as	O
reported	O
in	O
,	O
while	O
the	O
InputCascadeCNN	Method
*	O
takes	O
3	O
minutes	O
,	O
thanks	O
to	O
the	O
fully	Method
convolutional	Method
architecture	Method
and	O
the	O
GPU	Method
implementation	Method
,	O
which	O
is	O
over	O
30	O
times	O
faster	O
than	O
the	O
winner	O
of	O
the	O
challenge	O
.	O

The	O
TwoPathCNN	Method
*	Method
has	O
a	O
performance	O
close	O
to	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
.	O

However	O
,	O
with	O
a	O
prediction	Metric
time	Metric
of	O
25	O
seconds	O
,	O
it	O
is	O
over	O
200	O
times	O
faster	O
than	O
Tustison	Method
’s	Method
method	Method
.	O

Other	O
top	O
methods	O
in	O
the	O
table	O
are	O
that	O
of	O
Meier	O
et	O
al	O
and	O
Reza	O
et	O
al	O
with	O
processing	Metric
times	Metric
of	O
6	O
and	O
90	O
minutes	O
respectively	O
.	O

Recently	O
published	O
competitive	O
results	O
on	O
the	O
BRATS	Material
2013	O
dataset	O
,	O
reporting	O
dice	Metric
measures	Metric
of	O
for	O
Complete	O
,	O
Core	O
and	O
Enhancing	O
tumor	O
regions	O
.	O

Since	O
they	O
do	O
not	O
report	O
Specificity	Metric
and	Metric
Sensitivity	Metric
measures	Metric
,	O
a	O
completely	O
fair	O
comparison	O
with	O
that	O
method	O
is	O
not	O
possible	O
.	O

However	O
,	O
as	O
mentioned	O
in	O
,	O
their	O
method	O
takes	O
70	O
minutes	O
to	O
process	O
a	O
subject	O
,	O
which	O
is	O
about	O
23	O
times	O
slower	O
than	O
our	O
method	O
.	O

Regarding	O
other	O
methods	O
using	O
CNNs	Method
,	O
used	O
an	O
average	O
of	O
two	O
3D	Method
convolutional	Method
networks	Method
with	O
dice	Metric
measures	Metric
of	O
for	O
Complete	O
,	O
Core	O
and	O
Enhancing	O
tumor	O
regions	O
on	O
BRATS	Material
2013	O
test	O
dataset	O
with	O
a	O
prediction	Metric
time	Metric
of	O
about	O
minute	O
per	O
model	O
which	O
makes	O
for	O
a	O
total	O
of	O
minutes	O
.	O

Again	O
,	O
since	O
they	O
do	O
not	O
report	O
Specificity	Metric
and	Metric
Sensitivity	Metric
measures	Metric
,	O
we	O
can	O
not	O
make	O
a	O
full	O
comparison	O
.	O

However	O
,	O
based	O
on	O
their	O
dice	Metric
scores	Metric
our	O
TwoPathCNN	O
*	O
is	O
similar	O
in	O
performance	O
while	O
taking	O
only	O
25	O
seconds	O
,	O
which	O
is	O
four	O
times	O
faster	O
.	O

And	O
the	O
InputCascadeCNN	Method
*	O
is	O
better	O
or	O
equal	O
in	O
accuracy	Metric
while	O
having	O
the	O
same	O
processing	Metric
time	Metric
.	O

As	O
for	O
,	O
they	O
do	O
not	O
report	O
results	O
on	O
BRATS	Material
2013	O
test	O
dataset	O
.	O

However	O
,	O
their	O
method	O
is	O
very	O
similar	O
to	O
the	O
LocalPathCNN	Method
which	O
,	O
according	O
to	O
our	O
experiments	O
,	O
has	O
worse	O
performance	O
.	O

Using	O
our	O
best	O
performing	O
method	O
,	O
we	O
took	O
part	O
in	O
the	O
BRATS	Material
2015	Material
challenge	Material
.	O

The	O
BRATS	Material
2015	Material
training	Material
dataset	Material
comprises	O
of	O
220	O
subjects	O
with	O
high	O
grade	O
and	O
54	O
subjects	O
with	O
low	O
grade	O
gliomas	O
.	O

There	O
are	O
53	O
subjects	O
with	O
mixed	O
high	O
and	O
low	O
grade	O
gliomas	O
for	O
testing	O
.	O

Every	O
participating	O
group	O
had	O
48	O
hours	O
from	O
receiving	O
the	O
test	O
subjects	O
to	O
process	O
them	O
and	O
submit	O
their	O
segmentation	O
results	O
to	O
the	O
online	Method
evaluation	Method
system	Method
.	O

BRATS’15	Material
contains	O
the	O
training	O
data	O
of	O
2013	O
.	O

The	O
ground	O
truth	O
for	O
the	O
rest	O
of	O
the	O
training	O
brains	O
is	O
generated	O
by	O
a	O
voted	O
average	O
of	O
segmented	O
results	O
of	O
the	O
top	O
performing	O
methods	O
in	O
BRATS’13	Material
and	O
BRATS’12	Material
.	O

Some	O
of	O
these	O
automatically	O
generated	O
ground	Metric
truths	Metric
have	O
been	O
refined	O
manually	O
by	O
a	O
user	O
.	O

Because	O
distribution	O
of	O
the	O
intensity	O
values	O
in	O
this	O
dataset	O
is	O
very	O
variable	O
from	O
one	O
subject	O
to	O
another	O
,	O
we	O
used	O
a	O
7	Method
fold	Method
cross	Method
validation	Method
for	O
training	O
.	O

At	O
test	O
time	O
,	O
a	O
voted	O
average	O
of	O
these	O
models	O
was	O
made	O
to	O
make	O
prediction	O
for	O
each	O
subject	O
in	O
the	O
test	O
dataset	O
.	O

The	O
results	O
of	O
the	O
challenge	O
are	O
presented	O
in	O
Figure	O
[	O
reference	O
]	O
.	O

The	O
semi	Method
-	Method
automatic	Method
methods	Method
participating	O
in	O
the	O
challenge	O
have	O
been	O
highlighted	O
in	O
grey	O
.	O

Please	O
note	O
since	O
these	O
results	O
are	O
not	O
yet	O
publicly	O
available	O
,	O
we	O
refrain	O
from	O
disclosing	O
the	O
name	O
of	O
the	O
participants	O
.	O

In	O
this	O
figure	O
the	O
semi	Method
-	Method
automatic	Method
methods	Method
are	O
highlighted	O
in	O
gray	O
.	O

As	O
seen	O
from	O
the	O
figure	O
,	O
our	O
method	O
ranks	O
either	O
first	O
or	O
second	O
on	O
Complete	O
tumor	O
and	O
tumor	O
Core	O
categories	O
and	O
gets	O
competitive	O
results	O
on	O
active	Task
tumor	Task
category	Task
.	O

Our	O
method	O
has	O
also	O
less	O
outliers	O
than	O
most	O
other	O
approaches	O
.	O

section	O
:	O
Conclusion	O
In	O
this	O
paper	O
,	O
we	O
presented	O
an	O
automatic	Method
brain	Method
tumor	Method
segmentation	Method
method	Method
based	O
on	O
deep	Method
convolutional	Method
neural	Method
networks	Method
.	O

We	O
considered	O
different	O
architectures	O
and	O
investigated	O
their	O
impact	O
on	O
the	O
performance	O
.	O

Results	O
from	O
the	O
BRATS	Material
2013	Material
online	Metric
evaluation	Metric
system	Metric
confirms	O
that	O
with	O
our	O
best	O
model	O
we	O
managed	O
to	O
improve	O
on	O
the	O
currently	O
published	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
method	O
both	O
on	O
accuracy	Metric
and	O
speed	Metric
as	O
presented	O
in	O
MICCAI	Material
2013	Material
.	O

The	O
high	O
performance	O
is	O
achieved	O
with	O
the	O
help	O
of	O
a	O
novel	O
two	Method
-	Method
pathway	Method
architecture	Method
(	O
which	O
can	O
model	O
both	O
the	O
local	O
details	O
and	O
global	O
context	O
)	O
as	O
well	O
as	O
modeling	O
local	O
label	O
dependencies	O
by	O
stacking	O
two	O
CNN	Method
’s	O
.	O

Training	Task
is	O
based	O
on	O
a	O
two	O
phase	O
procedure	O
,	O
which	O
we	O
’	O
ve	O
found	O
allows	O
us	O
to	O
train	O
CNNs	Method
efficiently	O
when	O
the	O
distribution	O
of	O
labels	O
is	O
unbalanced	O
.	O

Thanks	O
to	O
the	O
convolutional	Method
nature	Method
of	O
the	O
models	O
and	O
by	O
using	O
an	O
efficient	O
GPU	Method
implementation	Method
,	O
the	O
resulting	O
segmentation	Method
system	Method
is	O
very	O
fast	O
.	O

The	O
time	O
needed	O
to	O
segment	O
an	O
entire	O
brain	O
with	O
any	O
of	O
the	O
these	O
CNN	Method
architectures	O
varies	O
between	O
seconds	O
and	O
minutes	O
,	O
making	O
them	O
practical	O
segmentation	Method
methods	Method
.	O

section	O
:	O
References	O
bibliography	O
:	O
References	O
