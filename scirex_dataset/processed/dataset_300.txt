document	O
:	O
Graph	Method
-	Method
Structured	Method
Representations	Method
for	O
Visual	Task
Question	Task
Answering	Task
This	O
paper	O
proposes	O
to	O
improve	O
visual	Task
question	Task
answering	Task
(	O
VQA	Task
)	O
with	O
structured	Method
representations	Method
of	O
both	O
scene	O
contents	O
and	O
questions	O
.	O

A	O
key	O
challenge	O
in	O
VQA	Task
is	O
to	O
require	O
joint	Task
reasoning	Task
over	O
the	O
visual	O
and	O
text	O
domains	O
.	O

The	O
predominant	O
CNN	Method
/	O
LSTM	O
-	O
based	O
approach	O
to	O
VQA	Task
is	O
limited	O
by	O
monolithic	Method
vector	Method
representations	Method
that	O
largely	O
ignore	O
structure	O
in	O
the	O
scene	O
and	O
in	O
the	O
question	O
.	O

CNN	Method
feature	O
vectors	O
can	O
not	O
effectively	O
capture	O
situations	O
as	O
simple	O
as	O
multiple	O
object	O
instances	O
,	O
and	O
LSTMs	Method
process	O
questions	O
as	O
series	O
of	O
words	O
,	O
which	O
do	O
not	O
reflect	O
the	O
true	O
complexity	O
of	O
language	O
structure	O
.	O

We	O
instead	O
propose	O
to	O
build	O
graphs	O
over	O
the	O
scene	O
objects	O
and	O
over	O
the	O
question	O
words	O
,	O
and	O
we	O
describe	O
a	O
deep	Method
neural	Method
network	Method
that	O
exploits	O
the	O
structure	O
in	O
these	O
representations	O
.	O

We	O
show	O
that	O
this	O
approach	O
achieves	O
significant	O
improvements	O
over	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
,	O
increasing	O
accuracy	Metric
from	O
71.2	O
%	O
to	O
74.4	O
%	O
on	O
the	O
“	O
abstract	O
scenes	O
”	O
multiple	O
-	O
choice	O
benchmark	O
,	O
and	O
from	O
34.7	O
%	O
to	O
39.1	O
%	O
for	O
the	O
more	O
challenging	O
“	O
balanced	O
”	O
scenes	O
,	O
i.e	O
.	O

image	O
pairs	O
with	O
fine	O
-	O
grained	O
differences	O
and	O
opposite	O
yes	O
/	O
no	O
answers	O
to	O
a	O
same	O
question	O
.	O

section	O
:	O
Introduction	O
The	O
task	O
of	O
Visual	Task
Question	Task
Answering	Task
has	O
received	O
growing	O
interest	O
in	O
the	O
recent	O
years	O
(	O
see	O
for	O
example	O
)	O
.	O

One	O
of	O
the	O
more	O
interesting	O
aspects	O
of	O
the	O
problem	O
is	O
that	O
it	O
combines	O
computer	Task
vision	Task
,	O
natural	Task
language	Task
processing	Task
,	O
and	O
artificial	Task
intelligence	Task
.	O

In	O
its	O
open	O
-	O
ended	O
form	O
,	O
a	O
question	O
is	O
provided	O
as	O
text	O
in	O
natural	O
language	O
together	O
with	O
an	O
image	O
,	O
and	O
a	O
correct	O
answer	O
must	O
be	O
predicted	O
,	O
typically	O
in	O
the	O
form	O
of	O
a	O
single	O
word	O
or	O
a	O
short	O
phrase	O
.	O

In	O
the	O
multiple	Method
-	Method
choice	Method
variant	Method
,	O
an	O
answer	O
is	O
selected	O
from	O
a	O
provided	O
set	O
of	O
candidates	O
,	O
alleviating	O
evaluation	O
issues	O
related	O
to	O
synonyms	O
and	O
paraphrasing	O
.	O

Multiple	O
datasets	O
for	O
VQA	Task
have	O
been	O
introduced	O
with	O
either	O
real	O
or	O
synthetic	O
images	O
.	O

Our	O
experiments	O
uses	O
the	O
latter	O
,	O
being	O
based	O
on	O
clip	O
art	O
or	O
“	O
cartoon	O
”	O
images	O
created	O
by	O
humans	O
to	O
depict	O
realistic	O
scenes	O
(	O
they	O
are	O
usually	O
referred	O
to	O
as	O
“	O
abstract	O
scenes	O
”	O
,	O
despite	O
this	O
being	O
a	O
misnomer	O
)	O
.	O

Our	O
experiments	O
focus	O
on	O
this	O
dataset	O
of	O
clip	O
art	O
scenes	O
as	O
they	O
allow	O
to	O
focus	O
on	O
semantic	Task
reasoning	Task
and	O
vision	Task
-	Task
language	Task
interactions	Task
,	O
in	O
isolation	O
from	O
the	O
performance	O
of	O
visual	Task
recognition	Task
(	O
see	O
examples	O
in	O
Fig	O
.	O

[	O
reference	O
]	O
)	O
.	O

They	O
also	O
allow	O
the	O
manipulation	O
of	O
the	O
image	O
data	O
so	O
as	O
to	O
better	O
illuminate	O
algorithm	O
performance	O
.	O

A	O
particularly	O
attractive	O
VQA	Task
dataset	O
was	O
introduced	O
in	O
by	O
selecting	O
only	O
the	O
questions	O
with	O
binary	O
answers	O
(	O
e.g	O
.	O

yes	O
/	O
no	O
)	O
and	O
pairing	O
each	O
(	O
synthetic	O
)	O
image	O
with	O
a	O
minimally	O
-	O
different	O
complementary	O
version	O
that	O
elicits	O
the	O
opposite	O
(	O
no	O
/	O
yes	O
)	O
answer	O
(	O
see	O
examples	O
in	O
Fig	O
.	O

[	O
reference	O
]	O
,	O
bottom	O
rows	O
)	O
.	O

This	O
strongly	O
contrasts	O
with	O
other	O
VQA	Task
datasets	O
of	O
real	O
images	O
,	O
where	O
a	O
correct	O
answer	O
is	O
often	O
obvious	O
without	O
looking	O
at	O
the	O
image	O
,	O
by	O
relying	O
on	O
systematic	O
regularities	O
of	O
frequent	O
questions	O
and	O
answers	O
.	O

Performance	O
improvements	O
reported	O
on	O
such	O
datasets	O
are	O
difficult	O
to	O
interpret	O
as	O
actual	O
progress	O
in	O
scene	Task
understanding	Task
and	O
reasoning	Task
as	O
they	O
might	O
similarly	O
be	O
taken	O
to	O
represent	O
a	O
better	O
modeling	O
of	O
the	O
language	O
prior	O
of	O
the	O
dataset	O
.	O

This	O
hampers	O
,	O
or	O
at	O
best	O
obscures	O
,	O
progress	O
toward	O
the	O
greater	O
goal	O
of	O
general	Task
VQA	Task
.	O

In	O
our	O
view	O
,	O
and	O
despite	O
obvious	O
limitations	O
of	O
synthetic	O
images	O
,	O
improvements	O
on	O
the	O
aforementioned	O
“	O
balanced	O
”	O
dataset	O
constitute	O
an	O
illuminating	O
measure	O
of	O
progress	O
in	O
scene	Task
-	Task
understanding	Task
,	O
because	O
a	O
language	Method
model	Method
alone	O
can	O
not	O
perform	O
better	O
than	O
chance	O
on	O
this	O
data	O
.	O

paragraph	O
:	O
Challenges	O
The	O
questions	O
in	O
the	O
clip	O
-	O
art	O
dataset	O
vary	O
greatly	O
in	O
their	O
complexity	O
.	O

Some	O
can	O
be	O
directly	O
answered	O
from	O
observations	O
of	O
visual	O
elements	O
,	O
e.g	O
.	O

Is	O
there	O
a	O
dog	O
in	O
the	O
room	O
?	O
,	O
or	O
Is	O
the	O
weather	O
good	O
?	O
.	O

Others	O
require	O
relating	O
multiple	O
facts	O
or	O
understanding	O
complex	O
actions	O
,	O
e.g	O
.	O

Is	O
the	O
boy	O
going	O
to	O
catch	O
the	O
ball	O
?	O
,	O
or	O
Is	O
it	O
winter	O
?	O
.	O

An	O
additional	O
challenge	O
,	O
which	O
affects	O
all	O
VQA	Task
datasets	O
,	O
is	O
the	O
sparsity	O
of	O
the	O
training	O
data	O
.	O

Even	O
a	O
large	O
number	O
of	O
training	O
questions	O
(	O
almost	O
25	O
,	O
000	O
for	O
the	O
clip	O
art	O
scenes	O
of	O
)	O
can	O
not	O
possibly	O
cover	O
the	O
combinatorial	O
diversity	O
of	O
possible	O
objects	O
and	O
concepts	O
.	O

Adding	O
to	O
this	O
challenge	O
,	O
most	O
methods	O
for	O
VQA	Task
process	O
the	O
question	O
through	O
a	O
recurrent	Method
neural	Method
network	Method
(	O
such	O
as	O
an	O
LSTM	Method
)	O
trained	O
from	O
scratch	O
solely	O
on	O
the	O
training	O
questions	O
.	O

paragraph	O
:	O
Language	Method
representation	Method
The	O
above	O
reasons	O
motivate	O
us	O
to	O
take	O
advantage	O
of	O
the	O
extensive	O
existing	O
work	O
in	O
the	O
natural	O
language	O
community	O
to	O
aid	O
processing	O
the	O
questions	O
.	O

First	O
,	O
we	O
identify	O
the	O
syntactic	O
structure	O
of	O
the	O
question	O
using	O
a	O
dependency	Method
parser	Method
.	O

This	O
produces	O
a	O
graph	Method
representation	Method
of	O
the	O
question	O
in	O
which	O
each	O
node	O
represents	O
a	O
word	O
and	O
each	O
edge	O
a	O
particular	O
type	O
of	O
dependency	O
(	O
e.g	O
.	O

determiner	O
,	O
nominal	O
subject	O
,	O
direct	O
object	O
,	O
etc	O
.	O

)	O
.	O

Second	O
,	O
we	O
associate	O
each	O
word	O
(	O
node	O
)	O
with	O
a	O
vector	Method
embedding	Method
pretrained	Method
on	O
large	O
corpora	O
of	O
text	O
data	O
.	O

This	O
embedding	O
maps	O
the	O
words	O
to	O
a	O
space	O
in	O
which	O
distances	O
are	O
semantically	O
meaningful	O
.	O

Consequently	O
,	O
this	O
essentially	O
regularizes	O
the	O
remainder	O
of	O
the	O
network	O
to	O
share	O
learned	O
concepts	O
among	O
related	O
words	O
and	O
synonyms	O
.	O

This	O
particularly	O
helps	O
in	O
dealing	O
with	O
rare	O
words	O
,	O
and	O
also	O
allows	O
questions	O
to	O
include	O
words	O
absent	O
from	O
the	O
training	O
questions	O
/	O
answers	O
.	O

Note	O
that	O
this	O
pretraining	O
and	O
ad	Task
hoc	Task
processing	Task
of	O
the	O
language	Task
part	Task
mimics	O
a	O
practice	O
common	O
for	O
the	O
image	Task
part	Task
,	O
in	O
which	O
visual	O
features	O
are	O
usually	O
obtained	O
from	O
a	O
fixed	O
CNN	Method
,	O
itself	O
pretrained	O
on	O
a	O
larger	O
dataset	O
and	O
with	O
a	O
different	O
(	O
supervised	Metric
classification	Metric
)	Metric
objective	Metric
.	O

paragraph	O
:	O
Scene	Method
representation	Method
Each	O
object	O
in	O
the	O
scene	O
corresponds	O
to	O
a	O
node	O
in	O
the	O
scene	O
graph	O
,	O
which	O
has	O
an	O
associated	O
feature	O
vector	O
describing	O
its	O
appearance	O
.	O

The	O
graph	O
is	O
fully	O
connected	O
,	O
with	O
each	O
edge	O
representing	O
the	O
relative	O
position	O
of	O
the	O
objects	O
in	O
the	O
image	O
.	O

paragraph	O
:	O
Applying	O
Neural	Method
Networks	Method
to	O
graphs	O
The	O
two	O
graph	Method
representations	Method
feed	O
into	O
a	O
deep	Method
neural	Method
network	Method
that	O
we	O
will	O
describe	O
in	O
Section	O
[	O
reference	O
]	O
.	O

The	O
advantage	O
of	O
this	O
approach	O
with	O
text	Task
-	Task
and	Task
scene	Task
-	Task
graphs	Task
,	O
rather	O
than	O
more	O
typical	O
representations	O
,	O
is	O
that	O
the	O
graphs	O
can	O
capture	O
relationships	O
between	O
words	O
and	O
between	O
objects	O
which	O
are	O
of	O
semantic	O
significance	O
.	O

This	O
enables	O
the	O
GNN	Method
to	O
exploit	O
(	O
1	O
)	O
the	O
unordered	O
nature	O
of	O
scene	O
elements	O
(	O
the	O
objects	O
in	O
particular	O
)	O
and	O
(	O
2	O
)	O
the	O
semantic	O
relationships	O
between	O
elements	O
(	O
and	O
the	O
grammatical	O
relationships	O
between	O
words	O
in	O
particular	O
)	O
.	O

This	O
contrasts	O
with	O
the	O
typical	O
approach	O
of	O
representing	O
the	O
image	O
with	O
CNN	Method
activations	O
(	O
which	O
are	O
sensitive	O
to	O
individual	O
object	O
locations	O
but	O
less	O
so	O
to	O
relative	O
position	O
)	O
and	O
the	O
processing	O
words	O
of	O
the	O
question	O
serially	O
with	O
an	O
RNN	Method
(	O
despite	O
the	O
fact	O
that	O
grammatical	O
structure	O
is	O
very	O
non	O
-	O
linear	O
)	O
.	O

The	O
graph	Method
representation	Method
ignores	O
the	O
order	O
in	O
which	O
elements	O
are	O
processed	O
,	O
but	O
instead	O
represents	O
the	O
relationships	O
between	O
different	O
elements	O
using	O
different	O
edge	O
types	O
.	O

Our	O
network	O
uses	O
multiple	O
layers	O
that	O
iterate	O
over	O
the	O
features	O
associated	O
with	O
every	O
node	O
,	O
then	O
ultimately	O
identifies	O
a	O
soft	O
matching	O
between	O
nodes	O
from	O
the	O
two	O
graphs	O
.	O

This	O
matching	O
reflects	O
the	O
correspondences	O
between	O
the	O
words	O
in	O
the	O
question	O
and	O
the	O
objects	O
in	O
the	O
image	O
.	O

The	O
features	O
of	O
the	O
matched	O
nodes	O
then	O
feed	O
into	O
a	O
classifier	Method
to	O
infer	O
the	O
answer	O
to	O
the	O
question	O
(	O
Fig	O
.	O

[	O
reference	O
]	O
)	O
.	O

The	O
main	O
contributions	O
of	O
this	O
paper	O
are	O
four	O
-	O
fold	O
.	O

We	O
describe	O
how	O
to	O
use	O
graph	Method
representations	Method
of	Method
scene	Method
and	Method
question	Method
for	O
VQA	Task
,	O
and	O
a	O
neural	Method
network	Method
capable	O
of	O
processing	O
these	O
representations	O
to	O
infer	O
an	O
answer	O
.	O

We	O
show	O
how	O
to	O
make	O
use	O
of	O
an	O
off	O
-	O
the	O
-	O
shelf	O
language	Method
parsing	Method
tool	Method
by	O
generating	O
a	O
graph	Method
representation	Method
of	Method
text	Method
that	O
captures	O
grammatical	O
relationships	O
,	O
and	O
by	O
making	O
this	O
information	O
accessible	O
to	O
the	O
VQA	Task
model	O
.	O

This	O
representation	O
uses	O
a	O
pre	O
-	O
trained	O
word	Method
embedding	Method
to	O
form	O
node	O
features	O
,	O
and	O
encodes	O
syntactic	O
dependencies	O
between	O
words	O
as	O
edge	O
features	O
.	O

We	O
train	O
the	O
proposed	O
model	O
on	O
the	O
VQA	Task
“	O
abstract	O
scenes	O
”	O
benchmark	O
and	O
demonstrate	O
its	O
efficacy	O
by	O
raising	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
accuracy	Metric
from	O
71.2	O
%	O
to	O
74.4	O
%	O
in	O
the	O
multiple	Task
-	Task
choice	Task
setting	Task
.	O

On	O
the	O
“	O
balanced	O
”	O
version	O
of	O
the	O
dataset	O
,	O
we	O
raise	O
the	O
accuracy	Metric
from	O
34.7	O
%	O
to	O
39.1	O
%	O
in	O
the	O
hardest	O
setting	O
(	O
requiring	O
a	O
correct	O
answer	O
over	O
pairs	O
of	O
scenes	O
)	O
.	O

We	O
evaluate	O
the	O
uncertainty	O
in	O
the	O
model	O
by	O
presenting	O
–	O
for	O
the	O
first	O
time	O
on	O
the	O
task	O
of	O
VQA	Task
–	O
precision	Metric
/	Metric
recall	Metric
curves	Metric
of	O
predicted	O
answers	O
.	O

Those	O
curves	O
provide	O
more	O
insight	O
than	O
the	O
single	O
accuracy	Metric
metric	Metric
and	O
show	O
that	O
the	O
uncertainty	O
estimated	O
by	O
the	O
model	O
about	O
its	O
predictions	O
correlates	O
with	O
the	O
ambiguity	O
of	O
the	O
human	O
-	O
provided	O
ground	O
truth	O
.	O

section	O
:	O
Related	O
work	O
The	O
task	O
of	O
visual	Task
question	Task
answering	Task
has	O
received	O
increasing	O
interest	O
since	O
the	O
seminal	O
paper	O
of	O
Antol	O
et	O
al	O
.	O

.	O

Most	O
recent	O
methods	O
are	O
based	O
on	O
the	O
idea	O
of	O
a	O
joint	Method
embedding	Method
of	O
the	O
image	O
and	O
the	O
question	O
using	O
a	O
deep	Method
neural	Method
network	Method
.	O

The	O
image	O
is	O
passed	O
through	O
a	O
convolutional	Method
neural	Method
network	Method
(	O
CNN	Method
)	O
pretrained	O
for	O
image	Task
classification	Task
,	O
from	O
which	O
intermediate	O
features	O
are	O
extracted	O
to	O
describe	O
the	O
image	O
.	O

The	O
question	O
is	O
typically	O
passed	O
through	O
a	O
recurrent	Method
neural	Method
network	Method
(	O
RNN	Method
)	O
such	O
as	O
an	O
LSTM	Method
,	O
which	O
produces	O
a	O
fixed	Method
-	Method
size	Method
vector	Method
representing	O
the	O
sequence	O
of	O
words	O
.	O

These	O
two	O
representations	O
are	O
mapped	O
to	O
a	O
joint	O
space	O
by	O
one	O
or	O
several	O
non	Method
-	Method
linear	Method
layers	Method
.	O

They	O
can	O
then	O
be	O
fed	O
into	O
a	O
classifier	Method
over	O
an	O
output	O
vocabulary	O
,	O
predicting	O
the	O
final	O
answer	O
.	O

Most	O
recent	O
papers	O
on	O
VQA	Task
propose	O
improvements	O
and	O
variations	O
on	O
this	O
basic	O
idea	O
.	O

Consult	O
for	O
a	O
survey	O
.	O

A	O
major	O
improvement	O
to	O
the	O
basic	O
method	O
is	O
to	O
use	O
an	O
attention	Method
mechanism	Method
.	O

It	O
models	O
interactions	O
between	O
specific	O
parts	O
of	O
the	O
inputs	O
(	O
image	O
and	O
question	O
)	O
depending	O
on	O
their	O
actual	O
contents	O
.	O

The	O
visual	O
input	O
is	O
then	O
typically	O
represented	O
a	O
spatial	Method
feature	Method
map	Method
,	O
instead	O
of	O
holistic	O
,	O
image	O
-	O
wide	O
features	O
.	O

The	O
feature	Method
map	Method
is	O
used	O
with	O
the	O
question	O
to	O
determine	O
spatial	O
weights	O
that	O
reflect	O
the	O
most	O
relevant	O
regions	O
of	O
the	O
image	O
.	O

Our	O
approach	O
uses	O
a	O
similar	O
weighting	Method
operation	Method
,	O
which	O
,	O
with	O
our	O
graph	Method
representation	Method
,	O
we	O
equate	O
to	O
a	O
subgraph	Method
matching	Method
.	O

Graph	O
nodes	O
representing	O
question	O
words	O
are	O
associated	O
with	O
graph	O
nodes	O
representing	O
scene	O
objects	O
and	O
vice	O
versa	O
.	O

Similarly	O
,	O
the	O
co	Method
-	Method
attention	Method
model	Method
of	O
Lu	O
et	O
al	O
.	O

determines	O
attention	O
weights	O
on	O
both	O
image	O
regions	O
and	O
question	O
words	O
.	O

Their	O
best	O
-	O
performing	O
approach	O
proceeds	O
in	O
a	O
sequential	O
manner	O
,	O
starting	O
with	O
question	Task
-	Task
guided	Task
visual	Task
attention	Task
followed	O
by	O
image	Method
-	Method
guided	Method
question	Method
attention	Method
.	O

In	O
our	O
case	O
,	O
we	O
found	O
that	O
a	O
joint	Method
,	Method
one	Method
-	Method
pass	Method
version	Method
performs	O
better	O
.	O

A	O
major	O
contribution	O
of	O
our	O
model	O
is	O
to	O
use	O
structured	Method
representations	Method
of	O
the	O
input	O
scene	O
and	O
the	O
question	O
.	O

This	O
contrasts	O
with	O
typical	O
CNN	Method
and	O
RNN	Method
models	O
which	O
are	O
limited	O
to	O
spatial	O
feature	O
maps	O
and	O
sequences	O
of	O
words	O
respectively	O
.	O

The	O
dynamic	Method
memory	Method
networks	Method
(	O
DMN	Method
)	O
,	O
applied	O
to	O
VQA	Task
in	O
also	O
maintain	O
a	O
set	Method
-	Method
like	Method
representation	Method
of	O
the	O
input	O
.	O

As	O
in	O
our	O
model	O
,	O
the	O
DMN	Method
models	Method
interactions	Method
between	O
different	O
parts	O
of	O
the	O
input	O
.	O

Our	O
method	O
can	O
additionally	O
take	O
,	O
as	O
input	O
,	O
features	O
characterizing	O
arbitrary	O
relations	O
between	O
parts	O
of	O
the	O
input	O
(	O
the	O
edge	O
features	O
in	O
our	O
graphs	O
)	O
.	O

This	O
specifically	O
allows	O
making	O
use	O
of	O
syntactic	O
dependencies	O
between	O
words	O
after	O
pre	O
-	O
parsing	O
the	O
question	O
.	O

Most	O
VQA	Task
systems	O
are	O
trained	O
end	O
-	O
to	O
-	O
end	O
from	O
questions	O
and	O
images	O
to	O
answers	O
,	O
with	O
the	O
exception	O
of	O
the	O
visual	Method
feature	Method
extractor	Method
,	O
which	O
is	O
typically	O
a	O
CNN	Method
pretrained	O
for	O
image	Task
classification	Task
.	O

For	O
the	O
language	Task
processing	Task
part	Task
,	O
some	O
methods	O
address	O
the	O
the	O
semantic	O
aspect	O
with	O
word	Method
embeddings	Method
pretrained	O
on	O
a	O
language	Task
modeling	Task
task	Task
(	O
e.g	O
.	O

)	O
.	O

The	O
syntactic	O
relationships	O
between	O
the	O
words	O
in	O
the	O
question	O
are	O
typically	O
overlooked	O
,	O
however	O
.	O

In	O
,	O
hand	O
-	O
designed	O
rules	O
serve	O
to	O
identify	O
primary	O
and	O
secondary	O
objects	O
of	O
the	O
questions	O
.	O

In	O
the	O
Neural	Method
Module	Method
Networks	Method
,	O
the	O
question	O
is	O
processed	O
by	O
a	O
dependency	Method
parser	Method
,	O
and	O
fragments	O
of	O
the	O
parse	O
,	O
selected	O
with	O
ad	O
hoc	O
fixed	O
rules	O
are	O
associated	O
with	O
modules	O
,	O
are	O
assembled	O
into	O
a	O
full	Method
neural	Method
network	Method
.	O

In	O
contrast	O
,	O
our	O
method	O
is	O
trained	O
to	O
make	O
direct	O
use	O
of	O
the	O
output	O
of	O
a	O
syntactic	Method
parser	Method
.	O

Neural	Method
networks	Method
on	O
graphs	O
have	O
received	O
significant	O
attention	O
recently	O
.	O

The	O
approach	O
most	O
similar	O
to	O
ours	O
is	O
the	O
Gated	Method
Graph	Method
Sequence	Method
Neural	Method
Network	Method
,	O
which	O
associate	O
a	O
gated	Method
recurrent	Method
unit	Method
(	O
GRU	Method
)	O
to	O
each	O
node	O
,	O
and	O
updates	O
the	O
feature	O
vector	O
of	O
each	O
node	O
by	O
iteratively	O
passing	O
messages	O
between	O
neighbours	O
.	O

Also	O
related	O
is	O
the	O
work	O
of	O
Vinyals	O
et	O
al	O
.	O

for	O
embedding	O
a	O
set	O
into	O
fixed	O
-	O
size	O
vector	O
,	O
invariant	O
to	O
the	O
order	O
of	O
its	O
elements	O
.	O

They	O
do	O
so	O
by	O
feeding	O
the	O
entire	O
set	O
through	O
a	O
recurrent	Method
unit	Method
multiple	O
times	O
.	O

Each	O
iteration	O
uses	O
an	O
attention	Method
mechanism	Method
to	O
focus	O
on	O
different	O
parts	O
of	O
the	O
set	O
.	O

Our	O
formulation	O
similarly	O
incorporates	O
information	O
from	O
neighbours	O
into	O
each	O
node	O
feature	O
over	O
multiple	O
iterations	O
,	O
but	O
we	O
did	O
not	O
find	O
any	O
advantage	O
in	O
using	O
an	O
attention	Method
mechanism	Method
within	O
the	O
recurrent	Method
unit	Method
.	O

section	O
:	O
Graph	Task
representation	Task
of	Task
scenes	Task
and	Task
questions	Task
The	O
input	O
data	O
for	O
each	O
training	O
or	O
test	O
instance	O
is	O
a	O
question	O
,	O
and	O
a	O
parameterized	O
description	O
of	O
contents	O
of	O
the	O
scene	O
.	O

The	O
question	O
is	O
processed	O
with	O
the	O
Stanford	Method
dependency	Method
parser	Method
,	O
which	O
outputs	O
the	O
following	O
.	O

A	O
set	O
of	O
words	O
that	O
constitute	O
the	O
nodes	O
of	O
the	O
question	O
graph	O
.	O

Each	O
word	O
is	O
represented	O
by	O
its	O
index	O
in	O
the	O
input	O
vocabulary	O
,	O
a	O
token	O
(	O
)	O
.	O

A	O
set	O
of	O
pairwise	O
relations	O
between	O
words	O
,	O
which	O
constitute	O
the	O
edges	O
of	O
our	O
graph	O
.	O

An	O
edge	O
between	O
words	O
and	O
is	O
represented	O
by	O
,	O
an	O
index	O
among	O
the	O
possible	O
types	O
of	O
dependencies	O
.	O

The	O
dataset	O
provides	O
the	O
following	O
information	O
about	O
the	O
image	O
A	O
set	O
of	O
objects	O
that	O
constitute	O
the	O
nodes	O
of	O
the	O
scene	O
graph	O
.	O

Each	O
node	O
is	O
represented	O
by	O
a	O
vector	O
of	O
visual	O
features	O
(	O
)	O
.	O

Please	O
refer	O
to	O
the	O
supplementary	O
material	O
for	O
implementation	O
details	O
.	O

A	O
set	O
of	O
pairwise	O
relations	O
between	O
all	O
objects	O
.	O

They	O
form	O
the	O
edges	O
of	O
a	O
fully	O
-	O
connected	O
graph	O
of	O
the	O
scene	O
.	O

The	O
edge	O
between	O
objects	O
and	O
is	O
represented	O
by	O
a	O
vector	O
that	O
encodes	O
relative	O
spatial	O
relationships	O
(	O
see	O
supp	O
.	O

mat	O
.	O

)	O
.	O

Our	O
experiments	O
are	O
carried	O
out	O
on	O
datasets	O
of	O
clip	O
art	O
scenes	O
,	O
in	O
which	O
descriptions	O
of	O
the	O
scenes	O
are	O
provided	O
in	O
the	O
form	O
of	O
lists	O
of	O
objects	O
with	O
their	O
visual	O
features	O
.	O

The	O
method	O
is	O
equally	O
applicable	O
to	O
real	O
images	O
,	O
with	O
the	O
object	O
list	O
replaced	O
by	O
candidate	O
object	O
detections	O
.	O

Our	O
experiments	O
on	O
clip	Task
art	Task
allows	O
the	O
effect	O
of	O
the	O
proposed	O
method	O
to	O
be	O
isolated	O
from	O
the	O
performance	O
of	O
the	O
object	Method
detector	Method
.	O

Please	O
refer	O
to	O
the	O
supplementary	O
material	O
for	O
implementation	O
details	O
.	O

The	O
features	O
of	O
all	O
nodes	O
and	O
edges	O
are	O
projected	O
to	O
a	O
vector	O
space	O
of	O
common	O
dimension	O
(	O
typically	O
=	O
300	O
)	O
.	O

The	O
question	O
nodes	O
and	O
edges	O
use	O
vector	Method
embeddings	Method
implemented	O
as	O
look	O
-	O
up	O
tables	O
,	O
and	O
the	O
scene	O
nodes	O
and	O
edges	O
use	O
affine	Method
projections	Method
:	O
with	O
the	O
word	Method
embedding	Method
(	O
usually	O
pretrained	O
,	O
see	O
supplementary	O
material	O
)	O
,	O
the	O
embedding	O
of	O
dependencies	O
,	O
and	O
weight	O
matrices	O
,	O
and	O
and	O
biases	O
.	O

section	O
:	O
Processing	Task
graphs	Task
with	O
neural	Method
networks	Method
We	O
now	O
describe	O
a	O
deep	Method
neural	Method
network	Method
suitable	O
for	O
processing	O
the	O
question	Task
and	Task
scene	Task
graphs	Task
to	O
infer	O
an	O
answer	O
.	O

See	O
Fig	O
.	O

[	O
reference	O
]	O
for	O
an	O
overview	O
.	O

The	O
two	O
graphs	O
representing	O
the	O
question	O
and	O
the	O
scene	O
are	O
processed	O
independently	O
in	O
a	O
recurrent	Method
architecture	Method
.	O

We	O
drop	O
the	O
exponents	O
and	O
for	O
this	O
paragraph	O
as	O
the	O
same	O
procedure	O
applies	O
to	O
both	O
graphs	O
.	O

Each	O
node	O
is	O
associated	O
with	O
a	O
gated	Method
recurrent	Method
unit	Method
(	O
GRU	Method
)	O
and	O
processed	O
over	O
a	O
fixed	O
number	O
of	O
iterations	O
(	O
typically	O
=	O
4	O
)	O
:	O
Square	O
brackets	O
with	O
a	O
semicolon	O
represent	O
a	O
concatenation	O
of	O
vectors	O
,	O
and	O
the	O
Hadamard	Method
(	Method
element	Method
-	Method
wise	Method
)	Method
product	Method
.	O

The	O
final	O
state	O
of	O
the	O
GRU	Method
is	O
used	O
as	O
the	O
new	O
representation	O
of	O
the	O
nodes	O
:	O
.	O

The	O
operation	O
transforms	O
features	O
from	O
a	O
variable	O
number	O
of	O
neighbours	O
(	O
i.e	O
.	O

connected	O
nodes	O
)	O
to	O
a	O
fixed	Method
-	Method
size	Method
representation	Method
.	O

Any	O
commutative	O
operation	O
can	O
be	O
used	O
(	O
e.g	O
.	O

sum	O
,	O
maximum	O
)	O
.	O

In	O
our	O
implementation	O
,	O
we	O
found	O
the	O
best	O
performance	O
with	O
the	O
average	Method
function	Method
,	O
taking	O
care	O
of	O
averaging	O
over	O
the	O
variable	O
number	O
of	O
connected	O
neighbours	O
.	O

An	O
intuitive	O
interpretation	O
of	O
the	O
recurrent	Method
processing	Method
is	O
to	O
progressively	O
integrate	O
context	O
information	O
from	O
connected	O
neighbours	O
into	O
each	O
node	O
’s	O
own	O
representation	O
.	O

A	O
node	O
corresponding	O
to	O
the	O
word	O
’	O
ball	O
’	O
,	O
for	O
instance	O
,	O
might	O
thus	O
incorporate	O
the	O
fact	O
that	O
the	O
associated	O
adjective	O
is	O
’	O
red	O
’	O
.	O

Our	O
formulation	O
is	O
similar	O
but	O
slightly	O
different	O
from	O
the	O
gated	Method
graph	Method
networks	Method
,	O
as	O
the	O
propagation	O
of	O
information	O
in	O
our	O
model	O
is	O
limited	O
to	O
the	O
first	O
order	O
.	O

Note	O
that	O
our	O
graphs	O
are	O
typically	O
densely	O
connected	O
.	O

We	O
now	O
introduce	O
a	O
form	O
of	O
attention	O
into	O
the	O
model	O
,	O
which	O
constitutes	O
an	O
essential	O
part	O
of	O
the	O
model	O
.	O

The	O
motivation	O
is	O
two	O
-	O
fold	O
:	O
(	O
1	O
)	O
to	O
identify	O
parts	O
of	O
the	O
input	O
data	O
most	O
relevant	O
to	O
produce	O
the	O
answer	O
and	O
(	O
2	O
)	O
to	O
align	O
specific	O
words	O
in	O
the	O
question	O
with	O
particular	O
elements	O
of	O
the	O
scene	O
.	O

Practically	O
,	O
we	O
estimate	O
the	O
relevance	O
of	O
each	O
possible	O
pairwise	O
combination	O
of	O
words	O
and	O
objects	O
.	O

More	O
precisely	O
,	O
we	O
compute	O
scalar	O
“	O
matching	O
weights	O
”	O
between	O
node	O
sets	O
and	O
.	O

These	O
weights	O
are	O
comparable	O
to	O
the	O
“	O
attention	O
weights	O
”	O
in	O
other	O
models	O
(	O
e.g	O
.	O

)	O
.	O

Therefore	O
,	O
:	O
where	O
and	O
are	O
learned	O
weights	O
and	O
biases	O
,	O
and	O
the	O
logistic	Method
function	Method
that	O
introduces	O
a	O
non	O
-	O
linearity	O
and	O
bounds	O
the	O
weights	O
to	O
.	O

The	O
formulation	O
is	O
similar	O
to	O
a	O
cosine	O
similarity	O
with	O
learned	O
weights	O
on	O
the	O
feature	O
dimensions	O
.	O

Note	O
that	O
the	O
weights	O
are	O
computed	O
using	O
the	O
initial	O
embedding	O
of	O
the	O
node	O
features	O
(	O
pre	Method
-	Method
GRU	Method
)	O
.	O

We	O
apply	O
the	O
scalar	O
weights	O
to	O
the	O
corresponding	O
pairwise	O
combinations	O
of	O
question	O
and	O
scene	O
features	O
,	O
thereby	O
focusing	O
and	O
giving	O
more	O
importance	O
to	O
the	O
matched	O
pairs	O
(	O
Eq	O
.	O

[	O
reference	O
]	O
)	O
.	O

We	O
sum	O
the	O
weighted	O
features	O
over	O
the	O
scene	O
elements	O
(	O
Eq	O
.	O

[	O
reference	O
]	O
)	O
then	O
over	O
the	O
question	O
elements	O
(	O
Eq	O
.	O

[	O
reference	O
]	O
)	O
,	O
interleaving	O
the	O
sums	O
with	O
affine	O
projections	O
and	O
non	O
-	O
linearities	O
to	O
obtain	O
a	O
final	O
prediction	Task
:	O
with	O
,	O
,	O
,	O
learned	O
weights	O
and	O
biases	O
,	O
a	O
ReLU	Method
,	O
and	O
a	O
softmax	Method
or	O
a	O
logistic	Method
function	Method
(	O
see	O
experiments	O
,	O
Section	O
[	O
reference	O
]	O
)	O
.	O

The	O
summations	O
over	O
the	O
scene	O
elements	O
and	O
question	O
elements	O
is	O
a	O
form	O
of	O
pooling	Method
that	O
brings	O
the	O
variable	O
number	O
of	O
features	O
(	O
due	O
to	O
the	O
variable	O
number	O
of	O
words	O
and	O
objects	O
in	O
the	O
input	O
)	O
to	O
a	O
fixed	O
-	O
size	O
output	O
.	O

The	O
final	O
output	O
vector	O
contains	O
scores	O
for	O
the	O
possible	O
answers	O
,	O
and	O
has	O
a	O
number	O
of	O
dimensions	O
equal	O
to	O
2	O
for	O
the	O
binary	O
questions	O
of	O
the	O
“	O
balanced	O
”	O
dataset	O
,	O
or	O
to	O
the	O
number	O
of	O
all	O
candidate	O
answers	O
in	O
the	O
“	O
abstract	Material
scenes	Material
”	Material
dataset	Material
.	O

The	O
candidate	O
answers	O
are	O
those	O
appearing	O
at	O
least	O
times	O
in	O
the	O
training	O
set	O
(	O
see	O
supplementary	O
material	O
for	O
details	O
)	O
.	O

section	O
:	O
Evaluation	O
paragraph	O
:	O
Datasets	O
Our	O
evaluation	O
uses	O
two	O
datasets	O
:	O
the	O
original	O
“	O
abstract	O
scenes	O
”	O
from	O
Antol	O
et	O
al	O
.	O

and	O
its	O
“	O
balanced	O
”	O
extension	O
from	O
.	O

They	O
both	O
contain	O
scenes	O
created	O
by	O
humans	O
in	O
a	O
drag	O
-	O
and	O
-	O
drop	O
interface	O
for	O
arranging	O
clip	O
art	O
objects	O
and	O
figures	O
.	O

The	O
original	O
dataset	O
contains	O
scenes	O
(	O
for	O
training	O
validation	O
test	O
respectively	O
)	O
and	O
questions	O
,	O
each	O
with	O
10	O
human	O
-	O
provided	O
ground	O
-	O
truth	O
answers	O
.	O

Questions	O
are	O
categorized	O
based	O
on	O
the	O
type	O
of	O
the	O
correct	O
answer	O
into	O
yes	O
/	O
no	O
,	O
number	O
,	O
and	O
other	O
,	O
but	O
the	O
same	O
method	O
is	O
used	O
for	O
all	O
categories	O
,	O
the	O
type	O
of	O
the	O
test	O
questions	O
being	O
unknown	O
.	O

The	O
“	O
balanced	O
”	O
version	O
of	O
the	O
dataset	O
contains	O
only	O
the	O
subset	O
of	O
questions	O
which	O
have	O
binary	O
(	O
yes	O
/	O
no	O
)	O
answers	O
and	O
,	O
in	O
addition	O
,	O
complementary	O
scenes	O
created	O
to	O
elicit	O
the	O
opposite	O
answer	O
to	O
each	O
question	O
.	O

This	O
is	O
significant	O
because	O
guessing	O
the	O
modal	O
answer	O
from	O
the	O
training	O
set	O
will	O
the	O
succeed	O
only	O
half	O
of	O
the	O
time	O
(	O
slightly	O
more	O
than	O
in	O
practice	O
because	O
of	O
disagreement	O
between	O
annotators	O
)	O
and	O
give	O
accuracy	Metric
over	O
complementary	O
pairs	O
.	O

This	O
contrasts	O
with	O
other	O
VQA	Task
datasets	O
where	O
blind	Task
guessing	Task
can	O
be	O
very	O
effective	O
.	O

The	O
pairs	O
of	O
complementary	O
scenes	O
also	O
typically	O
differ	O
by	O
only	O
one	O
or	O
two	O
objects	O
being	O
displaced	O
,	O
removed	O
,	O
or	O
slightly	O
modified	O
(	O
see	O
examples	O
in	O
Fig	O
.	O

[	O
reference	O
]	O
,	O
bottom	O
rows	O
)	O
.	O

This	O
makes	O
the	O
questions	O
very	O
challenging	O
by	O
requiring	O
to	O
take	O
into	O
account	O
subtle	O
details	O
of	O
the	O
scenes	O
.	O

paragraph	O
:	O
Metrics	O
The	O
main	O
metric	O
is	O
the	O
average	O
“	O
VQA	Task
score	O
”	O
,	O
which	O
is	O
a	O
soft	Metric
accuracy	Metric
that	O
takes	O
into	O
account	O
variability	O
of	O
ground	O
truth	O
answers	O
from	O
multiple	O
human	O
annotators	O
.	O

Let	O
us	O
refer	O
to	O
a	O
test	O
question	O
by	O
an	O
index	O
,	O
and	O
to	O
each	O
possible	O
answer	O
in	O
the	O
output	O
vocabulary	O
by	O
an	O
index	O
.	O

The	O
ground	Metric
truth	Metric
score	Metric
if	O
the	O
answer	O
was	O
provided	O
by	O
annotators	O
.	O

Otherwise	O
,	O
.	O

Our	O
method	O
outputs	O
a	O
predicted	O
score	O
for	O
each	O
question	O
and	O
answer	O
(	O
in	O
Eq	O
.	O

[	O
reference	O
]	O
)	O
and	O
the	O
overall	O
accuracy	Metric
is	O
the	O
average	Metric
ground	Metric
truth	Metric
score	Metric
of	O
the	O
highest	O
prediction	O
per	O
question	O
,	O
i.e	O
.	O

.	O

It	O
has	O
been	O
argued	O
that	O
the	O
“	O
balanced	O
”	O
dataset	O
can	O
better	O
evaluate	O
a	O
method	O
’s	O
level	O
of	O
visual	Task
understanding	Task
than	O
other	O
datasets	O
,	O
because	O
it	O
is	O
less	O
susceptible	O
to	O
the	O
use	O
of	O
language	O
priors	O
and	O
dataset	O
regularities	O
(	O
i.e	O
.	O

guessing	O
from	O
the	O
question	O
)	O
.	O

Our	O
initial	O
experiments	O
confirmed	O
that	O
the	O
performances	O
of	O
various	O
algorithms	O
on	O
the	O
balanced	O
dataset	O
were	O
indeed	O
better	O
separated	O
,	O
and	O
we	O
used	O
it	O
for	O
our	O
ablative	Task
analysis	Task
.	O

We	O
also	O
focus	O
on	O
the	O
hardest	O
evaluation	Metric
setting	Metric
,	O
which	O
measures	O
the	O
accuracy	Metric
over	O
pairs	O
of	O
complementary	O
scenes	O
.	O

This	O
is	O
the	O
only	O
metric	O
in	O
which	O
blind	Method
models	Method
(	O
guessing	O
from	O
the	O
question	O
)	O
obtain	O
null	Metric
accuracy	Metric
.	O

This	O
setting	O
also	O
does	O
not	O
consider	O
pairs	O
of	O
test	O
scenes	O
deemed	O
ambiguous	O
because	O
of	O
disagreement	O
between	O
annotators	O
.	O

Each	O
test	O
scene	O
is	O
still	O
evaluated	O
independently	O
however	O
,	O
so	O
the	O
model	O
is	O
unable	O
to	O
increase	O
performance	O
by	O
forcing	O
opposite	O
answers	O
to	O
pairs	O
of	O
questions	O
.	O

The	O
metric	O
is	O
then	O
a	O
standard	O
“	O
hard	Metric
”	Metric
accuracy	Metric
,	O
i.e	O
.	O

all	O
ground	Metric
truth	Metric
scores	Metric
.	O

Please	O
refer	O
to	O
the	O
supplementary	O
material	O
for	O
additional	O
details	O
.	O

subsection	O
:	O
Evaluation	O
on	O
the	O
“	O
balanced	O
”	O
dataset	O
We	O
compare	O
our	O
method	O
against	O
the	O
three	O
models	O
proposed	O
in	O
.	O

They	O
all	O
use	O
an	O
ensemble	Method
of	Method
models	Method
exploiting	O
either	O
an	O
LSTM	Method
for	O
processing	O
the	O
question	O
,	O
or	O
an	O
elaborate	O
set	O
of	O
hand	O
-	O
designed	O
rules	O
to	O
identify	O
two	O
objects	O
as	O
the	O
focus	O
of	O
the	O
question	O
.	O

The	O
visual	O
features	O
in	O
the	O
three	O
models	O
are	O
respectively	O
empty	O
(	O
blind	Method
model	Method
)	O
,	O
global	O
(	O
scene	O
-	O
wide	O
)	O
,	O
or	O
focused	O
on	O
the	O
two	O
objects	O
identified	O
from	O
the	O
question	O
.	O

These	O
models	O
are	O
specifically	O
designed	O
for	O
binary	Task
questions	Task
,	O
whereas	O
ours	O
is	O
generally	O
applicable	O
.	O

Nevertheless	O
,	O
we	O
obtain	O
significantly	O
better	O
accuracy	Metric
than	O
all	O
three	O
(	O
Table	O
[	O
reference	O
]	O
)	O
.	O

Differences	O
in	O
performance	O
are	O
mostly	O
visible	O
in	O
the	O
“	O
pairs	O
”	O
setting	O
,	O
which	O
we	O
believe	O
is	O
more	O
reliable	O
as	O
it	O
discards	O
ambiguous	O
test	O
questions	O
on	O
which	O
human	O
annotators	O
disagreed	O
.	O

During	O
training	O
,	O
we	O
take	O
care	O
to	O
keep	O
pairs	O
of	O
complementary	O
scenes	O
together	O
when	O
forming	O
mini	O
-	O
batches	O
.	O

This	O
has	O
a	O
significant	O
positive	O
effect	O
on	O
the	O
stability	Metric
of	O
the	O
optimization	Task
.	O

Interestingly	O
,	O
we	O
did	O
not	O
notice	O
any	O
tendency	O
toward	O
overfitting	O
when	O
training	O
on	O
balanced	O
scenes	O
.	O

We	O
hypothesize	O
that	O
the	O
pairs	O
of	O
complementary	O
scenes	O
have	O
a	O
strong	O
regularizing	O
effect	O
that	O
force	O
the	O
learned	O
model	O
to	O
focus	O
on	O
relevant	O
details	O
of	O
the	O
scenes	O
.	O

In	O
Fig	O
.	O

[	O
reference	O
]	O
(	O
and	O
in	O
the	O
supplementary	O
material	O
)	O
,	O
we	O
visualize	O
the	O
matching	O
weights	O
between	O
question	O
words	O
and	O
scene	O
objects	O
(	O
Eq	O
.	O

[	O
reference	O
]	O
)	O
.	O

As	O
expected	O
,	O
these	O
tend	O
to	O
be	O
larger	O
between	O
semantically	O
related	O
elements	O
(	O
e.g	O
.	O

daytime	O
sun	O
,	O
dog	O
puppy	O
,	O
boy	O
human	O
)	O
although	O
some	O
are	O
more	O
difficult	O
to	O
interpret	O
.	O

Our	O
best	O
performance	O
of	O
about	O
is	O
still	O
low	O
in	O
absolute	O
terms	O
,	O
which	O
is	O
understandable	O
from	O
the	O
wide	O
range	O
of	O
concepts	O
involved	O
in	O
the	O
questions	O
(	O
see	O
examples	O
in	O
Fig	O
.	O

[	O
reference	O
]	O
and	O
in	O
the	O
supplementary	O
material	O
)	O
.	O

It	O
seems	O
unlikely	O
that	O
these	O
concepts	O
could	O
be	O
learned	O
from	O
training	O
question	O
/	O
answers	O
alone	O
,	O
and	O
we	O
suggest	O
that	O
any	O
further	O
significant	O
improvement	O
in	O
performance	O
will	O
require	O
external	O
sources	O
of	O
information	O
at	O
training	O
and	O
/	O
or	O
test	O
time	O
.	O

paragraph	O
:	O
Ablative	Task
evaluation	Task
We	O
evaluated	O
variants	O
of	O
our	O
model	O
to	O
measure	O
the	O
impact	O
of	O
various	O
design	O
choices	O
(	O
see	O
numbered	O
rows	O
in	O
Table	O
[	O
reference	O
]	O
)	O
.	O

On	O
the	O
question	O
side	O
,	O
we	O
evaluate	O
(	O
row	O
1	O
)	O
our	O
graph	Method
approach	Method
without	O
syntactic	Method
parsing	Method
,	O
building	O
question	Method
graphs	Method
with	O
only	O
two	O
types	O
of	O
edges	O
,	O
previous	O
/	O
next	O
and	O
linking	O
consecutive	O
nodes	O
.	O

This	O
shows	O
the	O
advantage	O
of	O
using	O
the	O
graph	Method
method	Method
together	O
with	O
syntactic	Method
parsing	Method
.	O

Optimizing	O
the	O
word	O
embeddings	O
from	O
scratch	O
(	O
row	O
2	O
)	O
rather	O
than	O
from	O
pretrained	O
Glove	O
vectors	O
produces	O
a	O
significant	O
drop	O
in	O
performance	O
.	O

On	O
the	O
scene	O
side	O
,	O
we	O
removed	O
the	O
edge	O
features	O
(	O
row	O
3	O
)	O
by	O
setting	O
.	O

It	O
confirms	O
that	O
the	O
model	O
makes	O
use	O
of	O
the	O
spatial	O
relations	O
between	O
objects	O
encoded	O
by	O
the	O
edges	O
of	O
the	O
graph	O
.	O

In	O
rows	O
4–6	O
,	O
we	O
disabled	O
the	O
recurrent	Method
graph	Method
processing	Method
(	O
)	O
for	O
the	O
either	O
the	O
question	O
,	O
the	O
scene	O
,	O
or	O
both	O
.	O

We	O
finally	O
tested	O
the	O
model	O
with	O
uniform	O
matching	O
weights	O
(	O
,	O
row	O
10	O
)	O
.	O

As	O
expected	O
,	O
it	O
performed	O
poorly	O
.	O

Our	O
weights	O
act	O
similarly	O
to	O
the	O
attention	Method
mechanisms	Method
in	O
other	O
models	O
(	O
e.g	O
.	O

)	O
and	O
our	O
observations	O
confirm	O
that	O
such	O
mechanisms	O
are	O
crucial	O
for	O
good	O
performance	O
.	O

paragraph	O
:	O
Precision	Metric
/	O
recall	Metric
We	O
are	O
interested	O
in	O
assessing	O
the	O
confidence	O
of	O
our	O
model	O
in	O
its	O
predicted	O
answers	O
.	O

Most	O
existing	O
VQA	Task
methods	O
treat	O
the	O
answering	Task
as	O
a	O
hard	O
classification	Task
over	O
candidate	O
answers	O
,	O
and	O
almost	O
all	O
reported	O
results	O
consist	O
of	O
a	O
single	O
accuracy	Metric
metric	Metric
.	O

To	O
provide	O
more	O
insight	O
,	O
we	O
produce	O
precision	Metric
/	Metric
recall	Metric
curves	Metric
for	O
predicted	O
answers	O
.	O

A	O
precision	Metric
/	Metric
recall	Metric
point	Metric
is	O
obtained	O
by	O
setting	O
a	O
threshold	O
on	O
predicted	O
scores	O
such	O
that	O
where	O
is	O
the	O
indicator	O
function	O
.	O

We	O
plot	O
precision	Metric
/	Metric
recall	Metric
curves	Metric
in	O
Fig	O
.	O

[	O
reference	O
]	O
for	O
both	O
datasets	O
.	O

The	O
predicted	Metric
score	Metric
proves	O
to	O
be	O
a	O
reliable	O
indicator	O
of	O
the	O
model	Metric
confidence	Metric
,	O
as	O
a	O
low	O
threshold	O
can	O
achieve	O
near	O
-	O
perfect	O
accuracy	Metric
(	O
Fig	O
.	O

[	O
reference	O
]	O
,	O
left	O
and	O
middle	O
)	O
by	O
filtering	O
out	O
harder	O
and	O
/	O
or	O
ambiguous	O
test	O
cases	O
.	O

We	O
compare	O
models	O
trained	O
with	O
either	O
a	O
softmax	O
or	O
a	O
sigmoid	O
as	O
the	O
final	O
non	O
-	O
linearity	O
(	O
Eq	O
.	O

[	O
reference	O
]	O
)	O
.	O

The	O
common	O
practice	O
is	O
to	O
train	O
the	O
softmax	Method
for	O
a	O
hard	Task
classification	Task
objective	Task
,	O
using	O
a	O
cross	Metric
-	Metric
entropy	Metric
loss	Metric
and	O
the	O
answer	O
of	O
highest	O
ground	O
truth	O
score	O
as	O
the	O
target	O
.	O

In	O
an	O
attempt	O
to	O
make	O
better	O
use	O
of	O
the	O
multiple	O
human	O
-	O
provided	O
answers	O
,	O
we	O
propose	O
to	O
use	O
the	O
soft	O
ground	O
truth	O
scores	O
as	O
the	O
target	O
with	O
a	O
logarithmic	O
loss	O
.	O

This	O
shows	O
an	O
advantage	O
on	O
the	O
“	O
abstract	Material
scenes	Material
”	Material
dataset	Material
(	O
Fig	O
.	O

[	O
reference	O
]	O
,	O
left	O
and	O
middle	O
)	O
.	O

In	O
that	O
dataset	O
,	O
the	O
soft	O
target	O
scores	O
reflect	O
frequent	O
ambiguities	O
in	O
the	O
questions	O
and	O
the	O
scenes	O
,	O
and	O
when	O
synonyms	O
constitute	O
multiple	O
acceptable	O
answers	O
.	O

In	O
those	O
cases	O
,	O
we	O
can	O
avoid	O
the	O
potential	O
confusion	O
induced	O
by	O
a	O
hard	O
classification	O
for	O
one	O
specific	O
answer	O
.	O

The	O
“	O
balanced	O
”	O
dataset	O
,	O
by	O
nature	O
,	O
contains	O
almost	O
no	O
such	O
ambiguities	O
,	O
and	O
there	O
is	O
no	O
significant	O
difference	O
between	O
the	O
different	O
training	O
objectives	O
(	O
Fig	O
.	O

[	O
reference	O
]	O
,	O
right	O
)	O
.	O

paragraph	O
:	O
Effect	O
of	O
training	O
set	O
size	O
Our	O
motivation	O
for	O
introducing	O
language	Task
parsing	Task
and	O
pretrained	Task
word	Task
embeddings	Task
is	O
to	O
better	O
generalize	O
the	O
concepts	O
learned	O
from	O
the	O
limited	O
training	O
examples	O
.	O

Words	O
representing	O
semantically	O
close	O
concepts	O
ideally	O
get	O
assigned	O
close	O
word	O
embeddings	O
.	O

Similarly	O
,	O
paraphrases	O
of	O
similar	O
questions	O
should	O
produce	O
parse	O
graphs	O
with	O
more	O
similarities	O
than	O
a	O
simple	O
concatenation	O
of	O
words	O
would	O
reveal	O
(	O
as	O
in	O
the	O
input	O
to	O
traditional	O
LSTMs	Method
)	O
.	O

We	O
trained	O
our	O
model	O
with	O
limited	O
subsets	O
of	O
the	O
training	O
data	O
(	O
see	O
Fig	O
.	O

[	O
reference	O
]	O
)	O
.	O

Unsurprisingly	O
,	O
the	O
performance	O
grows	O
steadily	O
with	O
the	O
amount	O
of	O
training	O
data	O
,	O
which	O
suggests	O
that	O
larger	O
datasets	O
would	O
improve	O
performance	O
.	O

In	O
our	O
opinion	O
however	O
,	O
it	O
seems	O
unlikely	O
that	O
sufficient	O
data	O
,	O
covering	O
all	O
possible	O
concepts	O
,	O
could	O
be	O
collected	O
in	O
the	O
form	O
of	O
question	O
/	O
answer	O
examples	O
.	O

More	O
data	O
can	O
however	O
be	O
brought	O
in	O
with	O
other	O
sources	O
of	O
information	O
and	O
supervision	O
.	O

Our	O
use	O
of	O
parsing	Method
and	O
word	Method
embeddings	Method
is	O
a	O
small	O
step	O
in	O
that	O
direction	O
.	O

Both	O
techniques	O
clearly	O
improve	O
generalization	Task
(	O
Fig	O
.	O

[	O
reference	O
]	O
)	O
.	O

The	O
effect	O
may	O
be	O
particularly	O
visible	O
in	O
our	O
case	O
because	O
of	O
the	O
relatively	O
small	O
number	O
of	O
training	O
examples	O
(	O
about	O
k	O
questions	O
in	O
the	O
“	O
balanced	O
”	O
dataset	O
)	O
.	O

It	O
is	O
unclear	O
whether	O
huge	O
VQA	Task
datasets	O
could	O
ultimately	O
negate	O
this	O
advantage	O
.	O

Future	O
experiments	O
on	O
larger	O
datasets	O
(	O
e.g	O
.	O

)	O
may	O
answer	O
this	O
question	O
.	O

subsection	O
:	O
Evaluation	O
on	O
the	O
“	O
abstract	Material
scenes	Material
”	Material
dataset	Material
We	O
report	O
our	O
results	O
on	O
the	O
original	O
“	O
abstract	Material
scenes	Material
”	Material
dataset	Material
in	O
Table	O
[	O
reference	O
]	O
.	O

The	O
evaluation	O
is	O
performed	O
on	O
an	O
automated	O
server	O
that	O
does	O
not	O
allow	O
for	O
an	O
extensive	O
ablative	Task
analysis	Task
.	O

Anecdotally	O
,	O
performance	O
on	O
the	O
validation	O
set	O
corroborates	O
all	O
findings	O
presented	O
above	O
,	O
in	O
particular	O
the	O
strong	O
benefit	O
of	O
pre	Method
-	Method
parsing	Method
,	O
pretrained	Method
word	Method
embeddings	Method
,	O
and	O
graph	Method
processing	Method
with	O
a	O
GRU	Method
.	O

At	O
the	O
time	O
of	O
our	O
submission	O
,	O
our	O
method	O
occupies	O
the	O
top	O
place	O
on	O
the	O
leader	O
board	O
in	O
both	O
the	O
open	O
-	O
ended	O
and	O
multiple	Task
choice	Task
settings	Task
.	O

The	O
advantage	O
over	O
existing	O
method	O
is	O
most	O
pronounced	O
on	O
the	O
binary	Task
and	Task
the	Task
counting	Task
questions	Task
.	O

Refer	O
to	O
Fig	O
.	O

[	O
reference	O
]	O
and	O
to	O
the	O
supplementary	O
for	O
visualizations	O
of	O
the	O
results	O
.	O

section	O
:	O
Conclusions	O
We	O
presented	O
a	O
deep	Method
neural	Method
network	Method
for	O
visual	Task
question	Task
answering	Task
that	O
processes	O
graph	Task
-	Task
structured	Task
representations	Task
of	Task
scenes	Task
and	Task
questions	Task
.	O

This	O
enables	O
leveraging	O
existing	O
natural	Method
language	Method
processing	Method
tools	Method
,	O
in	O
particular	O
pretrained	Method
word	Method
embeddings	Method
and	O
syntactic	Task
parsing	Task
.	O

The	O
latter	O
showed	O
significant	O
advantage	O
over	O
a	O
traditional	O
sequential	Task
processing	Task
of	Task
the	Task
questions	Task
,	O
e.g	O
.	O

with	O
LSTMs	Method
.	O

In	O
our	O
opinion	O
,	O
VQA	Task
systems	O
are	O
unlikely	O
to	O
learn	O
everything	O
from	O
question	O
/	O
answer	O
examples	O
alone	O
.	O

We	O
believe	O
that	O
any	O
significant	O
improvement	O
in	O
performance	O
will	O
require	O
additional	O
sources	O
of	O
information	O
and	O
supervision	O
.	O

Our	O
explicit	O
processing	O
of	O
the	O
language	O
part	O
is	O
a	O
small	O
step	O
in	O
that	O
direction	O
.	O

It	O
has	O
clearly	O
shown	O
to	O
improve	O
generalization	Task
without	O
resting	O
entirely	O
on	O
VQA	Task
-	O
specific	O
annotations	O
.	O

We	O
have	O
so	O
far	O
applied	O
our	O
method	O
to	O
datasets	O
of	O
clip	O
art	O
scenes	O
.	O

Its	O
direct	O
extension	O
to	O
real	O
images	O
will	O
be	O
addressed	O
in	O
future	O
work	O
,	O
by	O
replacing	O
nodes	O
in	O
the	O
input	O
scene	O
graph	O
with	O
proposals	O
from	O
pretrained	Method
object	Method
detectors	Method
.	O

bibliography	O
:	O
References	O
appendix	O
:	O
Supplementary	O
material	O
appendix	O
:	O
Implementation	O
We	O
provide	O
below	O
practical	O
details	O
of	O
our	O
implementation	O
of	O
the	O
proposed	O
method	O
.	O

Size	O
of	O
vector	O
embeddings	O
of	O
node	O
features	O
,	O
edge	O
features	O
,	O
and	O
all	O
hidden	O
states	O
within	O
the	O
network	O
:	O
=	O
300	O
.	O

Note	O
that	O
smaller	O
values	O
such	O
as	O
=	O
200	O
also	O
give	O
very	O
good	O
results	O
(	O
not	O
reported	O
in	O
this	O
paper	O
)	O
at	O
a	O
fraction	O
of	O
the	O
training	O
time	O
.	O

Number	O
of	O
recurrent	O
iterations	O
to	O
update	O
graph	Method
node	Method
representations	Method
:	O
=	O
=	O
4	O
.	O

Anecdotally	O
,	O
we	O
observed	O
that	O
processing	O
the	O
scene	O
graph	O
benefits	O
from	O
more	O
iterations	O
than	O
the	O
question	O
graph	O
,	O
for	O
which	O
performance	O
nearly	O
saturates	O
with	O
2	O
or	O
more	O
iterations	O
.	O

As	O
reported	O
in	O
the	O
ablative	O
evaluation	O
(	O
Table	O
[	O
reference	O
]	O
)	O
,	O
the	O
use	O
of	O
at	O
least	O
a	O
single	O
iteration	O
has	O
a	O
stronger	O
influence	O
than	O
its	O
exact	O
number	O
.	O

All	O
weights	O
except	O
word	O
embeddings	O
are	O
initialized	O
randomly	O
following	O
.	O

Word	Method
embeddings	Method
are	O
initialized	O
with	O
Glove	O
vectors	O
of	O
dimension	O
300	O
available	O
publicly	O
,	O
trained	O
for	O
6	O
billion	O
words	O
on	O
Wikipedia	Material
and	O
Gigaword	Material
.	O

The	O
word	O
embeddings	O
are	O
fine	O
-	O
tuned	O
with	O
a	O
learning	Metric
rate	Metric
of	O
of	O
the	O
other	O
weights	O
.	O

Dropout	Method
with	O
ratio	O
0.3	O
is	O
applied	O
between	O
the	O
weighted	O
sum	O
over	O
scene	O
elements	O
(	O
Eq	O
.	O

[	O
reference	O
]	O
)	O
and	O
the	O
final	O
classifier	Method
(	O
Eq	O
.	O

[	O
reference	O
]	O
)	O
.	O

Weights	O
are	O
optimized	O
with	O
Adadelta	Method
with	O
mini	O
-	O
batches	O
of	O
128	O
questions	O
.	O

We	O
run	O
optimization	Method
until	O
convergence	O
(	O
typically	O
20	O
epochs	O
on	O
the	O
“	O
abstract	Material
scenes	Material
”	O
,	O
100	O
epochs	O
on	O
the	O
“	O
balanced	O
”	O
dataset	O
)	O
and	O
report	O
performance	O
on	O
the	O
test	O
set	O
from	O
the	O
epoch	O
with	O
the	O
highest	O
performance	O
on	O
the	O
validation	O
set	O
(	O
measured	O
by	O
VQA	Task
score	O
on	O
the	O
“	O
abstract	Material
scenes	Material
”	Material
dataset	Material
,	O
and	O
accuracy	Metric
over	O
pairs	O
on	O
the	O
“	O
balanced	O
”	O
dataset	O
)	O
.	O

The	O
edges	O
between	O
word	O
nodes	O
in	O
the	O
input	O
question	O
graph	O
are	O
labeled	O
with	O
the	O
dependency	O
labels	O
identified	O
by	O
the	O
Stanford	Method
parser	Method
.	O

These	O
dependencies	O
are	O
directed	O
,	O
and	O
we	O
supplement	O
all	O
of	O
them	O
with	O
their	O
symmetric	O
,	O
albeit	O
tagged	O
with	O
a	O
different	O
set	O
of	O
labels	O
.	O

The	O
output	O
of	O
the	O
parser	Method
includes	O
the	O
propagation	O
of	O
conjunct	O
dependencies	O
(	O
its	O
default	O
setting	O
)	O
.	O

This	O
yields	O
quite	O
densely	O
connected	O
graphs	O
.	O

The	O
input	O
features	O
of	O
the	O
object	O
nodes	O
are	O
those	O
directly	O
available	O
in	O
the	O
datasets	O
.	O

They	O
represent	O
:	O
the	O
object	O
category	O
(	O
human	O
,	O
animal	O
,	O
small	O
or	O
large	O
object	O
)	O
as	O
one	O
one	O
-	O
hot	O
vector	O
,	O
the	O
object	O
type	O
(	O
table	O
,	O
sun	O
,	O
dog	O
window	O
,	O
…	O
)	O
as	O
a	O
one	O
-	O
hot	O
vector	O
,	O
the	O
expression	O
/	O
pose	O
/	O
type	O
(	O
various	O
depictions	O
being	O
possible	O
for	O
each	O
object	O
type	O
)	O
as	O
a	O
one	O
-	O
hot	O
vector	O
,	O
and	O
10	O
scalar	O
values	O
describing	O
the	O
pose	O
of	O
human	O
figures	O
(	O
the	O
X	O
/	O
Y	O
position	O
of	O
arms	O
,	O
legs	O
,	O
and	O
head	O
relative	O
to	O
the	O
torso	O
)	O
.	O

They	O
form	O
altogether	O
a	O
feature	O
vector	O
of	O
dimension	O
159	O
.	O

The	O
edge	O
features	O
between	O
objects	O
represent	O
:	O
the	O
signed	O
difference	O
in	O
their	O
X	O
/	O
Y	O
position	O
,	O
the	O
inverse	O
of	O
their	O
absolute	O
difference	O
in	O
X	O
/	O
Y	O
position	O
,	O
and	O
their	O
relative	O
position	O
on	O
depth	O
planes	O
as	O
+	O
1	O
if	O
closer	O
(	O
potentially	O
occluding	O
the	O
other	O
)	O
,	O
-	O
1	O
otherwise	O
.	O

All	O
input	O
features	O
are	O
normalized	O
for	O
zero	O
mean	O
and	O
unit	O
variance	O
.	O

When	O
training	O
for	O
the	O
“	O
balanced	O
”	O
dataset	O
,	O
care	O
is	O
taken	O
to	O
keep	O
each	O
pair	O
of	O
complementary	O
scenes	O
in	O
a	O
same	O
mini	O
-	O
batch	O
when	O
shuffling	O
training	O
instances	O
.	O

This	O
has	O
a	O
noticeable	O
effect	O
on	O
the	O
stability	O
of	O
the	O
optimization	Task
.	O

In	O
the	O
open	Task
-	Task
ended	Task
setting	Task
,	O
the	O
output	O
space	O
is	O
made	O
of	O
all	O
answers	O
that	O
appear	O
at	O
least	O
5	O
times	O
in	O
the	O
training	O
set	O
.	O

These	O
correspond	O
to	O
623	O
possible	O
answers	O
,	O
which	O
cover	O
96	O
%	O
of	O
the	O
training	O
questions	O
.	O

Our	O
model	O
was	O
implemented	O
in	O
Matlab	O
from	O
scratch	O
.	O

Training	Task
takes	O
in	O
the	O
order	O
of	O
5	O
to	O
10	O
hours	O
on	O
one	O
CPU	O
,	O
depending	O
on	O
the	O
dataset	O
and	O
on	O
the	O
size	O
of	O
the	O
internal	Method
representations	Method
.	O

appendix	O
:	O
Additional	O
details	O
Why	O
do	O
we	O
choose	O
to	O
focus	O
on	O
abstract	O
scenes	O
?	O
Does	O
this	O
method	O
extend	O
to	O
real	O
images	O
?	O
The	O
balanced	Material
dataset	Material
of	Material
abstract	Material
scenes	Material
was	O
the	O
only	O
one	O
allowing	O
evaluation	O
free	O
from	O
dataset	O
biases	O
.	O

Abstract	Material
scenes	Material
also	O
enabled	O
removing	O
confounding	O
factors	O
(	O
visual	Task
recognition	Task
)	O
.	O

It	O
is	O
not	O
unreasonable	O
to	O
view	O
the	O
scene	O
descriptions	O
(	O
provided	O
with	O
abstract	Material
scenes	Material
)	O
as	O
the	O
output	O
of	O
a	O
“	O
perfect	O
”	O
vision	Method
system	Method
.	O

The	O
proposel	O
model	O
could	O
be	O
extended	O
to	O
real	O
images	O
by	O
building	O
graphs	O
of	O
the	O
images	O
where	O
scene	O
nodes	O
are	O
candidates	O
from	O
an	O
object	Method
detection	Method
algorithm	Method
.	O

The	O
multiple	O
-	O
choice	O
(	O
M.C.	O
)	O
setting	O
should	O
be	O
easier	O
than	O
open	O
-	O
ended	O
(	O
O.E.	O
)	O
.	O

Therefore	O
,	O
why	O
is	O
the	O
accuracy	Metric
not	O
better	O
for	O
binary	O
and	O
number	O
questions	O
in	O
the	O
M.C	O
setting	O
(	O
rather	O
than	O
O.E.	O
)	O
?	O
This	O
intuition	O
is	O
incorrect	O
in	O
practice	O
.	O

The	O
wording	O
of	O
binary	O
and	O
number	O
questions	O
(	O
“	O
How	O
many	O
…	O
”	O
)	O
can	O
easily	O
narrow	O
down	O
the	O
set	O
of	O
possible	O
answers	O
,	O
whether	O
evaluated	O
in	O
a	O
M.C.	O
or	O
O.E.	O
setting	O
.	O

One	O
thus	O
can	O
not	O
qualify	O
one	O
as	O
strictly	O
easier	O
than	O
the	O
other	O
.	O

Other	O
factors	O
can	O
then	O
influence	O
the	O
performance	O
either	O
way	O
.	O

Note	O
also	O
that	O
,	O
for	O
example	O
that	O
most	O
choices	O
of	O
number	O
questions	O
are	O
not	O
numbers	O
.	O

In	O
Table	O
1	O
,	O
why	O
is	O
there	O
a	O
large	O
improvement	O
of	O
the	O
metric	O
over	O
balanced	O
pairs	O
of	O
scenes	O
,	O
but	O
not	O
of	O
the	O
metric	O
over	O
individual	O
scenes	O
?	O
The	O
metric	O
over	O
pairs	O
is	O
much	O
harder	O
to	O
satisfy	O
and	O
should	O
be	O
regarded	O
as	O
more	O
meaningful	O
.	O

The	O
other	O
metric	O
(	O
over	O
scenes	O
)	O
essentially	O
saturates	O
at	O
the	O
same	O
point	O
between	O
the	O
two	O
methods	O
.	O

How	O
are	O
precison	Metric
/	Metric
recall	Metric
curves	Metric
helping	O
better	O
understand	O
model	O
compared	O
to	O
a	O
simple	O
accuracy	Metric
number	Metric
?	O
A	O
P	O
/	O
R	O
curve	O
shows	O
the	O
confidence	O
of	O
the	O
model	O
in	O
its	O
answers	O
.	O

A	O
practical	O
VQA	Task
system	O
will	O
need	O
to	O
provide	O
an	O
indication	O
of	O
certainty	O
,	O
including	O
the	O
possibility	O
of	O
“	O
I	O
do	O
n’t	O
know	O
”	O
.	O

Reporting	O
P	O
/	O
R	O
is	O
a	O
step	O
in	O
that	O
direction	O
.	O

P	O
/	O
R	O
curves	O
also	O
contain	O
more	O
information	O
and	O
can	O
show	O
differences	O
between	O
methods	O
(	O
e.g	O
.	O

Fig.3	O
left	O
)	O
that	O
may	O
otherwise	O
not	O
be	O
appreciable	O
through	O
an	O
aggregate	Metric
metric	Metric
.	O

Why	O
is	O
attention	O
computed	O
with	O
pre	O
-	O
GRU	O
node	O
features	O
?	O
This	O
performed	O
slightly	O
better	O
than	O
the	O
alternative	O
.	O

The	O
intuition	O
is	O
that	O
the	O
identity	O
of	O
each	O
node	O
is	O
sufficient	O
,	O
and	O
the	O
context	O
(	O
transfered	O
by	O
the	O
GRU	Method
from	O
neighbouring	O
nodes	O
)	O
is	O
probably	O
less	O
useful	O
to	O
compute	O
attention	O
.	O

Why	O
are	O
the	O
largest	O
performance	O
gains	O
obtained	O
with	O
“	O
number	O
”	O
questions	O
?	O
We	O
could	O
not	O
draw	O
definitive	O
conclusions	O
.	O

Competing	Method
methods	Method
seem	O
to	O
rely	O
on	O
dataset	O
biases	O
(	O
predominance	O
of	O
2	O
and	O
3	O
as	O
answers	O
)	O
.	O

Ours	O
was	O
developed	O
(	O
cross	O
-	O
validated	O
)	O
for	O
the	O
balanced	O
dataset	O
,	O
which	O
requires	O
not	O
to	O
rely	O
on	O
such	O
biases	O
,	O
and	O
may	O
simply	O
be	O
better	O
at	O
utilizing	O
the	O
input	O
and	O
not	O
biases	O
.	O

This	O
may	O
in	O
turn	O
explain	O
minimal	O
gains	O
on	O
other	O
questions	O
,	O
which	O
could	O
benefit	O
from	O
using	O
biases	O
(	O
because	O
of	O
a	O
larger	O
pool	O
of	O
reasonable	O
answers	O
)	O
.	O

appendix	O
:	O
Additional	O
results	O
We	O
provide	O
below	O
additional	O
example	O
results	O
in	O
the	O
same	O
format	O
as	O
in	O
Fig	O
.	O

[	O
reference	O
]	O
.	O

subsection	O
:	O
Additional	O
results	O
:	O
abstract	O
scenes	O
dataset	O
subsection	O
:	O
Additional	O
results	O
:	O
balanced	O
dataset	O
