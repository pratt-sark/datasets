document	O
:	O
Unsupervised	Task
Cross	Task
-	Task
Domain	Task
Image	Task
Generation	Task
We	O
study	O
the	O
problem	O
of	O
transferring	O
a	O
sample	O
in	O
one	O
domain	O
to	O
an	O
analog	O
sample	O
in	O
another	O
domain	O
.	O

Given	O
two	O
related	O
domains	O
,	O
and	O
,	O
we	O
would	O
like	O
to	O
learn	O
a	O
generative	Method
function	Method
that	O
maps	O
an	O
input	O
sample	O
from	O
to	O
the	O
domain	O
,	O
such	O
that	O
the	O
output	O
of	O
a	O
given	O
function	O
,	O
which	O
accepts	O
inputs	O
in	O
either	O
domains	O
,	O
would	O
remain	O
unchanged	O
.	O

Other	O
than	O
the	O
function	O
,	O
the	O
training	O
data	O
is	O
unsupervised	O
and	O
consist	O
of	O
a	O
set	O
of	O
samples	O
from	O
each	O
domain	O
.	O

The	O
Domain	Method
Transfer	Method
Network	Method
(	O
DTN	Method
)	O
we	O
present	O
employs	O
a	O
compound	Method
loss	Method
function	Method
that	O
includes	O
a	O
multiclass	O
GAN	Method
loss	O
,	O
an	O
-	Method
constancy	Method
component	Method
,	O
and	O
a	O
regularizing	Method
component	Method
that	O
encourages	O
to	O
map	O
samples	O
from	O
to	O
themselves	O
.	O

We	O
apply	O
our	O
method	O
to	O
visual	O
domains	O
including	O
digits	O
and	O
face	O
images	O
and	O
demonstrate	O
its	O
ability	O
to	O
generate	O
convincing	O
novel	O
images	O
of	O
previously	O
unseen	O
entities	O
,	O
while	O
preserving	O
their	O
identity	O
.	O

section	O
:	O
Introduction	O
Humans	O
excel	O
in	O
tasks	O
that	O
require	O
making	O
analogies	O
between	O
distinct	O
domains	O
,	O
transferring	O
elements	O
from	O
one	O
domain	O
to	O
another	O
,	O
and	O
using	O
these	O
capabilities	O
in	O
order	O
to	O
blend	O
concepts	O
that	O
originated	O
from	O
multiple	O
source	O
domains	O
.	O

Our	O
experience	O
tells	O
us	O
that	O
these	O
remarkable	O
capabilities	O
are	O
developed	O
with	O
very	O
little	O
,	O
if	O
any	O
,	O
supervision	O
that	O
is	O
given	O
in	O
the	O
form	O
of	O
explicit	O
analogies	O
.	O

Recent	O
achievements	O
replicate	O
some	O
of	O
these	O
capabilities	O
to	O
some	O
degree	O
:	O
Generative	Method
Adversarial	Method
Networks	Method
(	O
GANs	Method
)	O
are	O
able	O
to	O
convincingly	O
generate	O
novel	O
samples	O
that	O
match	O
that	O
of	O
a	O
given	O
training	O
set	O
;	O
style	Method
transfer	Method
methods	Method
are	O
able	O
to	O
alter	O
the	O
visual	O
style	O
of	O
images	O
;	O
domain	Method
adaptation	Method
methods	Method
are	O
able	O
to	O
generalize	O
learned	O
functions	O
to	O
new	O
domains	O
even	O
without	O
labeled	O
samples	O
in	O
the	O
target	O
domain	O
and	O
transfer	Method
learning	Method
is	O
now	O
commonly	O
used	O
to	O
import	O
existing	O
knowledge	O
and	O
to	O
make	O
learning	Task
much	O
more	O
efficient	O
.	O

These	O
capabilities	O
,	O
however	O
,	O
do	O
not	O
address	O
the	O
general	O
analogy	Task
synthesis	Task
problem	Task
that	O
we	O
tackle	O
in	O
this	O
work	O
.	O

Namely	O
,	O
given	O
separated	O
but	O
otherwise	O
unlabeled	O
samples	O
from	O
domains	O
and	O
and	O
a	O
multivariate	O
function	O
,	O
learn	O
a	O
mapping	Method
such	O
that	O
.	O

In	O
order	O
to	O
solve	O
this	O
problem	O
,	O
we	O
make	O
use	O
of	O
deep	Method
neural	Method
networks	Method
of	O
a	O
specific	O
structure	O
in	O
which	O
the	O
function	O
is	O
a	O
composition	O
of	O
the	O
input	O
function	O
and	O
a	O
learned	O
function	O
.	O

A	O
compound	Method
loss	Method
that	O
integrates	O
multiple	O
terms	O
is	O
used	O
.	O

One	O
term	O
is	O
a	O
Generative	Method
Adversarial	Method
Network	Method
(	O
GAN	Method
)	O
term	O
that	O
encourages	O
the	O
creation	O
of	O
samples	O
that	O
are	O
indistinguishable	O
from	O
the	O
training	O
samples	O
of	O
the	O
target	O
domain	O
,	O
regardless	O
of	O
or	O
.	O

The	O
second	O
loss	O
term	O
enforces	O
that	O
for	O
every	O
in	O
the	O
source	O
domain	O
training	O
set	O
,	O
is	O
small	O
.	O

The	O
third	O
loss	O
term	O
is	O
a	O
regularizer	Method
that	O
encourages	O
to	O
be	O
the	O
identity	O
mapping	O
for	O
all	O
.	O

The	O
type	O
of	O
problems	O
we	O
focus	O
on	O
in	O
our	O
experiments	O
are	O
visual	O
,	O
although	O
our	O
methods	O
are	O
not	O
limited	O
to	O
visual	O
or	O
even	O
to	O
perceptual	Task
tasks	Task
.	O

Typically	O
,	O
would	O
be	O
a	O
neural	Method
network	Method
representation	Method
that	O
is	O
taken	O
as	O
the	O
activations	O
of	O
a	O
network	O
that	O
was	O
trained	O
,	O
e.g.	O
,	O
by	O
using	O
the	O
cross	O
entropy	O
loss	O
,	O
in	O
order	O
to	O
classify	O
or	O
to	O
capture	O
identity	O
.	O

As	O
a	O
main	O
application	O
challenge	O
,	O
we	O
tackle	O
the	O
problem	O
of	O
emoji	Task
generation	Task
for	O
a	O
given	O
facial	O
image	O
.	O

Despite	O
a	O
growing	O
interest	O
in	O
emoji	O
and	O
the	O
hurdle	O
of	O
creating	O
such	O
personal	O
emoji	O
manually	O
,	O
no	O
system	O
has	O
been	O
proposed	O
,	O
to	O
our	O
knowledge	O
,	O
that	O
can	O
solve	O
this	O
problem	O
.	O

Our	O
method	O
is	O
able	O
to	O
produce	O
face	O
emoji	O
that	O
are	O
visually	O
appealing	O
and	O
capture	O
much	O
more	O
of	O
the	O
facial	O
characteristics	O
than	O
the	O
emoji	O
created	O
by	O
well	O
-	O
trained	O
human	Method
annotators	Method
who	O
use	O
the	O
conventional	O
tools	O
.	O

section	O
:	O
Related	O
work	O
As	O
far	O
as	O
we	O
know	O
,	O
the	O
domain	Method
transfer	Method
problem	O
we	O
formulate	O
is	O
novel	O
despite	O
being	O
ecological	O
(	O
i.e.	O
,	O
appearing	O
naturally	O
in	O
the	O
real	O
-	O
world	O
)	O
,	O
widely	O
applicable	O
,	O
and	O
related	O
to	O
cognitive	Task
reasoning	Task
thewaywethink	O
.	O

In	O
the	O
discussion	O
below	O
,	O
we	O
survey	O
recent	O
GAN	Method
work	O
,	O
compare	O
our	O
work	O
to	O
the	O
recent	O
image	Task
synthesis	Task
work	O
and	O
make	O
links	O
to	O
unsupervised	Task
domain	Task
adaptation	Task
.	O

GAN	Method
gan	O
methods	O
train	O
a	O
generator	Method
network	Method
that	O
synthesizes	O
samples	O
from	O
a	O
target	O
distribution	O
given	O
noise	O
vectors	O
.	O

is	O
trained	O
jointly	O
with	O
a	O
discriminator	Method
network	Method
,	O
which	O
distinguishes	O
between	O
samples	O
generated	O
by	O
and	O
a	O
training	O
set	O
from	O
the	O
target	O
distribution	O
.	O

The	O
goal	O
of	O
is	O
to	O
create	O
samples	O
that	O
are	O
classified	O
by	O
as	O
real	O
samples	O
.	O

While	O
originally	O
proposed	O
for	O
generating	Task
random	Task
samples	Task
,	O
GANs	Method
can	O
be	O
used	O
as	O
a	O
general	O
tool	O
to	O
measure	O
equivalence	O
between	O
distributions	O
.	O

Specifically	O
,	O
the	O
optimization	Task
of	O
corresponds	O
to	O
taking	O
the	O
most	O
discriminative	O
achievable	O
,	O
which	O
in	O
turn	O
implies	O
that	O
the	O
indistinguishability	O
is	O
true	O
for	O
every	O
.	O

Formally	O
,	O
domaingan	O
linked	O
the	O
GAN	Method
loss	O
to	O
the	O
H	O
-	O
divergence	O
between	O
two	O
distributions	O
of	O
bendavid	O
.	O

The	O
generative	Method
architecture	Method
that	O
we	O
employ	O
is	O
based	O
on	O
the	O
successful	O
architecture	O
of	O
dcgan	Method
.	O

There	O
has	O
recently	O
been	O
a	O
growing	O
concern	O
about	O
the	O
uneven	O
distribution	O
of	O
the	O
samples	O
generated	O
by	O
–	O
that	O
they	O
tend	O
to	O
cluster	O
around	O
a	O
set	O
of	O
modes	O
in	O
the	O
target	O
domain	O
gantricks	O
.	O

In	O
general	O
,	O
we	O
do	O
not	O
observe	O
such	O
an	O
effect	O
in	O
our	O
results	O
,	O
due	O
to	O
the	O
requirement	O
to	O
generate	O
samples	O
that	O
satisfy	O
specific	O
-	O
constancy	O
criteria	O
.	O

A	O
few	O
contributions	O
(	O
“	O
Conditional	Method
GANs	Method
”	O
)	O
have	O
employed	O
GANs	Method
in	O
order	O
to	O
generate	O
samples	O
from	O
a	O
specific	O
class	O
mirza2014conditional	O
,	O
or	O
even	O
based	O
on	O
a	O
textual	Method
description	Method
RAYLLS16	Method
.	O

When	O
performing	O
such	O
conditioning	O
,	O
one	O
can	O
distinguish	O
between	O
samples	O
that	O
were	O
correctly	O
generated	O
but	O
fail	O
to	O
match	O
the	O
conditional	O
constraint	O
and	O
samples	O
that	O
were	O
not	O
correctly	O
generated	O
.	O

This	O
is	O
modeled	O
as	O
a	O
ternary	Method
discriminative	Method
function	Method
RAYLLS16	O
,	O
introspectivegan	O
.	O

The	O
recent	O
work	O
by	O
deepsim	Method
,	O
has	O
shown	O
promising	O
results	O
for	O
learning	O
to	O
map	O
embeddings	Task
to	O
their	O
pre	O
-	O
images	O
,	O
given	O
input	O
-	O
target	O
pairs	O
.	O

Like	O
us	O
,	O
they	O
employ	O
a	O
GAN	Method
as	O
well	O
as	O
additional	O
losses	O
in	O
the	O
feature	O
-	O
and	O
the	O
pixel	O
-	O
space	O
.	O

Their	O
method	O
is	O
able	O
to	O
invert	O
the	O
mid	O
-	O
level	O
activations	O
of	O
AlexNet	Method
and	O
reconstruct	O
the	O
input	O
image	O
.	O

In	O
contrast	O
,	O
we	O
solve	O
the	O
problem	O
of	O
unsupervised	Task
domain	Task
transfer	Task
and	O
apply	O
the	O
loss	Method
terms	Method
in	O
different	O
domains	O
:	O
pixel	O
loss	O
in	O
the	O
target	O
domain	O
,	O
and	O
feature	Method
loss	Method
in	O
the	O
source	O
domain	O
.	O

Another	O
class	O
of	O
very	O
promising	O
generative	Method
techniques	Method
that	O
has	O
recently	O
gained	O
traction	O
is	O
neural	Method
style	Method
transfer	Method
.	O

In	O
these	O
methods	O
,	O
new	O
images	O
are	O
synthesized	O
by	O
minimizing	O
the	O
content	Metric
loss	Metric
with	O
respect	O
to	O
one	O
input	O
sample	O
and	O
the	O
style	O
loss	O
with	O
respect	O
to	O
one	O
or	O
more	O
input	O
samples	O
.	O

The	O
content	Task
loss	Task
is	O
typically	O
the	O
encoding	O
of	O
the	O
image	O
by	O
a	O
network	Method
training	Method
for	O
an	O
image	Task
categorization	Task
task	Task
,	O
similar	O
to	O
our	O
work	O
.	O

The	O
style	Metric
loss	Metric
compares	O
the	O
statistics	O
of	O
the	O
activations	O
in	O
various	O
layers	O
of	O
the	O
neural	Method
network	Method
.	O

We	O
do	O
not	O
employ	O
style	O
losses	O
in	O
our	O
method	O
.	O

While	O
initially	O
style	Method
transfer	Method
was	O
obtained	O
by	O
a	O
slow	Method
optimization	Method
process	Method
styletransfer	Method
,	O
recently	O
,	O
the	O
emphasis	O
was	O
put	O
on	O
feed	Method
-	Method
forward	Method
methods	Method
ulyanov16texture	O
,	O
Johnson2016Perceptual	O
.	O

There	O
are	O
many	O
links	O
between	O
style	Task
transfer	Task
and	O
our	O
work	O
:	O
both	O
are	O
unsupervised	O
and	O
generate	O
a	O
sample	O
under	O
constancy	O
given	O
an	O
input	O
sample	O
.	O

However	O
,	O
our	O
work	O
is	O
much	O
more	O
general	O
in	O
its	O
scope	O
and	O
does	O
not	O
rely	O
on	O
a	O
predefined	O
family	O
of	O
perceptual	O
losses	O
.	O

Our	O
method	O
can	O
be	O
used	O
in	O
order	O
to	O
perform	O
style	Task
transfer	Task
,	O
but	O
not	O
the	O
other	O
way	O
around	O
.	O

Another	O
key	O
difference	O
is	O
that	O
the	O
current	O
style	Method
transfer	Method
methods	Method
are	O
aimed	O
at	O
replicating	O
the	O
style	O
of	O
one	O
or	O
several	O
images	O
,	O
while	O
our	O
work	O
considers	O
a	O
distribution	O
in	O
the	O
target	O
space	O
.	O

In	O
many	O
applications	O
,	O
there	O
is	O
an	O
abundance	O
of	O
unlabeled	O
data	O
in	O
the	O
target	O
domain	O
,	O
which	O
can	O
be	O
modeled	O
accurately	O
in	O
an	O
unsupervised	Method
manner	Method
.	O

Given	O
the	O
impressive	O
results	O
of	O
recent	O
style	Method
transfer	Method
work	O
,	O
in	O
particular	O
for	O
face	Task
images	Task
,	O
one	O
might	O
get	O
the	O
false	O
impression	O
that	O
emoji	O
are	O
just	O
a	O
different	O
style	O
of	O
drawing	O
faces	O
.	O

By	O
way	O
of	O
analogy	O
,	O
this	O
claim	O
is	O
similar	O
to	O
stating	O
that	O
a	O
Siamese	O
cat	O
is	O
a	O
Labrador	O
in	O
a	O
different	O
style	O
.	O

Emoji	O
differ	O
from	O
facial	O
photographs	O
in	O
both	O
content	O
and	O
style	O
.	O

Style	Task
transfer	Task
can	O
create	O
visually	O
appealing	O
face	O
images	O
;	O
However	O
,	O
the	O
properties	O
of	O
the	O
target	O
domain	O
are	O
compromised	O
.	O

In	O
the	O
computer	Task
vision	Task
literature	O
,	O
work	O
has	O
been	O
done	O
to	O
automatically	O
generate	O
sketches	O
from	O
images	O
,	O
see	O
6243138	O
for	O
a	O
survey	O
.	O

These	O
systems	O
are	O
able	O
to	O
emphasize	O
image	O
edges	O
and	O
facial	O
features	O
in	O
a	O
convincing	O
way	O
.	O

However	O
,	O
unlike	O
our	O
method	O
,	O
they	O
require	O
matching	O
pairs	O
of	O
samples	O
,	O
and	O
were	O
not	O
shown	O
to	O
work	O
across	O
two	O
distant	O
domains	O
as	O
in	O
our	O
method	O
.	O

Due	O
to	O
the	O
lack	O
of	O
supervised	O
training	O
data	O
,	O
we	O
did	O
not	O
try	O
to	O
apply	O
such	O
methods	O
to	O
our	O
problems	O
.	O

However	O
,	O
one	O
can	O
assume	O
that	O
if	O
such	O
methods	O
were	O
appropriate	O
for	O
emoji	Task
synthesis	Task
,	O
automatic	Task
face	Task
emoji	Task
services	Task
would	O
be	O
available	O
.	O

Unsupervised	Task
domain	Task
adaptation	Task
addresses	O
the	O
following	O
problem	O
:	O
given	O
a	O
labeled	O
training	O
set	O
in	O
,	O
for	O
some	O
target	O
space	O
,	O
and	O
an	O
unlabeled	O
set	O
of	O
samples	O
from	O
domain	O
,	O
learn	O
a	O
function	O
ICML2012Chen_416	O
,	O
domaingan	O
.	O

One	O
can	O
solve	O
the	O
sample	Task
transfer	Task
problem	Task
(	O
our	O
problem	O
)	O
using	O
domain	Method
adaptation	Method
and	O
vice	O
versa	O
.	O

In	O
both	O
cases	O
,	O
the	O
solution	O
is	O
indirect	O
.	O

In	O
order	O
to	O
solve	O
domain	Method
adaptation	Method
using	O
domain	Method
transfer	Method
,	O
one	O
would	O
learn	O
a	O
function	O
from	O
to	O
and	O
use	O
it	O
as	O
the	O
input	O
method	O
of	O
the	O
domain	Method
transfer	Method
algorithm	Method
in	O
order	O
to	O
obtain	O
a	O
map	O
from	O
to	O
.	O

The	O
training	O
samples	O
could	O
then	O
be	O
transferred	O
to	O
and	O
used	O
to	O
learn	O
a	O
classifier	Method
there	O
.	O

In	O
the	O
other	O
direction	O
,	O
given	O
the	O
function	O
,	O
one	O
can	O
invert	O
in	O
the	O
domain	O
by	O
generating	O
training	O
samples	O
for	O
and	O
learn	O
from	O
them	O
a	O
function	O
from	O
to	O
.	O

Domain	Method
adaptation	Method
can	O
then	O
be	O
used	O
in	O
order	O
to	O
map	O
to	O
,	O
thus	O
achieving	O
domain	Method
transfer	Method
.	O

Based	O
on	O
the	O
work	O
by	O
googlesomething	O
,	O
we	O
expect	O
that	O
,	O
even	O
in	O
the	O
target	O
domain	O
of	O
emoji	O
,	O
will	O
be	O
hard	O
to	O
learn	O
,	O
making	O
this	O
solution	O
hypothetical	O
at	O
this	O
point	O
.	O

section	O
:	O
A	O
baseline	O
problem	O
formulation	O
Given	O
a	O
set	O
of	O
unlabeled	O
samples	O
in	O
a	O
source	O
domain	O
sampled	O
i.i.d	O
according	O
to	O
some	O
distribution	O
,	O
a	O
set	O
of	O
samples	O
in	O
the	O
target	O
domain	O
sampled	O
i.i.d	O
from	O
distribution	O
,	O
a	O
function	O
from	O
the	O
domain	O
,	O
some	O
metric	O
,	O
and	O
a	O
weight	O
,	O
we	O
wish	O
to	O
learn	O
a	O
function	O
that	O
minimizes	O
the	O
combined	Metric
risk	Metric
,	O
which	O
is	O
comprised	O
of	O
where	O
is	O
a	O
binary	O
classification	O
function	O
from	O
,	O
the	O
probability	O
of	O
the	O
class	O
it	O
assigns	O
for	O
a	O
sample	O
,	O
and	O
The	O
first	O
term	O
is	O
the	O
adversarial	O
risk	O
,	O
which	O
requires	O
that	O
for	O
every	O
discriminative	O
function	O
,	O
the	O
samples	O
from	O
the	O
target	O
domain	O
would	O
be	O
indistinguishable	O
from	O
the	O
samples	O
generated	O
by	O
for	O
samples	O
in	O
the	O
source	O
domain	O
.	O

An	O
adversarial	O
risk	O
is	O
not	O
the	O
only	O
option	O
.	O

An	O
alternative	O
term	O
that	O
does	O
not	O
employ	O
GANs	Method
would	O
directly	O
compare	O
the	O
distribution	O
to	O
the	O
distribution	O
of	O
where	O
,	O
e.g.	O
,	O
by	O
using	O
KL	Method
-	Method
divergence	Method
.	O

The	O
second	O
term	O
is	O
the	O
-	O
constancy	O
term	O
,	O
which	O
requires	O
that	O
is	O
invariant	O
under	O
.	O

In	O
practice	O
,	O
we	O
have	O
experimented	O
with	O
multiple	O
forms	O
of	O
including	O
Mean	Metric
Squared	Metric
Error	Metric
(	O
MSE	Metric
)	O
and	O
cosine	Metric
distance	Metric
,	O
as	O
well	O
as	O
other	O
variants	O
including	O
metric	Method
learning	Method
losses	Method
(	O
hinge	Method
)	O
and	O
triplet	Method
losses	Method
.	O

The	O
performance	O
is	O
mostly	O
unchanged	O
,	O
and	O
we	O
report	O
results	O
using	O
the	O
simplest	O
MSE	Metric
solution	O
.	O

Similarly	O
to	O
other	O
GAN	Method
formulations	O
,	O
one	O
can	O
minimize	O
the	O
loss	O
associated	O
with	O
the	O
risk	O
over	O
,	O
while	O
maximizing	O
it	O
over	O
,	O
where	O
and	O
are	O
deep	Method
neural	Method
networks	Method
,	O
and	O
the	O
expectations	O
in	O
are	O
replaced	O
by	O
summations	O
over	O
the	O
corresponding	O
training	O
sets	O
.	O

However	O
,	O
this	O
baseline	O
solution	O
,	O
as	O
we	O
will	O
show	O
experimentally	O
,	O
does	O
not	O
produce	O
desirable	O
results	O
.	O

section	O
:	O
The	O
domain	Method
transfer	Method
network	O
We	O
suggest	O
to	O
employ	O
a	O
more	O
elaborate	O
architecture	O
that	O
contains	O
two	O
high	O
level	O
modifications	O
.	O

First	O
,	O
we	O
employ	O
as	O
the	O
baseline	Method
representation	Method
to	O
the	O
function	O
.	O

Second	O
,	O
we	O
consider	O
,	O
during	O
training	O
,	O
the	O
generated	O
samples	O
for	O
.	O

The	O
first	O
change	O
is	O
stated	O
as	O
,	O
for	O
some	O
learned	O
function	O
.	O

By	O
applying	O
this	O
,	O
we	O
focus	O
the	O
learning	O
effort	O
of	O
on	O
the	O
aspects	O
that	O
are	O
most	O
relevant	O
to	O
.	O

In	O
addition	O
,	O
in	O
most	O
applications	O
,	O
is	O
not	O
as	O
accurate	O
on	O
as	O
it	O
on	O
.	O

The	O
composed	Method
function	Method
,	O
which	O
is	O
trained	O
on	O
samples	O
from	O
both	O
and	O
,	O
adds	O
layers	O
on	O
top	O
of	O
,	O
which	O
adapt	O
it	O
.	O

The	O
second	O
change	O
alters	O
the	O
form	O
of	O
,	O
making	O
it	O
multiclass	O
instead	O
of	O
binary	O
.	O

It	O
also	O
introduces	O
a	O
new	O
term	O
that	O
requires	O
to	O
be	O
the	O
identity	O
matrix	O
on	O
samples	O
from	O
.	O

Taken	O
together	O
and	O
written	O
in	O
terms	O
of	O
training	Metric
loss	Metric
,	O
we	O
now	O
have	O
two	O
losses	O
and	O
,	O
for	O
some	O
weights	O
,	O
where	O
and	O
where	O
is	O
a	O
ternary	O
classification	O
function	O
from	O
the	O
domain	O
to	O
,	O
and	O
is	O
the	O
probability	O
it	O
assigns	O
to	O
class	O
for	O
an	O
input	O
sample	O
,	O
and	O
is	O
a	O
distance	O
function	O
in	O
.	O

During	O
optimization	Task
,	O
is	O
minimized	O
over	O
and	O
is	O
minimized	O
over	O
.	O

See	O
Fig	O
.	O

[	O
reference	O
]	O
for	O
an	O
illustration	O
of	O
our	O
method	O
.	O

The	O
last	O
loss	O
,	O
is	O
an	O
anisotropic	Method
total	Method
variation	Method
loss	Method
TV	Method
,	O
Mahendran15	Method
,	O
which	O
is	O
added	O
in	O
order	O
to	O
slightly	O
smooth	O
the	O
resulting	O
image	O
.	O

The	O
loss	O
is	O
defined	O
on	O
the	O
generated	O
image	O
as	O
where	O
we	O
employ	O
.	O

In	O
our	O
work	O
,	O
MSE	Metric
is	O
used	O
for	O
both	O
and	O
.	O

We	O
also	O
experimented	O
with	O
replacing	Method
,	O
which	O
,	O
in	O
visual	Task
domains	Task
,	O
compares	O
images	O
,	O
with	O
a	O
second	O
GAN	Method
.	O

No	O
noticeable	O
improvement	O
was	O
observed	O
.	O

Throughout	O
the	O
experiments	O
,	O
the	O
adaptive	Method
learning	Method
rate	Method
method	Method
Adam	Method
by	O
adam	Method
is	O
used	O
as	O
the	O
optimization	Method
algorithm	Method
.	O

[	O
]	O
[	O
]	O
section	O
:	O
Experiments	O
The	O
Domain	Method
Transfer	Method
Network	Method
(	O
DTN	Method
)	Method
is	O
evaluated	O
in	O
two	O
application	O
domains	O
:	O
digits	O
and	O
face	O
images	O
.	O

In	O
the	O
first	O
domain	O
,	O
we	O
transfer	O
images	O
from	O
the	O
Street	Material
View	Material
House	Material
Number	Material
(	O
SVHN	Material
)	O
dataset	O
of	O
to	O
the	O
domain	O
of	O
the	O
MNIST	Material
dataset	Material
by	O
.	O

In	O
the	O
face	Task
domain	Task
,	O
we	O
transfer	O
a	O
set	O
of	O
random	O
and	O
unlabeled	O
face	O
images	O
to	O
a	O
space	O
of	O
emoji	O
images	O
.	O

In	O
both	O
cases	O
,	O
the	O
source	O
and	O
target	O
domains	O
differ	O
considerably	O
.	O

subsection	O
:	O
Digits	O
:	O
from	O
SVHN	Material
to	Material
MNIST	Material
For	O
working	O
with	O
digits	O
,	O
we	O
employ	O
the	O
extra	O
training	O
split	O
of	O
SVHN	Material
,	O
which	O
contains	O
531	O
,	O
131	O
images	O
for	O
two	O
purposes	O
:	O
learning	O
the	O
function	O
and	O
as	O
an	O
unsupervised	O
training	O
set	O
s	O
for	O
the	O
domain	Method
transfer	Method
method	Method
.	O

The	O
evaluation	O
is	O
done	O
on	O
the	O
test	O
split	O
of	O
SVHN	Material
,	O
comprised	O
of	O
26	O
,	O
032	O
images	O
.	O

The	O
architecture	O
of	O
consists	O
of	O
four	O
convolutional	Method
layers	Method
with	O
filters	Method
respectively	O
,	O
each	O
followed	O
by	O
max	Method
pooling	Method
and	O
ReLU	Method
non	Method
-	Method
linearity	Method
.	O

The	O
error	O
on	O
the	O
test	O
split	O
is	O
4.95	O
%	O
.	O

Even	O
tough	O
this	O
accuracy	Metric
is	O
far	O
from	O
the	O
best	O
reported	O
results	O
,	O
it	O
seems	O
to	O
be	O
sufficient	O
for	O
the	O
purpose	O
of	O
domain	Method
transfer	Method
.	O

Within	O
the	O
DTN	Method
,	O
maps	O
a	O
RGB	Material
image	Material
to	O
the	O
activations	O
of	O
the	O
last	O
convolutional	Method
layer	Method
of	O
size	O
(	O
post	O
a	O
max	Method
pooling	Method
and	O
before	O
the	O
ReLU	Method
)	O
.	O

In	O
order	O
to	O
apply	O
on	O
MNIST	Material
images	Material
,	O
we	O
replicate	O
the	O
grayscale	O
image	O
three	O
times	O
.	O

The	O
set	O
t	O
contains	O
the	O
test	O
set	O
of	O
the	O
MNIST	Material
dataset	Material
.	O

For	O
supporting	O
quantitative	O
evaluation	O
,	O
we	O
have	O
trained	O
a	O
classifier	Method
on	O
the	O
train	O
set	O
of	O
the	O
MNIST	Material
dataset	Material
,	O
consisting	O
of	O
the	O
same	O
architecture	O
as	O
.	O

The	O
accuracy	Metric
of	O
this	O
classifier	O
on	O
the	O
test	O
set	O
approaches	O
perfect	O
performance	O
at	O
99.4	O
%	O
accuracy	Metric
,	O
and	O
is	O
,	O
therefore	O
,	O
trustworthy	O
as	O
an	O
evaluation	Metric
metric	Metric
.	O

In	O
comparison	O
,	O
the	O
network	O
,	O
achieves	O
76.08	O
%	O
accuracy	Metric
on	O
t	O
.	O

Network	Method
,	O
inspired	O
by	O
,	O
maps	O
SVHN	Method
-	Method
trained	Method
’s	Method
128D	Method
representations	Method
to	O
grayscale	O
images	O
.	O

employs	O
four	O
blocks	O
of	O
deconvolution	Method
,	O
batch	Method
-	Method
normalization	Method
,	O
and	O
ReLU	Method
,	O
with	O
a	O
hyperbolic	Method
tangent	Method
terminal	Method
.	O

The	O
architecture	O
of	O
consists	O
of	O
four	O
batch	Method
-	Method
normalized	Method
convolutional	Method
layers	Method
and	O
employs	O
ReLU	Method
.	O

In	O
the	O
digit	O
experiments	O
,	O
the	O
results	O
were	O
obtained	O
with	O
the	O
tradeoff	Method
hyperparamemters	Method
.	O

We	O
did	O
not	O
observe	O
a	O
need	O
to	O
add	O
a	O
smoothness	O
term	O
and	O
the	O
weight	O
of	O
was	O
set	O
to	O
.	O

Despite	O
not	O
being	O
very	O
accurate	O
on	O
both	O
domains	O
(	O
and	O
also	O
considerably	O
worse	O
than	O
the	O
SVHN	Material
state	O
of	O
the	O
art	O
)	O
,	O
we	O
were	O
able	O
to	O
achieve	O
visually	O
appealing	O
domain	Method
transfer	Method
,	O
as	O
shown	O
in	O
Fig	O
.	O

[	O
reference	O
]	O
(	O
a	O
)	O
.	O

In	O
order	O
to	O
evaluate	O
the	O
contribution	O
of	O
each	O
of	O
the	O
method	O
’s	Method
components	Method
,	O
we	O
have	O
employed	O
the	O
MNIST	Method
network	Method
on	O
the	O
set	O
of	O
samples	O
,	O
using	O
the	O
true	O
SVHN	Material
labels	O
of	O
the	O
test	O
set	O
.	O

We	O
first	O
compare	O
to	O
the	O
baseline	O
method	O
of	O
Sec	O
.	O

[	O
reference	O
]	O
,	O
where	O
the	O
generative	Method
function	Method
,	O
which	O
works	O
directly	O
with	O
samples	O
in	O
,	O
is	O
composed	O
out	O
of	O
a	O
few	O
additional	O
layers	O
at	O
the	O
bottom	O
of	O
.	O

The	O
results	O
,	O
shown	O
in	O
Tab	O
.	O

[	O
reference	O
]	O
,	O
demonstrate	O
that	O
DTN	Method
has	O
a	O
clear	O
advantage	O
over	O
the	O
baseline	O
method	O
.	O

In	O
addition	O
,	O
the	O
contribution	O
of	O
each	O
one	O
of	O
the	O
terms	O
in	O
the	O
loss	O
function	O
is	O
shown	O
in	O
the	O
table	O
.	O

The	O
regularization	Method
term	Method
seems	O
less	O
crucial	O
than	O
the	O
constancy	O
term	O
.	O

However	O
,	O
at	O
least	O
one	O
of	O
them	O
is	O
required	O
in	O
order	O
to	O
obtain	O
good	O
performance	O
.	O

The	O
GAN	Method
constraints	O
are	O
also	O
important	O
.	O

Finally	O
,	O
the	O
inclusion	O
of	O
within	O
the	O
generator	Method
function	Method
has	O
a	O
dramatic	O
influence	O
on	O
the	O
results	O
.	O

As	O
explained	O
in	O
Sec	O
.	O

[	O
reference	O
]	O
,	O
domain	Method
transfer	Method
can	O
be	O
used	O
in	O
order	O
to	O
perform	O
unsupervised	Task
domain	Task
adaptation	Task
.	O

For	O
this	O
purposes	O
,	O
we	O
transformed	O
the	O
set	O
to	O
the	O
MNIST	Material
domain	Material
(	O
as	O
above	O
)	O
,	O
and	O
using	O
the	O
true	O
labels	O
of	O
employed	O
a	O
simple	O
nearest	Method
neighbor	Method
classifier	Method
there	O
.	O

The	O
choice	O
of	O
classifier	Method
was	O
to	O
emphasize	O
the	O
simplicity	O
of	O
the	O
approach	O
;	O
However	O
,	O
the	O
constraints	O
of	O
the	O
unsupervised	Task
domain	Task
transfer	Task
problem	O
would	O
be	O
respected	O
for	O
any	O
classifier	Method
trained	O
on	O
.	O

The	O
results	O
of	O
this	O
experiment	O
are	O
reported	O
in	O
Tab	O
.	O

[	O
reference	O
]	O
,	O
which	O
shows	O
a	O
clear	O
advantage	O
over	O
the	O
state	O
of	O
the	O
art	O
method	O
of	O
.	O

This	O
is	O
true	O
both	O
when	O
transferring	O
the	O
samples	O
of	O
the	O
set	O
and	O
when	O
transferring	O
the	O
test	O
set	O
of	O
SVHN	Material
,	O
which	O
is	O
much	O
smaller	O
and	O
was	O
not	O
seen	O
during	O
the	O
training	O
of	O
the	O
DTN	Method
.	O

subsubsection	O
:	O
Unseen	O
digits	O
Another	O
set	O
of	O
experiments	O
was	O
performed	O
in	O
order	O
to	O
study	O
the	O
ability	O
of	O
the	O
domain	Method
transfer	Method
network	O
to	O
overcome	O
the	O
omission	O
of	O
a	O
class	O
of	O
samples	O
.	O

This	O
type	O
of	O
ablation	Task
can	O
occur	O
in	O
the	O
source	O
or	O
the	O
target	O
domain	O
,	O
or	O
during	O
the	O
training	O
of	O
and	O
can	O
help	O
us	O
understand	O
the	O
importance	O
of	O
each	O
of	O
these	O
inputs	O
.	O

The	O
results	O
are	O
shown	O
visually	O
in	O
Fig	O
.	O

[	O
reference	O
]	O
,	O
and	O
qualitatively	O
in	O
Tab	O
.	O

[	O
reference	O
]	O
,	O
based	O
on	O
the	O
accuracy	Metric
of	O
the	O
MNIST	Method
classifier	Method
only	O
on	O
the	O
transferred	O
samples	O
from	O
the	O
test	O
set	O
of	O
SVHN	Material
that	O
belong	O
to	O
class	O
‘	O
3	O
’	O
.	O

It	O
is	O
evident	O
that	O
not	O
including	O
the	O
class	O
in	O
the	O
source	O
domain	O
is	O
much	O
less	O
detrimental	O
than	O
eliminating	O
it	O
from	O
the	O
target	O
domain	O
.	O

This	O
is	O
the	O
desirable	O
behavior	O
:	O
never	O
seeing	O
any	O
‘	O
3’	O
-	O
like	O
shapes	O
in	O
,	O
the	O
generator	O
should	O
not	O
generate	O
such	O
samples	O
.	O

Results	O
are	O
better	O
when	O
not	O
observing	O
‘	O
3	O
’	O
in	O
both	O
than	O
when	O
not	O
seeing	O
it	O
only	O
in	O
since	O
in	O
the	O
latter	O
case	O
,	O
learns	O
to	O
map	O
source	O
samples	O
of	O
‘	O
3	O
’	O
to	O
target	O
images	O
of	O
other	O
classes	O
.	O

subsection	O
:	O
Faces	O
:	O
from	O
Photos	O
to	O
Emoji	O
For	O
face	O
images	O
,	O
we	O
use	O
a	O
set	O
of	O
one	O
million	O
random	O
images	O
without	O
identity	O
information	O
.	O

The	O
set	O
consists	O
of	O
assorted	O
facial	O
avatars	O
(	O
emoji	O
)	O
created	O
by	O
an	O
online	O
service	O
(	O
)	O
.	O

The	O
emoji	O
images	O
were	O
processed	O
by	O
a	O
fully	O
automatic	Method
process	Method
that	O
localizes	O
,	O
based	O
on	O
as	O
set	O
of	O
heuristics	O
,	O
the	O
center	O
of	O
the	O
irides	O
and	O
the	O
tip	O
of	O
the	O
nose	O
.	O

Based	O
on	O
these	O
coordinates	O
,	O
the	O
emoji	O
were	O
centered	O
and	O
scaled	O
into	O
RGB	Material
images	Material
.	O

As	O
the	O
function	O
,	O
we	O
employ	O
the	O
representation	Method
layer	Method
of	Method
the	Method
DeepFace	Method
network	Method
.	O

This	O
representation	O
is	O
256	O
-	O
dimensional	O
and	O
was	O
trained	O
on	O
a	O
labeled	O
set	O
of	O
four	O
million	O
images	O
that	O
does	O
not	O
intersect	O
the	O
set	O
.	O

Network	Method
D	O
takes	O
RGB	Material
images	Material
(	O
either	O
natural	O
or	O
scaled	O
-	O
up	O
emoji	O
)	O
and	O
consists	O
of	O
6	O
blocks	O
,	O
each	O
containing	O
a	O
convolution	Method
with	O
stride	O
2	O
,	O
batch	Method
normalization	Method
,	O
and	O
a	O
leaky	Method
ReLU	Method
with	O
a	O
parameter	O
of	O
0.2	O
.	O

Network	Method
maps	Method
’s	O
256D	Method
representations	Method
to	O
RGB	Material
images	Material
through	O
a	O
network	O
with	O
5	O
blocks	O
,	O
each	O
consisting	O
of	O
an	O
upscaling	Method
convolution	Method
,	O
batch	Method
-	Method
normalization	Method
and	O
ReLU	Method
.	O

Adding	O
convolution	Method
to	O
each	O
block	O
resulted	O
in	O
lower	O
training	Metric
errors	Metric
,	O
and	O
made	O
9	O
-	O
layers	O
deep	O
.	O

We	O
set	O
,	O
,	O
as	O
the	O
tradeoff	O
hyperparameters	O
within	O
via	O
validation	Metric
.	O

As	O
expected	O
,	O
higher	O
values	O
of	O
resulted	O
in	O
better	O
-	O
constancy	O
,	O
however	O
introduced	O
artifacts	O
such	O
as	O
general	O
noise	O
or	O
distortions	O
.	O

In	O
order	O
to	O
upscale	O
the	O
output	O
to	O
print	Metric
quality	Metric
,	O
we	O
used	O
the	O
method	O
of	O
,	O
which	O
was	O
shown	O
to	O
work	O
well	O
on	O
art	O
.	O

We	O
did	O
not	O
retrain	O
this	O
network	O
for	O
our	O
application	O
,	O
and	O
used	O
the	O
published	O
one	O
.	O

Results	O
without	O
this	O
upscale	O
are	O
shown	O
,	O
for	O
comparison	O
,	O
in	O
Appendix	O
[	O
reference	O
]	O
.	O

paragraph	O
:	O
Comparison	O
With	O
Human	O
Annotators	O
For	O
evaluation	O
purposes	O
only	O
,	O
a	O
team	O
of	O
professional	O
annotators	O
manually	O
created	O
an	O
emoji	Method
,	O
using	O
the	O
web	Method
service	Method
of	O
,	O
for	O
random	O
images	O
from	O
the	O
CelebA	Material
dataset	Material
celeba	Material
.	O

Fig	O
.	O

[	O
reference	O
]	O
shows	O
side	O
by	O
side	O
samples	O
of	O
the	O
original	O
image	O
,	O
the	O
human	O
generated	O
emoji	O
and	O
the	O
emoji	O
generated	O
by	O
the	O
learned	O
generator	Method
function	Method
.	O

As	O
can	O
be	O
seen	O
,	O
the	O
automatically	O
generated	O
emoji	O
tend	O
to	O
be	O
more	O
informative	O
,	O
albeit	O
less	O
restrictive	O
than	O
the	O
ones	O
created	O
manually	O
.	O

In	O
order	O
to	O
evaluate	O
the	O
identifiability	O
of	O
the	O
resulting	O
emoji	Method
,	O
we	O
have	O
collected	O
a	O
second	O
example	O
for	O
each	O
identity	O
in	O
the	O
set	O
of	O
CelebA	Material
images	Material
and	O
a	O
set	O
of	O
100	O
,	O
000	O
random	O
face	O
images	O
,	O
which	O
were	O
not	O
included	O
in	O
.	O

We	O
then	O
employed	O
the	O
VGG	Method
face	Method
CNN	Method
descriptor	Method
of	Method
in	O
order	O
to	O
perform	O
retrieval	Task
as	O
follows	O
.	O

For	O
each	O
image	O
in	O
our	O
manually	O
annotated	O
set	O
,	O
we	O
create	O
a	O
gallery	O
,	O
where	O
is	O
the	O
other	O
image	O
of	O
the	O
person	O
in	O
.	O

We	O
then	O
perform	O
retrieval	Task
using	O
the	O
VGG	Method
face	Method
descriptor	Method
using	O
either	O
the	O
manually	O
created	O
emoji	O
or	O
as	O
probe	O
.	O

The	O
VGG	Method
network	Method
is	O
used	O
in	O
order	O
to	O
avoid	O
a	O
bias	O
that	O
might	O
be	O
caused	O
by	O
using	O
both	O
for	O
training	O
the	O
DTN	Method
and	O
for	O
evaluation	Task
.	O

The	O
results	O
are	O
reported	O
in	O
Tab	O
.	O

[	O
reference	O
]	O
.	O

As	O
can	O
be	O
seen	O
,	O
the	O
emoji	O
generated	O
by	O
are	O
much	O
more	O
discriminative	O
than	O
the	O
emoji	O
created	O
manually	O
and	O
obtain	O
a	O
median	Metric
rank	Metric
of	O
16	O
in	O
cross	Task
-	Task
domain	Task
identification	Task
out	O
of	O
distractors	O
.	O

paragraph	O
:	O
Multiple	O
Images	O
Per	O
Person	O
We	O
evaluate	O
the	O
visual	Metric
quality	Metric
that	O
is	O
obtained	O
per	O
person	O
and	O
not	O
just	O
per	O
image	O
,	O
by	O
testing	O
DTN	Method
on	O
the	O
Facescrub	Material
dataset	O
facescrub	O
.	O

For	O
each	O
person	O
,	O
we	O
considered	O
the	O
set	O
of	O
their	O
images	O
,	O
and	O
selected	O
the	O
emoji	O
that	O
was	O
most	O
similar	O
to	O
their	O
source	O
image	O
:	O
This	O
simple	O
heuristic	O
seems	O
to	O
work	O
well	O
in	O
practice	O
;	O
The	O
general	O
problem	O
of	O
mapping	O
a	O
set	O
to	O
a	O
single	O
output	O
in	O
is	O
left	O
for	O
future	O
work	O
.	O

Fig	O
.	O

[	O
reference	O
]	O
(	O
b	O
)	O
contains	O
several	O
examples	O
from	O
the	O
Facescrub	Material
dataset	O
.	O

For	O
the	O
complete	O
set	O
of	O
identities	O
,	O
see	O
Appendix	O
[	O
reference	O
]	O
.	O

paragraph	O
:	O
Network	Task
Visualization	Task
The	O
obtained	O
mapping	O
can	O
serve	O
as	O
a	O
visualization	Method
tool	Method
for	O
studying	O
the	O
properties	O
of	O
the	O
face	Method
representation	Method
.	O

This	O
is	O
studied	O
in	O
Appendix	O
[	O
reference	O
]	O
by	O
computing	O
the	O
emoji	Method
generated	O
for	O
the	O
standard	O
basis	O
of	O
.	O

The	O
resulting	O
images	O
present	O
a	O
large	O
amount	O
of	O
variability	O
,	O
indicating	O
that	O
does	O
not	O
present	O
a	O
significant	O
mode	O
effect	O
.	O

[	O
]	O
[	O
]	O
[	O
]	O
[	O
]	O
[	O
]	O
[	O
]	O
subsection	O
:	O
Style	Task
Transfer	Task
as	O
a	O
specific	O
Domain	Task
Transfer	Task
task	Task
Fig	O
.	O

[	O
reference	O
]	O
(	O
a	O
-	O
c	O
)	O
demonstrates	O
that	O
neural	Method
style	Method
transfer	Method
can	O
not	O
solve	O
the	O
photo	Task
to	Task
emoji	Task
transfer	Task
task	Task
in	O
a	O
convincing	O
way	O
.	O

The	O
output	O
image	O
is	O
perhaps	O
visually	O
appealing	O
;	O
However	O
,	O
it	O
does	O
not	O
belong	O
to	O
the	O
space	O
of	O
emoji	O
.	O

Our	O
result	O
are	O
given	O
in	O
Fig	O
.	O

[	O
reference	O
]	O
(	O
d	O
)	O
for	O
comparison	O
.	O

Note	O
that	O
DTN	Method
is	O
able	O
to	O
fix	O
the	O
missing	O
hair	O
in	O
the	O
image	O
.	O

Domain	Method
transfer	Method
is	O
more	O
general	O
than	O
style	Task
transfer	Task
in	O
the	O
sense	O
that	O
we	O
can	O
perform	O
style	Method
transfer	Method
using	O
a	O
DTN	Method
.	O

In	O
order	O
to	O
show	O
this	O
,	O
we	O
have	O
transformed	O
,	O
using	O
the	O
method	O
of	O
,	O
the	O
training	O
images	O
of	O
CelebA	Material
based	O
on	O
the	O
style	O
of	O
a	O
single	O
image	O
(	O
shown	O
in	O
Fig	O
.	O

[	O
reference	O
]	O
(	O
e	O
)	O
)	O
.	O

The	O
original	O
photos	O
were	O
used	O
as	O
the	O
set	O
,	O
and	O
the	O
transformed	O
images	O
were	O
used	O
as	O
.	O

Applying	O
DTN	Method
,	O
using	O
face	Method
representation	Method
,	O
we	O
obtained	O
styled	O
face	O
images	O
such	O
as	O
the	O
one	O
shown	O
in	O
the	O
figure	O
[	O
reference	O
]	O
(	O
f	O
)	O
.	O

section	O
:	O
Discussion	O
and	O
Limitations	O
Asymmetry	O
is	O
central	O
to	O
our	O
work	O
.	O

Not	O
only	O
does	O
our	O
solution	O
handle	O
the	O
two	O
domains	O
and	O
differently	O
,	O
the	O
function	O
is	O
unlikely	O
to	O
be	O
equally	O
effective	O
in	O
both	O
domains	O
since	O
in	O
most	O
practical	O
cases	O
,	O
would	O
be	O
trained	O
on	O
samples	O
from	O
one	O
domain	O
.	O

While	O
an	O
explicit	O
domain	Method
adaptation	Method
step	O
can	O
be	O
added	O
in	O
order	O
to	O
make	O
more	O
effective	O
on	O
the	O
second	O
domain	O
,	O
we	O
found	O
it	O
to	O
be	O
unnecessary	O
.	O

Adaptation	Task
of	O
occurs	O
implicitly	O
due	O
to	O
the	O
application	O
of	O
downstream	O
.	O

Using	O
the	O
same	O
function	O
,	O
we	O
can	O
replace	O
the	O
roles	O
of	O
the	O
two	O
domains	O
,	O
and	O
.	O

For	O
example	O
,	O
we	O
can	O
synthesize	O
an	O
SVHN	Material
image	O
that	O
resembles	O
a	O
given	O
MNIST	Material
image	Material
,	O
or	O
synthesize	O
a	O
face	O
that	O
matches	O
an	O
emoji	O
.	O

As	O
expected	O
,	O
this	O
yields	O
less	O
appealing	O
results	O
due	O
to	O
the	O
asymmetric	O
nature	O
of	O
and	O
the	O
lower	O
information	O
content	O
in	O
these	O
new	O
source	O
domains	O
,	O
see	O
Appendix	O
[	O
reference	O
]	O
.	O

Domain	Method
transfer	Method
,	O
as	O
an	O
unsupervised	Method
method	Method
,	O
could	O
prove	O
useful	O
across	O
a	O
wide	O
variety	O
of	O
computational	Task
tasks	Task
.	O

Here	O
,	O
we	O
demonstrate	O
the	O
ability	O
to	O
use	O
domain	Method
transfer	Method
in	O
order	O
to	O
perform	O
unsupervised	Task
domain	Task
adaptation	Task
.	O

While	O
this	O
is	O
currently	O
only	O
shown	O
in	O
a	O
single	O
experiment	O
,	O
the	O
simplicity	O
of	O
performing	O
domain	Method
adaptation	Method
and	O
the	O
fact	O
that	O
state	O
of	O
the	O
art	O
results	O
were	O
obtained	O
effortlessly	O
with	O
a	O
simple	O
nearest	Method
neighbor	Method
classifier	Method
suggest	O
it	O
to	O
be	O
a	O
promising	O
direction	O
for	O
future	O
research	O
.	O

bibliography	O
:	O
References	O
appendix	O
:	O
Facescrub	Material
dataset	O
generations	O
In	O
Fig	O
.	O

[	O
reference	O
]	O
we	O
show	O
the	O
full	O
set	O
of	O
identities	O
of	O
the	O
Facescrub	Material
dataset	O
,	O
and	O
their	O
corresponding	O
generated	O
emoji	O
.	O

appendix	O
:	O
The	O
effect	O
of	O
super	Task
-	Task
resolution	Task
As	O
mentioned	O
in	O
Sec	O
.	O

[	O
reference	O
]	O
,	O
in	O
order	O
to	O
upscale	O
the	O
output	O
to	O
print	O
quality	O
,	O
the	O
method	O
of	O
is	O
used	O
.	O

Fig	O
.	O

[	O
reference	O
]	O
shows	O
the	O
effect	O
of	O
applying	O
this	O
postprocessing	Method
step	Method
.	O

appendix	O
:	O
The	O
basis	O
elements	O
of	O
the	O
face	Method
representation	Method
Fig	O
.	O

[	O
reference	O
]	O
depicts	O
the	O
face	O
emoji	O
generated	O
by	O
for	O
the	O
standard	O
basis	O
of	O
the	O
face	Method
representation	Method
deepface	Method
,	O
viewed	O
as	O
the	O
vector	O
space	O
.	O

appendix	O
:	O
Domain	Method
transfer	Method
in	O
the	O
reverse	O
direction	O
For	O
completion	O
,	O
we	O
present	O
,	O
in	O
Fig	O
.	O

[	O
reference	O
]	O
results	O
obtained	O
by	O
performing	O
domain	Method
transfer	Method
using	O
DTNs	Method
in	O
the	O
reverse	O
direction	O
of	O
the	O
one	O
reported	O
in	O
Sec	O
.	O

[	O
reference	O
]	O
.	O

[	O
]	O
[	O
]	O
