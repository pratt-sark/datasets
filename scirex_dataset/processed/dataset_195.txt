document	O
:	O
Revisiting	O
Unreasonable	O
Effectiveness	O
of	O
Data	O
in	O
Deep	Task
Learning	Task
Era	Task
The	O
success	O
of	O
deep	Task
learning	Task
in	O
vision	Task
can	O
be	O
attributed	O
to	O
:	O
(	O
a	O
)	O
models	O
with	O
high	O
capacity	O
;	O
(	O
b	O
)	O
increased	O
computational	Metric
power	Metric
;	O
and	O
(	O
c	O
)	O
availability	O
of	O
large	O
-	O
scale	O
labeled	O
data	O
.	O

Since	O
2012	O
,	O
there	O
have	O
been	O
significant	O
advances	O
in	O
representation	O
capabilities	O
of	O
the	O
models	O
and	O
computational	Method
capabilities	Method
of	O
GPUs	Method
.	O

But	O
the	O
size	O
of	O
the	O
biggest	O
dataset	O
has	O
surprisingly	O
remained	O
constant	O
.	O

What	O
will	O
happen	O
if	O
we	O
increase	O
the	O
dataset	O
size	O
by	O
or	O
?	O
This	O
paper	O
takes	O
a	O
step	O
towards	O
clearing	O
the	O
clouds	O
of	O
mystery	O
surrounding	O
the	O
relationship	O
between	O
‘	O
enormous	O
data	O
’	O
and	O
visual	Method
deep	Method
learning	Method
.	O

By	O
exploiting	O
the	O
JFT	Method
-	O
300	O
M	Method
dataset	O
which	O
has	O
more	O
than	O
375	O
M	Method
noisy	O
labels	O
for	O
300	O
M	Method
images	O
,	O
we	O
investigate	O
how	O
the	O
performance	O
of	O
current	O
vision	Task
tasks	Task
would	O
change	O
if	O
this	O
data	O
was	O
used	O
for	O
representation	Method
learning	Method
.	O

Our	O
paper	O
delivers	O
some	O
surprising	O
(	O
and	O
some	O
expected	O
)	O
findings	O
.	O

First	O
,	O
we	O
find	O
that	O
the	O
performance	O
on	O
vision	Task
tasks	Task
increases	O
logarithmically	O
based	O
on	O
volume	O
of	O
training	O
data	O
size	O
.	O

Second	O
,	O
we	O
show	O
that	O
representation	Method
learning	Method
(	O
or	O
pre	Task
-	Task
training	Task
)	O
still	O
holds	O
a	O
lot	O
of	O
promise	O
.	O

One	O
can	O
improve	O
performance	O
on	O
many	O
vision	Task
tasks	Task
by	O
just	O
training	O
a	O
better	O
base	O
model	O
.	O

Finally	O
,	O
as	O
expected	O
,	O
we	O
present	O
new	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
results	O
for	O
different	O
vision	Task
tasks	Task
including	O
image	Task
classification	Task
,	O
object	O
detection	Task
,	O
semantic	Task
segmentation	Task
and	O
human	Task
pose	Task
estimation	Task
.	O

Our	O
sincere	O
hope	O
is	O
that	O
this	O
inspires	O
vision	Task
community	Task
to	O
not	O
undervalue	O
the	O
data	O
and	O
develop	O
collective	O
efforts	O
in	O
building	O
larger	O
datasets	O
.	O

1	O
]	O
Chen	O
Sun	O
1	O
,	O
2	O
]	O
Abhinav	O
Shrivastava	O
1	O
]	O
Saurabh	O
Singh	O
1	O
,	O
2	O
]	O
Abhinav	O
Gupta	O
[	O
1	O
]	O
Google	O
Research	O
[	O
2	O
]	O
Carnegie	O
Mellon	O
University	O
section	O
:	O
Introduction	O
There	O
is	O
unanimous	O
agreement	O
that	O
the	O
current	O
ConvNet	Method
revolution	Method
is	O
a	O
product	O
of	O
big	O
labeled	O
datasets	O
(	O
specifically	O
,	O
1	O
M	Method
labeled	O
images	O
from	O
ImageNet	Material
)	O
and	O
large	O
computational	O
power	O
(	O
thanks	O
to	O
GPUs	Method
)	O
.	O

Every	O
year	O
we	O
get	O
further	O
increase	O
in	O
computational	Metric
power	Metric
(	O
a	O
newer	O
and	O
faster	O
GPU	O
)	O
but	O
our	O
datasets	O
have	O
not	O
been	O
so	O
fortunate	O
.	O

ImageNet	Material
,	O
a	O
dataset	O
of	O
1	O
M	Method
labeled	O
images	O
based	O
on	O
1000	O
categories	O
,	O
was	O
used	O
to	O
train	O
AlexNet	Method
more	O
than	O
five	O
years	O
ago	O
.	O

Curiously	O
,	O
while	O
both	O
GPUs	Method
and	O
model	Method
capacity	Method
have	O
continued	O
to	O
grow	O
,	O
datasets	O
to	O
train	O
these	O
models	O
have	O
remained	O
stagnant	O
.	O

Even	O
a	O
101	Method
-	Method
layer	Method
ResNet	Method
with	O
significantly	O
more	O
capacity	O
and	O
depth	O
is	O
still	O
trained	O
with	O
1	O
M	Method
images	O
from	O
ImageNet	Material
circa	O
2011	O
.	O

Why	O
is	O
that	O
?	O
Have	O
we	O
once	O
again	O
belittled	O
the	O
importance	O
of	O
data	O
in	O
front	O
of	O
deeper	O
models	O
and	O
computational	Metric
power	Metric
?	O
What	O
will	O
happen	O
if	O
we	O
scale	O
up	O
the	O
amount	O
of	O
training	O
data	O
or	O
,	O
will	O
the	O
performance	O
double	O
?	O
This	O
paper	O
takes	O
the	O
first	O
steps	O
towards	O
clearing	O
the	O
clouds	O
of	O
mystery	O
surrounding	O
the	O
relationship	O
between	O
‘	O
enormous	O
data	O
’	O
and	O
deep	Method
learning	Method
.	O

We	O
exploit	O
the	O
already	O
existing	O
JFT	Material
-	Material
image	Material
dataset	Material
,	O
first	O
introduced	O
by	O
Hinton	O
and	O
expanded	O
by	O
.	O

The	O
JFT	Method
dataset	O
has	O
more	O
than	O
300	O
M	Method
images	O
that	O
are	O
labeled	O
with	O
18291	O
categories	O
.	O

The	O
annotations	O
have	O
been	O
automatically	O
obtained	O
and	O
,	O
therefore	O
,	O
are	O
noisy	O
and	O
not	O
exhaustive	O
.	O

These	O
annotations	O
have	O
been	O
cleaned	O
using	O
complex	O
algorithms	O
to	O
increase	O
the	O
precision	Metric
of	Metric
labels	Metric
;	O
however	O
there	O
is	O
still	O
approximately	O
20	O
%	O
error	O
in	O
precision	Metric
.	O

We	O
will	O
use	O
this	O
data	O
to	O
investigate	O
the	O
nature	O
of	O
relationship	O
between	O
amount	O
of	O
data	O
and	O
performance	O
on	O
vision	Task
tasks	Task
.	O

Specifically	O
,	O
we	O
will	O
look	O
into	O
the	O
power	O
of	O
data	O
for	O
visual	Task
representation	Task
learning	Task
(	O
pre	Task
-	Task
training	Task
)	O
.	O

We	O
evaluate	O
our	O
learned	O
representation	O
on	O
a	O
variety	O
of	O
vision	Task
tasks	Task
:	O
image	Task
classification	Task
,	O
object	O
detection	Task
,	O
semantic	Task
segmentation	Task
and	O
human	Task
pose	Task
estimation	Task
.	O

Our	O
experiments	O
yield	O
some	O
surprising	O
(	O
and	O
some	O
expected	O
)	O
findings	O
:	O
Better	O
Representation	Method
Learning	Method
Helps	O
!	O

Our	O
first	O
observation	O
is	O
that	O
large	O
-	O
scale	O
data	O
helps	O
in	O
representation	Task
learning	Task
as	O
evidenced	O
by	O
improvement	O
in	O
performance	O
on	O
each	O
and	O
every	O
vision	Task
task	Task
we	O
study	O
.	O

This	O
suggests	O
that	O
collection	O
of	O
a	O
larger	O
-	O
scale	O
dataset	O
to	O
study	O
visual	Task
pretraining	Task
may	O
greatly	O
benefit	O
the	O
field	O
.	O

Our	O
findings	O
also	O
suggest	O
a	O
bright	O
future	O
for	O
unsupervised	Method
or	Method
self	Method
-	Method
supervised	Method
representation	Method
learning	Method
approaches	Method
.	O

It	O
seems	O
the	O
scale	O
of	O
data	O
can	O
overpower	O
noise	O
in	O
the	O
label	O
space	O
.	O

Performance	O
increases	O
logarithmically	O
based	O
on	O
volume	O
of	O
training	O
data	O
.	O

We	O
find	O
there	O
is	O
a	O
logarithmic	O
relationship	O
between	O
performance	O
on	O
vision	Task
tasks	Task
and	O
the	O
amount	O
of	O
training	O
data	O
used	O
for	O
representation	Method
learning	Method
.	O

Note	O
that	O
previous	O
papers	O
on	O
large	Task
-	Task
scale	Task
learning	Task
have	O
shown	O
diminishing	O
returns	O
even	O
on	O
log	O
-	O
scale	O
.	O

Capacity	O
is	O
Crucial	O
:	O
We	O
also	O
observe	O
that	O
to	O
fully	O
exploit	O
300	O
M	Method
images	O
,	O
one	O
needs	O
higher	O
capacity	Method
models	Method
.	O

For	O
example	O
,	O
in	O
case	O
of	O
ResNet	Method
-	Method
50	Method
the	O
gain	O
on	O
COCO	Material
object	O
detection	Task
is	O
much	O
smaller	O
(	O
1.87	O
%	O
)	O
compared	O
to	O
(	O
3	O
%	O
)	O
when	O
using	O
ResNet	Method
-	Method
152	Method
.	O

Training	O
with	O
Long	O
-	O
tail	O
:	O
Our	O
data	O
has	O
quite	O
a	O
long	O
tail	O
and	O
yet	O
the	O
representation	Method
learning	Method
seems	O
to	O
work	O
.	O

This	O
long	O
-	O
tail	O
does	O
not	O
seem	O
to	O
adversely	O
affect	O
the	O
stochastic	Task
training	Task
of	Task
ConvNets	Task
(	O
training	O
still	O
converges	O
)	O
.	O

New	O
state	O
of	O
the	O
art	O
results	O
:	O
Finally	O
,	O
our	O
paper	O
presents	O
new	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
results	O
on	O
several	O
benchmarks	O
using	O
the	O
models	O
learned	O
from	O
JFT	Method
-	O
300M.	O
For	O
example	O
,	O
a	O
single	O
model	O
(	O
without	O
any	O
bells	O
and	O
whistles	O
)	O
can	O
now	O
achieve	O
37.4	O
AP	Metric
as	O
compared	O
to	O
34.3	O
AP	Metric
on	O
the	O
COCO	Material
detection	Task
benchmark	O
.	O

section	O
:	O
Related	O
Work	O
Ever	O
since	O
the	O
seminal	O
work	O
by	O
Krizhevsky	O
showcased	O
the	O
power	O
of	O
Convolutional	Method
Neural	Method
Networks	Method
(	O
ConvNets	Method
)	O
on	O
large	Task
-	Task
scale	Task
image	Task
recognition	Task
task	Task
,	O
a	O
lot	O
of	O
work	O
has	O
been	O
done	O
to	O
make	O
them	O
more	O
accurate	O
.	O

A	O
common	O
approach	O
is	O
to	O
increase	O
the	O
complexity	Metric
of	O
these	O
networks	O
by	O
increasing	O
the	O
width	O
or	O
depth	O
of	O
these	O
networks	O
.	O

For	O
example	O
,	O
Simonyan	O
and	O
Zisserman	O
proposed	O
the	O
VGG	Method
-	Method
19	Method
model	Method
which	O
uses	O
smaller	O
convolutional	Method
filters	Method
and	O
has	O
depth	O
of	O
19	O
layers	O
.	O

Since	O
then	O
the	O
representational	O
power	O
and	O
depth	O
of	O
these	O
models	O
have	O
continued	O
to	O
grow	O
every	O
year	O
.	O

GoogleNet	Method
was	O
a	O
22	Method
-	Method
layer	Method
network	Method
.	O

In	O
this	O
paper	O
,	O
we	O
perform	O
all	O
our	O
experiments	O
with	O
the	O
ResNet	Method
models	Method
proposed	O
by	O
He	O
.	O

The	O
core	O
idea	O
is	O
to	O
add	O
residual	O
connections	O
between	O
layers	O
which	O
helps	O
in	O
optimization	Task
of	Task
very	Task
-	Task
deep	Task
models	Task
.	O

This	O
results	O
in	O
new	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
performances	O
on	O
a	O
number	O
of	O
recognition	Task
tasks	Task
.	O

Convolutional	Method
neural	Method
networks	Method
learn	O
a	O
hierarchy	Method
of	Method
visual	Method
representations	Method
.	O

These	O
visual	Method
representations	Method
have	O
been	O
shown	O
to	O
be	O
effective	O
on	O
a	O
wide	O
range	O
of	O
computer	Task
vision	Task
tasks	Task
.	O

Learning	O
these	O
visual	Method
representations	Method
require	O
large	O
-	O
scale	O
training	O
data	O
.	O

However	O
,	O
the	O
biggest	O
detection	Task
and	O
segmentation	Task
datasets	O
are	O
still	O
on	O
the	O
order	O
of	O
hundreds	O
of	O
thousands	O
of	O
images	O
.	O

Therefore	O
,	O
most	O
of	O
these	O
approaches	O
employ	O
pre	Method
-	Method
training	Method
.	O

The	O
original	O
model	O
is	O
learning	O
using	O
million	O
labeled	O
images	O
in	O
ImageNet	Material
and	O
then	O
further	O
trained	O
on	O
target	O
tasks	O
(	O
fine	Task
-	Task
tuning	Task
)	O
to	O
yield	O
better	O
performance	O
.	O

Huang	O
thoroughly	O
evaluated	O
the	O
influence	O
of	O
multiple	O
ConvNet	Method
architectures	Method
on	O
object	O
detection	Task
performance	O
,	O
and	O
found	O
that	O
it	O
is	O
closely	O
correlated	O
with	O
the	O
models	O
’	O
capacity	Metric
and	O
classification	Task
performances	O
on	O
ImageNet	Material
.	O

While	O
there	O
has	O
been	O
significant	O
work	O
on	O
increasing	O
the	O
representational	Method
capacity	Method
of	O
ConvNets	Method
,	O
the	O
amount	O
of	O
training	O
data	O
for	O
pre	Task
-	Task
training	Task
has	O
remain	O
kind	O
of	O
fixed	O
over	O
years	O
.	O

The	O
prime	O
reason	O
behind	O
this	O
is	O
the	O
lack	O
of	O
human	O
verified	O
image	O
datasets	O
larger	O
than	O
ImageNet	Material
.	O

In	O
order	O
to	O
overcome	O
the	O
bottleneck	O
,	O
there	O
have	O
been	O
recent	O
efforts	O
on	O
visual	Method
representation	Method
learning	Method
using	O
web	Method
-	Method
supervision	Method
or	O
unsupervised	Method
paradigms	Method
.	O

However	O
,	O
most	O
of	O
these	O
efforts	O
are	O
still	O
are	O
still	O
exploratory	O
in	O
nature	O
and	O
far	O
lower	O
in	O
performance	O
compared	O
to	O
fully	Method
-	Method
supervised	Method
learning	Method
.	O

In	O
this	O
paper	O
,	O
we	O
aim	O
to	O
shift	O
the	O
discussion	O
from	O
models	O
to	O
data	O
.	O

Our	O
paper	O
is	O
inspired	O
from	O
several	O
papers	O
which	O
have	O
time	O
and	O
again	O
paid	O
closer	O
look	O
to	O
impact	O
and	O
properties	O
of	O
data	O
rather	O
than	O
models	O
.	O

In	O
2009	O
,	O
Pereira	O
presented	O
a	O
survey	O
paper	O
to	O
look	O
into	O
impact	O
of	O
data	O
in	O
fields	O
such	O
as	O
natural	Task
language	Task
processing	Task
and	O
computer	Task
vision	Task
.	O

They	O
argued	O
unlike	O
physics	O
,	O
areas	O
in	O
AI	Task
are	O
more	O
likely	O
to	O
see	O
an	O
impact	O
using	O
more	O
data	Method
-	Method
driven	Method
approaches	Method
.	O

Another	O
related	O
work	O
is	O
the	O
empirical	O
study	O
by	O
Torralba	O
and	O
Efros	O
that	O
highlighted	O
the	O
dataset	O
biases	O
in	O
current	O
computer	Method
vision	Method
approaches	Method
and	O
how	O
it	O
impacts	O
future	O
research	O
.	O

Specifically	O
,	O
we	O
focus	O
on	O
understanding	O
the	O
relationship	O
between	O
data	O
and	O
visual	Task
deep	Task
learning	Task
.	O

There	O
have	O
been	O
some	O
efforts	O
to	O
understand	O
this	O
relationship	O
.	O

For	O
example	O
,	O
Oquab	O
showed	O
that	O
expanding	O
the	O
training	O
data	O
to	O
cover	O
1512	O
labels	O
from	O
ImageNet	Material
-	O
14	O
M	Method
further	O
improves	O
the	O
object	O
detection	Task
performance	O
.	O

Similarly	O
,	O
Huh	O
showed	O
that	O
using	O
a	O
smaller	O
subset	O
of	O
images	O
for	O
training	O
from	O
ImageNet	Material
hurts	O
performance	O
.	O

Both	O
these	O
studies	O
also	O
show	O
that	O
selection	O
of	O
categories	O
for	O
training	Task
is	O
important	O
and	O
random	O
addition	O
of	O
categories	O
tends	O
to	O
hurt	O
the	O
performance	O
.	O

But	O
what	O
happens	O
when	O
the	O
number	O
of	O
categories	O
are	O
increased	O
10x	O
?	O
Do	O
we	O
still	O
need	O
manual	O
selection	O
of	O
categories	O
?	O
Similarly	O
,	O
neither	O
of	O
these	O
efforts	O
demonstrated	O
data	O
effects	O
at	O
significantly	O
larger	O
scale	O
.	O

Some	O
recent	O
work	O
have	O
looked	O
at	O
training	O
ConvNets	Method
with	O
significantly	O
larger	O
data	O
.	O

While	O
looked	O
at	O
geo	Task
-	Task
localization	Task
,	O
utilized	O
the	O
YFCC	O
-	O
100	O
M	Method
dataset	O
for	O
representation	Task
learning	Task
.	O

However	O
,	O
unlike	O
ours	O
,	O
showed	O
plateauing	O
of	O
detection	Task
performance	O
when	O
trained	O
on	O
100	O
M	Method
images	O
.	O

Why	O
is	O
that	O
?	O
We	O
believe	O
there	O
could	O
be	O
two	O
possible	O
reasons	O
:	O
a	O
)	O
YFCC	O
-	O
100	O
M	Method
images	O
come	O
only	O
from	O
Flickr	Material
.	O

JFT	Method
includes	O
images	O
all	O
over	O
the	O
web	O
,	O
and	O
has	O
better	O
visual	O
diversity	O
.	O

The	O
usage	O
of	O
user	O
feedback	O
signals	O
in	O
JFT	Method
further	O
reduces	O
label	O
noise	O
.	O

YFCC	O
-	O
100	O
M	Method
has	O
a	O
much	O
bigger	O
vocabulary	O
size	O
and	O
noisier	O
annotations	O
.	O

b	O
)	O
But	O
more	O
importantly	O
,	O
they	O
did	O
not	O
see	O
real	O
effect	O
of	O
data	O
due	O
to	O
use	O
of	O
smaller	O
AlexNet	Method
of	Method
VGG	Method
models	Method
.	O

In	O
our	O
experiments	O
,	O
we	O
see	O
more	O
gain	O
with	O
larger	O
model	O
sizes	O
.	O

section	O
:	O
The	O
JFT	Method
-	O
300	O
M	Method
Dataset	O
We	O
now	O
introduce	O
the	O
JFT	Method
-	O
300	O
M	Method
dataset	O
used	O
throughout	O
this	O
paper	O
.	O

JFT	Method
-	Method
300	Method
M	Method
is	O
a	O
follow	O
up	O
version	O
of	O
the	O
dataset	O
introduced	O
by	O
.	O

The	O
JFT	Method
-	O
300	O
M	Method
dataset	O
is	O
closely	O
related	O
and	O
derived	O
from	O
the	O
data	O
which	O
powers	O
the	O
Image	Task
Search	Task
.	O

In	O
this	O
version	O
,	O
the	O
dataset	O
has	O
300	O
M	Method
images	O
and	O
375	O
M	Method
labels	O
,	O
on	O
average	O
each	O
image	O
has	O
1.26	O
labels	O
.	O

These	O
images	O
are	O
labeled	O
with	O
18291	O
categories	O
:	O
,	O
1165	O
type	O
of	O
animals	O
and	O
5720	O
types	O
of	O
vehicles	O
are	O
labeled	O
in	O
the	O
dataset	O
.	O

These	O
categories	O
form	O
a	O
rich	O
hierarchy	O
with	O
the	O
maximum	O
depth	O
of	O
hierarchy	O
being	O
12	O
and	O
maximum	O
number	O
of	O
child	O
for	O
parent	O
node	O
being	O
2876	O
.	O

The	O
images	O
are	O
labeled	O
using	O
an	O
algorithm	O
that	O
uses	O
complex	O
mixture	O
of	O
raw	O
web	O
signals	O
,	O
connections	O
between	O
web	O
-	O
pages	O
and	O
user	O
feedback	O
.	O

The	O
algorithm	O
starts	O
from	O
over	O
one	O
billion	O
image	O
label	O
pairs	O
,	O
and	O
ends	O
up	O
with	O
375	O
M	Method
labels	O
for	O
300	O
M	Method
images	O
with	O
the	O
aim	O
to	O
select	O
labeled	O
images	O
with	O
high	O
precision	Metric
.	O

However	O
,	O
there	O
is	O
still	O
some	O
noise	O
in	O
the	O
labels	O
:	O
approximately	O
20	O
%	O
of	O
the	O
labels	O
in	O
this	O
dataset	O
are	O
noisy	O
.	O

Since	O
there	O
is	O
no	O
exhaustive	O
annotation	O
,	O
we	O
have	O
no	O
way	O
to	O
estimate	O
the	O
recall	O
of	O
the	O
labels	O
.	O

Figure	O
[	O
reference	O
]	O
shows	O
the	O
kind	O
of	O
noise	O
that	O
exists	O
in	O
the	O
dataset	O
.	O

Because	O
the	O
labels	O
are	O
generated	O
automatically	O
,	O
there	O
is	O
a	O
problem	O
of	O
‘	O
tortoise	O
’	O
being	O
confused	O
with	O
‘	O
tortoise	O
-	O
shell	O
glasses	O
’	O
.	O

Finally	O
,	O
it	O
is	O
important	O
to	O
discuss	O
the	O
data	O
distribution	O
of	O
JFT	Method
-	O
300M.	O
The	O
distribution	O
is	O
heavily	O
long	O
-	O
tailed	O
:	O
,	O
there	O
are	O
more	O
than	O
2	O
M	Method
‘	O
flowers	O
’	O
,	O
3250	O
‘	O
subarau360	O
’	O
but	O
only	O
131	O
images	O
of	O
‘	O
train	O
conductors	O
’	O
.	O

In	O
fact	O
,	O
the	O
tail	O
is	O
so	O
heavy	O
that	O
we	O
have	O
more	O
than	O
3	O
K	O
categories	O
with	O
less	O
than	O
100	O
images	O
each	O
and	O
approximately	O
2	O
K	O
categories	O
with	O
less	O
than	O
20	O
images	O
per	O
category	O
.	O

section	O
:	O
Training	O
and	O
Evaluation	O
Framework	O
We	O
now	O
describe	O
our	O
training	Method
and	Method
evaluation	Method
framework	Method
for	O
the	O
paper	O
.	O

subsection	O
:	O
Training	O
on	O
JFT	Method
-	O
300	O
M	Method
Data	O
Although	O
there	O
are	O
several	O
novel	O
ConvNet	Method
architectures	Method
recently	O
proposed	O
,	O
we	O
decide	O
to	O
use	O
a	O
standard	O
Residual	Method
Network	Method
architecture	Method
with	O
101	O
layers	O
(	O
ResNet	Method
-	Method
101	Method
)	O
for	O
its	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
performance	O
and	O
the	O
ease	O
of	O
comparison	O
with	O
previous	O
work	O
.	O

To	O
train	O
a	O
ResNet	Method
-	Method
101	Method
model	O
on	O
JFT	Material
-	Material
300	Material
M	Material
,	O
We	O
add	O
a	O
fully	Method
-	Method
connected	Method
layer	Method
with	O
18291	O
outputs	O
at	O
the	O
end	O
of	O
the	O
network	O
for	O
classification	Task
.	O

As	O
the	O
image	O
labels	O
are	O
not	O
mutually	O
exclusive	O
,	O
we	O
compute	O
per	Method
-	Method
label	Method
logistic	Method
loss	Method
,	O
and	O
treat	O
all	O
non	O
-	O
present	O
labels	O
as	O
negatives	O
.	O

To	O
alleviate	O
the	O
issue	O
of	O
missing	O
labels	O
,	O
we	O
use	O
a	O
hand	O
-	O
designed	O
label	Method
hierarchy	Method
and	O
fill	O
in	O
the	O
missing	O
labels	O
accordingly	O
.	O

For	O
example	O
,	O
an	O
image	O
with	O
label	O
‘	O
apple	O
’	O
is	O
also	O
considered	O
as	O
a	O
correct	O
example	O
for	O
‘	O
fruit	O
’	O
.	O

During	O
training	O
,	O
all	O
input	O
images	O
are	O
resized	O
to	O
pixels	O
,	O
and	O
then	O
randomly	O
cropped	O
to	O
.	O

The	O
image	O
pixels	O
are	O
normalized	O
to	O
the	O
range	O
of	O
independently	O
per	O
channel	O
,	O
and	O
we	O
use	O
random	O
reflection	O
for	O
data	Task
augmentation	Task
.	O

We	O
set	O
weight	O
decay	O
to	O
and	O
use	O
batch	Method
normalization	Method
after	O
all	O
the	O
convolutional	Method
layers	Method
.	O

RMSProp	Method
optimizer	Method
is	O
used	O
with	O
momentum	O
of	O
0.9	O
,	O
and	O
the	O
batch	O
size	O
is	O
set	O
to	O
32	O
.	O

The	O
learning	Metric
rate	Metric
is	O
initially	O
and	O
we	O
decay	O
it	O
by	O
0.9	O
every	O
3	O
M	Method
steps	O
.	O

We	O
use	O
asynchronous	Method
gradient	Method
descent	Method
training	Method
on	O
50	O
NVIDIA	Method
K80	Method
GPUs	Method
.	O

The	O
model	O
is	O
implemented	O
in	O
TensorFlow	Method
.	O

To	O
allow	O
asynchrounous	Task
training	Task
of	Task
models	Task
on	O
50	O
GPUs	O
,	O
we	O
adopt	O
the	O
Downpour	Method
SGD	Method
training	Method
scheme	Method
,	O
where	O
we	O
use	O
17	O
parameter	Method
servers	Method
to	O
store	O
and	O
update	O
the	O
model	O
weights	O
.	O

The	O
final	O
classification	Method
fully	Method
-	Method
connected	Method
layer	Method
with	O
2048	O
input	O
units	O
and	O
over	O
18	O
K	O
output	O
units	O
has	O
over	O
36	O
M	Method
parameters	O
.	O

To	O
handle	O
this	O
in	O
our	O
parameter	O
servers	O
,	O
we	O
split	O
it	O
vertically	O
into	O
50	O
equal	O
sized	O
sub	O
-	O
fc	O
layers	O
,	O
and	O
distribute	O
them	O
around	O
different	O
parameter	O
servers	O
.	O

ImageNet	Material
baseline	O
:	O
As	O
observed	O
by	O
,	O
hyperparameters	O
that	O
are	O
selected	O
to	O
train	O
with	O
JFT	Method
-	O
300	O
M	Method
data	O
yield	O
sub	O
-	O
optimal	O
performance	O
when	O
training	O
on	O
ImageNet	Material
(	O
IVSVRC	O
2012	O
image	Task
classification	Task
dataset	O
with	O
1.2	O
M	Method
images	O
)	O
.	O

Therefore	O
,	O
for	O
ImageNet	Material
,	O
we	O
use	O
a	O
momentum	Method
optimizer	Method
with	O
the	O
momentum	O
of	O
0.9	O
,	O
and	O
set	O
the	O
initial	O
learning	Metric
rate	Metric
to	O
and	O
batch	O
size	O
to	O
32	O
.	O

Learning	Metric
rate	Metric
is	O
reduced	O
by	O
a	O
factor	O
of	O
10	O
every	O
30	O
epochs	O
(	O
1.2	O
M	Method
steps	O
)	O
,	O
and	O
we	O
train	O
the	O
model	O
for	O
a	O
total	O
of	O
5	O
M	Method
steps	O
.	O

Similar	O
to	O
JFT	Method
-	O
300	O
M	Method
training	O
,	O
we	O
use	O
asynchronous	Method
gradient	Method
descent	Method
training	Method
on	O
50	O
NVIDIA	Method
K80	Method
GPUs	Method
and	O
17	O
parameter	Method
servers	Method
.	O

Our	O
baseline	O
ResNet	Method
-	Method
101	Method
performs	O
1	O
%	O
better	O
than	O
the	O
open	O
-	O
sourced	O
ResNet	Method
-	Method
101	Method
checkpoint	O
from	O
the	O
authors	O
of	O
,	O
using	O
the	O
same	O
evaluation	O
protocol	O
.	O

subsection	O
:	O
Monitoring	Task
Training	Task
Progress	Task
For	O
monitoring	O
the	O
training	O
progress	O
on	O
JFT	Material
-	Material
300	Material
M	Material
,	O
we	O
use	O
the	O
validation	O
set	O
from	O
Chollet	Method
:	O
‘	O
FastEval14k	Method
’	Method
.	O

FastEval14k	Method
consists	O
of	O
14000	O
images	O
with	O
labels	O
from	O
6000	O
classes	O
(	O
subset	O
of	O
18291	O
classes	O
from	O
JFT	Material
-	Material
300	Material
M	Material
)	O
.	O

Unlike	O
labels	O
in	O
JFT	Material
-	Material
300	Material
M	Material
,	O
the	O
images	O
in	O
FastEval14k	Material
are	O
densely	O
annotated	O
and	O
there	O
are	O
around	O
37	O
labels	O
per	O
image	O
on	O
average	O
.	O

We	O
use	O
the	O
same	O
mAP@100	Metric
metric	Metric
as	O
in	O
,	O
which	O
is	O
computed	O
as	O
the	O
mean	Metric
average	Metric
precision	Metric
(	O
mAP	Metric
)	O
for	O
top	Metric
-	Metric
100	Metric
predictions	Metric
.	O

Note	O
that	O
the	O
class	O
AP	Metric
is	O
weighted	O
by	O
how	O
common	O
the	O
class	O
is	O
among	O
social	O
media	O
images	O
.	O

We	O
tried	O
two	O
strategies	O
to	O
initialize	O
the	O
model	Method
weights	Method
for	O
training	Task
:	O
random	Method
initialization	Method
and	O
initializing	O
from	O
an	O
ImageNet	Material
checkpoint	O
.	O

In	O
both	O
settings	O
,	O
we	O
used	O
the	O
same	O
training	O
schedule	O
(	O
,	O
learning	Metric
rates	Metric
)	O
.	O

We	O
found	O
that	O
on	O
FastEval14k	Material
benchmark	Material
,	O
model	O
trained	O
from	O
ImageNet	Method
initialization	Method
performs	O
better	O
at	O
the	O
first	O
15	O
M	Method
iterations	O
,	O
but	O
then	O
becomes	O
on	O
par	O
with	O
random	Method
initialization	Method
.	O

Figure	O
[	O
reference	O
]	O
shows	O
the	O
training	O
progress	O
for	O
these	O
two	O
settings	O
.	O

On	O
FastEval14k	Material
benchmark	Material
,	O
model	O
trained	O
from	O
ImageNet	Method
initialization	Method
performs	O
better	O
at	O
the	O
first	O
15	O
M	Method
iterations	O
,	O
but	O
then	O
becomes	O
on	O
par	O
with	O
random	Method
initialization	Method
.	O

Please	O
note	O
that	O
the	O
full	O
training	O
schedule	O
takes	O
90	O
M	Method
iterations	O
or	O
around	O
10	O
epochs	O
.	O

However	O
,	O
due	O
to	O
the	O
time	O
constraints	O
,	O
we	O
train	O
the	O
models	O
for	O
36	O
M	Method
iterations	O
or	O
4	O
epochs	O
,	O
which	O
takes	O
approximately	O
2	O
months	O
.	O

We	O
will	O
study	O
the	O
impact	O
of	O
training	O
iterations	O
in	O
Section	O
[	O
reference	O
]	O
.	O

subsection	O
:	O
Evaluating	O
the	O
Visual	Method
Representations	Method
We	O
use	O
two	O
approaches	O
to	O
evaluate	O
the	O
quality	O
of	O
visual	Method
representations	Method
learned	O
from	O
300	O
M	Method
training	O
data	O
.	O

The	O
first	O
approach	O
is	O
to	O
freeze	O
the	O
model	O
weights	O
and	O
use	O
these	O
models	O
as	O
pure	O
feature	Method
extractors	Method
.	O

The	O
second	O
approach	O
is	O
to	O
use	O
the	O
model	O
weights	O
as	O
initialization	O
and	O
fine	O
-	O
tune	O
the	O
weights	O
for	O
other	O
tasks	O
.	O

For	O
evaluating	O
visual	Task
representations	Task
,	O
we	O
select	O
three	O
representative	O
computer	Task
vision	Task
tasks	Task
:	O
object	O
detection	Task
,	O
semantic	Task
segmentation	Task
and	O
human	Task
pose	Task
estimation	Task
.	O

We	O
will	O
perform	O
a	O
more	O
rigorous	O
ablative	Task
analysis	Task
to	O
observe	O
the	O
effect	O
of	O
dataset	Metric
size	Metric
,	O
vocabulary	Metric
size	Metric
,	O
on	O
the	O
object	O
detection	Task
task	O
.	O

For	O
the	O
other	O
tasks	O
,	O
we	O
will	O
just	O
show	O
how	O
JFT	Method
-	O
300	O
M	Method
provides	O
significant	O
improvement	O
compared	O
to	O
baseline	O
ImageNet	Material
ResNet	O
.	O

De	Task
-	Task
duplication	Task
One	O
concern	O
with	O
using	O
large	O
-	O
scale	O
sets	O
such	O
as	O
JFT	Material
-	Material
300	Material
M	Material
is	O
the	O
possible	O
overlap	O
between	O
training	O
and	O
test	O
sets	O
.	O

Such	O
duplication	O
exist	O
in	O
current	O
frameworks	O
as	O
well	O
:	O
890	O
out	O
of	O
50	O
K	O
validation	O
images	O
in	O
ImageNet	Material
have	O
near	O
-	O
duplicate	O
images	O
training	O
set	O
.	O

However	O
,	O
to	O
ensure	O
such	O
duplication	O
does	O
not	O
affect	O
our	O
results	O
,	O
we	O
performed	O
all	O
experiments	O
by	O
removing	O
near	O
-	O
duplicate	O
images	O
from	O
test	O
sets	O
.	O

We	O
found	O
the	O
difference	O
in	O
performance	O
to	O
be	O
insignificant	O
for	O
all	O
the	O
experiments	O
.	O

We	O
therefore	O
report	O
de	O
-	O
duplicated	O
test	O
-	O
set	O
results	O
in	O
Appendix	O
A.	O
Object	Task
Detection	Task
.	O

We	O
use	O
the	O
Faster	O
RCNN	Method
framework	Method
for	O
its	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
performance	O
.	O

Faster	O
RCNN	Method
is	O
a	O
two	O
-	O
stage	Method
model	Method
.	O

The	O
first	O
stage	O
is	O
called	O
region	Method
proposal	Method
network	Method
(	O
RPN	Method
)	Method
,	O
which	O
aims	O
at	O
generating	O
class	Task
-	Task
agnostic	Task
object	Task
proposals	Task
.	O

The	O
second	O
stage	O
is	O
a	O
box	Method
classifier	Method
,	O
it	O
takes	O
the	O
boxes	O
predicted	O
by	O
RPN	Method
and	O
crops	O
feature	Method
maps	Method
to	O
generate	O
classification	Task
predictions	Task
and	O
refined	Task
bounding	Task
box	Task
predictions	Task
.	O

These	O
two	O
stages	O
share	O
a	O
common	O
feature	O
map	O
generated	O
by	O
a	O
ConvNet	Method
,	O
and	O
box	Method
classifier	Method
has	O
additional	O
convolutional	Method
layers	Method
before	O
its	O
final	O
classification	Method
and	Method
regression	Method
layers	Method
.	O

To	O
use	O
the	O
ResNet	Method
-	Method
101	Method
model	O
pre	O
-	O
trained	O
on	O
JFT	Method
-	O
300	O
M	Method
data	O
,	O
we	O
split	O
the	O
model	O
into	O
two	O
parts	O
:	O
the	O
first	O
part	O
starts	O
from	O
conv1	O
block	O
and	O
ends	O
at	O
conv4	O
block	O
,	O
it	O
is	O
used	O
for	O
feature	Task
extraction	Task
and	O
is	O
shared	O
by	O
both	O
RPN	Method
and	Method
box	Method
classifier	Method
;	O
the	O
second	O
part	O
consists	O
of	O
the	O
conv5	O
block	O
,	O
it	O
is	O
used	O
by	O
box	Method
classifier	Method
.	O

Semantic	Task
Segmentation	Task
.	O

We	O
use	O
the	O
DeepLab	Method
framework	Method
with	O
ResNet	Method
-	Method
101	Method
base	O
architecture	O
for	O
the	O
task	O
of	O
semantic	Task
segmentation	Task
.	O

In	O
particular	O
,	O
we	O
use	O
a	O
variant	O
which	O
adds	O
four	O
branches	O
after	O
the	O
conv5	O
block	O
of	O
ResNet	Method
-	Method
101	Method
architecture	O
.	O

Each	O
branch	O
is	O
an	O
atrous	Method
convolutional	Method
layer	Method
that	O
predicts	O
a	O
sub	O
-	O
sampled	O
pixel	O
-	O
wise	O
class	O
probabilities	O
.	O

Predictions	O
from	O
all	O
branches	O
are	O
fused	O
together	O
to	O
produce	O
the	O
final	O
segmentation	Task
output	O
.	O

Please	O
refer	O
to	O
the	O
DeepLab	Method
-	Method
ASPP	Method
-	Method
L	Method
model	Method
(	O
A	O
trous	O
S	O
patial	O
P	O
yramid	O
P	O
ooling	O
,	O
with	O
L	O
arge	O
atrous	O
rates	O
)	O
from	O
for	O
details	O
.	O

Pose	Task
Estimation	Task
.	O

We	O
follow	O
the	O
framework	O
proposed	O
by	O
Papandreou	O
.	O

It	O
uses	O
person	O
bounding	O
boxes	O
detected	O
by	O
Faster	O
RCNN	Method
,	O
then	O
applies	O
a	O
ResNet	Method
fully	Method
convolutionally	Method
to	O
produce	O
heatmaps	O
and	O
offsets	O
for	O
all	O
keypoints	O
.	O

A	O
novel	O
scoring	O
and	O
non	Method
-	Method
maximum	Method
suppression	Method
(	O
NMS	Method
)	O
scheme	O
is	O
used	O
to	O
suppress	O
duplicate	O
detections	O
and	O
improve	O
performance	O
.	O

We	O
simply	O
replace	O
the	O
base	O
models	O
used	O
in	O
their	O
framework	O
by	O
our	O
trained	O
ResNet	Method
-	Method
101	Method
models	O
.	O

section	O
:	O
Experiments	O
We	O
present	O
results	O
of	O
fine	O
-	O
tuning	O
JFT	Method
-	O
300	O
M	Method
ResNet	Method
-	Method
101	Method
checkpoints	O
on	O
four	O
tasks	O
:	O
image	Task
classification	Task
,	O
object	O
detection	Task
,	O
semantic	Task
segmentation	Task
and	O
human	Task
pose	Task
estimation	Task
.	O

subsection	O
:	O
Image	Task
Classification	Task
We	O
fine	O
-	O
tune	O
the	O
JFT	Method
-	O
300	O
M	Method
pre	O
-	O
trained	O
ResNet101	O
using	O
ImageNet	Material
classification	O
data	O
and	O
compare	O
it	O
with	O
a	O
ResNet101	Method
model	Method
trained	O
from	O
scratch	O
.	O

For	O
this	O
experiment	O
,	O
we	O
use	O
the	O
standard	O
ILSVRC	Method
2012	O
‘	O
train	O
’	O
and	O
‘	O
val	O
’	O
sets	O
for	O
training	O
and	O
evaluation	Task
.	O

There	O
are	O
1.2	O
M	Method
training	O
images	O
and	O
50	O
K	O
validation	O
images	O
,	O
over	O
1000	O
classes	O
.	O

We	O
use	O
the	O
same	O
ImageNet	Material
training	O
setup	O
as	O
described	O
in	O
Section	O
[	O
reference	O
]	O
for	O
the	O
ImageNet	Material
baseline	O
,	O
but	O
lowered	O
the	O
initial	O
learning	Metric
rate	Metric
to	O
(	O
standard	O
for	O
fine	Task
-	Task
tuning	Task
)	O
.	O

We	O
initialize	O
the	O
model	O
weights	O
from	O
the	O
JFT	Method
-	O
300	O
M	Method
checkpoint	O
trained	O
for	O
36	O
M	Method
iterations	O
and	O
fine	O
-	O
tune	O
on	O
ImageNet	Material
for	O
4	O
M	Method
iterations	O
.	O

Table	O
[	O
reference	O
]	O
compares	O
the	O
fine	Task
-	Task
tuning	Task
results	O
with	O
models	O
trained	O
from	O
the	O
scratch	O
.	O

For	O
reference	O
,	O
we	O
show	O
the	O
random	Method
initialization	Method
performance	O
for	O
the	O
open	O
-	O
sourced	O
checkpoint	O
from	O
the	O
authors	O
of	O
.	O

We	O
report	O
top	Metric
-	Metric
1	Metric
and	O
top	Metric
-	Metric
5	Metric
accuracies	Metric
with	O
a	O
single	O
crop	O
being	O
evaluated	O
.	O

We	O
can	O
see	O
that	O
fine	O
-	O
tuning	O
on	O
JFT	Material
-	Material
300	Material
M	Material
gives	O
considerable	O
performance	O
boost	O
for	O
both	O
top	Metric
-	Metric
1	Metric
and	O
top	Metric
-	Metric
5	Metric
accuracies	Metric
.	O

subsection	O
:	O
Object	Task
Detection	Task
We	O
next	O
evaluate	O
the	O
JFT	Method
-	O
300	O
M	Method
checkpoints	O
on	O
object	O
detection	Task
tasks	O
.	O

We	O
evaluate	O
on	O
the	O
two	O
most	O
popular	O
datasets	O
:	O
COCO	Material
and	O
PASCAL	Material
VOC	Material
.	O

Instead	O
of	O
just	O
showing	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
performance	O
,	O
we	O
will	O
also	O
perform	O
a	O
rigorous	O
ablative	Method
analysis	Method
to	O
gain	O
insights	O
into	O
the	O
relationship	O
between	O
data	O
and	O
representation	Task
learning	Task
.	O

Specifically	O
,	O
we	O
use	O
object	O
detection	Task
experiments	O
to	O
answer	O
the	O
following	O
questions	O
:	O
How	O
does	O
the	O
performance	O
of	O
trained	O
representations	O
vary	O
with	O
iterations	O
and	O
epochs	O
?	O
Does	O
the	O
performance	O
of	O
learned	O
visual	Method
representations	Method
saturate	O
after	O
certain	O
amount	O
of	O
data	O
?	O
Do	O
we	O
see	O
any	O
plateauing	O
effect	O
with	O
more	O
and	O
more	O
data	O
?	O
How	O
important	O
is	O
representational	O
capacity	O
?	O
Is	O
the	O
number	O
of	O
classes	O
a	O
key	O
factor	O
in	O
learning	Task
visual	Task
representation	Task
?	O
How	O
could	O
clean	O
data	O
(	O
,	O
ImageNet	Material
)	O
help	O
improve	O
the	O
visual	Method
representations	Method
?	O
subsubsection	O
:	O
Experimental	O
Setup	O
For	O
COCO	Material
,	O
we	O
use	O
a	O
held	O
-	O
out	O
8000	O
images	O
from	O
the	O
standard	O
‘	O
val	O
’	O
set	O
as	O
our	O
validation	O
set	O
,	O
we	O
refer	O
to	O
it	O
as	O
‘	O
minival	O
∗	O
’	O
,	O
the	O
same	O
set	O
of	O
images	O
was	O
used	O
by	O
.	O

We	O
use	O
a	O
combination	O
of	O
the	O
standard	O
training	O
set	O
and	O
the	O
remaining	O
validation	O
images	O
for	O
training	O
.	O

Unless	O
otherwise	O
specified	O
,	O
all	O
COCO	Material
results	O
are	O
reported	O
on	O
the	O
minival	O
∗	O
set	O
.	O

In	O
particular	O
,	O
we	O
are	O
interested	O
in	O
mean	Metric
average	Metric
precision	Metric
at	O
50	O
%	O
IOU	Metric
threshold	Metric
(	O
mAP@.5	Metric
)	O
,	O
and	O
the	O
average	O
of	O
mAP	Metric
at	O
IOU	Metric
thresholds	Metric
50	O
%	O
to	O
95	O
%	O
(	O
mAP@	Metric
[	Metric
.5	Metric
,	O
.95	O
]	O
)	O
.	O

For	O
our	O
best	O
ResNet101	Method
models	Method
,	O
we	O
also	O
evaluate	O
on	O
the	O
COCO	Material
‘	O
test	O
-	O
dev	O
’	O
split	O
(	O
evaluated	O
by	O
the	O
official	O
result	O
server	O
)	O
.	O

For	O
PASCAL	Material
VOC	Material
,	O
we	O
use	O
the	O
16551	O
‘	O
trainval	O
’	O
images	O
from	O
PASCAL	Material
VOC	Material
2007	Material
and	O
2012	O
for	O
training	O
,	O
and	O
report	O
performance	O
on	O
the	O
PASCAL	Material
VOC	Material
2007	Material
Test	Material
,	O
which	O
has	O
4952	O
images	O
using	O
mAP@.5	Metric
metric	Metric
.	O

We	O
use	O
the	O
TensorFlow	Method
Faster	Method
RCNN	Method
implementation	Method
and	O
adopt	O
their	O
default	O
training	Method
hyperparameters	Method
except	O
for	O
learning	Metric
rate	Metric
schedules	Metric
.	O

We	O
use	O
asynchronous	Task
training	Task
with	O
9	O
GPU	O
workers	O
and	O
11	O
parameter	O
servers	O
,	O
momentum	Method
optimizer	Method
is	O
used	O
with	O
the	O
momentum	O
of	O
0.9	O
.	O

Each	O
worker	O
takes	O
a	O
single	O
input	O
image	O
per	O
step	O
,	O
the	O
batch	O
size	O
for	O
RPN	Method
and	O
box	Method
classifier	Method
training	Method
are	O
64	O
and	O
256	O
respectively	O
.	O

Input	O
images	O
are	O
resized	O
to	O
have	O
600	O
minimum	O
pixels	O
and	O
1024	O
maximum	O
pixels	O
while	O
maintaining	O
the	O
aspect	O
ratio	O
.	O

The	O
only	O
data	Method
augmentation	Method
used	O
is	O
random	Method
flipping	Method
.	O

For	O
COCO	Material
,	O
we	O
set	O
the	O
initial	O
learning	Metric
rate	Metric
to	O
be	O
,	O
and	O
decay	O
the	O
learning	Metric
rate	Metric
by	O
a	O
factor	O
of	O
10	O
after	O
2.5	O
M	Method
steps	O
,	O
the	O
total	O
number	O
of	O
steps	O
is	O
3M.	O
For	O
PASCAL	Material
VOC	Material
,	O
we	O
set	O
the	O
initial	O
learning	Metric
rate	Metric
to	O
be	O
,	O
and	O
decay	O
the	O
learning	Metric
rate	Metric
by	O
0.1	O
after	O
500	O
K	O
steps	O
,	O
and	O
the	O
model	O
is	O
trained	O
for	O
700	O
K	O
steps	O
.	O

The	O
training	O
schedules	O
were	O
selected	O
on	O
held	O
-	O
out	O
validation	O
images	O
using	O
the	O
open	O
-	O
source	O
ResNet	Method
-	Method
101	Method
model	O
(	O
pre	O
-	O
trained	O
on	O
ImageNet	Material
)	O
.	O

We	O
found	O
the	O
same	O
training	O
schedules	O
work	O
well	O
on	O
other	O
checkpoints	O
,	O
and	O
keep	O
them	O
fixed	O
throughout	O
for	O
fairer	O
comparison	O
.	O

During	O
inference	Task
,	O
we	O
use	O
300	O
RPN	Method
proposals	Method
.	O

Our	O
vanilla	Method
FasterRCNN	Method
implementation	Method
does	O
not	O
use	O
the	O
multi	O
-	O
scale	O
inference	O
,	O
context	O
or	O
box	Method
-	Method
refinement	Method
as	O
described	O
in	O
.	O

subsubsection	O
:	O
Comparison	O
with	O
ImageNet	Material
Models	O
We	O
first	O
present	O
the	O
performance	O
comparison	O
with	O
ImageNet	Material
checkpoints	O
.	O

Table	O
[	O
reference	O
]	O
shows	O
the	O
detection	Task
performance	O
on	O
COCO	Material
‘	O
test	O
-	O
dev	O
’	O
split	O
.	O

To	O
show	O
that	O
our	O
Faster	O
RCNN	Method
baseline	Method
is	O
competitive	O
,	O
we	O
also	O
report	O
results	O
from	O
the	O
Faster	O
RCNN	Method
paper	Method
,	O
which	O
uses	O
both	O
box	O
refinement	O
and	O
context	O
information	O
.	O

We	O
can	O
see	O
that	O
our	O
ImageNet	Material
baseline	O
performs	O
competitively	O
.	O

We	O
evaluate	O
JFT	Material
-	Material
300	Material
M	Material
trained	O
from	O
scratch	O
(	O
‘	O
300	O
M	Method
’	O
)	O
and	O
from	O
ImageNet	Method
initialization	Method
(	O
’	O
ImageNet	Material
+	O
300	O
M	Method
’	O
)	O
.	O

Both	O
models	O
outperforms	O
the	O
ImageNet	Material
baseline	O
by	O
large	O
margins	O
,	O
with	O
3.3	O
%	O
and	O
4.4	O
%	O
boost	O
in	O
mAP@.5	Metric
,	O
2.4	O
%	O
and	O
3.1	O
%	O
in	O
mAP@	Metric
[	Metric
.5	Metric
,	Metric
.95	Metric
]	Metric
respectively	O
.	O

As	O
a	O
reference	O
,	O
we	O
also	O
show	O
the	O
performance	O
of	O
ImageNet	Material
trained	O
InceptionResNetv2	O
in	O
Table	O
[	O
reference	O
]	O
.	O

We	O
would	O
like	O
to	O
point	O
out	O
that	O
the	O
gain	O
is	O
even	O
more	O
significant	O
than	O
recently	O
achieved	O
by	O
doubling	O
the	O
number	O
of	O
layers	O
on	O
Inception	Material
ResNet	Material
.	O

This	O
clearly	O
indicates	O
that	O
while	O
there	O
are	O
indications	O
of	O
a	O
plateauing	O
effect	O
on	O
model	Method
representation	Method
capacity	Method
;	O
in	O
terms	O
of	O
data	O
there	O
is	O
still	O
a	O
lot	O
that	O
can	O
be	O
easily	O
gained	O
.	O

Table	O
[	O
reference	O
]	O
shows	O
the	O
performance	O
on	O
the	O
PASCAL	Material
VOC	Material
2007	Material
‘	O
test	O
’	O
set	O
.	O

Again	O
,	O
both	O
JFT	Method
-	O
300	O
M	Method
checkpoints	O
outperforms	O
the	O
ImageNet	Material
baseline	O
significantly	O
,	O
by	O
5.1	O
%	O
and	O
5.0	O
%	O
mAP@.5	Metric
respectively	O
.	O

subsubsection	O
:	O
Impact	O
of	O
Epochs	O
We	O
study	O
how	O
the	O
number	O
of	O
training	O
epochs	O
affects	O
the	O
object	O
detection	Task
performance	O
.	O

For	O
this	O
experiment	O
we	O
report	O
results	O
on	O
COCO	Material
minival	O
∗	O
set	O
.	O

Table	O
[	O
reference	O
]	O
shows	O
the	O
performance	O
comparison	O
when	O
the	O
JFT	Method
-	O
300	O
M	Method
model	O
has	O
been	O
trained	O
for	O
1.3	O
,	O
2.6	O
and	O
4	O
epochs	O
respectively	O
.	O

We	O
can	O
see	O
that	O
as	O
the	O
number	O
of	O
training	O
steps	O
increases	O
,	O
the	O
performance	O
also	O
improves	O
.	O

As	O
a	O
comparison	O
,	O
in	O
Table	O
[	O
reference	O
]	O
we	O
show	O
the	O
ImageNet	Material
counterpart	O
when	O
trained	O
for	O
3	O
,	O
6	O
,	O
12	O
and	O
150	O
epochs	O
,	O
we	O
can	O
see	O
that	O
the	O
performance	O
of	O
ImageNet	Material
checkpoints	O
improves	O
faster	O
than	O
JFT	Material
-	Material
300	Material
M	Material
with	O
respect	O
to	O
the	O
number	O
of	O
epochs	O
.	O

We	O
would	O
also	O
like	O
to	O
point	O
out	O
that	O
our	O
learning	Method
schedules	Method
have	O
been	O
developed	O
using	O
the	O
experience	O
from	O
smaller	O
datasets	O
.	O

One	O
can	O
envision	O
better	O
learning	Method
schedules	Method
which	O
provide	O
more	O
improvement	O
as	O
more	O
epochs	O
are	O
used	O
.	O

subsubsection	O
:	O
Impact	O
of	O
Data	Metric
Size	Metric
For	O
this	O
experiment	O
,	O
we	O
randomly	O
sample	O
a	O
subset	O
of	O
10	O
M	Method
,	O
30	O
M	Method
and	O
100	O
M	Method
images	O
from	O
the	O
JFT	Method
-	O
300	O
M	Method
training	O
data	O
.	O

We	O
use	O
the	O
same	O
training	O
schedule	O
as	O
the	O
JFT	Method
-	O
300	O
M	Method
model	O
training	O
.	O

We	O
pick	O
the	O
checkpoints	O
corresponding	O
to	O
the	O
4th	O
epoch	O
for	O
each	O
subset	O
.	O

To	O
study	O
the	O
impact	O
of	O
learned	O
visual	O
representations	O
,	O
we	O
also	O
conduct	O
an	O
experiments	O
to	O
freeze	O
the	O
model	O
weights	O
for	O
all	O
layers	O
before	O
the	O
conv5	O
block	O
.	O

For	O
this	O
set	O
of	O
experiments	O
we	O
change	O
the	O
learning	Metric
rate	Metric
decay	Metric
to	O
happen	O
at	O
900	O
K	O
steps	O
,	O
and	O
the	O
total	O
number	O
of	O
training	O
steps	O
to	O
1.5	O
M	Method
,	O
as	O
we	O
find	O
they	O
tend	O
to	O
converge	O
earlier	O
.	O

In	O
Figure	O
[	O
reference	O
]	O
,	O
we	O
show	O
the	O
mAP@	O
[	O
.5	O
,	O
.95	O
]	O
with	O
checkpoints	O
trained	O
on	O
different	O
JFT	Method
-	O
300	O
M	Method
subsets	O
,	O
the	O
blue	O
curve	O
corresponds	O
to	O
the	O
regular	Method
faster	Method
RCNN	Method
training	Method
(	O
with	O
fine	Method
-	Method
tuning	Method
)	O
,	O
while	O
the	O
red	O
curve	O
corresponds	O
to	O
freezing	Method
feature	Method
extractors	Method
.	O

Not	O
surprisingly	O
,	O
fine	Method
-	Method
tuning	Method
offers	O
significantly	O
better	O
performance	O
on	O
all	O
data	O
sizes	O
.	O

Most	O
interestingly	O
,	O
we	O
can	O
see	O
that	O
the	O
performance	O
grows	O
logarithmically	O
as	O
pre	O
-	O
training	O
data	O
expands	O
,	O
this	O
is	O
particularly	O
true	O
when	O
feature	Method
extraction	Method
layers	Method
are	O
frozen	O
.	O

subsubsection	O
:	O
Impact	O
of	O
Classes	O
JFT	Method
-	Method
300	Method
M	Method
has	O
18	O
K	O
labels	O
in	O
total	O
.	O

To	O
understand	O
what	O
the	O
large	O
number	O
of	O
classes	O
brings	O
us	O
,	O
we	O
select	O
a	O
subset	O
of	O
941	O
labels	O
which	O
have	O
direct	O
correspondence	O
to	O
the	O
1000	O
ImageNet	Material
labels	O
,	O
and	O
sample	O
JFT	Method
-	O
300	O
M	Method
images	O
which	O
contain	O
at	O
least	O
one	O
of	O
such	O
labels	O
.	O

This	O
results	O
in	O
a	O
subset	O
of	O
30	O
M	Method
images	O
.	O

We	O
then	O
train	O
on	O
this	O
dataset	O
for	O
4	O
epochs	O
using	O
the	O
same	O
training	Method
scheme	Method
.	O

Table	O
[	O
reference	O
]	O
shows	O
the	O
performance	O
comparison	O
on	O
COCO	Material
minival	O
∗	O
set	O
.	O

We	O
see	O
that	O
the	O
two	O
models	O
perform	O
on	O
par	O
with	O
each	O
other	O
.	O

This	O
indicates	O
that	O
the	O
performance	O
benefit	O
comes	O
from	O
more	O
training	O
images	O
instead	O
of	O
more	O
labels	O
.	O

subsubsection	O
:	O
Impact	O
of	O
Model	Metric
Capacity	Metric
Finally	O
,	O
we	O
study	O
the	O
impact	O
of	O
model	Method
capacity	Method
when	O
300	O
M	Method
images	O
are	O
available	O
for	O
training	O
.	O

We	O
conduct	O
the	O
experiments	O
on	O
the	O
50	O
-	O
layer	O
,	O
101	O
-	O
layer	O
and	O
152	Method
-	Method
layer	Method
ResNet	Method
models	Method
.	O

Each	O
model	O
is	O
trained	O
from	O
scratch	O
on	O
the	O
JFT	Method
-	O
300	O
M	Method
data	O
,	O
with	O
the	O
same	O
hyper	O
parameters	O
used	O
for	O
ResNet	Method
-	Method
101	Method
experiments	O
.	O

For	O
comparison	O
,	O
we	O
also	O
train	O
the	O
models	O
on	O
ImageNet	Material
data	O
till	O
convergence	O
,	O
using	O
the	O
same	O
hyper	O
parameters	O
for	O
ResNet	Method
-	Method
101	Method
.	O

Figure	O
[	O
reference	O
]	O
shows	O
the	O
performance	O
of	O
fine	O
-	O
tuning	O
different	O
pre	Method
-	Method
trained	Method
models	Method
on	O
COCO	Material
minival	O
∗	O
set	O
.	O

We	O
observe	O
that	O
higher	O
capacity	Method
models	Method
are	O
better	O
at	O
utilizing	O
300	O
M	Method
data	O
.	O

For	O
example	O
,	O
in	O
case	O
of	O
ResNet	O
-	O
50	O
the	O
gain	O
is	O
smaller	O
compared	O
to	O
when	O
using	O
ResNet	Method
-	Method
152	Method
.	O

subsection	O
:	O
Semantic	Task
Segmentation	Task
We	O
use	O
the	O
PASCAL	Material
VOC	Material
2012	O
semantic	Task
segmentation	Task
benchmark	O
which	O
has	O
pixel	O
-	O
wise	O
labels	O
for	O
20	O
foreground	O
classes	O
and	O
one	O
background	O
class	O
.	O

As	O
is	O
standard	O
practice	O
,	O
all	O
models	O
are	O
trained	O
on	O
an	O
augmented	Material
PASCAL	Material
VOC	Material
2012	Material
‘	O
trainaug	O
’	O
set	O
with	O
10582	O
images	O
(	O
extra	O
annotations	O
from	O
)	O
.	O

We	O
report	O
quantitative	O
results	O
on	O
the	O
PASCAL	Material
VOC	Material
2012	Material
‘	O
val	O
’	O
set	O
(	O
1449	O
images	O
)	O
using	O
the	O
standard	O
mean	Metric
intersection	Metric
-	Metric
over	Metric
-	Metric
union	Metric
(	O
mIOU	Metric
)	O
metric	O
.	O

Implementation	O
details	O
.	O

The	O
DeepLab	Method
-	Method
ASPP	Method
-	O
L	Method
model	Method
has	O
four	O
parallel	O
branches	O
after	O
conv5	Method
block	Method
of	O
ResNet101	Method
architecture	Method
.	O

Each	O
branch	O
is	O
a	O
convolutional	Method
layer	Method
,	O
with	O
a	O
different	O
atrous	O
rate	O
(	O
)	O
.	O

Different	O
atrous	O
rates	O
enable	O
the	O
model	O
to	O
capture	O
objects	O
and	O
context	O
at	O
different	O
scales	O
.	O

Output	O
of	O
each	O
branch	O
is	O
pixel	O
-	O
wise	O
scores	O
for	O
21	O
classes	O
with	O
the	O
same	O
resolution	O
output	O
map	O
(	O
subsampled	O
by	O
factor	O
of	O
8	O
compared	O
to	O
the	O
original	O
image	O
)	O
.	O

These	O
scores	O
are	O
added	O
together	O
and	O
normalized	O
for	O
the	O
final	O
pixel	O
-	O
wise	O
class	O
probabilities	O
.	O

For	O
training	Task
,	O
we	O
use	O
mini	Method
-	Method
batch	Method
SGD	Method
with	O
momentum	Method
.	O

Our	O
model	O
is	O
trained	O
for	O
30k	O
SGD	Method
iterations	Method
using	O
a	O
mini	O
-	O
batch	O
of	O
6	O
images	O
,	O
momentum	O
of	O
0.9	O
,	O
an	O
initialize	Metric
learning	Metric
rate	Metric
(	O
LR	Method
)	O
of	O
and	O
”	O
polynomial	Method
”	Method
learning	Method
rate	Method
policy	Method
.	O

All	O
layers	O
are	O
trained	O
with	O
L2	Method
-	Method
regularization	Method
(	O
weight	O
decay	O
of	O
)	O
.	O

We	O
do	O
not	O
use	O
any	O
data	Task
-	Task
augmentation	Task
,	O
multi	Task
-	Task
scale	Task
training	Task
/	Task
testing	Task
or	O
post	Task
-	Task
processing	Task
using	O
CRFs	Method
for	O
this	O
task	O
.	O

To	O
initialize	O
the	O
DeepLab	Method
-	Method
ASPP	Method
-	Method
L	Method
model	Method
using	O
ImageNet	Material
or	O
JFT	Material
-	Material
300	Material
M	Material
trained	O
checkpoints	O
,	O
the	O
final	O
classification	Method
layer	Method
from	O
these	O
checkpoints	O
is	O
replaced	O
with	O
four	O
convolutional	O
branches	O
(	O
initialized	O
using	O
Xavier	Method
)	O
.	O

All	O
input	O
images	O
are	O
resized	O
to	O
,	O
which	O
results	O
in	O
a	O
conv5	O
block	O
from	O
the	O
ResNet101	Method
network	Method
as	O
well	O
as	O
predictions	O
from	O
the	O
entire	O
model	O
.	O

paragraph	O
:	O
Comparison	O
with	O
ImageNet	Material
Models	O
.	O

We	O
present	O
quantitative	O
comparison	O
of	O
JFT	Method
-	O
300	O
M	Method
checkpoints	O
with	O
ImageNet	Material
checkpoints	O
in	O
Figure	O
[	O
reference	O
]	O
(	O
left	O
)	O
.	O

We	O
see	O
that	O
the	O
JFT	Method
-	O
300	O
M	Method
checkpoint	O
outperforms	O
ImageNet	Material
by	O
1.7	O
%	O
points	O
.	O

We	O
further	O
observe	O
that	O
the	O
JFT	Method
-	O
300	O
M	Method
model	O
trained	O
from	O
the	O
ImageNet	Material
checkpoint	O
provides	O
2.9	O
%	O
points	O
boost	O
over	O
the	O
vanilla	O
ImageNet	Material
checkpoint	O
.	O

paragraph	O
:	O
Impact	O
of	O
Data	Metric
Size	Metric
.	O

In	O
Figure	O
[	O
reference	O
]	O
(	O
right	O
)	O
,	O
we	O
further	O
present	O
analysis	O
of	O
impact	O
of	O
training	Metric
data	Metric
size	Metric
by	O
randomly	O
sampling	O
a	O
subset	O
of	O
10	O
M	Method
,	O
30	O
M	Method
and	O
100	O
M	Method
images	O
from	O
the	O
JFT	Method
-	O
300	O
M	Method
for	O
training	O
base	O
checkpoints	O
(	O
same	O
as	O
Section	O
[	O
reference	O
]	O
)	O
.	O

Once	O
again	O
we	O
observe	O
that	O
the	O
performance	O
increases	O
logarithmically	O
as	O
the	O
pre	Material
-	Material
training	Material
dataset	Material
increases	O
.	O

subsection	O
:	O
Human	Task
Pose	Task
Estimation	Task
We	O
train	O
the	O
fully	Method
-	Method
convolutional	Method
pose	Method
detector	Method
by	O
initializing	O
the	O
base	Method
ResNet	Method
model	Method
with	O
our	O
checkpoints	O
and	O
fine	O
-	O
tuning	O
.	O

The	O
model	O
is	O
trained	O
with	O
SGD	Method
+	Method
Momentum	Method
for	O
450	O
K	O
steps	O
.	O

The	O
learning	Metric
rate	Metric
was	O
dropped	O
by	O
a	O
factor	O
of	O
10	O
after	O
250	O
K	O
steps	O
,	O
starting	O
with	O
a	O
base	O
learning	Metric
rate	Metric
.	O

Best	O
hyper	O
parameter	O
combination	O
for	O
each	O
model	O
was	O
then	O
selected	O
independently	O
and	O
used	O
in	O
further	O
experimentation	O
.	O

In	O
Table	O
[	O
reference	O
]	O
,	O
we	O
present	O
the	O
end	O
to	O
end	Task
pose	Task
estimation	Task
results	O
evaluated	O
on	O
COCO	Material
‘	O
test	O
-	O
dev	O
’	O
set	O
.	O

G	Method
-	Method
RMI	Method
Pose	Method
uses	O
the	O
ImageNet	Material
pre	O
-	O
trained	O
checkpoint	O
for	O
fine	Task
-	Task
tuning	Task
,	O
and	O
we	O
can	O
see	O
that	O
our	O
models	O
with	O
JFT	Method
-	O
300	O
M	Method
initialization	O
perform	O
much	O
better	O
.	O

Note	O
that	O
to	O
have	O
a	O
fair	O
comparison	O
with	O
G	Method
-	Method
RMI	Method
Pose	Method
,	O
we	O
show	O
their	O
performance	O
when	O
only	O
COCO	Material
images	O
are	O
used	O
for	O
training	O
(	O
fine	Task
-	Task
tuning	Task
)	O
and	O
no	O
ensembling	Method
is	O
performed	O
.	O

We	O
use	O
the	O
person	O
detection	Task
results	O
provided	O
by	O
the	O
authors	O
and	O
apply	O
our	O
trained	O
pose	Method
detectors	Method
on	O
the	O
same	O
set	O
of	O
person	O
boxes	O
.	O

section	O
:	O
Discussions	O
Is	O
it	O
to	O
be	O
expected	O
that	O
performance	O
of	O
computer	Method
vision	Method
algorithms	Method
would	O
always	O
improve	O
with	O
more	O
and	O
more	O
data	O
?	O
In	O
our	O
personal	O
correspondences	O
with	O
several	O
researchers	O
,	O
the	O
general	O
consensus	O
seems	O
to	O
be	O
that	O
everyone	O
expects	O
some	O
gain	O
in	O
performance	O
numbers	O
if	O
the	O
dataset	O
size	O
is	O
increased	O
dramatically	O
,	O
with	O
decreasing	O
marginal	O
performance	O
as	O
the	O
dataset	O
grows	O
.	O

Yet	O
,	O
while	O
a	O
tremendous	O
amount	O
of	O
time	O
is	O
spent	O
on	O
engineering	O
and	O
parameter	O
sweeps	O
;	O
little	O
to	O
no	O
time	O
has	O
been	O
spent	O
collectively	O
on	O
data	O
.	O

Our	O
paper	O
is	O
an	O
attempt	O
to	O
put	O
the	O
focus	O
back	O
on	O
the	O
data	O
.	O

The	O
models	O
seem	O
to	O
be	O
plateauing	O
but	O
when	O
it	O
comes	O
to	O
the	O
performance	O
with	O
respect	O
to	O
data	O
–	O
but	O
modest	O
performance	O
improvements	O
are	O
still	O
possible	O
for	O
exponential	O
increases	O
of	O
the	O
data	O
.	O

Another	O
major	O
finding	O
of	O
our	O
paper	O
is	O
that	O
having	O
better	O
models	O
is	O
not	O
leading	O
to	O
substantial	O
gains	O
because	O
ImageNet	Material
is	O
no	O
more	O
sufficient	O
to	O
use	O
all	O
the	O
parameters	O
or	O
their	O
representational	O
power	O
.	O

paragraph	O
:	O
Representation	Method
learning	Method
:	O
One	O
of	O
the	O
underlying	O
debates	O
is	O
that	O
should	O
we	O
spend	O
more	O
time	O
collecting	O
data	O
for	O
individual	Task
tasks	Task
such	O
as	O
detection	Task
and	O
segmentation	Task
.	O

Our	O
findings	O
show	O
there	O
is	O
still	O
a	O
lot	O
to	O
be	O
gained	O
from	O
representation	Method
learning	Method
.	O

Improved	O
base	Method
models	Method
or	O
base	O
features	O
can	O
lead	O
to	O
significant	O
gains	O
in	O
performance	O
.	O

paragraph	O
:	O
Disclaimer	O
–	O
Large	Task
scale	Task
learning	Task
:	O
We	O
would	O
like	O
to	O
highlight	O
that	O
the	O
training	O
regime	O
,	O
learning	O
schedules	O
and	O
parameters	O
used	O
in	O
this	O
paper	O
are	O
based	O
on	O
our	O
understanding	O
of	O
training	O
ConvNets	Method
with	O
1	O
M	Method
images	O
.	O

Searching	O
the	O
right	O
set	O
of	O
hyper	O
-	O
parameters	O
requires	O
significant	O
more	O
effort	O
:	O
even	O
training	O
a	O
JFT	Method
model	O
for	O
4	O
epochs	O
needed	O
2	O
months	O
on	O
50	O
K	O
-	O
80	O
GPUs	O
.	O

Therefore	O
,	O
in	O
some	O
sense	O
the	O
quantitative	O
performance	O
reported	O
in	O
this	O
paper	O
underestimates	O
the	O
impact	O
of	O
data	O
for	O
all	O
reported	O
image	O
volumes	O
.	O

Acknowledgements	O
:	O
This	O
work	O
would	O
not	O
have	O
been	O
possible	O
without	O
the	O
heroic	O
efforts	O
of	O
Image	Method
Understanding	Method
and	O
Expander	O
teams	O
at	O
Google	O
who	O
built	O
the	O
massive	O
JFT	Method
dataset	O
.	O

We	O
would	O
specifically	O
like	O
to	O
thank	O
Tom	O
Duerig	O
,	O
Neil	O
Alldrin	O
,	O
Howard	O
Zhou	O
,	O
Lu	O
Chen	O
,	O
David	O
Cai	O
,	O
Gal	O
Chechik	O
,	O
Zheyun	O
Feng	O
,	O
Xiangxin	O
Zhu	O
and	O
Rahul	O
Sukthankar	O
for	O
their	O
help	O
.	O

Also	O
big	O
thanks	O
to	O
the	O
VALE	O
team	O
for	O
APIs	O
and	O
specifically	O
,	O
Jonathan	O
Huang	O
,	O
George	O
Papandreou	O
,	O
Liang	O
-	O
Chieh	O
Chen	O
and	O
Kevin	O
Murphy	O
for	O
helpful	O
discussions	O
.	O

bibliography	O
:	O
References	O
section	O
:	O
Appendix	O
A	O
subsubsection	O
:	O
De	O
-	O
duplication	O
Experiments	O
A	O
dataset	O
with	O
300	O
M	Method
images	O
is	O
almost	O
guaranteed	O
to	O
contain	O
images	O
that	O
overlap	O
with	O
the	O
validation	O
set	O
of	O
target	O
tasks	O
.	O

In	O
fact	O
,	O
we	O
find	O
that	O
even	O
for	O
ImageNet	Material
,	O
there	O
are	O
890	O
out	O
of	O
50	O
K	O
validation	O
images	O
have	O
near	O
-	O
duplicate	O
images	O
in	O
the	O
training	O
.	O

We	O
use	O
visual	O
embeddings	O
to	O
measure	O
similarities	O
and	O
identify	O
duplicate	Task
or	Task
near	Task
-	Task
duplicate	Task
images	Task
.	O

The	O
embeddings	O
are	O
based	O
on	O
deep	O
learning	O
features	O
.	O

We	O
find	O
there	O
are	O
5536	O
out	O
of	O
50	O
K	O
images	O
in	O
ImageNet	Material
validation	O
set	O
,	O
1648	O
out	O
of	O
8	O
K	O
images	O
in	O
COCO	Material
minival	O
∗	O
,	O
201	O
out	O
of	O
4952	O
images	O
in	O
Pascal	Material
VOC	Material
2007	Material
test	Material
set	Material
,	O
and	O
84	O
out	O
of	O
1449	O
images	O
in	O
Pascal	Material
VOC	Material
2012	Material
validation	Material
set	Material
that	O
have	O
near	O
duplicates	O
in	O
JFT	Method
-	O
300M.	O
We	O
rerun	O
several	O
experiments	O
by	O
removing	O
near	O
-	O
duplicate	O
images	O
from	O
validation	O
sets	O
and	O
then	O
comparing	O
performance	O
between	O
baselines	O
and	O
learned	O
models	O
.	O

We	O
observe	O
no	O
significant	O
differences	O
in	O
trends	O
.	O

Table	O
[	O
reference	O
]	O
,	O
[	O
reference	O
]	O
and	O
[	O
reference	O
]	O
show	O
that	O
the	O
duplicate	O
images	O
have	O
minimal	O
impact	O
on	O
performance	O
for	O
all	O
experiments	O
.	O

We	O
do	O
not	O
conduct	O
de	Task
-	Task
duplication	Task
experiments	O
of	O
COCO	Material
testdev	O
dataset	O
for	O
object	O
detection	Task
and	O
pose	Task
estimation	Task
as	O
their	O
groundtruth	O
annotations	O
are	O
not	O
publicly	O
available	O
.	O

section	O
:	O
Appendix	O
B	O
subsubsection	O
:	O
Detailed	O
and	O
Per	O
-	O
category	O
Results	O
:	O
Object	Task
Detection	Task
In	O
this	O
section	O
,	O
we	O
present	O
detailed	O
and	O
per	O
-	O
category	O
object	O
detection	Task
results	O
for	O
Table	O
2	O
(	O
Section	O
5.2	O
)	O
from	O
the	O
main	O
submission	O
,	O
evaluated	O
on	O
the	O
COCO	Material
test	O
-	O
dev	O
split	O
.	O

In	O
Table	O
[	O
reference	O
]	O
,	O
we	O
report	O
detailed	O
AP	Metric
and	O
AR	O
results	O
using	O
different	O
initializations	O
.	O

In	O
Table	O
[	O
reference	O
]	O
,	O
we	O
provide	O
per	O
-	O
category	O
AP	Metric
and	O
AP@.5	O
results	O
.	O

subsubsection	O
:	O
Per	O
-	O
category	O
Results	O
:	O
Semantic	Task
Segmentation	Task
In	O
Table	O
[	O
reference	O
]	O
,	O
we	O
report	O
quantitative	O
results	O
on	O
the	O
VOC	O
2012	O
segmentation	Task
validation	O
set	O
for	O
all	O
classes	O
(	O
refer	O
to	O
Figure	O
5	O
(	O
left	O
)	O
,	O
Section	O
5.3	O
in	O
the	O
main	O
submission	O
)	O
.	O

Results	O
are	O
reported	O
for	O
different	O
initializations	O
.	O

We	O
observe	O
more	O
than	O
7	O
point	O
improvement	O
for	O
categories	O
like	O
boat	O
and	O
horse	O
.	O

subsubsection	O
:	O
Detailed	O
Results	O
:	O
Human	Task
Pose	Task
Estimation	Task
In	O
Table	O
[	O
reference	O
]	O
,	O
we	O
present	O
all	O
AP	Metric
and	O
AR	O
results	O
for	O
the	O
performance	O
reported	O
in	O
Table	O
7	O
(	O
Section	O
5.4	O
)	O
in	O
the	O
main	O
submission	O
.	O

