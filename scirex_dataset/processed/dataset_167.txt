document	O
:	O
Deep	Method
Speech	Method
:	O
Scaling	O
up	O
end	Task
-	Task
to	Task
-	Task
end	Task
speech	Task
recognition	Task
We	O
present	O
a	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
speech	Method
recognition	Method
system	Method
developed	O
using	O
end	Method
-	Method
to	Method
-	Method
end	Method
deep	Method
learning	Method
.	O

Our	O
architecture	O
is	O
significantly	O
simpler	O
than	O
traditional	O
speech	Method
systems	Method
,	O
which	O
rely	O
on	O
laboriously	O
engineered	O
processing	Method
pipelines	Method
;	O
these	O
traditional	O
systems	O
also	O
tend	O
to	O
perform	O
poorly	O
when	O
used	O
in	O
noisy	O
environments	O
.	O

In	O
contrast	O
,	O
our	O
system	O
does	O
not	O
need	O
hand	Method
-	Method
designed	Method
components	Method
to	O
model	O
background	O
noise	O
,	O
reverberation	O
,	O
or	O
speaker	O
variation	O
,	O
but	O
instead	O
directly	O
learns	O
a	O
function	O
that	O
is	O
robust	O
to	O
such	O
effects	O
.	O

We	O
do	O
not	O
need	O
a	O
phoneme	O
dictionary	O
,	O
nor	O
even	O
the	O
concept	O
of	O
a	O
“	O
phoneme	O
.	O

”	O
Key	O
to	O
our	O
approach	O
is	O
a	O
well	O
-	O
optimized	O
RNN	Method
training	O
system	O
that	O
uses	O
multiple	O
GPUs	Method
,	O
as	O
well	O
as	O
a	O
set	O
of	O
novel	O
data	Method
synthesis	Method
techniques	Method
that	O
allow	O
us	O
to	O
efficiently	O
obtain	O
a	O
large	O
amount	O
of	O
varied	O
data	O
for	O
training	O
.	O

Our	O
system	O
,	O
called	O
Deep	Method
Speech	Method
,	O
outperforms	O
previously	O
published	O
results	O
on	O
the	O
widely	O
studied	O
Switchboard	Material
Hub5’00	Material
,	O
achieving	O
16.0	O
%	O
error	Metric
on	O
the	O
full	O
test	O
set	O
.	O

Deep	Method
Speech	Method
also	O
handles	O
challenging	O
noisy	O
environments	O
better	O
than	O
widely	O
used	O
,	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
commercial	O
speech	Method
systems	Method
.	O

section	O
:	O
Introduction	O
Top	O
speech	Method
recognition	Method
systems	Method
rely	O
on	O
sophisticated	O
pipelines	Method
composed	O
of	O
multiple	O
algorithms	O
and	O
hand	Method
-	Method
engineered	Method
processing	Method
stages	Method
.	O

In	O
this	O
paper	O
,	O
we	O
describe	O
an	O
end	Task
-	Task
to	Task
-	Task
end	Task
speech	Task
system	Task
,	O
called	O
“	O
Deep	Method
Speech	Method
”	O
,	O
where	O
deep	Method
learning	Method
supersedes	O
these	O
processing	O
stages	O
.	O

Combined	O
with	O
a	O
language	Method
model	Method
,	O
this	O
approach	O
achieves	O
higher	O
performance	O
than	O
traditional	O
methods	O
on	O
hard	Task
speech	Task
recognition	Task
tasks	Task
while	O
also	O
being	O
much	O
simpler	O
.	O

These	O
results	O
are	O
made	O
possible	O
by	O
training	O
a	O
large	O
recurrent	Method
neural	Method
network	Method
(	O
RNN	Method
)	O
using	O
multiple	O
GPUs	Method
and	O
thousands	O
of	O
hours	O
of	O
data	O
.	O

Because	O
this	O
system	O
learns	O
directly	O
from	O
data	O
,	O
we	O
do	O
not	O
require	O
specialized	Method
components	Method
for	O
speaker	Task
adaptation	Task
or	O
noise	Task
filtering	Task
.	O

In	O
fact	O
,	O
in	O
settings	O
where	O
robustness	Metric
to	O
speaker	O
variation	O
and	O
noise	O
are	O
critical	O
,	O
our	O
system	O
excels	O
:	O
Deep	Method
Speech	Method
outperforms	O
previously	O
published	O
methods	O
on	O
the	O
Switchboard	Material
Hub5’00	Material
corpus	O
,	O
achieving	O
16.0	O
%	O
error	Metric
,	O
and	O
performs	O
better	O
than	O
commercial	O
systems	O
in	O
noisy	Task
speech	Task
recognition	Task
tests	Task
.	O

Traditional	O
speech	Method
systems	Method
use	O
many	O
heavily	O
engineered	O
processing	Method
stages	Method
,	O
including	O
specialized	O
input	O
features	O
,	O
acoustic	Method
models	Method
,	O
and	O
Hidden	Method
Markov	Method
Models	Method
(	O
HMMs	Method
)	O
.	O

To	O
improve	O
these	O
pipelines	O
,	O
domain	Method
experts	Method
must	O
invest	O
a	O
great	O
deal	O
of	O
effort	O
tuning	O
their	O
features	O
and	O
models	O
.	O

The	O
introduction	O
of	O
deep	Method
learning	Method
algorithms	Method
has	O
improved	O
speech	Task
system	Task
performance	O
,	O
usually	O
by	O
improving	O
acoustic	Method
models	Method
.	O

While	O
this	O
improvement	O
has	O
been	O
significant	O
,	O
deep	Method
learning	Method
still	O
plays	O
only	O
a	O
limited	O
role	O
in	O
traditional	O
speech	Method
pipelines	Method
.	O

As	O
a	O
result	O
,	O
to	O
improve	O
performance	O
on	O
a	O
task	O
such	O
as	O
recognizing	Task
speech	Task
in	O
a	O
noisy	O
environment	O
,	O
one	O
must	O
laboriously	O
engineer	O
the	O
rest	O
of	O
the	O
system	O
for	O
robustness	Task
.	O

In	O
contrast	O
,	O
our	O
system	O
applies	O
deep	Method
learning	Method
end	Method
-	Method
to	Method
-	Method
end	Method
using	O
recurrent	Method
neural	Method
networks	Method
.	O

We	O
take	O
advantage	O
of	O
the	O
capacity	O
provided	O
by	O
deep	Method
learning	Method
systems	Method
to	O
learn	O
from	O
large	O
datasets	O
to	O
improve	O
our	O
overall	O
performance	O
.	O

Our	O
model	O
is	O
trained	O
end	O
-	O
to	O
-	O
end	O
to	O
produce	O
transcriptions	O
and	O
thus	O
,	O
with	O
sufficient	O
data	O
and	O
computing	O
power	O
,	O
can	O
learn	O
robustness	Metric
to	O
noise	O
or	O
speaker	O
variation	O
on	O
its	O
own	O
.	O

Tapping	O
the	O
benefits	O
of	O
end	Task
-	Task
to	Task
-	Task
end	Task
deep	Task
learning	Task
,	O
however	O
,	O
poses	O
several	O
challenges	O
:	O
(	O
i	O
)	O
we	O
must	O
find	O
innovative	O
ways	O
to	O
build	O
large	O
,	O
labeled	O
training	O
sets	O
and	O
(	O
ii	O
)	O
we	O
must	O
be	O
able	O
to	O
train	O
networks	O
that	O
are	O
large	O
enough	O
to	O
effectively	O
utilize	O
all	O
of	O
this	O
data	O
.	O

One	O
challenge	O
for	O
handling	O
labeled	Task
data	Task
in	O
speech	Method
systems	Method
is	O
finding	O
the	O
alignment	Task
of	O
text	O
transcripts	O
with	O
input	O
speech	O
.	O

This	O
problem	O
has	O
been	O
addressed	O
by	O
Graves	O
,	O
Fernández	O
,	O
Gomez	O
and	O
Schmidhuber	O
,	O
thus	O
enabling	O
neural	Method
networks	Method
to	O
easily	O
consume	O
unaligned	O
,	O
transcribed	O
audio	O
during	O
training	O
.	O

Meanwhile	O
,	O
rapid	Task
training	Task
of	Task
large	Task
neural	Task
networks	Task
has	O
been	O
tackled	O
by	O
Coates	O
et	O
al	O
.	O

,	O
demonstrating	O
the	O
speed	O
advantages	O
of	O
multi	Method
-	Method
GPU	Method
computation	Method
.	O

We	O
aim	O
to	O
leverage	O
these	O
insights	O
to	O
fulfill	O
the	O
vision	O
of	O
a	O
generic	Method
learning	Method
system	Method
,	O
based	O
on	O
large	O
speech	O
datasets	O
and	O
scalable	O
RNN	Method
training	O
,	O
that	O
can	O
surpass	O
more	O
complicated	O
traditional	O
methods	O
.	O

This	O
vision	O
is	O
inspired	O
partly	O
by	O
the	O
work	O
of	O
Lee	O
et	O
.	O

al	O
.	O

who	O
applied	O
early	O
unsupervised	Method
feature	Method
learning	Method
techniques	Method
to	O
replace	O
hand	O
-	O
built	O
speech	O
features	O
.	O

We	O
have	O
chosen	O
our	O
RNN	Method
model	O
specifically	O
to	O
map	O
well	O
to	O
GPUs	O
and	O
we	O
use	O
a	O
novel	O
model	Method
partition	Method
scheme	Method
to	O
improve	O
parallelization	Task
.	O

Additionally	O
,	O
we	O
propose	O
a	O
process	O
for	O
assembling	O
large	O
quantities	O
of	O
labeled	O
speech	O
data	O
exhibiting	O
the	O
distortions	O
that	O
our	O
system	O
should	O
learn	O
to	O
handle	O
.	O

Using	O
a	O
combination	O
of	O
collected	O
and	O
synthesized	O
data	O
,	O
our	O
system	O
learns	O
robustness	Metric
to	O
realistic	O
noise	O
and	O
speaker	O
variation	O
(	O
including	O
Lombard	O
Effect	O
)	O
.	O

Taken	O
together	O
,	O
these	O
ideas	O
suffice	O
to	O
build	O
an	O
end	Task
-	Task
to	Task
-	Task
end	Task
speech	Task
system	Task
that	O
is	O
at	O
once	O
simpler	O
than	O
traditional	O
pipelines	Method
yet	O
also	O
performs	O
better	O
on	O
difficult	O
speech	Task
tasks	Task
.	O

Deep	Method
Speech	Method
achieves	O
an	O
error	Metric
rate	O
of	O
16.0	O
%	O
on	O
the	O
full	O
Switchboard	Material
Hub5’00	Material
test	O
set	O
—	O
the	O
best	O
published	O
result	O
.	O

Further	O
,	O
on	O
a	O
new	O
noisy	O
speech	O
recognition	O
dataset	O
of	O
our	O
own	O
construction	O
,	O
our	O
system	O
achieves	O
a	O
word	Metric
error	Metric
rate	Metric
of	O
19.1	O
%	O
where	O
the	O
best	O
commercial	O
systems	O
achieve	O
30.5	O
%	O
error	Metric
.	O

In	O
the	O
remainder	O
of	O
this	O
paper	O
,	O
we	O
will	O
introduce	O
the	O
key	O
ideas	O
behind	O
our	O
speech	Method
recognition	Method
system	Method
.	O

We	O
begin	O
by	O
describing	O
the	O
basic	O
recurrent	Method
neural	Method
network	Method
model	Method
and	O
training	Method
framework	Method
that	O
we	O
use	O
in	O
Section	O
[	O
reference	O
]	O
,	O
followed	O
by	O
a	O
discussion	O
of	O
GPU	Task
optimizations	Task
(	O
Section	O
[	O
reference	O
]	O
)	O
,	O
and	O
our	O
data	Method
capture	Method
and	O
synthesis	Method
strategy	Method
(	O
Section	O
[	O
reference	O
]	O
)	O
.	O

We	O
conclude	O
with	O
our	O
experimental	O
results	O
demonstrating	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
performance	O
of	O
Deep	Method
Speech	Method
(	O
Section	O
[	O
reference	O
]	O
)	O
,	O
followed	O
by	O
a	O
discussion	O
of	O
related	O
work	O
and	O
our	O
conclusions	O
.	O

section	O
:	O
RNN	Method
Training	O
Setup	O
The	O
core	O
of	O
our	O
system	O
is	O
a	O
recurrent	Method
neural	Method
network	Method
(	O
RNN	Method
)	O
trained	O
to	O
ingest	O
speech	O
spectrograms	O
and	O
generate	O
English	Material
text	Material
transcriptions	Material
.	O

Let	O
a	O
single	O
utterance	O
and	O
label	O
be	O
sampled	O
from	O
a	O
training	O
set	O
.	O

Each	O
utterance	O
,	O
,	O
is	O
a	O
time	O
-	O
series	O
of	O
length	O
where	O
every	O
time	O
-	O
slice	O
is	O
a	O
vector	O
of	O
audio	O
features	O
,	O
.	O

We	O
use	O
spectrograms	O
as	O
our	O
features	O
,	O
so	O
denotes	O
the	O
power	O
of	O
the	O
’	O
th	O
frequency	O
bin	O
in	O
the	O
audio	O
frame	O
at	O
time	O
.	O

The	O
goal	O
of	O
our	O
RNN	Method
is	O
to	O
convert	O
an	O
input	O
sequence	O
into	O
a	O
sequence	O
of	O
character	O
probabilities	O
for	O
the	O
transcription	O
,	O
with	O
,	O
where	O
.	O

Our	O
RNN	Method
model	O
is	O
composed	O
of	O
5	O
layers	O
of	O
hidden	O
units	O
.	O

For	O
an	O
input	O
,	O
the	O
hidden	O
units	O
at	O
layer	O
are	O
denoted	O
with	O
the	O
convention	O
that	O
is	O
the	O
input	O
.	O

The	O
first	O
three	O
layers	O
are	O
not	O
recurrent	O
.	O

For	O
the	O
first	O
layer	O
,	O
at	O
each	O
time	O
,	O
the	O
output	O
depends	O
on	O
the	O
spectrogram	O
frame	O
along	O
with	O
a	O
context	O
of	O
frames	O
on	O
each	O
side	O
.	O

The	O
remaining	O
non	Method
-	Method
recurrent	Method
layers	Method
operate	O
on	O
independent	O
data	O
for	O
each	O
time	O
step	O
.	O

Thus	O
,	O
for	O
each	O
time	O
,	O
the	O
first	O
3	O
layers	O
are	O
computed	O
by	O
:	O
where	O
is	O
the	O
clipped	O
rectified	Method
-	Method
linear	Method
(	O
ReLu	Method
)	O
activation	O
function	O
and	O
are	O
the	O
weight	O
matrix	O
and	O
bias	O
parameters	O
for	O
layer	O
.	O

The	O
fourth	O
layer	O
is	O
a	O
bi	Method
-	Method
directional	Method
recurrent	Method
layer	Method
.	O

This	O
layer	O
includes	O
two	O
sets	O
of	O
hidden	O
units	O
:	O
a	O
set	O
with	O
forward	Method
recurrence	Method
,	O
,	O
and	O
a	O
set	O
with	O
backward	O
recurrence	O
:	O
Note	O
that	O
must	O
be	O
computed	O
sequentially	O
from	O
to	O
for	O
the	O
’	O
th	O
utterance	O
,	O
while	O
the	O
units	O
must	O
be	O
computed	O
sequentially	O
in	O
reverse	O
from	O
to	O
.	O

The	O
fifth	O
(	O
non	Method
-	Method
recurrent	Method
)	Method
layer	Method
takes	O
both	O
the	O
forward	O
and	O
backward	O
units	O
as	O
inputs	O
where	O
.	O

The	O
output	Method
layer	Method
is	O
a	O
standard	O
softmax	Method
function	Method
that	O
yields	O
the	O
predicted	O
character	O
probabilities	O
for	O
each	O
time	O
slice	O
and	O
character	O
in	O
the	O
alphabet	O
:	O
Here	O
and	O
denote	O
the	O
’	O
th	O
column	O
of	O
the	O
weight	O
matrix	O
and	O
’	O
th	O
bias	O
,	O
respectively	O
.	O

Once	O
we	O
have	O
computed	O
a	O
prediction	O
for	O
,	O
we	O
compute	O
the	O
CTC	Method
loss	O
to	O
measure	O
the	O
error	Metric
in	O
prediction	O
.	O

During	O
training	Task
,	O
we	O
can	O
evaluate	O
the	O
gradient	O
with	O
respect	O
to	O
the	O
network	O
outputs	O
given	O
the	O
ground	O
-	O
truth	O
character	O
sequence	O
.	O

From	O
this	O
point	O
,	O
computing	O
the	O
gradient	O
with	O
respect	O
to	O
all	O
of	O
the	O
model	O
parameters	O
may	O
be	O
done	O
via	O
back	Method
-	Method
propagation	Method
through	O
the	O
rest	O
of	O
the	O
network	O
.	O

We	O
use	O
Nesterov	Method
’s	Method
Accelerated	Method
gradient	Method
method	Method
for	O
training	Task
.	O

The	O
complete	O
RNN	Method
model	O
is	O
illustrated	O
in	O
Figure	O
[	O
reference	O
]	O
.	O

Note	O
that	O
its	O
structure	O
is	O
considerably	O
simpler	O
than	O
related	O
models	O
from	O
the	O
literature	O
—we	O
have	O
limited	O
ourselves	O
to	O
a	O
single	O
recurrent	Method
layer	Method
(	O
which	O
is	O
the	O
hardest	O
to	O
parallelize	O
)	O
and	O
we	O
do	O
not	O
use	O
Long	Method
-	Method
Short	Method
-	Method
Term	Method
-	Method
Memory	Method
(	O
LSTM	Method
)	O
circuits	O
.	O

One	O
disadvantage	O
of	O
LSTM	Method
cells	O
is	O
that	O
they	O
require	O
computing	O
and	O
storing	O
multiple	O
gating	O
neuron	O
responses	O
at	O
each	O
step	O
.	O

Since	O
the	O
forward	Method
and	Method
backward	Method
recurrences	Method
are	O
sequential	O
,	O
this	O
small	O
additional	O
cost	O
can	O
become	O
a	O
computational	Metric
bottleneck	Metric
.	O

By	O
using	O
a	O
homogeneous	Method
model	Method
we	O
have	O
made	O
the	O
computation	O
of	O
the	O
recurrent	O
activations	O
as	O
efficient	O
as	O
possible	O
:	O
computing	O
the	O
ReLu	Method
outputs	O
involves	O
only	O
a	O
few	O
highly	O
optimized	O
BLAS	Method
operations	O
on	O
the	O
GPU	O
and	O
a	O
single	O
point	O
-	O
wise	O
nonlinearity	O
.	O

subsection	O
:	O
Regularization	Task
While	O
we	O
have	O
gone	O
to	O
significant	O
lengths	O
to	O
expand	O
our	O
datasets	O
(	O
c.f	O
.	O

Section	O
[	O
reference	O
]	O
)	O
,	O
the	O
recurrent	Method
networks	Method
we	O
use	O
are	O
still	O
adept	O
at	O
fitting	O
the	O
training	O
data	O
.	O

In	O
order	O
to	O
reduce	O
variance	O
further	O
,	O
we	O
use	O
several	O
techniques	O
.	O

During	O
training	Task
we	O
apply	O
a	O
dropout	Metric
rate	Metric
between	O
5	O
%	O
-	O
10	O
%	O
.	O

We	O
apply	O
dropout	Method
in	O
the	O
feed	Method
-	Method
forward	Method
layers	Method
but	O
not	O
to	O
the	O
recurrent	O
hidden	O
activations	O
.	O

A	O
commonly	O
employed	O
technique	O
in	O
computer	Task
vision	Task
during	O
network	Task
evaluation	Task
is	O
to	O
randomly	O
jitter	O
inputs	O
by	O
translations	O
or	O
reflections	O
,	O
feed	O
each	O
jittered	O
version	O
through	O
the	O
network	O
,	O
and	O
vote	O
or	O
average	O
the	O
results	O
.	O

Such	O
jittering	O
is	O
not	O
common	O
in	O
ASR	Task
,	O
however	O
we	O
found	O
it	O
beneficial	O
to	O
translate	O
the	O
raw	O
audio	O
files	O
by	O
5ms	O
(	O
half	O
the	O
filter	O
bank	O
step	O
size	O
)	O
to	O
the	O
left	O
and	O
right	O
,	O
then	O
forward	O
propagate	O
the	O
recomputed	O
features	O
and	O
average	O
the	O
output	O
probabilities	O
.	O

At	O
test	O
time	O
we	O
also	O
use	O
an	O
ensemble	O
of	O
several	O
RNNs	Method
,	O
averaging	O
their	O
outputs	O
in	O
the	O
same	O
way	O
.	O

subsection	O
:	O
Language	Method
Model	Method
When	O
trained	O
from	O
large	O
quantities	O
of	O
labeled	O
speech	O
data	O
,	O
the	O
RNN	Method
model	O
can	O
learn	O
to	O
produce	O
readable	O
character	O
-	O
level	O
transcriptions	O
.	O

Indeed	O
for	O
many	O
of	O
the	O
transcriptions	O
,	O
the	O
most	O
likely	O
character	O
sequence	O
predicted	O
by	O
the	O
RNN	Method
is	O
exactly	O
correct	O
without	O
external	O
language	O
constraints	O
.	O

The	O
errors	O
made	O
by	O
the	O
RNN	Method
in	O
this	O
case	O
tend	O
to	O
be	O
phonetically	O
plausible	O
renderings	O
of	O
English	O
words	O
—	O
Table	O
[	O
reference	O
]	O
shows	O
some	O
examples	O
.	O

Many	O
of	O
the	O
errors	O
occur	O
on	O
words	O
that	O
rarely	O
or	O
never	O
appear	O
in	O
our	O
training	O
set	O
.	O

In	O
practice	O
,	O
this	O
is	O
hard	O
to	O
avoid	O
:	O
training	O
from	O
enough	O
speech	O
data	O
to	O
hear	O
all	O
of	O
the	O
words	O
or	O
language	O
constructions	O
we	O
might	O
need	O
to	O
know	O
is	O
impractical	O
.	O

Therefore	O
,	O
we	O
integrate	O
our	O
system	O
with	O
an	O
N	Method
-	Method
gram	Method
language	Method
model	Method
since	O
these	O
models	O
are	O
easily	O
trained	O
from	O
huge	O
unlabeled	O
text	O
corpora	O
.	O

For	O
comparison	O
,	O
while	O
our	O
speech	O
datasets	O
typically	O
include	O
up	O
to	O
3	O
million	O
utterances	O
,	O
the	O
N	Method
-	Method
gram	Method
language	Method
model	Method
used	O
for	O
the	O
experiments	O
in	O
Section	O
[	O
reference	O
]	O
is	O
trained	O
from	O
a	O
corpus	O
of	O
220	O
million	O
phrases	O
,	O
supporting	O
a	O
vocabulary	O
of	O
495	O
,	O
000	O
words	O
.	O

Given	O
the	O
output	O
of	O
our	O
RNN	Method
we	O
perform	O
a	O
search	O
to	O
find	O
the	O
sequence	O
of	O
characters	O
that	O
is	O
most	O
probable	O
according	O
to	O
both	O
the	O
RNN	Method
output	O
and	O
the	O
language	Method
model	Method
(	O
where	O
the	O
language	Method
model	Method
interprets	O
the	O
string	O
of	O
characters	O
as	O
words	O
)	O
.	O

Specifically	O
,	O
we	O
aim	O
to	O
find	O
a	O
sequence	O
that	O
maximizes	O
the	O
combined	O
objective	O
:	O
where	O
and	O
are	O
tunable	O
parameters	O
(	O
set	O
by	O
cross	Metric
-	Metric
validation	Metric
)	O
that	O
control	O
the	O
trade	O
-	O
off	O
between	O
the	O
RNN	Method
,	O
the	O
language	O
model	O
constraint	O
and	O
the	O
length	O
of	O
the	O
sentence	O
.	O

The	O
term	O
denotes	O
the	O
probability	O
of	O
the	O
sequence	O
according	O
to	O
the	O
N	Method
-	Method
gram	Method
model	Method
.	O

We	O
maximize	O
this	O
objective	O
using	O
a	O
highly	O
optimized	O
beam	Method
search	Method
algorithm	Method
,	O
with	O
a	O
typical	O
beam	O
size	O
in	O
the	O
range	O
1000	O
-	O
8000—similar	O
to	O
the	O
approach	O
described	O
by	O
Hannun	O
et	O
al	O
.	O

.	O

section	O
:	O
Optimizations	O
As	O
noted	O
above	O
,	O
we	O
have	O
made	O
several	O
design	O
decisions	O
to	O
make	O
our	O
networks	O
amenable	O
to	O
high	Task
-	Task
speed	Task
execution	Task
(	O
and	O
thus	O
fast	Task
training	Task
)	O
.	O

For	O
example	O
,	O
we	O
have	O
opted	O
for	O
homogeneous	Method
rectified	Method
-	Method
linear	Method
networks	Method
that	O
are	O
simple	O
to	O
implement	O
and	O
depend	O
on	O
just	O
a	O
few	O
highly	O
-	O
optimized	O
BLAS	Method
calls	O
.	O

When	O
fully	O
unrolled	O
,	O
our	O
networks	O
include	O
almost	O
5	O
billion	O
connections	O
for	O
a	O
typical	O
utterance	O
and	O
thus	O
efficient	O
computation	O
is	O
critical	O
to	O
make	O
our	O
experiments	O
feasible	O
.	O

We	O
use	O
multi	Method
-	Method
GPU	Method
training	Method
to	O
accelerate	O
our	O
experiments	O
,	O
but	O
doing	O
this	O
effectively	O
requires	O
some	O
additional	O
work	O
,	O
as	O
we	O
explain	O
.	O

subsection	O
:	O
Data	Task
parallelism	Task
In	O
order	O
to	O
process	O
data	O
efficiently	O
,	O
we	O
use	O
two	O
levels	O
of	O
data	O
parallelism	O
.	O

First	O
,	O
each	O
GPU	Method
processes	O
many	O
examples	O
in	O
parallel	O
.	O

This	O
is	O
done	O
in	O
the	O
usual	O
way	O
by	O
concatenating	O
many	O
examples	O
into	O
a	O
single	O
matrix	O
.	O

For	O
instance	O
,	O
rather	O
than	O
performing	O
a	O
single	O
matrix	Method
-	Method
vector	Method
multiplication	Method
in	O
the	O
recurrent	Method
layer	Method
,	O
we	O
prefer	O
to	O
do	O
many	O
in	O
parallel	O
by	O
computing	O
where	O
(	O
where	O
corresponds	O
to	O
the	O
’	O
th	O
example	O
at	O
time	O
)	O
.	O

The	O
GPU	Method
is	O
most	O
efficient	O
when	O
is	O
relatively	O
wide	O
(	O
e.g.	O
,	O
1000	O
examples	O
or	O
more	O
)	O
and	O
thus	O
we	O
prefer	O
to	O
process	O
as	O
many	O
examples	O
on	O
one	O
GPU	O
as	O
possible	O
(	O
up	O
to	O
the	O
limit	O
of	O
GPU	O
memory	O
)	O
.	O

When	O
we	O
wish	O
to	O
use	O
larger	O
minibatches	O
than	O
a	O
single	O
GPU	Method
can	O
support	O
on	O
its	O
own	O
we	O
use	O
data	O
parallelism	O
across	O
multiple	O
GPUs	Method
,	O
with	O
each	O
GPU	Method
processing	O
a	O
separate	O
minibatch	O
of	O
examples	O
and	O
then	O
combining	O
its	O
computed	O
gradient	O
with	O
its	O
peers	O
during	O
each	O
iteration	O
.	O

We	O
typically	O
use	O
or	O
data	O
parallelism	O
across	O
GPUs	O
.	O

Data	Task
parallelism	Task
is	O
not	O
easily	O
implemented	O
,	O
however	O
,	O
when	O
utterances	O
have	O
different	O
lengths	O
since	O
they	O
can	O
not	O
be	O
combined	O
into	O
a	O
single	O
matrix	Method
multiplication	Method
.	O

We	O
resolve	O
the	O
problem	O
by	O
sorting	O
our	O
training	O
examples	O
by	O
length	O
and	O
combining	O
only	O
similarly	O
-	O
sized	O
utterances	O
into	O
minibatches	O
,	O
padding	O
with	O
silence	O
when	O
necessary	O
so	O
that	O
all	O
utterances	O
in	O
a	O
batch	O
have	O
the	O
same	O
length	O
.	O

This	O
solution	O
is	O
inspired	O
by	O
the	O
ITPACK	Method
/	Method
ELLPACK	Method
sparse	Method
matrix	Method
format	Method
;	O
a	O
similar	O
solution	O
was	O
used	O
by	O
the	O
Sutskever	O
et	O
al	O
.	O

to	O
accelerate	O
RNNs	Method
for	O
text	O
.	O

subsection	O
:	O
Model	Method
parallelism	Method
Data	O
parallelism	O
yields	O
training	Task
speedups	O
for	O
modest	O
multiples	O
of	O
the	O
minibatch	O
size	O
(	O
e.g.	O
,	O
2	O
to	O
4	O
)	O
,	O
but	O
faces	O
diminishing	O
returns	O
as	O
batching	O
more	O
examples	O
into	O
a	O
single	O
gradient	Method
update	Method
fails	O
to	O
improve	O
the	O
training	Metric
convergence	Metric
rate	Metric
.	O

That	O
is	O
,	O
processing	O
as	O
many	O
examples	O
on	O
as	O
many	O
GPUs	Method
fails	O
to	O
yield	O
a	O
speedup	O
in	O
training	Task
.	O

It	O
is	O
also	O
inefficient	O
to	O
fix	O
the	O
total	O
minibatch	O
size	O
but	O
spread	O
out	O
the	O
examples	O
to	O
as	O
many	O
GPUs	O
:	O
as	O
the	O
minibatch	O
within	O
each	O
GPU	O
shrinks	O
,	O
most	O
operations	O
become	O
memory	O
-	O
bandwidth	O
limited	O
.	O

To	O
scale	O
further	O
,	O
we	O
parallelize	O
by	O
partitioning	O
the	O
model	O
(	O
“	O
model	O
parallelism	O
”	O
)	O
.	O

Our	O
model	O
is	O
challenging	O
to	O
parallelize	O
due	O
to	O
the	O
sequential	O
nature	O
of	O
the	O
recurrent	O
layers	O
.	O

Since	O
the	O
bidirectional	Method
layer	Method
is	O
comprised	O
of	O
a	O
forward	Method
computation	Method
and	O
a	O
backward	Method
computation	Method
that	O
are	O
independent	O
,	O
we	O
can	O
perform	O
the	O
two	O
computations	O
in	O
parallel	O
.	O

Unfortunately	O
,	O
naively	O
splitting	O
the	O
RNN	Method
to	O
place	O
and	O
on	O
separate	O
GPUs	O
commits	O
us	O
to	O
significant	O
data	O
transfers	O
when	O
we	O
go	O
to	O
compute	O
(	O
which	O
depends	O
on	O
both	O
and	O
)	O
.	O

Thus	O
,	O
we	O
have	O
chosen	O
a	O
different	O
partitioning	O
of	O
work	O
that	O
requires	O
less	O
communication	O
for	O
our	O
models	O
:	O
we	O
divide	O
the	O
model	O
in	O
half	O
along	O
the	O
time	O
dimension	O
.	O

All	O
layers	O
except	O
the	O
recurrent	Method
layer	Method
can	O
be	O
trivially	O
decomposed	O
along	O
the	O
time	O
dimension	O
,	O
with	O
the	O
first	O
half	O
of	O
the	O
time	O
-	O
series	O
,	O
from	O
to	O
,	O
assigned	O
to	O
one	O
GPU	O
and	O
the	O
second	O
half	O
to	O
another	O
GPU	O
.	O

When	O
computing	O
the	O
recurrent	O
layer	O
activations	O
,	O
the	O
first	O
GPU	Method
begins	O
computing	O
the	O
forward	O
activations	O
,	O
while	O
the	O
second	O
begins	O
computing	O
the	O
backward	O
activations	O
.	O

At	O
the	O
mid	O
-	O
point	O
(	O
)	O
,	O
the	O
two	O
GPUs	O
exchange	O
the	O
intermediate	O
activations	O
,	O
and	O
and	O
swap	O
roles	O
.	O

The	O
first	O
GPU	O
then	O
finishes	O
the	O
backward	Task
computation	Task
of	O
and	O
the	O
second	O
GPU	Method
finishes	O
the	O
forward	Task
computation	Task
of	O
.	O

subsection	O
:	O
Striding	O
We	O
have	O
worked	O
to	O
minimize	O
the	O
running	Metric
time	Metric
of	O
the	O
recurrent	Method
layers	Method
of	O
our	O
RNN	Method
,	O
since	O
these	O
are	O
the	O
hardest	O
to	O
parallelize	O
.	O

As	O
a	O
final	O
optimization	Task
,	O
we	O
shorten	O
the	O
recurrent	Method
layers	Method
by	O
taking	O
“	O
steps	O
”	O
(	O
or	O
strides	O
)	O
of	O
size	O
2	O
in	O
the	O
original	O
input	O
so	O
that	O
the	O
unrolled	O
RNN	Method
has	O
half	O
as	O
many	O
steps	O
.	O

This	O
is	O
similar	O
to	O
a	O
convolutional	Method
network	Method
with	O
a	O
step	O
-	O
size	O
of	O
2	O
in	O
the	O
first	O
layer	O
.	O

We	O
use	O
the	O
cuDNN	Method
library	Method
to	O
implement	O
this	O
first	O
layer	O
of	O
convolution	Method
efficiently	O
.	O

section	O
:	O
Training	O
Data	O
Large	Task
-	Task
scale	Task
deep	Task
learning	Task
systems	Task
require	O
an	O
abundance	O
of	O
labeled	O
data	O
.	O

For	O
our	O
system	O
we	O
need	O
many	O
recorded	O
utterances	O
and	O
corresponding	O
English	Material
transcriptions	Material
,	O
but	O
there	O
are	O
few	O
public	O
datasets	O
of	O
sufficient	O
scale	O
.	O

To	O
train	O
our	O
largest	O
models	O
we	O
have	O
thus	O
collected	O
an	O
extensive	O
dataset	O
consisting	O
of	O
5000	O
hours	O
of	O
read	O
speech	O
from	O
9600	O
speakers	O
.	O

For	O
comparison	O
,	O
we	O
have	O
summarized	O
the	O
labeled	O
datasets	O
available	O
to	O
us	O
in	O
Table	O
[	O
reference	O
]	O
.	O

subsection	O
:	O
Synthesis	Task
by	O
superposition	O
To	O
expand	O
our	O
potential	O
training	O
data	O
even	O
further	O
we	O
use	O
data	Method
synthesis	Method
,	O
which	O
has	O
been	O
successfully	O
applied	O
in	O
other	O
contexts	O
to	O
amplify	O
the	O
effective	O
number	O
of	O
training	O
samples	O
.	O

In	O
our	O
work	O
,	O
the	O
goal	O
is	O
primarily	O
to	O
improve	O
performance	O
in	O
noisy	O
environments	O
where	O
existing	O
systems	O
break	O
down	O
.	O

Capturing	O
labeled	O
data	O
(	O
e.g.	O
,	O
read	O
speech	O
)	O
from	O
noisy	O
environments	O
is	O
not	O
practical	O
,	O
however	O
,	O
and	O
thus	O
we	O
must	O
find	O
other	O
ways	O
to	O
generate	O
such	O
data	O
.	O

To	O
a	O
first	O
order	O
,	O
audio	O
signals	O
are	O
generated	O
through	O
a	O
process	O
of	O
superposition	Method
of	Method
source	Method
signals	Method
.	O

We	O
can	O
use	O
this	O
fact	O
to	O
synthesize	O
noisy	O
training	O
data	O
.	O

For	O
example	O
,	O
if	O
we	O
have	O
a	O
speech	O
audio	O
track	O
and	O
a	O
“	O
noise	O
”	O
audio	O
track	O
,	O
then	O
we	O
can	O
form	O
the	O
“	O
noisy	O
speech	O
”	O
track	O
to	O
simulate	O
audio	O
captured	O
in	O
a	O
noisy	O
environment	O
.	O

If	O
necessary	O
,	O
we	O
can	O
add	O
reverberations	O
,	O
echoes	O
or	O
other	O
forms	O
of	O
damping	O
to	O
the	O
power	O
spectrum	O
of	O
or	O
and	O
then	O
simply	O
add	O
them	O
together	O
to	O
make	O
fairly	O
realistic	O
audio	O
scenes	O
.	O

There	O
are	O
,	O
however	O
,	O
some	O
risks	O
in	O
this	O
approach	O
.	O

For	O
example	O
,	O
in	O
order	O
to	O
take	O
1000	O
hours	O
of	O
clean	O
speech	O
and	O
create	O
1000	O
hours	O
of	O
noisy	O
speech	O
,	O
we	O
will	O
need	O
unique	O
noise	O
tracks	O
spanning	O
roughly	O
1000	O
hours	O
.	O

We	O
can	O
not	O
settle	O
for	O
,	O
say	O
,	O
10	O
hours	O
of	O
repeating	O
noise	O
,	O
since	O
it	O
may	O
become	O
possible	O
for	O
the	O
recurrent	Method
network	Method
to	O
memorize	O
the	O
noise	O
track	O
and	O
“	O
subtract	O
”	O
it	O
out	O
of	O
the	O
synthesized	O
data	O
.	O

Thus	O
,	O
instead	O
of	O
using	O
a	O
single	O
noise	Method
source	Method
with	O
a	O
length	O
of	O
1000	O
hours	O
,	O
we	O
use	O
a	O
large	O
number	O
of	O
shorter	O
clips	O
(	O
which	O
are	O
easier	O
to	O
collect	O
from	O
public	O
video	O
sources	O
)	O
and	O
treat	O
them	O
as	O
separate	O
sources	O
of	O
noise	O
before	O
superimposing	O
all	O
of	O
them	O
:	O
.	O

When	O
superimposing	O
many	O
signals	O
collected	O
from	O
video	O
clips	O
,	O
we	O
can	O
end	O
up	O
with	O
“	O
noise	O
”	O
sounds	O
that	O
are	O
different	O
from	O
the	O
kinds	O
of	O
noise	O
recorded	O
in	O
real	O
environments	O
.	O

To	O
ensure	O
a	O
good	O
match	O
between	O
our	O
synthetic	O
data	O
and	O
real	O
data	O
,	O
we	O
rejected	O
any	O
candidate	O
noise	O
clips	O
where	O
the	O
average	O
power	O
in	O
each	O
frequency	O
band	O
differed	O
significantly	O
from	O
the	O
average	O
power	O
observed	O
in	O
real	O
noisy	O
recordings	O
.	O

subsection	O
:	O
Capturing	Task
Lombard	Task
Effect	Task
One	O
challenging	O
effect	O
encountered	O
by	O
speech	Method
recognition	Method
systems	Method
in	O
noisy	O
environments	O
is	O
the	O
“	O
Lombard	O
Effect	O
”	O
:	O
speakers	O
actively	O
change	O
the	O
pitch	O
or	O
inflections	O
of	O
their	O
voice	O
to	O
overcome	O
noise	O
around	O
them	O
.	O

This	O
(	O
involuntary	O
)	O
effect	O
does	O
not	O
show	O
up	O
in	O
recorded	O
speech	O
datasets	O
since	O
they	O
are	O
collected	O
in	O
quiet	O
environments	O
.	O

To	O
ensure	O
that	O
the	O
effect	O
is	O
represented	O
in	O
our	O
training	O
data	O
we	O
induce	O
the	O
Lombard	O
effect	O
intentionally	O
during	O
data	Method
collection	Method
by	O
playing	O
loud	O
background	O
noise	O
through	O
headphones	O
worn	O
by	O
a	O
person	O
as	O
they	O
record	O
an	O
utterance	O
.	O

The	O
noise	O
induces	O
them	O
to	O
inflect	O
their	O
voice	O
,	O
thus	O
allowing	O
us	O
to	O
capture	O
the	O
Lombard	O
effect	O
in	O
our	O
training	O
data	O
.	O

section	O
:	O
Experiments	O
We	O
performed	O
two	O
sets	O
of	O
experiments	O
to	O
evaluate	O
our	O
system	O
.	O

In	O
both	O
cases	O
we	O
use	O
the	O
model	O
described	O
in	O
Section	O
[	O
reference	O
]	O
trained	O
from	O
a	O
selection	O
of	O
the	O
datasets	O
in	O
Table	O
[	O
reference	O
]	O
to	O
predict	O
character	Task
-	Task
level	Task
transcriptions	Task
.	O

The	O
predicted	O
probability	O
vectors	O
and	O
language	Method
model	Method
are	O
then	O
fed	O
into	O
our	O
decoder	Method
to	O
yield	O
a	O
word	Task
-	Task
level	Task
transcription	Task
,	O
which	O
is	O
compared	O
with	O
the	O
ground	Metric
truth	Metric
transcription	Metric
to	O
yield	O
the	O
word	Metric
error	Metric
rate	Metric
(	O
WER	Metric
)	O
.	O

subsection	O
:	O
Conversational	O
speech	O
:	O
Switchboard	Material
Hub5’00	Material
(	Material
full	Material
)	Material
To	O
compare	O
our	O
system	O
to	O
prior	O
research	O
we	O
use	O
an	O
accepted	O
but	O
highly	O
challenging	O
test	O
set	O
,	O
Hub5’00	Material
(	O
LDC2002S23	Material
)	O
.	O

Some	O
researchers	O
split	O
this	O
set	O
into	O
“	O
easy	O
”	O
(	O
Switchboard	Material
)	O
and	O
“	O
hard	O
”	O
(	O
CallHome	O
)	O
instances	O
,	O
often	O
reporting	O
new	O
results	O
on	O
the	O
easier	O
portion	O
alone	O
.	O

We	O
use	O
the	O
full	O
set	O
,	O
which	O
is	O
the	O
most	O
challenging	O
case	O
and	O
report	O
the	O
overall	O
word	Metric
error	Metric
rate	Metric
.	O

We	O
evaluate	O
our	O
system	O
trained	O
on	O
only	O
the	O
300	O
hour	O
Switchboard	Material
conversational	O
telephone	O
speech	O
dataset	O
and	O
trained	O
on	O
both	O
Switchboard	Material
(	O
SWB	Material
)	O
and	O
Fisher	Material
(	O
FSH	Material
)	O
,	O
a	O
2000	O
hour	O
corpus	O
collected	O
in	O
a	O
similar	O
manner	O
as	O
Switchboard	Material
.	O

Many	O
researchers	O
evaluate	O
models	O
trained	O
only	O
with	O
300	O
hours	O
from	O
Switchboard	Material
conversational	O
telephone	O
speech	O
when	O
testing	O
on	O
Hub5’00	Material
.	O

In	O
part	O
this	O
is	O
because	O
training	O
on	O
the	O
full	O
2000	O
hour	O
Fisher	Material
corpus	O
is	O
computationally	O
difficult	O
.	O

Using	O
the	O
techniques	O
mentioned	O
in	O
Section	O
[	O
reference	O
]	O
our	O
system	O
is	O
able	O
perform	O
a	O
full	O
pass	O
over	O
the	O
2300	O
hours	O
of	O
data	O
in	O
just	O
a	O
few	O
hours	O
.	O

Since	O
the	O
Switchboard	Material
and	O
Fisher	Material
corpora	Material
are	O
distributed	O
at	O
a	O
sample	O
rate	O
of	O
8kHz	O
,	O
we	O
compute	O
spectrograms	Method
of	O
80	O
linearly	Method
spaced	Method
log	Method
filter	Method
banks	Method
and	O
an	O
energy	Method
term	Method
.	O

The	O
filter	Method
banks	Method
are	O
computed	O
over	O
windows	O
of	O
20ms	O
strided	O
by	O
10ms	O
.	O

We	O
did	O
not	O
evaluate	O
more	O
sophisticated	O
features	O
such	O
as	O
the	O
mel	Method
-	Method
scale	Method
log	Method
filter	Method
banks	Method
or	O
the	O
mel	Method
-	Method
frequency	Method
cepstral	Method
coefficients	Method
.	O

Speaker	Task
adaptation	Task
is	O
critical	O
to	O
the	O
success	O
of	O
current	O
ASR	Method
systems	Method
,	O
particularly	O
when	O
trained	O
on	O
300	O
hour	O
Switchboard	Material
.	O

For	O
the	O
models	O
we	O
test	O
on	O
Hub5’00	Material
,	O
we	O
apply	O
a	O
simple	O
form	O
of	O
speaker	Method
adaptation	Method
by	O
normalizing	O
the	O
spectral	O
features	O
on	O
a	O
per	O
speaker	O
basis	O
.	O

Other	O
than	O
this	O
,	O
we	O
do	O
not	O
modify	O
the	O
input	O
features	O
in	O
any	O
way	O
.	O

For	O
decoding	Task
,	O
we	O
use	O
a	O
4	Method
-	Method
gram	Method
language	Method
model	Method
with	O
a	O
30	O
,	O
000	O
word	O
vocabulary	O
trained	O
on	O
the	O
Fisher	Material
and	O
Switchboard	Material
transcriptions	O
.	O

Again	O
,	O
hyperparameters	O
for	O
the	O
decoding	Metric
objective	Metric
are	O
chosen	O
via	O
cross	Method
-	Method
validation	Method
on	O
a	O
held	O
-	O
out	O
development	O
set	O
.	O

The	O
Deep	Method
Speech	Method
SWB	O
model	O
is	O
a	O
network	O
of	O
5	O
hidden	Method
layers	Method
each	O
with	O
2048	O
neurons	O
trained	O
on	O
only	O
300	O
hour	O
switchboard	O
.	O

The	O
Deep	Method
Speech	Method
SWB	O
+	O
FSH	Material
model	O
is	O
an	O
ensemble	O
of	O
4	O
RNNs	Method
each	O
with	O
5	O
hidden	Method
layers	Method
of	O
2304	O
neurons	O
trained	O
on	O
the	O
full	O
2300	O
hour	O
combined	O
corpus	O
.	O

All	O
networks	O
are	O
trained	O
on	O
inputs	O
of	O
+	O
/-	O
9	O
frames	O
of	O
context	O
.	O

We	O
report	O
results	O
in	O
Table	O
[	O
reference	O
]	O
.	O

The	O
model	O
from	O
Vesely	O
et	O
al	O
.	O

(	O
DNN	Method
-	O
GMM	O
sMBR	O
)	O
uses	O
a	O
sequence	Method
based	Method
loss	Method
function	Method
on	O
top	O
of	O
a	O
DNN	Method
after	O
using	O
a	O
typical	O
hybrid	O
DNN	Method
-	O
HMM	O
system	O
to	O
realign	O
the	O
training	O
set	O
.	O

The	O
performance	O
of	O
this	O
model	O
on	O
the	O
combined	O
Hub5’00	Material
test	Material
set	Material
is	O
the	O
best	O
previously	O
published	O
result	O
.	O

When	O
trained	O
on	O
the	O
combined	O
2300	O
hours	O
of	O
data	O
the	O
Deep	Method
Speech	Method
system	O
improves	O
upon	O
this	O
baseline	O
by	O
2.4	O
%	O
absolute	Metric
WER	Metric
and	O
13.0	O
%	O
relative	O
.	O

The	O
model	O
from	O
Maas	O
et	O
al	O
.	O

(	O
DNN	Method
-	Method
HMM	Method
FSH	Method
)	O
achieves	O
19.9	O
%	O
WER	Metric
when	O
trained	O
on	O
the	O
Fisher	Material
2000	O
hour	O
corpus	O
.	O

That	O
system	O
was	O
built	O
using	O
Kaldi	Method
,	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
open	Method
source	Method
speech	Method
recognition	Method
software	Method
.	O

We	O
include	O
this	O
result	O
to	O
demonstrate	O
that	O
Deep	Method
Speech	Method
,	O
when	O
trained	O
on	O
a	O
comparable	O
amount	O
of	O
data	O
is	O
competitive	O
with	O
the	O
best	O
existing	O
ASR	Method
systems	Method
.	O

subsection	O
:	O
Noisy	O
speech	O
Few	O
standards	O
exist	O
for	O
testing	O
noisy	O
speech	O
performance	O
,	O
so	O
we	O
constructed	O
our	O
own	O
evaluation	O
set	O
of	O
100	O
noisy	O
and	O
100	O
noise	O
-	O
free	O
utterances	O
from	O
10	O
speakers	O
.	O

The	O
noise	O
environments	O
included	O
a	O
background	O
radio	O
or	O
TV	O
;	O
washing	O
dishes	O
in	O
a	O
sink	O
;	O
a	O
crowded	O
cafeteria	O
;	O
a	O
restaurant	O
;	O
and	O
inside	O
a	O
car	O
driving	O
in	O
the	O
rain	O
.	O

The	O
utterance	O
text	O
came	O
primarily	O
from	O
web	O
search	O
queries	O
and	O
text	O
messages	O
,	O
as	O
well	O
as	O
news	O
clippings	O
,	O
phone	O
conversations	O
,	O
Internet	O
comments	O
,	O
public	O
speeches	O
,	O
and	O
movie	O
scripts	O
.	O

We	O
did	O
not	O
have	O
precise	O
control	O
over	O
the	O
signal	Metric
-	Metric
to	Metric
-	Metric
noise	Metric
ratio	Metric
(	O
SNR	Metric
)	O
of	O
the	O
noisy	O
samples	O
,	O
but	O
we	O
aimed	O
for	O
an	O
SNR	Metric
between	O
2	O
and	O
6	O
dB.	O
For	O
the	O
following	O
experiments	O
,	O
we	O
train	O
our	O
RNNs	Method
on	O
all	O
the	O
datasets	O
(	O
more	O
than	O
7000	O
hours	O
)	O
listed	O
in	O
Table	O
[	O
reference	O
]	O
.	O

Since	O
we	O
train	O
for	O
15	O
to	O
20	O
epochs	O
with	O
newly	O
synthesized	O
noise	O
in	O
each	O
pass	O
,	O
our	O
model	O
learns	O
from	O
over	O
100	O
,	O
000	O
hours	O
of	O
novel	O
data	O
.	O

We	O
use	O
an	O
ensemble	O
of	O
6	O
networks	O
each	O
with	O
5	O
hidden	O
layers	O
of	O
2560	O
neurons	O
.	O

No	O
form	O
of	O
speaker	Method
adaptation	Method
is	O
applied	O
to	O
the	O
training	O
or	O
evaluation	O
sets	O
.	O

We	O
normalize	O
training	O
examples	O
on	O
a	O
per	O
utterance	O
basis	O
in	O
order	O
to	O
make	O
the	O
total	O
power	O
of	O
each	O
example	O
consistent	O
.	O

The	O
features	O
are	O
160	O
linearly	Method
spaced	Method
log	Method
filter	Method
banks	Method
computed	O
over	O
windows	O
of	O
20ms	O
strided	O
by	O
10ms	O
and	O
an	O
energy	Method
term	Method
.	O

Audio	O
files	O
are	O
resampled	O
to	O
16kHz	O
prior	O
to	O
the	O
featurization	Method
.	O

Finally	O
,	O
from	O
each	O
frequency	O
bin	O
we	O
remove	O
the	O
global	O
mean	O
over	O
the	O
training	O
set	O
and	O
divide	O
by	O
the	O
global	Metric
standard	Metric
deviation	Metric
,	O
primarily	O
so	O
the	O
inputs	O
are	O
well	O
scaled	O
during	O
the	O
early	O
stages	O
of	O
training	Task
.	O

As	O
described	O
in	O
Section	O
[	O
reference	O
]	O
,	O
we	O
use	O
a	O
5	Method
-	Method
gram	Method
language	Method
model	Method
for	O
the	O
decoding	Task
.	O

We	O
train	O
the	O
language	Method
model	Method
on	O
220	O
million	O
phrases	O
of	O
the	O
Common	O
Crawl	O
,	O
selected	O
such	O
that	O
at	O
least	O
95	O
%	O
of	O
the	O
characters	O
of	O
each	O
phrase	O
are	O
in	O
the	O
alphabet	O
.	O

Only	O
the	O
most	O
common	O
495	O
,	O
000	O
words	O
are	O
kept	O
,	O
the	O
rest	O
remapped	O
to	O
an	O
UNKNOWN	O
token	O
.	O

We	O
compared	O
the	O
Deep	Method
Speech	Method
system	O
to	O
several	O
commercial	O
speech	Method
systems	Method
:	O
(	O
1	O
)	O
wit.ai	Method
,	O
(	O
2	O
)	O
Google	Method
Speech	Method
API	Method
,	O
(	O
3	O
)	O
Bing	Method
Speech	Method
and	O
(	O
4	O
)	O
Apple	Method
Dictation	Method
.	O

Our	O
test	O
is	O
designed	O
to	O
benchmark	O
performance	O
in	O
noisy	O
environments	O
.	O

This	O
situation	O
creates	O
challenges	O
for	O
evaluating	O
the	O
web	Task
speech	Task
APIs	Task
:	O
these	O
systems	O
will	O
give	O
no	O
result	O
at	O
all	O
when	O
the	O
SNR	O
is	O
too	O
low	O
or	O
in	O
some	O
cases	O
when	O
the	O
utterance	O
is	O
too	O
long	O
.	O

Therefore	O
we	O
restrict	O
our	O
comparison	O
to	O
the	O
subset	O
of	O
utterances	O
for	O
which	O
all	O
systems	O
returned	O
a	O
non	O
-	O
empty	O
result	O
.	O

The	O
results	O
of	O
evaluating	O
each	O
system	O
on	O
our	O
test	O
files	O
appear	O
in	O
Table	O
[	O
reference	O
]	O
.	O

To	O
evaluate	O
the	O
efficacy	O
of	O
the	O
noise	Method
synthesis	Method
techniques	Method
described	O
in	O
Section	O
[	O
reference	O
]	O
,	O
we	O
trained	O
two	O
RNNs	Method
,	O
one	O
on	O
5000	O
hours	O
of	O
raw	O
data	O
and	O
the	O
other	O
trained	O
on	O
the	O
same	O
5000	O
hours	O
plus	O
noise	O
.	O

On	O
the	O
100	O
clean	O
utterances	O
both	O
models	O
perform	O
about	O
the	O
same	O
,	O
9.2	O
%	O
WER	Metric
and	O
9.0	O
%	O
WER	Metric
for	O
the	O
clean	Method
trained	Method
model	Method
and	O
the	O
noise	Method
trained	Method
model	Method
respectively	O
.	O

However	O
,	O
on	O
the	O
100	O
noisy	O
utterances	O
the	O
noisy	Method
model	Method
achieves	O
22.6	O
%	O
WER	Metric
over	O
the	O
clean	O
model	O
’s	O
28.7	O
%	O
WER	Metric
,	O
a	O
6.1	O
%	O
absolute	O
and	O
21.3	O
%	O
relative	O
improvement	O
.	O

section	O
:	O
Related	O
Work	O
Several	O
parts	O
of	O
our	O
work	O
are	O
inspired	O
by	O
previous	O
results	O
.	O

Neural	Method
network	Method
acoustic	Method
models	Method
and	O
other	O
connectionist	Method
approaches	Method
were	O
first	O
introduced	O
to	O
speech	Task
pipelines	Task
in	O
the	O
early	O
1990s	O
.	O

These	O
systems	O
,	O
similar	O
to	O
DNN	Method
acoustic	Method
models	Method
,	O
replace	O
only	O
one	O
stage	O
of	O
the	O
speech	Method
recognition	Method
pipeline	Method
.	O

Mechanically	O
,	O
our	O
system	O
is	O
similar	O
to	O
other	O
efforts	O
to	O
build	O
end	O
-	O
to	O
-	O
end	O
speech	Method
systems	Method
from	O
deep	Method
learning	Method
algorithms	Method
.	O

For	O
example	O
,	O
Graves	O
et	O
al	O
.	O

have	O
previously	O
introduced	O
the	O
“	O
Connectionist	Method
Temporal	Method
Classification	Method
”	O
(	O
CTC	Method
)	O
loss	O
function	O
for	O
scoring	Task
transcriptions	Task
produced	O
by	O
RNNs	Method
and	O
,	O
with	O
LSTM	Method
networks	O
,	O
have	O
previously	O
applied	O
this	O
approach	O
to	O
speech	O
.	O

We	O
similarly	O
adopt	O
the	O
CTC	Method
loss	O
for	O
part	O
of	O
our	O
training	Method
procedure	Method
but	O
use	O
much	O
simpler	O
recurrent	Method
networks	Method
with	O
rectified	Method
-	Method
linear	Method
activations	Method
.	O

Our	O
recurrent	Method
network	Method
is	O
similar	O
to	O
the	O
bidirectional	Method
RNN	Method
used	O
by	O
Hannun	O
et	O
al	O
.	O

,	O
but	O
with	O
multiple	O
changes	O
to	O
enhance	O
its	O
scalability	O
.	O

By	O
focusing	O
on	O
scalability	O
,	O
we	O
have	O
shown	O
that	O
these	O
simpler	O
networks	O
can	O
be	O
effective	O
even	O
without	O
the	O
more	O
complex	O
LSTM	Method
machinery	O
.	O

Our	O
work	O
is	O
certainly	O
not	O
the	O
first	O
to	O
exploit	O
scalability	O
to	O
improve	O
performance	O
of	O
DL	Method
algorithms	Method
.	O

The	O
value	O
of	O
scalability	Task
in	O
deep	Task
learning	Task
is	O
well	O
-	O
studied	O
and	O
the	O
use	O
of	O
parallel	O
processors	O
(	O
including	O
GPUs	Method
)	O
has	O
been	O
instrumental	O
to	O
recent	O
large	Task
-	Task
scale	Task
DL	Task
results	O
.	O

Early	O
ports	O
of	O
DL	Method
algorithms	Method
to	O
GPUs	Method
revealed	O
significant	O
speed	O
gains	O
.	O

Researchers	O
have	O
also	O
begun	O
choosing	O
designs	O
that	O
map	O
well	O
to	O
GPU	O
hardware	O
to	O
gain	O
even	O
more	O
efficiency	O
,	O
including	O
convolutional	Method
and	O
locally	Method
connected	Method
networks	Method
,	O
especially	O
when	O
optimized	O
libraries	O
like	O
cuDNN	Method
and	O
BLAS	Method
are	O
available	O
.	O

Indeed	O
,	O
using	O
high	O
-	O
performance	O
computing	Method
infrastructure	Method
,	O
it	O
is	O
possible	O
today	O
to	O
train	O
neural	Method
networks	Method
with	O
more	O
than	O
10	O
billion	O
connections	O
using	O
clusters	Method
of	Method
GPUs	Method
.	O

These	O
results	O
inspired	O
us	O
to	O
focus	O
first	O
on	O
making	O
scalable	O
design	O
choices	O
to	O
efficiently	O
utilize	O
many	O
GPUs	O
before	O
trying	O
to	O
engineer	O
the	O
algorithms	O
and	O
models	O
themselves	O
.	O

With	O
the	O
potential	O
to	O
train	O
large	O
models	O
,	O
there	O
is	O
a	O
need	O
for	O
large	O
training	O
sets	O
as	O
well	O
.	O

In	O
other	O
fields	O
,	O
such	O
as	O
computer	Task
vision	Task
,	O
large	O
labeled	O
training	O
sets	O
have	O
enabled	O
significant	O
leaps	O
in	O
performance	O
as	O
they	O
are	O
used	O
to	O
feed	O
larger	O
and	O
larger	O
DL	Task
systems	Task
.	O

In	O
speech	Task
recognition	Task
,	O
however	O
,	O
such	O
large	O
training	O
sets	O
are	O
less	O
common	O
,	O
with	O
typical	O
benchmarks	O
having	O
training	O
sets	O
ranging	O
from	O
tens	O
of	O
hours	O
(	O
e.g.	O
the	O
Wall	Material
Street	Material
Journal	Material
corpus	Material
with	O
80	O
hours	O
)	O
to	O
several	O
hundreds	O
of	O
hours	O
(	O
e.g.	O
Switchboard	Material
and	O
Broadcast	Material
News	Material
)	O
.	O

Larger	O
benchmark	O
datasets	O
,	O
such	O
as	O
the	O
Fisher	Material
corpus	O
with	O
2000	O
hours	O
of	O
transcribed	O
speech	O
,	O
are	O
rare	O
and	O
only	O
recently	O
being	O
studied	O
.	O

To	O
fully	O
utilize	O
the	O
expressive	O
power	O
of	O
the	O
recurrent	Method
networks	Method
available	O
to	O
us	O
,	O
we	O
rely	O
not	O
only	O
on	O
large	O
sets	O
of	O
labeled	O
utterances	O
,	O
but	O
also	O
on	O
synthesis	Method
techniques	Method
to	O
generate	O
novel	O
examples	O
.	O

This	O
approach	O
is	O
well	O
known	O
in	O
computer	Task
vision	Task
but	O
we	O
have	O
found	O
this	O
especially	O
convenient	O
and	O
effective	O
for	O
speech	Task
when	O
done	O
properly	O
.	O

section	O
:	O
Conclusion	O
We	O
have	O
presented	O
an	O
end	O
-	O
to	O
-	O
end	O
deep	Method
learning	Method
-	Method
based	Method
speech	Method
system	Method
capable	O
of	O
outperforming	O
existing	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
recognition	O
pipelines	O
in	O
two	O
challenging	O
scenarios	O
:	O
clear	O
,	O
conversational	O
speech	O
and	O
speech	O
in	O
noisy	O
environments	O
.	O

Our	O
approach	O
is	O
enabled	O
particularly	O
by	O
multi	Method
-	Method
GPU	Method
training	Method
and	O
by	O
data	Method
collection	Method
and	O
synthesis	O
strategies	O
to	O
build	O
large	O
training	O
sets	O
exhibiting	O
the	O
distortions	O
our	O
system	O
must	O
handle	O
(	O
such	O
as	O
background	O
noise	O
and	O
Lombard	O
effect	O
)	O
.	O

Combined	O
,	O
these	O
solutions	O
enable	O
us	O
to	O
build	O
a	O
data	Method
-	Method
driven	Method
speech	Method
system	Method
that	O
is	O
at	O
once	O
better	O
performing	O
than	O
existing	O
methods	O
while	O
no	O
longer	O
relying	O
on	O
the	O
complex	O
processing	Method
stages	Method
that	O
had	O
stymied	O
further	O
progress	O
.	O

We	O
believe	O
this	O
approach	O
will	O
continue	O
to	O
improve	O
as	O
we	O
capitalize	O
on	O
increased	O
computing	O
power	O
and	O
dataset	O
sizes	O
in	O
the	O
future	O
.	O

section	O
:	O
Acknowledgments	O
We	O
are	O
grateful	O
to	O
Jia	O
Lei	O
,	O
whose	O
work	O
on	O
DL	O
for	O
speech	O
at	O
Baidu	O
has	O
spurred	O
us	O
forward	O
,	O
for	O
his	O
advice	O
and	O
support	O
throughout	O
this	O
project	O
.	O

We	O
also	O
thank	O
Ian	O
Lane	O
,	O
Dan	O
Povey	O
,	O
Dan	O
Jurafsky	O
,	O
Dario	O
Amodei	O
,	O
Andrew	O
Maas	O
,	O
Calisa	O
Cole	O
and	O
Li	O
Wei	O
for	O
helpful	O
conversations	O
.	O

bibliography	O
:	O
References	O
