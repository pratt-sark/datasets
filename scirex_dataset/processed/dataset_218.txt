Challenges	O
in	O
Data	Task
-	Task
to	Task
-	Task
Document	Task
Generation	Task
section	O
:	O
Abstract	O
Recent	O
neural	Method
models	Method
have	O
shown	O
significant	O
progress	O
on	O
the	O
problem	O
of	O
generating	O
short	O
descriptive	O
texts	O
conditioned	O
on	O
a	O
small	O
number	O
of	O
database	O
records	O
.	O

In	O
this	O
work	O
,	O
we	O
suggest	O
a	O
slightly	O
more	O
difficult	O
data	O
-	O
to	O
-	O
text	O
generation	Task
task	O
,	O
and	O
investigate	O
how	O
effective	O
current	O
approaches	O
are	O
on	O
this	O
task	O
.	O

In	O
particular	O
,	O
we	O
introduce	O
a	O
new	O
,	O
large	O
-	O
scale	O
corpus	O
of	O
data	O
records	O
paired	O
with	O
descriptive	O
documents	O
,	O
propose	O
a	O
series	O
of	O
extractive	Method
evaluation	Method
methods	Method
for	O
analyzing	O
performance	O
,	O
and	O
obtain	O
baseline	O
results	O
using	O
current	O
neural	O
generation	Task
methods	O
.	O

Experiments	O
show	O
that	O
these	O
models	O
produce	O
fluent	O
text	O
,	O
but	O
fail	O
to	O
convincingly	O
approximate	O
humangenerated	O
documents	O
.	O

Moreover	O
,	O
even	O
templated	Method
baselines	Method
exceed	O
the	O
performance	O
of	O
these	O
neural	Method
models	Method
on	O
some	O
metrics	O
,	O
though	O
copy	Method
-	Method
and	Method
reconstructionbased	Method
extensions	Method
lead	O
to	O
noticeable	O
improvements	O
.	O

section	O
:	O
Introduction	O
Over	O
the	O
past	O
several	O
years	O
,	O
neural	Task
text	Task
generation	Task
systems	O
have	O
shown	O
impressive	O
performance	O
on	O
tasks	O
such	O
as	O
machine	Task
translation	Task
and	O
summarization	Task
.	O

As	O
neural	Method
systems	Method
begin	O
to	O
move	O
toward	O
generating	O
longer	O
outputs	O
in	O
response	O
to	O
longer	O
and	O
more	O
complicated	O
inputs	O
,	O
however	O
,	O
the	O
generated	O
texts	O
begin	O
to	O
display	O
reference	O
errors	O
,	O
intersentence	O
incoherence	O
,	O
and	O
a	O
lack	O
of	O
fidelity	O
to	O
the	O
source	O
material	O
.	O

The	O
goal	O
of	O
this	O
paper	O
is	O
to	O
suggest	O
a	O
particular	O
,	O
long	O
-	O
form	O
generation	Task
task	O
in	O
which	O
these	O
challenges	O
may	O
be	O
fruitfully	O
explored	O
,	O
to	O
provide	O
a	O
publically	O
available	O
dataset	O
for	O
this	O
task	O
,	O
to	O
suggest	O
some	O
automatic	Metric
evaluation	Metric
metrics	Metric
,	O
and	O
finally	O
to	O
establish	O
how	O
current	O
,	O
neural	Task
text	Task
generation	Task
methods	O
perform	O
on	O
this	O
task	O
.	O

A	O
classic	O
problem	O
in	O
natural	O
-	O
language	O
generation	Task
(	O
NLG	O
)	O
[	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
involves	O
taking	O
structured	O
data	O
,	O
such	O
as	O
a	O
table	O
,	O
as	O
input	O
,	O
and	O
producing	O
text	O
that	O
adequately	O
and	O
fluently	O
describes	O
this	O
data	O
as	O
output	O
.	O

Unlike	O
machine	Task
translation	Task
,	O
which	O
aims	O
for	O
a	O
complete	O
transduction	Task
of	Task
the	Task
sentence	Task
to	O
be	O
translated	O
,	O
this	O
form	O
of	O
NLG	Task
is	O
typically	O
taken	O
to	O
require	O
addressing	O
(	O
at	O
least	O
)	O
two	O
separate	O
challenges	O
:	O
what	O
to	O
say	O
,	O
the	O
selection	O
of	O
an	O
appropriate	O
subset	O
of	O
the	O
input	O
data	O
to	O
discuss	O
,	O
and	O
how	O
to	O
say	O
it	O
,	O
the	O
surface	O
realization	O
of	O
a	O
generation	Task
[	O
reference	O
][	O
reference	O
]	O
.	O

Traditionally	O
,	O
these	O
two	O
challenges	O
have	O
been	O
modularized	O
and	O
handled	O
separately	O
by	O
generation	Task
systems	O
.	O

However	O
,	O
neural	O
generation	Task
systems	O
,	O
which	O
are	O
typically	O
trained	O
end	O
-	O
to	O
-	O
end	O
as	O
conditional	Method
language	Method
models	Method
[	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
,	O
blur	O
this	O
distinction	O
.	O

In	O
this	O
context	O
,	O
we	O
believe	O
the	O
problem	O
of	O
generating	Task
multi	Task
-	Task
sentence	Task
summaries	Task
of	Task
tables	Task
or	O
database	O
records	O
to	O
be	O
a	O
reasonable	O
next	O
-	O
problem	O
for	O
neural	Method
techniques	Method
to	O
tackle	O
as	O
they	O
begin	O
to	O
consider	O
more	O
difficult	O
NLG	Task
tasks	Task
.	O

In	O
particular	O
,	O
we	O
would	O
like	O
this	O
generation	Task
task	O
to	O
have	O
the	O
following	O
two	O
properties	O
:	O
(	O
1	O
)	O
it	O
is	O
relatively	O
easy	O
to	O
obtain	O
fairly	O
clean	O
summaries	O
and	O
their	O
corresponding	O
databases	O
for	O
dataset	Task
construction	Task
,	O
and	O
(	O
2	O
)	O
the	O
summaries	O
should	O
be	O
primarily	O
focused	O
on	O
conveying	O
the	O
information	O
in	O
the	O
database	O
.	O

This	O
latter	O
property	O
ensures	O
that	O
the	O
task	O
is	O
somewhat	O
congenial	O
to	O
a	O
standard	O
encoder	Method
-	Method
decoder	Method
approach	Method
,	O
and	O
,	O
more	O
importantly	O
,	O
that	O
it	O
is	O
reasonable	O
to	O
evaluate	O
generations	O
in	O
terms	O
of	O
their	O
fidelity	O
to	O
the	O
database	O
.	O

One	O
task	O
that	O
meets	O
these	O
criteria	O
is	O
that	O
of	O
generating	Task
summaries	Task
of	Task
sports	Task
games	Task
from	O
associated	O
box	O
-	O
score	O
data	O
,	O
and	O
there	O
is	O
indeed	O
a	O
long	O
history	O
of	O
NLG	Method
work	O
that	O
generates	O
sports	O
game	O
summaries	O
[	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
.	O

To	O
this	O
end	O
,	O
we	O
make	O
the	O
following	O
contributions	O
:	O
•	O
We	O
introduce	O
a	O
new	O
large	O
-	O
scale	O
corpus	O
consisting	O
of	O
textual	O
descriptions	O
of	O
basketball	O
games	O
paired	O
with	O
extensive	O
statistical	O
tables	O
.	O

This	O
dataset	O
is	O
sufficiently	O
large	O
that	O
fully	O
data	Method
-	Method
driven	Method
approaches	Method
might	O
be	O
sufficient	O
.	O

•	O
We	O
introduce	O
a	O
series	O
of	O
extractive	Method
evaluation	Method
models	Method
to	O
automatically	O
evaluate	O
output	O
generation	Task
performance	O
,	O
exploiting	O
the	O
fact	O
that	O
post	O
-	O
hoc	O
information	Task
extraction	Task
is	O
significantly	O
easier	O
than	O
generation	Task
itself	O
.	O

•	O
We	O
apply	O
a	O
series	O
of	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
neural	Method
methods	Method
,	O
as	O
well	O
as	O
a	O
simple	O
templated	O
generation	Task
system	O
,	O
to	O
our	O
data	O
-	O
to	O
-	O
document	O
generation	Task
task	O
in	O
order	O
to	O
establish	O
baselines	O
and	O
study	O
their	O
generations	O
.	O

Our	O
experiments	O
indicate	O
that	O
neural	Method
systems	Method
are	O
quite	O
good	O
at	O
producing	O
fluent	O
outputs	O
and	O
generally	O
score	O
well	O
on	O
standard	O
word	Metric
-	Metric
match	Metric
metrics	Metric
,	O
but	O
perform	O
quite	O
poorly	O
at	O
content	Method
selection	Method
and	O
at	O
capturing	Task
long	Task
-	Task
term	Task
structure	Task
.	O

While	O
the	O
use	O
of	O
copy	Method
-	Method
based	Method
models	Method
and	O
additional	O
reconstruction	O
terms	O
in	O
the	O
training	Metric
loss	Metric
can	O
lead	O
to	O
improvements	O
in	O
BLEU	Metric
and	O
in	O
our	O
proposed	O
extractive	Task
evaluations	Task
,	O
current	O
models	O
are	O
still	O
quite	O
far	O
from	O
producing	O
human	O
-	O
level	O
output	O
,	O
and	O
are	O
significantly	O
worse	O
than	O
templated	Method
systems	Method
in	O
terms	O
of	O
content	Method
selection	Method
and	O
realization	Task
.	O

Overall	O
,	O
we	O
believe	O
this	O
problem	O
of	O
data	O
-	O
to	O
-	O
document	O
generation	Task
highlights	O
important	O
remaining	O
challenges	O
in	O
neural	O
generation	Task
systems	O
,	O
and	O
the	O
use	O
of	O
extractive	Task
evaluation	Task
reveals	O
significant	O
issues	O
hidden	O
by	O
standard	O
automatic	Metric
metrics	Metric
.	O

section	O
:	O
Data	O
-	O
to	O
-	O
Text	O
Datasets	O
We	O
consider	O
the	O
problem	O
of	O
generating	O
descriptive	O
text	O
from	O
database	O
records	O
.	O

Following	O
the	O
notation	O
in	O
[	O
reference	O
]	O
,	O
let	O
s	O
=	O
{	O
r	O
j	O
}	O
J	O
j=1	O
be	O
a	O
set	O
of	O
records	O
,	O
where	O
for	O
each	O
r	O
∈	O
s	O
we	O
define	O
r.t	O
∈	O
T	O
to	O
be	O
the	O
type	O
of	O
r	O
,	O
and	O
we	O
assume	O
each	O
r	O
to	O
be	O
a	O
binarized	O
relation	O
,	O
where	O
r.e	O
and	O
r.m	O
are	O
a	O
record	O
's	O
entity	O
and	O
value	O
,	O
respectively	O
.	O

For	O
example	O
,	O
a	O
database	O
recording	O
statistics	O
for	O
a	O
basketball	O
game	O
might	O
have	O
a	O
record	O
r	O
such	O
that	O
r.t	O
=	O
POINTS	O
,	O
r.e	O
=	O
RUSSELL	O
WESTBROOK	O
,	O
and	O
r.m	O
=	O
50	O
.	O

In	O
this	O
case	O
,	O
r.e	O
gives	O
the	O
player	O
in	O
question	O
,	O
and	O
r.m	O
gives	O
the	O
number	O
of	O
points	O
the	O
player	O
scored	O
.	O

From	O
these	O
records	O
,	O
we	O
are	O
interested	O
in	O
generating	O
descriptive	O
text	O
,	O
ŷ	O
1:T	O
=	O
ŷ	O
1	O
,	O
.	O

.	O

.	O

,	O
ŷ	O
T	O
of	O
T	O
words	O
such	O
thatŷ	O
1:T	O
is	O
an	O
adequate	O
and	O
fluent	O
summary	O
of	O
s.	O
A	O
dataset	O
for	O
training	Task
data	Task
-	Task
to	Task
-	Task
document	Task
systems	Task
typically	O
consists	O
of	O
(	O
s	O
,	O
y	O
1:T	O
)	O
pairs	O
,	O
where	O
y	O
1:T	O
is	O
a	O
document	O
consisting	O
of	O
a	O
gold	O
(	O
i.e.	O
,	O
human	O
generated	O
)	O
summary	O
for	O
database	O
s.	O
Several	O
benchmark	O
datasets	O
have	O
been	O
used	O
in	O
recent	O
years	O
for	O
the	O
text	O
generation	Task
task	O
,	O
the	O
most	O
popular	O
of	O
these	O
being	O
WEATHERGOV	Material
[	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
.	O

Recently	O
,	O
neural	O
generation	Task
systems	O
have	O
show	O
strong	O
results	O
on	O
these	O
datasets	O
,	O
with	O
the	O
system	O
of	O
[	O
reference	O
]	O
achieving	O
BLEU	Metric
scores	O
in	O
the	O
60s	O
and	O
70s	O
on	O
WEATHERGOV	Material
,	O
and	O
BLEU	Metric
scores	O
of	O
almost	O
30	O
even	O
on	O
the	O
smaller	O
ROBOCUP	Material
dataset	Material
.	O

These	O
results	O
are	O
quite	O
promising	O
,	O
and	O
suggest	O
that	O
neural	Method
models	Method
are	O
a	O
good	O
fit	O
for	O
text	O
generation	Task
.	O

However	O
,	O
the	O
statistics	O
of	O
these	O
datasets	O
,	O
shown	O
in	O
Table	O
1	O
,	O
indicate	O
that	O
these	O
datasets	O
use	O
relatively	O
simple	O
language	O
and	O
record	O
structure	O
.	O

Furthermore	O
,	O
there	O
is	O
reason	O
to	O
believe	O
that	O
WEATHERGOV	Material
is	O
at	O
least	O
partially	O
machine	O
-	O
generated	O
[	O
reference	O
]	O
.	O

More	O
recently	O
,	O
[	O
reference	O
]	O
introduced	O
the	O
WIKIBIO	Material
dataset	Material
,	O
which	O
is	O
at	O
least	O
an	O
order	O
of	O
magnitude	O
larger	O
in	O
terms	O
of	O
number	O
of	O
tokens	O
and	O
record	O
types	O
.	O

However	O
,	O
as	O
shown	O
in	O
Table	O
1	O
,	O
this	O
dataset	O
too	O
only	O
contains	O
short	O
(	O
single	O
-	O
sentence	O
)	O
generations	O
,	O
and	O
relatively	O
few	O
records	O
per	O
generation	Task
.	O

As	O
such	O
,	O
we	O
believe	O
that	O
early	O
success	O
on	O
these	O
datasets	O
is	O
not	O
yet	O
sufficient	O
for	O
testing	O
the	O
desired	O
linguistic	Metric
capabilities	Metric
of	O
text	O
generation	Task
at	O
a	O
document	O
-	O
scale	O
.	O

With	O
this	O
challenge	O
in	O
mind	O
,	O
we	O
introduce	O
a	O
new	O
dataset	O
for	O
data	O
-	O
to	O
-	O
document	O
text	O
generation	Task
,	O
available	O
at	O
https:	O
//	O
github.com	O
/	O
harvar	O
dnlp	O
/	O
boxscore	O
-	O
data	O
.	O

The	O
dataset	O
is	O
intended	O
to	O
be	O
comparable	O
to	O
WEATHERGOV	Material
in	O
terms	O
of	O
token	Metric
count	Metric
,	O
but	O
to	O
have	O
significantly	O
longer	O
target	O
texts	O
,	O
a	O
larger	O
vocabulary	O
space	O
,	O
and	O
to	O
require	O
more	O
difficult	O
content	Method
selection	Method
.	O

The	O
dataset	O
consists	O
of	O
two	O
sources	O
of	O
articles	O
summarizing	O
NBA	Material
basketball	Material
games	Material
,	O
paired	O
with	O
their	O
corresponding	O
box	O
-	O
and	O
line	O
-	O
score	O
tables	O
.	O

The	O
data	O
statistics	O
of	O
these	O
two	O
sources	O
,	O
RO	O
-	O
TOWIRE	O
and	O
SBNATION	Method
,	O
are	O
also	O
shown	O
in	O
Ta	O
An	O
example	O
data	O
-	O
record	O
and	O
document	O
pair	O
from	O
the	O
ROTOWIRE	Material
dataset	Material
.	O

We	O
show	O
a	O
subset	O
of	O
the	O
game	O
's	O
records	O
(	O
there	O
are	O
628	O
in	O
total	O
)	O
,	O
and	O
a	O
selection	O
from	O
the	O
gold	O
document	O
.	O

The	O
document	O
mentions	O
only	O
a	O
select	O
subset	O
of	O
the	O
records	O
,	O
but	O
may	O
express	O
them	O
in	O
a	O
complicated	O
manner	O
.	O

In	O
addition	O
to	O
capturing	O
the	O
writing	O
style	O
,	O
a	O
generation	Task
system	O
should	O
select	O
similar	O
record	O
content	O
,	O
express	O
it	O
clearly	O
,	O
and	O
order	O
it	O
appropriately	O
.	O

section	O
:	O
Evaluating	O
Document	Task
Generation	Task
We	O
begin	O
by	O
discussing	O
the	O
evaluation	Task
of	Task
generated	Task
documents	Task
,	O
since	O
both	O
the	O
task	O
we	O
introduce	O
and	O
the	O
evaluation	O
methods	O
we	O
propose	O
are	O
motivated	O
by	O
some	O
of	O
the	O
shortcomings	O
of	O
current	O
approaches	O
to	O
evaluation	Task
.	O

Text	O
generation	Task
systems	O
are	O
typically	O
evaluated	O
using	O
a	O
combination	O
of	O
automatic	Metric
measures	Metric
,	O
such	O
as	O
BLEU	Metric
[	O
reference	O
]	O
,	O
and	O
human	Metric
evaluation	Metric
.	O

While	O
BLEU	Metric
is	O
perhaps	O
a	O
reasonably	O
effective	O
way	O
of	O
evaluating	O
short	O
-	O
form	O
text	O
generation	Task
,	O
we	O
found	O
it	O
to	O
be	O
unsatisfactory	O
for	O
document	O
generation	Task
.	O

In	O
particular	O
,	O
we	O
note	O
that	O
it	O
primarily	O
rewards	O
fluent	O
text	O
generation	Task
,	O
rather	O
than	O
generations	O
that	O
capture	O
the	O
most	O
important	O
information	O
in	O
the	O
database	O
,	O
or	O
that	O
report	O
the	O
information	O
in	O
a	O
particularly	O
coherent	O
way	O
.	O

While	O
human	Task
evaluation	Task
,	O
on	O
the	O
other	O
hand	O
,	O
is	O
likely	O
ultimately	O
necessary	O
for	O
evaluating	O
generations	Task
[	O
reference	O
][	O
reference	O
]	O
,	O
it	O
is	O
much	O
less	O
convenient	O
than	O
using	O
automatic	Metric
metrics	Metric
.	O

Furthermore	O
,	O
we	O
believe	O
that	O
current	O
text	Task
generations	Task
are	O
sufficiently	O
bad	O
in	O
sufficiently	O
obvious	O
ways	O
that	O
automatic	Metric
metrics	Metric
can	O
still	O
be	O
of	O
use	O
in	O
evaluation	Task
,	O
and	O
we	O
are	O
not	O
yet	O
at	O
the	O
point	O
of	O
needing	O
to	O
rely	O
solely	O
on	O
human	O
evaluators	O
.	O

section	O
:	O
Extractive	Task
Evaluation	Task
To	O
address	O
this	O
evaluation	O
challenge	O
,	O
we	O
begin	O
with	O
the	O
intuition	O
that	O
assessing	O
document	Metric
quality	Metric
is	O
easier	O
than	O
document	O
generation	Task
.	O

In	O
particular	O
,	O
it	O
is	O
much	O
easier	O
to	O
automatically	O
extract	O
information	O
from	O
documents	O
than	O
to	O
generate	O
documents	O
that	O
accurately	O
convey	O
desired	O
information	O
.	O

As	O
such	O
,	O
simple	O
,	O
high	O
-	O
precision	Metric
information	O
extraction	O
models	O
can	O
serve	O
as	O
the	O
basis	O
for	O
assessing	O
and	O
better	O
understanding	O
the	O
quality	O
of	O
automatic	Task
generations	Task
.	O

We	O
emphasize	O
that	O
such	O
an	O
evaluation	Method
scheme	Method
is	O
most	O
appropriate	O
when	O
evaluating	Task
generations	Task
(	O
such	O
as	O
basketball	O
game	O
summaries	O
)	O
that	O
are	O
primarily	O
intended	O
to	O
summarize	O
information	O
.	O

While	O
many	O
generation	Task
problems	Task
do	O
not	O
fall	O
into	O
this	O
category	O
,	O
we	O
believe	O
this	O
to	O
be	O
an	O
interesting	O
category	O
,	O
and	O
one	O
worth	O
focusing	O
on	O
because	O
it	O
is	O
amenable	O
to	O
this	O
sort	O
of	O
evaluation	O
.	O

To	O
see	O
how	O
a	O
simple	O
information	Method
extraction	Method
system	Method
might	O
work	O
,	O
consider	O
the	O
document	O
in	O
Figure	O
1	O
.	O

We	O
may	O
first	O
extract	O
candidate	O
entity	O
(	O
player	O
,	O
team	O
,	O
and	O
city	O
)	O
and	O
value	O
(	O
number	O
and	O
certain	O
string	O
)	O
pairs	O
r.e	O
,	O
r.m	O
that	O
appear	O
in	O
the	O
text	O
,	O
and	O
then	O
predict	O
the	O
type	O
r.t	O
(	O
or	O
none	O
)	O
of	O
each	O
candidate	O
pair	O
.	O

For	O
example	O
,	O
we	O
might	O
extract	O
the	O
entity	O
-	O
value	O
pair	O
(	O
"	O
Miami	O
Heat	O
"	O
,	O
"	O
95	O
"	O
)	O
from	O
the	O
first	O
sentence	O
in	O
Figure	O
1	O
,	O
and	O
then	O
predict	O
that	O
the	O
type	O
of	O
this	O
pair	O
is	O
POINTS	O
,	O
giving	O
us	O
an	O
extracted	O
record	O
r	O
such	O
that	O
(	O
r.e	O
,	O
r.m	O
,	O
r.t	O
)	O
=	O
(	O
MIAMI	O
HEAT	O
,	O
95	O
,	O
POINTS	O
)	O
.	O

Indeed	O
,	O
many	O
relation	Method
extraction	Method
systems	Method
reduce	O
relation	Task
extraction	Task
to	O
multi	Task
-	Task
class	Task
classification	Task
precisely	O
in	O
this	O
way	O
[	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
.	O

More	O
concretely	O
,	O
given	O
a	O
documentŷ	O
1:T	O
,	O
we	O
consider	O
all	O
pairs	O
of	O
word	O
-	O
spans	O
in	O
each	O
sentence	O
that	O
represent	O
possible	O
entities	O
e	O
and	O
values	O
m.	O
We	O
then	O
model	O
p	O
(	O
r.t	O
|	O
e	O
,	O
m	O
;	O
θ	O
)	O
for	O
each	O
pair	O
,	O
using	O
r.t	O
=	O
ǫ	O
to	O
indicate	O
unrelated	O
pairs	O
.	O

We	O
use	O
architectures	O
similar	O
to	O
those	O
discussed	O
in	O
[	O
reference	O
]	O
and	O
dos	O
[	O
reference	O
]	O
to	O
parameterize	O
this	O
probability	O
;	O
full	O
details	O
are	O
given	O
in	O
the	O
Appendix	O
.	O

Importantly	O
,	O
we	O
note	O
that	O
the	O
(	O
s	O
,	O
y	O
1:T	O
)	O
pairs	O
typically	O
used	O
for	O
training	O
data	Task
-	Task
to	Task
-	Task
document	Task
systems	Task
are	O
also	O
sufficient	O
for	O
training	O
the	O
information	Method
extraction	Method
model	Method
presented	O
above	O
,	O
since	O
we	O
can	O
obtain	O
(	O
partial	O
)	O
supervision	O
by	O
simply	O
checking	O
whether	O
a	O
candidate	O
record	O
lexically	O
matches	O
a	O
record	O
in	O
s.	O
1	O
However	O
,	O
since	O
there	O
may	O
be	O
multiple	O
records	O
r	O
∈	O
s	O
with	O
the	O
same	O
e	O
and	O
m	O
but	O
with	O
different	O
types	O
r.t	O
,	O
we	O
will	O
not	O
always	O
be	O
able	O
to	O
determine	O
the	O
type	O
of	O
a	O
given	O
entity	O
-	O
value	O
pair	O
found	O
in	O
the	O
text	O
.	O

We	O
therefore	O
train	O
our	O
classifier	Method
to	O
minimize	O
a	O
latent	O
-	O
variable	O
loss	O
:	O
for	O
all	O
document	O
spans	O
e	O
and	O
m	O
,	O
with	O
observed	O
types	O
t	O
(	O
e	O
,	O
m	O
)	O
=	O
{	O
r.t	O
:	O
r	O
∈	O
s	O
,	O
r.e	O
=	O
e	O
,	O
r.m	O
=	O
m	O
}	O
(	O
possi	O
-	O
1	O
Alternative	O
approaches	O
explicitly	O
align	O
the	O
document	O
with	O
the	O
table	O
for	O
this	O
task	O
[	O
reference	O
]	O
bly	O
{	O
ǫ	O
}	O
)	O
,	O
we	O
minimize	O
We	O
find	O
that	O
this	O
simple	O
system	O
trained	O
in	O
this	O
way	O
is	O
quite	O
accurate	O
at	O
predicting	Task
relations	Task
.	O

On	O
the	O
ROTOWIRE	Material
data	O
it	O
achieves	O
over	O
90	O
%	O
accuracy	Metric
on	O
held	O
-	O
out	O
data	O
,	O
and	O
recalls	O
approximately	O
60	O
%	O
of	O
the	O
relations	O
licensed	O
by	O
the	O
records	O
.	O

section	O
:	O
Comparing	O
Generations	O
With	O
a	O
sufficiently	O
precise	O
relation	Method
extraction	Method
system	Method
,	O
we	O
can	O
begin	O
to	O
evaluate	O
how	O
well	O
an	O
automatic	Method
generationŷ	Method
1:T	Method
has	O
captured	O
the	O
information	O
in	O
a	O
set	O
of	O
records	O
s.	O
In	O
particular	O
,	O
since	O
the	O
predictions	O
of	O
a	O
precise	O
information	Method
extraction	Method
system	Method
serve	O
to	O
align	O
entity	O
-	O
mention	O
pairs	O
in	O
the	O
text	O
with	O
database	O
records	O
,	O
this	O
alignment	O
can	O
be	O
used	O
both	O
to	O
evaluate	O
a	O
generation	Task
's	O
content	Method
selection	Method
(	O
"	O
what	O
the	O
generation	Task
says	O
"	O
)	O
,	O
as	O
well	O
as	O
content	Task
placement	Task
(	O
"	O
how	O
the	O
generation	Task
says	O
it	O
"	O
)	O
.	O

We	O
consider	O
in	O
particular	O
three	O
induced	Metric
metrics	Metric
:	O
•	O
Content	Method
Selection	Method
(	O
CS	Metric
)	O
:	O
precision	Metric
and	O
recall	Metric
of	O
unique	O
relations	O
r	O
extracted	O
from	O
y	O
1:T	O
that	O
are	O
also	O
extracted	O
from	O
y	O
1:T	O
.	O

This	O
measures	O
how	O
well	O
the	O
generated	O
document	O
matches	O
the	O
gold	O
document	O
in	O
terms	O
of	O
selecting	O
which	O
records	O
to	O
generate	O
.	O

•	O
Relation	Method
Generation	Method
(	O
RG	Metric
)	O
:	O
precision	Metric
and	O
number	O
of	O
unique	O
relations	O
r	O
extracted	O
from	O
y	O
1:T	O
that	O
also	O
appear	O
in	O
s.	O
This	O
measures	O
how	O
well	O
the	O
system	O
is	O
able	O
to	O
generate	O
text	O
containing	O
factual	O
(	O
i.e.	O
,	O
correct	O
)	O
records	O
.	O

•	O
Content	Method
Ordering	Method
(	O
CO	Method
)	O
:	O
normalized	O
Damerau	O
-	O
Levenshtein	O
Distance	O
[	O
reference	O
]	O
2	O
between	O
the	O
sequences	O
of	O
records	O
extracted	O
from	O
y	O
1:T	O
and	O
that	O
extracted	O
fromŷ	O
1:T	O
.	O

This	O
measures	O
how	O
well	O
the	O
system	O
orders	O
the	O
records	O
it	O
chooses	O
to	O
discuss	O
.	O

We	O
note	O
that	O
CS	Metric
primarily	O
targets	O
the	O
"	O
what	O
to	O
say	O
"	O
aspect	O
of	O
evaluation	Task
,	O
CO	O
targets	O
the	O
"	O
how	O
to	O
say	O
it	O
"	O
aspect	O
,	O
and	O
RG	Metric
targets	O
both	O
.	O

We	O
conclude	O
this	O
section	O
by	O
contrasting	O
the	O
automatic	Task
evaluation	Task
we	O
have	O
proposed	O
with	O
recently	O
proposed	O
adversarial	Method
evaluation	Method
approaches	Method
,	O
which	O
also	O
advocate	O
automatic	Metric
metrics	Metric
backed	O
by	O
classification	Method
[	O
reference	O
][	O
reference	O
]	O
.	O

Unlike	O
adversarial	Method
evaluation	Method
,	O
which	O
uses	O
a	O
blackbox	Method
classifier	Method
to	O
determine	O
the	O
quality	O
of	O
a	O
generation	Task
,	O
our	O
metrics	O
are	O
defined	O
with	O
respect	O
to	O
the	O
predictions	O
of	O
an	O
information	Method
extraction	Method
system	Method
.	O

Accordingly	O
,	O
our	O
metrics	O
are	O
quite	O
interpretable	O
,	O
since	O
by	O
construction	O
it	O
is	O
always	O
possible	O
to	O
determine	O
which	O
fact	O
(	O
i.e.	O
,	O
entity	O
-	O
value	O
pair	O
)	O
in	O
the	O
generation	Task
is	O
determined	O
by	O
the	O
extractor	O
to	O
not	O
match	O
the	O
database	O
or	O
the	O
gold	O
generation	Task
.	O

section	O
:	O
Neural	Task
Data	Task
-	Task
to	Task
-	Task
Document	Task
Models	Task
In	O
this	O
section	O
we	O
briefly	O
describe	O
the	O
neural	O
generation	Task
methods	O
we	O
apply	O
to	O
the	O
proposed	O
task	O
.	O

As	O
a	O
base	O
model	O
we	O
utilize	O
the	O
now	O
standard	O
attentionbased	Method
encoder	Method
-	Method
decoder	Method
model	Method
[	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
.	O

We	O
also	O
experiment	O
with	O
several	O
recent	O
extensions	O
to	O
this	O
model	O
,	O
including	O
copy	O
-	O
based	O
generation	Task
,	O
and	O
training	O
with	O
a	O
source	O
reconstruction	O
term	O
in	O
the	O
loss	O
(	O
in	O
addition	O
to	O
the	O
standard	O
per	O
-	O
targetword	O
loss	O
)	O
.	O

Base	Method
Model	Method
For	O
our	O
base	O
model	O
,	O
we	O
map	O
each	O
record	O
r	O
∈	O
s	O
into	O
a	O
vectorr	O
by	O
first	O
embedding	O
r.t	O
(	O
e.g.	O
,	O
POINTS	O
)	O
,	O
r.e	O
(	O
e.g.	O
,	O
RUSSELL	O
WESTBROOK	O
)	O
,	O
and	O
r.m	O
(	O
e.g.	O
,	O
50	O
)	O
,	O
and	O
then	O
applying	O
a	O
1	Method
-	Method
layer	Method
MLP	Method
(	O
similar	O
to	O
[	O
reference	O
]	O
)	O
.	O

[	O
reference	O
]	O
Our	O
source	O
data	O
-	O
records	O
are	O
then	O
represented	O
ass	O
=	O
{	O
r	O
j	O
}	O
J	O
j=1	O
.	O

Givens	O
,	O
we	O
use	O
an	O
LSTM	Method
decoder	Method
with	O
attention	Method
and	O
input	Method
-	Method
feeding	Method
,	O
in	O
the	O
style	O
of	O
[	O
reference	O
]	O
,	O
to	O
compute	O
the	O
probability	O
of	O
each	O
target	O
word	O
,	O
conditioned	O
on	O
the	O
previous	O
words	O
and	O
on	O
s.	O
The	O
model	O
is	O
trained	O
end	O
-	O
to	O
-	O
end	O
to	O
minimize	O
the	O
negative	O
log	O
-	O
likelihood	O
of	O
the	O
words	O
in	O
the	O
gold	O
text	O
y	O
1:T	O
given	O
corresponding	O
source	O
material	O
s.	O
Copying	Task
There	O
has	O
been	O
a	O
surge	O
of	O
recent	O
work	O
involving	O
augmenting	O
encoder	Method
-	Method
decoder	Method
models	Method
to	O
copy	O
words	O
directly	O
from	O
the	O
source	O
material	O
on	O
which	O
they	O
condition	O
[	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
.	O

These	O
models	O
typically	O
introduce	O
an	O
additional	O
binary	O
variable	O
z	O
t	O
into	O
the	O
per	O
-	O
timestep	O
target	O
word	O
distribution	O
,	O
which	O
indicates	O
whether	O
the	O
target	O
word	O
[	O
reference	O
]	O
We	O
also	O
include	O
an	O
additional	O
feature	O
for	O
whether	O
the	O
player	O
is	O
on	O
the	O
home	O
-	O
or	O
away	O
-	O
team.ŷ	O
t	O
is	O
copied	O
from	O
the	O
source	O
or	O
generated	O
:	O
p	O
(	O
ŷ	O
t	O
,	O
z	O
t	O
=	O
z	O
|ŷ	O
1:t−1	O
,	O
s	O
)	O
.	O

In	O
our	O
case	O
,	O
we	O
assume	O
that	O
target	O
words	O
are	O
copied	O
from	O
the	O
value	O
portion	O
of	O
a	O
record	O
r	O
;	O
that	O
is	O
,	O
a	O
copy	O
impliesŷ	O
t	O
=	O
r.m	O
for	O
some	O
r	O
and	O
t.	O
Joint	Method
Copy	Method
Model	Method
The	O
models	O
of	O
[	O
reference	O
]	O
and	O
[	O
reference	O
]	O
parameterize	O
the	O
joint	O
distribution	O
table	O
overŷ	O
t	O
and	O
z	O
t	O
directly	O
:	O
where	O
copy	O
and	O
gen	Method
are	O
functions	O
parameterized	O
in	O
terms	O
of	O
the	O
decoder	O
RNN	O
's	O
hidden	O
state	O
that	O
assign	O
scores	O
to	O
words	O
,	O
and	O
where	O
the	O
notationŷ	O
t	O
∈	O
s	O
indicates	O
thatŷ	O
t	O
is	O
equal	O
to	O
r.m	O
for	O
some	O
r	O
∈	O
s.	O
section	O
:	O
Conditional	Method
Copy	Method
Model	O
Gülçehre	O
et	O
al	O
.	O

(	O
2016	O
)	O
,	O
on	O
the	O
other	O
hand	O
,	O
decompose	O
the	O
joint	O
probability	O
as	O
:	O
where	O
an	O
MLP	Method
is	O
used	O
to	O
model	O
p	O
(	O
z	O
t	O
|ŷ	O
1:t−1	O
,	O
s	O
)	O
.	O

Models	O
with	O
copy	Method
-	Method
decoders	Method
may	O
be	O
trained	O
to	O
minimize	O
the	O
negative	O
log	O
marginal	O
probability	O
,	O
marginalizing	O
out	O
the	O
latent	O
-	O
variable	O
z	O
t	O
[	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
.	O

However	O
,	O
if	O
it	O
is	O
known	O
which	O
target	O
words	O
y	O
t	O
are	O
copied	O
,	O
it	O
is	O
possible	O
to	O
train	O
with	O
a	O
loss	Method
that	O
does	O
not	O
marginalize	O
out	O
the	O
latent	O
z	O
t	O
.	O

[	O
reference	O
]	O
,	O
for	O
instance	O
,	O
assume	O
that	O
any	O
target	O
word	O
y	O
t	O
that	O
also	O
appears	O
in	O
the	O
source	O
is	O
copied	O
,	O
and	O
train	O
to	O
minimize	O
the	O
negative	O
joint	O
log	O
-	O
likelihood	O
of	O
the	O
y	O
t	O
and	O
z	O
t	O
.	O

In	O
applying	O
such	O
a	O
loss	O
in	O
our	O
case	O
,	O
we	O
again	O
note	O
that	O
there	O
may	O
be	O
multiple	O
records	O
r	O
such	O
that	O
r.m	O
appears	O
inŷ	O
1:T	O
.	O

Accordingly	O
,	O
we	O
slightly	O
modify	O
the	O
p	O
copy	O
portion	O
of	O
the	O
loss	O
of	O
[	O
reference	O
]	O
to	O
sum	O
over	O
all	O
matched	O
records	O
.	O

In	O
particular	O
,	O
we	O
model	O
the	O
probability	O
of	O
relations	O
r	O
∈	O
s	O
such	O
that	O
r.m	O
=	O
y	O
t	O
and	O
r.e	O
is	O
in	O
the	O
same	O
sentence	O
as	O
r.m	O
.	O

Letting	O
r	O
(	O
y	O
t	O
We	O
note	O
here	O
that	O
the	O
key	O
distinction	O
for	O
our	O
purposes	O
between	O
the	O
Joint	Method
Copy	Method
model	Method
and	O
the	O
Conditional	Method
Copy	Method
model	Method
is	O
that	O
the	O
latter	O
conditions	O
on	O
whether	O
there	O
is	O
a	O
copy	O
or	O
not	O
,	O
and	O
so	O
in	O
p	O
copy	O
the	O
source	O
records	O
compete	O
only	O
with	O
each	O
other	O
.	O

In	O
the	O
Joint	Method
Copy	Method
model	Method
,	O
however	O
,	O
the	O
source	O
records	O
also	O
compete	O
with	O
words	O
that	O
can	O
not	O
be	O
copied	O
.	O

As	O
a	O
result	O
,	O
training	O
the	O
Conditional	Method
Copy	Method
model	Method
with	O
the	O
supervised	O
loss	O
of	O
[	O
reference	O
]	O
can	O
be	O
seen	O
as	O
training	O
with	O
a	O
word	O
-	O
level	O
reconstruction	O
loss	O
,	O
where	O
the	O
decoder	Method
is	O
trained	O
to	O
choose	O
the	O
record	O
in	O
s	O
that	O
gives	O
rise	O
to	O
y	O
t	O
.	O

Reconstruction	Method
Losses	Method
Reconstruction	Method
-	Method
based	Method
techniques	Method
can	O
also	O
be	O
applied	O
at	O
the	O
documentor	O
sentence	O
-	O
level	O
during	O
training	Task
.	O

One	O
simple	O
approach	O
to	O
this	O
problem	O
is	O
to	O
utilize	O
the	O
hidden	O
states	O
of	O
the	O
decoder	Method
to	O
try	O
to	O
reconstruct	O
the	O
database	O
.	O

A	O
fully	Method
differentiable	Method
approach	Method
using	O
the	O
decoder	O
hidden	O
states	O
has	O
recently	O
been	O
successfully	O
applied	O
to	O
neural	Task
machine	Task
translation	Task
by	O
[	O
reference	O
]	O
.	O

Unlike	O
copying	O
,	O
this	O
method	O
is	O
applied	O
only	O
at	O
training	O
,	O
and	O
attempts	O
to	O
learn	O
decoder	O
hidden	O
states	O
with	O
broader	O
coverage	O
of	O
the	O
input	O
data	O
.	O

In	O
adopting	O
this	O
reconstruction	Method
approach	Method
we	O
segment	O
the	O
decoder	O
hidden	O
states	O
h	O
t	O
into	O
⌈	O
T	O
B	O
⌉	O
contiguous	O
blocks	O
of	O
size	O
at	O
most	O
B.	O
Denoting	O
a	O
single	O
one	O
of	O
these	O
hidden	O
state	O
blocks	O
as	O
b	O
i	O
,	O
we	O
attempt	O
to	O
predict	O
each	O
field	O
value	O
in	O
some	O
record	O
r	O
∈	O
s	O
from	O
b	O
i	O
.	O

We	O
define	O
p	O
(	O
r.e	O
,	O
r.m	O
|	O
b	O
i	O
)	O
,	O
the	O
probability	O
of	O
the	O
entity	O
and	O
value	O
in	O
record	O
r	O
given	O
b	O
i	O
,	O
to	O
be	O
softmax	O
(	O
f	O
(	O
b	O
i	O
)	O
)	O
,	O
where	O
f	O
is	O
a	O
parameterized	O
function	O
of	O
b	O
i	O
,	O
which	O
in	O
our	O
experiments	O
utilize	O
a	O
convolutional	Method
layer	Method
followed	O
by	O
an	O
MLP	Method
;	O
full	O
details	O
are	O
given	O
in	O
the	O
Appendix	O
.	O

We	O
further	O
extend	O
this	O
idea	O
and	O
predict	O
K	O
records	O
in	O
s	O
from	O
b	O
i	O
,	O
rather	O
than	O
one	O
.	O

We	O
can	O
train	O
with	O
the	O
following	O
reconstruction	O
loss	O
for	O
a	O
particular	O
b	O
i	O
:	O
where	O
p	O
k	O
is	O
the	O
k'th	O
predicted	O
distribution	O
over	O
records	O
,	O
and	O
where	O
we	O
have	O
modeled	O
each	O
component	O
of	O
r	O
independently	O
.	O

This	O
loss	O
attempts	O
to	O
make	O
the	O
most	O
probable	O
record	O
in	O
s	O
given	O
b	O
i	O
more	O
probable	O
.	O

We	O
found	O
that	O
augmenting	O
the	O
above	O
loss	O
with	O
a	O
term	O
that	O
penalizes	O
the	O
total	O
variation	O
distance	O
(	O
TVD	O
)	O
between	O
the	O
p	O
k	O
to	O
be	O
helpful	O
.	O

[	O
reference	O
]	O
Both	O
L	Method
(	Method
θ	Method
)	Method
and	O
the	O
TVD	Method
term	Method
are	O
simply	O
added	O
to	O
the	O
standard	O
negative	Method
log	Method
-	Method
likelihood	Method
objective	Method
at	O
training	O
time	O
.	O

section	O
:	O
Experimental	O
Methods	O
In	O
this	O
section	O
we	O
highlight	O
a	O
few	O
important	O
details	O
of	O
our	O
models	O
and	O
methods	O
;	O
full	O
details	O
are	O
in	O
the	O
Appendix	O
.	O

For	O
our	O
ROTOWIRE	Material
models	O
,	O
the	O
record	Method
encoder	Method
producesr	O
j	O
in	O
R	O
600	O
,	O
and	O
we	O
use	O
a	O
2	Method
-	Method
layer	Method
LSTM	Method
decoder	Method
with	O
hidden	O
states	O
of	O
the	O
same	O
size	O
as	O
ther	O
j	O
,	O
and	O
dot	Method
-	Method
product	Method
attention	Method
and	O
input	O
-	O
feeding	O
in	O
the	O
style	O
of	O
[	O
reference	O
]	O
.	O

Unlike	O
past	O
work	O
,	O
we	O
use	O
two	O
identically	Method
structured	Method
attention	Method
layers	Method
,	O
one	O
to	O
compute	O
the	O
standard	O
generation	Task
probabilities	O
(	O
gen	O
or	O
p	O
gen	O
)	O
,	O
and	O
one	O
to	O
produce	O
the	O
scores	O
used	O
in	O
copy	O
or	O
p	O
copy	O
.	O

We	O
train	O
the	O
generation	Task
models	O
using	O
SGD	Method
and	O
truncated	Method
BPTT	Method
[	O
reference	O
][	O
reference	O
]	O
,	O
as	O
in	O
language	Task
modeling	Task
.	O

That	O
is	O
,	O
we	O
split	O
each	O
y	O
1:T	O
into	O
contiguous	O
blocks	O
of	O
length	O
100	O
,	O
and	O
backprop	O
both	O
the	O
gradients	O
with	O
respect	O
to	O
the	O
current	O
block	O
as	O
well	O
as	O
with	O
respect	O
to	O
the	O
encoder	O
parameters	O
for	O
each	O
block	O
.	O

Our	O
extractive	Method
evaluator	Method
consists	O
of	O
an	O
ensemble	O
of	O
3	O
single	Method
-	Method
layer	Method
convolutional	Method
and	Method
3	Method
singlelayer	Method
bidirectional	Method
LSTM	Method
models	Method
.	O

The	O
convolutional	Method
models	Method
concatenate	O
convolutions	Method
with	O
kernel	O
widths	O
2	O
,	O
3	O
,	O
and	O
5	O
,	O
and	O
200	O
feature	O
maps	O
in	O
the	O
style	O
of	O
[	O
reference	O
]	O
.	O

Both	O
models	O
are	O
trained	O
with	O
SGD	Method
.	O

Templatized	Method
Generator	Method
In	O
addition	O
to	O
neural	Method
baselines	Method
,	O
we	O
also	O
use	O
a	O
problem	O
-	O
specific	O
,	O
template	Method
-	Method
based	Method
generator	Method
.	O

The	O
template	Method
-	Method
based	Method
generator	Method
first	O
emits	O
a	O
sentence	O
about	O
the	O
teams	O
playing	O
in	O
the	O
game	O
,	O
using	O
a	O
templatized	O
sentence	O
taken	O
from	O
the	O
training	O
set	O
:	O
The	O
<	O
team1	O
>	O
(	O
<	O
wins1>	O
-	O
<losses1	O
>	O
)	O
defeated	O
the	O
<	O
team2	O
>	O
(	O
<	O
wins2>	O
-	O
<losses2	O
>	O
)	O
<	O
pts1>	O
-	O
<pts2>.	O
Then	O
,	O
6	O
player	O
-	O
specific	O
sentences	O
of	O
the	O
following	O
form	O
are	O
emitted	O
(	O
again	O
adapting	O
a	O
simple	O
sentence	O
from	O
the	O
training	O
set	O
)	O
:	O
<	O
player	O
>	O
scored	O
<	O
pts	O
>	O
points	O
(	O
<	O
fgm>	O
-	O
<fga	O
>	O
FG	O
,	O
<	O
tpm>	O
-	O
<tpa	O
>	O
3PT	O
,	O
<	O
ftm>	O
-	O
<fta	O
>	O
FT	O
)	O
to	O
go	O
with	O
<	O
reb	O
>	O
rebounds	O
.	O

The	O
6	O
highest	O
-	O
scoring	O
players	O
in	O
the	O
game	O
are	O
used	O
to	O
fill	O
in	O
the	O
above	O
template	O
.	O

Finally	O
,	O
a	O
typical	O
end	O
sentence	O
is	O
emitted	O
:	O
The	O
<	O
team1	O
>	O
'	O
next	O
game	O
will	O
be	O
at	O
home	O
against	O
the	O
Dallas	O
Mavericks	O
,	O
while	O
the	O
<	O
team2	O
>	O
will	O
travel	O
to	O
play	O
the	O
Bulls	O
.	O

Code	O
implementing	O
all	O
models	O
can	O
be	O
found	O
at	O
https:	O
//	O
github.com	O
/	O
harvardnlp	O
/	O
d	O
ata2text	O
.	O

Our	O
encoder	Method
-	Method
decoder	Method
models	Method
are	O
based	O
on	O
OpenNMT	O
[	O
reference	O
]	O
.	O

section	O
:	O
Results	O
We	O
found	O
that	O
all	O
models	O
performed	O
quite	O
poorly	O
on	O
the	O
SBNATION	Material
data	Material
,	O
with	O
the	O
best	O
model	O
achieving	O
a	O
validation	O
perplexity	Metric
of	O
33.34	O
and	O
a	O
BLEU	Metric
score	O
of	O
1.78	O
.	O

This	O
poor	O
performance	O
is	O
presumably	O
attributable	O
to	O
the	O
noisy	O
quality	O
of	O
the	O
SBNATION	Material
data	Material
,	O
and	O
the	O
fact	O
that	O
many	O
documents	O
in	O
the	O
dataset	O
focus	O
on	O
information	O
not	O
in	O
the	O
box	O
-	O
and	O
line	O
-	O
scores	O
.	O

Accordingly	O
,	O
we	O
focus	O
on	O
ROTOWIRE	Material
in	O
what	O
follows	O
.	O

The	O
main	O
results	O
for	O
the	O
ROTOWIRE	Material
dataset	Material
are	O
shown	O
in	O
Table	O
2	O
,	O
which	O
shows	O
the	O
performance	O
of	O
the	O
models	O
in	O
Section	O
4	O
in	O
terms	O
of	O
the	O
metrics	O
defined	O
in	O
Section	O
3.2	O
,	O
as	O
well	O
as	O
in	O
terms	O
of	O
perplexity	Metric
and	O
BLEU	Metric
.	O

section	O
:	O
Discussion	O
There	O
are	O
several	O
interesting	O
relationships	O
in	O
the	O
development	O
portion	O
of	O
Table	O
2	O
.	O

First	O
we	O
note	O
that	O
the	O
Template	Method
model	Method
scores	O
very	O
poorly	O
on	O
BLEU	Metric
,	O
but	O
does	O
quite	O
well	O
on	O
the	O
extractive	Metric
metrics	Metric
,	O
providing	O
an	O
upper	O
-	O
bound	O
for	O
how	O
domain	O
knowledge	O
could	O
help	O
content	Method
selection	Method
and	O
generation	Task
.	O

All	O
the	O
neural	Method
models	Method
make	O
significant	O
improvements	O
in	O
terms	O
of	O
BLEU	Metric
score	O
,	O
with	O
the	O
conditional	Method
copying	Method
with	O
beam	Method
search	Method
performing	O
the	O
best	O
,	O
even	O
though	O
all	O
the	O
neural	Method
models	Method
achieve	O
roughly	O
the	O
same	O
perplexity	Metric
.	O

The	O
extractive	Metric
metrics	Metric
provide	O
further	O
insight	O
into	O
the	O
behavior	O
of	O
the	O
models	O
.	O

We	O
first	O
note	O
that	O
on	O
the	O
gold	O
documents	O
y	O
1:T	O
,	O
the	O
extractive	Method
model	Method
reaches	O
92	O
%	O
precision	Metric
.	O

Using	O
the	O
Joint	O
The	O
Utah	O
Jazz	O
(	O
38	O
-	O
26	O
)	O
defeated	O
the	O
Houston	O
Rockets	O
(	O
38	O
-	O
26	O
)	O
117	O
-	O
91	O
on	O
Wednesday	O
at	O
Energy	O
Solutions	O
Arena	O
in	O
Salt	O
Lake	O
City	O
.	O

The	O
Jazz	O
got	O
out	O
to	O
a	O
quick	O
start	O
in	O
this	O
one	O
,	O
out	O
-	O
scoring	O
the	O
Rockets	O
31	O
-	O
15	O
in	O
the	O
first	O
quarter	O
alone	O
.	O

Along	O
with	O
the	O
quick	O
start	O
,	O
the	O
Rockets	O
were	O
the	O
superior	O
shooters	O
in	O
this	O
game	O
,	O
going	O
54	O
percent	O
from	O
the	O
field	O
and	O
43	O
percent	O
from	O
the	O
three	O
-	O
point	O
line	O
,	O
while	O
the	O
Jazz	O
went	O
38	O
percent	O
from	O
the	O
floor	O
and	O
a	O
meager	O
19	O
percent	O
from	O
deep	O
.	O

The	O
Rockets	O
were	O
able	O
to	O
out	O
-	O
rebound	O
the	O
Rockets	O
49	O
-	O
49	O
,	O
giving	O
them	O
just	O
enough	O
of	O
an	O
advantage	O
to	O
secure	O
the	O
victory	O
in	O
front	O
of	O
their	O
home	O
crowd	O
.	O

The	O
Jazz	O
were	O
led	O
by	O
the	O
duo	O
of	O
Derrick	O
Favors	O
and	O
James	O
Harden	O
.	O

Favors	O
went	O
2	O
-	O
for	O
-	O
6	O
from	O
the	O
field	O
and	O
0	O
-	O
for	O
-	O
1	O
from	O
the	O
three	O
-	O
point	O
line	O
to	O
score	O
a	O
game	O
-	O
high	O
of	O
15	O
points	O
,	O
while	O
also	O
adding	O
four	O
rebounds	O
and	O
four	O
assists	O
....	O
Copy	Method
model	Method
,	O
generation	Task
only	O
has	O
a	O
record	O
generation	Task
(	O
RG	Metric
)	O
precision	Metric
of	O
47	O
%	O
indicating	O
that	O
relationships	O
are	O
often	O
generated	O
incorrectly	O
.	O

The	O
best	O
Conditional	Method
Copy	Method
system	O
improves	O
this	O
value	O
to	O
71	O
%	O
,	O
a	O
significant	O
improvement	O
and	O
potentially	O
the	O
cause	O
of	O
the	O
improved	O
BLEU	Metric
score	O
,	O
but	O
still	O
far	O
below	O
gold	O
.	O

Notably	O
,	O
content	Method
selection	Method
(	O
CS	Metric
)	O
and	O
content	O
ordering	O
(	O
CO	O
)	O
seem	O
to	O
have	O
no	O
correlation	O
at	O
all	O
with	O
BLEU	Metric
.	O

There	O
is	O
some	O
improvement	O
with	O
CS	Metric
for	O
the	O
conditional	Method
model	Method
or	O
reconstruction	Task
loss	Task
,	O
but	O
not	O
much	O
change	O
as	O
we	O
move	O
to	O
beam	Task
search	Task
.	O

CO	Method
actually	O
gets	O
worse	O
as	O
beam	Method
search	Method
is	O
utilized	O
,	O
possibly	O
a	O
side	O
effect	O
of	O
generating	O
more	O
records	O
(	O
RG	Metric
#	O
)	O
.	O

The	O
fact	O
that	O
these	O
scores	O
are	O
much	O
worse	O
than	O
the	O
simple	O
templated	Method
model	Method
indicates	O
that	O
further	O
research	O
is	O
needed	O
into	O
better	O
copying	O
alone	O
for	O
content	Method
selection	Method
and	O
better	O
long	Method
term	Method
content	Method
ordering	Method
models	Method
.	O

Test	O
results	O
are	O
consistent	O
with	O
development	O
results	O
,	O
indicating	O
that	O
the	O
Conditional	Method
Copy	Method
model	Method
is	O
most	O
effective	O
at	O
BLEU	Metric
,	O
RG	Metric
,	O
and	O
CS	Metric
,	O
and	O
that	O
reconstruction	Task
is	O
quite	O
helpful	O
for	O
improving	O
the	O
joint	Method
model	Method
.	O

section	O
:	O
Human	Metric
Evaluation	Metric
We	O
also	O
undertook	O
two	O
human	Task
evaluation	Task
studies	Task
,	O
using	O
Amazon	Method
Mechanical	Method
Turk	Method
.	O

The	O
first	O
study	O
attempted	O
to	O
determine	O
whether	O
generations	O
considered	O
to	O
be	O
more	O
precise	O
by	O
our	O
metrics	O
were	O
also	O
considered	O
more	O
precise	O
by	O
human	Metric
raters	Metric
.	O

To	O
accomplish	O
this	O
,	O
raters	O
were	O
presented	O
with	O
a	O
particular	O
NBA	O
game	O
's	O
box	O
score	O
and	O
line	O
score	O
,	O
as	O
well	O
as	O
with	O
(	O
randomly	O
selected	O
)	O
sentences	O
from	O
summaries	O
generated	O
by	O
our	O
different	O
models	O
for	O
Table	O
2	O
:	O
Performance	O
of	O
induced	Metric
metrics	Metric
on	O
gold	Metric
and	Metric
system	Metric
outputs	Metric
of	O
RotoWire	Material
development	Material
and	O
test	Material
data	Material
.	O

Columns	O
indicate	O
Record	Metric
Generation	Metric
(	O
RG	Metric
)	O
precision	Metric
and	O
count	Metric
,	O
Content	Method
Selection	Method
(	O
CS	Metric
)	O
precision	Metric
and	O
recall	Metric
,	O
Count	Metric
Ordering	Metric
(	O
CO	Metric
)	O
in	O
normalized	Metric
Damerau	Metric
-	Metric
Levenshtein	Metric
distance	Metric
,	O
perplexity	Metric
,	O
and	O
BLEU	Metric
.	O

These	O
first	O
three	O
metrics	O
are	O
described	O
in	O
Section	O
3.2	O
.	O

Models	O
compare	O
Joint	O
and	O
Conditional	Method
Copy	Method
also	O
with	O
addition	O
Reconstruction	O
loss	O
and	O
Total	O
Variation	O
Distance	O
extensions	O
(	O
described	O
in	O
Section	O
4	O
)	O
.	O

those	O
games	O
.	O

Raters	O
were	O
then	O
asked	O
to	O
count	O
how	O
many	O
facts	O
in	O
each	O
sentence	O
were	O
supported	O
by	O
records	O
in	O
the	O
box	O
or	O
line	O
scores	O
,	O
and	O
how	O
many	O
were	O
contradicted	O
.	O

We	O
randomly	O
selected	O
20	O
distinct	O
games	O
to	O
present	O
to	O
raters	O
,	O
and	O
a	O
total	O
of	O
20	O
generated	O
sentences	O
per	O
game	O
were	O
evaluated	O
by	O
raters	O
.	O

The	O
left	O
two	O
columns	O
of	O
Table	O
3	O
contain	O
the	O
average	O
numbers	O
of	O
supporting	O
and	O
contradicting	O
facts	O
per	O
sentence	O
as	O
determined	O
by	O
the	O
raters	O
,	O
for	O
each	O
model	O
.	O

We	O
see	O
that	O
these	O
results	O
are	O
generally	O
in	O
line	O
with	O
the	O
RG	Metric
and	O
CS	Metric
metrics	Metric
,	O
with	O
the	O
Conditional	Method
Copy	Method
model	Method
having	O
the	O
highest	O
number	O
of	O
supporting	O
facts	O
,	O
and	O
the	O
reconstruction	Method
terms	Method
significantly	O
improving	O
the	O
Joint	Method
Copy	Method
models	Method
.	O

Using	O
a	O
Tukey	Method
HSD	Method
post	Method
-	O
hoc	O
analysis	O
of	O
an	O
ANOVA	Method
with	O
the	O
number	O
of	O
contradicting	O
facts	O
as	O
the	O
dependent	O
variable	O
and	O
the	O
generating	Method
model	Method
and	O
rater	O
i	O
d	O
as	O
independent	O
variables	O
,	O
we	O
found	O
significant	O
(	O
p	O
<	O
0.01	O
)	O
pairwise	O
differences	O
in	O
contradictory	O
facts	O
between	O
the	O
gold	O
generations	O
and	O
all	O
models	O
except	O
"	O
Copy	Method
+	Method
Rec	Method
+	Method
TVD	Method
,	O
"	O
as	O
well	O
as	O
a	O
significant	O
difference	O
between	O
"	O
Copy	O
+	O
Rec	O
+	O
TVD	O
"	O
and	O
"	O
Copy	O
"	O
.	O

We	O
similarly	O
found	O
a	O
significant	O
pairwise	O
difference	O
between	O
"	O
Copy	O
+	O
Rec	O
+	O
TVD	O
"	O
and	O
"	O
Copy	O
"	O
for	O
number	O
of	O
supporting	O
facts	O
.	O

Our	O
second	O
study	O
attempted	O
to	O
determine	O
whether	O
generated	O
summaries	O
differed	O
in	O
terms	O
of	O
how	O
natural	O
their	O
ordering	O
of	O
records	O
(	O
as	O
captured	O
,	O
for	O
instance	O
,	O
by	O
the	O
DLD	Metric
metric	Metric
)	O
is	O
.	O

Table	O
3	O
:	O
Average	O
rater	O
judgment	O
of	O
number	O
of	O
box	O
score	O
fields	O
supporting	O
(	O
left	O
column	O
)	O
or	O
contradicting	O
(	O
middle	O
column	O
)	O
a	O
generated	O
sentence	O
,	O
and	O
average	O
rater	Metric
Likert	Metric
rating	Metric
for	O
the	O
naturalness	O
of	O
a	O
summary	O
's	O
ordering	O
(	O
right	O
column	O
)	O
.	O

All	O
generations	O
use	O
B=1	O
.	O

we	O
presented	O
raters	O
with	O
random	O
summaries	O
generated	O
by	O
our	O
models	O
and	O
asked	O
them	O
to	O
rate	O
the	O
naturalness	O
of	O
the	O
ordering	O
of	O
facts	O
in	O
the	O
summaries	O
on	O
a	O
1	O
-	O
7	O
Likert	O
scale	O
.	O

30	O
random	O
summaries	O
were	O
used	O
in	O
this	O
experiment	O
,	O
each	O
rated	O
3	O
times	O
by	O
distinct	O
raters	O
.	O

The	O
average	O
Likert	O
ratings	O
are	O
shown	O
in	O
the	O
rightmost	O
column	O
of	O
Table	O
3	O
.	O

While	O
it	O
is	O
encouraging	O
that	O
the	O
gold	O
summaries	O
received	O
a	O
higher	O
average	O
score	O
than	O
the	O
generated	O
summaries	O
(	O
and	O
that	O
the	O
reconstruction	O
term	O
again	O
improved	O
the	O
Joint	Method
Copy	Method
model	Method
)	O
,	O
a	O
Tukey	Method
HSD	Method
analysis	Method
similar	O
to	O
the	O
one	O
presented	O
above	O
revealed	O
no	O
significant	O
pairwise	O
differences	O
.	O

section	O
:	O
Qualitative	O
Example	O
Figure	O
2	O
shows	O
a	O
document	O
generated	O
by	O
the	O
Conditional	Method
Copy	Method
model	Method
,	O
using	O
a	O
beam	O
of	O
size	O
5	O
.	O

This	O
particular	O
generation	Task
evidently	O
has	O
several	O
nice	O
properties	O
:	O
it	O
nicely	O
learns	O
the	O
colloquial	O
style	O
of	O
the	O
text	O
,	O
correctly	O
using	O
idioms	O
such	O
as	O
"	O
19	O
percent	O
from	O
deep	O
.	O

"	O
It	O
is	O
also	O
partially	O
accurate	O
in	O
its	O
use	O
of	O
the	O
records	O
;	O
we	O
highlight	O
in	O
blue	O
when	O
it	O
generates	O
text	O
that	O
is	O
licensed	O
by	O
a	O
record	O
in	O
the	O
associated	O
box	O
-	O
and	O
line	O
-	O
scores	O
.	O

At	O
the	O
same	O
time	O
,	O
the	O
generation	Task
also	O
contains	O
major	O
logical	O
errors	O
.	O

First	O
,	O
there	O
are	O
basic	O
copying	O
mistakes	O
,	O
such	O
as	O
flipping	O
the	O
teams	O
'	O
win	O
/	O
loss	O
records	O
.	O

The	O
system	O
also	O
makes	O
obvious	O
semantic	O
errors	O
;	O
for	O
instance	O
,	O
it	O
generates	O
the	O
phrase	O
"	O
the	O
Rockets	O
were	O
able	O
to	O
out	O
-	O
rebound	O
the	O
Rockets	O
.	O

"	O
Finally	O
,	O
we	O
see	O
the	O
model	O
hallucinates	O
factual	O
statements	O
,	O
such	O
as	O
"	O
in	O
front	O
of	O
their	O
home	O
crowd	O
,	O
"	O
which	O
is	O
presumably	O
likely	O
according	O
to	O
the	O
language	Method
model	Method
,	O
but	O
ultimately	O
incorrect	O
(	O
and	O
not	O
supported	O
by	O
anything	O
in	O
the	O
box	O
-	O
or	O
linescores	O
)	O
.	O

In	O
practice	O
,	O
our	O
proposed	O
extractive	Method
evaluation	Method
will	O
pick	O
up	O
on	O
many	O
errors	O
in	O
this	O
passage	O
.	O

For	O
instance	O
,	O
"	O
four	O
assists	O
"	O
is	O
an	O
RG	Metric
error	O
,	O
repeating	O
the	O
Rockets	O
'	O
rebounds	O
could	O
manifest	O
in	O
a	O
lower	O
CO	Metric
score	Metric
,	O
and	O
incorrectly	O
indicating	O
the	O
win	O
/	O
loss	O
records	O
is	O
a	O
CS	Metric
error	O
.	O

section	O
:	O
Related	O
Work	O
In	O
this	O
section	O
we	O
note	O
additional	O
related	O
work	O
not	O
noted	O
throughout	O
.	O

Natural	O
language	O
generation	Task
has	O
been	O
studied	O
for	O
decades	O
[	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
,	O
and	O
generating	Task
summaries	Task
of	Task
sports	Task
games	Task
has	O
been	O
a	O
topic	O
of	O
interest	O
for	O
almost	O
as	O
long	O
[	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
.	O

Historically	O
,	O
research	O
has	O
focused	O
on	O
both	O
content	Method
selection	Method
(	O
"	O
what	O
to	O
say	O
"	O
)	O
[	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
,	O
and	O
surface	Method
realization	Method
(	O
"	O
how	O
to	O
say	O
it	O
"	O
)	O
[	O
reference	O
][	O
reference	O
]	O
with	O
earlier	O
work	O
using	O
(	O
hand	O
-	O
built	O
)	O
grammars	Method
,	O
and	O
later	O
work	O
using	O
SMT	Method
-	O
like	O
approaches	O
[	O
reference	O
]	O
or	O
generating	O
from	O
PCFGs	Method
[	O
reference	O
]	O
or	O
other	O
formalisms	O
[	O
reference	O
][	O
reference	O
]	O
.	O

In	O
the	O
late	O
2000s	O
and	O
early	O
2010s	O
,	O
a	O
number	O
of	O
systems	O
were	O
proposed	O
that	O
did	O
both	O
[	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
.	O

Within	O
the	O
world	O
of	O
neural	Task
text	Task
generation	Task
,	O
some	O
recent	O
work	O
has	O
focused	O
on	O
conditioning	O
language	Method
models	Method
on	O
tables	O
[	O
reference	O
]	O
,	O
and	O
generating	O
short	O
biographies	O
from	O
Wikipedia	Material
Tables	Material
[	O
reference	O
][	O
reference	O
]	O
.	O

[	O
reference	O
]	O
use	O
a	O
neural	O
encoder	Method
-	Method
decoder	Method
approach	Method
on	O
standard	O
record	O
-	O
based	O
generation	Task
datasets	O
,	O
obtaining	O
impressive	O
results	O
,	O
and	O
motivating	O
the	O
need	O
for	O
more	O
challenging	O
NLG	Task
problems	Task
.	O

section	O
:	O
Conclusion	O
and	O
Future	O
Work	O
This	O
work	O
explores	O
the	O
challenges	O
facing	O
neural	Task
data	Task
-	Task
to	Task
-	Task
document	Task
generation	Task
by	O
introducing	O
a	O
new	O
dataset	O
,	O
and	O
proposing	O
various	O
metrics	O
for	O
automatically	O
evaluating	O
content	Method
selection	Method
,	O
generation	Task
,	O
and	O
ordering	Task
.	O

We	O
see	O
that	O
recent	O
ideas	O
in	O
copying	Task
and	Task
reconstruction	Task
lead	O
to	O
improvements	O
on	O
this	O
task	O
,	O
but	O
that	O
there	O
is	O
a	O
significant	O
gap	O
even	O
between	O
these	O
neural	Method
models	Method
and	O
templated	Method
systems	Method
.	O

We	O
hope	O
to	O
motivate	O
researchers	O
to	O
focus	O
further	O
on	O
generation	Task
problems	Task
that	O
are	O
relevant	O
both	O
to	O
content	Method
selection	Method
and	O
surface	Task
realization	Task
,	O
but	O
may	O
not	O
be	O
reflected	O
clearly	O
in	O
the	O
model	O
's	O
perplexity	Metric
.	O

Future	O
work	O
on	O
this	O
task	O
might	O
include	O
approaches	O
that	O
process	O
or	O
attend	O
to	O
the	O
source	O
records	O
in	O
a	O
more	O
sophisticated	O
way	O
,	O
generation	Task
models	O
that	O
attempt	O
to	O
incorporate	O
semantic	O
or	O
reference	O
-	O
related	O
constraints	O
,	O
and	O
approaches	O
to	O
conditioning	O
on	O
facts	O
or	O
records	O
that	O
are	O
not	O
as	O
explicit	O
in	O
the	O
box	O
-	O
and	O
line	O
-	O
scores	O
.	O

section	O
:	O
A.	O
Additional	O
Dataset	O
Details	O
The	O
ROTOWIRE	Material
data	O
covers	O
NBA	Material
games	Material
played	O
between	O
1	O
/	O
1	O
/	O
2014	O
and	O
3	O
/	O
29	O
/	O
2017	O
;	O
some	O
games	O
have	O
multiple	O
summaries	O
.	O

The	O
summaries	O
have	O
been	O
randomly	O
split	O
into	O
training	O
,	O
validation	O
,	O
and	O
test	O
sets	O
consisting	O
of	O
3398	O
,	O
727	O
,	O
and	O
728	O
summaries	O
,	O
respectively	O
.	O

The	O
SBNATION	Material
data	Material
covers	O
NBA	Material
games	Material
played	O
between	O
11	O
/	O
3	O
/	O
2006	O
and	O
3	O
/	O
26	O
/	O
2017	O
;	O
some	O
games	O
have	O
multiple	O
summaries	O
.	O

The	O
summaries	O
have	O
been	O
randomly	O
split	O
into	O
training	O
,	O
validation	O
,	O
and	O
test	O
sets	O
consisting	O
of	O
7633	O
,	O
1635	O
,	O
and	O
1635	O
summaries	O
,	O
respectively	O
.	O

All	O
numbers	O
in	O
the	O
box	O
-	O
and	O
line	O
-	O
scores	O
(	O
but	O
not	O
the	O
summaries	O
)	O
are	O
converted	O
to	O
integers	O
;	O
fractional	O
numbers	O
corresponding	O
to	O
percents	O
are	O
multiplied	O
by	O
100	O
to	O
obtain	O
integers	O
in	O
[	O
reference	O
][	O
reference	O
]	O
.	O

We	O
show	O
the	O
types	O
of	O
records	O
in	O
the	O
data	O
in	O
Table	O
4	O
.	O

section	O
:	O
B.	O
Generation	Method
Model	Method
Details	O
Encoder	Method
For	O
the	O
ROTOWIRE	Material
data	O
,	O
a	O
relation	O
r	O
is	O
encoded	O
intor	O
by	O
embedding	O
each	O
of	O
r.e	O
,	O
r.t	O
,	O
r.m	O
and	O
a	O
"	O
home	O
-	O
or	O
-	O
away	O
"	O
indicator	O
feature	O
in	O
R	O
600	O
,	O
and	O
applying	O
a	O
1	Method
-	Method
layer	Method
MLP	Method
(	O
with	O
ReLU	Method
nonlinearity	Method
)	O
to	O
map	O
the	O
concatenation	O
of	O
these	O
vectors	O
back	O
into	O
R	O
600	O
.	O

To	O
initialize	O
the	O
decoder	Method
LSTMs	Method
,	O
we	O
first	O
mean	O
-	O
pool	O
over	O
ther	O
j	O
by	O
entity	O
(	O
giving	O
one	O
vector	O
per	O
entity	O
)	O
,	O
and	O
then	O
linearly	O
transform	O
the	O
concatenation	O
of	O
these	O
pooled	O
entity	Method
-	Method
representations	Method
so	O
that	O
they	O
can	O
initialize	O
the	O
cells	O
and	O
hidden	O
states	O
of	O
a	O
2	Method
-	Method
layer	Method
LSTM	Method
with	O
states	O
also	O
in	O
R	O
600	O
.	O

The	O
SBNATION	Method
setup	Method
is	O
identical	O
,	O
except	O
all	O
vectors	O
are	O
in	O
R	O
700	O
.	O

Decoder	Method
As	O
mentioned	O
in	O
the	O
body	O
of	O
the	O
paper	O
,	O
we	O
compute	O
two	O
different	O
attention	O
distributions	O
(	O
i.e.	O
,	O
using	O
different	O
parameters	O
)	O
at	O
each	O
decoding	O
step	O
.	O

For	O
the	O
Joint	Method
Copy	Method
model	Method
,	O
one	O
attention	Method
distribution	Method
is	O
not	O
normalized	O
,	O
and	O
is	O
normalized	O
along	O
with	O
all	O
the	O
output	O
-	O
word	O
probabilities	O
.	O

Within	O
the	O
Conditional	Method
Copy	Method
model	Method
we	O
compute	O
p	O
(	O
z	O
t	O
|ŷ	O
1:t−1	O
,	O
s	O
)	O
by	O
mean	Method
-	Method
pooling	Method
ther	O
j	O
,	O
concatenating	O
them	O
with	O
the	O
current	O
(	O
topmost	O
)	O
hidden	O
state	O
of	O
the	O
LSTM	Method
,	O
and	O
then	O
feeding	O
this	O
concatenation	O
via	O
a	O
1	Method
-	Method
layer	Method
ReLU	Method
MLP	Method
with	O
hidden	O
dimension	O
600	O
,	O
and	O
with	O
a	O
Sigmoid	Method
output	Method
layer	Method
.	O

For	O
the	O
reconstruction	Task
-	Task
loss	Task
,	O
we	O
feed	O
blocks	O
(	O
of	O
size	O
at	O
most	O
100	O
)	O
of	O
the	O
decoder	O
's	O
LSTM	O
hidden	O
states	O
through	O
a	O
[	O
reference	O
])-	O
style	Method
convolutional	Method
model	Method
.	O

We	O
use	O
kernels	O
of	O
width	O
3	O
and	O
5	O
,	O
200	O
filters	O
,	O
a	O
ReLU	Method
nonlinearity	Method
,	O
and	O
maxover	Method
-	Method
time	Method
pooling	Method
.	O

To	O
create	O
the	O
p	O
k	O
,	O
these	O
now	O
400	O
-	O
dimensional	O
features	O
are	O
then	O
mapped	O
via	O
an	O
MLP	Method
with	O
a	O
ReLU	Method
nonlinearity	Method
into	O
3	O
separate	O
200	O
dimensional	O
vectors	O
corresponding	O
to	O
the	O
predicted	O
relation	O
's	O
entity	O
,	O
value	O
,	O
and	O
type	O
,	O
respectively	O
.	O

These	O
200	O
dimensional	O
vectors	O
are	O
then	O
fed	O
through	O
(	O
separate	O
)	O
linear	Method
decoders	Method
and	O
softmax	Method
layers	Method
in	O
order	O
to	O
obtain	O
distributions	O
over	O
entities	O
,	O
values	O
,	O
and	O
types	O
.	O

We	O
use	O
K	O
=	O
3	O
distinct	O
p	O
k	O
.	O

Models	O
are	O
trained	O
with	O
SGD	Method
,	O
a	O
learning	Metric
rate	Metric
of	O
1	O
(	O
which	O
is	O
divided	O
by	O
2	O
every	O
time	O
validation	O
perplexity	Metric
fails	O
to	O
decrease	O
)	O
,	O
and	O
a	O
batch	O
size	O
of	O
16	O
.	O

We	O
use	O
dropout	Method
(	O
at	O
a	O
rate	O
of	O
0.5	O
)	O
between	O
LSTM	Method
layers	Method
and	O
before	O
the	O
linear	Method
decoder	Method
.	O

section	O
:	O
C.	O
Information	Task
Extraction	Task
Details	O
Data	O
To	O
form	O
an	O
information	Task
extraction	Task
dataset	Task
,	O
we	O
first	O
sentence	O
-	O
tokenize	O
the	O
gold	O
summary	O
documents	O
y	O
1:T	O
using	O
NLTK	Method
[	O
reference	O
]	O
.	O

We	O
then	O
determine	O
which	O
word	O
-	O
spans	O
y	O
i	O
:	O
j	O
could	O
represent	O
entities	O
(	O
by	O
matching	O
against	O
players	O
,	O
teams	O
,	O
or	O
cities	O
in	O
the	O
database	O
)	O
,	O
and	O
which	O
word	O
-	O
spans	O
y	O
k	O
:	O
l	O
could	O
represent	O
numbers	O
(	O
using	O
the	O
open	O
source	O
text2num	O
library	O
5	O
to	O
convert	O
(	O
strings	O
of	O
)	O
number	O
-	O
words	O
into	O
numbers	O
)	O
.	O

[	O
reference	O
]	O
We	O
then	O
consider	O
each	O
y	O
i	O
:	O
j	O
,	O
y	O
k	O
:	O
l	O
pair	O
in	O
the	O
same	O
sentence	O
,	O
and	O
if	O
there	O
is	O
a	O
record	O
r	O
in	O
the	O
database	O
such	O
that	O
r.e	O
=	O
y	O
i	O
:	O
j	O
and	O
r.m	O
=	O
text2num	O
(	O
y	O
k	O
:	O
l	O
)	O
we	O
annotate	O
the	O
y	O
i	O
:	O
j	O
,	O
y	O
k	O
:	O
l	O
pair	O
with	O
the	O
label	O
r.t	O
;	O
otherwise	O
,	O
we	O
give	O
it	O
a	O
label	O
of	O
ǫ	O
.	O

Model	O
We	O
predict	O
relations	O
by	O
ensembling	O
3	O
convolutional	Method
models	Method
and	O
3	O
bidirectional	Method
LSTM	Method
[	O
reference	Method
][	Method
reference	Method
]	Method
)	Method
models	Method
.	O

Each	O
model	O
consumes	O
the	O
words	O
in	O
the	O
sentence	O
,	O
which	O
are	O
embedded	O
in	O
R	O
200	O
,	O
as	O
well	O
as	O
the	O
distances	O
of	O
each	O
word	O
in	O
the	O
sentence	O
from	O
both	O
the	O
entity	O
-	O
word	O
-	O
span	O
and	O
the	O
number	O
-	O
word	O
-	O
spans	O
(	O
as	O
described	O
above	O
)	O
,	O
which	O
are	O
each	O
embedded	O
in	O
R	O
100	O
.	O

These	O
vectors	O
are	O
concatenated	O
(	O
into	O
a	O
vector	O
in	O
R	O
500	O
)	O
and	O
fed	O
into	O
either	O
a	O
convolutional	Method
model	Method
or	O
a	O
bidirectional	Method
LSTM	Method
model	Method
.	O

The	O
convolutional	Method
model	Method
uses	O
600	O
total	O
filters	O
,	O
with	O
200	O
filters	O
for	O
kernels	O
of	O
width	O
2	O
,	O
3	O
,	O
and	O
5	O
,	O
respectively	O
,	O
a	O
ReLU	Method
nonlinearity	Method
,	O
and	O
maxpooling	Method
.	O

These	O
features	O
are	O
then	O
mapped	O
via	O
a	O
1	O
-	O
section	O
:	O
section	O
:	O
Acknowledgments	O
We	O
gratefully	O
acknowledge	O
the	O
support	O
of	O
a	O
Google	O
Research	O
Award	O
.	O

section	O
:	O
section	O
:	O
Appendix	O
Player	O
Types	O
:	O
Possible	O
Record	Method
Types	Method
layer	Method
(	O
ReLU	Method
)	O
MLP	Method
into	O
R	O
500	O
,	O
which	O
predicts	O
one	O
of	O
the	O
39	O
relation	O
types	O
(	O
or	O
ǫ	O
)	O
with	O
a	O
linear	Method
decoder	Method
layer	Method
and	O
softmax	Method
.	O

The	O
bidirectional	Method
LSTM	Method
model	Method
uses	O
a	O
single	O
layer	O
with	O
500	O
units	O
in	O
each	O
direction	O
,	O
which	O
are	O
concatenated	O
.	O

The	O
hidden	O
states	O
are	O
max	O
-	O
pooled	O
,	O
and	O
then	O
mapped	O
via	O
a	O
1	Method
-	Method
layer	Method
(	Method
ReLU	Method
)	Method
MLP	Method
into	O
R	Method
700	Method
,	O
which	O
predicts	O
one	O
of	O
the	O
39	O
relation	O
types	O
(	O
or	O
ǫ	O
)	O
with	O
a	O
linear	Method
decoder	Method
layer	Method
and	O
softmax	Method
.	O

section	O
:	O
