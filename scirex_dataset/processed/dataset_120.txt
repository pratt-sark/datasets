document	O
:	O
Efficient	O
Piecewise	Method
Training	Method
of	O
Deep	Method
Structured	Method
Models	Method
for	O
Semantic	Task
Segmentation	Task
Recent	O
advances	O
in	O
semantic	Task
image	Task
segmentation	Task
have	O
mostly	O
been	O
achieved	O
by	O
training	O
deep	Method
convolutional	Method
neural	Method
networks	Method
(	O
CNNs	Method
)	O
.	O

We	O
show	O
how	O
to	O
improve	O
semantic	Task
segmentation	Task
through	O
the	O
use	O
of	O
contextual	O
information	O
;	O
specifically	O
,	O
we	O
explore	O
‘	O
patch	O
-	O
patch	O
’	O
context	O
between	O
image	O
regions	O
,	O
and	O
‘	O
patch	O
-	O
background	O
’	O
context	O
.	O

For	O
learning	O
from	O
the	O
patch	O
-	O
patch	O
context	O
,	O
we	O
formulate	O
Conditional	Method
Random	Method
Fields	Method
(	O
CRFs	Method
)	O
with	O
CNN	Method
-	Method
based	Method
pairwise	Method
potential	Method
functions	Method
to	O
capture	O
semantic	O
correlations	O
between	O
neighboring	O
patches	O
.	O

Efficient	O
piecewise	Method
training	Method
of	O
the	O
proposed	O
deep	Method
structured	Method
model	Method
is	O
then	O
applied	O
to	O
avoid	O
repeated	O
expensive	O
CRF	Method
inference	Method
for	O
back	Method
propagation	Method
.	O

For	O
capturing	O
the	O
patch	Task
-	Task
background	Task
context	Task
,	O
we	O
show	O
that	O
a	O
network	Method
design	Method
with	O
traditional	O
multi	O
-	O
scale	O
image	O
input	O
and	O
sliding	Method
pyramid	Method
pooling	Method
is	O
effective	O
for	O
improving	O
performance	O
.	O

Our	O
experimental	O
results	O
set	O
new	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
performance	O
on	O
a	O
number	O
of	O
popular	O
semantic	O
segmentation	O
datasets	O
,	O
including	O
NYUDv2	O
,	O
PASCAL	O
VOC	O
2012	O
,	O
PASCAL	Material
-	Material
Context	Material
,	O
and	O
SIFT	O
-	O
flow	O
.	O

In	O
particular	O
,	O
we	O
achieve	O
an	O
intersection	Metric
-	Metric
over	Metric
-	Metric
union	Metric
score	Metric
of	O
on	O
the	O
challenging	O
PASCAL	O
VOC	O
2012	O
dataset	O
.	O

paragraph	O
:	O
0pt	O
5pt5pt	O
section	O
:	O
Introduction	O
Semantic	Task
image	Task
segmentation	Task
aims	O
to	O
predict	O
a	O
category	O
label	O
for	O
every	O
image	O
pixel	O
,	O
which	O
is	O
an	O
important	O
yet	O
challenging	O
task	O
for	O
image	Task
understanding	Task
.	O

Recent	O
approaches	O
have	O
applied	O
convolutional	Method
neural	Method
network	Method
(	O
CNNs	Method
)	O
to	O
this	O
pixel	Task
-	Task
level	Task
labeling	Task
task	Task
and	O
achieved	O
remarkable	O
success	O
.	O

Among	O
these	O
CNN	Method
-	Method
based	Method
methods	Method
,	O
fully	Method
convolutional	Method
neural	Method
networks	Method
(	O
FCNNs	Method
)	O
have	O
become	O
a	O
popular	O
choice	O
,	O
because	O
of	O
their	O
computational	Metric
efficiency	Metric
for	O
dense	Task
prediction	Task
and	O
end	Task
-	Task
to	Task
-	Task
end	Task
style	Task
learning	Task
.	O

Contextual	O
relationships	O
are	O
ubiquitous	O
and	O
provide	O
important	O
cues	O
for	O
scene	Task
understanding	Task
tasks	Task
.	O

Spatial	O
context	O
can	O
be	O
formulated	O
in	O
terms	O
of	O
semantic	O
compatibility	O
relations	O
between	O
one	O
object	O
and	O
its	O
neighboring	O
objects	O
or	O
image	O
patches	O
(	O
stuff	O
)	O
,	O
in	O
which	O
a	O
compatibility	O
relation	O
is	O
an	O
indication	O
of	O
the	O
co	O
-	O
occurrence	O
of	O
visual	O
patterns	O
.	O

For	O
example	O
,	O
a	O
car	O
is	O
likely	O
to	O
appear	O
over	O
a	O
road	O
,	O
and	O
a	O
glass	O
is	O
likely	O
to	O
appear	O
over	O
a	O
table	O
.	O

Context	O
can	O
also	O
encode	O
incompatibility	O
relations	O
.	O

For	O
example	O
,	O
a	O
car	O
is	O
not	O
likely	O
to	O
be	O
surrounded	O
by	O
sky	O
.	O

These	O
relations	O
also	O
exist	O
at	O
finer	O
scales	O
,	O
for	O
example	O
,	O
in	O
object	O
part	O
-	O
to	O
-	O
part	O
relations	O
,	O
and	O
part	O
-	O
to	O
-	O
object	O
relations	O
.	O

In	O
some	O
cases	O
,	O
contextual	O
information	O
is	O
the	O
most	O
important	O
cue	O
,	O
particularly	O
when	O
a	O
single	O
object	O
shows	O
significant	O
visual	O
ambiguities	O
.	O

A	O
more	O
detailed	O
discussion	O
of	O
the	O
value	O
of	O
spatial	O
context	O
can	O
be	O
found	O
in	O
.	O

We	O
explore	O
two	O
types	O
of	O
spatial	O
context	O
to	O
improve	O
the	O
segmentation	Task
performance	O
:	O
patch	O
-	O
patch	O
context	O
and	O
patch	O
-	O
background	O
context	O
.	O

The	O
patch	O
-	O
patch	O
context	O
is	O
the	O
semantic	O
relation	O
between	O
the	O
visual	O
patterns	O
of	O
two	O
image	O
patches	O
.	O

Likewise	O
,	O
patch	O
-	O
background	O
context	O
is	O
the	O
semantic	O
relation	O
between	O
a	O
patch	O
and	O
a	O
large	O
background	O
region	O
.	O

Explicitly	O
modeling	O
the	O
patch	O
-	O
patch	O
contextual	O
relations	O
has	O
not	O
been	O
well	O
studied	O
in	O
recent	O
CNN	Method
-	Method
based	Method
segmentation	Method
methods	Method
.	O

In	O
this	O
work	O
,	O
we	O
propose	O
to	O
explicitly	O
model	O
the	O
contextual	O
relations	O
using	O
conditional	Method
random	Method
fields	Method
(	O
CRFs	Method
)	O
.	O

We	O
formulate	O
CNN	Method
-	Method
based	Method
pairwise	Method
potential	Method
functions	Method
to	O
capture	O
semantic	O
correlations	O
between	O
neighboring	O
patches	O
.	O

Some	O
recent	O
methods	O
combine	O
CNNs	Method
and	O
CRFs	Method
for	O
semantic	Task
segmentation	Task
,	O
e.g.	O
,	O
the	O
dense	Method
CRFs	Method
applied	O
in	O
.	O

The	O
purpose	O
of	O
applying	O
the	O
dense	Method
CRFs	Method
in	O
these	O
methods	O
is	O
to	O
refine	O
the	O
upsampled	Task
low	Task
-	Task
resolution	Task
prediction	Task
to	O
sharpen	Task
object	Task
/	Task
region	Task
boundaries	Task
.	O

These	O
methods	O
consider	O
Potts	Method
-	Method
model	Method
-	Method
based	Method
pairwise	Method
potentials	Method
for	O
enforcing	O
local	O
smoothness	O
.	O

There	O
the	O
pairwise	O
potentials	O
are	O
conventional	O
log	Method
-	Method
linear	Method
functions	Method
.	O

In	O
contrast	O
,	O
we	O
learn	O
more	O
general	O
pairwise	O
potentials	O
using	O
CNNs	Method
to	O
model	O
the	O
semantic	O
compatibility	O
between	O
image	O
regions	O
.	O

Our	O
CNN	Method
pairwise	Method
potentials	Method
aim	O
to	O
improve	O
the	O
coarse	Task
-	Task
level	Task
prediction	Task
rather	O
than	O
doing	O
local	O
smoothness	O
,	O
and	O
thus	O
have	O
a	O
different	O
purpose	O
compared	O
to	O
Potts	Method
-	Method
model	Method
-	Method
based	Method
pairwise	Method
potentials	Method
.	O

Since	O
these	O
two	O
types	O
of	O
potentials	O
have	O
different	O
effects	O
,	O
they	O
can	O
be	O
combined	O
to	O
improve	O
the	O
segmentation	Task
system	Task
.	O

Fig	O
.	O

[	O
reference	O
]	O
illustrates	O
our	O
prediction	Method
process	Method
.	O

In	O
contrast	O
to	O
patch	O
-	O
patch	O
context	O
,	O
patch	O
-	O
background	O
context	O
is	O
widely	O
explored	O
in	O
the	O
literature	O
.	O

For	O
CNN	Method
-	Method
based	Method
methods	Method
,	O
background	O
information	O
can	O
be	O
effectively	O
captured	O
by	O
combining	O
features	O
from	O
a	O
multi	O
-	O
scale	O
image	O
network	O
input	O
,	O
and	O
has	O
shown	O
good	O
performance	O
in	O
some	O
recent	O
segmentation	Method
methods	Method
.	O

A	O
special	O
case	O
of	O
capturing	Task
patch	Task
-	Task
background	Task
context	Task
is	O
considering	O
the	O
whole	O
image	O
as	O
the	O
background	O
region	O
and	O
incorporating	O
the	O
image	O
-	O
level	O
label	O
information	O
into	O
learning	Task
.	O

In	O
our	O
approach	O
,	O
to	O
encode	O
rich	O
background	O
information	O
,	O
we	O
construct	O
multi	Method
-	Method
scale	Method
networks	Method
and	O
apply	O
sliding	Method
pyramid	Method
pooling	Method
on	O
feature	Method
maps	Method
.	O

The	O
traditional	O
pyramid	Method
pooling	Method
(	O
in	O
a	O
sliding	O
manner	O
)	O
on	O
the	O
feature	O
map	O
is	O
able	O
to	O
capture	O
information	O
from	O
background	O
regions	O
of	O
different	O
sizes	O
.	O

Incorporating	O
general	O
pairwise	O
(	O
or	O
high	O
-	O
order	O
)	O
potentials	O
usually	O
involves	O
expensive	O
inference	Task
,	O
which	O
brings	O
challenges	O
for	O
CRF	Task
learning	Task
.	O

To	O
facilitate	O
efficient	O
learning	Task
we	O
apply	O
piecewise	Method
training	Method
of	O
the	O
CRF	Method
to	O
avoid	O
repeated	Task
inference	Task
during	O
back	Method
propagation	Method
training	Method
.	O

Thus	O
our	O
main	O
contributions	O
are	O
as	O
follows	O
.	O

1	O
.	O

We	O
formulate	O
CNN	Method
-	Method
based	Method
general	Method
pairwise	Method
potential	Method
functions	Method
in	O
CRFs	Method
to	O
explicitly	O
model	O
patch	O
-	O
patch	O
semantic	O
relations	O
.	O

2	O
.	O

Deep	Method
CNN	Method
-	Method
based	Method
general	Method
pairwise	Method
potentials	Method
are	O
challenging	O
for	O
efficient	O
CNN	Task
-	Task
CRF	Task
joint	Task
learning	Task
.	O

We	O
perform	O
approximate	Task
training	Task
,	O
using	O
piecewise	Method
training	Method
of	O
CRFs	O
,	O
to	O
avoid	O
the	O
repeated	O
inference	O
at	O
every	O
stochastic	Method
gradient	Method
descent	O
iteration	O
and	O
thus	O
achieve	O
efficient	O
learning	Task
.	O

3	O
.	O

We	O
explore	O
background	O
context	O
by	O
applying	O
a	O
network	Method
architecture	Method
with	O
traditional	O
multi	O
-	O
scale	O
image	O
input	O
and	O
sliding	Method
pyramid	Method
pooling	Method
.	O

We	O
empirically	O
demonstrate	O
the	O
effectiveness	O
of	O
this	O
network	Method
architecture	Method
for	O
semantic	Task
segmentation	Task
.	O

4	O
.	O

We	O
set	O
new	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
performance	O
on	O
a	O
number	O
of	O
popular	O
semantic	O
segmentation	O
datasets	O
,	O
including	O
NYUDv2	O
,	O
PASCAL	O
VOC	O
2012	O
,	O
PASCAL	Material
-	Material
Context	Material
,	O
and	O
SIFT	O
-	O
flow	O
.	O

In	O
particular	O
,	O
we	O
achieve	O
an	O
intersection	Metric
-	Metric
over	Metric
-	Metric
union	Metric
score	Metric
of	O
on	O
the	O
PASCAL	O
VOC	O
2012	O
dataset	O
,	O
which	O
is	O
the	O
best	O
reported	O
result	O
to	O
date	O
.	O

subsection	O
:	O
Related	O
work	O
Exploiting	O
contextual	O
information	O
has	O
been	O
widely	O
studied	O
in	O
the	O
literature	O
(	O
e.g.	O
,	O
)	O
.	O

For	O
example	O
,	O
the	O
early	O
work	O
“	O
TAS	Method
”	O
models	O
different	O
types	O
of	O
spatial	O
context	O
between	O
Things	O
and	O
Stuff	O
using	O
a	O
generative	Method
probabilistic	Method
graphical	Method
model	Method
.	O

The	O
most	O
successful	O
recent	O
methods	O
for	O
semantic	Task
image	Task
segmentation	Task
are	O
based	O
on	O
CNNs	Method
.	O

A	O
number	O
of	O
these	O
CNN	Method
-	Method
based	Method
methods	Method
for	O
segmentation	Task
are	O
region	Method
-	Method
proposal	Method
-	Method
based	Method
methods	Method
,	O
which	O
first	O
generate	O
region	O
proposals	O
and	O
then	O
assign	O
category	O
labels	O
to	O
each	O
.	O

Very	O
recently	O
,	O
FCNNs	Method
have	O
become	O
a	O
popular	O
choice	O
for	O
semantic	Task
segmentation	Task
,	O
because	O
of	O
their	O
effective	O
feature	Task
generation	Task
and	O
end	Task
-	Task
to	Task
-	Task
end	Task
training	Task
.	O

FCNNs	Method
have	O
also	O
been	O
applied	O
to	O
a	O
range	O
of	O
other	O
dense	Task
-	Task
prediction	Task
tasks	Task
recently	O
,	O
such	O
as	O
image	Task
restoration	Task
,	O
image	Task
super	Task
-	Task
resolution	Task
and	Task
depth	Task
estimation	Task
.	O

The	O
method	O
we	O
propose	O
here	O
is	O
similarly	O
built	O
upon	O
fully	Method
convolution	Method
-	Method
style	Method
networks	Method
.	O

The	O
direct	Method
prediction	Method
of	O
FCNN	Method
based	Method
methods	Method
usually	O
are	O
in	O
low	O
-	O
resolution	O
.	O

To	O
obtain	O
high	Task
-	Task
resolution	Task
predictions	Task
,	O
a	O
number	O
of	O
recent	O
methods	O
focus	O
on	O
refining	O
the	O
low	Task
-	Task
resolution	Task
prediction	Task
to	O
obtain	O
high	Task
resolution	Task
prediction	Task
.	O

DeepLab	Method
-	Method
CRF	Method
performs	O
bilinear	Method
upsampling	Method
of	O
the	O
prediction	O
score	O
map	O
to	O
the	O
input	O
image	O
size	O
and	O
apply	O
the	O
dense	Method
CRF	Method
method	Method
to	O
refine	O
the	O
object	O
boundary	O
by	O
leveraging	O
the	O
color	O
contrast	O
information	O
.	O

CRF	Method
-	Method
RNN	Method
extends	O
this	O
approach	O
by	O
implementing	O
recurrent	Method
layers	Method
for	O
end	Task
-	Task
to	Task
-	Task
end	Task
learning	Task
of	O
the	O
dense	Method
CRF	Method
and	O
the	O
FCNN	Method
network	Method
.	O

The	O
work	O
in	O
learns	O
deconvolution	Method
layers	Method
to	O
upsample	O
the	O
low	Task
-	Task
resolution	Task
predictions	Task
.	O

The	O
depth	Method
estimation	Method
method	Method
explores	O
super	Method
-	Method
pixel	Method
pooling	Method
for	O
building	O
the	O
gap	O
between	O
low	O
-	O
resolution	O
feature	O
map	O
and	O
high	Task
-	Task
resolution	Task
final	Task
prediction	Task
.	O

Eigen	O
et	O
al	O
.	O

perform	O
coarse	Method
-	Method
to	Method
-	Method
fine	Method
learning	Method
of	O
multiple	Method
networks	Method
with	O
different	O
resolution	O
outputs	O
for	O
refining	O
the	O
coarse	Task
prediction	Task
.	O

The	O
methods	O
in	O
explore	O
middle	O
layer	O
features	O
(	O
skip	O
connections	O
)	O
for	O
high	Task
-	Task
resolution	Task
prediction	Task
.	O

Unlike	O
these	O
methods	O
,	O
our	O
method	O
focuses	O
on	O
improving	O
the	O
coarse	Task
(	Task
low	Task
-	Task
resolution	Task
)	Task
prediction	Task
by	O
learning	O
general	Method
CNN	Method
pairwise	Method
potentials	Method
to	O
capture	O
semantic	O
relations	O
between	O
patches	O
.	O

These	O
refinement	Method
methods	Method
are	O
complementary	O
to	O
our	O
method	O
.	O

Combining	O
the	O
strengths	O
of	O
CNNs	Method
and	O
CRFs	Method
for	O
segmentation	Task
has	O
been	O
the	O
focus	O
of	O
several	O
recently	O
developed	O
approaches	O
.	O

DeepLab	Method
-	Method
CRF	Method
in	O
trains	O
FCNNs	Method
and	O
applies	O
a	O
dense	Method
CRF	Method
method	Method
as	O
a	O
post	Task
-	Task
processing	Task
step	Task
.	O

CRF	Method
-	Method
RNN	Method
and	O
the	O
method	O
in	O
extend	O
DeepLab	Method
and	O
by	O
jointly	O
learning	O
the	O
dense	Method
CRFs	Method
and	O
CNNs	Method
.	O

They	O
consider	O
Potts	Method
-	Method
model	Method
based	Method
pairwise	Method
potential	Method
functions	Method
which	O
enforce	O
smoothness	O
only	O
.	O

The	O
CRF	Method
model	Method
in	O
these	O
methods	O
is	O
for	O
refining	O
the	O
up	Task
-	Task
sampled	Task
prediction	Task
.	O

Unlike	O
these	O
methods	O
,	O
our	O
approach	O
learns	O
CNN	Method
-	Method
based	Method
pairwise	Method
potential	Method
functions	Method
for	O
modeling	O
semantic	O
relations	O
between	O
patches	O
.	O

Jointly	O
learning	O
CNNs	Method
and	O
CRFs	Method
has	O
also	O
been	O
explored	O
in	O
other	O
applications	O
apart	O
from	O
segmentation	Task
.	O

The	O
recent	O
work	O
in	O
proposes	O
to	O
jointly	O
learn	O
continuous	Method
CRFs	Method
and	O
CNNs	Method
for	O
depth	Task
estimation	Task
from	O
single	O
monocular	O
images	O
.	O

The	O
work	O
in	O
combines	O
CRFs	Method
and	O
CNNs	Method
for	O
human	Task
pose	Task
estimation	Task
.	O

The	O
authors	O
of	O
explore	O
joint	Method
training	Method
of	O
Markov	Method
random	Method
fields	Method
and	O
deep	Method
neural	Method
networks	Method
for	O
predicting	Task
words	Task
from	O
noisy	O
images	O
and	O
image	Task
s	Task
classification	Task
.	O

Different	O
from	O
these	O
methods	O
,	O
we	O
explore	O
efficient	O
piecewise	Method
training	Method
of	O
CRFs	O
with	O
CNN	Method
pairwise	Method
potentials	Method
.	O

section	O
:	O
Modeling	Task
semantic	Task
pairwise	Task
relations	Task
Fig	O
.	O

[	O
reference	O
]	O
conceptualizes	O
our	O
architecture	O
at	O
a	O
high	O
level	O
.	O

Given	O
an	O
image	O
,	O
we	O
first	O
apply	O
a	O
convolutional	Method
network	Method
to	O
generate	O
a	O
feature	Method
map	Method
.	O

We	O
refer	O
to	O
this	O
network	O
as	O
‘	O
FeatMap	Method
-	Method
Net	Method
’	O
.	O

The	O
resulting	O
feature	O
map	O
is	O
at	O
a	O
lower	O
resolution	O
than	O
the	O
original	O
image	O
because	O
of	O
the	O
down	O
-	O
sampling	O
operations	O
in	O
the	O
pooling	Method
layers	Method
.	O

We	O
then	O
create	O
the	O
CRF	Method
graph	Method
as	O
follows	O
:	O
for	O
each	O
location	O
in	O
the	O
feature	O
map	O
(	O
which	O
corresponds	O
to	O
a	O
rectangular	O
region	O
in	O
the	O
input	O
image	O
)	O
we	O
create	O
one	O
node	O
in	O
the	O
CRF	Method
graph	Method
.	O

Pairwise	O
connections	O
in	O
the	O
CRF	O
graph	O
are	O
constructed	O
by	O
connecting	O
one	O
node	O
to	O
all	O
other	O
nodes	O
which	O
lie	O
within	O
a	O
spatial	O
range	O
box	O
(	O
the	O
dashed	O
box	O
in	O
Fig	O
.	O

[	O
reference	O
]	O
)	O
.	O

We	O
consider	O
different	O
spatial	O
relations	O
by	O
defining	O
different	O
types	O
of	O
range	O
box	O
,	O
and	O
each	O
type	O
of	O
spatial	O
relation	O
is	O
modeled	O
by	O
a	O
specific	O
pairwise	O
potential	O
function	O
.	O

As	O
shown	O
in	O
Fig	O
.	O

[	O
reference	O
]	O
,	O
our	O
method	O
models	O
the	O
“	O
surrounding	O
”	O
and	O
“	O
above	O
/	O
below	O
”	O
spatial	O
relations	O
.	O

In	O
our	O
experiments	O
,	O
the	O
size	O
of	O
the	O
range	O
box	O
(	O
dash	O
box	O
in	O
the	O
figure	O
)	O
size	O
is	O
.	O

Here	O
we	O
denote	O
by	O
the	O
length	O
of	O
the	O
short	O
edge	O
of	O
the	O
feature	O
map	O
.	O

Note	O
that	O
although	O
‘	O
FeatMap	Method
-	Method
Net	Method
’	O
defines	O
a	O
common	O
architecture	O
,	O
in	O
fact	O
we	O
train	O
three	O
such	O
networks	O
:	O
one	O
for	O
the	O
unary	O
potential	O
and	O
one	O
each	O
for	O
the	O
two	O
types	O
of	O
pairwise	O
potential	O
.	O

section	O
:	O
Contextual	Method
Deep	Method
CRFs	Method
Here	O
we	O
describe	O
the	O
details	O
of	O
our	O
deep	Method
CRF	Method
model	Method
.	O

We	O
denote	O
by	O
one	O
input	O
image	O
and	O
the	O
labeling	O
mask	O
which	O
describes	O
the	O
label	O
configuration	O
of	O
each	O
node	O
in	O
the	O
CRF	Method
graph	Method
.	O

The	O
energy	O
function	O
is	O
denoted	O
by	O
which	O
models	O
the	O
compatibility	O
of	O
the	O
input	O
-	O
output	O
pair	O
,	O
with	O
a	O
small	O
output	O
value	O
indicating	O
high	O
confidence	O
in	O
the	O
prediction	Task
.	O

All	O
network	O
parameters	O
are	O
denoted	O
by	O
which	O
we	O
need	O
to	O
learn	O
.	O

The	O
conditional	O
likelihood	O
for	O
one	O
image	O
is	O
formulated	O
as	O
follows	O
:	O
Here	O
is	O
the	O
partition	O
function	O
.	O

The	O
energy	O
function	O
is	O
typically	O
formulated	O
by	O
a	O
set	O
of	O
unary	O
and	O
pairwise	O
potentials	O
:	O
Here	O
is	O
a	O
unary	O
potential	O
function	O
,	O
and	O
to	O
make	O
the	O
exposition	O
more	O
general	O
,	O
we	O
consider	O
multiple	O
types	O
of	O
unary	O
potentials	O
with	O
the	O
set	O
of	O
all	O
such	O
unary	O
potentials	O
.	O

is	O
a	O
set	O
of	O
nodes	O
for	O
the	O
potential	O
.	O

Likewise	O
,	O
is	O
a	O
pairwise	O
potential	O
function	O
with	O
the	O
set	O
of	O
all	O
types	O
of	O
pairwise	O
potential	O
.	O

is	O
the	O
set	O
of	O
edges	O
for	O
the	O
potential	O
.	O

and	O
indicates	O
the	O
corresponding	O
image	O
regions	O
which	O
associate	O
to	O
the	O
specified	O
node	O
and	O
edge	O
.	O

subsection	O
:	O
Unary	O
potential	O
functions	O
We	O
formulate	O
the	O
unary	Method
potential	Method
function	Method
by	O
stacking	O
the	O
FeatMap	Method
-	Method
Net	Method
for	O
generating	O
feature	Task
maps	Task
and	O
a	O
shallow	Method
fully	Method
connected	Method
network	Method
(	O
referred	O
to	O
as	O
Unary	Method
-	Method
Net	Method
)	O
to	O
generate	O
the	O
final	O
output	O
of	O
the	O
unary	O
potential	O
function	O
.	O

The	O
unary	O
potential	O
function	O
is	O
written	O
as	O
follows	O
:	O
Here	O
is	O
the	O
output	O
value	O
of	O
Unary	O
-	O
Net	O
,	O
which	O
corresponds	O
to	O
the	O
-	O
th	O
node	O
and	O
the	O
-	O
th	O
class	O
.	O

Fig	O
.	O

[	O
reference	O
]	O
includes	O
an	O
illustration	O
of	O
the	O
Unary	Method
-	Method
Net	Method
and	O
how	O
it	O
integrates	O
with	O
FeatMap	Method
-	Method
Net	Method
.	O

The	O
unary	O
potential	O
at	O
each	O
CRF	O
node	O
is	O
simply	O
the	O
-	O
dimensional	O
output	O
(	O
where	O
is	O
the	O
number	O
of	O
classes	O
)	O
of	O
Unary	Method
-	Method
Net	Method
applied	O
to	O
the	O
node	O
feature	O
vector	O
from	O
the	O
correpsonding	O
location	O
in	O
the	O
feature	O
map	O
(	O
i.e.	O
the	O
output	O
of	O
FeatMap	Method
-	Method
Net	Method
)	O
.	O

subsection	O
:	O
Pairwise	O
potential	O
functions	O
Fig	O
.	O

[	O
reference	O
]	O
likewise	O
illustrates	O
how	O
the	O
pairwise	O
potentials	O
are	O
generated	O
.	O

The	O
edge	O
features	O
are	O
formed	O
by	O
concatenating	O
the	O
corresponding	O
feature	O
vectors	O
of	O
two	O
connected	O
nodes	O
(	O
similar	O
to	O
)	O
.	O

The	O
feature	O
vector	O
for	O
each	O
node	O
in	O
the	O
pair	O
is	O
from	O
the	O
feature	O
map	O
output	O
by	O
FeatMap	Method
-	Method
Net	Method
.	O

The	O
edge	O
features	O
of	O
one	O
pair	O
are	O
then	O
fed	O
to	O
a	O
shallow	Method
fully	Method
connected	Method
network	Method
(	O
referred	O
to	O
as	O
Pairwise	Method
-	Method
Net	Method
)	O
to	O
generate	O
the	O
final	O
output	O
that	O
is	O
the	O
pairwise	O
potential	O
.	O

The	O
size	O
of	O
this	O
is	O
to	O
match	O
the	O
number	O
of	O
possible	O
label	O
combinations	O
for	O
a	O
pair	O
of	O
nodes	O
.	O

The	O
pairwise	O
potential	O
function	O
is	O
written	O
as	O
follows	O
:	O
Here	O
is	O
the	O
output	O
value	O
of	O
Pairwise	O
-	O
Net	O
.	O

It	O
is	O
the	O
confidence	O
value	O
for	O
the	O
node	O
pair	O
when	O
they	O
are	O
labeled	O
with	O
the	O
class	O
value	O
,	O
which	O
measures	O
the	O
compatibility	O
of	O
the	O
label	O
pair	O
)	O
given	O
the	O
input	O
image	O
.	O

is	O
the	O
corresponding	O
set	O
of	O
CNN	O
parameters	O
for	O
the	O
potential	O
,	O
which	O
we	O
need	O
to	O
learn	O
.	O

Our	O
formulation	O
of	O
pairwise	Task
potentials	Task
is	O
different	O
from	O
the	O
Potts	Method
-	Method
model	Method
-	Method
based	Method
formulation	Method
in	O
the	O
existing	O
methods	O
of	O
.	O

The	O
Potts	Method
-	Method
model	Method
-	Method
based	Method
pairwise	Method
potentials	Method
are	O
a	O
log	Method
-	Method
linear	Method
functions	Method
and	O
employ	O
a	O
special	O
formulation	O
for	O
enforcing	O
neighborhood	Task
smoothness	Task
.	O

In	O
contrast	O
,	O
our	O
pairwise	Method
potentials	Method
model	O
the	O
semantic	O
compatibility	O
between	O
two	O
nodes	O
with	O
the	O
output	O
for	O
every	O
possible	O
value	O
of	O
the	O
label	O
pair	O
)	O
individually	O
parameterized	O
by	O
CNNs	Method
.	O

In	O
our	O
system	O
,	O
after	O
obtaining	O
the	O
coarse	Task
level	Task
prediction	Task
,	O
we	O
still	O
need	O
to	O
perform	O
a	O
refinement	O
step	O
to	O
obtain	O
the	O
final	O
high	Task
-	Task
resolution	Task
prediction	Task
(	O
as	O
shown	O
in	O
Fig	O
.	O

[	O
reference	O
]	O
)	O
.	O

Hence	O
we	O
also	O
apply	O
the	O
dense	Method
CRF	Method
method	Method
,	O
as	O
in	O
many	O
other	O
recent	O
methods	O
,	O
in	O
the	O
prediction	Task
refinement	Task
step	Task
.	O

Therefore	O
,	O
our	O
system	O
takes	O
advantage	O
of	O
both	O
contextual	Method
CNN	Method
potentials	Method
and	O
the	O
traditional	O
smoothness	Method
potentials	Method
to	O
improve	O
the	O
final	O
system	O
.	O

More	O
details	O
are	O
described	O
in	O
Sec	O
.	O

[	O
reference	O
]	O
.	O

As	O
in	O
,	O
modeling	O
asymmetric	O
relations	O
requires	O
the	O
potential	O
function	O
is	O
capable	O
of	O
modeling	O
input	O
orders	O
,	O
since	O
we	O
have	O
:	O
.	O

Take	O
the	O
asymmetric	O
relation	O
“	O
above	O
/	O
below	O
”	O
as	O
an	O
example	O
;	O
we	O
take	O
advantage	O
of	O
the	O
input	O
pair	O
order	O
to	O
indicate	O
the	O
spatial	O
configuration	O
of	O
two	O
nodes	O
,	O
thus	O
the	O
input	O
indicates	O
the	O
configuration	O
that	O
the	O
node	O
is	O
spatially	O
lies	O
above	O
the	O
node	O
.	O

The	O
asymmetric	O
property	O
is	O
readily	O
achieved	O
with	O
our	O
general	O
formulation	Method
of	Method
pairwise	Method
potentials	Method
.	O

The	O
potential	O
output	O
for	O
every	O
possible	O
pairwise	O
label	O
combination	O
for	O
is	O
individually	O
parameterized	O
by	O
the	O
pairwise	O
CNNs	Method
.	O

section	O
:	O
Exploiting	O
background	O
context	O
To	O
encode	O
rich	O
background	O
information	O
,	O
we	O
use	O
multi	O
-	O
scale	O
CNNs	Method
and	O
sliding	Method
pyramid	Method
pooling	Method
for	O
our	O
FeatMap	Method
-	Method
Net	Method
.	O

Fig	O
.	O

[	O
reference	O
]	O
shows	O
the	O
details	O
of	O
the	O
FeatMap	Method
-	Method
Net	Method
.	O

CNNs	Method
with	O
multi	Method
-	Method
scale	Method
image	Method
network	Method
inputs	Method
have	O
shown	O
good	O
performance	O
in	O
some	O
recent	O
segmentation	Method
methods	Method
.	O

The	O
traditional	O
pyramid	Method
pooling	Method
(	O
in	O
a	O
sliding	O
manner	O
)	O
on	O
the	O
feature	O
map	O
is	O
able	O
to	O
capture	O
information	O
from	O
background	O
regions	O
of	O
different	O
sizes	O
.	O

We	O
observe	O
that	O
these	O
two	O
techniques	O
(	O
multi	Method
-	Method
scale	Method
network	Method
design	Method
and	O
pyramid	Method
pooling	Method
)	O
for	O
encoding	Task
background	Task
information	Task
are	O
very	O
effective	O
for	O
improving	O
performance	O
.	O

Applying	O
CNNs	Method
on	O
multi	O
-	O
scale	O
images	O
has	O
shown	O
good	O
performance	O
in	O
some	O
recent	O
segmentation	Method
methods	Method
.	O

In	O
our	O
multi	Method
-	Method
scale	Method
network	Method
,	O
an	O
input	O
image	O
is	O
first	O
resized	O
into	O
scales	O
,	O
then	O
each	O
resized	O
image	O
goes	O
through	O
6	O
convolution	O
blocks	O
to	O
output	O
one	O
feature	O
map	O
.	O

In	O
our	O
experiment	O
,	O
the	O
scales	O
for	O
the	O
input	O
image	O
are	O
set	O
to	O
,	O
and	O
.	O

All	O
scales	O
share	O
the	O
same	O
top	O
convolution	O
blocks	O
.	O

In	O
addition	O
,	O
each	O
scale	O
has	O
an	O
exclusive	O
convolution	Method
block	Method
(	O
“	O
Conv	O
Block	O
6	O
”	O
in	O
the	O
figure	O
)	O
which	O
captures	O
scale	O
-	O
dependent	O
information	O
.	O

The	O
resulting	O
feature	O
maps	O
(	O
corresponding	O
to	O
scales	O
)	O
are	O
of	O
different	O
resolutions	O
,	O
therefore	O
we	O
upscale	O
the	O
two	O
smaller	O
ones	O
to	O
the	O
size	O
of	O
the	O
largest	O
feature	O
map	O
using	O
bilinear	Method
interpolation	Method
.	O

These	O
feature	Method
maps	Method
are	O
then	O
concatenated	O
to	O
form	O
one	O
feature	Method
map	Method
.	O

We	O
perform	O
spatial	Method
pyramid	Method
pooling	Method
(	O
a	O
modified	O
version	O
using	O
sliding	O
windows	O
)	O
on	O
the	O
feature	O
map	O
to	O
capture	O
information	O
from	O
background	O
regions	O
in	O
multiple	O
sizes	O
.	O

This	O
increases	O
the	O
field	O
-	O
of	O
-	O
view	O
for	O
the	O
feature	Method
map	Method
and	O
thus	O
it	O
is	O
able	O
to	O
capture	O
the	O
information	O
from	O
a	O
large	O
image	O
region	O
.	O

Increasing	O
the	O
field	O
-	O
of	O
-	O
view	O
generally	O
helps	O
to	O
improve	O
performance	O
.	O

The	O
details	O
of	O
spatial	Method
pyramid	Method
pooling	Method
are	O
illustrated	O
in	O
Fig	O
.	O

[	O
reference	O
]	O
.	O

In	O
our	O
experiment	O
,	O
we	O
perform	O
-	Method
level	Method
pooling	Method
for	O
each	O
image	O
scale	O
.	O

We	O
define	O
and	O
sliding	Method
pooling	Method
windows	Method
(	O
max	Method
-	Method
pooling	Method
)	O
to	O
generate	O
sets	O
of	O
pooled	O
feature	O
maps	O
,	O
which	O
are	O
then	O
concatenated	O
to	O
the	O
original	O
feature	O
map	O
to	O
construct	O
the	O
final	O
feature	O
map	O
.	O

The	O
detailed	O
network	Method
layer	Method
configuration	Method
for	O
all	O
networks	O
are	O
described	O
in	O
Fig	O
.	O

[	O
reference	O
]	O
.	O

section	O
:	O
Prediction	Task
In	O
the	O
prediction	Task
stage	Task
,	O
our	O
deep	Method
structured	Method
model	Method
will	O
generate	O
low	Task
-	Task
resolution	Task
prediction	Task
(	O
as	O
shown	O
in	O
Fig	O
.	O

[	O
reference	O
]	O
)	O
,	O
which	O
is	O
of	O
the	O
input	O
image	O
size	O
.	O

This	O
is	O
due	O
to	O
the	O
stride	O
setting	O
of	O
pooling	Method
or	Method
convolution	Method
layers	Method
for	O
sub	Method
-	Method
sampling	Method
.	O

Therefore	O
,	O
we	O
apply	O
two	O
prediction	Method
stages	Method
for	O
obtaining	O
the	O
final	O
high	Task
-	Task
resolution	Task
prediction	Task
:	O
the	O
coarse	Method
-	Method
level	Method
prediction	Method
stage	Method
and	O
the	O
prediction	Method
refinement	Method
stage	Method
.	O

subsection	O
:	O
Coarse	Task
-	Task
level	Task
prediction	Task
stage	Task
We	O
perform	O
CRF	Method
inference	Method
on	O
our	O
contextual	Method
structured	Method
model	Method
to	O
obtain	O
the	O
coarse	Task
prediction	Task
of	Task
a	Task
test	Task
image	Task
.	O

We	O
consider	O
the	O
marginal	Task
inference	Task
over	Task
nodes	Task
for	O
prediction	Task
:	O
The	O
obtained	O
marginal	O
distribution	O
can	O
be	O
further	O
applied	O
in	O
the	O
next	O
prediction	Task
stage	Task
for	O
boundary	Task
refinement	Task
.	O

Our	O
CRF	Method
graph	Method
does	O
not	O
form	O
a	O
tree	O
structure	O
,	O
nor	O
are	O
the	O
potentials	O
submodular	O
,	O
hence	O
we	O
need	O
to	O
an	O
apply	O
approximate	Task
inference	Task
.	O

To	O
address	O
this	O
we	O
apply	O
an	O
efficient	O
message	Method
passing	Method
algorithm	Method
which	O
is	O
based	O
on	O
the	O
mean	Method
field	Method
approximation	Method
.	O

The	O
mean	Method
field	Method
algorithm	Method
constructs	O
a	O
simpler	O
distribution	O
,	O
e.g.	O
,	O
a	O
product	O
of	O
independent	O
marginals	O
:	O
,	O
which	O
minimizes	O
the	O
KL	Metric
-	Metric
divergence	Metric
between	O
the	O
distribution	O
and	O
.	O

In	O
our	O
experiments	O
,	O
we	O
perform	O
mean	Method
field	Method
iterations	Method
.	O

subsection	O
:	O
Prediction	Task
refinement	Task
stage	Task
We	O
generate	O
the	O
score	O
map	O
for	O
the	O
coarse	Task
prediction	Task
from	O
the	O
marginal	Method
distribution	Method
which	O
we	O
obtain	O
from	O
the	O
mean	Method
-	Method
field	Method
inference	Method
.	O

We	O
first	O
bilinearly	O
up	O
-	O
sample	O
the	O
score	Method
map	Method
of	O
the	O
coarse	Method
prediction	Method
to	O
the	O
size	O
of	O
the	O
input	O
image	O
.	O

Then	O
we	O
apply	O
a	O
common	O
post	Method
-	Method
processing	Method
method	Method
(	O
dense	Method
CRF	Method
)	O
to	O
sharpen	O
the	O
object	O
boundary	O
for	O
generating	O
the	O
final	O
high	Task
-	Task
resolution	Task
prediction	Task
.	O

This	O
post	Method
-	Method
processing	Method
method	Method
leverages	O
low	O
-	O
level	O
pixel	O
intensity	O
information	O
(	O
color	O
contrast	O
)	O
for	O
boundary	Task
refinement	Task
.	O

Note	O
that	O
most	O
recent	O
work	O
on	O
image	Task
segmentation	Task
similarly	O
produces	O
low	Task
-	Task
resolution	Task
prediction	Task
and	O
have	O
a	O
upsampling	Method
and	Method
refinement	Method
process	Method
/	O
model	O
for	O
the	O
final	O
prediction	Task
,	O
e.g.	O
,	O
.	O

In	O
summary	O
,	O
we	O
simply	O
perform	O
bilinear	Method
upsampling	Method
of	Method
the	Method
coarse	Method
score	Method
map	Method
and	O
apply	O
the	O
boundary	Method
refinement	Method
post	Method
-	Method
processing	Method
.	O

We	O
argue	O
that	O
this	O
stage	O
can	O
be	O
further	O
improved	O
by	O
applying	O
more	O
sophisticated	O
refinement	Method
methods	Method
,	O
e.g.	O
,	O
training	O
deconvolution	Method
networks	Method
,	O
training	O
multiple	O
coarse	Method
to	Method
fine	Method
learning	Method
networks	Method
,	O
and	O
exploring	O
middle	O
layer	O
features	O
for	O
high	Task
-	Task
resolution	Task
prediction	Task
.	O

It	O
is	O
expected	O
that	O
applying	O
better	O
refinement	Method
approaches	Method
will	O
gain	O
further	O
performance	O
improvement	O
.	O

section	O
:	O
CRF	Method
training	Method
A	O
common	O
approach	O
for	O
CRF	Task
learning	Task
is	O
to	O
maximize	O
the	O
likelihood	O
,	O
or	O
equivalently	O
minimize	O
the	O
negative	O
log	O
-	O
likelihood	O
,	O
which	O
can	O
be	O
written	O
for	O
one	O
image	O
as	O
:	O
Adding	O
regularization	O
to	O
the	O
CNN	O
parameter	O
,	O
the	O
optimization	Task
problem	Task
for	O
CRF	Task
learning	Task
is	O
:	O
Here	O
,	O
denote	O
the	O
-	O
th	O
training	O
image	O
and	O
its	O
segmentation	O
mask	O
;	O
is	O
the	O
number	O
of	O
training	O
images	O
;	O
is	O
the	O
weight	O
decay	O
parameter	O
.	O

We	O
can	O
apply	O
stochastic	Method
gradient	Method
(	O
SGD	Method
)	O
based	O
methods	O
to	O
optimize	O
the	O
above	O
problem	O
for	O
learning	Task
.	O

The	O
energy	O
function	O
is	O
constructed	O
from	O
CNNs	Method
,	O
and	O
its	O
gradient	O
easily	O
computed	O
by	O
applying	O
the	O
chain	Method
rule	Method
as	O
in	O
conventional	O
CNNs	Method
.	O

However	O
,	O
the	O
partition	O
function	O
brings	O
difficulties	O
for	O
optimization	Task
.	O

Its	O
gradient	O
is	O
:	O
Generally	O
the	O
size	O
of	O
the	O
output	O
space	O
is	O
exponential	O
in	O
the	O
number	O
of	O
nodes	O
,	O
which	O
prohibits	O
the	O
direct	O
calculation	O
of	O
and	O
its	O
gradient	O
.	O

The	O
CRF	Method
graph	Method
we	O
considered	O
for	O
segmentation	Task
here	O
is	O
a	O
loopy	O
graph	O
(	O
not	O
tree	O
-	O
structured	O
)	O
,	O
for	O
which	O
the	O
inference	Task
is	O
generally	O
computationally	O
expensive	O
.	O

More	O
importantly	O
,	O
usually	O
a	O
large	O
number	O
of	O
SGD	Method
iterations	O
(	O
tens	O
or	O
hundreds	O
of	O
thousands	O
)	O
are	O
required	O
for	O
training	O
CNNs	Method
.	O

Thus	O
performing	O
inference	Task
at	O
each	O
SGD	Method
iteration	O
is	O
very	O
computationally	O
expensive	O
.	O

subsection	O
:	O
Piecewise	Method
training	Method
of	O
CRFs	O
Instead	O
of	O
directly	O
solving	O
the	O
optimization	Task
in	O
(	O
[	O
reference	O
]	O
)	O
,	O
we	O
propose	O
to	O
apply	O
an	O
approximate	Method
CRF	Method
learning	Method
method	Method
.	O

In	O
the	O
literature	O
,	O
there	O
are	O
two	O
popular	O
types	O
of	O
learning	Method
methods	Method
which	O
approximate	O
the	O
CRF	O
objective	O
:	O
pseudo	Method
-	Method
likelihood	Method
learning	Method
and	O
piecewise	Method
learning	Method
.	O

The	O
main	O
advantage	O
of	O
these	O
methods	O
in	O
term	O
of	O
training	Task
deep	Task
CRF	Task
is	O
that	O
they	O
do	O
not	O
involve	O
marginal	Method
inference	Method
for	O
gradient	Task
calculation	Task
,	O
which	O
significantly	O
improves	O
the	O
efficiency	O
of	O
training	Task
.	O

Decision	Method
tree	Method
fields	Method
and	O
regression	Method
tree	Method
fields	Method
are	O
based	O
on	O
pseudo	Method
-	Method
likelihood	Method
learning	Method
,	O
while	O
piecewise	Method
learning	Method
has	O
been	O
applied	O
in	O
the	O
work	O
.	O

Here	O
we	O
develop	O
this	O
idea	O
for	O
the	O
case	O
of	O
training	O
the	O
CRF	Method
with	O
the	O
CNN	O
potentials	O
.	O

In	O
piecewise	Method
training	Method
,	O
the	O
conditional	O
likelihood	O
is	O
formulated	O
as	O
a	O
number	O
of	O
independent	O
likelihoods	O
defined	O
on	O
potentials	O
,	O
written	O
as	O
:	O
The	O
likelihood	O
is	O
constructed	O
from	O
the	O
unary	O
potential	O
.	O

Likewise	O
,	O
is	O
constructed	O
from	O
the	O
pairwise	O
potential	O
.	O

and	O
are	O
written	O
as	O
:	O
Thus	O
the	O
optimization	Task
for	O
piecewise	Method
training	Method
is	O
to	O
minimize	O
the	O
negative	O
log	O
likelihood	O
with	O
regularization	O
:	O
Compared	O
to	O
the	O
objective	O
in	O
(	O
[	O
reference	O
]	O
)	O
for	O
direct	Method
maximum	Method
likelihood	Method
learning	Method
,	O
the	O
above	O
objective	O
does	O
not	O
involve	O
the	O
global	O
partition	O
function	O
.	O

To	O
calculate	O
the	O
gradient	O
of	O
the	O
above	O
objective	O
,	O
we	O
only	O
need	O
to	O
calculate	O
the	O
gradient	O
and	O
.	O

With	O
the	O
definition	O
in	O
(	O
[	O
reference	O
]	O
)	O
,	O
is	O
a	O
conventional	O
Softmax	Method
normalization	Method
function	Method
over	O
only	O
(	O
the	O
number	O
of	O
classes	O
)	O
elements	O
.	O

Similar	O
analysis	O
can	O
also	O
be	O
applied	O
to	O
.	O

Hence	O
,	O
we	O
can	O
easily	O
calculate	O
the	O
gradient	O
without	O
involving	O
expensive	O
inference	Task
.	O

Moreover	O
,	O
we	O
are	O
able	O
to	O
perform	O
parallel	Task
training	Task
of	Task
potential	Task
functions	Task
,	O
since	O
the	O
above	O
objective	O
is	O
formulated	O
as	O
a	O
summation	Method
of	Method
independent	Method
log	Method
-	Method
likelihoods	Method
.	O

As	O
previously	O
discussed	O
,	O
CNN	Task
training	Task
usually	O
involves	O
a	O
large	O
number	O
of	O
gradient	O
update	O
iterations	O
.	O

However	O
this	O
means	O
that	O
expensive	O
inference	Task
during	O
every	O
gradient	Method
iteration	Method
becomes	O
impractical	O
.	O

Our	O
piecewise	Method
approach	Method
here	O
provides	O
a	O
practical	O
solution	O
for	O
learning	Task
CRFs	Task
with	O
CNN	Method
potentials	Method
on	O
large	O
-	O
scale	O
data	O
.	O

section	O
:	O
Experiments	O
We	O
evaluate	O
our	O
method	O
on	O
popular	O
semantic	O
segmentation	O
datasets	O
:	O
PASCAL	O
VOC	O
2012	O
,	O
NYUDv2	O
,	O
PASCAL	Material
-	Material
Context	Material
and	O
SIFT	O
-	O
flow	O
.	O

The	O
segmentation	Task
performance	O
is	O
measured	O
by	O
the	O
intersection	Metric
-	Metric
over	Metric
-	Metric
union	Metric
(	O
IoU	Metric
)	O
score	O
,	O
the	O
pixel	Metric
accuracy	Metric
and	O
the	O
mean	Metric
accuracy	Metric
.	O

The	O
first	O
convolution	O
blocks	O
and	O
the	O
first	O
convolution	O
layer	O
in	O
the	O
th	O
convolution	O
block	O
are	O
initialized	O
from	O
the	O
VGG	Method
-	Method
16	Method
network	Method
.	O

All	O
remaining	O
layers	O
are	O
randomly	O
initialized	O
.	O

All	O
layers	O
are	O
trained	O
using	O
back	Method
-	Method
propagation	Method
/	O
SGD	Method
.	O

As	O
illustrated	O
in	O
Fig	O
.	O

[	O
reference	O
]	O
,	O
we	O
use	O
types	O
of	O
pairwise	O
potential	O
functions	O
.	O

In	O
total	O
,	O
we	O
have	O
1	O
type	O
of	O
unary	O
potential	O
function	O
and	O
2	O
types	O
of	O
pairwise	O
potential	O
functions	O
.	O

We	O
formulate	O
one	O
specific	O
FeatMap	Method
-	Method
Net	Method
and	Method
potential	Method
network	Method
(	O
Unary	Method
-	Method
Net	Method
or	O
Pairwise	Method
-	Method
Net	Method
)	O
for	O
one	O
type	O
of	O
potential	O
function	O
.	O

We	O
apply	O
simple	O
data	Method
augmentation	Method
in	O
the	O
training	O
stage	O
;	O
specifically	O
,	O
we	O
perform	O
random	Method
scaling	Method
(	O
from	O
to	O
)	O
and	O
flipping	O
of	O
the	O
images	O
for	O
training	O
.	O

Our	O
system	O
is	O
built	O
on	O
MatConvNet	Method
.	O

subsection	O
:	O
Results	O
on	O
NYUDv2	O
We	O
first	O
evaluate	O
our	O
method	O
on	O
the	O
dataset	O
NYUDv2	O
.	O

NYUDv2	O
dataset	O
has	O
1449	O
RGB	O
-	O
D	O
images	O
.	O

We	O
use	O
the	O
segmentation	O
labels	O
provided	O
in	O
in	O
which	O
labels	O
are	O
processed	O
into	O
classes	O
.	O

We	O
use	O
the	O
standard	O
training	O
set	O
which	O
contains	O
images	O
and	O
the	O
test	O
set	O
which	O
contains	O
images	O
.	O

We	O
train	O
our	O
models	O
only	O
on	O
RGB	O
images	O
without	O
using	O
the	O
depth	O
information	O
.	O

Results	O
are	O
shown	O
in	O
Table	O
[	O
reference	O
]	O
.	O

Unless	O
otherwise	O
specified	O
,	O
our	O
models	O
are	O
initialized	O
using	O
the	O
VGG	Method
-	Method
16	Method
network	Method
.	O

VGG	O
-	O
16	O
is	O
also	O
used	O
in	O
the	O
competing	Method
method	Method
FCN	Method
.	O

Our	O
contextual	Method
model	Method
with	O
CNN	Method
pairwise	Method
potentials	Method
achieves	O
the	O
best	O
performance	O
,	O
which	O
sets	O
a	O
new	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
result	O
on	O
the	O
NYUDv2	O
dataset	O
.	O

Note	O
that	O
we	O
do	O
not	O
use	O
any	O
depth	O
information	O
in	O
our	O
model	O
.	O

paragraph	O
:	O
Component	Method
Evaluation	Method
We	O
evaluate	O
the	O
performance	O
contribution	O
of	O
different	O
components	O
of	O
the	O
FeatMap	Method
-	Method
Net	Method
for	O
capturing	Task
patch	Task
-	Task
background	Task
context	Task
on	O
the	O
NYUDv2	O
dataset	O
.	O

We	O
present	O
the	O
results	O
of	O
adding	O
different	O
components	O
of	O
FeatMap	Method
-	Method
Net	Method
in	O
Table	O
[	O
reference	O
]	O
.	O

We	O
start	O
from	O
a	O
baseline	O
setting	O
of	O
our	O
FeatMap	Method
-	Method
Net	Method
(	O
“	O
FullyConvNet	Method
Baseline	Method
”	O
in	O
the	O
result	O
table	O
)	O
,	O
for	O
which	O
multi	Method
-	Method
scale	Method
and	Method
sliding	Method
pooling	Method
is	O
removed	O
.	O

This	O
baseline	O
setting	O
is	O
the	O
conventional	O
fully	Method
convolution	Method
network	Method
for	O
segmentation	Task
,	O
which	O
can	O
be	O
considered	O
as	O
our	O
implementation	O
of	O
the	O
FCN	Method
method	Method
in	O
.	O

The	O
result	O
shows	O
that	O
our	O
CNN	Method
baseline	Method
implementation	Method
(	O
“	O
FullyConvNet	Method
”	Method
)	O
achieves	O
very	O
similar	O
performance	O
(	O
slightly	O
better	O
)	O
than	O
the	O
FCN	Method
method	Method
.	O

Applying	O
multi	Method
-	Method
scale	Method
network	Method
design	Method
and	O
sliding	Method
pyramid	Method
pooling	Method
significantly	O
improve	O
the	O
performance	O
,	O
which	O
clearly	O
shows	O
the	O
benefits	O
of	O
encoding	O
rich	O
background	O
context	O
in	O
our	O
approach	O
.	O

Applying	O
the	O
dense	Method
CRF	Method
method	Method
for	O
boundary	Task
refinement	Task
gains	O
further	O
improvement	O
.	O

Finally	O
,	O
adding	O
our	O
contextual	Method
CNN	Method
pairwise	Method
potentials	Method
brings	O
significant	O
further	O
improvement	O
,	O
for	O
which	O
we	O
achieve	O
the	O
best	O
performance	O
in	O
this	O
dataset	O
.	O

aero	O
bike	O
bird	O
boat	O
bottle	O
bus	O
car	O
cat	O
chair	O
cow	O
table	O
dog	O
horse	O
mbike	O
person	O
potted	O
sheep	O
sofa	O
train	O
tv	O
textone12007_001311	O
textone22007_001284	O
textone32007_001430	O
textone42008_000149	O
textone52007_007470	O
textone62007_000762	O
textone72008_000533	O
texttwo12010_000666	O
texttwo22007_000830	O
texttwo32007_009346	O
texttwo42009_003666	O
texttwo52007_002624	O
texttwo62010_005860	O
texttwo72008_003333	O
0.7	O
in	O
img_idx10	O
¡	O
8	O
0.7	O
in	O
img_idx10	O
¡	O
8	O
0.7	O
in	O
img_idx10	O
¡	O
8	O
0.7	O
in	O
img_idx10	O
¡	O
8	O
0.7	O
in	O
img_idx10	O
¡	O
8	O
0.7	O
in	O
img_idx10	O
¡	O
8	O
subsection	O
:	O
Results	O
on	O
PASCAL	O
VOC	O
2012	O
PASCAL	O
VOC	O
2012	O
is	O
a	O
well	O
-	O
known	O
segmentation	O
evaluation	O
dataset	O
which	O
consists	O
of	O
20	O
object	O
categories	O
and	O
one	O
background	O
category	O
.	O

This	O
dataset	O
is	O
split	O
into	O
a	O
training	O
set	O
,	O
a	O
validation	O
set	O
and	O
a	O
test	O
set	O
,	O
which	O
respectively	O
contain	O
,	O
and	O
images	O
.	O

Following	O
a	O
conventional	O
setting	O
in	O
,	O
the	O
training	O
set	O
is	O
augmented	O
by	O
extra	O
annotated	O
VOC	O
images	O
provided	O
in	O
,	O
which	O
results	O
in	O
training	O
images	O
.	O

We	O
verify	O
our	O
performance	O
on	O
the	O
PASCAL	O
VOC	O
2012	O
test	O
set	O
.	O

We	O
compare	O
with	O
a	O
number	O
of	O
recent	O
methods	O
with	O
competitive	O
performance	O
.	O

Since	O
the	O
ground	O
truth	O
labels	O
are	O
not	O
available	O
for	O
the	O
test	O
set	O
,	O
we	O
report	O
the	O
result	O
through	O
the	O
VOC	Metric
evaluation	Metric
server	Metric
.	O

The	O
results	O
of	O
IoU	Metric
scores	O
are	O
shown	O
in	O
the	O
last	O
column	O
of	O
Table	O
[	O
reference	O
]	O
.	O

We	O
first	O
train	O
our	O
model	O
only	O
using	O
the	O
VOC	O
images	O
.	O

We	O
achieve	O
IoU	Metric
score	O
which	O
is	O
the	O
best	O
result	O
amongst	O
methods	O
that	O
only	O
use	O
the	O
VOC	O
training	O
data	O
.	O

To	O
improve	O
the	O
performance	O
,	O
following	O
the	O
setting	O
in	O
recent	O
work	O
,	O
we	O
train	O
our	O
model	O
with	O
the	O
extra	O
images	O
from	O
the	O
COCO	O
dataset	O
.	O

With	O
these	O
extra	O
training	O
images	O
,	O
we	O
achieve	O
an	O
IoU	Metric
score	O
of	O
.	O

For	O
further	O
improvement	O
,	O
we	O
also	O
exploit	O
the	O
the	O
middle	O
-	O
layer	O
features	O
as	O
in	O
the	O
recent	O
methods	O
.	O

We	O
learn	O
extra	O
refinement	O
layers	O
on	O
the	O
feature	O
maps	O
from	O
middle	O
layers	O
to	O
refine	O
the	O
coarse	Task
prediction	Task
.	O

The	O
feature	O
maps	O
from	O
the	O
middle	O
layers	O
encode	O
lower	O
level	O
visual	O
information	O
which	O
helps	O
to	O
predict	O
details	O
in	O
the	O
object	O
boundaries	O
.	O

Specifically	O
,	O
we	O
add	O
refinement	Method
convolution	Method
layers	Method
on	O
top	O
of	O
the	O
feature	O
maps	O
from	O
the	O
first	O
max	Method
-	Method
pooling	Method
layers	Method
and	O
the	O
input	O
image	O
.	O

The	O
resulting	O
feature	O
maps	O
and	O
the	O
coarse	O
prediction	O
score	O
map	O
are	O
then	O
concatenated	O
and	O
go	O
through	O
another	O
refinement	Method
convolution	Method
layers	Method
to	O
output	O
the	O
refined	O
prediction	Task
.	O

The	O
resolution	O
of	O
the	O
prediction	O
is	O
increased	O
from	O
(	O
coarse	Task
prediction	Task
)	O
to	O
of	O
the	O
input	O
image	O
.	O

With	O
this	O
refined	O
prediction	O
,	O
we	O
further	O
perform	O
boundary	Method
refinement	Method
to	O
generate	O
the	O
final	O
prediction	O
.	O

Finally	O
,	O
we	O
achieve	O
an	O
IoU	Metric
score	O
of	O
,	O
which	O
is	O
best	O
reported	O
result	O
on	O
this	O
challenging	O
dataset	O
.	O

The	O
results	O
for	O
each	O
category	O
are	O
shown	O
in	O
Table	O
[	O
reference	O
]	O
.	O

We	O
outperform	O
competing	O
methods	O
in	O
most	O
categories	O
.	O

For	O
only	O
using	O
the	O
VOC	O
training	O
set	O
,	O
our	O
method	O
outperforms	O
the	O
second	O
best	O
method	O
,	O
DPN	Method
,	O
on	O
categories	O
out	O
of	O
.	O

Using	O
VOC	O
+	O
COCO	O
training	O
set	O
,	O
our	O
method	O
outperforms	O
DPN	Method
on	O
categories	O
out	O
of	O
.	O

Some	O
prediction	O
examples	O
of	O
our	O
method	O
are	O
shown	O
in	O
Fig	O
.	O

[	O
reference	O
]	O
.	O

subsection	O
:	O
Results	O
on	O
PASCAL	Material
-	Material
Context	Material
The	O
PASCAL	Material
-	Material
Context	Material
dataset	O
provides	O
the	O
segmentation	O
labels	O
of	O
the	O
whole	O
scene	O
(	O
including	O
the	O
“	O
stuff	O
”	O
labels	O
)	O
for	O
the	O
PASCAL	O
VOC	O
images	O
.	O

We	O
use	O
the	O
segmentation	O
labels	O
which	O
contain	O
classes	O
(	O
classes	O
plus	O
the	O
“	O
background	O
”	O
class	O
)	O
for	O
evaluation	O
.	O

We	O
use	O
the	O
provided	O
training	O
/	O
test	O
splits	O
.	O

The	O
training	O
set	O
contains	O
images	O
and	O
the	O
test	O
set	O
has	O
images	O
.	O

Results	O
are	O
shown	O
in	O
Table	O
[	O
reference	O
]	O
.	O

Our	O
method	O
significantly	O
outperforms	O
the	O
competing	O
methods	O
.	O

To	O
our	O
knowledge	O
,	O
ours	O
is	O
the	O
best	O
reported	O
result	O
on	O
this	O
dataset	O
.	O

subsection	O
:	O
Results	O
on	O
SIFT	Task
-	Task
flow	Task
We	O
further	O
evaluate	O
our	O
method	O
on	O
the	O
SIFT	O
-	O
flow	O
dataset	O
.	O

This	O
dataset	O
contains	O
images	O
and	O
provide	O
the	O
segmentation	O
labels	O
for	O
classes	O
.	O

We	O
use	O
the	O
standard	O
split	O
for	O
training	O
and	O
evaluation	Task
.	O

The	O
training	O
set	O
has	O
images	O
and	O
the	O
rest	O
images	O
are	O
for	O
testing	O
.	O

Since	O
images	O
are	O
in	O
small	O
sizes	O
,	O
we	O
upscale	O
the	O
image	O
by	O
a	O
factor	O
of	O
for	O
training	Task
.	O

Results	O
are	O
shown	O
in	O
Table	O
[	O
reference	O
]	O
.	O

We	O
achieve	O
the	O
best	O
performance	O
for	O
this	O
dataset	O
.	O

section	O
:	O
Conclusions	O
We	O
have	O
proposed	O
a	O
method	O
which	O
combines	O
CNNs	Method
and	O
CRFs	Method
to	O
exploit	O
complex	O
contextual	O
information	O
for	O
semantic	Task
image	Task
segmentation	Task
.	O

We	O
formulate	O
CNN	Method
based	Method
pairwise	Method
potentials	Method
for	O
modeling	Task
semantic	Task
relations	Task
between	Task
image	Task
regions	Task
.	O

Our	O
method	O
shows	O
best	O
performance	O
on	O
several	O
popular	O
datasets	O
including	O
the	O
PASCAL	O
VOC	O
2012	O
dataset	O
.	O

The	O
proposed	O
method	O
is	O
potentially	O
widely	O
applicable	O
to	O
other	O
vision	Task
tasks	Task
.	O

paragraph	O
:	O
Acknowledgments	O
This	O
research	O
was	O
supported	O
by	O
the	O
Data	O
to	O
Decisions	O
Cooperative	O
Research	O
Centre	O
and	O
by	O
the	O
Australian	O
Research	O
Council	O
through	O
the	O
Australian	O
Centre	O
for	O
Robotic	Task
Vision	Task
(	O
CE140100016	O
)	O
.	O

C.	O
Shen	O
’s	O
participation	O
was	O
supported	O
by	O
an	O
ARC	O
Future	O
Fellowship	O
(	O
FT120100969	O
)	O
.	O

I.	O
Reid	O
’s	O
participation	O
was	O
supported	O
by	O
an	O
ARC	O
Laureate	O
Fellowship	O
(	O
FL130100102	O
)	O
.	O

C.	O
Shen	O
is	O
the	O
corresponding	O
author	O
(	O
e	O
-	O
mail	O
:	O
chunhua.shen@adelaide.edu.au	O
)	O
.	O

bibliography	O
:	O
References	O
