document	O
:	O
CyCADA	Method
:	O
Cycle	Method
-	Method
Consistent	Method
Adversarial	Method
Domain	Method
Adaptation	Method
Domain	Task
adaptation	Task
is	O
critical	O
for	O
success	O
in	O
new	O
,	O
unseen	O
environments	O
.	O

Adversarial	Method
adaptation	Method
models	Method
applied	O
in	O
feature	O
spaces	O
discover	O
domain	Method
invariant	Method
representations	Method
,	O
but	O
are	O
difficult	O
to	O
visualize	O
and	O
sometimes	O
fail	O
to	O
capture	O
pixel	Method
-	Method
level	Method
and	O
low	O
-	O
level	O
domain	O
shifts	O
.	O

Recent	O
work	O
has	O
shown	O
that	O
generative	Method
adversarial	Method
networks	Method
combined	O
with	O
cycle	O
-	O
consistency	O
constraints	O
are	O
surprisingly	O
effective	O
at	O
mapping	Task
images	Task
between	Task
domains	Task
,	O
even	O
without	O
the	O
use	O
of	O
aligned	O
image	O
pairs	O
.	O

We	O
propose	O
a	O
novel	O
discriminatively	O
-	O
trained	O
Cycle	Method
-	Method
Consistent	Method
Adversarial	Method
Domain	Method
Adaptation	Method
model	O
.	O

CyCADA	Method
adapts	O
representations	O
at	O
both	O
the	O
pixel	Method
-	Method
level	Method
and	O
feature	Method
-	Method
level	Method
,	O
enforces	O
cycle	O
-	O
consistency	O
while	O
leveraging	O
a	O
task	O
loss	O
,	O
and	O
does	O
not	O
require	O
aligned	O
pairs	O
.	O

Our	O
model	O
can	O
be	O
applied	O
in	O
a	O
variety	O
of	O
visual	Task
recognition	Task
and	Task
prediction	Task
settings	Task
.	O

We	O
show	O
new	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
results	O
across	O
multiple	O
adaptation	Task
tasks	Task
,	O
including	O
digit	Task
classification	Task
and	O
semantic	Task
segmentation	Task
of	Task
road	Task
scenes	Task
demonstrating	O
transfer	Task
from	O
synthetic	O
to	O
real	O
world	O
domains	O
.	O

section	O
:	O
Introduction	O
Deep	Method
neural	Method
networks	Method
excel	O
at	O
learning	O
from	O
large	O
amounts	O
of	O
data	O
,	O
but	O
can	O
be	O
poor	O
at	O
generalizing	O
learned	O
knowledge	O
to	O
new	O
datasets	O
or	O
environments	O
.	O

Even	O
a	O
slight	O
departure	O
from	O
a	O
network	O
’s	O
training	O
domain	O
can	O
cause	O
it	O
to	O
make	O
spurious	O
predictions	O
and	O
significantly	O
hurt	O
its	O
performance	O
tzeng_cvpr17	O
.	O

The	O
visual	Task
domain	Task
shift	Task
from	O
non	O
-	O
photorealistic	O
synthetic	O
data	O
to	O
real	O
images	O
presents	O
an	O
even	O
more	O
significant	O
challenge	O
.	O

While	O
we	O
would	O
like	O
to	O
train	O
models	O
on	O
large	O
amounts	O
of	O
synthetic	O
data	O
such	O
as	O
data	O
collected	O
from	O
graphics	O
game	O
engines	O
,	O
such	O
models	O
fail	O
to	O
generalize	O
to	O
real	O
-	O
world	O
imagery	O
.	O

For	O
example	O
,	O
a	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
semantic	Method
segmentation	Method
model	Method
trained	O
on	O
synthetic	O
dashcam	O
data	O
fails	O
to	O
segment	O
the	O
road	O
in	O
real	O
images	O
,	O
and	O
its	O
overall	O
per	Metric
-	Metric
pixel	Metric
label	Metric
accuracy	Metric
drops	O
from	O
93	O
%	O
(	O
if	O
trained	O
on	O
real	O
imagery	O
)	O
to	O
54	O
%	O
(	O
if	O
trained	O
only	O
on	O
synthetic	O
data	O
,	O
see	O
Table	O
[	O
reference	O
]	O
)	O
.	O

Feature	Method
-	Method
level	Method
unsupervised	Method
domain	Method
adaptation	Method
methods	Method
address	O
this	O
problem	O
by	O
aligning	O
the	O
features	O
extracted	O
from	O
the	O
network	O
across	O
the	O
source	O
(	O
e.g.	O
synthetic	O
)	O
and	O
target	O
(	O
e.g.	O
real	O
)	O
domains	O
,	O
without	O
any	O
labeled	O
target	O
samples	O
.	O

Alignment	Task
typically	O
involves	O
minimizing	O
some	O
measure	O
of	O
distance	O
between	O
the	O
source	O
and	O
target	O
feature	O
distributions	O
,	O
such	O
as	O
maximum	Metric
mean	Metric
discrepancy	Metric
long_icml15	O
,	O
correlation	Metric
distance	Metric
sun_taskcv16	O
,	O
or	O
adversarial	Metric
discriminator	Metric
accuracy	Metric
ganin_icml15	O
,	O
tzeng_cvpr17	O
.	O

This	O
class	O
of	O
techniques	O
suffers	O
from	O
two	O
main	O
limitations	O
.	O

First	O
,	O
aligning	O
marginal	O
distributions	O
does	O
not	O
enforce	O
any	O
semantic	O
consistency	O
,	O
e.g.	O
target	O
features	O
of	O
a	O
car	O
may	O
be	O
mapped	O
to	O
source	O
features	O
of	O
a	O
bicycle	O
.	O

Second	O
,	O
alignment	O
at	O
higher	O
levels	O
of	O
a	O
deep	Method
representation	Method
can	O
fail	O
to	O
model	O
aspects	O
of	O
low	O
-	O
level	O
appearance	O
variance	O
which	O
are	O
crucial	O
for	O
the	O
end	Task
visual	Task
task	Task
.	O

Generative	O
pixel	Method
-	Method
level	Method
domain	O
adaptation	O
models	O
perform	O
similar	O
distribution	Task
alignment	Task
—	O
not	O
in	O
feature	Method
space	Method
but	O
rather	O
in	O
raw	O
pixel	O
space	O
—	O
translating	O
source	O
data	O
to	O
the	O
‘	O
‘	O
style	O
’	O
’	O
of	O
a	O
target	O
domain	O
.	O

Recent	O
methods	O
can	O
learn	O
to	O
translate	O
images	O
given	O
only	O
unsupervised	O
data	O
from	O
both	O
domains	O
bousmalis_cvpr17	O
,	O
liu_arxiv16	O
,	O
shrivastava_cvpr17	O
.	O

The	O
results	O
are	O
visually	O
compelling	O
,	O
but	O
such	O
image	Method
-	Method
space	Method
models	Method
have	O
only	O
been	O
shown	O
to	O
work	O
for	O
small	O
image	O
sizes	O
and	O
limited	O
domain	O
shifts	O
.	O

A	O
more	O
recent	O
approach	O
bousmalis_arxiv17_robotic	O
was	O
applied	O
to	O
larger	O
(	O
but	O
still	O
not	O
high	O
resolution	O
)	O
images	O
,	O
but	O
in	O
a	O
visually	O
controlled	O
image	O
for	O
robotic	Task
applications	Task
.	O

Furthermore	O
,	O
they	O
also	O
do	O
not	O
necessarily	O
preserve	O
content	O
:	O
while	O
the	O
translated	O
image	O
may	O
‘	O
‘	O
look	O
’	O
’	O
like	O
it	O
came	O
from	O
the	O
right	O
domain	O
,	O
crucial	O
semantic	O
information	O
may	O
be	O
lost	O
.	O

For	O
example	O
,	O
a	O
model	O
adapting	O
from	O
line	O
-	O
drawings	O
to	O
photos	O
could	O
learn	O
to	O
make	O
a	O
line	O
-	O
drawing	O
of	O
a	O
cat	O
look	O
like	O
a	O
photo	O
of	O
a	O
dog	O
.	O

How	O
can	O
we	O
encourage	O
the	O
model	O
to	O
preserve	O
semantic	O
information	O
in	O
the	O
process	O
of	O
distribution	Task
alignment	Task
?	O
In	O
this	O
paper	O
,	O
we	O
explore	O
a	O
simple	O
yet	O
powerful	O
idea	O
:	O
give	O
an	O
additional	O
objective	O
to	O
the	O
model	O
to	O
reconstruct	O
the	O
original	O
data	O
from	O
the	O
adapted	O
version	O
.	O

Cycle	Method
-	Method
consistency	Method
was	O
recently	O
proposed	O
in	O
a	O
cross	Method
-	Method
domain	Method
image	Method
generation	Method
GAN	Method
model	Method
,	O
CycleGAN	Method
zhu_arxiv17	O
,	O
which	O
showed	O
transformative	Task
image	Task
-	Task
to	Task
-	Task
image	Task
generation	Task
results	O
,	O
but	O
was	O
agnostic	O
to	O
any	O
particular	O
task	O
.	O

We	O
propose	O
Cycle	Method
-	Method
Consistent	Method
Adversarial	Method
Domain	Method
Adaptation	Method
(	O
CyCADA	Method
)	O
,	O
which	O
adapts	O
representations	O
at	O
both	O
the	O
pixel	Method
-	Method
level	Method
and	O
feature	Method
-	Method
level	Method
while	O
enforcing	O
local	O
and	O
global	O
structural	O
consistency	O
through	O
pixel	O
cycle	O
-	O
consistency	O
and	O
semantic	O
losses	O
.	O

CyCADA	Method
unifies	O
prior	O
feature	Method
-	Method
level	Method
ganin_icml15	O
,	O
tzeng_cvpr17	O
and	O
image	Method
-	Method
level	Method
liu_arxiv16	O
,	O
bousmalis_cvpr17	O
,	O
shrivastava_cvpr17	O
adversarial	Method
domain	Method
adaptation	Method
methods	Method
together	O
with	O
cycle	O
-	O
consistent	O
image	O
-	O
to	O
-	O
image	O
translation	Task
techniques	O
zhu_arxiv17	O
,	O
as	O
illustrated	O
in	O
Table	O
[	O
reference	O
]	O
.	O

It	O
is	O
applicable	O
across	O
a	O
range	O
of	O
deep	Method
architectures	Method
and	O
/	O
or	O
representation	O
levels	O
,	O
and	O
has	O
several	O
advantages	O
over	O
existing	O
unsupervised	Method
domain	Method
adaptation	Method
methods	Method
.	O

We	O
use	O
a	O
reconstruction	O
(	O
cycle	O
-	O
consistency	O
)	O
loss	O
to	O
encourage	O
the	O
cross	Task
-	Task
domain	Task
transformation	Task
to	O
preserve	O
local	O
structural	O
information	O
and	O
a	O
semantic	O
loss	O
to	O
enforce	O
semantic	O
consistency	O
.	O

We	O
apply	O
our	O
CyCADA	Method
model	Method
to	O
the	O
task	O
of	O
digit	Task
recognition	Task
across	Task
domains	Task
and	O
the	O
task	O
of	O
semantic	Task
segmentation	Task
of	Task
urban	Task
scenes	Task
across	O
domains	O
.	O

Experiments	O
show	O
that	O
our	O
model	O
achieves	O
state	O
of	O
the	O
art	O
results	O
on	O
digit	Task
adaptation	Task
,	O
cross	Task
-	Task
season	Task
adaptation	Task
in	O
synthetic	O
data	O
,	O
and	O
on	O
the	O
challenging	O
synthetic	Task
-	Task
to	Task
-	Task
real	Task
scenario	Task
.	O

In	O
the	O
latter	O
case	O
,	O
it	O
improves	O
per	Metric
-	Metric
pixel	Metric
accuracy	Metric
from	O
54	O
%	O
to	O
82	O
%	O
,	O
nearly	O
closing	O
the	O
gap	O
to	O
the	O
target	Method
-	Method
trained	Method
model	Method
.	O

Our	O
experiments	O
confirm	O
that	O
domain	Method
adaptation	Method
can	O
benefit	O
greatly	O
from	O
cycle	O
-	O
consistent	O
pixel	O
transformations	O
,	O
and	O
that	O
this	O
is	O
especially	O
important	O
for	O
pixel	Method
-	Method
level	Method
semantic	O
segmentation	O
with	O
contemporary	O
FCN	Method
architectures	Method
.	O

Further	O
,	O
we	O
show	O
that	O
adaptation	O
at	O
both	O
the	O
pixel	O
and	O
representation	O
level	O
can	O
offer	O
complementary	O
improvements	O
with	O
joint	Method
pixel	Method
-	Method
space	Method
and	O
feature	Method
adaptation	Method
leading	O
to	O
the	O
highest	O
performing	O
model	O
for	O
digit	Task
classification	Task
tasks	Task
.	O

section	O
:	O
Related	O
Work	O
The	O
problem	O
of	O
visual	Task
domain	Task
adaptation	Task
was	O
introduced	O
along	O
with	O
a	O
pairwise	Method
metric	Method
transform	Method
solution	Method
by	O
saenko_eccv10	O
and	O
was	O
further	O
popularized	O
by	O
the	O
broad	O
study	O
of	O
visual	O
dataset	O
bias	O
efros_cvpr11	O
.	O

Early	O
deep	Method
adaptive	Method
works	O
focused	O
on	O
feature	Method
space	Method
alignment	O
through	O
minimizing	O
the	O
distance	O
between	O
first	O
or	O
second	O
order	O
feature	Method
space	Method
statistics	O
of	O
the	O
source	O
and	O
target	O
tzeng_arxiv15	O
,	O
long_icml15	O
.	O

These	O
latent	Method
distribution	Method
alignment	Method
approaches	Method
were	O
further	O
improved	O
through	O
the	O
use	O
of	O
domain	Method
adversarial	Method
objectives	Method
whereby	O
a	O
domain	Method
classifier	Method
is	O
trained	O
to	O
distinguish	O
between	O
the	O
source	O
and	O
target	O
representations	O
while	O
the	O
domain	Method
representation	Method
is	O
learned	O
so	O
as	O
to	O
maximize	O
the	O
error	O
of	O
the	O
domain	Method
classifier	Method
.	O

The	O
representation	O
is	O
optimized	O
using	O
the	O
standard	O
minimax	Method
objective	Method
ganin_icml15	Method
,	O
the	O
symmetric	Method
confusion	Method
objective	Method
tzeng_iccv15	O
,	O
or	O
the	O
inverted	Method
label	Method
objective	Method
tzeng_cvpr17	O
.	O

Each	O
of	O
these	O
objectives	O
is	O
related	O
to	O
the	O
literature	O
on	O
generative	Method
adversarial	Method
networks	Method
goodfellow_nips14	O
and	O
follow	O
-	O
up	O
work	O
for	O
improved	O
training	Method
procedures	Method
for	O
these	O
networks	O
salimans_arxiv16	O
,	O
arjovsky_arxiv17	Method
.	O

The	O
feature	Method
-	Method
space	Method
adaptation	Method
methods	Method
described	O
above	O
focus	O
on	O
modifications	O
to	O
the	O
discriminative	O
representation	O
space	O
.	O

In	O
contrast	O
,	O
other	O
recent	O
methods	O
have	O
sought	O
adaptation	O
in	O
the	O
pixel	O
-	O
space	O
using	O
various	O
generative	Method
approaches	Method
.	O

One	O
advantage	O
of	O
pixel	Method
-	Method
space	Method
adaptation	Method
,	O
as	O
we	O
have	O
shown	O
,	O
is	O
that	O
the	O
result	O
may	O
be	O
more	O
human	O
interpretable	O
,	O
since	O
an	O
image	O
from	O
one	O
domain	O
can	O
now	O
be	O
visualized	O
in	O
a	O
new	O
domain	O
.	O

CoGANs	O
liu_arxiv16	O
jointly	O
learn	O
a	O
source	Method
and	Method
target	Method
representation	Method
through	O
explicit	O
weight	Method
sharing	Method
of	O
certain	O
layers	O
while	O
each	O
source	O
and	O
target	O
has	O
a	O
unique	O
generative	O
adversarial	O
objective	O
.	O

ghifary_eccv16	O
uses	O
an	O
additional	O
reconstruction	O
objective	O
in	O
the	O
target	O
domain	O
to	O
encourage	O
alignment	Task
in	O
the	O
unsupervised	Task
adaptation	Task
setting	Task
.	O

In	O
contrast	O
,	O
another	O
approach	O
is	O
to	O
directly	O
convert	O
the	O
target	O
image	O
into	O
a	O
source	O
style	O
image	O
(	O
or	O
visa	O
versa	O
)	O
,	O
largely	O
based	O
on	O
Generative	Method
Adversarial	Method
Networks	Method
(	O
GANs	Method
)	O
goodfellow_nips14	O
.	O

Researchers	O
have	O
successfully	O
applied	O
GANs	Method
to	O
various	O
applications	O
such	O
as	O
image	Task
generation	Task
denton2015deep	O
,	O
radford2015unsupervised	O
,	O
zhao2016energy	O
,	O
image	Task
editing	Task
zhu2016generative	O
and	O
feature	Task
learning	Task
salimans2016improved	O
,	O
donahue2016adversarial	O
.	O

Recent	O
work	O
isola2016image	O
,	O
sangkloy2016scribbler	O
,	O
karacan2016learning	O
adopt	O
conditional	Method
GANs	Method
mirza_arxiv14	O
for	O
these	O
image	Task
-	Task
to	Task
-	Task
image	Task
translation	Task
problems	Task
isola2016image	O
,	O
but	O
they	O
require	O
input	O
-	O
output	O
image	O
pairs	O
for	O
training	O
,	O
which	O
is	O
in	O
general	O
not	O
available	O
in	O
domain	Task
adaptation	Task
problems	Task
.	O

There	O
also	O
exist	O
lines	O
of	O
work	O
where	O
such	O
training	O
pairs	O
are	O
not	O
given	O
.	O

yoo_eccv16	O
learns	O
a	O
source	O
to	O
target	O
encoder	Method
-	Method
decoder	Method
along	O
with	O
a	O
generative	Method
adversarial	Method
objective	Method
on	O
the	O
reconstruction	Task
which	O
is	O
is	O
applied	O
for	O
predicting	O
the	O
clothing	O
people	O
are	O
wearing	O
.	O

The	O
Domain	Method
Transfer	Method
Network	Method
taigman_iclr17	O
trains	O
a	O
generator	Method
to	O
transform	O
a	O
source	O
image	O
into	O
a	O
target	O
image	O
by	O
enforcing	O
consistency	O
in	O
the	O
embedding	O
space	O
.	O

shrivastava_cvpr17	O
instead	O
uses	O
an	O
L1	Method
reconstruction	Method
loss	Method
to	O
force	O
the	O
generated	O
target	O
images	O
to	O
be	O
similar	O
to	O
their	O
original	O
source	O
images	O
.	O

This	O
works	O
well	O
for	O
limited	O
domain	O
shifts	O
where	O
the	O
domains	O
are	O
similar	O
in	O
pixel	O
-	O
space	O
,	O
but	O
can	O
be	O
too	O
limiting	O
for	O
settings	O
with	O
larger	O
domain	O
shifts	O
.	O

bousmalis_cvpr17	O
use	O
a	O
content	O
similarity	O
loss	O
to	O
ensure	O
the	O
generated	O
target	O
image	O
is	O
similar	O
to	O
the	O
original	O
source	O
image	O
;	O
however	O
,	O
this	O
requires	O
prior	O
knowledge	O
about	O
which	O
parts	O
of	O
the	O
image	O
stay	O
the	O
same	O
across	O
domains	O
(	O
e.g.	O
foreground	O
)	O
.	O

Our	O
method	O
does	O
not	O
require	O
pre	O
-	O
defining	O
what	O
content	O
is	O
shared	O
between	O
domains	O
and	O
instead	O
simply	O
translates	O
images	O
back	O
to	O
their	O
original	O
domains	O
while	O
ensuring	O
that	O
they	O
remain	O
identical	O
to	O
their	O
original	O
versions	O
.	O

BiGAN	O
donahue2016adversarial	O
and	O
ALI	O
dumoulin2016adversarially	O
take	O
an	O
approach	O
of	O
simultaneously	O
learning	O
the	O
transformations	O
between	O
the	O
pixel	O
and	O
the	O
latent	O
space	O
.	O

More	O
recently	O
,	O
Cycle	Method
-	Method
consistent	Method
Adversarial	Method
Networks	Method
(	O
CycleGAN	Method
)	O
zhu_arxiv17	O
produced	O
compelling	O
image	O
translation	Task
results	O
such	O
as	O
generating	O
photorealistic	O
images	O
from	O
impressionism	O
paintings	O
or	O
transforming	O
horses	O
into	O
zebras	O
at	O
high	O
resolution	O
using	O
the	O
cycle	O
-	O
consistency	O
loss	O
.	O

This	O
loss	O
was	O
simultaneously	O
proposed	O
by	O
and	O
to	O
great	O
effect	O
as	O
well	O
.	O

Our	O
motivation	O
comes	O
from	O
such	O
findings	O
about	O
the	O
effectiveness	O
of	O
the	O
cycle	Metric
-	Metric
consistency	Metric
loss	Metric
.	O

Few	O
works	O
have	O
explicitly	O
studied	O
visual	Task
domain	Task
adaptation	Task
for	O
the	O
semantic	Task
segmentation	Task
task	Task
.	O

Adaptation	Task
across	O
weather	O
conditions	O
in	O
simple	O
road	O
scenes	O
was	O
first	O
studied	O
by	O
levinkov_iccv13	O
.	O

More	O
recently	O
,	O
a	O
convolutional	Method
domain	Method
adversarial	Method
based	Method
approached	Method
was	O
proposed	O
for	O
more	O
general	Task
drive	Task
cam	Task
scenes	Task
and	O
for	O
adaptation	Task
from	O
simulated	O
to	O
real	O
environments	O
hoffman_arxiv16	O
.	O

ros_arxiv16	O
learns	O
a	O
multi	Method
-	Method
source	Method
model	Method
through	O
concatenating	O
all	O
available	O
labeled	O
data	O
and	O
learning	O
a	O
single	O
large	Method
model	Method
and	O
then	O
transfers	O
to	O
a	O
sparsely	O
labeled	O
target	O
domain	O
through	O
distillation	O
hinton_arxiv15	O
.	O

chen_iccv17	O
use	O
an	O
adversarial	Method
objective	Method
to	O
align	O
both	O
global	O
and	O
class	O
-	O
specific	O
statistics	O
,	O
while	O
mining	O
additional	O
temporal	O
data	O
from	O
street	O
view	O
datasets	O
to	O
learn	O
a	O
static	O
object	O
prior	O
.	O

zhang_iccv17	O
instead	O
perform	O
segmentation	Method
adaptation	Method
by	O
aligning	O
label	O
distributions	O
both	O
globally	O
and	O
across	O
superpixels	O
in	O
an	O
image	O
.	O

section	O
:	O
Cycle	Method
-	Method
Consistent	Method
Adversarial	Method
Domain	Method
Adaption	Method
We	O
consider	O
the	O
problem	O
of	O
unsupervised	Task
adaptation	Task
,	O
where	O
we	O
are	O
provided	O
source	O
data	O
,	O
source	O
labels	O
,	O
and	O
target	O
data	O
,	O
but	O
no	O
target	O
labels	O
.	O

The	O
goal	O
is	O
to	O
learn	O
a	O
model	O
that	O
can	O
correctly	O
predict	O
the	O
label	O
for	O
the	O
target	O
data	O
.	O

We	O
can	O
begin	O
by	O
simply	O
learning	O
a	O
source	Method
model	Method
that	O
can	O
perform	O
the	O
task	O
on	O
the	O
source	O
data	O
.	O

For	O
-	Task
way	Task
classification	Task
with	O
a	O
cross	Metric
-	Metric
entropy	Metric
loss	Metric
,	O
this	O
corresponds	O
to	O
where	O
denotes	O
the	O
softmax	O
function	O
.	O

However	O
,	O
while	O
the	O
learned	O
model	O
will	O
perform	O
well	O
on	O
the	O
source	O
data	O
,	O
typically	O
domain	O
shift	O
between	O
the	O
source	O
and	O
target	O
domain	O
leads	O
to	O
reduced	O
performance	O
when	O
evaluating	O
on	O
target	O
data	O
.	O

To	O
mitigate	O
the	O
effects	O
of	O
domain	Task
shift	Task
,	O
we	O
follow	O
previous	O
adversarial	Method
adaptation	Method
approaches	Method
and	O
learn	O
to	O
map	O
samples	O
across	O
domains	O
such	O
that	O
an	O
adversarial	Method
discriminator	Method
is	O
unable	O
to	O
distinguish	O
the	O
domains	O
.	O

By	O
mapping	O
samples	O
into	O
a	O
common	O
space	O
,	O
we	O
enable	O
our	O
model	O
to	O
learn	O
on	O
source	O
data	O
while	O
still	O
generalizing	O
to	O
target	O
data	O
.	O

To	O
this	O
end	O
,	O
we	O
introduce	O
a	O
mapping	O
from	O
source	O
to	O
target	O
and	O
train	O
it	O
to	O
produce	O
target	O
samples	O
that	O
fool	O
an	O
adversarial	Method
discriminator	Method
.	O

Conversely	O
,	O
the	O
adversarial	Method
discriminator	Method
attempts	O
to	O
classify	O
the	O
real	O
target	O
data	O
from	O
the	O
source	O
target	O
data	O
.	O

This	O
corresponds	O
to	O
the	O
loss	O
function	O
This	O
objective	O
ensures	O
that	O
,	O
given	O
source	O
samples	O
,	O
produces	O
convincing	O
target	O
samples	O
.	O

In	O
turn	O
,	O
this	O
ability	O
to	O
directly	O
map	O
samples	O
between	O
domains	O
allows	O
us	O
to	O
learn	O
a	O
target	O
model	O
by	O
minimizing	O
(	O
see	O
Figure	O
[	O
reference	O
]	O
green	O
portion	O
)	O
.	O

However	O
,	O
while	O
previous	O
approaches	O
that	O
optimized	O
similar	O
objectives	O
have	O
shown	O
effective	O
results	O
,	O
in	O
practice	O
they	O
can	O
often	O
be	O
unstable	O
and	O
prone	O
to	O
failure	O
.	O

Although	O
the	O
GAN	O
loss	O
in	O
Equation	O
[	O
reference	O
]	O
ensures	O
that	O
for	O
some	O
will	O
resemble	O
data	O
drawn	O
from	O
,	O
there	O
is	O
no	O
way	O
to	O
guarantee	O
that	O
preserves	O
the	O
structure	O
or	O
content	O
of	O
the	O
original	O
sample	O
.	O

In	O
order	O
to	O
encourage	O
the	O
source	O
content	O
to	O
be	O
preserved	O
during	O
the	O
conversion	Task
process	Task
,	O
we	O
impose	O
a	O
cycle	O
-	O
consistency	O
constraint	O
on	O
our	O
adaptation	Method
method	Method
zhu_arxiv17	O
,	O
yi2017dualgan	O
,	O
kim_arxiv17	O
(	O
see	O
Figure	O
[	O
reference	O
]	O
red	O
portion	O
)	O
.	O

To	O
this	O
end	O
,	O
we	O
introduce	O
another	O
mapping	O
from	O
target	O
to	O
source	O
and	O
train	O
it	O
according	O
to	O
the	O
same	O
GAN	O
loss	O
.	O

We	O
then	O
require	O
that	O
mapping	O
a	O
source	O
sample	O
from	O
source	O
to	O
target	O
and	O
back	O
to	O
the	O
source	O
reproduces	O
the	O
original	O
sample	O
,	O
thereby	O
enforcing	O
cycle	O
-	O
consistency	O
.	O

In	O
other	O
words	O
,	O
we	O
want	O
and	O
.	O

This	O
is	O
done	O
by	O
imposing	O
an	O
L1	O
penalty	O
on	O
the	O
reconstruction	Metric
error	Metric
,	O
which	O
is	O
referred	O
to	O
as	O
the	O
cycle	Metric
-	Metric
consistency	Metric
loss	Metric
:	O
Additionally	O
,	O
as	O
we	O
have	O
access	O
to	O
source	O
labeled	O
data	O
,	O
we	O
explicitly	O
encourage	O
high	O
semantic	O
consistency	O
before	O
and	O
after	O
image	O
translation	Task
.	O

We	O
pretrain	O
a	O
source	Method
task	Method
model	Method
,	O
fixing	O
the	O
weights	O
,	O
we	O
use	O
this	O
model	O
as	O
a	O
noisy	O
labeler	O
by	O
which	O
we	O
encourage	O
an	O
image	O
to	O
be	O
classified	O
in	O
the	O
same	O
way	O
after	O
translation	Task
as	O
it	O
was	O
before	O
translation	Task
according	O
to	O
this	O
classifier	Method
.	O

Let	O
us	O
define	O
the	O
predicted	O
label	O
from	O
a	O
fixed	O
classifier	Method
,	O
,	O
for	O
a	O
given	O
input	O
as	O
.	O

Then	O
we	O
can	O
define	O
the	O
semantic	O
consistency	O
before	O
and	O
after	O
image	O
translation	Task
as	O
follows	O
:	O
See	O
Figure	O
[	O
reference	O
]	O
black	O
portion	O
.	O

This	O
can	O
be	O
viewed	O
as	O
analogously	O
to	O
content	Task
losses	Task
in	O
style	Task
transfer	Task
gatys2016image	O
or	O
in	O
pixel	Task
adaptation	Task
dtn	Task
,	O
where	O
the	O
shared	O
content	O
to	O
preserve	O
is	O
dictated	O
by	O
the	O
source	Method
task	Method
model	Method
.	O

We	O
have	O
thus	O
far	O
described	O
an	O
adaptation	Method
method	Method
which	O
combines	O
cycle	O
consistency	O
,	O
semantic	O
consistency	O
,	O
and	O
adversarial	O
objectives	O
to	O
produce	O
a	O
final	O
target	O
model	O
.	O

As	O
a	O
pixel	Method
-	Method
level	Method
method	O
,	O
the	O
adversarial	Method
objective	Method
consists	O
of	O
a	O
discriminator	Method
which	O
distinguishes	O
between	O
two	O
image	O
sets	O
,	O
e.g.	O
transformed	O
source	O
and	O
real	O
target	O
image	O
.	O

Note	O
that	O
we	O
could	O
also	O
consider	O
a	O
feature	Method
-	Method
level	Method
method	Method
which	O
discriminates	O
between	O
the	O
features	O
or	O
semantics	O
from	O
two	O
image	O
sets	O
as	O
viewed	O
under	O
a	O
task	Method
network	Method
.	O

This	O
would	O
amount	O
to	O
an	O
additional	O
feature	Method
level	Method
GAN	O
loss	O
(	O
see	O
Figure	O
[	O
reference	O
]	O
orange	O
portion	O
)	O
:	O
Taken	O
together	O
,	O
these	O
loss	Method
functions	Method
form	O
our	O
complete	O
objective	O
:	O
This	O
ultimately	O
corresponds	O
to	O
solving	O
for	O
a	O
target	O
model	O
according	O
to	O
the	O
optimization	Task
problem	Task
We	O
have	O
introduced	O
a	O
method	O
for	O
unsupervised	Task
adaptation	Task
which	O
generalizes	O
adversarial	O
objectives	O
to	O
be	O
viewed	O
as	O
operating	O
at	O
the	O
pixel	O
or	O
feature	Method
level	Method
.	O

In	O
addition	O
,	O
we	O
introduce	O
the	O
use	O
of	O
cycle	O
-	O
consistency	O
together	O
with	O
semantic	O
transformation	O
constraints	O
to	O
guide	O
the	O
mapping	O
from	O
one	O
domain	O
to	O
another	O
.	O

In	O
this	O
work	O
,	O
we	O
apply	O
CyCADA	Method
to	O
both	O
digit	Task
adaptation	Task
and	O
to	O
semantic	Task
segmentation	Task
.	O

We	O
implement	O
as	O
a	O
pixel	Method
-	Method
to	Method
-	Method
pixel	Method
convnet	Method
,	O
as	O
a	O
convnet	Method
classifier	Method
or	O
a	O
Fully	Method
-	Method
Convolutional	Method
Net	Method
(	O
FCN	Method
)	O
and	O
as	O
a	O
convnet	Method
with	O
binary	O
outputs	O
.	O

section	O
:	O
Experiments	O
We	O
evaluate	O
CyCADA	Method
on	O
several	O
unsupervised	Task
adaptation	Task
scenarios	O
.	O

We	O
first	O
focus	O
on	O
adaptation	Task
for	O
digit	Task
classification	Task
using	O
the	O
MNIST	O
lecun_ieee98	O
,	O
USPS	O
,	O
and	O
Street	O
View	O
House	O
Numbers	O
(	O
SVHN	O
)	O
netzer_nips11	O
datasets	O
.	O

After	O
which	O
we	O
present	O
results	O
for	O
the	O
task	O
of	O
semantic	Task
image	Task
segmentation	Task
,	O
using	O
the	O
SYNTHIA	Material
ros_cvpr16	O
,	O
GTA	O
richter_eccv16	O
and	O
CityScapes	O
cordts_cvpr16	O
datasets	O
.	O

subsection	O
:	O
Digit	Method
Adaptation	Method
We	O
evaluate	O
our	O
method	O
across	O
the	O
adaptation	O
shifts	O
of	O
USPS	O
to	O
MNIST	O
,	O
MNIST	O
to	O
USPS	O
,	O
and	O
SVHN	Material
to	Material
MNIST	Material
,	O
using	O
the	O
full	O
training	O
sets	O
during	O
learning	O
phases	O
and	O
evaluating	O
on	O
the	O
standard	O
test	O
sets	O
.	O

We	O
report	O
classification	Metric
accuracy	Metric
for	O
each	O
shift	O
in	O
Table	O
[	O
reference	O
]	O
and	O
find	O
that	O
our	O
method	O
outperforms	O
competing	O
approaches	O
on	O
average	O
.	O

The	O
classifier	Method
for	O
our	O
method	O
for	O
all	O
digit	Task
shifts	Task
uses	O
a	O
variant	O
of	O
the	O
LeNet	Method
architecture	Method
(	O
see	O
[	O
reference	O
]	O
for	O
full	O
implementation	O
details	O
)	O
.	O

Note	O
that	O
the	O
recent	O
pixel	Method
-	Method
da	Method
method	Method
by	O
bousmalis_cvpr17	O
presents	O
results	O
for	O
only	O
the	O
MNIST	O
to	O
USPS	O
shift	O
and	O
reports	O
95.9	O
%	O
accuracy	Metric
,	O
while	O
our	O
method	O
achieves	O
95.6	O
%	O
accuracy	Metric
.	O

However	O
,	O
the	O
pixel	Method
-	Method
da	Method
approach	Method
cross	O
validates	O
with	O
some	O
labeled	O
data	O
which	O
is	O
not	O
an	O
equivalent	O
evaluation	O
setting	O
.	O

Ablation	O
:	O
Pixel	Method
vs	Method
Feature	Method
Level	Method
Transfer	Method
.	O

We	O
begin	O
by	O
evaluating	O
the	O
contribution	O
of	O
the	O
pixel	O
space	O
and	O
feature	Method
space	Method
transfer	Method
.	O

We	O
find	O
that	O
in	O
the	O
case	O
of	O
the	O
small	O
domain	O
shifts	O
between	O
USPS	O
and	O
MNIST	O
,	O
the	O
pixel	Method
space	Method
adaptation	Method
by	O
which	O
we	O
train	O
a	O
classifier	Method
using	O
images	O
translated	O
using	O
CycleGAN	Method
zhu_arxiv17	O
,	O
performs	O
very	O
well	O
,	O
outperforming	O
or	O
comparable	O
to	O
prior	Method
adaptation	Method
approaches	Method
.	O

Feature	Method
level	Method
adaptation	Method
offers	O
a	O
small	O
benefit	O
in	O
this	O
case	O
of	O
a	O
small	O
pixel	O
shift	O
.	O

However	O
,	O
for	O
the	O
more	O
difficult	O
shift	O
of	O
SVHN	Material
to	Material
MNIST	Material
,	O
we	O
find	O
that	O
feature	Method
level	Method
adaptation	Method
outperforms	O
the	O
pixel	Method
level	Method
adaptation	Method
,	O
and	O
importantly	O
,	O
both	O
may	O
be	O
combined	O
to	O
produce	O
an	O
overall	O
model	O
which	O
outperforms	O
all	O
competing	O
methods	O
.	O

Ablation	Task
:	O
No	O
Semantic	O
Consistency	O
.	O

We	O
experiment	O
without	O
the	O
addition	O
of	O
our	O
semantic	O
consistency	O
loss	O
and	O
find	O
that	O
the	O
standard	O
unsupervised	Method
CycleGAN	Method
approach	Method
diverged	O
when	O
training	O
SVHN	Material
to	Material
MNIST	Material
often	O
suffering	O
from	O
random	O
label	O
flipping	O
.	O

Figure	O
[	O
reference	O
]	O
(	O
a	O
)	O
demonstrates	O
two	O
examples	O
where	O
cycle	O
constraints	O
alone	O
fail	O
to	O
have	O
the	O
desired	O
behavior	O
for	O
our	O
end	O
task	O
.	O

An	O
SVHN	O
image	O
is	O
mapped	O
to	O
a	O
convincing	O
MNIST	O
type	O
image	O
and	O
back	O
to	O
a	O
SVHN	O
image	O
with	O
correct	O
semantics	O
.	O

However	O
,	O
the	O
MNIST	O
-	O
like	O
image	O
has	O
mismatched	O
semantics	O
.	O

Our	O
modified	O
version	O
,	O
which	O
uses	O
the	O
source	O
labels	O
to	O
train	O
a	O
weak	Method
classification	Method
model	Method
which	O
can	O
be	O
used	O
to	O
enforce	O
semantic	O
consistency	O
before	O
and	O
after	O
translation	Task
,	O
resolves	O
this	O
issue	O
and	O
produces	O
strong	O
performance	O
.	O

Ablation	O
:	O
No	O
Cycle	O
Consistency	O
.	O

We	O
study	O
the	O
result	O
when	O
learning	O
without	O
the	O
cycle	O
consistency	O
loss	O
.	O

First	O
note	O
that	O
there	O
is	O
no	O
reconstruction	O
guarantee	O
in	O
this	O
case	O
,	O
thus	O
in	O
Figure	O
[	O
reference	O
]	O
(	O
b	O
)	O
we	O
see	O
that	O
the	O
translation	Task
back	O
to	O
SVHN	O
fails	O
.	O

In	O
addition	O
,	O
we	O
find	O
that	O
while	O
the	O
semantic	O
loss	O
does	O
encourage	O
correct	O
semantics	O
it	O
relies	O
on	O
the	O
weak	O
source	O
labeler	O
and	O
thus	O
label	Task
flipping	Task
still	O
occurs	O
(	O
see	O
right	O
image	O
triple	O
)	O
.	O

subsection	O
:	O
Semantic	Task
Segmentation	Task
Adaptation	Task
The	O
task	O
is	O
to	O
assign	O
a	O
semantic	O
label	O
to	O
each	O
pixel	O
in	O
the	O
input	O
image	O
,	O
e.g.	O
,	O
,	O
etc	O
.	O

We	O
limit	O
our	O
evaluation	O
to	O
the	O
unsupervised	Task
adaptation	Task
setting	Task
,	O
where	O
labels	O
are	O
only	O
available	O
in	O
the	O
source	O
domain	O
,	O
but	O
we	O
are	O
evaluated	O
solely	O
on	O
our	O
performance	O
in	O
the	O
target	O
domain	O
.	O

For	O
each	O
experiment	O
,	O
we	O
use	O
three	O
metrics	O
to	O
evaluate	O
performance	O
.	O

Let	O
be	O
the	O
number	O
of	O
pixels	O
of	O
class	O
predicted	O
as	O
class	O
,	O
let	O
be	O
the	O
total	O
number	O
of	O
pixels	O
of	O
class	O
,	O
and	O
let	O
be	O
the	O
number	O
of	O
classes	O
.	O

Our	O
three	O
evaluation	Metric
metrics	Metric
are	O
,	O
mean	Metric
intersection	Metric
-	Metric
over	Metric
-	Metric
union	Metric
(	O
mIoU	Metric
)	O
,	O
frequency	Metric
weighted	Metric
intersection	Metric
-	Metric
over	Metric
-	Metric
union	Metric
(	O
fwIoU	Metric
)	O
,	O
and	O
pixel	Metric
accuracy	Metric
,	O
which	O
are	O
defined	O
as	O
follows	O
:	O
mIoU	Metric
,	O
fwIoU	Metric
,	O
pixel	Metric
acc	Metric
.	O

.	O

Cycle	Method
-	Method
consistent	Method
adversarial	Method
adaptation	Method
is	O
general	O
and	O
can	O
be	O
applied	O
at	O
any	O
layer	O
of	O
a	O
network	O
.	O

Since	O
optimizing	O
the	O
full	O
CyCADA	Method
objective	Method
in	O
Equation	O
[	O
reference	O
]	O
end	O
-	O
to	O
-	O
end	O
is	O
memory	O
-	O
intensive	O
in	O
practice	O
,	O
we	O
train	O
our	O
model	O
in	O
stages	O
.	O

First	O
,	O
we	O
perform	O
image	Method
-	Method
space	Method
adaptation	Method
and	O
map	O
our	O
source	O
data	O
into	O
the	O
target	O
domain	O
.	O

Next	O
,	O
using	O
the	O
adapted	O
source	O
data	O
with	O
the	O
original	O
source	O
labels	O
,	O
we	O
learn	O
a	O
task	Method
model	Method
that	O
is	O
suited	O
to	O
operating	O
on	O
target	O
data	O
.	O

Finally	O
,	O
we	O
perform	O
another	O
round	O
of	O
adaptation	Task
between	O
the	O
adapted	O
source	O
data	O
and	O
the	O
target	O
data	O
in	O
feature	O
-	O
space	O
,	O
using	O
one	O
of	O
the	O
intermediate	Method
layers	Method
of	O
the	O
task	Method
model	Method
.	O

Additionally	O
,	O
we	O
do	O
not	O
use	O
the	O
semantic	O
loss	O
for	O
the	O
segmentation	Task
experiments	O
as	O
it	O
would	O
require	O
loading	O
generators	Method
,	O
discriminators	Method
,	O
and	O
an	O
additional	O
semantic	Method
segmenter	Method
into	O
memory	O
all	O
at	O
once	O
for	O
two	O
images	O
.	O

We	O
did	O
not	O
have	O
the	O
required	O
memory	O
for	O
this	O
at	O
the	O
time	O
of	O
submission	O
,	O
but	O
leave	O
it	O
to	O
future	O
work	O
to	O
deploy	O
model	Method
parallelism	Method
or	O
experiment	O
with	O
larger	O
GPU	O
memory	O
.	O

For	O
our	O
first	O
evaluation	O
,	O
we	O
consider	O
the	O
SYNTHIA	Material
dataset	Material
ros_cvpr16	O
,	O
which	O
contains	O
synthetic	O
renderings	O
of	O
urban	O
scenes	O
.	O

We	O
use	O
the	O
SYNTHIA	Material
video	Material
sequences	Material
,	O
which	O
are	O
rendered	O
across	O
a	O
variety	O
of	O
environments	O
,	O
weather	O
conditions	O
,	O
and	O
lighting	O
conditions	O
.	O

This	O
provides	O
a	O
synthetic	O
testbed	O
for	O
evaluating	O
adaptation	Method
techniques	Method
.	O

For	O
comparison	O
with	O
previous	O
work	O
,	O
in	O
this	O
work	O
we	O
focus	O
on	O
adaptation	O
between	O
seasons	O
.	O

We	O
use	O
only	O
the	O
front	O
-	O
facing	O
views	O
in	O
the	O
sequences	O
so	O
as	O
to	O
mimic	O
dashcam	O
imagery	O
,	O
and	O
adapt	O
from	O
fall	O
to	O
winter	O
.	O

The	O
subset	O
of	O
the	O
dataset	O
we	O
use	O
contains	O
13	O
classes	O
and	O
consists	O
of	O
10	O
,	O
852	O
fall	Material
images	Material
and	O
7	O
,	O
654	O
winter	Material
images	Material
.	O

To	O
further	O
demonstrate	O
our	O
method	O
’s	O
applicability	O
to	O
real	Task
-	Task
world	Task
adaptation	Task
scenarios	Task
,	O
we	O
also	O
evaluate	O
our	O
model	O
in	O
a	O
challenging	O
synthetic	Task
-	Task
to	Task
-	Task
real	Task
adaptation	Task
setting	Task
.	O

For	O
our	O
synthetic	O
source	O
domain	O
,	O
we	O
use	O
the	O
GTA5	O
dataset	O
richter_eccv16	O
extracted	O
from	O
the	O
game	O
Grand	O
Theft	O
Auto	O
V	O
,	O
which	O
contains	O
24966	O
images	O
.	O

We	O
consider	O
adaptation	Task
from	O
GTA5	Material
to	Material
the	Material
real	Material
-	Material
world	Material
Cityscapes	Material
dataset	Material
cordts_cvpr16	O
,	O
from	O
which	O
we	O
used	O
19998	O
images	O
without	O
annotation	O
for	O
training	O
and	O
500	O
images	O
for	O
validation	Task
.	O

Both	O
of	O
these	O
datasets	O
are	O
evaluated	O
on	O
the	O
same	O
set	O
of	O
19	O
classes	O
,	O
allowing	O
for	O
straightforward	O
adaptation	O
between	O
the	O
two	O
domains	O
.	O

Image	Method
-	Method
space	Method
adaptation	Method
also	O
affords	O
us	O
the	O
ability	O
to	O
visually	O
inspect	O
the	O
results	O
of	O
the	O
adaptation	Method
method	Method
.	O

This	O
is	O
a	O
distinct	O
advantage	O
over	O
opaque	O
feature	Method
-	Method
space	Method
adaptation	Method
methods	Method
,	O
especially	O
in	O
truly	O
unsupervised	Task
settings	Task
—	O
without	O
labels	O
,	O
there	O
is	O
no	O
way	O
to	O
empirically	O
evaluate	O
the	O
adapted	O
model	O
,	O
and	O
thus	O
no	O
way	O
to	O
verify	O
that	O
adaptation	Method
is	O
improving	O
task	Task
performance	O
.	O

Visually	O
confirming	O
that	O
the	O
conversions	O
between	O
source	O
and	O
target	O
images	O
are	O
reasonable	O
,	O
while	O
not	O
a	O
guarantee	O
of	O
improved	O
task	O
performance	O
,	O
can	O
serve	O
as	O
a	O
sanity	O
check	O
to	O
ensure	O
that	O
adaptation	Task
is	O
not	O
completely	O
diverging	O
.	O

This	O
process	O
is	O
diagrammed	O
in	O
Figure	O
[	O
reference	O
]	O
.	O

For	O
implementation	O
details	O
please	O
see	O
Appendix	O
[	O
reference	O
]	O
.	O

subsubsection	O
:	O
Cross	O
-	O
season	O
adaptation	O
We	O
start	O
by	O
exploring	O
the	O
abilities	O
of	O
pixel	Method
space	Method
adaptation	Method
alone	O
(	O
using	O
FCN8s	Method
architecture	Method
)	O
for	O
the	O
setting	O
of	O
adapting	O
across	O
seasons	O
in	O
synthetic	O
data	O
.	O

For	O
this	O
we	O
use	O
the	O
SYNTHIA	Material
dataset	Material
and	O
adapt	O
from	O
fall	O
to	O
winter	O
weather	O
conditions	O
.	O

Typically	O
in	O
unsupervised	Task
adaptation	Task
settings	O
it	O
is	O
difficult	O
to	O
interpret	O
what	O
causes	O
the	O
performance	O
improvement	O
after	O
adaptation	Task
.	O

Therefore	O
,	O
we	O
use	O
this	O
setting	O
as	O
an	O
example	O
where	O
we	O
may	O
directly	O
visualize	O
the	O
shift	O
from	O
fall	O
to	O
winter	O
and	O
inspect	O
the	O
intermediate	O
pixel	O
level	O
adaptation	O
result	O
from	O
our	O
algorithm	O
.	O

In	O
Figure	O
[	O
reference	O
]	O
we	O
show	O
the	O
result	O
of	O
pixel	Method
only	Method
adaptation	Method
as	O
we	O
generate	O
a	O
winter	Material
domain	Material
image	Material
(	O
b	O
)	O
from	O
a	O
fall	Material
domain	Material
image	Material
(	O
a	O
)	O
,	O
and	O
visa	O
versa	O
(	O
c	O
-	O
d	O
)	O
.	O

We	O
may	O
clearly	O
see	O
the	O
changes	O
of	O
adding	O
or	O
removing	O
snow	O
.	O

This	O
visually	O
interpretable	O
result	O
matches	O
our	O
expectation	O
of	O
the	O
true	O
shift	O
between	O
these	O
domains	O
and	O
indeed	O
results	O
in	O
favorable	O
final	O
semantic	Task
segmentation	Task
performance	O
from	O
fall	O
to	O
winter	O
as	O
shown	O
in	O
Table	O
[	O
reference	O
]	O
.	O

We	O
find	O
that	O
CyCADA	Method
achieves	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
performance	O
on	O
this	O
task	O
with	O
image	Method
space	Method
adaptation	Method
alone	O
,	O
however	O
does	O
not	O
recover	O
full	O
supervised	Method
learning	Method
performance	O
(	O
train	O
on	O
target	O
)	O
.	O

Some	O
example	O
errors	O
includes	O
adding	O
snow	O
to	O
the	O
sidewalks	O
,	O
but	O
not	O
to	O
the	O
road	O
,	O
while	O
in	O
the	O
true	O
winter	O
domain	O
snow	O
appears	O
in	O
both	O
locations	O
.	O

However	O
,	O
even	O
this	O
mistake	O
is	O
interesting	O
as	O
it	O
implies	O
that	O
the	O
model	O
is	O
learning	O
to	O
distinguish	O
road	O
from	O
sidewalk	O
during	O
pixel	Task
adaptation	Task
,	O
despite	O
the	O
lack	O
of	O
pixel	O
annotations	O
.	O

sky	O
building	O
road	O
sidewalk	O
fence	O
vegetation	O
pole	O
car	O
traffic	O
sign	O
pedestrian	O
bicycle	O
lanemarking	O
traffic	O
light	O
mIoU	Metric
fwIoU	O
Pixel	O
acc	O
.	O

Cycle	Method
-	Method
consistent	Method
adversarial	Method
adaptation	Method
achieves	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
adaptation	Metric
performance	Metric
.	O

We	O
see	O
that	O
under	O
the	O
fwIoU	Metric
and	O
pixel	Metric
accuracy	Metric
metrics	O
,	O
CyCADA	Method
approaches	O
oracle	O
performance	O
,	O
falling	O
short	O
by	O
only	O
a	O
few	O
points	O
,	O
despite	O
being	O
entirely	O
unsupervised	O
.	O

This	O
indicates	O
that	O
CyCADA	Method
is	O
extremely	O
effective	O
at	O
correcting	O
the	O
most	O
common	O
classes	O
in	O
the	O
dataset	O
.	O

This	O
conclusion	O
is	O
supported	O
by	O
inspection	O
of	O
the	O
individual	O
classes	O
in	O
Table	O
[	O
reference	O
]	O
,	O
where	O
we	O
see	O
the	O
largest	O
improvement	O
on	O
common	O
classes	O
such	O
as	O
road	O
and	O
sidewalk	O
.	O

Architecture	O
road	O
sidewalk	O
building	O
wall	O
fence	O
pole	O
traffic	O
light	O
traffic	O
sign	O
vegetation	O
terrain	O
sky	O
person	O
rider	O
car	O
truck	O
bus	O
train	O
motorbike	O
bicycle	O
mIoU	Metric
fwIoU	O
Pixel	O
acc	O
.	O

subsubsection	O
:	O
Synthetic	O
to	O
real	Task
adaptation	Task
To	O
evaluate	O
our	O
method	O
’s	O
applicability	O
to	O
real	Task
-	Task
world	Task
adaptation	Task
settings	Task
,	O
we	O
investigate	O
adaptation	Task
from	O
synthetic	O
to	O
real	O
-	O
world	O
imagery	O
.	O

The	O
results	O
of	O
this	O
evaluation	O
are	O
presented	O
in	O
Table	O
[	O
reference	O
]	O
with	O
qualitative	O
results	O
shown	O
in	O
Figure	O
[	O
reference	O
]	O
.	O

Once	O
again	O
,	O
CyCADA	Method
achieves	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
results	O
,	O
recovering	O
approximately	O
40	O
%	O
of	O
the	O
performance	O
lost	O
to	O
domain	O
shift	O
.	O

CyCADA	Method
also	O
improves	O
or	O
maintains	O
performance	O
on	O
all	O
19	O
classes	O
.	O

Examination	O
of	O
fwIoU	Metric
and	O
pixel	Metric
accuracy	Metric
as	O
well	O
as	O
individual	O
class	Metric
IoUs	Metric
reveals	O
that	O
our	O
method	O
performs	O
well	O
on	O
most	O
of	O
the	O
common	O
classes	O
.	O

Although	O
some	O
classes	O
such	O
as	O
train	O
and	O
bicycle	O
see	O
little	O
or	O
no	O
improvement	O
,	O
we	O
note	O
that	O
those	O
classes	O
are	O
poorly	O
represented	O
in	O
the	O
GTA5	O
data	O
,	O
making	O
recognition	Task
very	O
difficult	O
.	O

We	O
compare	O
our	O
model	O
against	O
shrivastava_cvpr17	O
for	O
this	O
setting	O
,	O
but	O
found	O
this	O
approach	O
did	O
not	O
converge	O
and	O
resulted	O
in	O
worse	O
performance	O
than	O
the	O
source	Method
only	Method
model	Method
(	O
see	O
Appendix	O
for	O
full	O
details	O
)	O
.	O

We	O
visualize	O
the	O
results	O
of	O
image	Task
-	Task
space	Task
adaptation	Task
between	O
GTA5	Method
and	O
Cityscapes	O
in	O
Figure	O
[	O
reference	O
]	O
.	O

The	O
most	O
obvious	O
difference	O
between	O
the	O
original	O
images	O
and	O
the	O
adapted	O
images	O
is	O
the	O
saturation	O
levels	O
—	O
the	O
GTA5	O
imagery	O
is	O
much	O
more	O
vivid	O
than	O
the	O
Cityscapes	O
imagery	O
,	O
so	O
adaptation	O
adjusts	O
the	O
colors	O
to	O
compensate	O
.	O

We	O
also	O
observe	O
texture	O
changes	O
,	O
which	O
are	O
perhaps	O
most	O
apparent	O
in	O
the	O
road	O
:	O
in	O
-	O
game	O
,	O
the	O
roads	O
appear	O
rough	O
with	O
many	O
blemishes	O
,	O
but	O
Cityscapes	O
roads	O
tend	O
to	O
be	O
fairly	O
uniform	O
in	O
appearance	O
,	O
so	O
in	O
converting	O
from	O
GTA5	Material
to	Material
Cityscapes	Material
,	O
our	O
model	O
removes	O
most	O
of	O
the	O
texture	O
.	O

Somewhat	O
amusingly	O
,	O
our	O
model	O
has	O
a	O
tendency	O
to	O
add	O
a	O
hood	O
ornament	O
to	O
the	O
bottom	O
of	O
the	O
image	O
,	O
which	O
,	O
while	O
likely	O
irrelevant	O
to	O
the	O
segmentation	Task
task	Task
,	O
serves	O
as	O
a	O
further	O
indication	O
that	O
image	Method
-	Method
space	Method
adaptation	Method
is	O
producing	O
reasonable	O
results	O
.	O

section	O
:	O
Conclusion	O
We	O
presented	O
a	O
cycle	Method
-	Method
consistent	Method
adversarial	Method
domain	Method
adaptation	Method
method	Method
that	O
unifies	O
cycle	Method
-	Method
consistent	Method
adversarial	Method
models	Method
with	O
adversarial	Method
adaptation	Method
methods	Method
.	O

CyCADA	Method
is	O
able	O
to	O
adapt	O
even	O
in	O
the	O
absence	O
of	O
target	O
labels	O
and	O
is	O
broadly	O
applicable	O
at	O
both	O
the	O
pixel	Method
-	Method
level	Method
and	O
in	O
feature	Method
space	Method
.	O

An	O
image	Method
-	Method
space	Method
adaptation	Method
instantiation	Method
of	O
CyCADA	Method
also	O
provides	O
additional	O
interpretability	O
and	O
serves	O
as	O
a	O
useful	O
way	O
to	O
verify	O
successful	O
adaptation	Task
.	O

Finally	O
,	O
we	O
experimentally	O
validated	O
our	O
model	O
on	O
a	O
variety	O
of	O
adaptation	Task
tasks	Task
:	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
results	O
in	O
multiple	O
evaluation	O
settings	O
indicate	O
its	O
effectiveness	O
,	O
even	O
on	O
challenging	O
synthetic	Task
-	Task
to	Task
-	Task
real	Task
tasks	Task
.	O

bibliography	O
:	O
References	O
section	O
:	O
Appendix	O
subsection	O
:	O
Implementation	O
Details	O
We	O
begin	O
by	O
pretraining	O
the	O
source	Method
task	Method
model	Method
,	O
,	O
using	O
the	O
task	Method
loss	Method
on	O
the	O
labeled	O
source	O
data	O
.	O

Next	O
,	O
we	O
perform	O
pixel	Method
-	Method
level	Method
adaptation	O
using	O
our	O
image	Method
space	Method
GAN	Method
losses	Method
together	O
with	O
semantic	O
consistency	O
and	O
cycle	O
consistency	O
losses	O
.	O

This	O
yeilds	O
learned	O
parameters	O
for	O
the	O
image	O
transformations	O
,	O
and	O
,	O
image	Method
discriminators	Method
,	O
and	O
,	O
as	O
well	O
as	O
an	O
initial	O
setting	O
of	O
the	O
task	Method
model	Method
,	O
,	O
which	O
is	O
trained	O
using	O
pixel	O
transformed	O
source	O
images	O
and	O
the	O
corresponding	O
source	O
pixel	O
labels	O
.	O

Finally	O
,	O
we	O
perform	O
feature	Method
space	Method
adpatation	Method
in	O
order	O
to	O
update	O
the	O
target	O
semantic	Method
model	Method
,	O
,	O
to	O
have	O
features	O
which	O
are	O
aligned	O
between	O
the	O
source	O
images	O
mapped	O
into	O
target	O
style	O
and	O
the	O
real	O
target	O
images	O
.	O

During	O
this	O
phase	O
,	O
we	O
learn	O
the	O
feature	Method
discriminator	Method
,	O
and	O
use	O
this	O
to	O
guide	O
the	O
representation	Task
update	Task
to	O
.	O

In	O
general	O
,	O
our	O
method	O
could	O
also	O
perform	O
phases	O
2	O
and	O
3	O
simultaneously	O
,	O
but	O
this	O
would	O
require	O
more	O
GPU	O
memory	O
then	O
available	O
at	O
the	O
time	O
of	O
these	O
experiments	O
.	O

For	O
all	O
feature	Method
space	Method
adaptation	O
we	O
equally	O
weight	O
the	O
generator	Method
and	Method
discriminator	Method
losses	Method
.	O

We	O
only	O
update	O
the	O
generator	O
when	O
the	O
discriminator	Metric
accuracy	Metric
is	O
above	O
60	O
%	O
over	O
the	O
last	O
batch	O
(	O
digits	O
)	O
or	O
last	O
100	O
iterations	O
(	O
semantic	Task
segmentation	Task
)	O
–	O
this	O
reduces	O
the	O
potential	O
for	O
volatile	Task
training	Task
.	O

If	O
after	O
an	O
epoch	O
(	O
entire	O
pass	O
over	O
dataset	O
)	O
no	O
suitable	O
discriminator	O
is	O
found	O
,	O
the	O
feature	Method
adaptation	Method
stops	O
,	O
otherwise	O
it	O
continues	O
until	O
max	O
iterations	O
are	O
reached	O
.	O

subsubsection	O
:	O
Digit	O
Experiments	O
For	O
all	O
digit	O
experiments	O
we	O
use	O
a	O
variant	O
of	O
the	O
LeNet	Method
architecture	Method
as	O
the	O
task	O
net	O
(	O
Figure	O
[	O
reference	O
]	O
left	O
)	O
.	O

Our	O
feature	Method
discriminator	Method
network	Method
consists	O
of	O
3	O
fully	Method
connected	Method
layers	Method
(	O
Figure	O
[	O
reference	O
]	O
mid	O
left	O
)	O
.	O

The	O
image	Method
discriminator	Method
network	Method
consists	O
of	O
6	O
convolutional	Method
layers	Method
culminating	O
in	O
a	O
single	O
value	O
per	O
pixel	O
(	O
Figure	O
[	O
reference	O
]	O
mid	O
right	O
)	O
.	O

Finally	O
,	O
to	O
generate	O
one	O
image	O
domain	O
from	O
another	O
we	O
use	O
a	O
multilayer	Method
network	Method
which	O
consists	O
of	O
convolution	Method
layers	Method
followed	O
by	O
two	O
residual	O
blocks	O
and	O
then	O
deconvolution	Method
layers	Method
(	O
Figure	O
[	O
reference	O
]	O
right	O
)	O
.	O

All	O
stages	O
are	O
trained	O
using	O
the	O
Adam	Method
optimizer	Method
.	O

paragraph	O
:	O
Hyperparameters	Method
.	O

For	O
training	O
the	O
source	Method
task	Method
net	Method
model	Method
,	O
we	O
use	O
learning	O
rate	O
1e	O
-	O
4	O
and	O
train	O
for	O
100	O
epochs	O
over	O
the	O
data	O
with	O
batch	O
size	O
128	O
.	O

For	O
feature	Method
space	Method
adaptation	O
we	O
use	O
learning	Method
rate	Method
1e	O
-	O
5	O
and	O
train	O
for	O
max	O
200	O
epochs	O
over	O
the	O
data	O
.	O

For	O
pixel	Task
space	Task
adaptation	Task
we	O
train	O
our	O
generators	Method
and	Method
discriminators	Method
with	O
equal	Method
weighting	Method
on	O
all	O
losses	O
,	O
use	O
batch	O
size	O
100	O
,	O
learning	Metric
rate	Metric
2e	Metric
-	Metric
4	Metric
(	O
default	O
from	O
CycleGAN	Method
)	O
,	O
and	O
trained	O
for	O
50	O
epochs	O
.	O

We	O
ran	O
each	O
experiment	O
4	O
times	O
and	O
report	O
the	O
average	O
and	O
standard	O
error	O
across	O
the	O
runs	O
.	O

subsubsection	O
:	O
Semantic	Task
Segmentation	Task
We	O
experiment	O
with	O
both	O
the	O
VGG16	Method
-	Method
FCN8s	Method
architecture	Method
as	O
well	O
as	O
the	O
DRN	Method
-	Method
26	Method
architecture	Method
.	O

For	O
FCN8s	Method
,	O
we	O
train	O
our	O
source	Method
semantic	Method
segmentation	Method
model	Method
for	O
100k	O
iterations	O
using	O
SGD	Method
with	O
learning	Metric
rate	Metric
1e	O
-	O
3	O
and	O
momentum	O
0.9	O
.	O

For	O
the	O
DRN	Method
-	Method
26	Method
architecture	Method
,	O
we	O
train	O
our	O
source	Method
semantic	Method
segmentation	Method
model	Method
for	O
115	O
K	O
iterations	O
using	O
SGD	Method
with	O
learning	Metric
rate	Metric
1e	Metric
-	Metric
3	Metric
and	O
momentum	O
0.9	O
.	O

We	O
use	O
a	O
crop	O
size	O
of	O
600x600	O
and	O
a	O
batch	O
size	O
of	O
8	O
for	O
this	O
training	O
.	O

For	O
cycle	Task
-	Task
consistent	Task
image	Task
level	Task
adaptation	Task
,	O
we	O
followed	O
the	O
network	Method
architecture	Method
and	O
hyperparameters	Method
of	O
CycleGAN	O
zhu_arxiv17	O
.	O

All	O
images	O
were	O
resized	O
to	O
have	O
width	O
of	O
1024	O
pixels	O
while	O
keeping	O
the	O
aspect	O
ratio	O
,	O
and	O
the	O
training	O
was	O
performed	O
with	O
randomly	O
cropped	O
patches	O
of	O
size	O
400	O
by	O
400	O
.	O

Also	O
,	O
due	O
to	O
large	O
size	O
of	O
the	O
dataset	O
,	O
we	O
trained	O
only	O
20	O
epochs	O
.	O

For	O
feature	Method
level	Method
adaptation	Method
,	O
we	O
train	O
using	O
SGD	Method
with	O
momentum	O
,	O
0.99	O
,	O
and	O
learning	Metric
rate	Metric
1e	Metric
-	Metric
5	Metric
.	O

We	O
weight	O
the	O
representation	O
loss	O
ten	O
times	O
less	O
than	O
the	O
discriminator	O
loss	O
as	O
a	O
convienience	O
since	O
otherwise	O
the	O
discriminator	O
did	O
not	O
learn	O
a	O
suitable	O
model	O
within	O
a	O
single	O
epoch	O
.	O

Then	O
the	O
segmentation	Method
model	Method
was	O
trained	O
separately	O
using	O
the	O
adapted	O
source	O
images	O
and	O
the	O
ground	O
truth	O
labels	O
of	O
the	O
source	O
data	O
.	O

Due	O
to	O
memory	O
limitations	O
we	O
can	O
only	O
include	O
a	O
single	O
source	O
and	O
single	O
target	O
image	O
at	O
a	O
time	O
(	O
crops	O
of	O
size	O
768x768	O
)	O
,	O
this	O
small	O
batch	O
is	O
one	O
of	O
the	O
main	O
reasons	O
for	O
using	O
a	O
high	O
momentum	O
parameter	O
.	O

subsection	O
:	O
Comparison	O
to	O
shrivastava_cvpr17	O
for	O
Semantic	Task
Segmentation	Task
We	O
illustrate	O
the	O
performance	O
of	O
a	O
recent	O
pixel	Method
level	Method
adaptation	Method
approach	Method
proposed	O
by	O
shrivastava_cvpr17	O
on	O
our	O
semantic	O
segmentation	O
data	O
–	O
GTA	Material
to	Material
Cityscapes	Material
.	O

These	O
images	O
are	O
significantly	O
larger	O
and	O
more	O
complex	O
than	O
those	O
shown	O
in	O
the	O
experiments	O
in	O
the	O
original	O
paper	O
.	O

We	O
show	O
image	Task
to	Task
image	Task
translation	Task
results	O
under	O
three	O
different	O
settings	O
of	O
the	O
model	O
hyperparameter	O
,	O
,	O
which	O
controls	O
the	O
tradeoff	O
between	O
the	O
reconstruction	Metric
loss	Metric
and	O
the	O
visual	O
style	O
loss	O
.	O

When	O
(	O
Figure	O
[	O
reference	O
]	O
right	O
)	O
,	O
the	O
resulting	O
image	O
converges	O
to	O
a	O
near	O
replica	O
of	O
the	O
original	O
image	O
,	O
thus	O
preserving	O
content	O
but	O
lacking	O
the	O
correct	O
target	O
style	O
.	O

When	O
or	O
(	O
Figure	O
[	O
reference	O
]	O
left	O
)	O
,	O
the	O
results	O
lack	O
any	O
consistent	O
semantics	O
making	O
it	O
difficult	O
to	O
perceive	O
the	O
style	O
of	O
the	O
transformed	O
image	O
.	O

Thus	O
,	O
the	O
resulting	O
performance	O
for	O
this	O
model	O
is	O
11.6	O
mIoU	Metric
for	O
FCN8s	Method
with	O
VGG	Method
,	O
well	O
below	O
the	O
performance	O
of	O
the	O
corresponding	O
source	Method
model	Method
of	O
17.9	O
mIoU.	Metric
subsection	O
:	O
Experiment	O
Analysis	O
To	O
understand	O
the	O
types	O
of	O
mistakes	O
which	O
are	O
improved	O
upon	O
and	O
those	O
which	O
still	O
persist	O
after	O
adaptation	O
,	O
we	O
present	O
the	O
confusion	O
matricies	O
before	O
and	O
after	O
our	O
approach	O
for	O
the	O
digit	O
experiment	O
of	O
SVHN	Material
to	Material
MNIST	Material
(	O
Figure	O
[	O
reference	O
]	O
)	O
.	O

Before	O
adaptation	O
we	O
see	O
common	O
confusions	O
are	O
0s	O
with	O
2s	O
,	O
4s	O
,	O
and	O
7s	O
.	O

6	O
with	O
4	O
,	O
8	O
with	O
3	O
,	O
and	O
9	O
with	O
4	O
.	O

After	O
adaptation	O
all	O
errors	O
are	O
reduced	O
,	O
but	O
we	O
still	O
find	O
that	O
7s	O
are	O
confused	O
with	O
1s	O
and	O
0s	O
with	O
2s	O
.	O

These	O
errors	O
make	O
some	O
sense	O
as	O
with	O
hand	O
written	O
digits	O
,	O
these	O
digits	O
sometimes	O
resemble	O
one	O
another	O
.	O

It	O
remains	O
an	O
open	O
question	O
to	O
produce	O
a	O
model	O
which	O
may	O
overcome	O
these	O
types	O
of	O
errors	O
between	O
highly	O
similar	O
classes	O
.	O

