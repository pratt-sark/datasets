document	O
:	O
Shortcut	Method
-	Method
Stacked	Method
Sentence	Method
Encoders	Method
for	O
Multi	Task
-	Task
Domain	Task
Inference	Task
We	O
present	O
a	O
simple	O
sequential	O
sentence	O
encoder	Method
for	O
multi	Task
-	Task
domain	Task
natural	Task
language	Task
inference	Task
.	O

Our	O
encoder	Method
is	O
based	O
on	O
stacked	Method
bidirectional	Method
LSTM	Method
-	O
RNNs	O
with	O
shortcut	Method
connections	Method
and	O
fine	Method
-	Method
tuning	Method
of	Method
word	Method
embeddings	Method
.	O

The	O
overall	O
supervised	Method
model	Method
uses	O
the	O
above	O
encoder	Method
to	O
encode	O
two	O
input	O
sentences	O
into	O
two	O
vectors	O
,	O
and	O
then	O
uses	O
a	O
classifier	Method
over	O
the	O
vector	Method
combination	Method
to	O
label	O
the	O
relationship	O
between	O
these	O
two	O
sentences	O
as	O
that	O
of	O
entailment	O
,	O
contradiction	O
,	O
or	O
neural	O
.	O

Our	O
Shortcut	Method
-	Method
Stacked	Method
sentence	Method
encoders	Method
achieve	O
strong	O
improvements	O
over	O
existing	O
encoders	Method
on	O
matched	Task
and	Task
mismatched	Task
multi	Task
-	Task
domain	Task
natural	Task
language	Task
inference	Task
(	O
top	O
non	O
-	O
ensemble	O
single	O
-	O
model	O
result	O
in	O
the	O
EMNLP	Material
RepEval	Material
2017	O
Shared	O
Task	O
)	O
.	O

Moreover	O
,	O
they	O
achieve	O
the	O
new	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
encoding	Metric
result	O
on	O
the	O
original	O
SNLI	Material
dataset	O
.	O

section	O
:	O
Introduction	O
and	O
Background	O
Natural	Task
language	Task
inference	Task
(	O
NLI	Task
)	O
or	O
recognizing	Task
textual	Task
entailment	Task
(	Task
RTE	Task
)	Task
is	O
a	O
fundamental	O
semantic	Task
task	Task
in	O
the	O
field	O
of	O
natural	Task
language	Task
processing	Task
.	O

The	O
problem	O
is	O
to	O
determine	O
whether	O
a	O
given	O
hypothesis	O
sentence	O
can	O
be	O
logically	O
inferred	O
from	O
a	O
given	O
premise	O
sentence	O
.	O

Recently	O
released	O
datasets	O
such	O
as	O
the	O
Stanford	Material
Natural	Material
Language	Material
Inference	Material
Corpus	Material
(	O
SNLI	Material
)	O
and	O
the	O
Multi	Material
-	Material
Genre	Material
Natural	Material
Language	Material
Inference	Material
Corpus	Material
(	O
Multi	Material
-	Material
NLI	Material
)	O
have	O
not	O
only	O
encouraged	O
several	O
end	O
-	O
to	O
-	O
end	Method
neural	Method
network	Method
approaches	Method
to	O
NLI	Task
,	O
but	O
have	O
also	O
served	O
as	O
an	O
evaluation	O
resource	O
for	O
general	Task
representation	Task
learning	Task
of	Task
natural	Task
language	Task
.	O

Depending	O
on	O
whether	O
a	O
model	O
will	O
first	O
encode	O
a	O
sentence	O
into	O
a	O
fixed	O
-	O
length	O
vector	O
without	O
any	O
incorporating	O
information	O
from	O
the	O
other	O
sentence	O
,	O
the	O
several	O
proposed	O
models	O
can	O
be	O
categorized	O
into	O
two	O
groups	O
:	O
(	O
1	O
)	O
encoding	Method
-	Method
based	Method
models	Method
(	O
or	O
sentence	O
encoders	Method
)	O
,	O
such	O
as	O
Tree	O
-	O
based	O
CNN	O
encoders	Method
(	O
TBCNN	Method
)	O
in	O
mou2015natural	Method
or	O
Stack	Method
-	Method
augmented	Method
Parser	Method
-	Method
Interpreter	Method
Neural	Method
Network	Method
(	Method
SPINN	Method
)	Method
in	O
bowman2016fast	Method
,	O
and	O
(	O
2	O
)	O
joint	Method
,	Method
pairwise	Method
models	Method
that	O
use	O
cross	O
-	O
features	O
between	O
the	O
two	O
sentences	O
to	O
encode	O
them	O
,	O
such	O
as	O
the	O
Enhanced	Method
Sequential	Method
Inference	Method
Model	Method
(	O
ESIM	Method
)	Method
in	O
chen2017enhanced	O
or	O
the	O
bilateral	Method
multi	Method
-	Method
perspective	Method
matching	Method
(	O
BiMPM	Method
)	O
model	O
wang2017bilateral	O
.	O

Moreover	O
,	O
common	O
sentence	O
encoders	Method
can	O
again	O
be	O
classified	O
into	O
tree	O
-	O
based	O
encoders	Method
such	O
as	O
SPINN	Method
in	O
bowman2016fast	O
which	O
we	O
mentioned	O
before	O
,	O
or	O
sequential	O
encoders	Method
such	O
as	O
the	O
biLSTM	Method
model	O
by	O
snli	Material
:	O
emnlp2015	O
.	O

In	O
this	O
paper	O
,	O
we	O
follow	O
the	O
former	O
approach	O
of	O
encoding	Method
-	Method
based	Method
models	Method
,	O
and	O
propose	O
a	O
novel	O
yet	O
simple	O
sequential	O
sentence	O
encoder	Method
for	O
the	O
Multi	Material
-	Material
NLI	Material
problem	O
.	O

Our	O
encoder	Method
does	O
not	O
require	O
any	O
syntactic	O
information	O
of	O
the	O
sentence	O
.	O

It	O
also	O
does	O
not	O
contain	O
any	O
attention	O
or	O
memory	O
structure	O
.	O

It	O
is	O
basically	O
a	O
stacked	Method
(	Method
multi	Method
-	Method
layered	Method
)	Method
bidirectional	Method
LSTM	Method
-	Method
RNN	Method
with	O
shortcut	Method
connections	Method
(	O
feeding	O
all	O
previous	O
layers	O
’	O
outputs	O
and	O
word	O
embeddings	O
to	O
each	O
layer	O
)	O
and	O
word	Method
embedding	Method
fine	Method
-	Method
tuning	Method
.	O

The	O
overall	O
supervised	Method
model	Method
uses	O
these	O
shortcut	Method
-	Method
stacked	Method
encoders	Method
to	O
encode	O
two	O
input	O
sentences	O
into	O
two	O
vectors	O
,	O
and	O
then	O
we	O
use	O
a	O
classifier	Method
over	O
the	O
vector	Method
combination	Method
to	O
label	O
the	O
relationship	O
between	O
these	O
two	O
sentences	O
as	O
that	O
of	O
entailment	O
,	O
contradiction	O
,	O
or	O
neural	O
(	O
similar	O
to	O
the	O
classifier	Method
setup	Method
of	O
snli	Material
:	O
emnlp2015	O
and	O
conneau2017supervised	O
)	O
.	O

Our	O
simple	O
shortcut	Method
-	Method
stacked	Method
encoders	Method
achieve	O
strong	O
improvements	O
over	O
existing	O
encoders	Method
due	O
to	O
its	O
multi	O
-	O
layered	O
and	O
shortcut	O
-	O
connected	O
properties	O
,	O
on	O
both	O
matched	Metric
and	Metric
mismatched	Metric
evaluation	Metric
settings	Metric
for	O
multi	Task
-	Task
domain	Task
natural	Task
language	Task
inference	Task
,	O
as	O
well	O
as	O
on	O
the	O
original	O
SNLI	Material
dataset	O
.	O

It	O
is	O
the	O
top	O
single	O
-	O
model	O
(	O
non	O
-	O
ensemble	O
)	O
result	O
in	O
the	O
EMNLP	Task
RepEval	Task
2017	O
Multi	Material
-	Material
NLI	Material
Shared	O
Task	O
,	O
and	O
the	O
new	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
for	O
encoding	Task
-	O
based	O
results	O
on	O
the	O
SNLI	Material
dataset	O
.	O

Github	O
Code	O
Link	O
:	O
https:	O
//	O
github.com	O
/	O
easonnie	O
/	O
multiNLI_encoder	O
section	O
:	O
Model	O
Our	O
model	O
mainly	O
consists	O
of	O
two	O
separate	O
components	O
,	O
a	O
sentence	O
encoder	Method
and	O
an	O
entailment	Method
classifier	Method
.	O

The	O
sentence	O
encoder	Method
compresses	O
each	O
source	O
sentence	O
into	O
a	O
vector	Method
representation	Method
and	O
the	O
classifier	Method
makes	O
a	O
three	O
-	O
way	O
classification	Task
based	O
on	O
the	O
two	O
vectors	O
of	O
the	O
two	O
source	O
sentences	O
.	O

The	O
model	O
follows	O
the	O
‘	O
encoding	Method
-	Method
based	Method
rule	Method
’	O
,	O
i.e.	O
,	O
the	O
encoder	Method
will	O
encode	O
each	O
source	O
sentence	O
into	O
a	O
fixed	O
length	O
vector	O
without	O
any	O
information	O
or	O
function	O
based	O
on	O
the	O
other	O
sentence	O
(	O
e.g.	O
,	O
cross	O
-	O
attention	O
or	O
memory	O
comparing	O
the	O
two	O
sentences	O
)	O
.	O

In	O
order	O
to	O
fully	O
explore	O
the	O
generalization	O
of	O
the	O
sentence	O
encoder	Method
,	O
the	O
same	O
encoder	Method
is	O
applied	O
to	O
both	O
the	O
premise	O
and	O
the	O
hypothesis	O
with	O
shared	O
parameters	O
projecting	O
them	O
into	O
the	O
same	O
space	O
.	O

This	O
setting	O
follows	O
the	O
idea	O
of	O
Siamese	Method
Networks	Method
in	O
bromley1994signature	O
.	O

Figure	O
[	O
reference	O
]	O
shows	O
the	O
overview	O
of	O
our	O
encoding	Method
model	Method
(	O
the	O
standard	O
classifier	Method
setup	Method
is	O
not	O
shown	O
here	O
;	O
see	O
snli	Material
:	O
emnlp2015	O
and	O
conneau2017supervised	O
for	O
that	O
)	O
.	O

subsection	O
:	O
Sentence	Method
Encoder	Method
Our	O
sentence	O
encoder	Method
is	O
simply	O
composed	O
of	O
multiple	O
stacked	Method
bidirectional	Method
LSTM	Method
(	O
biLSTM	Method
)	O
layers	O
with	O
shortcut	O
connections	O
followed	O
by	O
a	O
max	Method
pooling	Method
layer	Method
.	O

Let	O
bilstm	Method
represent	O
the	O
th	O
biLSTM	Method
layer	O
,	O
which	O
is	O
defined	O
as	O
:	O
where	O
is	O
the	O
output	O
of	O
the	O
th	O
biLSTM	Method
at	O
time	O
t	O
over	O
input	O
sequence	O
.	O

In	O
a	O
typical	O
stacked	O
biLSTM	Method
structure	O
,	O
the	O
input	O
of	O
the	O
next	O
LSTM	Method
-	Method
RNN	Method
layer	Method
is	O
simply	O
the	O
output	O
sequence	O
of	O
the	O
previous	O
LSTM	Method
-	Method
RNN	Method
layer	Method
.	O

In	O
our	O
settings	O
,	O
the	O
input	O
sequences	O
for	O
the	O
th	O
biLSTM	Method
layer	O
are	O
the	O
concatenated	O
outputs	O
of	O
all	O
the	O
previous	O
layers	O
,	O
plus	O
the	O
original	O
word	O
embedding	O
sequence	O
.	O

This	O
gives	O
a	O
shortcut	Method
connection	Method
style	Method
setup	Method
,	O
related	O
to	O
the	O
widely	O
used	O
idea	O
of	O
residual	O
connections	O
in	O
CNNs	Method
for	O
computer	Task
vision	Task
,	O
highway	Method
networks	Method
for	O
RNNs	Task
in	O
speech	Task
processing	Task
,	O
and	O
shortcut	Method
connections	Method
in	O
hierarchical	Task
multitasking	Task
learning	Task
;	O
but	O
in	O
our	O
case	O
we	O
feed	O
in	O
all	O
the	O
previous	O
layers	O
’	O
output	O
sequences	O
as	O
well	O
as	O
the	O
word	O
embedding	O
sequence	O
to	O
every	O
layer	O
.	O

Let	O
represent	O
words	O
in	O
the	O
source	O
sentence	O
.	O

We	O
assume	O
is	O
a	O
word	O
embedding	O
vector	O
which	O
are	O
initialized	O
using	O
some	O
pre	O
-	O
trained	O
vector	Method
embeddings	Method
(	O
and	O
is	O
then	O
fine	O
-	O
tuned	O
end	O
-	O
to	O
-	O
end	O
via	O
the	O
NLI	Method
supervision	Method
)	O
.	O

Then	O
,	O
the	O
input	O
of	O
th	O
biLSTM	Method
layer	O
at	O
time	O
is	O
defined	O
as	O
:	O
where	O
represents	O
vector	Method
concatenation	Method
.	O

Then	O
,	O
assuming	O
we	O
have	O
layers	O
of	O
biLSTM	Method
,	O
the	O
final	O
vector	Method
representation	Method
will	O
be	O
obtained	O
by	O
applying	O
row	Method
-	Method
max	Method
-	Method
pool	Method
over	O
the	O
output	O
of	O
the	O
last	O
biLSTM	Method
layer	O
,	O
similar	O
to	O
conneau2017supervised	O
.	O

The	O
final	O
layer	O
is	O
defined	O
as	O
:	O
where	O
,	O
,	O
is	O
the	O
dimension	O
of	O
the	O
hidden	O
state	O
of	O
the	O
last	O
forward	Method
and	Method
backward	Method
LSTM	Method
layers	Method
,	O
and	O
is	O
the	O
final	O
vector	Method
representation	Method
for	O
the	O
source	O
sentence	O
(	O
which	O
is	O
later	O
fed	O
to	O
the	O
NLI	Method
classifier	Method
)	O
.	O

The	O
closest	O
encoder	Method
architecture	O
to	O
ours	O
is	O
that	O
of	O
conneau2017supervised	O
,	O
whose	O
model	O
consists	O
of	O
a	O
single	O
-	O
layer	O
biLSTM	Method
with	O
a	O
max	Method
-	Method
pooling	Method
layer	Method
,	O
which	O
we	O
treat	O
as	O
our	O
starting	O
point	O
.	O

Our	O
experiments	O
(	O
Section	O
[	O
reference	O
]	O
)	O
demonstrate	O
that	O
our	O
enhancements	O
of	O
the	O
stacked	Method
-	Method
biRNN	Method
with	Method
shortcut	Method
connections	Method
provide	O
significant	O
gains	O
on	O
top	O
of	O
this	O
baseline	O
(	O
for	O
both	O
SNLI	Material
and	O
Multi	Material
-	Material
NLI	Material
)	O
.	O

subsection	O
:	O
Entailment	Method
Classifier	Method
After	O
we	O
obtain	O
the	O
vector	Method
representation	Method
for	O
the	O
premise	O
and	O
hypothesis	O
sentence	O
,	O
we	O
apply	O
three	O
matching	Method
methods	Method
to	O
the	O
two	O
vectors	O
for	O
these	O
two	O
vectors	O
and	O
then	O
concatenate	O
these	O
three	O
match	O
vectors	O
(	O
based	O
on	O
the	O
heuristic	Method
matching	Method
presented	O
in	O
mou2015natural	O
)	O
.	O

Let	O
and	O
be	O
the	O
vector	Method
representations	Method
for	O
premise	O
and	O
hypothesis	O
,	O
respectively	O
.	O

The	O
matching	O
vector	O
is	O
then	O
defined	O
as	O
:	O
At	O
last	O
,	O
we	O
feed	O
this	O
final	O
concatenated	O
result	O
into	O
a	O
MLP	Method
layer	Method
and	O
use	O
a	O
softmax	Method
layer	Method
to	O
make	O
final	O
classification	Task
.	O

section	O
:	O
Experimental	O
Setup	O
subsection	O
:	O
Datasets	O
As	O
instructed	O
in	O
the	O
RepEval	O
Multi	Material
-	Material
NLI	Material
shared	O
task	O
,	O
we	O
use	O
all	O
of	O
the	O
training	O
data	O
in	O
Multi	Material
-	Material
NLI	Material
combined	O
with	O
15	O
%	O
randomly	O
selected	O
samples	O
from	O
the	O
SNLI	Material
training	O
set	O
resampled	O
at	O
each	O
epoch	O
)	O
as	O
our	O
final	O
training	O
set	O
for	O
all	O
models	O
;	O
and	O
we	O
use	O
both	O
the	O
cross	O
-	O
domain	O
(	O
‘	O
mismatched	O
’	O
)	O
and	O
in	O
-	O
domain	O
(	O
‘	O
matched	O
’	O
)	O
Multi	Material
-	Material
NLI	Material
development	O
sets	O
for	O
model	Task
selection	Task
.	O

For	O
the	O
SNLI	Material
test	O
results	O
in	O
Table	O
[	O
reference	O
]	O
,	O
we	O
train	O
on	O
only	O
the	O
SNLI	Material
training	O
set	O
(	O
and	O
we	O
also	O
verify	O
that	O
the	O
tuning	O
decisions	O
hold	O
true	O
on	O
the	O
SNLI	Material
dev	O
set	O
)	O
.	O

subsection	O
:	O
Parameter	O
Settings	O
We	O
use	O
cross	Metric
-	Metric
entropy	Metric
loss	Metric
as	O
the	O
training	Metric
objective	Metric
with	O
Adam	Method
-	Method
based	Method
optimization	Method
with	O
32	O
batch	O
size	O
.	O

The	O
starting	O
learning	Metric
rate	Metric
is	O
0.0002	O
with	O
half	O
decay	O
every	O
two	O
epochs	O
.	O

The	O
number	O
of	O
hidden	O
units	O
for	O
MLP	Method
in	O
classifier	Method
is	O
1600	O
.	O

Dropout	Method
layer	Method
is	O
also	O
applied	O
on	O
the	O
output	O
of	O
each	O
layer	O
of	O
MLP	Method
,	O
with	O
dropout	O
rate	O
set	O
to	O
0.1	O
.	O

We	O
used	O
pre	O
-	O
trained	O
300D	O
Glove	O
840B	O
vectors	O
to	O
initialize	O
the	O
word	O
embeddings	O
.	O

Tuning	Task
decisions	Task
for	O
word	Method
embedding	Method
training	Method
strategy	Method
,	O
the	O
hyperparameters	O
of	O
dimension	O
and	O
number	O
of	O
layers	O
for	O
biLSTM	Method
,	O
and	O
the	O
activation	O
type	O
and	O
number	O
of	O
layers	O
for	O
MLP	Method
,	O
are	O
all	O
explained	O
in	O
Section	O
[	O
reference	O
]	O
.	O

section	O
:	O
Results	O
and	O
Analysis	O
subsection	O
:	O
Ablation	Task
Analysis	Task
Results	O
We	O
now	O
investigate	O
the	O
effectiveness	O
of	O
each	O
of	O
the	O
enhancement	Method
components	Method
in	O
our	O
overall	O
model	O
.	O

These	O
ablation	O
results	O
are	O
shown	O
in	O
Tables	O
[	O
reference	O
]	O
,	O
[	O
reference	O
]	O
,	O
[	O
reference	O
]	O
and	O
[	O
reference	O
]	O
,	O
all	O
based	O
on	O
the	O
Multi	Material
-	Material
NLI	Material
development	O
sets	O
.	O

Finally	O
,	O
Table	O
[	O
reference	O
]	O
shows	O
results	O
for	O
different	O
encoders	Method
on	O
SNLI	Material
and	O
Multi	Material
-	Material
NLI	Material
test	Material
sets	Material
.	O

First	O
,	O
Table	O
[	O
reference	O
]	O
shows	O
the	O
performance	O
changes	O
for	O
different	O
number	O
of	O
biLSTM	Method
layers	O
and	O
their	O
varying	O
dimension	O
size	O
.	O

The	O
dimension	O
size	O
of	O
a	O
biLSTM	Method
layer	O
is	O
referring	O
to	O
the	O
dimension	O
of	O
the	O
hidden	O
state	O
for	O
both	O
the	O
forward	Method
and	Method
backward	Method
LSTM	Method
-	Method
RNNs	Method
.	O

As	O
shown	O
,	O
each	O
added	O
layer	Method
model	Method
improves	O
the	O
accuracy	Metric
and	O
we	O
achieve	O
a	O
substantial	O
improvement	O
in	O
accuracy	Metric
(	O
around	O
2	O
%	O
)	O
on	O
both	O
matched	O
and	O
mismatched	O
settings	O
,	O
compared	O
to	O
the	O
single	O
-	O
layer	O
biLSTM	Method
in	O
conneau2017supervised	O
.	O

We	O
only	O
experimented	O
with	O
up	O
to	O
3	O
layers	O
with	O
512	O
,	O
1024	O
,	O
2048	O
dimensions	O
each	O
,	O
so	O
the	O
model	O
still	O
has	O
potential	O
to	O
improve	O
the	O
result	O
further	O
with	O
a	O
larger	O
dimension	O
and	O
more	O
layers	O
.	O

Next	O
,	O
in	O
Table	O
[	O
reference	O
]	O
,	O
we	O
show	O
that	O
the	O
shortcut	O
connections	O
among	O
the	O
biLSTM	Method
layers	O
is	O
also	O
an	O
important	O
contributor	O
to	O
accuracy	Metric
improvement	O
(	O
around	O
1.5	O
%	O
on	O
top	O
of	O
the	O
full	Method
3	Method
-	Method
layered	Method
stacked	Method
-	Method
RNN	Method
model	Method
)	O
.	O

This	O
demonstrates	O
that	O
simply	O
stacking	O
the	O
biLSTM	Method
layers	O
is	O
not	O
sufficient	O
to	O
handle	O
a	O
complex	O
task	O
like	O
Multi	Material
-	Material
NLI	Material
and	O
it	O
is	O
significantly	O
better	O
to	O
have	O
the	O
higher	O
layer	O
connected	O
to	O
both	O
the	O
output	O
and	O
the	O
original	O
input	O
of	O
all	O
the	O
previous	O
layers	O
(	O
note	O
that	O
Table	O
[	O
reference	O
]	O
results	O
are	O
based	O
on	O
multi	Method
-	Method
layered	Method
models	Method
with	O
shortcut	O
connections	O
)	O
.	O

Next	O
,	O
in	O
Table	O
[	O
reference	O
]	O
,	O
we	O
show	O
that	O
fine	O
-	O
tuning	O
the	O
word	O
embeddings	O
also	O
improves	O
results	O
,	O
again	O
for	O
both	O
the	O
in	Task
-	Task
domain	Task
task	Task
and	O
cross	Task
-	Task
domain	Task
tasks	Task
(	O
the	O
ablation	O
results	O
are	O
based	O
on	O
a	O
smaller	O
model	O
with	O
a	O
128	O
+	O
256	O
2	O
-	O
layer	O
biLSTM	Method
)	O
.	O

Hence	O
,	O
all	O
our	O
models	O
were	O
trained	O
with	O
word	Method
embeddings	Method
being	O
fine	O
-	O
tuned	O
.	O

The	O
last	O
ablation	O
in	O
Table	O
[	O
reference	O
]	O
shows	O
that	O
a	O
classifier	Method
with	O
two	O
layers	O
of	O
relu	Method
is	O
preferable	O
than	O
other	O
options	O
.	O

Thus	O
,	O
we	O
use	O
that	O
setting	O
for	O
our	O
strongest	O
encoder	Method
.	O

subsection	O
:	O
Multi	Material
-	Material
NLI	Material
and	O
SNLI	Task
Test	Task
Results	Task
Finally	O
,	O
in	O
Table	O
[	O
reference	O
]	O
,	O
we	O
report	O
the	O
test	O
results	O
for	O
MNLI	Material
and	O
SNLI	Material
.	O

First	O
for	O
Multi	Material
-	Material
NLI	Material
,	O
we	O
improve	O
substantially	O
over	O
the	O
CBOW	O
and	O
biLSTM	Method
Encoder	O
baselines	O
reported	O
in	O
the	O
dataset	O
paper	O
.	O

We	O
also	O
show	O
that	O
our	O
final	O
shortcut	Method
-	Method
based	Method
stacked	Method
encoder	Method
achieves	O
around	O
3	O
%	O
improvement	O
as	O
compared	O
to	O
the	O
1	O
-	O
layer	O
biLSTM	Method
-	O
Max	O
Encoder	O
in	O
the	O
second	O
last	O
row	O
(	O
using	O
the	O
exact	O
same	O
classifier	O
and	O
optimizer	O
settings	O
)	O
.	O

Our	O
shortcut	O
-	O
encoder	Method
was	O
also	O
the	O
top	O
singe	Method
-	Method
model	Method
(	O
non	O
-	O
ensemble	O
)	O
result	O
on	O
the	O
EMNLP	Task
RepEval	Task
Shared	Task
Task	Task
leaderboard	Task
.	O

Next	O
,	O
for	O
SNLI	Material
,	O
we	O
compare	O
our	O
shortcut	Method
-	Method
stacked	Method
encoder	Method
with	O
the	O
current	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
encoders	Method
from	O
the	O
SNLI	Material
leaderboard	O
(	O
https:	O
//	O
nlp.stanford.edu	O
/	O
projects	O
/	O
snli	Material
/	O
)	O
.	O

We	O
also	O
compare	O
to	O
the	O
recent	O
biLSTM	Method
-	O
Max	O
Encoder	O
of	O
conneau2017supervised	O
,	O
which	O
served	O
as	O
our	O
model	O
’s	O
1	O
-	O
layer	O
starting	O
point	O
.	O

The	O
results	O
indicate	O
that	O
‘	O
Our	O
Shortcut	Method
-	Method
Stacked	Method
Encoder	Method
’	O
surpasses	O
all	O
the	O
previous	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
encoders	Method
,	O
and	O
achieves	O
the	O
new	O
best	O
encoding	Metric
-	O
based	O
result	O
on	O
SNLI	Material
,	O
suggesting	O
the	O
general	O
effectiveness	O
of	O
simple	O
shortcut	Method
-	Method
connected	Method
stacked	Method
layers	Method
in	O
sentence	O
encoders	Method
.	O

section	O
:	O
Conclusion	O
We	O
explored	O
various	O
simple	O
combinations	O
and	O
connections	O
of	O
biLSTM	Method
-	O
RNN	O
layered	O
architectures	O
and	O
developed	O
a	O
Shortcut	Method
-	Method
Stacked	Method
Sentence	Method
Encoder	Method
for	O
natural	Task
language	Task
inference	Task
.	O

Our	O
model	O
is	O
the	O
top	O
single	O
result	O
in	O
the	O
EMNLP	Task
RepEval	Task
2017	O
Multi	Material
-	Material
NLI	Material
Shared	O
Task	O
,	O
and	O
it	O
also	O
surpasses	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
encoders	Method
for	O
the	O
SNLI	Material
dataset	O
.	O

In	O
future	O
work	O
,	O
we	O
are	O
also	O
evaluating	O
the	O
effectiveness	O
of	O
shortcut	Method
-	Method
stacked	Method
sentence	Method
encoders	Method
on	O
several	O
other	O
semantic	Task
tasks	Task
.	O

section	O
:	O
Addendum	O
:	O
Shortcut	O
vs.	O
Residual	O
In	O
later	O
experiments	O
,	O
we	O
found	O
that	O
a	O
residual	Method
connection	Method
can	O
achieve	O
similar	O
accuracies	Metric
with	O
fewer	O
number	O
of	O
parameters	O
,	O
compared	O
to	O
a	O
shortcut	Method
connection	Method
.	O

Therefore	O
,	O
in	O
order	O
to	O
reduce	O
the	O
model	O
size	O
and	O
to	O
also	O
follow	O
the	O
SNLI	Material
leader	O
-	O
board	O
settings	O
(	O
e.g.	O
,	O
300D	O
and	O
600D	O
embeddings	O
)	O
,	O
we	O
performed	O
some	O
additional	O
SNLI	Material
experiments	O
with	O
the	O
shortcut	O
connections	O
replaced	O
with	O
residual	O
connections	O
,	O
where	O
the	O
input	O
to	O
each	O
next	O
biLSTM	Method
layer	O
is	O
the	O
concatenation	O
of	O
the	O
word	Method
embedding	Method
and	O
the	O
summation	O
of	O
outputs	O
of	O
all	O
previous	O
layers	O
(	O
related	O
to	O
ResNet	Task
in	Task
computer	Task
vision	Task
)	O
.	O

Table	O
[	O
reference	O
]	O
shows	O
these	O
residual	O
-	O
connection	O
SNLI	Material
test	O
results	O
and	O
the	O
parameter	Method
comparison	Method
to	O
shortcut	Method
-	Method
connection	Method
models	Method
(	O
using	O
3	O
stacked	O
-	O
biLSTM	Method
layers	O
,	O
and	O
one	O
800	Method
-	Method
unit	Method
MLP	Method
layer	Method
,	O
based	O
on	O
SNLI	Material
dev	O
set	O
tuning	O
)	O
.	O

section	O
:	O
Acknowledgments	O
We	O
thank	O
the	O
shared	O
task	O
organizers	O
and	O
the	O
anonymous	O
reviewers	O
.	O

This	O
work	O
was	O
partially	O
supported	O
by	O
a	O
Google	O
Faculty	O
Research	O
Award	O
,	O
an	O
IBM	O
Faculty	O
Award	O
,	O
a	O
Bloomberg	O
Data	O
Science	O
Research	O
Grant	O
,	O
and	O
NVidia	O
GPU	O
awards	O
.	O

bibliography	O
:	O
References	O
