Long	Task
Text	Task
Generation	Task
via	O
Adversarial	Method
Training	Method
with	O
Leaked	O
Information	O
section	O
:	O
Abstract	O
Automatically	Task
generating	Task
coherent	Task
and	Task
semantically	Task
meaningful	Task
text	Task
has	O
many	O
applications	O
in	O
machine	Task
translation	Task
,	O
dialogue	Task
systems	Task
,	O
image	Task
captioning	Task
,	O
etc	O
.	O

Recently	O
,	O
by	O
combining	O
with	O
policy	Method
gradient	Method
,	O
Generative	Method
Adversarial	Method
Nets	Method
(	O
GAN	Method
)	O
that	O
use	O
a	O
discriminative	Method
model	Method
to	O
guide	O
the	O
training	O
of	O
the	O
generative	Method
model	Method
as	O
a	O
reinforcement	Method
learning	Method
policy	Method
has	O
shown	O
promising	O
results	O
in	O
text	O
generation	Task
.	O

However	O
,	O
the	O
scalar	O
guiding	O
signal	O
is	O
only	O
available	O
after	O
the	O
entire	O
text	O
has	O
been	O
generated	O
and	O
lacks	O
intermediate	O
information	O
about	O
text	O
structure	O
during	O
the	O
generative	Method
process	Method
.	O

As	O
such	O
,	O
it	O
limits	O
its	O
success	O
when	O
the	O
length	O
of	O
the	O
generated	O
text	O
samples	O
is	O
long	O
(	O
more	O
than	O
20	O
words	O
)	O
.	O

In	O
this	O
paper	O
,	O
we	O
propose	O
a	O
new	O
framework	O
,	O
called	O
LeakGAN	Method
,	O
to	O
address	O
the	O
problem	O
for	O
long	O
text	O
generation	Task
.	O

We	O
allow	O
the	O
discriminative	Method
net	Method
to	O
leak	O
its	O
own	O
high	O
-	O
level	O
extracted	O
features	O
to	O
the	O
generative	Method
net	Method
to	O
further	O
help	O
the	O
guidance	Task
.	O

The	O
generator	Method
incorporates	O
such	O
informative	O
signals	O
into	O
all	O
generation	Task
steps	O
through	O
an	O
additional	O
MANAGER	Method
module	O
,	O
which	O
takes	O
the	O
extracted	O
features	O
of	O
current	O
generated	O
words	O
and	O
outputs	O
a	O
latent	O
vector	O
to	O
guide	O
the	O
WORKER	Method
module	O
for	O
next	O
-	O
word	O
generation	Task
.	O

Our	O
extensive	O
experiments	O
on	O
synthetic	O
data	O
and	O
various	O
realworld	O
tasks	O
with	O
Turing	O
test	O
demonstrate	O
that	O
LeakGAN	Method
is	O
highly	O
effective	O
in	O
long	O
text	O
generation	Task
and	O
also	O
improves	O
the	O
performance	O
in	O
short	O
text	O
generation	Task
scenarios	O
.	O

More	O
importantly	O
,	O
without	O
any	O
supervision	O
,	O
LeakGAN	Method
would	O
be	O
able	O
to	O
implicitly	O
learn	O
sentence	O
structures	O
only	O
through	O
the	O
interaction	O
between	O
MANAGER	Method
and	O
WORKER	Method
.	O

section	O
:	O
Introduction	O
The	O
ability	O
to	O
generate	O
coherent	Task
and	Task
semantically	Task
meaningful	Task
text	Task
plays	O
a	O
key	O
role	O
in	O
many	O
natural	Task
language	Task
processing	Task
applications	Task
such	O
as	O
machine	Task
translation	Task
,	O
dialogue	Task
generation	Task
,	O
and	O
image	Task
captioning	Task
[	O
reference	O
]	O
.	O

While	O
most	O
previous	O
work	O
focuses	O
on	O
task	Task
-	Task
specific	Task
applications	Task
in	O
supervised	Task
settings	Task
[	O
reference	O
][	O
reference	O
]	O
,	O
the	O
generic	O
unsupervised	O
text	O
generation	Task
,	O
which	O
aims	O
to	O
mimic	O
the	O
distribution	O
over	O
real	O
text	O
from	O
a	O
corpus	O
,	O
has	O
recently	O
drawn	O
much	O
attention	O
[	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
;	O
*	O
Correspondence	O
to	O
Weinan	O
Zhang	O
.	O

This	O
work	O
is	O
financially	O
supported	O
by	O
NSFC	O
(	O
61702327	O
)	O
and	O
Shanghai	O
Sailing	O
Program	O
(	O
17YF1428200	O
)	O
.	O

Copyright	O
c	O
2018	O
,	O
Association	O
for	O
the	O
Advancement	O
of	O
Artificial	O
Intelligence	O
(	O
www.aaai.org	O
)	O
.	O

All	O
rights	O
reserved	O
.	O

[	O
reference	O
]	O
.	O

A	O
typical	O
approach	O
is	O
to	O
train	O
a	O
recurrent	Method
neural	Method
network	Method
(	O
RNN	Method
)	O
to	O
maximize	O
the	O
log	O
-	O
likelihood	O
of	O
each	O
ground	O
-	O
truth	O
word	O
given	O
prior	O
observed	O
words	O
[	O
reference	O
]	O
,	O
which	O
,	O
however	O
,	O
suffers	O
from	O
so	O
-	O
called	O
exposure	O
bias	O
due	O
to	O
the	O
discrepancy	O
between	O
training	O
and	O
inference	Task
stage	Task
:	O
the	O
model	O
sequentially	O
generates	O
the	O
next	O
word	O
based	O
on	O
previously	O
generated	O
words	O
during	O
inference	Task
but	O
itself	O
is	O
trained	O
to	O
generate	O
words	O
given	O
ground	O
-	O
truth	O
words	O
[	O
reference	O
]	O
.	O

A	O
scheduled	Method
sampling	Method
approach	Method
is	O
proposed	O
to	O
addressed	O
this	O
problem	O
,	O
but	O
is	O
proved	O
to	O
be	O
fundamentally	O
inconsistent	O
[	O
reference	O
]	O
.	O

Generative	O
Adversarial	O
Nets	O
(	O
GAN	Method
)	O
[	O
reference	O
]	O
,	O
which	O
is	O
firstly	O
proposed	O
for	O
continous	O
data	O
(	O
image	Task
generation	Task
etc	O
.	O

)	O
,	O
is	O
then	O
extended	O
to	O
discrete	O
,	O
sequential	O
data	O
to	O
alleviate	O
the	O
above	O
problem	O
and	O
has	O
shown	O
promising	O
results	O
[	O
reference	O
]	O
)	O
.	O

Due	O
to	O
the	O
discrete	O
nature	O
of	O
text	O
samples	O
,	O
text	O
generation	Task
is	O
modeled	O
as	O
a	O
sequential	Task
decision	Task
making	Task
process	Task
,	O
where	O
the	O
state	O
is	O
previously	O
generated	O
words	O
,	O
the	O
action	O
is	O
the	O
next	O
word	O
to	O
be	O
generated	O
,	O
and	O
the	O
generative	Method
net	Method
G	Method
is	O
a	O
stochastic	Method
policy	Method
that	O
maps	O
current	O
state	O
to	O
a	O
distribution	O
over	O
the	O
action	O
space	O
.	O

After	O
the	O
whole	O
text	O
generation	Task
is	O
done	O
,	O
the	O
generated	O
text	O
samples	O
are	O
then	O
fed	O
to	O
the	O
discriminative	Method
net	Method
D	Method
,	O
a	O
classifier	Method
that	O
is	O
trained	O
to	O
distinguish	O
real	O
and	O
generated	O
text	O
samples	O
,	O
to	O
get	O
reward	O
signals	O
for	O
updating	O
G.	O
Since	O
then	O
,	O
various	O
methods	O
have	O
been	O
proposed	O
in	O
text	O
generation	Task
via	O
GAN	Method
[	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
.	O

Nonetheless	O
,	O
the	O
reported	O
results	O
are	O
limited	O
to	O
the	O
cases	O
that	O
the	O
generated	O
text	O
samples	O
are	O
short	O
(	O
say	O
,	O
fewer	O
than	O
20	O
words	O
)	O
while	O
more	O
challenging	O
long	O
text	O
generation	Task
is	O
hardly	O
studied	O
,	O
which	O
is	O
necessary	O
for	O
practical	O
tasks	O
such	O
as	O
auto	O
-	O
generation	Task
of	O
news	O
articles	O
or	O
product	Task
descriptions	Task
.	O

A	O
main	O
drawback	O
of	O
existing	O
methods	O
to	O
long	O
text	O
generation	Task
is	O
that	O
the	O
binary	O
guiding	O
signal	O
from	O
D	O
is	O
sparse	O
as	O
it	O
is	O
only	O
available	O
when	O
the	O
whole	O
text	O
sample	O
is	O
generated	O
.	O

Also	O
,	O
the	O
scalar	O
guiding	O
signal	O
for	O
a	O
whole	O
text	O
is	O
non	O
-	O
informative	O
as	O
it	O
does	O
not	O
necessarily	O
preserve	O
the	O
picture	O
about	O
the	O
intermediate	O
syntactic	O
structure	O
and	O
semantics	O
of	O
the	O
text	O
that	O
is	O
being	O
generated	O
for	O
G	O
to	O
sufficiently	O
learn	O
.	O

On	O
one	O
hand	O
,	O
to	O
make	O
the	O
guiding	O
signals	O
more	O
informative	O
,	O
discriminator	Method
D	Method
could	O
potentially	O
provide	O
more	O
guidance	O
beside	O
the	O
final	O
reward	Metric
value	Metric
,	O
since	O
D	O
is	O
a	O
trained	O
model	O
,	O
e.g.	O
a	O
convolutional	Method
neural	Method
network	Method
(	O
CNN	Method
)	O
[	O
reference	O
]	O
,	O
rather	O
than	O
an	O
unknown	O
black	O
box	O
.	O

With	O
that	O
idea	O
,	O
proposed	O
to	O
train	O
generator	Method
G	O
via	O
forcing	O
learned	O
feature	Method
representations	Method
of	O
real	O
and	O
generated	O
text	O
by	O
D	O
to	O
be	O
matched	O
,	O
instead	O
of	O
directly	O
training	O
G	O
to	O
maximize	O
the	O
reward	O
from	O
D	O
[	O
reference	O
]	O
.	O

Such	O
a	O
method	O
can	O
be	O
effective	O
in	O
short	O
text	O
generation	Task
,	O
but	O
the	O
guiding	O
signals	O
are	O
still	O
absent	O
until	O
the	O
end	O
of	O
the	O
text	O
)	O
.	O

On	O
the	O
other	O
hand	O
,	O
to	O
alleviate	O
the	O
sparsity	Task
problem	Task
of	Task
the	Task
guiding	Task
signal	Task
,	O
the	O
idea	O
of	O
hierarchy	O
naturally	O
arises	O
in	O
text	O
generation	Task
,	O
since	O
the	O
real	O
text	O
samples	O
are	O
generated	O
following	O
some	O
kinds	O
of	O
hierarchy	O
such	O
as	O
the	O
semantic	O
structure	O
and	O
the	O
part	O
-	O
of	O
-	O
speech	O
[	O
reference	O
]	O
.	O

By	O
decomposing	O
the	O
whole	O
generation	Task
task	O
into	O
various	O
sub	O
-	O
tasks	O
according	O
to	O
the	O
hierarchical	O
structure	O
,	O
it	O
becomes	O
much	O
easier	O
for	O
the	O
model	O
to	O
learn	O
.	O

Early	O
efforts	O
have	O
been	O
made	O
to	O
incorporate	O
the	O
hierarchy	Method
idea	Method
in	O
text	O
generation	Task
[	O
reference	O
][	O
reference	O
]	O
)	O
but	O
all	O
use	O
a	O
predefined	O
sub	O
-	O
task	O
set	O
from	O
domain	O
knowledge	O
,	O
which	O
makes	O
them	O
unable	O
to	O
adapt	O
to	O
arbitrary	O
sequence	O
generation	Task
tasks	O
.	O

In	O
this	O
paper	O
,	O
we	O
propose	O
a	O
new	O
algorithmic	Method
framework	Method
called	O
LeakGAN	Method
to	O
address	O
both	O
the	O
non	Task
-	Task
informativeness	Task
and	O
the	O
sparsity	Task
issues	Task
.	O

LeakGAN	Method
is	O
a	O
new	O
way	O
of	O
providing	O
richer	O
information	O
from	O
the	O
discriminator	Method
to	O
the	O
generator	Method
by	O
borrowing	O
the	O
recent	O
advances	O
in	O
hierarchical	Method
reinforcement	Method
learning	Method
[	O
reference	O
]	O
.	O

As	O
illustrated	O
in	O
Figure	O
1	O
,	O
we	O
specifically	O
introduce	O
a	O
hierarchical	O
generator	Method
G	O
,	O
which	O
consists	O
of	O
a	O
high	O
-	O
level	O
MANAGER	Method
module	O
and	O
a	O
low	O
-	O
level	O
WORKER	Method
module	O
.	O

The	O
MANAGER	Method
is	O
a	O
long	Method
shortterm	Method
memory	Method
network	Method
(	Method
LSTM	Method
)	Method
[	O
reference	O
]	O
and	O
serves	O
as	O
a	O
mediator	O
.	O

In	O
each	O
step	O
,	O
it	O
receives	O
generator	Method
D	O
's	O
high	O
-	O
level	O
feature	O
representation	O
,	O
e.g.	O
,	O
the	O
feature	O
map	O
of	O
the	O
CNN	Method
,	O
and	O
uses	O
it	O
to	O
form	O
the	O
guiding	O
goal	O
for	O
the	O
WORKER	Method
module	O
in	O
that	O
timestep	O
.	O

As	O
the	O
information	O
from	O
D	O
is	O
internally	O
-	O
maintained	O
and	O
in	O
an	O
adversarial	Method
game	Method
it	O
is	O
not	O
supposed	O
to	O
provide	O
G	O
with	O
such	O
information	O
.	O

We	O
thus	O
call	O
it	O
a	O
leakage	O
of	O
information	O
from	O
D.	O
Next	O
,	O
given	O
the	O
goal	O
embedding	O
produced	O
by	O
the	O
MAN	Method
-	Method
AGER	Method
,	O
the	O
WORKER	Method
first	O
encodes	O
current	O
generated	O
words	O
with	O
another	O
LSTM	Method
,	O
then	O
combines	O
the	O
output	O
of	O
the	O
LSTM	Method
and	O
the	O
goal	Method
embedding	Method
to	O
take	O
a	O
final	O
action	O
at	O
current	O
state	O
.	O

As	O
such	O
,	O
the	O
guiding	O
signals	O
from	O
D	O
are	O
not	O
only	O
available	O
to	O
G	O
at	O
the	O
end	O
in	O
terms	O
of	O
the	O
scalar	O
reward	O
signals	O
,	O
but	O
also	O
available	O
in	O
terms	O
of	O
a	O
goal	O
embedding	O
vector	O
during	O
the	O
generation	Method
process	Method
to	O
guide	O
G	O
how	O
to	O
get	O
improved	O
.	O

We	O
conduct	O
extensive	O
experiments	O
based	O
on	O
synthetic	O
and	O
real	O
data	O
.	O

For	O
synthetic	O
data	O
,	O
LeakGAN	Method
obtains	O
much	O
lower	O
negative	Metric
log	Metric
-	Metric
likelihood	Metric
than	O
previous	O
models	O
with	O
sequence	O
length	O
set	O
to	O
20	O
and	O
40	O
.	O

For	O
real	O
data	O
,	O
we	O
use	O
the	O
text	O
in	O
EMNLP2017	Material
WMT	Material
News	Material
,	O
COCO	Material
Image	Material
Caption	Material
and	O
Chinese	Material
Poems	Material
as	O
the	O
long	O
,	O
mid	O
-	O
length	O
and	O
short	O
text	O
corpus	O
,	O
respectively	O
.	O

In	O
all	O
those	O
cases	O
,	O
LeakGAN	Method
shows	O
significant	O
improvements	O
compared	O
to	O
previous	O
models	O
in	O
terms	O
of	O
BLEU	Metric
statistics	Metric
and	O
human	Metric
Turing	Metric
test	Metric
.	O

We	O
further	O
provide	O
a	O
deep	O
investigation	O
on	O
the	O
interaction	O
between	O
MAN	Task
-	Task
AGER	Task
and	O
WORKER	Method
,	O
which	O
indicates	O
LeakGAN	Method
implicitly	O
learns	O
sentence	O
structures	O
,	O
such	O
as	O
punctuation	O
,	O
clause	O
structure	O
and	O
long	O
suffix	O
without	O
any	O
supervision	O
.	O

Figure	O
1	O
:	O
An	O
overview	O
of	O
our	O
LeakGAN	Method
text	O
generation	Task
framework	O
.	O

While	O
the	O
generator	Method
is	O
responsible	O
to	O
generate	O
the	O
next	O
word	O
,	O
the	O
discriminator	Method
adversarially	Method
judges	O
the	O
generated	O
sentence	O
once	O
it	O
is	O
complete	O
.	O

The	O
chief	O
novelty	O
lies	O
in	O
that	O
,	O
unlike	O
conventional	O
adversarial	Method
training	Method
,	O
during	O
the	O
process	O
,	O
the	O
discriminator	O
reveals	O
its	O
internal	O
state	O
(	O
feature	O
f	O
t	O
)	O
in	O
order	O
to	O
guide	O
the	O
generator	Method
more	O
informatively	O
and	O
frequently	O
.	O

(	O
See	O
Methodology	O
Section	O
for	O
more	O
details	O
.	O

)	O
section	O
:	O
Related	O
Work	O
Generating	Task
text	Task
that	O
mimics	O
human	O
's	O
expression	O
has	O
been	O
studied	O
for	O
poem	Task
generation	Task
[	O
reference	O
]	O
,	O
image	Task
captioning	Task
,	O
dialogue	Task
system	Task
)	O
machine	Task
translation	Task
.	O

[	O
reference	O
]	O
proposed	O
a	O
recurent	Method
neural	Method
network	Method
(	Method
RNN	Method
)	Method
based	Method
generative	Method
model	Method
to	O
use	O
the	O
human	O
-	O
generated	O
text	O
where	O
at	O
each	O
step	O
the	O
model	O
tries	O
to	O
predict	O
the	O
next	O
word	O
given	O
previous	O
real	O
word	O
sequence	O
and	O
is	O
trained	O
in	O
a	O
supervised	Method
fashion	Method
.	O

A	O
common	O
difficulty	O
of	O
all	O
supervised	Method
generative	Method
models	Method
is	O
that	O
it	O
is	O
hard	O
to	O
design	O
an	O
appropriate	O
,	O
differentiable	Metric
,	Metric
lowbias	Metric
metric	Metric
to	O
evaluate	O
the	O
output	O
of	O
the	O
generator	Method
,	O
which	O
inspires	O
the	O
adversarial	Method
training	Method
mechanisms	Method
.	O

[	O
reference	O
]	O
proposed	O
generative	Method
adversarial	Method
nets	Method
(	O
GANs	Method
)	O
to	O
generate	O
continuous	O
data	O
like	O
images	O
.	O

GAN	Method
introduces	O
a	O
minimax	Method
game	Method
between	O
a	O
generative	Method
model	Method
and	O
a	O
discriminative	Method
model	Method
,	O
where	O
the	O
discriminator	Method
can	O
be	O
viewed	O
as	O
the	O
dynamically	O
-	O
updated	O
evaluation	Metric
metric	Metric
to	O
guide	O
the	O
tuning	O
of	O
the	O
generated	O
data	O
.	O

To	O
apply	O
GANs	Method
to	O
text	O
generation	Task
,	O
[	O
reference	O
]	O
proposed	O
SeqGAN	Method
that	O
models	O
the	O
text	O
generation	Task
as	O
a	O
sequential	Task
decision	Task
making	Task
process	Task
and	O
trains	O
the	O
generative	Method
model	Method
with	O
policy	Method
gradient	Method
methods	Method
.	O

MaliGAN	O
[	O
reference	O
]	O
)	O
modifies	O
the	O
orginal	O
GAN	Method
objective	O
and	O
proposes	O
a	O
set	O
of	O
training	Method
techniques	Method
to	O
reduce	O
the	O
potential	O
variance	O
.	O

To	O
deal	O
with	O
the	O
gradient	O
vanishing	O
problem	O
of	O
GAN	Method
,	O
RankGAN	Method
[	O
reference	O
]	O
proposes	O
an	O
alternative	O
solution	O
to	O
this	O
problem	O
by	O
replacing	O
the	O
original	O
binary	Method
classifier	Method
discriminator	Method
with	O
a	O
ranking	Method
model	Method
by	O
taking	O
a	O
softmax	O
over	O
the	O
expected	O
cosine	O
distances	O
from	O
the	O
generated	O
sequences	O
to	O
the	O
real	O
data	O
.	O

Another	O
problem	O
for	O
the	O
adversarial	O
sequence	O
generation	Task
models	O
is	O
that	O
the	O
binary	O
feedback	O
from	O
the	O
discriminator	Method
is	O
not	O
sufficiently	O
informative	O
,	O
which	O
requires	O
a	O
huge	O
number	O
of	O
training	O
and	O
generated	O
samples	O
to	O
improve	O
the	O
generator	Method
and	O
could	O
result	O
in	O
mode	Task
collapse	Task
problems	Task
.	O

Feature	Method
Matching	Method
)	O
provides	O
a	O
mechanism	O
that	O
matches	O
the	O
latent	O
feature	O
distributions	O
of	O
real	O
and	O
generated	O
sequences	O
via	O
a	O
kernelized	Method
discepancy	Method
metric	Method
to	O
alleviate	O
the	O
weak	Task
guidance	Task
and	Task
mode	Task
collapse	Task
problems	Task
.	O

However	O
,	O
such	O
enhancement	O
only	O
happens	O
when	O
the	O
whole	O
text	O
sample	O
is	O
generated	O
and	O
thus	O
the	O
guiding	O
signal	O
is	O
still	O
sparse	O
during	O
the	O
training	O
.	O

Reinforcement	Method
learning	Method
(	O
RL	Method
)	O
on	O
the	O
other	O
hand	O
also	O
faces	O
a	O
similar	O
difficulty	O
when	O
reward	O
signals	O
are	O
sparse	O
[	O
reference	O
]	O
)	O
.	O

Hierarchical	Method
RL	Method
is	O
one	O
of	O
the	O
promising	O
techniques	O
for	O
handling	O
the	O
sparse	Task
reward	Task
issue	Task
[	O
reference	O
]	O
.	O

A	O
typical	O
approach	O
in	O
hierarchical	Task
RL	Task
is	O
to	O
manually	O
identify	O
the	O
hierarchical	O
structure	O
for	O
the	O
agent	O
by	O
defining	O
several	O
low	O
-	O
level	O
sub	O
-	O
tasks	O
and	O
learning	O
micropolicies	O
for	O
each	O
sub	O
-	O
task	O
while	O
learning	O
a	O
macro	Method
-	Method
policy	Method
for	O
choosing	O
which	O
sub	O
-	O
task	O
to	O
solve	O
.	O

Such	O
methods	O
can	O
be	O
very	O
effective	O
when	O
the	O
hierarchical	O
structure	O
is	O
known	O
a	O
priori	O
using	O
domain	O
knowledge	O
in	O
a	O
given	O
specific	O
task	O
,	O
but	O
fail	O
to	O
flexibly	O
adapt	O
to	O
other	O
tasks	O
.	O

Recently	O
,	O
[	O
reference	O
]	O
proposed	O
an	O
end	Method
-	Method
to	Method
-	Method
end	Method
framework	Method
for	O
hierarchical	Task
RL	Task
where	O
the	O
sub	O
-	O
tasks	O
are	O
not	O
identified	O
manually	O
but	O
implicitly	O
learned	O
by	O
a	O
MANAGER	Method
module	O
which	O
takes	O
current	O
state	O
as	O
input	O
and	O
output	O
a	O
goal	O
embedding	O
vector	O
to	O
guide	O
the	O
low	O
-	O
level	O
WORKER	Method
module	O
.	O

In	O
this	O
work	O
,	O
we	O
model	O
the	O
text	O
generation	Task
procedure	O
via	O
adversarial	Method
training	Method
and	O
policy	Method
gradient	Method
[	O
reference	O
]	O
.	O

To	O
address	O
the	O
sparse	Task
reward	Task
issue	Task
in	O
long	O
text	O
generation	Task
,	O
we	O
follow	O
[	O
reference	O
]	O
and	O
propose	O
a	O
hierarchy	Method
design	Method
,	O
i.e.	O
MANAGER	Method
and	O
WORKER	Method
,	O
for	O
the	O
generator	Method
.	O

As	O
the	O
reward	O
function	O
in	O
our	O
case	O
is	O
a	O
discriminative	Method
model	Method
rather	O
than	O
a	O
black	O
box	O
in	O
[	O
reference	O
]	O
,	O
the	O
high	O
-	O
level	O
feature	O
extracted	O
by	O
the	O
discriminator	Method
given	O
the	O
current	O
generated	O
word	O
sequence	O
is	O
sent	O
to	O
the	O
MANAGER	Method
module	O
.	O

As	O
such	O
,	O
the	O
MANAGER	Method
module	O
can	O
be	O
also	O
viewed	O
as	O
a	O
spy	O
that	O
leaks	O
information	O
from	O
the	O
discriminator	Method
to	O
better	O
guide	O
the	O
generator	Method
.	O

To	O
our	O
knowledge	O
,	O
this	O
is	O
the	O
first	O
work	O
that	O
considers	O
the	O
information	O
leaking	O
in	O
GAN	Method
framework	O
for	O
better	O
training	Task
generators	Task
and	O
combines	O
hierarchical	Method
RL	Method
to	O
address	O
long	O
text	O
generation	Task
problems	O
.	O

section	O
:	O
Methodology	O
We	O
formalize	O
the	O
text	O
generation	Task
problem	O
as	O
a	O
sequential	Task
decision	Task
making	Task
process	Task
[	O
reference	O
]	O
.	O

Specifically	O
,	O
at	O
each	O
timestep	O
t	O
,	O
the	O
agent	O
takes	O
the	O
previously	O
generated	O
words	O
as	O
its	O
current	O
state	O
,	O
denoted	O
as	O
s	O
t	O
=	O
(	O
x	O
1	O
,	O
.	O

.	O

.	O

,	O
x	O
i	O
,	O
.	O

.	O

.	O

,	O
x	O
t	O
)	O
,	O
where	O
x	O
i	O
represents	O
a	O
word	O
token	O
in	O
the	O
given	O
vocabulary	O
V	O
.	O

A	O
θ	Method
-	Method
parameterized	Method
generative	Method
net	Method
G	Method
θ	Method
,	O
which	O
corresponds	O
to	O
a	O
stochastic	Method
policy	Method
,	O
maps	O
s	O
t	O
to	O
a	O
distribution	O
over	O
the	O
whole	O
vocabulary	O
,	O
i.e.	O
G	O
θ	O
(	O
·	O
|s	O
t	O
)	O
,	O
from	O
which	O
the	O
action	O
x	O
t	O
+	O
1	O
,	O
i.e.	O
the	O
next	O
word	O
to	O
select	O
is	O
sampled	O
.	O

We	O
also	O
train	O
a	O
φ	Method
-	Method
parameterized	Method
discriminative	Method
model	Method
D	Method
φ	Method
that	O
provides	O
a	O
scalar	O
guiding	O
signal	O
D	O
φ	O
(	O
s	O
T	O
)	O
for	O
G	O
θ	O
to	O
adjust	O
its	O
parameters	O
when	O
the	O
whole	O
sentence	O
s	O
T	O
has	O
been	O
generated	O
.	O

As	O
we	O
discussed	O
previously	O
,	O
although	O
the	O
above	O
adversarial	Method
training	Method
is	O
principled	O
,	O
the	O
scalar	O
guiding	O
signal	O
becomes	O
relatively	O
less	O
informative	O
when	O
the	O
sentence	O
length	O
T	O
goes	O
larger	O
.	O

To	O
address	O
this	O
,	O
the	O
proposed	O
LeakGAN	Method
framework	O
allows	O
discriminator	Method
D	Method
φ	Method
to	O
provide	O
additional	O
information	O
,	O
denoted	O
as	O
features	O
f	O
t	O
,	O
of	O
the	O
current	O
sentence	O
s	O
t	O
(	O
it	O
is	O
internally	O
used	O
for	O
D	O
φ	O
itself	O
for	O
discrimination	Task
)	O
to	O
generator	Method
G	O
θ	O
(	O
·	O
|s	O
t	O
)	O
.	O

In	O
LeakGAN	Method
,	O
a	O
hierarchical	Method
RL	Method
architecture	Method
is	O
used	O
as	O
a	O
promising	O
mechanism	O
to	O
effectively	O
incorporate	O
such	O
leaked	O
information	O
f	O
t	O
into	O
the	O
generation	Task
procedure	Task
of	O
G	Method
θ	Method
(	O
also	O
see	O
Figure	O
1	O
)	O
.	O

section	O
:	O
Leaked	O
Features	O
from	O
D	O
as	O
Guiding	Method
Signals	Method
Different	O
from	O
typical	O
model	Method
-	Method
free	Method
RL	Method
settings	Method
where	O
the	O
reward	O
function	O
is	O
a	O
black	O
box	O
,	O
our	O
adversarial	O
text	O
generation	Task
uses	O
D	Method
φ	Method
as	O
a	O
learned	O
reward	O
function	O
.	O

Typically	O
,	O
D	Method
φ	Method
is	O
a	O
neural	Method
network	Method
and	O
can	O
be	O
decomposed	O
into	O
a	O
feature	Method
extractor	Method
F	Method
(	O
·	O
;	O
φ	O
f	O
)	O
and	O
a	O
final	O
sigmoid	Method
classification	Method
layer	Method
with	O
weight	O
vector	O
φ	O
l	O
.	O

Mathematically	O
,	O
given	O
input	O
s	O
,	O
we	O
have	O
where	O
φ	O
=	O
(	O
φ	O
f	O
,	O
φ	O
l	O
)	O
and	O
sigmoid	O
(	O
z	O
)	O
=	O
1	O
/(	O
1	O
+	O
e	O
−z	O
)	O
.	O

f	O
=	O
F	O
(	O
s	O
;	O
φ	O
f	O
)	O
is	O
the	O
feature	O
vector	O
of	O
s	O
in	O
the	O
last	O
layer	O
of	O
D	O
φ	O
,	O
which	O
is	O
to	O
be	O
leaked	O
to	O
generator	Method
G	O
θ	O
.	O

As	O
is	O
shown	O
in	O
Eq	O
.	O

(	O
1	O
)	O
,	O
for	O
a	O
given	O
D	O
φ	O
,	O
the	O
reward	O
value	O
for	O
each	O
state	O
s	O
mainly	O
depends	O
on	O
the	O
extracted	O
features	O
f	O
.	O

As	O
such	O
,	O
the	O
objective	O
of	O
getting	O
a	O
higher	O
reward	O
from	O
D	O
φ	O
is	O
equivalent	O
to	O
finding	O
a	O
higher	O
reward	O
region	O
in	O
this	O
extracted	O
feature	O
space	O
F	O
(	O
S	O
;	O
φ	O
f	O
)	O
=	O
{	O
F	O
(	O
s	O
;	O
φ	O
f	O
)	O
}	O
s∈S	O
.	O

Specifically	O
,	O
our	O
feature	Method
extractor	Method
F	O
(	O
·	O
;	O
φ	O
f	O
)	O
in	O
D	O
φ	O
is	O
implemented	O
by	O
a	O
CNN	Method
[	O
reference	O
]	O
;	O
thus	O
F	O
(	O
s	O
;	O
φ	O
f	O
)	O
outputs	O
the	O
CNN	O
feature	O
map	O
vector	O
as	O
f	O
after	O
its	O
convolution	Method
-	Method
pooling	Method
-	Method
activation	Method
layer	Method
.	O

Other	O
neural	Method
network	Method
models	Method
such	O
as	O
LSTM	Method
(	O
Hochreiter	O
and	O
Schmidhuber	O
1997	O
)	O
can	O
also	O
be	O
used	O
to	O
implement	O
Compared	O
to	O
the	O
scalar	O
signal	O
D	O
φ	O
(	O
s	O
)	O
,	O
the	O
feature	O
vector	O
f	O
is	O
a	O
much	O
more	O
informative	O
guiding	O
signal	O
for	O
G	Task
θ	Task
,	O
since	O
it	O
tells	O
what	O
the	O
position	O
of	O
currently	O
-	O
generated	O
words	O
is	O
in	O
the	O
extracted	O
feature	O
space	O
.	O

section	O
:	O
A	O
Hierarchical	O
Structure	O
of	O
G	O
In	O
each	O
step	O
t	O
during	O
the	O
generation	Task
procedure	Task
,	O
to	O
utilize	O
the	O
leaked	O
information	O
f	O
t	O
from	O
D	O
φ	O
,	O
we	O
follow	O
hierarchical	Method
RL	Method
[	O
reference	O
]	O
to	O
have	O
a	O
hierarchical	Method
architecture	Method
of	Method
G	Method
θ	Method
.	O

Specifically	O
,	O
we	O
introduce	O
a	O
MANAGER	Method
module	O
,	O
an	O
LSTM	Method
that	O
takes	O
the	O
extracted	O
feature	O
vector	O
f	O
t	O
as	O
its	O
input	O
at	O
each	O
step	O
t	O
and	O
outputs	O
a	O
goal	O
vector	O
g	O
t	O
,	O
which	O
is	O
then	O
fed	O
into	O
the	O
WORKER	Method
module	O
to	O
guide	O
the	O
generation	Task
of	O
the	O
next	O
word	O
in	O
order	O
to	O
approach	O
the	O
higher	O
reward	O
region	O
in	O
F	O
(	O
S	O
;	O
φ	O
f	O
)	O
.	O

Next	O
we	O
will	O
first	O
describe	O
the	O
detailed	O
generator	Method
model	O
in	O
LeakGAN	Method
and	O
then	O
show	O
how	O
the	O
MANAGER	Method
and	O
WORKER	Method
are	O
trained	O
with	O
the	O
guiding	O
signals	O
from	O
D	O
φ	O
.	O

Generation	Task
Process	Task
.	O

The	O
MANAGER	Method
and	O
WORKER	Method
modules	Method
both	O
start	O
from	O
an	O
all	O
-	O
zero	O
hidden	O
state	O
,	O
denoted	O
as	O
h	O
M	O
0	O
and	O
h	O
W	O
0	O
respectively	O
.	O

At	O
each	O
step	O
,	O
the	O
MANAGER	Method
receives	O
the	O
leaked	O
feature	O
vector	O
f	O
t	O
from	O
the	O
discriminator	Method
D	Method
φ	Method
,	O
which	O
is	O
further	O
combined	O
with	O
current	O
hidden	O
state	O
of	O
the	O
MANAGER	Method
to	O
produce	O
the	O
goal	O
vector	O
g	O
t	O
aŝ	O
where	O
M	O
(	O
·	O
;	O
θ	O
m	O
)	O
denotes	O
the	O
MANAGER	Method
module	O
implemented	O
by	O
an	O
LSTM	Method
with	O
parameters	O
θ	O
m	O
and	O
h	O
M	O
t	O
is	O
the	O
recurrent	O
hidden	O
vector	O
of	O
the	O
LSTM	Method
.	O

To	O
incorporate	O
goals	O
produced	O
by	O
MANAGER	Method
,	O
a	O
linear	Method
transformation	Method
ψ	Method
with	O
weight	O
matrix	O
W	O
ψ	O
is	O
performed	O
on	O
a	O
summation	O
over	O
recent	O
c	O
goals	O
to	O
produce	O
a	O
k	O
-	O
dimensional	O
goal	O
embedding	O
vector	O
w	O
t	O
as	O
Given	O
the	O
goal	O
embedding	O
vector	O
w	O
t	O
,	O
the	O
WORKER	Method
module	O
takes	O
the	O
current	O
word	O
x	O
t	O
as	O
input	O
and	O
outputs	O
a	O
matrix	O
O	O
t	O
,	O
which	O
is	O
further	O
combined	O
with	O
w	O
t	O
by	O
matrix	Method
product	Method
to	O
determine	O
the	O
final	O
action	O
space	O
distribution	O
under	O
current	O
state	O
s	O
t	O
through	O
a	O
softmax	Method
where	O
W	O
(	O
·	O
;	O
θ	O
w	O
)	O
denotes	O
the	O
WORKER	Method
module	O
,	O
i.e.	O
an	O
LSTM	Method
with	O
h	O
W	O
t	O
as	O
its	O
recurrent	O
hidden	O
vector	O
,	O
O	O
t	O
is	O
a	O
|V	O
|×k	O
matrix	O
that	O
represents	O
the	O
current	O
vector	O
for	O
all	O
words	O
,	O
thus	O
O	O
t	O
·	O
w	O
t	O
yields	O
the	O
calculated	O
logits	O
for	O
all	O
words	O
,	O
and	O
α	O
is	O
the	O
temperature	O
parameter	O
to	O
control	O
the	O
generation	Task
entropy	O
.	O

section	O
:	O
Training	O
of	O
G	O
Notice	O
that	O
the	O
above	O
procedure	O
is	O
fully	O
differentiable	O
.	O

One	O
can	O
train	O
G	Method
θ	Method
in	O
an	O
end	O
-	O
to	O
-	O
end	O
manner	O
using	O
a	O
policy	Method
gradient	Method
algorithm	Method
such	O
as	O
REINFORCE	Method
[	O
reference	O
]	O
.	O

In	O
LeakGAN	Method
,	O
we	O
would	O
hope	O
the	O
MANAGER	Method
module	O
to	O
capture	O
some	O
meaningful	O
patterns	O
.	O

Thus	O
,	O
we	O
follow	O
[	O
reference	O
]	O
)	O
and	O
train	O
the	O
MANAGER	Method
and	O
WORKER	Method
modules	Method
separately	O
,	O
where	O
the	O
MANAGER	Method
is	O
trained	O
to	O
predict	O
advantageous	O
directions	O
in	O
the	O
discriminative	O
feature	O
space	O
and	O
the	O
WORKER	Method
is	O
intrinsically	O
rewarded	O
to	O
follow	O
such	O
directions	O
.	O

Similar	O
to	O
[	O
reference	O
]	O
,	O
the	O
gradient	O
of	O
the	O
MAN	Method
-	Method
AGER	Method
module	Method
is	O
defined	O
as	O
is	O
the	O
expected	O
reward	O
under	O
the	O
current	O
policy	O
which	O
can	O
be	O
approximately	O
estimated	O
via	O
Monte	Method
Carlo	Method
search	Method
[	O
reference	O
][	O
reference	O
]	O
.	O

d	O
cos	O
represents	O
the	O
cosine	O
similarity	O
between	O
the	O
change	O
of	O
feature	Method
representation	Method
after	O
cstep	O
transitions	O
,	O
i.e.	O
f	O
t	O
+	O
c	O
−	O
f	O
t	O
,	O
and	O
the	O
goal	O
vector	O
g	O
t	O
(	O
θ	O
m	O
)	O
1	O
produced	O
by	O
MANAGER	Method
as	O
in	O
Eq	O
.	O

(	O
2	O
)	O
.	O

Intuitively	O
,	O
the	O
loss	O
function	O
is	O
to	O
force	O
the	O
goal	O
vector	O
to	O
match	O
the	O
transition	O
in	O
the	O
feature	O
space	O
while	O
achieving	O
high	O
reward	O
.	O

At	O
the	O
same	O
time	O
,	O
the	O
WORKER	Method
is	O
trained	O
to	O
maximize	O
the	O
reward	O
using	O
the	O
REINFORCE	Method
algorithm	Method
[	O
reference	O
]	O
as	O
is	O
done	O
in	O
[	O
reference	O
]	O
,	O
[	O
reference	O
]	O
We	O
use	O
gt	Method
(	Method
θm	Method
)	O
to	O
explicitly	O
show	O
gt	Method
is	O
parameterized	O
by	O
θm	O
.	O

which	O
can	O
be	O
approximated	O
by	O
sampling	O
the	O
state	O
s	O
t−1	O
and	O
the	O
action	O
x	O
t	O
taken	O
by	O
WORKER	Method
.	O

As	O
the	O
WORKER	Method
is	O
encouraged	O
to	O
follow	O
the	O
directions	O
produced	O
by	O
the	O
MANAGER	Method
,	O
following	O
[	O
reference	O
]	O
,	O
the	O
intrinsic	O
reward	O
for	O
the	O
WORKER	Method
is	O
defined	O
as	O
In	O
practice	O
,	O
before	O
the	O
adversarial	Method
training	Method
,	O
we	O
need	O
to	O
pretrain	O
G	O
θ	O
.	O

To	O
be	O
consistent	O
,	O
in	O
the	O
pre	Task
-	Task
train	Task
stage	Task
,	O
we	O
also	O
use	O
the	O
separate	O
training	Method
scheme	Method
,	O
where	O
the	O
gradient	Method
of	Method
MAN	Method
-	Method
AGER	Method
is	O
wheref	O
t	O
=	O
F	O
(	O
ŝ	O
t	O
)	O
,	O
ŝ	O
t	O
andŝ	O
t	O
+	O
c	O
are	O
states	O
of	O
real	O
text	O
,	O
and	O
the	O
state	O
-	O
action	O
value	O
Q	O
F	O
(	O
s	O
t	O
,	O
g	O
t	O
)	O
in	O
Eq	O
.	O

(	O
7	O
)	O
is	O
set	O
as	O
1	O
here	O
since	O
the	O
data	O
instances	O
used	O
in	O
pre	O
-	O
training	O
are	O
all	O
real	O
sentences	O
.	O

As	O
such	O
,	O
the	O
MANAGER	Method
is	O
trained	O
to	O
mimic	O
the	O
transition	O
of	O
real	O
text	O
samples	O
in	O
the	O
feature	O
space	O
.	O

While	O
the	O
WORKER	Method
is	O
trained	O
via	O
maximum	Method
likelihood	Method
estimation	Method
(	O
MLE	Method
)	O
.	O

In	O
the	O
training	Task
process	Task
,	O
the	O
generator	Method
G	O
θ	O
and	O
discriminator	Method
D	Method
φ	Method
are	O
alternatively	O
trained	O
.	O

In	O
the	O
generator	Method
,	O
the	O
MAN	Method
-	Method
AGER	Method
M	Method
(	O
·	O
;	O
θ	O
m	O
)	O
and	O
WORKER	Method
W	Method
(	O
·	O
;	O
θ	O
w	O
)	O
(	O
including	O
ψ	Method
and	O
softmax	Method
)	O
are	O
alternatively	O
trained	O
while	O
fixing	O
the	O
other	O
.	O

The	O
details	O
of	O
the	O
training	O
procedure	O
are	O
attached	O
in	O
the	O
supplementary	O
material	O
2	O
.	O

section	O
:	O
Training	O
Techniques	O
Bootstrapped	Method
Rescaled	Method
Activation	Method
.	O

During	O
the	O
adversarial	Task
training	Task
of	O
[	O
reference	O
]	O
,	O
severe	O
gradient	Task
vanishing	Task
occurs	O
when	O
D	O
is	O
much	O
stronger	O
than	O
G	O
,	O
i.e.	O
the	O
reward	O
is	O
too	O
small	O
value	O
to	O
update	O
the	O
parameters	O
and	O
thus	O
need	O
be	O
rescaled	O
before	O
being	O
fed	O
into	O
G.	O
Inspired	O
by	O
ranking	O
idea	O
from	O
RankGAN	Method
[	O
reference	O
]	O
)	O
,	O
we	O
propose	O
a	O
simple	O
,	O
time	O
-	O
efficient	O
,	O
rank	Method
-	Method
based	Method
method	Method
to	O
rescale	O
the	O
rewards	O
,	O
named	O
as	O
bootstrapped	Method
rescaled	Method
activation	Method
.	O

For	O
a	O
mini	O
-	O
batch	O
with	O
B	O
sequences	O
,	O
after	O
the	O
rollout	O
of	O
the	O
generative	Method
model	Method
,	O
the	O
reward	O
matrix	O
is	O
denoted	O
as	O
R	O
B×T	O
.	O

For	O
each	O
timestep	O
t	O
,	O
we	O
rescale	O
the	O
t	O
-	O
th	O
column	O
vector	O
R	O
where	O
rank	O
(	O
i	O
)	O
denotes	O
the	O
i	O
-	O
th	O
element	O
's	O
high	O
-	O
to	O
-	O
low	O
ranking	O
in	O
this	O
column	O
vector	O
.	O

δ	O
is	O
a	O
hyperparameter	O
that	O
controls	O
the	O
smoothness	O
of	O
the	O
rescale	O
activation	O
.	O

σ	O
(	O
·	O
)	O
is	O
an	O
activation	Method
function	Method
that	O
re	O
-	O
projects	O
the	O
equidifferent	O
scoring	O
based	O
on	O
ranking	Task
to	O
a	O
more	O
effective	O
distribution	O
.	O

In	O
our	O
experiment	O
,	O
for	O
example	O
,	O
the	O
model	O
adopts	O
hyperparameter	O
δ	O
=	O
12.0	O
and	O
the	O
sigmoid	O
function	O
as	O
σ	O
(	O
·	O
)	O
.	O

There	O
are	O
two	O
main	O
advantages	O
of	O
the	O
bootstrapped	Method
rescaled	Method
activation	Method
.	O

First	O
,	O
after	O
this	O
transformation	O
,	O
the	O
expectation	O
and	O
variance	O
of	O
the	O
reward	O
in	O
each	O
mini	O
-	O
batch	O
are	O
constant	O
.	O

In	O
this	O
case	O
,	O
the	O
rescale	O
activation	O
serves	O
as	O
a	O
value	Method
stabilizer	Method
that	O
is	O
helpful	O
for	O
algorithms	O
that	O
are	O
sensitive	O
in	O
numerical	O
variance	O
.	O

Second	O
,	O
as	O
all	O
ranking	Method
methods	Method
do	O
,	O
it	O
prevents	O
the	O
gradient	Task
vanishing	Task
problem	Task
,	O
which	O
accelerates	O
the	O
model	Task
convergence	Task
.	O

Interleaved	Method
Training	Method
.	O

In	O
traditional	O
generative	Method
adversarial	Method
models	Method
,	O
mode	Task
collapse	Task
is	O
a	O
common	O
problem	O
.	O

Here	O
we	O
propose	O
a	O
training	Method
scheme	Method
called	O
interleaved	Method
training	Method
to	O
alleviate	O
such	O
a	O
problem	O
.	O

As	O
its	O
name	O
is	O
,	O
we	O
adopt	O
an	O
interleaving	Method
of	Method
supervised	Method
training	Method
(	O
i.e.	Method
MLE	Method
)	O
and	O
adversarial	Method
training	Method
(	O
i.e.	O
GAN	Method
)	O
instead	O
of	O
full	O
GAN	Method
after	O
the	O
pre	Method
-	Method
training	Method
.	O

For	O
example	O
,	O
we	O
perform	O
one	O
epoch	O
of	O
supervised	Method
learning	Method
for	O
G	O
after	O
15	O
epochs	O
of	O
adversarial	Method
training	Method
.	O

An	O
explanation	O
of	O
why	O
this	O
scheme	O
works	O
is	O
that	O
blending	O
these	O
two	O
trainings	O
would	O
help	O
GAN	Method
get	O
rid	O
of	O
some	O
bad	O
local	O
minimums	O
and	O
alleviate	O
mode	O
collapse	O
.	O

Another	O
justification	O
is	O
that	O
the	O
inserted	O
supervised	Method
learning	Method
performs	O
an	O
implicit	Method
regularization	Method
on	O
the	O
generative	Method
model	Method
to	O
prevent	O
it	O
from	O
going	O
too	O
far	O
away	O
from	O
the	O
MLE	Method
solution	Method
.	O

Temperature	Task
Control	Task
.	O

The	O
Boltzmann	O
temperature	O
α	O
in	O
Eq	O
.	O

(	O
6	O
)	O
is	O
a	O
factor	O
that	O
could	O
be	O
used	O
to	O
balance	O
the	O
exploration	Task
and	Task
exploitation	Task
for	O
reinforcement	Task
learning	Task
problems	Task
.	O

Here	O
we	O
select	O
a	O
higher	O
temperature	O
when	O
we	O
are	O
training	O
the	O
model	O
and	O
a	O
lower	O
temperature	O
when	O
we	O
adopt	O
the	O
model	O
to	O
generate	O
samples	O
.	O

section	O
:	O
Experiment	O
The	O
experiment	O
consists	O
of	O
three	O
parts	O
:	O
synthetic	O
data	O
experiments	O
,	O
experiments	O
in	O
real	O
-	O
world	O
scenarios	O
and	O
some	O
explanation	O
study	O
.	O

The	O
repeatable	O
experiment	O
code	O
is	O
published	O
for	O
further	O
research	O
3	O
.	O

section	O
:	O
Training	O
Settings	O
Synthetic	O
Oracle	O
.	O

For	O
the	O
synthetic	O
data	O
experiments	O
,	O
simlar	O
to	O
(	O
Yu	O
et	O
al	O
.	O

2017	O
)	O
,	O
we	O
first	O
initialize	O
the	O
parameters	O
of	O
an	O
LSTM	Method
following	O
the	O
normal	O
distribution	O
N	O
(	O
0	O
,	O
1	O
)	O
as	O
the	O
oracle	O
describing	O
the	O
real	O
data	O
distribution	O
G	O
oracle	O
(	O
x	O
t	O
|x	O
1	O
,	O
.	O

.	O

.	O

,	O
x	O
t−1	O
)	O
.	O

We	O
use	O
it	O
to	O
generate	O
10	O
,	O
000	O
sequences	O
of	O
length	O
20	O
and	O
40	O
respectively	O
as	O
the	O
training	O
set	O
S	O
for	O
the	O
generative	Method
models	Method
.	O

GAN	Method
Setting	O
.	O

For	O
the	O
discriminator	Method
,	O
we	O
choose	O
the	O
CNN	Method
architecture	Method
[	O
reference	O
]	O
as	O
the	O
feature	Method
extractor	Method
and	O
the	O
binary	Method
classifier	Method
.	O

Note	O
that	O
one	O
could	O
design	O
specific	O
structure	O
for	O
different	O
tasks	O
to	O
refine	O
the	O
CNN	Task
performance	O
.	O

For	O
the	O
synthetic	O
data	O
experiment	O
,	O
the	O
CNN	O
kernel	O
size	O
ranges	O
from	O
1	O
to	O
T	O
.	O

The	O
number	O
of	O
each	O
kernel	O
is	O
between	O
100	O
and	O
200	O
.	O

In	O
this	O
case	O
,	O
the	O
feature	O
of	O
text	O
is	O
a	O
1	O
,	O
720	O
dimensional	O
vector	O
.	O

Dropout	Method
[	O
reference	O
]	O
)	O
with	O
the	O
keep	Metric
rate	Metric
0.75	Metric
and	O
L2	Method
regularization	Method
are	O
performed	O
to	O
avoid	O
overfitting	O
.	O

For	O
the	O
generator	Method
,	O
we	O
adopt	O
LSTM	Method
[	O
reference	O
]	O
as	O
the	O
architectures	O
of	O
MANAGER	Method
and	O
WORKER	Method
to	O
capture	O
the	O
sequence	O
context	O
information	O
.	O

The	O
MANAGER	Method
produces	O
the	O
16	O
-	O
dimensional	O
goal	O
embedding	O
feature	O
vector	O
w	O
t	O
using	O
the	O
feature	O
map	O
extracted	O
by	O
CNN	Method
.	O

The	O
goal	O
duration	O
time	O
c	O
is	O
a	O
hyperparameter	O
set	O
as	O
4	O
after	O
some	O
preliminary	O
experiments	O
.	O

Compared	O
Models	O
.	O

For	O
most	O
parts	O
of	O
our	O
experiment	O
,	O
three	O
baseline	O
models	O
are	O
mainly	O
compared	O
with	O
LeakGAN	Method
,	O
namely	O
an	O
MLE	Method
trained	Method
LSTM	Method
,	O
[	O
reference	O
]	O
and	O
RankGAN	Method
.	O

We	O
also	O
compare	O
model	O
3	O
https:	O
//	O
github.com	O
/	O
CR	O
-	O
Gjx	O
/	O
LeakGAN	Method
.	O

variants	O
,	O
such	O
as	O
SeqGAN	Method
with	O
bootstrapped	Method
rescaled	Method
activation	Method
,	O
and	O
include	O
the	O
real	O
data	O
to	O
be	O
referred	O
as	O
the	O
performance	O
upperbound	O
.	O

Evaluation	Metric
Metrics	Metric
.	O

Negative	Method
log	Method
-	Method
likehood	Method
(	Method
NLL	Method
)	Method
is	O
used	O
for	O
synthetic	O
data	O
experiment	O
since	O
there	O
is	O
the	O
oracle	O
data	O
distribution	O
available	O
for	O
evaluation	O
.	O

For	O
real	O
-	O
world	O
data	O
experiments	O
,	O
BLEU	Metric
statistics	Metric
[	O
reference	O
]	O
and	O
human	Metric
rating	Metric
scores	Metric
in	O
the	O
Turing	Metric
test	Metric
are	O
reported	O
.	O

We	O
further	O
perform	O
a	O
t	Metric
-	Metric
test	Metric
for	O
the	O
improvement	O
of	O
LeakGAN	Method
over	O
the	O
second	O
highest	O
performance	O
and	O
report	O
the	O
p	Metric
-	Metric
value	Metric
.	O

section	O
:	O
Synthetic	O
Data	O
Experiments	O
We	O
run	O
the	O
synthetic	O
data	O
experiment	O
with	O
the	O
text	O
-	O
length	O
set	O
as	O
20	O
and	O
40	O
respectively	O
.	O

The	O
training	O
curves	O
are	O
depicted	O
in	O
Figure	O
2	O
and	O
the	O
overall	O
NLL	Metric
performance	O
is	O
presented	O
in	O
Table	O
1	O
.	O

One	O
could	O
have	O
two	O
observations	O
from	O
the	O
results	O
.	O

(	O
i	O
)	O
In	O
the	O
pre	Task
-	Task
training	Task
stage	Task
,	O
LeakGAN	Method
has	O
already	O
shown	O
observable	O
performance	O
superiority	O
compared	O
to	O
other	O
models	O
,	O
which	O
indicates	O
that	O
the	O
proposed	O
hierarchical	Method
architecture	Method
itself	O
brings	O
improvement	O
over	O
the	O
previous	O
ones	O
.	O

(	O
ii	O
)	O
In	O
the	O
adversarial	Task
training	Task
stage	Task
,	O
LeakGAN	Method
shows	O
a	O
better	O
speed	O
of	O
convergence	Metric
,	O
and	O
the	O
local	O
minimum	O
it	O
explores	O
is	O
significantly	O
better	O
than	O
previous	O
results	O
.	O

The	O
results	O
demonstrate	O
the	O
effectiveness	O
of	O
the	O
information	Method
leakage	Method
framework	Method
and	O
the	O
hierarchical	Method
RL	Method
architecture	Method
for	O
generating	O
both	O
short	O
and	O
long	O
texts	O
.	O

section	O
:	O
Long	Task
Text	Task
Generation	Task
:	O
EMNLP2017	Material
WMT	Material
News	Material
We	O
choose	O
the	O
EMNLP2017	Material
WMT	Material
4	Material
Dataset	Material
as	O
the	O
long	O
text	O
corpus	O
.	O

Specifically	O
,	O
we	O
pick	O
the	O
News	O
section	O
from	O
the	O
original	O
dataset	O
.	O

The	O
news	O
dataset	O
consists	O
of	O
646	O
,	O
459	O
words	O
and	O
397	O
,	O
726	O
sentences	O
.	O

We	O
preprocess	O
the	O
data	O
by	O
eliminating	O
the	O
words	O
with	O
frequency	O
lower	O
than	O
4	O
,	O
050	O
as	O
well	O
as	O
the	O
sentence	O
containing	O
these	O
low	O
frequency	O
words	O
.	O

Besides	O
,	O
to	O
focus	O
on	O
long	O
sentences	O
,	O
we	O
remove	O
the	O
sentences	O
with	O
length	O
less	O
than	O
20	O
.	O

After	O
the	O
preprocessing	O
,	O
the	O
news	O
dataset	O
has	O
5	O
,	O
742	O
words	O
and	O
397	O
,	O
726	O
sentences	O
.	O

Then	O
we	O
randomly	O
sample	O
200	O
,	O
000	O
sentences	O
as	O
the	O
training	O
set	O
and	O
another	O
10	O
,	O
000	O
sentences	O
as	O
the	O
test	O
set	O
.	O

We	O
use	O
the	O
BLEU	Metric
-(	Metric
2	Metric
to	Metric
5	Metric
)	Metric
scores	O
[	O
reference	O
]	O
as	O
the	O
evaluation	Metric
metrics	Metric
.	O

The	O
results	O
are	O
provided	O
in	O
Table	O
2	O
.	O

In	O
all	O
measured	O
metrics	Metric
,	O
LeakGAN	Method
shows	O
significant	O
performance	O
gain	O
compared	O
to	O
baseline	O
models	O
.	O

The	O
consistently	O
higher	O
BLEU	Metric
scores	Metric
indicate	O
that	O
the	O
generated	O
sentences	O
of	O
LeakGAN	Method
are	O
of	O
high	O
quality	O
in	O
local	O
features	O
to	O
mimic	O
the	O
real	O
text	O
.	O

section	O
:	O
Middle	Task
Text	Task
Generation	Task
:	O
COCO	Material
Image	Material
Captions	Material
Another	O
real	O
dataset	O
we	O
use	O
is	O
the	O
COCO	Material
Image	Material
Captions	Material
Dataset	Material
[	O
reference	O
]	O
,	O
a	O
dataset	O
which	O
contains	O
groups	O
of	O
image	O
-	O
description	O
pairs	O
.	O

We	O
take	O
the	O
image	O
captions	O
as	O
the	O
text	O
to	O
generate	O
.	O

Note	O
that	O
the	O
COCO	Material
Dataset	Material
is	O
not	O
a	O
long	O
text	O
dataset	O
,	O
in	O
which	O
most	O
sentences	O
are	O
of	O
about	O
10	O
words	O
.	O

Thus	O
we	O
apply	O
some	O
preprocessing	O
on	O
the	O
dataset	O
.	O

The	O
COCO	Material
Image	Material
Captions	Material
training	Material
dataset	Material
consists	O
of	O
20	O
,	O
734	O
words	O
and	O
417	O
,	O
126	O
sentences	O
.	O

We	O
remove	O
the	O
words	O
with	O
frequency	O
lower	O
than	O
10	O
as	O
well	O
as	O
the	O
sentence	O
containing	O
them	O
.	O

After	O
the	O
preprocessing	O
,	O
the	O
dataset	O
includes	O
4	O
,	O
980	O
words	O
.	O

We	O
randomly	O
sample	O
80	O
,	O
000	O
sentences	O
for	O
the	O
training	O
set	O
,	O
and	O
another	O
5	O
,	O
000	O
for	O
the	O
test	O
set	O
.	O

The	O
results	O
BLEU	Metric
scores	Metric
are	O
provided	O
in	O
Table	O
3	O
.	O

The	O
results	O
of	O
the	O
BLEU	Metric
scores	Metric
on	O
the	O
COCO	Material
dataset	Material
indicate	O
that	O
LeakGAN	Method
performs	O
significantly	O
better	O
than	O
baseline	O
models	O
in	O
mid	O
-	O
length	O
text	O
generation	Task
task	O
.	O

section	O
:	O
Short	Task
Text	Task
Generation	Task
:	O
Chinese	Material
Poems	Material
To	O
evaluate	O
the	O
performance	O
of	O
LeakGAN	Method
in	O
short	O
text	O
generation	Task
,	O
we	O
pick	O
the	O
dataset	O
of	O
Chinese	Material
poems	Material
which	O
is	O
proposed	O
by	O
[	O
reference	O
]	O
and	O
most	O
related	O
work	O
such	O
as	O
[	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
)	O
.	O

The	O
dataset	O
consists	O
of	O
4	Material
-	Material
line	Material
5	Material
-	Material
character	Material
poems	Material
.	O

Following	O
the	O
above	O
work	O
,	O
we	O
use	O
the	O
BLEU	Metric
-	Metric
2	Metric
scores	Metric
as	O
the	O
evaluating	Metric
metrics	Metric
.	O

The	O
experimental	O
results	O
are	O
provided	O
in	O
Table	O
4	O
.	O

The	O
results	O
on	O
Chinese	Material
Poems	Material
indicate	O
that	O
LeakGAN	Method
successfully	O
handles	O
the	O
short	O
text	O
generation	Task
tasks	O
.	O

Figure	O
3	O
:	O
The	O
illustration	O
of	O
BLEU	Metric
improvement	Metric
change	O
along	O
with	O
the	O
generated	O
text	O
length	O
on	O
WMT	Material
News	Material
.	O

section	O
:	O
Performance	O
Robustness	Metric
in	O
Long	Task
Text	Task
Generation	Task
Long	O
text	O
generation	Task
has	O
always	O
been	O
difficult	O
among	O
all	O
text	O
generation	Task
problems	O
.	O

The	O
difficulty	O
of	O
the	O
problem	O
is	O
due	O
to	O
many	O
factors	O
,	O
such	O
as	O
LSTM	Method
-	Method
RNN	Method
's	O
failure	O
to	O
capture	O
longterm	O
dependency	O
,	O
discriminator	O
's	O
failure	O
to	O
give	O
those	O
"	O
good	O
but	O
tiny	O
"	O
sequences	O
appropriate	O
penalty	O
.	O

To	O
explicitly	O
evaluate	O
the	O
superiority	O
of	O
LeakGAN	Method
in	O
long	O
text	O
generation	Task
,	O
here	O
we	O
use	O
the	O
relative	O
performance	O
gain	O
of	O
LeakGAN	Method
over	O
[	O
reference	O
]	O
and	O
RankGAN	Method
[	O
reference	O
]	O
.	O

The	O
results	O
over	O
EMNLP2017	Material
WMT	Material
News	Material
data	O
are	O
shown	O
in	O
Figure	O
3	O
.	O

The	O
curves	O
clearly	O
show	O
that	O
LeakGAN	Method
yields	O
larger	O
performance	O
gain	O
over	O
the	O
baselines	O
when	O
the	O
generated	O
sentences	O
are	O
longer	O
.	O

This	O
fact	O
supports	O
our	O
claim	O
that	O
LeakGAN	Method
is	O
a	O
robust	O
framework	O
for	O
long	Task
text	Task
.	O

section	O
:	O
Turing	Task
Test	Task
and	O
Generated	O
Samples	O
Since	O
BLEU	Metric
score	Metric
is	O
a	O
metric	O
focusing	O
on	O
the	O
local	O
text	O
statistics	O
,	O
which	O
may	O
not	O
be	O
sufficient	O
for	O
evaluating	O
text	O
generation	Task
quality	O
,	O
we	O
also	O
conduct	O
a	O
Turing	Method
test	Method
based	O
on	O
questionnaires	O
on	O
the	O
Internet	O
.	O

In	O
the	O
questionnaire	O
,	O
each	O
(	O
machine	O
generated	O
or	O
real	O
)	O
sentence	O
gets	O
+	O
1	O
score	O
when	O
it	O
is	O
regarded	O
as	O
a	O
real	O
one	O
,	O
and	O
0	O
score	O
otherwise	O
.	O

We	O
conduct	O
the	O
test	O
with	O
text	O
generated	O
by	O
the	O
models	O
trained	O
on	O
WMT	Material
News	Material
and	O
COCO	Material
Image	Material
Captions	Material
.	O

The	O
average	O
score	O
for	O
each	O
algorithm	O
is	O
calculated	O
.	O

In	O
practice	O
,	O
we	O
sample	O
20	O
sentences	O
from	O
every	O
method	O
and	O
invite	O
62	O
people	O
to	O
participate	O
the	O
test	O
,	O
where	O
everyone	O
should	O
judge	O
the	O
quality	O
of	O
30	O
sentences	O
from	O
the	O
compared	O
three	O
methods	O
and	O
thus	O
each	O
sentence	O
is	O
judged	O
by	O
31	O
people	O
.	O

For	O
the	O
comparison	O
fairness	O
,	O
the	O
sentences	O
used	O
in	O
the	O
questionnaires	O
are	O
randomly	O
sampled	O
.	O

Table	O
5	O
gives	O
the	O
results	O
.	O

The	O
performance	O
on	O
two	O
datasets	O
indicates	O
that	O
the	O
generated	O
sentences	O
of	O
LeakGAN	Method
are	O
of	O
higher	O
global	Metric
consistency	Metric
and	O
better	O
readability	Metric
than	O
those	O
of	O
SeqGAN	Method
.	O

A	O
few	O
samples	O
generated	O
by	O
LeakGAN	Method
are	O
illustrated	O
in	O
Table	O
6	O
.	O

More	O
samples	O
and	O
their	O
comparison	O
with	O
those	O
from	O
(	O
1	O
)	O
A	O
bathroom	O
with	O
tiled	O
walls	O
and	O
a	O
shower	O
on	O
it	O
.	O

(	O
2	O
)	O
A	O
young	O
man	O
is	O
holding	O
a	O
bottle	O
of	O
wine	O
in	O
his	O
hand	O
.	O

(	O
2	O
)	O
A	O
couple	O
of	O
kids	O
in	O
front	O
of	O
a	O
bathroom	O
that	O
is	O
in	O
a	O
bathroom	O
.	O

EMNLP2017	Material
WMT	Method
(	O
1	O
)	O
The	O
American	O
Medical	O
Association	O
said	O
that	O
the	O
militants	O
had	O
been	O
arrested	O
in	O
connection	O
with	O
the	O
murder	O
of	O
the	O
same	O
incident	O
.	O

(	O
1	O
)	O
"	O
I	O
think	O
you	O
should	O
really	O
really	O
leave	O
for	O
because	O
we	O
had	O
n't	O
been	O
busy	O
,	O
where	O
it	O
goes	O
to	O
one	O
,	O
"	O
he	O
wrote	O
.	O

(	O
2	O
)	O
This	O
is	O
the	O
first	O
time	O
that	O
the	O
Fed	O
has	O
been	O
able	O
to	O
launch	O
a	O
probe	O
into	O
the	O
country	O
'	O
s	O
nuclear	O
program	O
.	O

(	O
2	O
)	O
What	O
you	O
have	O
to	O
stop	O
,	O
if	O
we	O
do	O
that	O
,	O
as	O
late	O
,	O
law	O
enforcement	O
and	O
where	O
schools	O
use	O
a	O
list	O
of	O
aid	O
,	O
it	O
can	O
rise	O
.	O

section	O
:	O
Model	O
Explanation	O
Feature	O
Trace	O
.	O

To	O
verify	O
that	O
LeakGAN	Method
successfully	O
exploits	O
of	O
the	O
leaked	O
message	O
,	O
we	O
visualize	O
the	O
feature	O
vector	O
f	O
T	O
extracted	O
from	O
the	O
real	O
data	O
by	O
discriminator	Method
.	O

Besides	O
,	O
we	O
visualize	O
the	O
feature	O
trace	O
,	O
i.e.	O
the	O
features	O
f	O
t	O
of	O
prefix	O
s	O
t	O
during	O
the	O
generation	Task
,	O
for	O
LeakGAN	Method
,	O
SeqGAN	Method
and	O
RankGAN	Method
via	O
a	O
2	Method
-	Method
D	Method
principal	Method
component	Method
analysis	Method
(	O
PCA	Method
)	O
.	O

The	O
visualized	O
traces	O
are	O
plotted	O
in	O
Figure	O
4	O
and	O
more	O
cases	O
are	O
presented	O
in	O
the	O
supplementary	O
material	O
.	O

As	O
we	O
can	O
see	O
,	O
during	O
the	O
generation	Method
process	Method
,	O
in	O
LeakGAN	Method
,	O
the	O
feature	O
vector	O
gradually	O
approaches	O
the	O
real	O
data	O
feature	O
vector	O
region	O
.	O

However	O
,	O
previous	O
models	O
,	O
i.e.	O
SeqGAN	Method
and	O
RankGAN	Method
,	O
fail	O
to	O
match	O
the	O
features	O
even	O
when	O
the	O
generation	Task
is	O
completed	O
.	O

This	O
indicates	O
that	O
the	O
proposed	O
Leak	O
-	O
GAN	Method
does	O
finish	O
its	O
design	O
purpose	O
of	O
exploiting	O
the	O
leaked	O
information	O
from	O
D	O
φ	O
to	O
better	O
match	O
the	O
feature	O
vector	O
distributions	O
of	O
real	O
data	O
.	O

Behaviors	O
of	O
Worker	O
and	O
Manager	O
.	O

To	O
give	O
more	O
details	O
of	O
how	O
WORKER	Method
and	O
MANAGER	Method
interact	O
with	O
each	O
other	O
and	O
make	O
use	O
of	O
the	O
leaked	O
information	O
in	O
the	O
generative	Method
model	Method
,	O
we	O
visualize	O
the	O
interaction	O
vector	O
of	O
the	O
WORKER	Method
and	O
MANAGER	Method
,	O
i.e.	O
,	O
the	O
dimension	O
-	O
wise	O
product	O
of	O
their	O
output	O
(	O
O	O
t	O
·	O
w	O
t	O
as	O
in	O
Eq	O
.	O

(	O
6	O
)	O
)	O
.	O

Note	O
that	O
to	O
simplify	O
the	O
explanation	O
,	O
here	O
we	O
reduce	O
the	O
signal	O
dimension	O
from	O
16	O
to	O
8	O
.	O

Figure	O
5	O
presents	O
an	O
example	O
sentence	O
and	O
more	O
cases	O
are	O
provided	O
in	O
the	O
supplementary	O
material	O
.	O

From	O
Figure	O
5	O
,	O
we	O
find	O
some	O
intuitive	O
interpretations	O
of	O
the	O
implicit	O
rules	O
learned	O
by	O
the	O
interaction	O
of	O
WORKER	Method
and	O
MANAGER	Method
.	O

(	O
i	O
)	O
The	O
5th	O
dimension	O
stands	O
for	O
current	O
token	O
's	O
divergence	O
from	O
an	O
entity	O
token	O
.	O

If	O
the	O
5th	O
value	O
is	O
high	O
,	O
the	O
token	O
would	O
most	O
possibly	O
be	O
a	O
structural	O
token	O
,	O
such	O
as	O
a	O
modal	O
verb	O
,	O
an	O
article	O
or	O
a	O
preposition	O
.	O

(	O
ii	O
)	O
The	O
6th	O
dimension	O
suggests	O
how	O
long	O
the	O
suffix	O
from	O
current	O
step	O
will	O
be	O
.	O

If	O
a	O
peak	O
occurs	O
in	O
the	O
curve	O
,	O
there	O
must	O
be	O
some	O
token	O
that	O
triggers	O
a	O
long	O
suffix	O
.	O

A	O
frequently	O
occurring	O
example	O
is	O
the	O
formal	O
subject	O
.	O

(	O
iii	O
)	O
Although	O
hard	O
to	O
observe	O
,	O
we	O
do	O
find	O
connections	O
of	O
the	O
7th	O
dimension	O
and	O
the	O
substructure	O
of	O
a	O
sentence	O
.	O

For	O
example	O
,	O
when	O
the	O
start	O
or	O
the	O
end	O
of	O
a	O
subsentence	O
occurs	O
,	O
there	O
is	O
an	O
observable	O
fluctuation	O
in	O
the	O
7th	O
dimension	O
.	O

This	O
indicates	O
that	O
the	O
token	O
is	O
most	O
likely	O
to	O
be	O
a	O
punctuation	O
or	O
a	O
conjuction	O
.	O

section	O
:	O
Conclusion	O
and	O
Future	O
work	O
In	O
this	O
paper	O
,	O
we	O
proposed	O
a	O
new	O
algorithmic	Method
framework	Method
called	O
LeakGAN	Method
for	O
generating	Task
long	Task
text	Task
via	O
adversarial	Task
training	Task
.	O

By	O
leaking	O
the	O
feature	O
extracted	O
by	O
the	O
discriminator	Method
as	O
the	O
step	O
-	O
by	O
-	O
step	O
guiding	O
signal	O
to	O
guide	O
the	O
generator	Method
better	O
generating	Task
long	Task
text	Task
,	O
LeakGAN	Method
addresses	O
the	O
non	Task
-	Task
informativeness	Task
and	Task
sparsity	Task
problems	Task
of	O
the	O
scalar	O
reward	O
signal	O
in	O
previous	O
GAN	Method
solutions	O
.	O

In	O
the	O
extensive	O
experiments	O
with	O
synthetic	O
data	O
and	O
real	O
world	O
data	O
including	O
long	O
,	O
mid	O
-	O
length	O
and	O
short	O
text	O
,	O
LeakGAN	Method
achieved	O
significant	O
performance	O
improvement	O
over	O
previous	O
solutions	O
,	O
on	O
both	O
BLEU	Metric
scores	Metric
and	O
human	Metric
ratings	Metric
.	O

Moreover	O
,	O
the	O
analysis	O
of	O
the	O
results	O
shows	O
that	O
LeakGAN	Method
yields	O
larger	O
performance	O
gain	O
when	O
the	O
longer	O
sentences	O
are	O
generated	O
.	O

Finally	O
,	O
we	O
also	O
visualize	O
and	O
explain	O
the	O
efficacy	O
of	O
the	O
guiding	O
signals	O
that	O
LeakGAN	Method
learns	O
without	O
any	O
supervision	O
.	O

For	O
future	O
work	O
,	O
we	O
plan	O
to	O
apply	O
LeakGAN	Method
in	O
more	O
natural	Task
language	Task
process	Task
applications	Task
like	O
dialogue	Task
systems	Task
and	O
image	Task
captioning	Task
by	O
providing	O
more	O
task	O
-	O
specific	O
guiding	O
information	O
.	O

Also	O
,	O
enhancing	O
the	O
capacity	O
of	O
the	O
discriminator	Method
to	O
check	O
the	O
global	O
consistency	O
of	O
the	O
whole	O
sentence	O
is	O
a	O
promising	O
direction	O
.	O

section	O
:	O
Experiment	O
Settings	O
For	O
synthetic	O
data	O
with	O
length	O
20	O
,	O
the	O
learning	Metric
rate	Metric
for	O
MANAGER	Method
and	O
WORKER	Method
is	O
set	O
to	O
0.001	O
.	O

The	O
goal	O
dimension	O
size	O
k	O
is	O
set	O
to	O
16	O
.	O

The	O
embedding	Metric
size	Metric
of	O
the	O
LSTM	Method
-	Method
RNNs	Method
is	O
set	O
to	O
32	O
.	O

For	O
the	O
discriminative	Method
model	Method
,	O
we	O
set	O
the	O
hyperparameters	O
of	O
the	O
CNN	Method
as	O
Table	O
1	O
For	O
synthetic	O
data	O
with	O
length	O
40	O
,	O
the	O
learning	Metric
rate	Metric
for	O
MANAGER	Method
and	O
WORKER	Method
is	O
set	O
to	O
0.0005	O
.	O

The	O
goal	O
dimension	O
size	O
k	O
is	O
set	O
to	O
16	O
.	O

The	O
embedding	Metric
size	Metric
of	O
the	O
LSTM	Method
-	Method
RNNs	Method
is	O
set	O
to	O
32	O
.	O

For	O
the	O
discriminative	Method
model	Method
,	O
we	O
set	O
the	O
hyperparameters	O
of	O
the	O
CNN	Method
as	O
Table	O
1	O
Table	O
1	O
:	O
Convolutional	O
layer	O
structures	O
.	O

section	O
:	O
Discussions	O
The	O
Necessity	O
of	O
the	O
Hierarchical	Method
Architecture	Method
The	O
hierarchical	Method
architecture	Method
in	O
LeakGAN	Method
serves	O
as	O
the	O
mechanism	O
of	O
incorporating	O
leaked	O
information	O
from	O
D	O
into	O
G.	O
However	O
,	O
in	O
the	O
body	O
part	O
,	O
we	O
have	O
n't	O
shown	O
whether	O
the	O
explotation	O
of	O
hierachical	Method
architecture	Method
is	O
a	O
must	O
.	O

Actually	O
,	O
what	O
we	O
have	O
to	O
point	O
out	O
is	O
,	O
the	O
explotation	O
of	O
hierarchical	Method
reinforment	Method
learning	Method
is	O
not	O
a	O
must	O
,	O
but	O
a	O
good	O
choice	O
in	O
sequence	Task
decision	Task
scenarios	Task
.	O

We	O
attempt	O
to	O
replace	O
the	O
hierarchical	Method
architecture	Method
by	O
a	O
fully	Method
connected	Method
layer	Method
.	O

However	O
,	O
the	O
model	O
is	O
so	O
numerically	O
sensitive	O
that	O
we	O
can	O
not	O
operate	O
a	O
stable	O
training	O
on	O
it	O
the	O
original	O
training	O
settings	O
.	O

A	O
possible	O
reason	O
is	O
that	O
,	O
since	O
the	O
feature	O
space	O
of	O
CNN	O
changes	O
rapidly	O
during	O
the	O
training	Method
procedure	Method
,	O
linear	Method
transformation	Method
without	O
any	O
normalization	Method
may	O
not	O
be	O
able	O
to	O
incorporate	O
the	O
information	O
contained	O
in	O
the	O
feature	O
vector	O
leaked	O
from	O
D.	O
Here	O
we	O
present	O
more	O
examples	O
for	O
illustrating	O
the	O
interaction	O
of	O
WORKER	Method
and	O
MANAGER	Method
to	O
support	O
our	O
claims	O
in	O
the	O
main	O
text	O
as	O
below	O
.	O

Each	O
curve	O
shows	O
a	O
subscore	O
of	O
the	O
token	O
of	O
that	O
time	O
step	O
.	O

Each	O
dimension	O
of	O
the	O
score	O
,	O
i.e.	O
each	O
subscore	O
measures	O
a	O
specific	O
feature	O
of	O
the	O
token	O
in	O
that	O
context	O
.	O

section	O
:	O
Illustration	O
of	O
WORKER	Method
and	O
MANAGER	Method
's	Method
Behaviors	Method
(	O
i	O
)	O
The	O
5th	O
dimension	O
stands	O
for	O
current	O
token	O
's	O
divergence	O
from	O
an	O
entity	O
token	O
.	O

If	O
the	O
5th	O
value	O
is	O
high	O
,	O
the	O
token	O
would	O
most	O
possibly	O
be	O
a	O
structural	O
token	O
,	O
such	O
as	O
a	O
modal	O
verb	O
,	O
an	O
article	O
or	O
a	O
preposition	O
.	O

(	O
ii	O
)	O
The	O
6th	O
dimension	O
suggests	O
how	O
long	O
the	O
suffix	O
from	O
current	O
step	O
will	O
be	O
.	O

If	O
a	O
peak	O
occurs	O
in	O
the	O
curve	O
,	O
there	O
must	O
be	O
some	O
token	O
that	O
triggers	O
a	O
long	O
suffix	O
.	O

A	O
frequently	O
occurring	O
example	O
is	O
the	O
formal	O
subject	O
.	O

(	O
iii	O
)	O
Although	O
hard	O
to	O
observe	O
,	O
we	O
do	O
find	O
connections	O
of	O
the	O
7th	O
dimension	O
and	O
the	O
substructure	O
of	O
a	O
sentence	O
.	O

For	O
example	O
,	O
when	O
the	O
start	O
or	O
end	O
of	O
a	O
sub	O
-	O
sentence	O
occurs	O
,	O
there	O
is	O
an	O
observable	O
fluctuation	O
in	O
the	O
7th	O
dimension	O
.	O

This	O
indicates	O
that	O
the	O
token	O
is	O
most	O
likely	O
to	O
be	O
a	O
punctuation	O
or	O
a	O
conjuction	O
.	O

As	O
we	O
can	O
see	O
,	O
during	O
the	O
generation	Method
process	Method
,	O
in	O
LeakGAN	Method
,	O
the	O
feature	O
vector	O
gradually	O
approaches	O
the	O
real	O
data	O
feature	O
vector	O
region	O
.	O

However	O
,	O
previous	O
models	O
,	O
i.e.	O
SeqGAN	Method
and	O
RankGAN	Method
,	O
fail	O
to	O
match	O
the	O
features	O
even	O
when	O
the	O
generation	Task
is	O
completed	O
.	O

This	O
indicates	O
that	O
the	O
proposed	O
LeakGAN	Method
does	O
finish	O
its	O
designed	O
purpose	O
of	O
exploiting	O
the	O
leaked	O
information	O
from	O
D	O
φ	O
to	O
better	O
match	O
the	O
feature	O
vector	O
distributions	O
of	O
real	O
data	O
.	O

A	O
man	O
wearing	O
a	O
suit	O
and	O
coat	O
holds	O
a	O
tie	O
through	O
and	O
wood	O
pants	O
.	O

Two	O
men	O
are	O
working	O
on	O
a	O
laptop	O
in	O
a	O
room	O
.	O

A	O
man	O
who	O
is	O
standing	O
next	O
to	O
a	O
brown	O
and	O
white	O
horse	O
.	O

A	O
street	O
sign	O
with	O
a	O
red	O
stop	O
sign	O
on	O
the	O
street	O
pole	O
.	O

A	O
cat	O
is	O
laying	O
on	O
a	O
keyboard	O
and	O
mouse	O
in	O
the	O
air	O
.	O

A	O
man	O
with	O
a	O
rainbow	O
-	O
colored	O
shirt	O
and	O
a	O
black	O
dog	O
.	O

A	O
crowd	O
of	O
people	O
standing	O
around	O
or	O
standing	O
on	O
a	O
sidewalk	O
.	O

A	O
man	O
is	O
sitting	O
on	O
his	O
desk	O
holding	O
an	O
umbrella	O
.	O

SeqGAN	O
A	O
woman	O
is	O
riding	O
a	O
bike	O
on	O
the	O
street	O
next	O
to	O
a	O
bus	O
.	O

section	O
:	O
Illustration	O
of	O
Feature	O
Trace	O
A	O
silver	O
stove	O
,	O
the	O
refrigerator	O
,	O
sitting	O
in	O
a	O
kitchen	O
.	O

A	O
guy	O
doing	O
tricks	O
on	O
a	O
skateboard	O
while	O
a	O
man	O
is	O
standing	O
on	O
a	O
cellphone	O
.	O

A	O
bunch	O
of	O
birds	O
that	O
are	O
sitting	O
in	O
the	O
sand	O
.	O

A	O
bathroom	O
with	O
tiled	O
walls	O
and	O
a	O
shower	O
on	O
it	O
.	O

A	O
couple	O
of	O
people	O
are	O
riding	O
bikes	O
down	O
an	O
asphalt	O
road	O
.	O

An	O
old	O
photo	O
of	O
a	O
man	O
riding	O
on	O
a	O
motorcycle	O
with	O
some	O
people	O
.	O

A	O
beautiful	O
young	O
girl	O
in	O
the	O
bathroom	O
has	O
one	O
has	O
wine	O
glasses	O
and	O
bottles	O
above	O
the	O
counters	O
.	O

A	O
person	O
in	O
a	O
helmet	O
standing	O
next	O
to	O
a	O
red	O
street	O
.	O

An	O
empty	O
clean	O
bathroom	O
with	O
a	O
toilet	O
and	O
sink	O
and	O
tub	O
.	O

A	O
kid	O
in	O
a	O
black	O
shirt	O
and	O
dog	O
arms	O
in	O
a	O
restaurant	O
kitchen	O
.	O

A	O
bathroom	O
has	O
a	O
toilet	O
,	O
a	O
sink	O
and	O
mirror	O
.	O

Two	O
bicycles	O
are	O
parked	O
outside	O
inside	O
a	O
small	O
brown	O
field	O
.	O

The	O
large	O
rug	O
is	O
on	O
the	O
city	O
under	O
the	O
city	O
.	O

A	O
bathroom	O
that	O
is	O
has	O
a	O
picture	O
above	O
and	O
a	O
sink	O
.	O

A	O
small	O
child	O
jumping	O
with	O
glasses	O
to	O
a	O
motor	O
scooter	O
.	O

A	O
white	O
bathroom	O
with	O
a	O
toilet	O
,	O
television	O
and	O
bathtub	O
and	O
a	O
sink	O
.	O

A	O
baby	O
in	O
a	O
blue	O
dress	O
standing	O
in	O
front	O
of	O
a	O
Frisbee	O
.	O

A	O
cat	O
and	O
a	O
woman	O
standing	O
by	O
two	O
computer	O
preparing	O
food	O
.	O

A	O
pair	O
of	O
skis	O
and	O
pedestrians	O
in	O
a	O
parking	O
area	O
near	O
some	O
different	O
go	O
.	O

Two	O
bikes	O
in	O
a	O
parking	O
lot	O
with	O
a	O
dog	O
that	O
has	O
a	O
back	O
on	O
her	O
.	O

Out	O
of	O
those	O
who	O
came	O
last	O
year	O
,	O
69	O
per	O
cent	O
were	O
men	O
,	O
18	O
per	O
cent	O
were	O
children	O
and	O
just	O
13	O
per	O
cent	O
were	O
women	O
.	O

'	O
Sometimes	O
I	O
think	O
about	O
leaving	O
sex	O
work	O
,	O
but	O
because	O
I	O
am	O
alone	O
living	O
costs	O
are	O
really	O
expensive	O
,	O
'	O
she	O
said	O
.	O

'	O
I	O
was	O
then	O
stuck	O
in	O
the	O
house	O
for	O
nearly	O
two	O
years	O
only	O
going	O
out	O
for	O
short	O
periods	O
of	O
time	O
,	O
'	O
she	O
said	O
.	O

He	O
has	O
not	O
played	O
for	O
Tottenham	O
's	O
first	O
team	O
since	O
and	O
it	O
is	O
now	O
nearly	O
two	O
years	O
since	O
he	O
completed	O
a	O
full	O
Premier	O
League	O
match	O
for	O
the	O
club	O
.	O

This	O
is	O
a	O
part	O
of	O
the	O
population	O
that	O
is	O
notorious	O
for	O
its	O
lack	O
of	O
interest	O
in	O
actually	O
showing	O
up	O
when	O
the	O
political	O
process	O
takes	O
place	O
.	O

I	O
was	O
paid	O
far	O
too	O
little	O
to	O
pick	O
up	O
a	O
dead	O
off	O
of	O
the	O
ground	O
and	O
put	O
it	O
back	O
in	O
the	O
box	O
.	O

Local	O
media	O
reported	O
the	O
group	O
were	O
not	O
looking	O
to	O
hurt	O
anybody	O
,	O
but	O
they	O
would	O
not	O
rule	O
out	O
violence	O
if	O
police	O
tried	O
to	O
remove	O
them	O
.	O

The	O
55	O
to	O
43	O
vote	O
was	O
largely	O
split	O
down	O
party	O
lines	O
and	O
fell	O
short	O
of	O
the	O
60	O
votes	O
needed	O
for	O
the	O
bill	O
to	O
advance	O
.	O

We	O
got	O
to	O
a	O
bus	O
station	O
in	O
the	O
evening	O
,	O
but	O
our	O
connection	O
did	O
n't	O
leave	O
until	O
the	O
following	O
morning	O
.	O

It	O
's	O
actually	O
something	O
that	O
I	O
had	O
to	O
add	O
,	O
because	O
I	O
was	O
getting	O
really	O
frustrated	O
losing	O
to	O
my	O
hitting	O
partner	O
all	O
the	O
time	O
.	O

Taiwan	O
's	O
Defence	O
Ministry	O
said	O
it	O
was	O
"	O
aware	O
of	O
the	O
information	O
,	O
"	O
and	O
declined	O
further	O
immediate	O
comment	O
,	O
Reuters	O
reported	O
.	O

Her	O
response	O
to	O
the	O
international	O
refugee	O
crisis	O
gave	O
a	O
million	O
refugees	O
hope	O
that	O
they	O
may	O
be	O
able	O
to	O
begin	O
a	O
new	O
life	O
.	O

I	O
'	O
m	O
racing	O
against	O
a	O
guy	O
who	O
I	O
lost	O
a	O
medal	O
to	O
-	O
but	O
am	O
I	O
ever	O
going	O
to	O
get	O
that	O
medal	O
back	O
?	O
LeakGAN	Method
A	O
man	O
has	O
been	O
arrested	O
at	O
age	O
28	O
,	O
a	O
resident	O
in	O
Seattle	O
,	O
which	O
was	O
widely	O
reported	O
in	O
2007	O
.	O

I	O
also	O
think	O
that	O
'	O
s	O
a	O
good	O
place	O
for	O
us	O
,	O
I	O
'	O
m	O
sure	O
that	O
this	O
would	O
be	O
a	O
good	O
opportunity	O
for	O
me	O
to	O
get	O
in	O
touch	O
.	O

What	O
is	O
the	O
biggest	O
problem	O
for	O
Clinton	O
is	O
that	O
Donald	O
Trump	O
will	O
be	O
in	O
the	O
race	O
and	O
he	O
'	O
s	O
unlikely	O
to	O
be	O
the	O
nominee	O
.	O

"	O
We	O
'	O
re	O
going	O
to	O
do	O
and	O
we	O
'	O
re	O
going	O
to	O
put	O
it	O
out	O
and	O
get	O
the	O
ball	O
,	O
"	O
he	O
said	O
.	O

"	O
I	O
would	O
be	O
afraid	O
to	O
blame	O
the	O
girls	O
to	O
go	O
back	O
but	O
I	O
was	O
just	O
disappointed	O
with	O
the	O
race	O
,	O
"	O
he	O
said	O
.	O

"	O
I	O
'	O
m	O
not	O
going	O
to	O
work	O
together	O
with	O
a	O
different	O
role	O
and	O
we	O
can	O
win	O
the	O
game	O
,	O
"	O
he	O
added	O
.	O

The	O
couple	O
's	O
lives	O
are	O
still	O
missing	O
and	O
they	O
have	O
been	O
killed	O
in	O
the	O
city	O
's	O
way	O
to	O
play	O
against	O
them	O
,	O
and	O
because	O
I	O
came	O
out	O
there	O
.	O

For	O
the	O
last	O
three	O
years	O
,	O
we	O
'	O
ve	O
got	O
a	O
lot	O
of	O
things	O
that	O
we	O
need	O
to	O
do	O
with	O
this	O
is	O
based	O
on	O
the	O
financial	O
markets	O
.	O

Do	O
n't	O
ask	O
me	O
,	O
but	O
I	O
know	O
,	O
if	O
I	O
'	O
ll	O
be	O
able	O
to	O
be	O
out	O
of	O
Hillary	O
Clinton	O
,	O
I	O
think	O
it	O
's	O
being	O
made	O
for	O
the	O
Congress	O
.	O

"	O
I	O
am	O
proud	O
to	O
be	O
able	O
to	O
move	O
forward	O
because	O
we	O
do	O
n't	O
have	O
to	O
look	O
at	O
about	O
,	O
"	O
he	O
said	O
.	O

That	O
'	O
s	O
why	O
we	O
'	O
re	O
the	O
most	O
important	O
people	O
for	O
the	O
African	O
American	O
community	O
and	O
we	O
'	O
ve	O
made	O
a	O
good	O
response	O
.	O

But	O
the	O
move	O
will	O
be	O
only	O
in	O
a	O
fight	O
against	O
them	O
,	O
as	O
well	O
as	O
likely	O
to	O
prevent	O
an	O
agreement	O
to	O
remain	O
in	O
the	O
EU	O
.	O

The	O
American	O
Medical	O
Association	O
said	O
that	O
the	O
militants	O
had	O
been	O
arrested	O
in	O
connection	O
with	O
the	O
murder	O
of	O
the	O
same	O
incident	O
.	O

The	O
two	O
-	O
year	O
-	O
old	O
girl	O
has	O
been	O
charged	O
with	O
a	O
suspect	O
who	O
was	O
in	O
the	O
vehicle	O
to	O
the	O
police	O
station	O
.	O

It	O
is	O
hard	O
to	O
buy	O
on	O
the	O
Olympics	O
,	O
but	O
we	O
probably	O
do	O
n't	O
see	O
a	O
lot	O
of	O
it	O
.	O

"	O
I	O
'	O
m	O
not	O
going	O
to	O
be	O
very	O
proud	O
of	O
the	O
other	O
countries	O
,	O
"	O
he	O
said	O
.	O

He	O
said	O
the	O
U.	O
N.	O
intelligence	O
industry	O
will	O
not	O
comment	O
on	O
the	O
ground	O
,	O
which	O
would	O
be	O
sensitive	O
to	O
the	O
European	O
Union	O
.	O

I	O
take	O
my	O
work	O
in	O
the	O
days	O
,	O
but	O
I	O
would	O
have	O
to	O
go	O
down	O
on	O
Wednesday	O
night	O
.	O

section	O
:	O
SeqGAN	O
You	O
only	O
certainly	O
might	O
not	O
rush	O
it	O
down	O
for	O
those	O
circumstances	O
where	O
we	O
are	O
when	O
they	O
were	O
the	O
heads	O
,	O
and	O
when	O
she	O
's	O
name	O
.	O

"	O
I	O
think	O
you	O
should	O
really	O
really	O
leave	O
for	O
because	O
we	O
had	O
n't	O
been	O
busy	O
,	O
where	O
it	O
goes	O
to	O
one	O
,	O
"	O
he	O
wrote	O
.	O

All	O
the	O
study	O
knew	O
was	O
that	O
they	O
are	O
,	O
so	O
they	O
continue	O
to	O
provide	O
support	O
service	O
and	O
it	O
does	O
n't	O
exist	O
.	O

'	O
It	O
can	O
say	O
become	O
up	O
with	O
nothing	O
sales	O
have	O
reached	O
the	O
charge	O
for	O
the	O
other	O
any	O
evidence	O
that	O
been	O
virtually	O
well	O
below	O
the	O
$	O
800	O
.	O

Three	O
times	O
before	O
the	O
start	O
of	O
the	O
season	O
is	O
much	O
early	O
on	O
2015	O
we	O
are	O
in	O
the	O
third	O
training	O
every	O
year	O
.	O

That	O
's	O
the	O
idea	O
of	O
strength	O
that	O
decision	O
they	O
said	O
,	O
we	O
have	O
n't	O
already	O
lost	O
four	O
or	O
seven	O
,	O
or	O
Liverpool	O
's	O
team	O
.	O

That	O
is	O
not	O
the	O
time	O
for	O
the	O
cost	O
of	O
changing	O
the	O
system	O
and	O
it	O
was	O
pushing	O
for	O
$	O
20	O
million	O
.	O

We	O
had	O
to	O
take	O
it	O
a	O
good	O
day	O
for	O
a	O
military	O
,	O
but	O
nearly	O
6	O
,	O
000	O
]	O
and	O
prepare	O
for	O
them	O
through	O
.	O

I	O
actually	O
did	O
n't	O
tell	O
the	O
background	O
check	O
the	O
difference	O
after	O
my	O
hour	O
was	O
to	O
be	O
recalled	O
...	O
and	O
it	O
was	O
great	O
.	O

We	O
are	O
thinking	O
about	O
40	O
,	O
000	O
and	O
jobs	O
in	O
what	O
is	O
wrong	O
in	O
the	O
coming	O
and	O
you	O
know	O
.	O

That	O
is	O
out	O
how	O
working	O
you	O
ca	O
n't	O
set	O
out	O
some	O
pretty	O
tight	O
...	O
or	O
what	O
I	O
'	O
m	O
going	O
through	O
.	O

"	O
I	O
wanted	O
to	O
be	O
made	O
you	O
decided	O
to	O
have	O
a	O
crisis	O
that	O
way	O
up	O
and	O
get	O
some	O
sort	O
of	O
weapon	O
,	O
not	O
much	O
to	O
give	O
birth	O
to	O
for	O
an	O
American	O
room	O
.	O

She	O
had	O
been	O
fined	O
almost	O
200	O
,	O
000	O
with	O
couple	O
of	O
asylum	O
seekers	O
in	O
Syria	O
and	O
Iraq	O
.	O

Perhaps	O
not	O
,	O
in	O
looking	O
for	O
,	O
housing	O
officials	O
would	O
help	O
the	O
frustration	O
of	O
Government	O
,	O
with	O
an	O
FBI	O
shortly	O
before	O
2020	O
.	O

Once	O
we	O
got	O
to	O
real	O
show	O
for	O
the	O
young	O
man	O
since	O
I	O
'	O
m	O
sure	O
she	O
went	O
to	O
love	O
it	O
just	O
,	O
whether	O
to	O
be	O
late	O
later	O
last	O
year	O
.	O

But	O
,	O
after	O
a	O
holiday	O
period	O
we	O
might	O
have	O
to	O
go	O
on	O
a	O
total	O
-	O
out	O
debate	O
like	O
that	O
could	O
have	O
happened	O
to	O
us	O
.	O

section	O
:	O
section	O
:	O
Appendix	O
Formulas	O
for	O
Reference	O
Discriminator	O
f	O
=	O
F	O
(	O
s	O
;	O
φ	O
f	O
)	O
,	O
(	O
1	O
)	O
MANAGER	Method
of	O
Generatorĝ	O
WORKER	Method
of	O
Generator	O
Pseudo	O
Code	O
section	O
:	O
Algorithm	O
1	O
Adversarial	Method
Training	Method
with	O
Leaked	O
Information	O
Require	O
:	O
Hierachical	Method
policy	Method
G	O
θm	O
,	O
θw	O
;	O
discriminator	O
D	O
φ	O
;	O
a	O
sequence	O
dataset	O
S	O
=	O
{	O
X1:T	O
}	O
1	O
:	O
Initialize	O
G	O
θm	O
,	O
θw	O
,	O
D	O
φ	O
with	O
random	O
weights	O
θm	O
,	O
θw	O
,	O
φ	O
.	O

2	O
:	O
Pre	O
-	O
train	O
D	O
φ	O
(	O
i.e.	O
the	O
feature	Method
extractor	Method
F	O
(	O
·	O
;	O
φ	O
f	O
)	O
and	O
the	O
output	O
layer	O
sigmoid	O
(	O
φ	O
l	O
,	O
·	O
)	O
)	O
using	O
S	O
as	O
positive	O
samples	O
and	O
output	O
from	O
G	O
θm	O
,	O
θw	O
as	O
negative	O
samples	O
.	O

3	O
:	O
Pre	O
-	O
train	O
G	O
θm	O
,	O
θw	O
using	O
leaked	O
information	O
from	O
D	O
φ	O
4	O
:	O
Perform	O
the	O
two	O
parts	O
of	O
pre	Method
-	Method
training	Method
interleavingly	Method
until	O
convergence	O
.	O

5	O
:	O
repeat	O
6	O
:	O
for	O
g	O
-	O
steps	O
do	O
7	O
:	O
Generate	O
a	O
sequence	O
Y1:T	O
=	O
(	O
y1	O
,	O
.	O

.	O

.	O

,	O
yT	O
)	O
∼	O
G	O
θ	O
8	O
:	O
for	O
t	O
in	O
1	O
:	O
T	O
do	O
9	O
:	O
Store	O
leaked	O
information	O
ft	O
from	O
D	O
φ	O
10	O
:	O
Get	O
Q	O
(	O
ft	O
,	O
gt	O
)	O
by	O
Monte	Method
Carlo	Method
Search	Method
via	O
Eq	O
.	O

(	O
8	O
)	O
section	O
:	O
