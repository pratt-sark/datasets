While	O
extraordinary	O
progress	O
has	O
been	O
made	O
towards	O
developing	O
neural	Method
network	Method
architectures	Method
for	O
classification	Task
tasks	Task
,	O
commonly	O
used	O
loss	Method
functions	Method
such	O
as	O
the	O
multi	Method
-	Method
category	Method
cross	Method
entropy	Method
loss	Method
are	O
inadequate	O
for	O
ranking	Task
and	O
ordinal	O
regression	O
problems	O
.	O

To	O
address	O
this	O
issue	O
,	O
approaches	O
have	O
been	O
developed	O
that	O
transform	O
ordinal	O
target	O
variables	O
series	O
of	O
binary	Task
classification	Task
tasks	Task
,	O
resulting	O
in	O
robust	O
ranking	Task
algorithms	O
with	O
good	O
generalization	Task
performance	O
.	O

However	O
,	O
to	O
model	O
ordinal	O
information	O
appropriately	O
,	O
ideally	O
,	O
a	O
rank	Method
-	Method
monotonic	Method
prediction	Method
function	Method
is	O
required	O
such	O
that	O
confidence	O
scores	O
are	O
ordered	O
and	O
consistent	O
.	O

We	O
propose	O
a	O
new	O
framework	O
(	O
Consistent	Method
Rank	Method
Logits	Method
,	O
CORAL	Method
)	O
with	O
theoretical	O
guarantees	O
for	O
rank	Metric
-	Metric
monotonicity	Metric
and	O
consistent	Metric
confidence	Metric
scores	Metric
.	O

Through	O
parameter	Method
sharing	Method
,	O
our	O
framework	O
benefits	O
from	O
low	O
training	Metric
complexity	Metric
and	O
can	O
easily	O
be	O
implemented	O
to	O
extend	O
common	O
convolutional	Method
neural	Method
network	Method
classifiers	Method
for	O
ordinal	Task
regression	Task
tasks	Task
.	O

Furthermore	O
,	O
our	O
empirical	O
results	O
support	O
the	O
proposed	O
theory	O
and	O
show	O
a	O
substantial	O
improvement	O
compared	O
to	O
the	O
current	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
ordinal	Method
regression	Method
method	Method
for	O
age	Task
prediction	Task
from	O
face	O
images	O
.	O

⌈⌉	O
⌊⌋	O
ConsistentRankLogits	O
(	O
CORAL	Method
)	O
CNNforOrdinalRegression	O
section	O
:	O
Introduction	O
Ordinal	Task
regression	Task
,	O
sometimes	O
also	O
referred	O
to	O
as	O
ordinal	Task
classification	Task
,	O
describes	O
the	O
task	O
of	O
predicting	Task
object	Task
labels	Task
on	O
an	O
ordinal	O
scale	O
.	O

Here	O
,	O
a	O
ranking	Task
rule	O
or	O
classifier	Method
maps	O
each	O
object	O
into	O
an	O
ordered	O
set	O
,	O
where	O
.	O

In	O
contrast	O
to	O
classification	Task
,	O
the	O
ranks	O
include	O
ordering	O
information	O
.	O

In	O
comparison	O
with	O
metric	Method
regression	Method
,	O
which	O
assumes	O
that	O
is	O
a	O
continuous	O
random	O
variable	O
,	O
ordinal	Method
regression	Method
regards	O
as	O
a	O
finite	O
sequence	O
where	O
the	O
metric	O
distance	O
between	O
ranks	O
is	O
not	O
defined	O
.	O

Along	O
with	O
age	Task
estimation	Task
niu2016ordinal	O
,	O
popular	O
applications	O
for	O
ordinal	Task
regression	Task
include	O
predicting	O
the	O
progression	Task
of	Task
various	Task
diseases	Task
,	O
such	O
as	O
Alzheimer	Task
’s	Task
disease	Task
doyle2014predicting	O
,	O
Crohn	Task
’s	Task
disease	Task
,	O
artery	Task
disease	Task
,	O
and	O
kidney	Task
disease	Task
.	O

Also	O
,	O
ordinal	Method
regression	Method
models	Method
are	O
common	O
choices	O
for	O
text	Task
message	Task
advertising	Task
and	O
various	O
recommender	Task
systems	Task
.	O

While	O
the	O
field	O
of	O
machine	Task
learning	Task
field	Task
developed	O
many	O
powerful	O
algorithms	O
for	O
predictive	Task
modeling	Task
,	O
most	O
algorithms	O
were	O
designed	O
for	O
classification	Task
tasks	Task
.	O

About	O
ten	O
years	O
ago	O
,	O
Li	O
and	O
Lin	O
proposed	O
a	O
general	O
framework	O
for	O
ordinal	Task
regression	Task
via	O
extended	Task
binary	Task
classification	Task
,	O
which	O
has	O
become	O
the	O
standard	O
choice	O
for	O
extending	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
machine	Method
learning	Method
algorithms	Method
for	O
ordinal	Task
regression	Task
tasks	Task
.	O

However	O
,	O
implementations	O
of	O
extended	Task
binary	Task
classification	Task
for	O
ordinal	Task
regression	Task
commonly	O
suffer	O
from	O
classifier	O
inconsistencies	O
among	O
the	O
binary	O
rankings	O
,	O
which	O
we	O
address	O
in	O
this	O
paper	O
with	O
a	O
new	O
method	O
and	O
theorem	O
for	O
guaranteed	Task
classifier	Task
consistency	Task
that	O
can	O
easily	O
be	O
implemented	O
in	O
various	O
machine	Method
learning	Method
algorithms	Method
.	O

Furthermore	O
,	O
we	O
present	O
an	O
empirical	O
study	O
of	O
our	O
approach	O
on	O
challenging	O
real	O
-	O
world	O
datasets	O
for	O
predicting	Task
the	Task
age	Task
of	Task
individuals	Task
from	O
face	O
images	O
using	O
our	O
method	O
with	O
convolutional	Method
neural	Method
networks	Method
(	O
CNN	Method
)	O
.	O

The	O
main	O
contributions	O
of	O
our	O
paper	O
are	O
as	O
follows	O
:	O
the	O
Consistent	Method
Rank	Method
Logits	Method
(	O
CORAL	Method
)	O
framework	O
for	O
ordinal	Task
regression	Task
with	O
theoretical	O
guarantees	O
for	O
classifier	Metric
consistency	Metric
and	O
well	O
-	O
defined	O
generalization	Metric
bounds	Metric
with	O
and	O
without	O
dataset	O
-	O
and	O
task	Method
-	Method
specific	Method
importance	Method
weighting	Method
;	O
CNN	Method
architectures	Method
with	O
CORAL	Method
formulation	O
for	O
ordinal	Task
regression	Task
tasks	Task
that	O
come	O
with	O
the	O
added	O
side	O
benefit	O
of	O
reducing	O
the	O
number	O
of	O
parameters	O
to	O
be	O
trained	O
compared	O
to	O
CNNs	Method
for	O
classification	Task
;	O
experimental	O
validation	O
showing	O
that	O
the	O
guaranteed	Metric
classifier	Metric
consistency	Metric
leads	O
to	O
a	O
substantial	O
improvement	O
over	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
CNN	Method
for	O
ordinal	Task
regression	Task
applied	O
to	O
age	Task
estimation	Task
from	O
face	O
images	O
.	O

section	O
:	O
Related	O
Work	O
subsection	O
:	O
Ordinal	Task
Regression	Task
and	O
Ranking	Task
Several	O
multivariate	Method
extensions	Method
of	Method
generalized	Method
linear	Method
models	Method
have	O
been	O
developed	O
in	O
the	O
past	O
for	O
ordinal	Task
regression	Task
,	O
including	O
the	O
popular	O
proportional	Method
odds	Method
and	O
the	O
proportional	Method
hazards	Method
models	Method
.	O

Moreover	O
,	O
ordinal	Task
regression	Task
has	O
become	O
a	O
popular	O
topic	O
of	O
study	O
in	O
the	O
field	O
of	O
machine	Task
learning	Task
to	O
extend	O
classification	Method
algorithms	Method
by	O
reformulating	O
the	O
problem	O
to	O
utilize	O
multiple	O
binary	Task
classification	Task
tasks	Task
.	O

Early	O
work	O
in	O
this	O
regard	O
includes	O
the	O
use	O
of	O
perceptrons	Method
crammer2002pranking	Method
,	O
shen2005ranking	O
and	O
Support	Method
Vector	Method
Machines	Method
herbrich1999support	O
,	O
shashua2003ranking	O
,	O
rajaram2003classification	O
,	O
chu2005new	O
.	O

A	O
general	O
reduction	Method
framework	Method
that	O
unified	O
the	O
view	O
of	O
a	O
number	O
of	O
these	O
existing	O
algorithms	O
for	O
ordinal	Task
regression	Task
was	O
later	O
proposed	O
in	O
li2007ordinal	O
.	O

While	O
earlier	O
works	O
on	O
using	O
CNNs	Method
for	O
ordinal	Task
targets	Task
have	O
employed	O
conventional	O
classification	Method
approaches	Method
,	O
the	O
general	Method
reduction	Method
framework	Method
from	O
ordinal	Task
regression	Task
to	O
binary	Task
classification	Task
by	O
li2007ordinal	O
was	O
recently	O
adopted	O
by	O
niu2016ordinal	O
.	O

In	O
niu2016ordinal	Task
,	O
an	O
ordinal	Task
regression	Task
problem	Task
with	O
ranks	O
was	O
transformed	O
into	O
binary	Task
classification	Task
problems	Task
,	O
with	O
the	O
th	Task
task	Task
predicting	O
whether	O
the	O
age	O
label	O
of	O
a	O
face	O
image	O
exceeds	O
rank	O
,	O
.	O

Here	O
,	O
all	O
tasks	O
share	O
the	O
same	O
intermediate	O
layers	O
but	O
are	O
assigned	O
distinct	O
weight	O
parameters	O
in	O
the	O
output	O
layer	O
.	O

One	O
issue	O
with	O
this	O
architecture	O
is	O
that	O
for	O
some	O
input	O
images	O
the	O
outputs	O
of	O
the	O
tasks	O
do	O
not	O
agree	O
with	O
each	O
other	O
.	O

Hence	O
,	O
the	O
model	O
does	O
not	O
guarantee	O
that	O
the	O
predictions	O
are	O
consistent	O
.	O

For	O
example	O
,	O
in	O
an	O
age	Task
estimation	Task
setting	O
,	O
it	O
would	O
be	O
contradictory	O
if	O
the	O
th	O
binary	O
task	O
predicted	O
that	O
the	O
age	O
of	O
a	O
person	O
was	O
larger	O
than	O
30	O
,	O
but	O
a	O
previous	O
task	O
predicted	O
it	O
was	O
not	O
larger	O
than	O
20	O
,	O
which	O
is	O
suboptimal	O
when	O
the	O
task	O
predictions	O
are	O
combined	O
to	O
obtain	O
the	O
estimated	O
age	O
.	O

While	O
the	O
ordinal	Method
regression	Method
CNN	Method
yielded	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
results	O
on	O
an	O
ordinal	Task
regression	Task
problem	Task
such	O
as	O
age	Task
estimation	Task
,	O
the	O
authors	O
acknowledged	O
the	O
classifier	O
inconsistency	O
as	O
not	O
being	O
ideal	O
but	O
also	O
noted	O
that	O
ensuring	O
that	O
the	O
binary	Method
classifiers	Method
are	O
consistent	O
would	O
increase	O
the	O
training	Metric
complexity	Metric
substantially	O
niu2016ordinal	Task
.	O

Our	O
proposed	O
method	O
addresses	O
both	O
of	O
these	O
issues	O
with	O
a	O
theoretical	Metric
guarantee	Metric
for	O
classifier	Metric
consistency	Metric
as	O
well	O
as	O
a	O
reduction	O
of	O
the	O
training	Metric
complexity	Metric
.	O

subsection	O
:	O
CNN	Method
Architectures	Method
for	O
Age	Task
Estimation	Task
Due	O
to	O
its	O
broad	O
utility	O
in	O
social	Task
networking	Task
,	O
video	Task
surveillance	Task
,	O
and	O
biometric	Task
verification	Task
,	O
age	Task
estimation	Task
from	O
human	O
faces	O
is	O
an	O
area	O
of	O
active	O
research	O
.	O

Various	O
techniques	O
have	O
been	O
developed	O
for	O
extracting	O
facial	O
features	O
as	O
inputs	O
to	O
classification	Method
or	Method
metric	Method
regression	Method
algorithms	Method
o19993d	O
,	O
ramanathan2009computational	O
,	O
turaga2010role	O
,	O
kohail2012using	O
,	O
wu2012age	O
,	O
geng2013facial	O
.	O

In	O
recent	O
years	O
,	O
CNN	Method
research	Method
has	O
rapidly	O
advanced	O
,	O
and	O
CNNs	Method
now	O
surpass	O
most	O
traditional	O
methods	O
on	O
image	Task
-	Task
analyses	Task
tasks	Task
while	O
not	O
requiring	O
feature	Task
extraction	Task
beyond	O
standard	O
image	Method
preprocessing	Method
steps	Method
.	O

Hence	O
,	O
most	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
age	Task
estimation	Task
methods	O
are	O
now	O
utilizing	O
CNN	Method
architectures	Method
rothe2015dex	O
,	O
chen2016cascaded	O
,	O
niu2016ordinal	O
,	O
ranjan2017all	O
,	O
chen2017using	O
.	O

Related	O
to	O
the	O
idea	O
of	O
training	O
binary	Method
classifiers	Method
separately	O
and	O
combining	O
the	O
independent	O
predictions	O
for	O
ranking	Task
frank2001simple	O
,	O
a	O
modification	O
of	O
the	O
ordinal	Method
regression	Method
CNN	Method
niu2016ordinal	O
was	O
recently	O
proposed	O
for	O
age	Task
estimation	Task
,	O
called	O
Ranking	Method
-	Method
CNN	Method
,	O
that	O
trains	O
an	O
ensemble	Method
of	Method
CNNs	Method
for	O
binary	Task
classifications	Task
and	O
aggregates	O
the	O
predictions	O
to	O
predict	O
the	O
age	Task
label	Task
of	O
a	O
given	O
face	O
image	O
chen2017using	O
.	O

The	O
researchers	O
showed	O
that	O
training	O
a	O
series	O
of	O
CNNs	Method
improves	O
the	O
predictive	Metric
performance	Metric
over	O
a	O
single	O
CNN	Method
with	O
multiple	O
binary	O
outputs	O
.	O

However	O
,	O
ensembles	Method
of	Method
CNNs	Method
come	O
with	O
a	O
substantial	O
increase	O
in	O
training	Metric
complexity	Metric
and	O
do	O
not	O
guarantee	O
classifier	Metric
consistency	Metric
,	O
which	O
means	O
that	O
the	O
individual	O
binary	Method
classifiers	Method
used	O
for	O
ranking	Task
can	O
produce	O
contradictory	O
results	O
.	O

Another	O
approach	O
for	O
utilizing	O
binary	Method
classifiers	Method
for	O
ordinal	Task
regression	Task
is	O
the	O
siamese	Method
CNN	Method
architecture	Method
by	O
.	O

Since	O
this	O
siamese	Method
CNN	Method
has	O
only	O
a	O
single	O
output	O
neuron	O
,	O
comparisons	O
between	O
the	O
input	O
image	O
and	O
multiple	O
,	O
carefully	O
selected	O
anchor	O
images	O
are	O
required	O
to	O
compute	O
the	O
rank	O
.	O

Age	Method
distribution	Method
learning	Method
has	O
made	O
other	O
notable	O
progress	O
in	O
age	Task
estimation	Task
;	O
here	O
,	O
the	O
researchers	O
defined	O
a	O
new	O
loss	Method
function	Method
to	O
penalize	O
the	O
difference	O
between	O
estimated	O
age	O
distributions	O
and	O
the	O
ground	O
truth	O
age	O
labels	O
.	O

Recent	O
research	O
has	O
also	O
shown	O
that	O
training	O
a	O
multi	Method
-	Method
task	Method
CNN	Method
for	O
various	O
face	Task
analysis	Task
tasks	Task
,	O
including	O
face	Task
detection	Task
,	O
gender	Task
prediction	Task
,	O
age	Task
estimation	Task
,	O
etc	O
.	O

,	O
can	O
improve	O
the	O
overall	O
performance	O
across	O
different	O
tasks	O
compared	O
to	O
a	O
single	Method
-	Method
task	Method
CNN	Method
ranjan2017all	O
by	O
sharing	O
lower	O
-	O
layer	O
parameters	O
.	O

In	O
chen2016cascaded	O
,	O
a	O
cascaded	Method
convolutional	Method
neural	Method
network	Method
was	O
designed	O
to	O
classify	O
face	O
images	O
into	O
age	O
groups	O
followed	O
by	O
regression	Method
modules	Method
for	O
more	O
accurate	O
age	Task
estimation	Task
.	O

In	O
both	O
studies	O
,	O
the	O
authors	O
used	O
metric	Method
regression	Method
for	O
the	O
age	Task
estimation	Task
subtasks	O
.	O

While	O
our	O
paper	O
focuses	O
on	O
the	O
comparison	O
of	O
different	O
ordinal	Method
regression	Method
approaches	Method
,	O
we	O
hypothesize	O
that	O
such	O
all	Method
-	Method
in	Method
-	Method
one	Method
and	Method
cascaded	Method
CNNs	Method
can	O
be	O
further	O
improved	O
by	O
our	O
method	O
,	O
since	O
,	O
as	O
shown	O
in	O
niu2016ordinal	O
,	O
ordinal	Method
regression	Method
CNNs	Method
outperform	O
metric	Method
regression	Method
CNNs	Method
in	O
age	Task
estimation	Task
tasks	O
.	O

section	O
:	O
Proposed	O
Method	O
This	O
section	O
describes	O
the	O
proposed	O
CORAL	Method
framework	O
that	O
addresses	O
the	O
problem	O
of	O
classifier	Task
inconsistency	Task
in	O
ordinal	Method
regression	Method
CNNs	Method
based	O
on	O
multiple	O
binary	Task
classification	Task
tasks	Task
for	O
ranking	Task
.	O

subsection	O
:	O
Preliminaries	O
Let	O
be	O
the	O
training	O
dataset	O
consisting	O
of	O
examples	O
.	O

Here	O
,	O
denotes	O
the	O
-	O
th	O
image	O
and	O
denotes	O
the	O
corresponding	O
rank	O
,	O
where	O
with	O
ordered	O
rank	O
.	O

The	O
symbol	O
denotes	O
the	O
ordering	O
between	O
the	O
ranks	O
.	O

The	O
ordinal	Task
regression	Task
task	Task
is	O
to	O
find	O
a	O
ranking	Task
rule	O
such	O
that	O
some	O
loss	O
function	O
is	O
minimized	O
.	O

Let	O
be	O
a	O
cost	O
matrix	O
li2007ordinal	O
,	O
where	O
is	O
the	O
cost	O
of	O
predicting	O
an	O
example	O
as	O
rank	O
.	O

Typically	O
,	O
and	O
for	O
.	O

In	O
ordinal	Task
regression	Task
,	O
we	O
generally	O
prefer	O
each	O
row	O
of	O
the	O
cost	O
matrix	O
to	O
be	O
V	O
-	O
shaped	O
.	O

That	O
is	O
if	O
and	O
if	O
.	O

The	O
classification	O
cost	O
matrix	O
has	O
entries	O
,	O
which	O
does	O
not	O
consider	O
ordering	O
information	O
.	O

In	O
ordinal	Task
regression	Task
,	O
where	O
the	O
ranks	O
are	O
treated	O
as	O
numerical	O
values	O
,	O
the	O
absolute	O
cost	O
matrix	O
is	O
commonly	O
defined	O
by	O
.	O

In	O
li2007ordinal	O
,	O
the	O
researchers	O
proposed	O
a	O
general	O
reduction	Method
framework	Method
for	O
extending	O
an	O
ordinal	Task
regression	Task
problem	Task
into	O
several	O
binary	Task
classification	Task
problems	Task
.	O

This	O
framework	O
requires	O
the	O
use	O
of	O
a	O
cost	O
matrix	O
that	O
is	O
convex	O
in	O
each	O
row	O
(	O
for	O
each	O
)	O
to	O
obtain	O
a	O
rank	Method
-	Method
monotonic	Method
threshold	Method
model	Method
.	O

Since	O
the	O
cost	O
-	O
related	O
weighting	O
of	O
each	O
binary	Task
task	Task
is	O
specific	O
for	O
each	O
training	O
example	O
,	O
this	O
approach	O
was	O
described	O
as	O
unfeasible	O
in	O
practice	O
due	O
to	O
its	O
high	O
training	Metric
complexity	Metric
niu2016ordinal	O
.	O

Our	O
proposed	O
CORAL	Method
framework	O
does	O
neither	O
require	O
a	O
cost	O
matrix	O
with	O
convex	O
-	O
row	O
conditions	O
nor	O
explicit	O
weighting	O
terms	O
that	O
depend	O
on	O
each	O
training	O
example	O
to	O
obtain	O
a	O
rank	Method
-	Method
monotonic	Method
threshold	Method
model	Method
and	O
to	O
produce	O
consistent	O
predictions	O
for	O
each	O
binary	Task
task	Task
.	O

Moreover	O
,	O
CORAL	Method
allows	O
for	O
an	O
optional	O
task	O
importance	O
weighting	O
,	O
e.g.	O
,	O
to	O
adjust	O
for	O
label	O
and	O
class	O
imbalances	O
,	O
which	O
makes	O
it	O
more	O
applicable	O
in	O
practice	O
.	O

subsection	O
:	O
Ordinal	Task
Regression	Task
with	O
a	O
Consistent	Method
Rank	Method
Logits	Method
model	O
We	O
propose	O
the	O
Consistent	Method
Rank	Method
Logits	Method
(	O
CORAL	Method
)	O
model	O
for	O
multi	Task
-	Task
label	Task
CNNs	Task
with	Task
ordinal	Task
responses	Task
.	O

Within	O
this	O
framework	O
,	O
the	O
binary	Task
tasks	Task
produce	O
consistently	O
ranked	O
predictions	O
.	O

paragraph	O
:	O
Label	Task
Extension	Task
and	O
Rank	Task
Prediction	Task
.	O

Given	O
the	O
training	O
dataset	O
,	O
we	O
first	O
extend	O
a	O
rank	O
label	O
into	O
binary	O
labels	O
such	O
that	O
indicates	O
whether	O
exceeds	O
rank	O
,	O
i.e.	O
,	O
.	O

The	O
indicator	O
function	O
is	O
if	O
the	O
inner	O
condition	O
is	O
true	O
,	O
and	O
otherwise	O
.	O

Providing	O
the	O
extended	O
binary	O
labels	O
as	O
model	O
inputs	O
,	O
we	O
train	O
a	O
single	O
CNN	Method
with	O
binary	Method
classifiers	Method
in	O
the	O
output	O
layer	O
.	O

Here	O
,	O
the	O
binary	O
tasks	O
share	O
the	O
same	O
weight	O
parameter	O
but	O
have	O
independent	O
bias	O
units	O
,	O
which	O
solves	O
the	O
inconsistency	Task
problem	Task
among	O
the	O
predicted	O
binary	O
responses	O
and	O
reduces	O
the	O
model	Metric
complexity	Metric
.	O

Based	O
on	O
the	O
binary	O
task	O
responses	O
,	O
the	O
predicted	O
rank	O
for	O
an	O
input	O
is	O
then	O
obtained	O
via	O
where	O
is	O
the	O
prediction	O
of	O
the	O
th	O
binary	Method
classifier	Method
in	O
the	O
output	O
layer	O
.	O

We	O
require	O
that	O
reflect	O
the	O
ordinal	O
information	O
and	O
are	O
rank	O
-	O
monotonic	O
,	O
which	O
guarantees	O
that	O
the	O
predictions	O
are	O
consistent	O
.	O

paragraph	O
:	O
Loss	O
Function	O
.	O

Let	O
denote	O
the	O
weight	O
parameters	O
of	O
the	O
neural	Method
network	Method
excluding	O
the	O
bias	O
units	O
of	O
the	O
final	O
layer	O
.	O

The	O
penultimate	Method
layer	Method
,	O
whose	O
output	O
is	O
denoted	O
as	O
,	O
shares	O
a	O
single	O
weight	O
with	O
all	O
nodes	O
in	O
the	O
final	O
output	O
layer	O
.	O

independent	O
bias	O
units	O
are	O
then	O
added	O
to	O
such	O
that	O
are	O
the	O
inputs	O
to	O
the	O
corresponding	O
binary	Method
classifiers	Method
in	O
the	O
final	O
layer	O
.	O

Let	O
be	O
the	O
logistic	Method
sigmoid	Method
function	Method
.	O

The	O
predicted	O
empirical	O
probability	O
for	O
task	O
is	O
defined	O
as	O
For	O
model	Task
training	Task
,	O
we	O
minimize	O
the	O
loss	Metric
function	Metric
which	O
is	O
the	O
weighted	Method
cross	Method
-	Method
entropy	Method
of	Method
binary	Method
classifiers	Method
.	O

For	O
rank	Task
prediction	Task
(	O
Eq	O
.	O

[	O
reference	O
]	O
)	O
,	O
the	O
binary	O
labels	O
are	O
obtained	O
via	O
In	O
Eq	O
.	O

(	O
[	O
reference	O
]	O
)	O
,	O
denotes	O
the	O
weight	O
of	O
the	O
loss	O
associated	O
with	O
the	O
th	O
classifier	Method
(	O
assuming	O
)	O
.	O

In	O
the	O
remainder	O
of	O
the	O
paper	O
,	O
we	O
refer	O
to	O
as	O
the	O
importance	O
parameter	O
for	O
task	O
.	O

Some	O
tasks	O
may	O
be	O
less	O
robust	O
or	O
harder	O
to	O
optimize	O
,	O
which	O
can	O
be	O
taken	O
into	O
consideration	O
by	O
choosing	O
a	O
non	Method
-	Method
uniform	Method
task	Method
weighting	Method
scheme	Method
.	O

Also	O
,	O
in	O
many	O
real	Task
-	Task
world	Task
applications	Task
,	O
features	O
between	O
certain	O
adjacent	O
ranks	O
may	O
have	O
more	O
subtle	O
distinctions	O
.	O

For	O
example	O
,	O
facial	Task
aging	Task
is	O
commonly	O
regarded	O
as	O
a	O
non	Method
-	Method
stationary	Method
process	Method
ramanathan2009age	O
such	O
that	O
face	O
feature	O
transformations	O
could	O
be	O
more	O
detectable	O
during	O
certain	O
age	O
intervals	O
.	O

Moreover	O
,	O
the	O
relative	Metric
predictive	Metric
performance	Metric
of	O
the	O
binary	Task
tasks	Task
may	O
also	O
be	O
affected	O
by	O
the	O
degree	O
of	O
binary	O
data	O
imbalance	O
for	O
a	O
given	O
task	O
that	O
occurs	O
as	O
a	O
side	O
-	O
effect	O
of	O
extending	O
a	O
rank	O
label	O
into	O
binary	O
labels	O
.	O

Hence	O
,	O
we	O
hypothesize	O
that	O
choosing	O
non	Method
-	Method
uniform	Method
task	Method
weighting	Method
schemes	Method
improves	O
the	O
predictive	Metric
performance	Metric
of	O
the	O
overall	O
model	O
.	O

The	O
choice	O
of	O
task	O
importance	O
parameters	O
is	O
covered	O
in	O
more	O
detail	O
in	O
Section	O
[	O
reference	O
]	O
.	O

Next	O
,	O
we	O
provide	O
a	O
theoretical	O
guarantee	O
for	O
classifier	Metric
consistency	Metric
under	O
uniform	O
and	O
non	O
-	O
uniform	O
task	O
importance	O
weighting	O
given	O
that	O
the	O
task	O
importance	O
weights	O
are	O
positive	O
numbers	O
.	O

subsection	O
:	O
Theoretical	O
Guarantees	O
for	O
Classifier	Metric
Consistency	Metric
In	O
the	O
following	O
theorem	O
,	O
we	O
show	O
that	O
by	O
minimizing	O
the	O
loss	O
(	O
Eq	O
.	O

[	O
reference	O
]	O
)	O
,	O
the	O
learned	O
bias	O
units	O
of	O
the	O
output	O
layer	O
are	O
non	O
-	O
increasing	O
such	O
that	O
.	O

Consequently	O
,	O
the	O
predicted	Metric
confidence	Metric
scores	Metric
or	O
probability	Metric
estimates	Metric
of	O
the	O
tasks	O
are	O
decreasing	O
,	O
i.e.	O
,	O
for	O
all	O
,	O
ensuring	O
classifier	Metric
consistency	Metric
.	O

given	O
by	O
Eq	O
.	O

[	O
reference	O
]	O
are	O
also	O
rank	O
-	O
monotonic	O
.	O

theorem	O
:	O
(	O
ordered	O
biases	O
)	O
.	O

By	O
minimizing	O
loss	O
function	O
defined	O
in	O
Eq	O
.	O

(	O
)	O
,	O
the	O
optimal	O
solution	O
(	O
W*	O
,	O
b	O
*	O
)	O
satisfies	O
b1*≥b2*≥	O
…	O
≥b	O
-	O
K1*.	O
proof	O
:	O
Proof	O
.	O

Suppose	O
is	O
an	O
optimal	O
solution	O
and	O
for	O
some	O
.	O

Claim	O
:	O
by	O
either	O
replacing	O
with	O
or	O
replacing	O
with	O
,	O
we	O
can	O
decrease	O
the	O
objective	Metric
value	Metric
.	O

Let	O
By	O
the	O
ordering	O
relationship	O
we	O
have	O
.	O

Denote	O
and	O
Since	O
is	O
increasing	O
in	O
,	O
we	O
have	O
and	O
.	O

If	O
we	O
replace	O
with	O
,	O
the	O
loss	O
terms	O
related	O
to	O
th	O
task	O
are	O
updated	O
.	O

The	O
change	O
of	O
loss	O
(	O
Eq	O
.	O

[	O
reference	O
]	O
)	O
is	O
given	O
as	O
Accordingly	O
,	O
if	O
we	O
replace	O
with	O
,	O
the	O
change	O
of	O
is	O
given	O
as	O
By	O
adding	O
and	O
,	O
we	O
have	O
and	O
know	O
that	O
either	O
or	O
.	O

Thus	O
,	O
our	O
claim	O
is	O
justified	O
,	O
and	O
we	O
conclude	O
that	O
any	O
optimal	O
solution	O
that	O
minimizes	O
satisfies	O
.	O

∎	O
Note	O
that	O
the	O
theorem	O
for	O
rank	Task
-	Task
monotonicity	Task
in	O
li2007ordinal	O
,	O
in	O
contrast	O
to	O
Theorem	O
[	O
reference	O
]	O
,	O
requires	O
the	O
use	O
of	O
a	O
cost	O
matrix	O
with	O
each	O
row	O
being	O
convex	O
.	O

Under	O
this	O
convexity	O
condition	O
,	O
let	O
be	O
the	O
weight	O
of	O
loss	O
of	O
the	O
th	O
task	O
on	O
the	O
th	O
example	O
,	O
which	O
depends	O
on	O
the	O
label	O
.	O

In	O
li2007ordinal	O
,	O
the	O
researchers	O
proved	O
that	O
by	O
using	O
example	O
-	O
specific	O
task	O
weights	O
,	O
the	O
optimal	O
thresholds	O
are	O
ordered	O
.	O

This	O
assumption	O
requires	O
that	O
when	O
,	O
and	O
when	O
.	O

Theorem	O
[	O
reference	O
]	O
is	O
free	O
from	O
this	O
requirement	O
and	O
allows	O
us	O
to	O
choose	O
a	O
fixed	O
weight	O
for	O
each	O
task	O
that	O
does	O
not	O
depend	O
on	O
the	O
individual	O
training	O
examples	O
,	O
which	O
greatly	O
reduces	O
the	O
training	Metric
complexity	Metric
.	O

Moreover	O
,	O
Theorem	O
[	O
reference	O
]	O
allows	O
for	O
choosing	O
either	O
a	O
simple	O
uniform	Method
task	Method
weighting	Method
or	O
taking	O
dataset	O
imbalances	O
into	O
account	O
(	O
Section	O
[	O
reference	O
]	O
)	O
while	O
still	O
guaranteeing	O
that	O
the	O
predicted	O
probabilities	O
are	O
non	O
-	O
decreasing	O
and	O
the	O
task	O
predictions	O
are	O
consistent	O
.	O

subsection	O
:	O
Generalization	Metric
Bounds	Metric
Based	O
on	O
well	O
-	O
known	O
generalization	Method
bounds	Method
for	O
binary	Task
classification	Task
,	O
we	O
can	O
derive	O
new	O
generalization	Method
bounds	Method
for	O
our	O
ordinal	Method
regression	Method
approach	Method
that	O
apply	O
to	O
a	O
wide	O
range	O
of	O
practical	O
scenarios	O
as	O
we	O
only	O
require	O
and	O
.	O

Moreover	O
,	O
Theorem	O
[	O
reference	O
]	O
shows	O
that	O
if	O
each	O
binary	Task
classification	Task
task	Task
in	O
our	O
model	O
generalizes	O
well	O
in	O
terms	O
of	O
the	O
standard	O
0	Method
/	Method
1	Method
-	Method
loss	Method
,	O
the	O
final	O
rank	Task
prediction	Task
via	O
(	O
Eq	O
.	O

[	O
reference	O
]	O
)	O
also	O
generalizes	O
well	O
.	O

theorem	O
:	O
(	O
reduction	Task
of	Task
generalization	Task
error	Task
)	O
.	O

Suppose	O
C	O
is	O
the	O
cost	O
matrix	O
of	O
the	O
original	O
ordinal	Task
label	Task
prediction	Task
problem	Task
,	O
with	O
=	O
Cy	O
,	O
y0	O
and	O
>	O
Cy	O
,	O
k0	O
for	O
≠ky	O
.	O

P	O
is	O
the	O
underlying	O
distribution	O
of	O
(	O
x	O
,	O
y	O
)	O
,	O
i.e.	O
,	O
∼	O
(	O
x	O
,	O
y	O
)	O
P.	O
If	O
{	O
fk}=k1	O
-	O
K1	O
are	O
rank	O
-	O
monotonic	O
,	O
then	O
proof	O
:	O
Proof	O
.	O

For	O
any	O
,	O
we	O
have	O
If	O
,	O
then	O
.	O

If	O
,	O
then	O
.	O

We	O
have	O
and	O
Also	O
,	O
and	O
.	O

Thus	O
,	O
if	O
and	O
only	O
if	O
.	O

Since	O
,	O
Similarly	O
,	O
if	O
,	O
then	O
and	O
In	O
any	O
case	O
,	O
we	O
have	O
By	O
taking	O
the	O
expectation	O
on	O
both	O
sides	O
with	O
,	O
we	O
arrive	O
at	O
Eq	O
.	O

(	O
[	O
reference	O
]	O
)	O
.	O

∎	O
In	O
li2007ordinal	O
,	O
by	O
assuming	O
the	O
cost	O
matrix	O
to	O
have	O
V	O
-	O
shaped	O
rows	O
,	O
the	O
researchers	O
define	O
generalization	O
bounds	O
by	O
constructing	O
a	O
discrete	O
distribution	O
on	O
conditional	O
on	O
each	O
,	O
given	O
that	O
the	O
binary	O
classifications	O
are	O
rank	O
-	O
monotonic	O
or	O
every	O
row	O
of	O
is	O
convex	O
.	O

However	O
,	O
the	O
only	O
case	O
they	O
provided	O
for	O
the	O
existence	O
of	O
rank	Method
-	Method
monotonic	Method
binary	Method
classifiers	Method
was	O
the	O
ordered	Method
threshold	Method
model	Method
,	O
which	O
requires	O
a	O
cost	O
matrix	O
with	O
convex	O
rows	O
and	O
example	O
-	O
specific	O
task	O
weights	O
.	O

Our	O
result	O
does	O
not	O
rely	O
on	O
cost	O
matrices	O
with	O
V	O
-	O
shaped	O
or	O
convex	O
rows	O
and	O
can	O
be	O
applied	O
to	O
a	O
broader	O
variety	O
of	O
real	O
-	O
world	O
use	O
cases	O
.	O

subsection	O
:	O
Task	Method
Importance	Method
Weighting	Method
According	O
to	O
Theorem	O
[	O
reference	O
]	O
,	O
minimizing	O
the	O
loss	O
of	O
the	O
CORAL	Method
model	O
guarantees	O
that	O
the	O
bias	O
units	O
are	O
non	O
-	O
increasing	O
and	O
thus	O
the	O
binary	Method
classifiers	Method
are	O
consistent	O
as	O
long	O
as	O
the	O
task	O
importance	O
parameters	O
are	O
positive	O
(	O
)	O
.	O

We	O
first	O
experimented	O
with	O
a	O
weighting	Method
scheme	Method
proposed	O
in	O
that	O
aims	O
to	O
address	O
the	O
class	O
imbalance	O
in	O
the	O
face	O
image	O
datasets	O
.	O

However	O
,	O
compared	O
to	O
using	O
a	O
uniform	Method
scheme	Method
(	O
)	O
,	O
we	O
found	O
that	O
it	O
had	O
a	O
negative	O
effect	O
on	O
the	O
predictive	Metric
performance	Metric
for	O
all	O
models	O
evaluated	O
in	O
this	O
study	O
.	O

Hence	O
,	O
we	O
propose	O
a	O
weighting	Method
scheme	Method
that	O
takes	O
the	O
rank	O
distribution	O
of	O
the	O
training	O
examples	O
into	O
account	O
but	O
also	O
considers	O
the	O
label	O
imbalance	O
for	O
each	O
classification	Task
task	Task
after	O
extending	O
the	O
original	O
ranks	O
into	O
binary	O
labels	O
.	O

Specifically	O
,	O
our	O
task	Method
weighting	Method
scheme	Method
(	O
under	O
which	O
CORAL	Method
still	O
guarantees	O
classifier	Metric
consistency	Metric
)	O
is	O
defined	O
as	O
follows	O
.	O

Let	O
be	O
the	O
number	O
of	O
examples	O
whose	O
ranks	O
exceed	O
.	O

By	O
the	O
rank	O
ordering	O
we	O
have	O
.	O

Let	O
be	O
the	O
number	O
of	O
majority	O
binary	O
label	O
for	O
each	O
task	O
.	O

We	O
define	O
the	O
importance	O
of	O
the	O
th	O
task	O
as	O
the	O
scaled	O
:	O
Under	O
this	O
weighting	Method
scheme	Method
,	O
the	O
general	O
class	O
imbalance	O
of	O
a	O
dataset	O
is	O
taken	O
into	O
account	O
.	O

Moreover	O
,	O
in	O
our	O
examples	O
classification	Task
tasks	Task
corresponding	O
to	O
the	O
edges	O
of	O
the	O
distribution	O
of	O
unique	O
rank	O
labels	O
receive	O
a	O
higher	O
weight	O
than	O
the	O
classification	Task
tasks	Task
that	O
see	O
more	O
balanced	O
rank	O
label	O
vectors	O
during	O
training	O
(	O
Figure	O
[	O
reference	O
]	O
)	O
,	O
which	O
may	O
help	O
improve	O
the	O
predictive	Metric
performance	Metric
of	O
the	O
model	O
.	O

The	O
lowest	O
weight	O
may	O
not	O
always	O
be	O
assigned	O
to	O
the	O
center	O
-	O
rank	O
:	O
if	O
,	O
the	O
last	O
task	O
has	O
the	O
lowest	O
weight	O
,	O
and	O
if	O
,	O
the	O
first	O
task	O
has	O
the	O
lowest	O
weight	O
.	O

It	O
shall	O
be	O
noted	O
that	O
the	O
task	Method
importance	Method
weighting	Method
is	O
only	O
used	O
for	O
model	Task
parameter	Task
optimization	Task
;	O
when	O
computing	O
the	O
predicted	O
rank	O
by	O
adding	O
the	O
binary	O
results	O
(	O
Eq	O
.	O

[	O
reference	O
]	O
)	O
,	O
each	O
task	O
has	O
the	O
same	O
influence	O
on	O
the	O
final	O
rank	Task
prediction	Task
.	O

Since	O
,	O
it	O
prevents	O
tasks	O
from	O
having	O
negligible	O
weights	O
as	O
in	O
niu2016ordinal	O
when	O
a	O
dataset	O
contains	O
only	O
a	O
small	O
number	O
of	O
examples	O
for	O
certain	O
ranks	O
.	O

We	O
provide	O
an	O
empirical	O
comparison	O
between	O
a	O
uniform	Method
task	Method
weighting	Method
and	O
task	Method
weighting	Method
according	O
to	O
Eq	O
.	O

(	O
[	O
reference	O
]	O
)	O
in	O
Section	O
[	O
reference	O
]	O
.	O

section	O
:	O
Experiments	O
subsection	O
:	O
Datasets	O
and	O
Preprocessing	O
paragraph	O
:	O
MORPH	Material
-	Material
2	Material
and	O
CACD	Material
.	O

The	O
MORPH	Material
-	Material
2	Material
dataset	Material
ricanek2006morph	O
(	O
55	O
,	O
608	O
face	O
images	O
)	O
was	O
preprocessed	O
by	O
locating	O
the	O
average	O
eye	O
-	O
position	O
in	O
the	O
respective	O
dataset	O
using	O
facial	Method
landmark	Method
detection	Method
sagonas2016300	O
via	O
MLxtend	Method
raschka2018mlxtend	O
and	O
then	O
aligning	O
each	O
image	O
in	O
the	O
dataset	O
to	O
the	O
average	O
eye	O
position	O
.	O

The	O
faces	O
were	O
then	O
re	O
-	O
aligned	O
such	O
that	O
the	O
tip	O
of	O
the	O
nose	O
was	O
located	O
in	O
the	O
center	O
of	O
each	O
image	O
.	O

The	O
age	O
labels	O
used	O
in	O
this	O
study	O
ranged	O
between	O
16	O
-	O
70	O
years	O
.	O

The	O
CACD	Material
database	Material
was	O
preprocessed	O
similar	O
to	O
MORPH	Material
-	Material
2	Material
such	O
that	O
the	O
faces	O
spanned	O
the	O
whole	O
image	O
with	O
the	O
nose	O
tip	O
being	O
in	O
the	O
center	O
.	O

The	O
total	O
number	O
of	O
images	O
is	O
159	O
,	O
449	O
in	O
the	O
age	O
range	O
14	O
-	O
62	O
years	O
.	O

paragraph	O
:	O
AFAD	Material
and	O
UTKFace	Material
.	O

Since	O
the	O
faces	O
were	O
already	O
centered	O
in	O
the	O
Asian	Material
Face	Material
Database	Material
(	O
AFAD	Material
;	O
165	O
,	O
501	O
faces	O
with	O
ages	O
labels	O
between	O
15	O
-	O
40	O
)	O
niu2016ordinal	O
,	O
no	O
further	O
alignment	O
was	O
applied	O
.	O

The	O
UTKFace	Material
database	Material
was	O
also	O
available	O
in	O
a	O
preprocessed	O
form	O
such	O
that	O
no	O
additional	O
steps	O
were	O
required	O
.	O

In	O
this	O
study	O
,	O
we	O
considered	O
face	O
images	O
with	O
age	O
labels	O
between	O
21	O
-	O
60	O
years	O
(	O
16	O
,	O
434	O
images	O
)	O
.	O

Each	O
image	O
database	O
was	O
randomly	O
divided	O
into	O
80	O
%	O
training	O
data	O
and	O
20	O
%	O
test	O
data	O
.	O

All	O
images	O
were	O
resized	O
to	O
128x128x3	O
pixels	O
and	O
then	O
randomly	O
cropped	O
to	O
120x120x3	O
pixels	O
to	O
augment	O
the	O
model	Method
training	Method
.	O

During	O
model	Task
evaluation	Task
,	O
the	O
128x128x3	O
face	O
images	O
were	O
center	O
-	O
cropped	O
to	O
a	O
model	O
input	O
size	O
of	O
120x120x3	O
.	O

subsection	O
:	O
Convolutional	Method
Neural	Method
Network	Method
Architectures	Method
To	O
evaluate	O
the	O
performance	O
of	O
CORAL	Method
for	O
age	Task
estimation	Task
from	O
face	O
images	O
,	O
we	O
chose	O
the	O
ResNet	Method
-	Method
34	Method
architecture	Method
,	O
which	O
is	O
a	O
modern	O
CNN	Method
architecture	Method
that	O
is	O
known	O
for	O
achieving	O
good	O
performance	O
on	O
a	O
variety	O
of	O
image	Task
classification	Task
tasks	Task
.	O

For	O
the	O
remainder	O
of	O
this	O
paper	O
,	O
we	O
refer	O
to	O
the	O
original	O
ResNet	Method
-	Method
34	Method
CNN	Method
with	O
cross	Method
entropy	Method
loss	Method
as	O
CE	Method
-	Method
CNN	Method
.	O

To	O
implement	O
CORAL	Method
,	O
we	O
replaced	O
the	O
last	O
output	O
layer	O
with	O
the	O
corresponding	O
binary	O
tasks	O
(	O
Figure	O
[	O
reference	O
]	O
)	O
and	O
refer	O
to	O
this	O
CNN	Method
as	O
CORAL	Method
-	Method
CNN	Method
.	O

Similar	O
to	O
CORAL	Method
-	Method
CNN	Method
,	O
we	O
replaced	O
the	O
cross	Method
-	Method
entropy	Method
layer	Method
of	O
the	O
ResNet	Method
-	Method
34	Method
with	O
the	O
binary	Method
tasks	Method
for	O
ordinal	Task
regression	Task
described	O
in	O
and	O
refer	O
to	O
this	O
architecture	O
as	O
OR	Method
-	Method
CNN	Method
.	O

subsection	O
:	O
Training	O
and	O
Evaluation	O
For	O
model	Task
evaluation	Task
and	O
comparison	O
,	O
we	O
computed	O
the	O
mean	Metric
absolute	Metric
error	Metric
(	O
MAE	Metric
)	O
and	O
root	Metric
mean	Metric
squared	Metric
error	Metric
(	O
RMSE	Metric
)	O
,	O
which	O
are	O
standard	O
metrics	O
used	O
for	O
crow	Task
-	Task
counting	Task
and	Task
age	Task
prediction	Task
:	O
where	O
is	O
the	O
ground	O
truth	O
rank	O
of	O
the	O
th	O
test	O
example	O
and	O
is	O
the	O
predicted	O
rank	O
,	O
respectively	O
.	O

The	O
MAE	Metric
and	O
RMSE	Metric
values	O
reported	O
in	O
this	O
study	O
were	O
computed	O
on	O
the	O
test	O
set	O
after	O
the	O
last	O
training	O
epoch	O
.	O

The	O
training	O
was	O
repeated	O
three	O
times	O
with	O
different	O
random	O
seeds	O
for	O
model	Method
weight	Method
initialization	Method
while	O
the	O
random	O
seeds	O
were	O
consistent	O
between	O
the	O
different	O
methods	O
to	O
allow	O
for	O
fair	O
comparisons	O
.	O

All	O
CNNs	Method
were	O
trained	O
for	O
200	O
epochs	O
with	O
stochastic	Method
gradient	Method
descent	Method
via	O
adaptive	Method
moment	Method
estimation	Method
kingma2015adam	O
using	O
exponential	Method
decay	Method
rates	Method
and	O
(	O
PyTorch	O
default	O
)	O
and	O
learning	Metric
rate	Metric
.	O

In	O
addition	O
,	O
we	O
computed	O
the	O
Cumulative	Metric
Score	Metric
(	O
CS	Metric
)	O
as	O
the	O
proportion	O
of	O
images	O
for	O
which	O
the	O
absolute	O
differences	O
between	O
the	O
predicted	O
rank	O
labels	O
and	O
the	O
ground	O
truth	O
are	O
below	O
a	O
threshold	O
:	O
By	O
varying	O
the	O
threshold	O
,	O
CS	O
curves	O
were	O
plotted	O
to	O
compare	O
the	O
predictive	O
performances	O
of	O
the	O
different	O
age	Method
prediction	Method
models	Method
(	O
the	O
larger	O
the	O
area	O
under	O
the	O
curve	O
,	O
the	O
better	O
)	O
.	O

subsection	O
:	O
Hardware	O
and	O
Software	O
All	O
loss	Method
functions	Method
and	O
neural	Method
network	Method
models	Method
were	O
implemented	O
in	O
PyTorch	Method
1.0	Method
paszke2017automatic	O
and	O
trained	O
on	O
NVIDIA	O
GeForce	O
1080Ti	O
and	O
Titan	O
V	O
graphics	O
cards	O
.	O

The	O
source	O
code	O
is	O
available	O
at	O
.	O

section	O
:	O
Results	O
and	O
Discussion	O
We	O
conducted	O
a	O
series	O
of	O
experiments	O
on	O
four	O
independent	O
face	O
image	O
datasets	O
for	O
age	Task
estimation	Task
(	O
Section	O
[	O
reference	O
]	O
)	O
to	O
compare	O
our	O
CORAL	Method
approach	O
(	O
CORAL	Method
-	Method
CNN	Method
)	O
with	O
the	O
ordinal	Method
regression	Method
approach	Method
described	O
in	O
,	O
denoted	O
as	O
OR	Method
-	Method
CNN	Method
.	O

All	O
implementations	O
were	O
based	O
on	O
the	O
ResNet	Method
-	Method
34	Method
architecture	Method
as	O
described	O
in	O
Section	O
[	O
reference	O
]	O
,	O
including	O
the	O
standard	O
ResNet	Method
-	Method
34	Method
with	Method
cross	Method
-	Method
entropy	Method
loss	Method
(	O
CE	Method
-	Method
CNN	Method
)	O
as	O
performance	O
baseline	O
.	O

subsection	O
:	O
Estimating	O
the	O
Apparent	Task
Age	Task
from	O
Face	O
Images	O
First	O
,	O
we	O
note	O
that	O
for	O
all	O
methods	O
,	O
the	O
overall	O
predictive	Metric
performance	Metric
on	O
the	O
different	O
datasets	O
appears	O
in	O
the	O
following	O
order	O
:	O
MORPH	Material
-	Material
2	Material
AFAD	Material
CACD	Material
UTKFace	Material
(	O
Table	O
[	O
reference	O
]	O
and	O
Figure	O
[	O
reference	O
]	O
)	O
.	O

Possible	O
reasons	O
why	O
all	O
approaches	O
perform	O
best	O
on	O
MORPH	Material
-	Material
2	Material
are	O
that	O
MORPH	Material
-	Material
2	Material
has	O
the	O
best	O
overall	Metric
image	Metric
quality	Metric
and	O
relatively	O
consistent	O
lighting	O
conditions	O
and	O
viewing	O
angles	O
.	O

For	O
instance	O
,	O
we	O
found	O
that	O
AFAD	Material
includes	O
some	O
images	O
of	O
particularly	O
low	O
resolution	O
(	O
e.g.	O
,	O
20x20	O
)	O
.	O

While	O
UTKFace	Material
and	O
CACD	Material
also	O
contain	O
some	O
lower	O
-	O
quality	O
images	O
,	O
a	O
possible	O
reason	O
why	O
the	O
methods	O
perform	O
worse	O
on	O
UTKFace	Material
compared	O
to	O
AFAD	Material
is	O
that	O
UTKFace	Material
is	O
about	O
ten	O
times	O
smaller	O
than	O
AFAD	Material
.	O

While	O
CACD	Material
has	O
approximately	O
the	O
same	O
size	O
as	O
AFAD	Material
,	O
the	O
lower	O
performance	O
can	O
be	O
explained	O
by	O
the	O
wider	O
age	O
range	O
that	O
needs	O
to	O
be	O
considered	O
(	O
14	O
-	O
62	O
in	O
CACD	Material
compared	O
to	O
15	O
-	O
40	O
in	O
AFAD	Material
)	O
.	O

Across	O
all	O
datasets	O
(	O
Table	O
[	O
reference	O
]	O
and	O
Figure	O
[	O
reference	O
]	O
)	O
,	O
we	O
found	O
that	O
both	O
OR	Method
-	Method
CNN	Method
and	O
CORAL	Method
-	Method
CNN	Method
outperform	O
the	O
standard	O
cross	Method
-	Method
entropy	Method
loss	Method
(	O
OR	Method
-	Method
CNN	Method
)	O
on	O
these	O
ordinal	Task
regression	Task
tasks	Task
,	O
as	O
expected	O
.	O

Similarly	O
,	O
as	O
summarized	O
in	O
Table	O
[	O
reference	O
]	O
and	O
Figure	O
[	O
reference	O
]	O
,	O
our	O
CORAL	Method
method	O
shows	O
a	O
substantial	O
improvement	O
over	O
the	O
current	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
ordinal	Method
regression	Method
method	Method
(	O
OR	Method
-	Method
CNN	Method
)	O
by	O
,	O
which	O
does	O
not	O
guarantee	O
classifier	O
consistency	O
.	O

Moreover	O
,	O
we	O
repeated	O
each	O
experiment	O
three	O
times	O
using	O
different	O
random	O
seeds	O
for	O
model	Method
weight	Method
initialization	Method
and	O
dataset	Task
shuffling	Task
,	O
to	O
ensure	O
that	O
the	O
observed	O
performance	O
improvement	O
of	O
CORAL	Method
-	Method
CNN	Method
over	O
OR	Method
-	Method
CNN	Method
is	O
reproducible	O
and	O
not	O
coincidental	O
.	O

Furthermore	O
,	O
along	O
with	O
providing	O
the	O
theoretical	O
proof	O
for	O
classifier	Metric
consistency	Metric
in	O
CORAL	Method
-	Method
CNN	Method
(	O
Theorem	O
[	O
reference	O
]	O
)	O
,	O
we	O
also	O
empirically	O
verified	O
that	O
the	O
bias	O
units	O
of	O
the	O
CORAL	Method
-	O
CNN	O
output	O
layers	O
were	O
indeed	O
ordered	O
after	O
model	Method
training	Method
,	O
in	O
contrast	O
to	O
OR	Method
-	Method
CNN	Method
.	O

From	O
these	O
results	O
,	O
we	O
can	O
conclude	O
that	O
guaranteed	O
classifier	Metric
consistency	Metric
via	O
CORAL	Method
has	O
a	O
substantial	O
,	O
positive	O
effect	O
on	O
the	O
predictive	Metric
performance	Metric
of	O
an	O
ordinal	Method
regression	Method
CNN	Method
.	O

subsection	O
:	O
Task	Method
Importance	Method
Weighting	Method
While	O
all	O
results	O
described	O
in	O
the	O
previous	O
section	O
are	O
based	O
on	O
experiments	O
without	O
task	Method
importance	Method
weighting	Method
(	O
i.e.	O
,	O
)	O
,	O
we	O
repeated	O
all	O
experiments	O
using	O
our	O
weighting	Method
scheme	Method
proposed	O
in	O
Section	O
[	O
reference	O
]	O
,	O
which	O
takes	O
label	O
imbalances	O
into	O
account	O
.	O

Note	O
that	O
according	O
to	O
Theorem	O
[	O
reference	O
]	O
,	O
CORAL	Method
still	O
guarantees	O
classifier	Metric
consistency	Metric
under	O
any	O
chosen	O
task	Method
weighting	Method
scheme	Method
as	O
long	O
as	O
weights	O
are	O
assigned	O
positive	O
values	O
.	O

From	O
the	O
results	O
provided	O
in	O
Table	O
[	O
reference	O
]	O
,	O
we	O
find	O
that	O
by	O
using	O
a	O
task	Method
weighting	Method
scheme	Method
that	O
also	O
takes	O
label	O
imbalances	O
into	O
account	O
,	O
we	O
can	O
further	O
improve	O
the	O
performance	O
of	O
CORAL	Method
-	O
CNNs	O
across	O
all	O
four	O
datasets	O
.	O

section	O
:	O
Conclusions	O
In	O
this	O
paper	O
,	O
we	O
developed	O
the	O
CORAL	Method
framework	O
for	O
ordinal	Task
regression	Task
via	O
extended	O
binary	Method
classification	Method
with	O
theoretical	O
guarantees	O
for	O
classifier	Metric
consistency	Metric
.	O

Moreover	O
,	O
we	O
proved	O
classifier	O
consistency	O
without	O
requiring	O
rank	O
-	O
or	O
training	Method
label	Method
-	Method
dependent	Method
weighting	Method
schemes	Method
,	O
which	O
permits	O
straightforward	O
implementations	O
and	O
efficient	O
model	Method
training	Method
.	O

Furthermore	O
,	O
the	O
theoretical	Metric
generalization	Metric
bounds	Metric
assure	O
that	O
if	O
the	O
binary	Task
tasks	Task
generalize	O
well	O
,	O
then	O
the	O
final	O
rank	Task
prediction	Task
also	O
generalizes	O
well	O
.	O

We	O
also	O
showed	O
that	O
CORAL	Method
could	O
be	O
readily	O
implemented	O
to	O
extend	O
CNNs	Method
for	O
ordinal	Task
regression	Task
tasks	Task
and	O
evaluated	O
it	O
empirically	O
on	O
four	O
large	O
image	O
databases	O
for	O
predicting	O
the	O
apparent	Task
age	Task
from	O
face	O
images	O
.	O

The	O
results	O
unequivocally	O
showed	O
that	O
the	O
guaranteed	O
classifier	Metric
consistency	Metric
via	O
CORAL	Method
substantially	O
improved	O
the	O
predictive	Metric
performance	Metric
of	O
CNNs	Method
for	O
age	Task
estimation	Task
.	O

While	O
we	O
evaluated	O
the	O
CORAL	Method
framework	O
in	O
an	O
end	Method
-	Method
to	Method
-	Method
end	Method
learning	Method
approach	Method
using	O
CNNs	Method
for	O
age	Task
estimation	Task
,	O
our	O
method	O
can	O
be	O
readily	O
generalized	O
to	O
other	O
ordinal	Task
regression	Task
problems	Task
and	O
different	O
types	O
of	O
neural	Method
network	Method
architectures	Method
,	O
including	O
multilayer	Method
perceptrons	Method
and	O
recurrent	Method
neural	Method
networks	Method
.	O

section	O
:	O
Acknowledgements	O
Support	O
for	O
this	O
research	O
was	O
provided	O
by	O
the	O
Office	O
of	O
the	O
Vice	O
Chancellor	O
for	O
Research	O
and	O
Graduate	O
Education	O
at	O
the	O
University	O
of	O
Wisconsin	O
-	O
Madison	O
with	O
funding	O
from	O
the	O
Wisconsin	O
Alumni	O
Research	O
Foundation	O
.	O

Also	O
,	O
we	O
thank	O
the	O
NVIDIA	O
Corporation	O
for	O
a	O
generous	O
donation	O
via	O
an	O
NVIDIA	O
GPU	O
grant	O
to	O
support	O
this	O
study	O
.	O

bibliography	O
:	O
References	O
