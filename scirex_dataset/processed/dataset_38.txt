document	O
:	O
Image	Task
-	Task
to	Task
-	Task
Image	Task
Translation	Task
with	O
Conditional	Method
Adversarial	Method
Networks	Method
We	O
investigate	O
conditional	Method
adversarial	Method
networks	Method
as	O
a	O
general	O
-	O
purpose	O
solution	O
to	O
image	Task
-	Task
to	Task
-	Task
image	Task
translation	Task
problems	Task
.	O

These	O
networks	O
not	O
only	O
learn	O
the	O
mapping	O
from	O
input	O
image	O
to	O
output	O
image	O
,	O
but	O
also	O
learn	O
a	O
loss	O
function	O
to	O
train	O
this	O
mapping	O
.	O

This	O
makes	O
it	O
possible	O
to	O
apply	O
the	O
same	O
generic	O
approach	O
to	O
problems	O
that	O
traditionally	O
would	O
require	O
very	O
different	O
loss	Method
formulations	Method
.	O

We	O
demonstrate	O
that	O
this	O
approach	O
is	O
effective	O
at	O
synthesizing	Task
photos	Task
from	O
label	Method
maps	Method
,	O
reconstructing	O
objects	O
from	O
edge	O
maps	O
,	O
and	O
colorizing	O
images	O
,	O
among	O
other	O
tasks	O
.	O

Indeed	O
,	O
since	O
the	O
release	O
of	O
the	O
pix2pix	Method
software	O
associated	O
with	O
this	O
paper	O
,	O
a	O
large	O
number	O
of	O
internet	O
users	O
(	O
many	O
of	O
them	O
artists	O
)	O
have	O
posted	O
their	O
own	O
experiments	O
with	O
our	O
system	O
,	O
further	O
demonstrating	O
its	O
wide	O
applicability	O
and	O
ease	O
of	O
adoption	O
without	O
the	O
need	O
for	O
parameter	Method
tweaking	Method
.	O

As	O
a	O
community	O
,	O
we	O
no	O
longer	O
hand	O
-	O
engineer	O
our	O
mapping	Method
functions	Method
,	O
and	O
this	O
work	O
suggests	O
we	O
can	O
achieve	O
reasonable	O
results	O
without	O
hand	O
-	O
engineering	O
our	O
loss	Method
functions	Method
either	O
.	O

section	O
:	O
Introduction	O
Many	O
problems	O
in	O
image	Task
processing	Task
,	O
computer	Task
graphics	Task
,	O
and	O
computer	Task
vision	Task
can	O
be	O
posed	O
as	O
“	O
translating	O
”	O
an	O
input	O
image	O
into	O
a	O
corresponding	O
output	O
image	O
.	O

Just	O
as	O
a	O
concept	O
may	O
be	O
expressed	O
in	O
either	O
English	O
or	O
French	O
,	O
a	O
scene	O
may	O
be	O
rendered	O
as	O
an	O
RGB	O
image	O
,	O
a	O
gradient	O
field	O
,	O
an	O
edge	O
map	O
,	O
a	O
semantic	O
label	O
map	O
,	O
etc	O
.	O

In	O
analogy	O
to	O
automatic	Task
language	Task
translation	Task
,	O
we	O
define	O
automatic	Task
image	Task
-	Task
to	Task
-	Task
image	Task
translation	Task
as	O
the	O
task	O
of	O
translating	O
one	O
possible	O
representation	Task
of	Task
a	Task
scene	Task
into	O
another	O
,	O
given	O
sufficient	O
training	O
data	O
(	O
see	O
Figure	O
[	O
reference	O
]	O
)	O
.	O

Traditionally	O
,	O
each	O
of	O
these	O
tasks	O
has	O
been	O
tackled	O
with	O
separate	O
,	O
special	O
-	O
purpose	O
machinery	O
(	O
e.g.	O
,	O
)	O
,	O
despite	O
the	O
fact	O
that	O
the	O
setting	O
is	O
always	O
the	O
same	O
:	O
predict	O
pixels	O
from	O
pixels	O
.	O

Our	O
goal	O
in	O
this	O
paper	O
is	O
to	O
develop	O
a	O
common	O
framework	O
for	O
all	O
these	O
problems	O
.	O

The	O
community	O
has	O
already	O
taken	O
significant	O
steps	O
in	O
this	O
direction	O
,	O
with	O
convolutional	Method
neural	Method
nets	Method
(	O
CNNs	Method
)	O
becoming	O
the	O
common	O
workhorse	O
behind	O
a	O
wide	O
variety	O
of	O
image	Task
prediction	Task
problems	Task
.	O

CNNs	Method
learn	O
to	O
minimize	O
a	O
loss	O
function	O
–	O
an	O
objective	O
that	O
scores	O
the	O
quality	O
of	O
results	O
–	O
and	O
although	O
the	O
learning	Method
process	Method
is	O
automatic	O
,	O
a	O
lot	O
of	O
manual	O
effort	O
still	O
goes	O
into	O
designing	O
effective	O
losses	O
.	O

In	O
other	O
words	O
,	O
we	O
still	O
have	O
to	O
tell	O
the	O
CNN	O
what	O
we	O
wish	O
it	O
to	O
minimize	O
.	O

But	O
,	O
just	O
like	O
King	O
Midas	O
,	O
we	O
must	O
be	O
careful	O
what	O
we	O
wish	O
for	O
!	O

If	O
we	O
take	O
a	O
naive	O
approach	O
and	O
ask	O
the	O
CNN	Method
to	O
minimize	O
the	O
Euclidean	O
distance	O
between	O
predicted	O
and	O
ground	O
truth	O
pixels	O
,	O
it	O
will	O
tend	O
to	O
produce	O
blurry	O
results	O
.	O

This	O
is	O
because	O
Euclidean	O
distance	O
is	O
minimized	O
by	O
averaging	O
all	O
plausible	O
outputs	O
,	O
which	O
causes	O
blurring	O
.	O

Coming	O
up	O
with	O
loss	Method
functions	Method
that	O
force	O
the	O
CNN	Method
to	O
do	O
what	O
we	O
really	O
want	O
–	O
e.g.	O
,	O
output	O
sharp	O
,	O
realistic	O
images	O
–	O
is	O
an	O
open	O
problem	O
and	O
generally	O
requires	O
expert	O
knowledge	O
.	O

It	O
would	O
be	O
highly	O
desirable	O
if	O
we	O
could	O
instead	O
specify	O
only	O
a	O
high	O
-	O
level	O
goal	O
,	O
like	O
“	O
make	O
the	O
output	O
indistinguishable	O
from	O
reality	O
”	O
,	O
and	O
then	O
automatically	O
learn	O
a	O
loss	Method
function	Method
appropriate	O
for	O
satisfying	O
this	O
goal	O
.	O

Fortunately	O
,	O
this	O
is	O
exactly	O
what	O
is	O
done	O
by	O
the	O
recently	O
proposed	O
Generative	Method
Adversarial	Method
Networks	Method
(	O
GANs	Method
)	O
.	O

GANs	Method
learn	O
a	O
loss	O
that	O
tries	O
to	O
classify	O
if	O
the	O
output	O
image	O
is	O
real	O
or	O
fake	O
,	O
while	O
simultaneously	O
training	O
a	O
generative	Method
model	Method
to	O
minimize	O
this	O
loss	O
.	O

Blurry	O
images	O
will	O
not	O
be	O
tolerated	O
since	O
they	O
look	O
obviously	O
fake	O
.	O

Because	O
GANs	Method
learn	O
a	O
loss	Method
that	O
adapts	O
to	O
the	O
data	O
,	O
they	O
can	O
be	O
applied	O
to	O
a	O
multitude	O
of	O
tasks	O
that	O
traditionally	O
would	O
require	O
very	O
different	O
kinds	O
of	O
loss	O
functions	O
.	O

In	O
this	O
paper	O
,	O
we	O
explore	O
GANs	Method
in	O
the	O
conditional	Task
setting	Task
.	O

Just	O
as	O
GANs	Method
learn	O
a	O
generative	Method
model	Method
of	Method
data	Method
,	O
conditional	Method
GANs	Method
(	O
cGANs	Method
)	O
learn	O
a	O
conditional	Method
generative	Method
model	Method
.	O

This	O
makes	O
cGANs	Method
suitable	O
for	O
image	Task
-	Task
to	Task
-	Task
image	Task
translation	Task
tasks	Task
,	O
where	O
we	O
condition	O
on	O
an	O
input	O
image	O
and	O
generate	O
a	O
corresponding	O
output	O
image	O
.	O

GANs	Method
have	O
been	O
vigorously	O
studied	O
in	O
the	O
last	O
two	O
years	O
and	O
many	O
of	O
the	O
techniques	O
we	O
explore	O
in	O
this	O
paper	O
have	O
been	O
previously	O
proposed	O
.	O

Nonetheless	O
,	O
earlier	O
papers	O
have	O
focused	O
on	O
specific	O
applications	O
,	O
and	O
it	O
has	O
remained	O
unclear	O
how	O
effective	O
image	O
-	O
conditional	O
GANs	Method
can	O
be	O
as	O
a	O
general	O
-	O
purpose	O
solution	O
for	O
image	Task
-	Task
to	Task
-	Task
image	Task
translation	Task
.	O

Our	O
primary	O
contribution	O
is	O
to	O
demonstrate	O
that	O
on	O
a	O
wide	O
variety	O
of	O
problems	O
,	O
conditional	Method
GANs	Method
produce	O
reasonable	O
results	O
.	O

Our	O
second	O
contribution	O
is	O
to	O
present	O
a	O
simple	O
framework	O
sufficient	O
to	O
achieve	O
good	O
results	O
,	O
and	O
to	O
analyze	O
the	O
effects	O
of	O
several	O
important	O
architectural	O
choices	O
.	O

Code	O
is	O
available	O
at	O
https:	O
//	O
github.com	O
/	O
phillipi	O
/	O
pix2pix	Method
.	O

section	O
:	O
Related	O
work	O
Structured	Method
losses	Method
for	O
image	Task
modeling	Task
Image	Task
-	Task
to	Task
-	Task
image	Task
translation	Task
problems	Task
are	O
often	O
formulated	O
as	O
per	Task
-	Task
pixel	Task
classification	Task
or	Task
regression	Task
(	O
e.g.	O
,	O
)	O
.	O

These	O
formulations	O
treat	O
the	O
output	O
space	O
as	O
“	O
unstructured	O
”	O
in	O
the	O
sense	O
that	O
each	O
output	O
pixel	O
is	O
considered	O
conditionally	O
independent	O
from	O
all	O
others	O
given	O
the	O
input	O
image	O
.	O

Conditional	O
GANs	Method
instead	O
learn	O
a	O
structured	O
loss	O
.	O

Structured	O
losses	O
penalize	O
the	O
joint	O
configuration	O
of	O
the	O
output	O
.	O

A	O
large	O
body	O
of	O
literature	O
has	O
considered	O
losses	O
of	O
this	O
kind	O
,	O
with	O
methods	O
including	O
conditional	Method
random	Method
fields	Method
,	O
the	O
SSIM	Method
metric	Method
,	O
feature	Method
matching	Method
,	O
nonparametric	Method
losses	Method
,	O
the	O
convolutional	Method
pseudo	Method
-	Method
prior	Method
,	O
and	O
losses	Method
based	O
on	O
matching	Method
covariance	Method
statistics	Method
.	O

The	O
conditional	O
GAN	Method
is	O
different	O
in	O
that	O
the	O
loss	O
is	O
learned	O
,	O
and	O
can	O
,	O
in	O
theory	O
,	O
penalize	O
any	O
possible	O
structure	O
that	O
differs	O
between	O
output	O
and	O
target	O
.	O

Conditional	O
GANs	Method
We	O
are	O
not	O
the	O
first	O
to	O
apply	O
GANs	Method
in	O
the	O
conditional	O
setting	O
.	O

Prior	O
and	O
concurrent	O
works	O
have	O
conditioned	O
GANs	Method
on	O
discrete	O
labels	O
,	O
text	O
,	O
and	O
,	O
indeed	O
,	O
images	O
.	O

The	O
image	Method
-	Method
conditional	Method
models	Method
have	O
tackled	O
image	Task
prediction	Task
from	O
a	O
normal	Task
map	Task
,	O
future	Task
frame	Task
prediction	Task
,	O
product	Task
photo	Task
generation	Task
,	O
and	O
image	Task
generation	Task
from	O
sparse	O
annotations	O
(	O
c.f	O
.	O

for	O
an	O
autoregressive	Method
approach	Method
to	O
the	O
same	O
problem	O
)	O
.	O

Several	O
other	O
papers	O
have	O
also	O
used	O
GANs	Method
for	O
image	Task
-	Task
to	Task
-	Task
image	Task
mappings	Task
,	O
but	O
only	O
applied	O
the	O
GAN	Method
unconditionally	O
,	O
relying	O
on	O
other	O
terms	O
(	O
such	O
as	O
L2	Method
regression	Method
)	O
to	O
force	O
the	O
output	O
to	O
be	O
conditioned	O
on	O
the	O
input	O
.	O

These	O
papers	O
have	O
achieved	O
impressive	O
results	O
on	O
inpainting	Task
,	O
future	Task
state	Task
prediction	Task
,	O
image	Task
manipulation	Task
guided	O
by	O
user	O
constraints	O
,	O
style	Task
transfer	Task
,	O
and	O
superresolution	Task
.	O

Each	O
of	O
the	O
methods	O
was	O
tailored	O
for	O
a	O
specific	O
application	O
.	O

Our	O
framework	O
differs	O
in	O
that	O
nothing	O
is	O
application	O
-	O
specific	O
.	O

This	O
makes	O
our	O
setup	O
considerably	O
simpler	O
than	O
most	O
others	O
.	O

Our	O
method	O
also	O
differs	O
from	O
the	O
prior	O
works	O
in	O
several	O
architectural	O
choices	O
for	O
the	O
generator	Method
and	Method
discriminator	Method
.	O

Unlike	O
past	O
work	O
,	O
for	O
our	O
generator	O
we	O
use	O
a	O
“	Method
U	Method
-	Method
Net”	Method
-	Method
based	Method
architecture	Method
,	O
and	O
for	O
our	O
discriminator	Method
we	O
use	O
a	O
convolutional	Method
“	Method
PatchGAN	Method
”	Method
classifier	Method
,	O
which	O
only	O
penalizes	O
structure	O
at	O
the	O
scale	O
of	O
image	O
patches	O
.	O

A	O
similar	O
PatchGAN	Method
architecture	Method
was	O
previously	O
proposed	O
in	O
to	O
capture	O
local	O
style	O
statistics	O
.	O

Here	O
we	O
show	O
that	O
this	O
approach	O
is	O
effective	O
on	O
a	O
wider	O
range	O
of	O
problems	O
,	O
and	O
we	O
investigate	O
the	O
effect	O
of	O
changing	O
the	O
patch	O
size	O
.	O

section	O
:	O
Method	O
GANs	Method
are	O
generative	Method
models	Method
that	O
learn	O
a	O
mapping	O
from	O
random	O
noise	O
vector	O
to	O
output	O
image	O
,	O
.	O

In	O
contrast	O
,	O
conditional	Method
GANs	Method
learn	O
a	O
mapping	O
from	O
observed	O
image	O
and	O
random	O
noise	O
vector	O
,	O
to	O
,	O
.	O

The	O
generator	O
is	O
trained	O
to	O
produce	O
outputs	O
that	O
can	O
not	O
be	O
distinguished	O
from	O
“	O
real	O
”	O
images	O
by	O
an	O
adversarially	O
trained	O
discriminator	Method
,	O
,	O
which	O
is	O
trained	O
to	O
do	O
as	O
well	O
as	O
possible	O
at	O
detecting	O
the	O
generator	O
’s	O
“	O
fakes	O
”	O
.	O

This	O
training	O
procedure	O
is	O
diagrammed	O
in	O
Figure	O
[	O
reference	O
]	O
.	O

subsection	O
:	O
Objective	O
The	O
objective	O
of	O
a	O
conditional	O
GAN	Method
can	O
be	O
expressed	O
as	O
where	O
tries	O
to	O
minimize	O
this	O
objective	O
against	O
an	O
adversarial	O
that	O
tries	O
to	O
maximize	O
it	O
,	O
i.e.	O
.	O

To	O
test	O
the	O
importance	O
of	O
conditioning	O
the	O
discriminator	O
,	O
we	O
also	O
compare	O
to	O
an	O
unconditional	Method
variant	Method
in	O
which	O
the	O
discriminator	O
does	O
not	O
observe	O
:	O
Previous	O
approaches	O
have	O
found	O
it	O
beneficial	O
to	O
mix	O
the	O
GAN	Method
objective	O
with	O
a	O
more	O
traditional	O
loss	Metric
,	O
such	O
as	O
L2	Method
distance	Method
.	O

The	O
discriminator	O
’s	O
job	O
remains	O
unchanged	O
,	O
but	O
the	O
generator	O
is	O
tasked	O
to	O
not	O
only	O
fool	O
the	O
discriminator	Method
but	O
also	O
to	O
be	O
near	O
the	O
ground	O
truth	O
output	O
in	O
an	O
L2	O
sense	O
.	O

We	O
also	O
explore	O
this	O
option	O
,	O
using	O
L1	O
distance	O
rather	O
than	O
L2	O
as	O
L1	O
encourages	O
less	O
blurring	O
:	O
Our	O
final	O
objective	O
is	O
Without	O
,	O
the	O
net	O
could	O
still	O
learn	O
a	O
mapping	O
from	O
to	O
,	O
but	O
would	O
produce	O
deterministic	O
outputs	O
,	O
and	O
therefore	O
fail	O
to	O
match	O
any	O
distribution	O
other	O
than	O
a	O
delta	O
function	O
.	O

Past	O
conditional	Method
GANs	Method
have	O
acknowledged	O
this	O
and	O
provided	O
Gaussian	O
noise	O
as	O
an	O
input	O
to	O
the	O
generator	Method
,	O
in	O
addition	O
to	O
(	O
e.g.	O
,	O
)	O
.	O

In	O
initial	O
experiments	O
,	O
we	O
did	O
not	O
find	O
this	O
strategy	O
effective	O
–	O
the	O
generator	Method
simply	O
learned	O
to	O
ignore	O
the	O
noise	O
–	O
which	O
is	O
consistent	O
with	O
Mathieu	O
et	O
al	O
.	O

.	O

Instead	O
,	O
for	O
our	O
final	O
models	O
,	O
we	O
provide	O
noise	O
only	O
in	O
the	O
form	O
of	O
dropout	Method
,	O
applied	O
on	O
several	O
layers	O
of	O
our	O
generator	O
at	O
both	O
training	O
and	O
test	O
time	O
.	O

Despite	O
the	O
dropout	O
noise	O
,	O
we	O
observe	O
only	O
minor	O
stochasticity	O
in	O
the	O
output	O
of	O
our	O
nets	O
.	O

Designing	O
conditional	Method
GANs	Method
that	O
produce	O
highly	O
stochastic	O
output	O
,	O
and	O
thereby	O
capture	O
the	O
full	O
entropy	O
of	O
the	O
conditional	Method
distributions	Method
they	O
model	O
,	O
is	O
an	O
important	O
question	O
left	O
open	O
by	O
the	O
present	O
work	O
.	O

subsection	O
:	O
Network	Method
architectures	Method
We	O
adapt	O
our	O
generator	Method
and	Method
discriminator	Method
architectures	Method
from	O
those	O
in	O
.	O

Both	O
generator	Method
and	O
discriminator	Method
use	O
modules	O
of	O
the	O
form	O
convolution	Method
-	Method
BatchNorm	Method
-	Method
ReLu	Method
.	O

Details	O
of	O
the	O
architecture	O
are	O
provided	O
in	O
the	O
supplemental	O
materials	O
online	O
,	O
with	O
key	O
features	O
discussed	O
below	O
.	O

subsubsection	O
:	O
Generator	Method
with	O
skips	O
A	O
defining	O
feature	O
of	O
image	Task
-	Task
to	Task
-	Task
image	Task
translation	Task
problems	Task
is	O
that	O
they	O
map	O
a	O
high	O
resolution	O
input	O
grid	O
to	O
a	O
high	O
resolution	O
output	O
grid	O
.	O

In	O
addition	O
,	O
for	O
the	O
problems	O
we	O
consider	O
,	O
the	O
input	O
and	O
output	O
differ	O
in	O
surface	O
appearance	O
,	O
but	O
both	O
are	O
renderings	O
of	O
the	O
same	O
underlying	O
structure	O
.	O

Therefore	O
,	O
structure	O
in	O
the	O
input	O
is	O
roughly	O
aligned	O
with	O
structure	O
in	O
the	O
output	O
.	O

We	O
design	O
the	O
generator	Method
architecture	Method
around	O
these	O
considerations	O
.	O

Many	O
previous	O
solutions	O
to	O
problems	O
in	O
this	O
area	O
have	O
used	O
an	O
encoder	Method
-	Method
decoder	Method
network	Method
.	O

In	O
such	O
a	O
network	O
,	O
the	O
input	O
is	O
passed	O
through	O
a	O
series	O
of	O
layers	O
that	O
progressively	O
downsample	O
,	O
until	O
a	O
bottleneck	O
layer	O
,	O
at	O
which	O
point	O
the	O
process	O
is	O
reversed	O
.	O

Such	O
a	O
network	O
requires	O
that	O
all	O
information	O
flow	O
pass	O
through	O
all	O
the	O
layers	O
,	O
including	O
the	O
bottleneck	O
.	O

For	O
many	O
image	Task
translation	Task
problems	Task
,	O
there	O
is	O
a	O
great	O
deal	O
of	O
low	O
-	O
level	O
information	O
shared	O
between	O
the	O
input	O
and	O
output	O
,	O
and	O
it	O
would	O
be	O
desirable	O
to	O
shuttle	O
this	O
information	O
directly	O
across	O
the	O
net	O
.	O

For	O
example	O
,	O
in	O
the	O
case	O
of	O
image	Task
colorization	Task
,	O
the	O
input	O
and	O
output	O
share	O
the	O
location	O
of	O
prominent	O
edges	O
.	O

To	O
give	O
the	O
generator	O
a	O
means	O
to	O
circumvent	O
the	O
bottleneck	O
for	O
information	O
like	O
this	O
,	O
we	O
add	O
skip	O
connections	O
,	O
following	O
the	O
general	O
shape	O
of	O
a	O
“	O
U	Method
-	Method
Net	Method
”	O
.	O

Specifically	O
,	O
we	O
add	O
skip	O
connections	O
between	O
each	O
layer	O
and	O
layer	O
,	O
where	O
is	O
the	O
total	O
number	O
of	O
layers	O
.	O

Each	O
skip	Method
connection	Method
simply	O
concatenates	O
all	O
channels	O
at	O
layer	O
with	O
those	O
at	O
layer	O
.	O

subsubsection	O
:	O
Markovian	Method
discriminator	Method
(	O
PatchGAN	Method
)	O
It	O
is	O
well	O
known	O
that	O
the	O
L2	O
loss	O
–	O
and	O
L1	O
,	O
see	O
Figure	O
[	O
reference	O
]	O
–	O
produces	O
blurry	O
results	O
on	O
image	Task
generation	Task
problems	Task
.	O

Although	O
these	O
losses	O
fail	O
to	O
encourage	O
high	O
-	O
frequency	O
crispness	O
,	O
in	O
many	O
cases	O
they	O
nonetheless	O
accurately	O
capture	O
the	O
low	O
frequencies	O
.	O

For	O
problems	O
where	O
this	O
is	O
the	O
case	O
,	O
we	O
do	O
not	O
need	O
an	O
entirely	O
new	O
framework	O
to	O
enforce	O
correctness	O
at	O
the	O
low	O
frequencies	O
.	O

L1	O
will	O
already	O
do	O
.	O

This	O
motivates	O
restricting	O
the	O
GAN	Method
discriminator	O
to	O
only	O
model	O
high	O
-	O
frequency	O
structure	O
,	O
relying	O
on	O
an	O
L1	Method
term	Method
to	O
force	O
low	O
-	O
frequency	O
correctness	O
(	O
Eqn	O
.	O

[	O
reference	O
]	O
)	O
.	O

In	O
order	O
to	O
model	O
high	O
-	O
frequencies	O
,	O
it	O
is	O
sufficient	O
to	O
restrict	O
our	O
attention	O
to	O
the	O
structure	O
in	O
local	O
image	O
patches	O
.	O

Therefore	O
,	O
we	O
design	O
a	O
discriminator	Method
architecture	Method
–	O
which	O
we	O
term	O
a	O
Patch	Method
GAN	Method
–	O
that	O
only	O
penalizes	O
structure	O
at	O
the	O
scale	O
of	O
patches	O
.	O

This	O
discriminator	O
tries	O
to	O
classify	O
if	O
each	O
patch	O
in	O
an	O
image	O
is	O
real	O
or	O
fake	O
.	O

We	O
run	O
this	O
discriminator	O
convolutionally	O
across	O
the	O
image	O
,	O
averaging	O
all	O
responses	O
to	O
provide	O
the	O
ultimate	O
output	O
of	O
.	O

In	O
Section	O
[	O
reference	O
]	O
,	O
we	O
demonstrate	O
that	O
can	O
be	O
much	O
smaller	O
than	O
the	O
full	O
size	O
of	O
the	O
image	O
and	O
still	O
produce	O
high	O
quality	O
results	O
.	O

This	O
is	O
advantageous	O
because	O
a	O
smaller	O
PatchGAN	O
has	O
fewer	O
parameters	O
,	O
runs	O
faster	O
,	O
and	O
can	O
be	O
applied	O
to	O
arbitrarily	O
large	O
images	O
.	O

Such	O
a	O
discriminator	Method
effectively	O
models	O
the	O
image	O
as	O
a	O
Markov	Method
random	Method
field	Method
,	O
assuming	O
independence	O
between	O
pixels	O
separated	O
by	O
more	O
than	O
a	O
patch	O
diameter	O
.	O

This	O
connection	O
was	O
previously	O
explored	O
in	O
,	O
and	O
is	O
also	O
the	O
common	O
assumption	O
in	O
models	O
of	O
texture	O
and	O
style	O
.	O

Therefore	O
,	O
our	O
PatchGAN	Method
can	O
be	O
understood	O
as	O
a	O
form	O
of	O
texture	Task
/	Task
style	Task
loss	Task
.	O

subsection	O
:	O
Optimization	Task
and	O
inference	Task
To	O
optimize	O
our	O
networks	O
,	O
we	O
follow	O
the	O
standard	O
approach	O
from	O
:	O
we	O
alternate	O
between	O
one	O
gradient	Method
descent	Method
step	Method
on	O
,	O
then	O
one	O
step	O
on	O
.	O

As	O
suggested	O
in	O
the	O
original	O
GAN	Method
paper	O
,	O
rather	O
than	O
training	O
to	O
minimize	O
,	O
we	O
instead	O
train	O
to	O
maximize	O
.	O

In	O
addition	O
,	O
we	O
divide	O
the	O
objective	O
by	O
while	O
optimizing	Task
,	O
which	O
slows	O
down	O
the	O
rate	O
at	O
which	O
learns	O
relative	O
to	O
.	O

We	O
use	O
minibatch	Method
SGD	Method
and	O
apply	O
the	O
Adam	Method
solver	Method
,	O
with	O
a	O
learning	Metric
rate	Metric
of	O
,	O
and	O
momentum	O
parameters	O
,	O
.	O

At	O
inference	O
time	O
,	O
we	O
run	O
the	O
generator	Method
net	Method
in	O
exactly	O
the	O
same	O
manner	O
as	O
during	O
the	O
training	O
phase	O
.	O

This	O
differs	O
from	O
the	O
usual	O
protocol	O
in	O
that	O
we	O
apply	O
dropout	O
at	O
test	O
time	O
,	O
and	O
we	O
apply	O
batch	Method
normalization	Method
using	O
the	O
statistics	O
of	O
the	O
test	O
batch	O
,	O
rather	O
than	O
aggregated	O
statistics	O
of	O
the	O
training	O
batch	O
.	O

This	O
approach	O
to	O
batch	Task
normalization	Task
,	O
when	O
the	O
batch	O
size	O
is	O
set	O
to	O
1	O
,	O
has	O
been	O
termed	O
“	O
instance	Method
normalization	Method
”	O
and	O
has	O
been	O
demonstrated	O
to	O
be	O
effective	O
at	O
image	Task
generation	Task
tasks	Task
.	O

In	O
our	O
experiments	O
,	O
we	O
use	O
batch	O
sizes	O
between	O
1	O
and	O
10	O
depending	O
on	O
the	O
experiment	O
.	O

section	O
:	O
Experiments	O
To	O
explore	O
the	O
generality	O
of	O
conditional	Method
GANs	Method
,	O
we	O
test	O
the	O
method	O
on	O
a	O
variety	O
of	O
tasks	O
and	O
datasets	O
,	O
including	O
both	O
graphics	Task
tasks	Task
,	O
like	O
photo	Task
generation	Task
,	O
and	O
vision	Task
tasks	Task
,	O
like	O
semantic	Task
segmentation	Task
:	O
Semantic	O
labels↔photo	O
,	O
trained	O
on	O
the	O
Cityscapes	Material
dataset	Material
.	O

Architectural	O
labels→photo	O
,	O
trained	O
on	O
CMP	Method
Facades	Method
.	O

Map↔aerial	Material
photo	Material
,	O
trained	O
on	O
data	O
scraped	O
from	O
Google	O
Maps	O
.	O

BW→color	O
photos	O
,	O
trained	O
on	O
.	O

Edges→photo	O
,	O
trained	O
on	O
data	O
from	O
and	O
;	O
binary	O
edges	O
generated	O
using	O
the	O
HED	Method
edge	Method
detector	Method
plus	O
postprocessing	Method
.	O

Sketch→photo	Method
:	O
tests	O
edges	Method
photo	Method
models	Method
on	O
human	O
-	O
drawn	O
sketches	O
from	O
.	O

Day→night	O
,	O
trained	O
on	O
.	O

Thermal→color	O
photos	O
,	O
trained	O
on	O
data	O
from	O
.	O

Photo	O
with	O
missing	O
pixels→inpainted	O
photo	O
,	O
trained	O
on	O
Paris	O
StreetView	O
from	O
.	O

Details	O
of	O
training	O
on	O
each	O
of	O
these	O
datasets	O
are	O
provided	O
in	O
the	O
supplemental	O
materials	O
online	O
.	O

In	O
all	O
cases	O
,	O
the	O
input	O
and	O
output	O
are	O
simply	O
1	O
-	O
3	O
channel	O
images	O
.	O

Qualitative	O
results	O
are	O
shown	O
in	O
Figures	O
[	O
reference	O
]	O
,	O
[	O
reference	O
]	O
,	O
[	O
reference	O
]	O
,	O
[	O
reference	O
]	O
,	O
[	O
reference	O
]	O
,	O
[	O
reference	O
]	O
,	O
[	O
reference	O
]	O
,	O
[	O
reference	O
]	O
,	O
[	O
reference	O
]	O
,	O
[	O
reference	O
]	O
,	O
[	O
reference	O
]	O
,	O
[	O
reference	O
]	O
.	O

Several	O
failure	O
cases	O
are	O
highlighted	O
in	O
Figure	O
[	O
reference	O
]	O
.	O

More	O
comprehensive	O
results	O
are	O
available	O
at	O
https:	O
//	O
phillipi.github.io	O
/	O
pix2pix	Method
/	O
.	O

Data	O
requirements	O
and	O
speed	O
We	O
note	O
that	O
decent	O
results	O
can	O
often	O
be	O
obtained	O
even	O
on	O
small	O
datasets	O
.	O

Our	O
facade	O
training	O
set	O
consists	O
of	O
just	O
400	O
images	O
(	O
see	O
results	O
in	O
Figure	O
[	O
reference	O
]	O
)	O
,	O
and	O
the	O
day	O
to	O
night	O
training	O
set	O
consists	O
of	O
only	O
91	O
unique	O
webcams	O
(	O
see	O
results	O
in	O
Figure	O
[	O
reference	O
]	O
)	O
.	O

On	O
datasets	O
of	O
this	O
size	O
,	O
training	Task
can	O
be	O
very	O
fast	O
:	O
for	O
example	O
,	O
the	O
results	O
shown	O
in	O
Figure	O
[	O
reference	O
]	O
took	O
less	O
than	O
two	O
hours	O
of	O
training	O
on	O
a	O
single	O
Pascal	O
Titan	O
X	O
GPU	O
.	O

At	O
test	O
time	O
,	O
all	O
models	O
run	O
in	O
well	O
under	O
a	O
second	O
on	O
this	O
GPU	O
.	O

subsection	O
:	O
Evaluation	Metric
metrics	Metric
Evaluating	O
the	O
quality	Metric
of	O
synthesized	O
images	O
is	O
an	O
open	O
and	O
difficult	O
problem	O
.	O

Traditional	O
metrics	O
such	O
as	O
per	Metric
-	Metric
pixel	Metric
mean	Metric
-	Metric
squared	Metric
error	Metric
do	O
not	O
assess	O
joint	O
statistics	O
of	O
the	O
result	O
,	O
and	O
therefore	O
do	O
not	O
measure	O
the	O
very	O
structure	O
that	O
structured	O
losses	O
aim	O
to	O
capture	O
.	O

To	O
more	O
holistically	O
evaluate	O
the	O
visual	Metric
quality	Metric
of	O
our	O
results	O
,	O
we	O
employ	O
two	O
tactics	O
.	O

First	O
,	O
we	O
run	O
“	O
real	O
vs.	O
fake	O
”	O
perceptual	O
studies	O
on	O
Amazon	O
Mechanical	O
Turk	O
(	O
AMT	O
)	O
.	O

For	O
graphics	Task
problems	Task
like	O
colorization	Task
and	O
photo	Task
generation	Task
,	O
plausibility	O
to	O
a	O
human	O
observer	O
is	O
often	O
the	O
ultimate	O
goal	O
.	O

Therefore	O
,	O
we	O
test	O
our	O
map	Task
generation	Task
,	O
aerial	Task
photo	Task
generation	Task
,	O
and	O
image	Task
colorization	Task
using	O
this	O
approach	O
.	O

Second	O
,	O
we	O
measure	O
whether	O
or	O
not	O
our	O
synthesized	O
cityscapes	O
are	O
realistic	O
enough	O
that	O
off	O
-	O
the	O
-	O
shelf	O
recognition	Method
system	Method
can	O
recognize	O
the	O
objects	O
in	O
them	O
.	O

This	O
metric	O
is	O
similar	O
to	O
the	O
“	O
inception	Metric
score	Metric
”	Metric
from	O
,	O
the	O
object	Metric
detection	Metric
evaluation	Metric
in	O
,	O
and	O
the	O
“	O
semantic	Metric
interpretability	Metric
”	Metric
measures	Metric
in	O
and	O
.	O

AMT	Task
perceptual	Task
studies	Task
For	O
our	O
AMT	O
experiments	O
,	O
we	O
followed	O
the	O
protocol	O
from	O
:	O
Turkers	O
were	O
presented	O
with	O
a	O
series	O
of	O
trials	O
that	O
pitted	O
a	O
“	O
real	O
”	O
image	O
against	O
a	O
“	O
fake	O
”	O
image	O
generated	O
by	O
our	O
algorithm	O
.	O

On	O
each	O
trial	O
,	O
each	O
image	O
appeared	O
for	O
1	O
second	O
,	O
after	O
which	O
the	O
images	O
disappeared	O
and	O
Turkers	O
were	O
given	O
unlimited	O
time	O
to	O
respond	O
as	O
to	O
which	O
was	O
fake	O
.	O

The	O
first	O
10	O
images	O
of	O
each	O
session	O
were	O
practice	O
and	O
Turkers	O
were	O
given	O
feedback	O
.	O

No	O
feedback	O
was	O
provided	O
on	O
the	O
40	O
trials	O
of	O
the	O
main	O
experiment	O
.	O

Each	O
session	O
tested	O
just	O
one	O
algorithm	O
at	O
a	O
time	O
,	O
and	O
Turkers	O
were	O
not	O
allowed	O
to	O
complete	O
more	O
than	O
one	O
session	O
.	O

Turkers	O
evaluated	O
each	O
algorithm	O
.	O

Unlike	O
,	O
we	O
did	O
not	O
include	O
vigilance	O
trials	O
.	O

For	O
our	O
colorization	Task
experiments	Task
,	O
the	O
real	O
and	O
fake	O
images	O
were	O
generated	O
from	O
the	O
same	O
grayscale	O
input	O
.	O

For	O
map	Material
aerial	Material
photo	Material
,	O
the	O
real	O
and	O
fake	O
images	O
were	O
not	O
generated	O
from	O
the	O
same	O
input	O
,	O
in	O
order	O
to	O
make	O
the	O
task	O
more	O
difficult	O
and	O
avoid	O
floor	O
-	O
level	O
results	O
.	O

For	O
map	Material
aerial	Material
photo	Material
,	O
we	O
trained	O
on	O
resolution	O
images	O
,	O
but	O
exploited	O
fully	Method
-	Method
convolutional	Method
translation	Method
(	O
described	O
above	O
)	O
to	O
test	O
on	O
images	O
,	O
which	O
were	O
then	O
downsampled	O
and	O
presented	O
to	O
Turkers	O
at	O
resolution	O
.	O

For	O
colorization	Task
,	O
we	O
trained	O
and	O
tested	O
on	O
resolution	O
images	O
and	O
presented	O
the	O
results	O
to	O
Turkers	O
at	O
this	O
same	O
resolution	O
.	O

“	O
FCN	Metric
-	Metric
score	Metric
”	O
While	O
quantitative	Task
evaluation	Task
of	O
generative	Method
models	Method
is	O
known	O
to	O
be	O
challenging	O
,	O
recent	O
works	O
have	O
tried	O
using	O
pre	O
-	O
trained	O
semantic	Method
classifiers	Method
to	O
measure	O
the	O
discriminability	O
of	O
the	O
generated	O
stimuli	O
as	O
a	O
pseudo	Metric
-	Metric
metric	Metric
.	O

The	O
intuition	O
is	O
that	O
if	O
the	O
generated	O
images	O
are	O
realistic	O
,	O
classifiers	Method
trained	O
on	O
real	O
images	O
will	O
be	O
able	O
to	O
classify	O
the	O
synthesized	O
image	O
correctly	O
as	O
well	O
.	O

To	O
this	O
end	O
,	O
we	O
adopt	O
the	O
popular	O
FCN	Method
-	Method
8s	Method
architecture	Method
for	O
semantic	Task
segmentation	Task
,	O
and	O
train	O
it	O
on	O
the	O
cityscapes	Material
dataset	Material
.	O

We	O
then	O
score	O
synthesized	O
photos	O
by	O
the	O
classification	Metric
accuracy	Metric
against	O
the	O
labels	O
these	O
photos	O
were	O
synthesized	O
from	O
.	O

subsection	O
:	O
Analysis	O
of	O
the	O
objective	Metric
function	Metric
Which	O
components	O
of	O
the	O
objective	O
in	O
Eqn	O
.	O

[	O
reference	O
]	O
are	O
important	O
?	O
We	O
run	O
ablation	Task
studies	Task
to	O
isolate	O
the	O
effect	O
of	O
the	O
L1	O
term	O
,	O
the	O
GAN	Method
term	O
,	O
and	O
to	O
compare	O
using	O
a	O
discriminator	Method
conditioned	O
on	O
the	O
input	O
(	O
cGAN	Method
,	O
Eqn	O
.	O

[	O
reference	O
]	O
)	O
against	O
using	O
an	O
unconditional	Method
discriminator	Method
(	O
GAN	Method
,	O
Eqn	O
.	O

[	O
reference	O
]	O
)	O
.	O

Figure	O
[	O
reference	O
]	O
shows	O
the	O
qualitative	O
effects	O
of	O
these	O
variations	O
on	O
two	O
labels	Task
photo	Task
problems	Task
.	O

L1	Method
alone	O
leads	O
to	O
reasonable	O
but	O
blurry	O
results	O
.	O

The	O
cGAN	Method
alone	O
(	O
setting	O
in	O
Eqn	O
.	O

[	O
reference	O
]	O
)	O
gives	O
much	O
sharper	O
results	O
but	O
introduces	O
visual	O
artifacts	O
on	O
certain	O
applications	O
.	O

Adding	O
both	O
terms	O
together	O
(	O
with	O
)	O
reduces	O
these	O
artifacts	O
.	O

We	O
quantify	O
these	O
observations	O
using	O
the	O
FCN	Metric
-	Metric
score	Metric
on	O
the	O
cityscapes	Task
labels	Task
photo	Task
task	Task
(	O
Table	O
[	O
reference	O
]	O
)	O
:	O
the	O
GAN	Method
-	O
based	O
objectives	O
achieve	O
higher	O
scores	O
,	O
indicating	O
that	O
the	O
synthesized	O
images	O
include	O
more	O
recognizable	O
structure	O
.	O

We	O
also	O
test	O
the	O
effect	O
of	O
removing	O
conditioning	O
from	O
the	O
discriminator	Method
(	O
labeled	O
as	O
GAN	Method
)	O
.	O

In	O
this	O
case	O
,	O
the	O
loss	O
does	O
not	O
penalize	O
mismatch	O
between	O
the	O
input	O
and	O
output	O
;	O
it	O
only	O
cares	O
that	O
the	O
output	O
look	O
realistic	O
.	O

This	O
variant	O
results	O
in	O
poor	O
performance	O
;	O
examining	O
the	O
results	O
reveals	O
that	O
the	O
generator	O
collapsed	O
into	O
producing	O
nearly	O
the	O
exact	O
same	O
output	O
regardless	O
of	O
input	O
photograph	O
.	O

Clearly	O
,	O
it	O
is	O
important	O
,	O
in	O
this	O
case	O
,	O
that	O
the	O
loss	Metric
measure	O
the	O
quality	O
of	O
the	O
match	O
between	O
input	O
and	O
output	O
,	O
and	O
indeed	O
cGAN	Method
performs	O
much	O
better	O
than	O
GAN	Method
.	O

Note	O
,	O
however	O
,	O
that	O
adding	O
an	O
L1	O
term	O
also	O
encourages	O
that	O
the	O
output	O
respect	O
the	O
input	O
,	O
since	O
the	O
L1	O
loss	O
penalizes	O
the	O
distance	O
between	O
ground	O
truth	O
outputs	O
,	O
which	O
correctly	O
match	O
the	O
input	O
,	O
and	O
synthesized	O
outputs	O
,	O
which	O
may	O
not	O
.	O

Correspondingly	O
,	O
L1	Method
+	Method
GAN	Method
is	O
also	O
effective	O
at	O
creating	O
realistic	Task
renderings	Task
that	O
respect	O
the	O
input	O
label	O
maps	O
.	O

Combining	O
all	O
terms	O
,	O
L1	O
+	O
cGAN	Method
,	O
performs	O
similarly	O
well	O
.	O

Colorfulness	O
A	O
striking	O
effect	O
of	O
conditional	Method
GANs	Method
is	O
that	O
they	O
produce	O
sharp	O
images	O
,	O
hallucinating	O
spatial	O
structure	O
even	O
where	O
it	O
does	O
not	O
exist	O
in	O
the	O
input	O
label	O
map	O
.	O

One	O
might	O
imagine	O
cGANs	Method
have	O
a	O
similar	O
effect	O
on	O
“	O
sharpening	O
”	O
in	O
the	O
spectral	O
dimension	O
–	O
i.e.	O
making	O
images	O
more	O
colorful	O
.	O

Just	O
as	O
L1	Method
will	O
incentivize	O
a	O
blur	O
when	O
it	O
is	O
uncertain	O
where	O
exactly	O
to	O
locate	O
an	O
edge	O
,	O
it	O
will	O
also	O
incentivize	O
an	O
average	O
,	O
grayish	O
color	O
when	O
it	O
is	O
uncertain	O
which	O
of	O
several	O
plausible	O
color	O
values	O
a	O
pixel	O
should	O
take	O
on	O
.	O

Specially	O
,	O
L1	O
will	O
be	O
minimized	O
by	O
choosing	O
the	O
median	O
of	O
the	O
conditional	O
probability	O
density	O
function	O
over	O
possible	O
colors	O
.	O

An	O
adversarial	Method
loss	Method
,	O
on	O
the	O
other	O
hand	O
,	O
can	O
in	O
principle	O
become	O
aware	O
that	O
grayish	O
outputs	O
are	O
unrealistic	O
,	O
and	O
encourage	O
matching	O
the	O
true	O
color	O
distribution	O
.	O

In	O
Figure	O
[	O
reference	O
]	O
,	O
we	O
investigate	O
whether	O
our	O
cGANs	Method
actually	O
achieve	O
this	O
effect	O
on	O
the	O
Cityscapes	Material
dataset	Material
.	O

The	O
plots	O
show	O
the	O
marginal	O
distributions	O
over	O
output	O
color	O
values	O
in	O
Lab	O
color	O
space	O
.	O

The	O
ground	Metric
truth	Metric
distributions	Metric
are	O
shown	O
with	O
a	O
dotted	O
line	O
.	O

It	O
is	O
apparent	O
that	O
L1	O
leads	O
to	O
a	O
narrower	O
distribution	O
than	O
the	O
ground	O
truth	O
,	O
confirming	O
the	O
hypothesis	O
that	O
L1	O
encourages	O
average	O
,	O
grayish	O
colors	O
.	O

Using	O
a	O
cGAN	Method
,	O
on	O
the	O
other	O
hand	O
,	O
pushes	O
the	O
output	O
distribution	O
closer	O
to	O
the	O
ground	O
truth	O
.	O

subsection	O
:	O
Analysis	O
of	O
the	O
generator	Method
architecture	Method
A	O
U	Method
-	Method
Net	Method
architecture	Method
allows	O
low	O
-	O
level	O
information	O
to	O
shortcut	O
across	O
the	O
network	O
.	O

Does	O
this	O
lead	O
to	O
better	O
results	O
?	O
Figure	O
[	O
reference	O
]	O
and	O
Table	O
[	O
reference	O
]	O
compare	O
the	O
U	Method
-	Method
Net	Method
against	O
an	O
encoder	Method
-	Method
decoder	Method
on	O
cityscape	Task
generation	Task
.	O

The	O
encoder	Method
-	Method
decoder	Method
is	O
created	O
simply	O
by	O
severing	O
the	O
skip	O
connections	O
in	O
the	O
U	O
-	O
Net	O
.	O

The	O
encoder	Method
-	Method
decoder	Method
is	O
unable	O
to	O
learn	O
to	O
generate	O
realistic	O
images	O
in	O
our	O
experiments	O
.	O

The	O
advantages	O
of	O
the	O
U	Method
-	Method
Net	Method
appear	O
not	O
to	O
be	O
specific	O
to	O
conditional	Method
GANs	Method
:	O
when	O
both	O
U	Method
-	Method
Net	Method
and	O
encoder	Method
-	Method
decoder	Method
are	O
trained	O
with	O
an	O
L1	O
loss	O
,	O
the	O
U	Method
-	Method
Net	Method
again	O
achieves	O
the	O
superior	O
results	O
.	O

subsection	O
:	O
From	O
PixelGANs	Method
to	O
PatchGANs	Method
to	O
ImageGANs	Method
We	O
test	O
the	O
effect	O
of	O
varying	O
the	O
patch	O
size	O
of	O
our	O
discriminator	O
receptive	O
fields	O
,	O
from	O
a	O
“	O
PixelGAN	Method
”	O
to	O
a	O
full	O
“	O
ImageGAN	O
”	O
.	O

Figure	O
[	O
reference	O
]	O
shows	O
qualitative	O
results	O
of	O
this	O
analysis	O
and	O
Table	O
[	O
reference	O
]	O
quantifies	O
the	O
effects	O
using	O
the	O
FCN	Metric
-	Metric
score	Metric
.	O

Note	O
that	O
elsewhere	O
in	O
this	O
paper	O
,	O
unless	O
specified	O
,	O
all	O
experiments	O
use	O
PatchGANs	Method
,	O
and	O
for	O
this	O
section	O
all	O
experiments	O
use	O
an	O
L1	O
+	O
cGAN	Method
loss	O
.	O

The	O
PixelGAN	Method
has	O
no	O
effect	O
on	O
spatial	O
sharpness	O
but	O
does	O
increase	O
the	O
colorfulness	O
of	O
the	O
results	O
(	O
quantified	O
in	O
Figure	O
[	O
reference	O
]	O
)	O
.	O

For	O
example	O
,	O
the	O
bus	O
in	O
Figure	O
[	O
reference	O
]	O
is	O
painted	O
gray	O
when	O
the	O
net	O
is	O
trained	O
with	O
an	O
L1	Method
loss	Method
,	O
but	O
becomes	O
red	O
with	O
the	O
PixelGAN	Method
loss	Method
.	O

Color	Method
histogram	Method
matching	Method
is	O
a	O
common	O
problem	O
in	O
image	Task
processing	Task
,	O
and	O
PixelGANs	Method
may	O
be	O
a	O
promising	O
lightweight	O
solution	O
.	O

Using	O
a	O
PatchGAN	Method
is	O
sufficient	O
to	O
promote	O
sharp	O
outputs	O
,	O
and	O
achieves	O
good	O
FCN	Metric
-	Metric
scores	Metric
,	O
but	O
also	O
leads	O
to	O
tiling	O
artifacts	O
.	O

The	O
PatchGAN	Method
alleviates	O
these	O
artifacts	O
and	O
achieves	O
slightly	O
better	O
scores	O
.	O

Scaling	O
beyond	O
this	O
,	O
to	O
the	O
full	O
ImageGAN	Method
,	O
does	O
not	O
appear	O
to	O
improve	O
the	O
visual	Metric
quality	Metric
of	O
the	O
results	O
,	O
and	O
in	O
fact	O
gets	O
a	O
considerably	O
lower	O
FCN	Metric
-	Metric
score	Metric
(	O
Table	O
[	O
reference	O
]	O
)	O
.	O

This	O
may	O
be	O
because	O
the	O
ImageGAN	O
has	O
many	O
more	O
parameters	O
and	O
greater	O
depth	O
than	O
the	O
PatchGAN	Method
,	O
and	O
may	O
be	O
harder	O
to	O
train	O
.	O

Fully	Method
-	Method
convolutional	Method
translation	Method
An	O
advantage	O
of	O
the	O
PatchGAN	Method
is	O
that	O
a	O
fixed	Method
-	Method
size	Method
patch	Method
discriminator	Method
can	O
be	O
applied	O
to	O
arbitrarily	O
large	O
images	O
.	O

We	O
may	O
also	O
apply	O
the	O
generator	Method
convolutionally	Method
,	O
on	O
larger	O
images	O
than	O
those	O
on	O
which	O
it	O
was	O
trained	O
.	O

We	O
test	O
this	O
on	O
the	O
map	Material
aerial	Material
photo	Material
task	O
.	O

After	O
training	O
a	O
generator	O
on	O
images	O
,	O
we	O
test	O
it	O
on	O
images	O
.	O

The	O
results	O
in	O
Figure	O
[	O
reference	O
]	O
demonstrate	O
the	O
effectiveness	O
of	O
this	O
approach	O
.	O

subsection	O
:	O
Perceptual	Metric
validation	Metric
We	O
validate	O
the	O
perceptual	Metric
realism	Metric
of	O
our	O
results	O
on	O
the	O
tasks	O
of	O
map	Material
aerial	Material
photograph	Material
and	O
grayscale	O
color	O
.	O

Results	O
of	O
our	O
AMT	Method
experiment	Method
for	O
map	Task
photo	Task
are	O
given	O
in	O
Table	O
[	O
reference	O
]	O
.	O

The	O
aerial	Material
photos	Material
generated	O
by	O
our	O
method	O
fooled	O
participants	O
on	O
of	O
trials	O
,	O
significantly	O
above	O
the	O
L1	O
baseline	O
,	O
which	O
produces	O
blurry	O
results	O
and	O
nearly	O
never	O
fooled	O
participants	O
.	O

In	O
contrast	O
,	O
in	O
the	O
photo	O
map	O
direction	O
our	O
method	O
only	O
fooled	O
participants	O
on	O
%	O
of	O
trials	O
,	O
and	O
this	O
was	O
not	O
significantly	O
different	O
than	O
the	O
performance	O
of	O
the	O
L1	Method
baseline	Method
(	O
based	O
on	O
bootstrap	Method
test	Method
)	O
.	O

This	O
may	O
be	O
because	O
minor	O
structural	O
errors	O
are	O
more	O
visible	O
in	O
maps	O
,	O
which	O
have	O
rigid	O
geometry	O
,	O
than	O
in	O
aerial	Material
photographs	Material
,	O
which	O
are	O
more	O
chaotic	O
.	O

We	O
trained	O
colorization	Method
on	O
ImageNet	O
,	O
and	O
tested	O
on	O
the	O
test	O
split	O
introduced	O
by	O
.	O

Our	O
method	O
,	O
with	O
L1	O
+	O
cGAN	Method
loss	O
,	O
fooled	O
participants	O
on	O
of	O
trials	O
(	O
Table	O
[	O
reference	O
]	O
)	O
.	O

We	O
also	O
tested	O
the	O
results	O
of	O
and	O
a	O
variant	O
of	O
their	O
method	O
that	O
used	O
an	O
L2	O
loss	O
(	O
see	O
for	O
details	O
)	O
.	O

The	O
conditional	O
GAN	Method
scored	O
similarly	O
to	O
the	O
L2	Method
variant	Method
of	O
(	O
difference	O
insignificant	O
by	O
bootstrap	O
test	O
)	O
,	O
but	O
fell	O
short	O
of	O
’s	O
full	O
method	O
,	O
which	O
fooled	O
participants	O
on	O
of	O
trials	O
in	O
our	O
experiment	O
.	O

We	O
note	O
that	O
their	O
method	O
was	O
specifically	O
engineered	O
to	O
do	O
well	O
on	O
colorization	Task
.	O

subsection	O
:	O
Semantic	Task
segmentation	Task
Conditional	O
GANs	Method
appear	O
to	O
be	O
effective	O
on	O
problems	O
where	O
the	O
output	O
is	O
highly	O
detailed	O
or	O
photographic	O
,	O
as	O
is	O
common	O
in	O
image	Task
processing	Task
and	Task
graphics	Task
tasks	Task
.	O

What	O
about	O
vision	Task
problems	Task
,	O
like	O
semantic	Task
segmentation	Task
,	O
where	O
the	O
output	O
is	O
instead	O
less	O
complex	O
than	O
the	O
input	O
?	O
To	O
begin	O
to	O
test	O
this	O
,	O
we	O
train	O
a	O
cGAN	Method
(	O
with	O
/	O
without	O
L1	Method
loss	Method
)	O
on	O
cityscape	Material
photo	Material
labels	Material
.	O

Figure	O
[	O
reference	O
]	O
shows	O
qualitative	O
results	O
,	O
and	O
quantitative	Metric
classification	Metric
accuracies	Metric
are	O
reported	O
in	O
Table	O
[	O
reference	O
]	O
.	O

Interestingly	O
,	O
cGANs	Method
,	O
trained	O
without	O
the	O
L1	Method
loss	Method
,	O
are	O
able	O
to	O
solve	O
this	O
problem	O
at	O
a	O
reasonable	O
degree	O
of	O
accuracy	Metric
.	O

To	O
our	O
knowledge	O
,	O
this	O
is	O
the	O
first	O
demonstration	O
of	O
GANs	Method
successfully	O
generating	O
“	O
labels	O
”	O
,	O
which	O
are	O
nearly	O
discrete	O
,	O
rather	O
than	O
“	O
images	O
”	O
,	O
with	O
their	O
continuous	O
-	O
valued	O
variation	O
.	O

Although	O
cGANs	Method
achieve	O
some	O
success	O
,	O
they	O
are	O
far	O
from	O
the	O
best	O
available	O
method	O
for	O
solving	O
this	O
problem	O
:	O
simply	O
using	O
L1	Method
regression	Method
gets	O
better	O
scores	O
than	O
using	O
a	O
cGAN	Method
,	O
as	O
shown	O
in	O
Table	O
[	O
reference	O
]	O
.	O

We	O
argue	O
that	O
for	O
vision	Task
problems	Task
,	O
the	O
goal	O
(	O
i.e.	O
predicting	O
output	O
close	O
to	O
the	O
ground	O
truth	O
)	O
may	O
be	O
less	O
ambiguous	O
than	O
graphics	Task
tasks	Task
,	O
and	O
reconstruction	O
losses	O
like	O
L1	Method
are	O
mostly	O
sufficient	O
.	O

subsection	O
:	O
Community	O
-	O
driven	O
Research	O
Since	O
the	O
initial	O
release	O
of	O
the	O
paper	O
and	O
our	O
pix2pix	Method
codebase	O
,	O
the	O
Twitter	O
community	O
,	O
including	O
computer	Task
vision	Task
and	O
graphics	Task
practitioners	Task
as	O
well	O
as	O
visual	Task
artists	Task
,	O
have	O
successfully	O
applied	O
our	O
framework	O
to	O
a	O
variety	O
of	O
novel	O
image	Task
-	Task
to	Task
-	Task
image	Task
translation	Task
tasks	Task
,	O
far	O
beyond	O
the	O
scope	O
of	O
the	O
original	O
paper	O
.	O

Figure	O
[	O
reference	O
]	O
and	O
Figure	O
[	O
reference	O
]	O
show	O
just	O
a	O
few	O
examples	O
from	O
the	O
#	O
pix2pix	Method
hashtag	O
,	O
including	O
Background	Task
removal	Task
,	O
Palette	Task
generation	Task
,	O
Sketch	O
→	O
Portrait	O
,	O
Sketch→Pokemon	O
,	O
”	O
Do	O
as	O
I	O
Do	O
”	O
pose	Task
transfer	Task
,	O
Learning	O
to	O
see	O
:	O
Gloomy	O
Sunday	O
,	O
as	O
well	O
as	O
the	O
bizarrely	O
popular	O
#	O
edges2cats	O
and	O
#	O
fotogenerator	Method
.	O

Note	O
that	O
these	O
applications	O
are	O
creative	O
projects	O
,	O
were	O
not	O
obtained	O
in	O
controlled	O
,	O
scientific	O
conditions	O
,	O
and	O
may	O
rely	O
on	O
some	O
modifications	O
to	O
the	O
pix2pix	Method
code	O
we	O
released	O
.	O

Nonetheless	O
,	O
they	O
demonstrate	O
the	O
promise	O
of	O
our	O
approach	O
as	O
a	O
generic	O
commodity	Method
tool	Method
for	O
image	Task
-	Task
to	Task
-	Task
image	Task
translation	Task
problems	Task
.	O

section	O
:	O
Conclusion	O
The	O
results	O
in	O
this	O
paper	O
suggest	O
that	O
conditional	Method
adversarial	Method
networks	Method
are	O
a	O
promising	O
approach	O
for	O
many	O
image	Task
-	Task
to	Task
-	Task
image	Task
translation	Task
tasks	Task
,	O
especially	O
those	O
involving	O
highly	O
structured	O
graphical	O
outputs	O
.	O

These	O
networks	O
learn	O
a	O
loss	Metric
adapted	O
to	O
the	O
task	O
and	O
data	O
at	O
hand	O
,	O
which	O
makes	O
them	O
applicable	O
in	O
a	O
wide	O
variety	O
of	O
settings	O
.	O

paragraph	O
:	O
Acknowledgments	O
:	O
We	O
thank	O
Richard	O
Zhang	O
,	O
Deepak	O
Pathak	O
,	O
and	O
Shubham	O
Tulsiani	O
for	O
helpful	O
discussions	O
,	O
Saining	O
Xie	O
for	O
help	O
with	O
the	O
HED	Method
edge	Method
detector	Method
,	O
and	O
the	O
online	O
community	O
for	O
exploring	O
many	O
applications	O
and	O
suggesting	O
improvements	O
.	O

Thanks	O
to	O
Christopher	O
Hesse	O
,	O
Memo	O
Akten	O
,	O
Kaihu	O
Chen	O
,	O
Jack	O
Qiao	O
,	O
Mario	O
Klingemann	O
,	O
Brannon	O
Dorsey	O
,	O
Gerda	O
Bosman	O
,	O
Ivy	O
Tsai	O
,	O
and	O
Yann	O
LeCun	O
for	O
allowing	O
the	O
use	O
of	O
their	O
creations	O
in	O
Figure	O
[	O
reference	O
]	O
and	O
Figure	O
[	O
reference	O
]	O
.	O

This	O
work	O
was	O
supported	O
in	O
part	O
by	O
NSF	O
SMA	O
-	O
1514512	O
,	O
NGA	O
NURI	O
,	O
IARPA	O
via	O
Air	O
Force	O
Research	O
Laboratory	O
,	O
Intel	O
Corp	O
,	O
Berkeley	O
Deep	O
Drive	O
,	O
and	O
hardware	O
donations	O
by	O
Nvidia	O
.	O

J.	O
-	O
Y.Z.	O
is	O
supported	O
by	O
the	O
Facebook	O
Graduate	O
Fellowship	O
.	O

Disclaimer	O
:	O
The	O
views	O
and	O
conclusions	O
contained	O
herein	O
are	O
those	O
of	O
the	O
authors	O
and	O
should	O
not	O
be	O
interpreted	O
as	O
necessarily	O
representing	O
the	O
official	O
policies	O
or	O
endorsements	O
,	O
either	O
expressed	O
or	O
implied	O
,	O
of	O
IARPA	O
,	O
AFRL	O
or	O
the	O
U.S.	O
Government	O
.	O

bibliography	O
:	O
References	O
section	O
:	O
Appendix	O
subsection	O
:	O
Network	Method
architectures	Method
We	O
adapt	O
our	O
network	Method
architectures	Method
from	O
those	O
in	O
.	O

Code	O
for	O
the	O
models	O
is	O
available	O
at	O
https:	O
//	O
github.com	O
/	O
phillipi	O
/	O
pix2pix	Method
.	O

Let	O
Ck	Method
denote	O
a	O
Convolution	Method
-	Method
BatchNorm	Method
-	Method
ReLU	Method
layer	Method
with	O
k	Method
filters	Method
.	O

CDk	Method
denotes	O
a	O
Convolution	Method
-	Method
BatchNorm	Method
-	Method
Dropout	Method
-	Method
ReLU	Method
layer	Method
with	O
a	O
dropout	O
rate	O
of	O
.	O

All	O
convolutions	Method
are	O
spatial	Method
filters	Method
applied	O
with	O
stride	O
2	O
.	O

Convolutions	Method
in	O
the	O
encoder	Method
,	O
and	O
in	O
the	O
discriminator	Method
,	O
downsample	O
by	O
a	O
factor	O
of	O
2	O
,	O
whereas	O
in	O
the	O
decoder	O
they	O
upsample	O
by	O
a	O
factor	O
of	O
2	O
.	O

subsubsection	O
:	O
Generator	Method
architectures	Method
The	O
encoder	Method
-	Method
decoder	Method
architecture	Method
consists	O
of	O
:	O
encoder	Method
:	O
C64	Method
-	Method
C128	Method
-	Method
C256	Method
-	Method
C512	Method
-	Method
C512	Method
-	Method
C512	Method
-	Method
C512	Method
-	Method
C512	Method
decoder	Method
:	O
CD512	Method
-	Method
CD512	Method
-	Method
CD512	Method
-	Method
C512	Method
-	Method
C256	Method
-	Method
C128	Method
-	Method
C64	Method
After	O
the	O
last	O
layer	O
in	O
the	O
decoder	Method
,	O
a	O
convolution	Method
is	O
applied	O
to	O
map	O
to	O
the	O
number	O
of	O
output	O
channels	O
(	O
3	O
in	O
general	O
,	O
except	O
in	O
colorization	O
,	O
where	O
it	O
is	O
2	O
)	O
,	O
followed	O
by	O
a	O
Tanh	Method
function	Method
.	O

As	O
an	O
exception	O
to	O
the	O
above	O
notation	O
,	O
BatchNorm	Method
is	O
not	O
applied	O
to	O
the	O
first	O
C64	O
layer	O
in	O
the	O
encoder	Method
.	O

All	O
ReLUs	O
in	O
the	O
encoder	O
are	O
leaky	O
,	O
with	O
slope	O
0.2	O
,	O
while	O
ReLUs	O
in	O
the	O
decoder	O
are	O
not	O
leaky	O
.	O

The	O
U	Method
-	Method
Net	Method
architecture	Method
is	O
identical	O
except	O
with	O
skip	O
connections	O
between	O
each	O
layer	O
in	O
the	O
encoder	O
and	O
layer	O
in	O
the	O
decoder	O
,	O
where	O
is	O
the	O
total	O
number	O
of	O
layers	O
.	O

The	O
skip	O
connections	O
concatenate	O
activations	O
from	O
layer	O
to	O
layer	O
.	O

This	O
changes	O
the	O
number	O
of	O
channels	O
in	O
the	O
decoder	O
:	O
U	Method
-	Method
Net	Method
decoder	Method
:	O
CD512	Method
-	Method
CD1024	Method
-	Method
CD1024	Method
-	Method
C1024	Method
-	Method
C1024	Method
-	Method
C512	Method
-	Method
C256	Method
-	Method
C128	Method
subsubsection	O
:	O
Discriminator	Method
architectures	Method
The	O
discriminator	Method
architecture	Method
is	O
:	O
C64	Method
-	Method
C128	Method
-	Method
C256	Method
-	Method
C512	Method
After	O
the	O
last	O
layer	O
,	O
a	O
convolution	Method
is	O
applied	O
to	O
map	O
to	O
a	O
1	O
-	O
dimensional	O
output	O
,	O
followed	O
by	O
a	O
Sigmoid	O
function	O
.	O

As	O
an	O
exception	O
to	O
the	O
above	O
notation	O
,	O
BatchNorm	Method
is	O
not	O
applied	O
to	O
the	O
first	O
C64	Method
layer	Method
.	O

All	O
ReLUs	Method
are	O
leaky	O
,	O
with	O
slope	O
0.2	O
.	O

All	O
other	O
discriminators	O
follow	O
the	O
same	O
basic	O
architecture	O
,	O
with	O
depth	O
varied	O
to	O
modify	O
the	O
receptive	O
field	O
size	O
:	O
discriminator	Method
:	O
C64	O
-	O
C128	O
(	O
note	O
,	O
in	O
this	O
special	O
case	O
,	O
all	O
convolutions	Method
are	O
spatial	Method
filters	Method
)	O
discriminator	Method
:	O
C64	Method
-	Method
C128×286286	Method
discriminator	Method
:	O
C64	O
-	O
C128	O
-	O
C256	O
-	O
C512	O
-	O
C512	O
-	O
C512	O
subsection	O
:	O
Training	O
details	O
Random	O
jitter	O
was	O
applied	O
by	O
resizing	O
the	O
input	O
images	O
to	O
and	O
then	O
randomly	O
cropping	O
back	O
to	O
size	O
.	O

All	O
networks	O
were	O
trained	O
from	O
scratch	O
.	O

Weights	O
were	O
initialized	O
from	O
a	O
Gaussian	Method
distribution	Method
with	O
mean	O
0	O
and	O
standard	O
deviation	O
0.02	O
.	O

Cityscapes	Material
labels→photo	Material
2975	O
training	O
images	O
from	O
the	O
Cityscapes	Material
training	Material
set	Material
,	O
trained	O
for	O
200	O
epochs	O
,	O
with	O
random	O
jitter	O
and	O
mirroring	O
.	O

We	O
used	O
the	O
Cityscapes	Material
validation	Material
set	Material
for	O
testing	O
.	O

To	O
compare	O
the	O
U	Method
-	Method
net	Method
against	O
an	O
encoder	Method
-	Method
decoder	Method
,	O
we	O
used	O
a	O
batch	O
size	O
of	O
10	O
,	O
whereas	O
for	O
the	O
objective	O
function	O
experiments	O
we	O
used	O
batch	O
size	O
1	O
.	O

We	O
find	O
that	O
batch	O
size	O
1	O
produces	O
better	O
results	O
for	O
the	O
U	Task
-	Task
net	Task
,	O
but	O
is	O
inappropriate	O
for	O
the	O
encoder	Method
-	Method
decoder	Method
.	O

This	O
is	O
because	O
we	O
apply	O
batchnorm	Method
on	O
all	O
layers	O
of	O
our	O
network	O
,	O
and	O
for	O
batch	O
size	O
1	O
this	O
operation	O
zeros	O
the	O
activations	O
on	O
the	O
bottleneck	O
layer	O
.	O

The	O
U	Method
-	Method
net	Method
can	O
skip	O
over	O
the	O
bottleneck	O
,	O
but	O
the	O
encoder	Method
-	Method
decoder	Method
can	O
not	O
,	O
and	O
so	O
the	O
encoder	Method
-	Method
decoder	Method
requires	O
a	O
batch	O
size	O
greater	O
than	O
1	O
.	O

Note	O
,	O
an	O
alternative	O
strategy	O
is	O
to	O
remove	O
batchnorm	O
from	O
the	O
bottleneck	Method
layer	Method
.	O

See	O
errata	O
for	O
more	O
details	O
.	O

Architectural	O
labels→photo	O
400	O
training	O
images	O
from	O
,	O
trained	O
for	O
200	O
epochs	O
,	O
batch	O
size	O
1	O
,	O
with	O
random	O
jitter	O
and	O
mirroring	O
.	O

Data	O
were	O
split	O
into	O
train	O
and	O
test	O
randomly	O
.	O

Maps↔aerial	Material
photograph	Material
1096	O
training	O
images	O
scraped	O
from	O
Google	O
Maps	O
,	O
trained	O
for	O
200	O
epochs	O
,	O
batch	O
size	O
1	O
,	O
with	O
random	O
jitter	O
and	O
mirroring	O
.	O

Images	O
were	O
sampled	O
from	O
in	O
and	O
around	O
New	O
York	O
City	O
.	O

Data	O
were	O
then	O
split	O
into	O
train	O
and	O
test	O
about	O
the	O
median	O
latitude	O
of	O
the	O
sampling	O
region	O
(	O
with	O
a	O
buffer	O
region	O
added	O
to	O
ensure	O
that	O
no	O
training	O
pixel	O
appeared	O
in	O
the	O
test	O
set	O
)	O
.	O

BW→color	Method
1.2	O
million	O
training	O
images	O
(	O
Imagenet	O
training	O
set	O
)	O
,	O
trained	O
for	O
epochs	O
,	O
batch	O
size	O
4	O
,	O
with	O
only	O
mirroring	O
,	O
no	O
random	O
jitter	O
.	O

Tested	O
on	O
subset	O
of	O
Imagenet	O
val	O
set	O
,	O
following	O
protocol	O
of	O
and	O
.	O

Edges→shoes	O
50k	O
training	O
images	O
from	O
UT	O
Zappos50	O
K	O
dataset	O
trained	O
for	O
15	O
epochs	O
,	O
batch	O
size	O
4	O
.	O

Data	O
were	O
split	O
into	O
train	O
and	O
test	O
randomly	O
.	O

Edges→Handbag	O
137	O
K	O
Amazon	O
Handbag	O
images	O
from	O
,	O
trained	O
for	O
15	O
epochs	O
,	O
batch	O
size	O
4	O
.	O

Data	O
were	O
split	O
into	O
train	O
and	O
test	O
randomly	O
.	O

Day→night	O
17823	O
training	O
images	O
extracted	O
from	O
91	O
webcams	O
,	O
from	O
trained	O
for	O
17	O
epochs	O
,	O
batch	O
size	O
4	O
,	O
with	O
random	O
jitter	O
and	O
mirroring	O
.	O

We	O
use	O
91	O
webcams	O
as	O
training	O
,	O
and	O
10	O
webcams	O
for	O
test	O
.	O

Thermal→color	O
photos	O
36609	O
training	O
images	O
from	O
set	O
00–05	O
of	O
,	O
trained	O
for	O
10	O
epochs	O
,	O
batch	O
size	O
4	O
.	O

Images	O
from	O
set	O
06	O
-	O
11	O
are	O
used	O
for	O
testing	O
.	O

Photo	O
with	O
missing	O
pixels→inpainted	O
photo	O
14900	O
training	O
images	O
from	O
,	O
trained	O
for	O
25	O
epochs	O
,	O
batch	O
size	O
4	O
,	O
and	O
tested	O
on	O
100	O
held	O
out	O
images	O
following	O
the	O
split	O
of	O
.	O

subsection	O
:	O
Errata	O
For	O
all	O
experiments	O
reported	O
in	O
this	O
paper	O
with	O
batch	O
size	O
1	O
,	O
the	O
activations	O
of	O
the	O
bottleneck	O
layer	O
are	O
zeroed	O
by	O
the	O
batchnorm	Method
operation	Method
,	O
effectively	O
making	O
the	O
innermost	Method
layer	Method
skipped	O
.	O

This	O
issue	O
can	O
be	O
fixed	O
by	O
removing	O
batchnorm	Method
from	O
this	O
layer	O
,	O
as	O
has	O
been	O
done	O
in	O
the	O
public	O
code	O
.	O

We	O
observe	O
little	O
difference	O
with	O
this	O
change	O
and	O
therefore	O
leave	O
the	O
experiments	O
as	O
is	O
in	O
the	O
paper	O
.	O

subsection	O
:	O
Change	O
log	O
arXiv	O
v2	O
Reran	Method
generator	Method
architecture	Method
comparisons	O
(	O
Section	O
[	O
reference	O
]	O
)	O
with	O
batch	O
size	O
equal	O
to	O
10	O
rather	O
than	O
1	O
,	O
so	O
that	O
bottleneck	O
layer	O
is	O
not	O
zeroed	O
(	O
see	O
Errata	O
)	O
.	O

Reran	O
FCN	O
-	O
scores	O
with	O
minor	O
details	O
cleaned	O
up	O
(	O
results	O
saved	O
losslessly	O
as	O
pngs	O
,	O
removed	O
unecessary	O
downsampling	O
)	O
.	O

FCN	Metric
-	Metric
scores	Metric
computed	O
using	O
scripts	O
at	O
https:	O
//	O
github.com	O
/	O
phillipi	O
/	O
pix2pix	Method
/	O
tree	O
/	O
master	O
/	O
scripts	O
/	O
eval_cityscapes	O
,	O
commit	O
d7e7b8b	O
.	O

Updated	O
several	O
figures	O
and	O
text	O
.	O

Added	O
additional	O
results	O
on	O
thermal	O
color	O
photos	O
and	O
inpainting	Task
,	O
as	O
well	O
as	O
community	O
contributions	O
.	O

arXiv	O
v3	O
Added	O
additional	O
results	O
on	O
community	O
contributions	O
.	O

Fixed	O
minor	O
typos	O
.	O

