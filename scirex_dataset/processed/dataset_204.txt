document	O
:	O
Deep	Method
Laplacian	Method
Pyramid	Method
Networks	Method
for	O
Fast	O
and	O
Accurate	Task
Super	Task
-	Task
Resolution	Task
Convolutional	Method
neural	Method
networks	Method
have	O
recently	O
demonstrated	O
high	O
-	O
quality	Task
reconstruction	Task
for	O
single	Task
-	Task
image	Task
super	Task
-	Task
resolution	Task
.	O

In	O
this	O
paper	O
,	O
we	O
propose	O
the	O
Laplacian	Method
Pyramid	Method
Super	Method
-	Method
Resolution	Method
Network	Method
(	O
LapSRN	Method
)	O
to	O
progressively	O
reconstruct	O
the	O
sub	O
-	O
band	O
residuals	O
of	O
high	O
-	O
resolution	O
images	O
.	O

At	O
each	O
pyramid	O
level	O
,	O
our	O
model	O
takes	O
coarse	O
-	O
resolution	O
feature	O
maps	O
as	O
input	O
,	O
predicts	O
the	O
high	O
-	O
frequency	O
residuals	O
,	O
and	O
uses	O
transposed	Method
convolutions	Method
for	O
upsampling	O
to	O
the	O
finer	O
level	O
.	O

Our	O
method	O
does	O
not	O
require	O
the	O
bicubic	Method
interpolation	Method
as	O
the	O
pre	O
-	O
processing	O
step	O
and	O
thus	O
dramatically	O
reduces	O
the	O
computational	Metric
complexity	Metric
.	O

We	O
train	O
the	O
proposed	O
LapSRN	Method
with	O
deep	Method
supervision	Method
using	O
a	O
robust	O
Charbonnier	Metric
loss	Metric
function	Metric
and	O
achieve	O
high	O
-	O
quality	Metric
reconstruction	Metric
.	O

Furthermore	O
,	O
our	O
network	O
generates	O
multi	Task
-	Task
scale	Task
predictions	Task
in	O
one	O
feed	O
-	O
forward	O
pass	O
through	O
the	O
progressive	Method
reconstruction	Method
,	O
thereby	O
facilitates	O
resource	Task
-	Task
aware	Task
applications	Task
.	O

Extensive	O
quantitative	O
and	O
qualitative	O
evaluations	O
on	O
benchmark	O
datasets	O
show	O
that	O
the	O
proposed	O
algorithm	O
performs	O
favorably	O
against	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
methods	O
in	O
terms	O
of	O
speed	Metric
and	O
accuracy	Metric
.	O

section	O
:	O
Introduction	O
Single	Task
-	Task
image	Task
super	Task
-	Task
resolution	Task
(	O
SR	Task
)	O
aims	O
to	O
reconstruct	O
a	O
high	O
-	O
resolution	O
(	O
HR	O
)	O
image	O
from	O
a	O
single	O
low	O
-	O
resolution	O
(	O
LR	Method
)	O
input	O
image	O
.	O

In	O
recent	O
years	O
,	O
example	O
-	O
based	O
SR	Task
methods	O
have	O
demonstrated	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
performance	O
by	O
learning	O
a	O
mapping	Method
from	O
LR	Method
to	O
HR	O
image	O
patches	O
using	O
large	O
image	O
databases	O
.	O

Numerous	O
learning	Method
algorithms	Method
have	O
been	O
applied	O
to	O
learn	O
such	O
a	O
mapping	O
,	O
including	O
dictionary	Method
learning	Method
,	O
local	Method
linear	Method
regression	Method
,	O
and	O
random	Method
forest	Method
.	O

Recently	O
,	O
Dong	O
et	O
al	O
.	O

propose	O
a	O
Super	Method
-	Method
Resolution	Method
Convolutional	Method
Neural	Method
Network	Method
(	O
SRCNN	Method
)	Method
to	O
learn	O
a	O
nonlinear	O
LR	Method
-	O
to	O
-	O
HR	O
mapping	O
.	O

The	O
network	O
is	O
extended	O
to	O
embed	O
a	O
sparse	Method
coding	Method
-	Method
based	Method
network	Method
or	O
use	O
a	O
deeper	O
structure	O
.	O

While	O
these	O
models	O
demonstrate	O
promising	O
results	O
,	O
there	O
are	O
three	O
main	O
issues	O
.	O

First	O
,	O
existing	O
methods	O
use	O
a	O
pre	O
-	O
defined	O
upsampling	Method
operator	Method
,	O
e.g.	O
,	O
bicubic	Method
interpolation	Method
,	O
to	O
upscale	O
input	O
images	O
to	O
the	O
desired	O
spatial	O
resolution	O
before	O
applying	O
the	O
network	O
for	O
prediction	Task
.	O

This	O
pre	Method
-	Method
processing	Method
step	Method
increases	O
unnecessary	O
computational	Metric
cost	Metric
and	O
often	O
results	O
in	O
visible	O
reconstruction	O
artifacts	O
.	O

Several	O
algorithms	O
accelerate	O
SRCNN	Method
by	O
performing	O
convolution	Method
on	O
LR	Method
images	O
and	O
replacing	O
the	O
pre	Method
-	Method
defined	Method
upsampling	Method
operator	Method
with	O
sub	Method
-	Method
pixel	Method
convolution	Method
or	O
transposed	Method
convolution	Method
(	O
also	O
named	O
as	O
deconvolution	Task
in	O
some	O
of	O
the	O
literature	O
)	O
.	O

These	O
methods	O
,	O
however	O
,	O
use	O
relatively	O
small	O
networks	O
and	O
can	O
not	O
learn	O
complicated	O
mappings	O
well	O
due	O
to	O
the	O
limited	O
network	O
capacity	O
.	O

Second	O
,	O
existing	O
methods	O
optimize	O
the	O
networks	O
with	O
an	O
loss	O
and	O
thus	O
inevitably	O
generate	O
blurry	O
predictions	O
.	O

Since	O
the	O
loss	O
fails	O
to	O
capture	O
the	O
underlying	O
multi	O
-	O
modal	O
distributions	O
of	O
HR	O
patches	O
(	O
i.e.	O
,	O
the	O
same	O
LR	Method
patch	O
may	O
have	O
many	O
corresponding	O
HR	O
patches	O
)	O
,	O
the	O
reconstructed	O
HR	O
images	O
are	O
often	O
overly	O
-	O
smooth	O
and	O
not	O
close	O
to	O
human	O
visual	O
perception	O
on	O
natural	O
images	O
.	O

Third	O
,	O
most	O
methods	O
reconstruct	O
HR	O
images	O
in	O
one	O
upsampling	Method
step	Method
,	O
which	O
increases	O
the	O
difficulties	O
of	O
training	O
for	O
large	O
scaling	O
factors	O
(	O
e.g.	O
,	O
)	O
.	O

In	O
addition	O
,	O
existing	O
methods	O
can	O
not	O
generate	O
intermediate	Task
SR	Task
predictions	Task
at	O
multiple	O
resolutions	O
.	O

As	O
a	O
result	O
,	O
one	O
needs	O
to	O
train	O
a	O
large	O
variety	O
of	O
models	O
for	O
various	O
applications	O
with	O
different	O
desired	O
upsampling	O
scales	O
and	O
computational	Metric
loads	Metric
.	O

To	O
address	O
these	O
drawbacks	O
,	O
we	O
propose	O
the	O
Laplacian	Method
Pyramid	Method
Super	Method
-	Method
Resolution	Method
Network	Method
(	O
LapSRN	Method
)	O
based	O
on	O
a	O
cascade	Method
of	Method
convolutional	Method
neural	Method
networks	Method
(	O
CNNs	Method
)	O
.	O

Our	O
network	O
takes	O
an	O
LR	Method
image	O
as	O
input	O
and	O
progressively	O
predicts	O
the	O
sub	O
-	O
band	O
residuals	O
in	O
a	O
coarse	O
-	O
to	O
-	O
fine	O
fashion	O
.	O

At	O
each	O
level	O
,	O
we	O
first	O
apply	O
a	O
cascade	Method
of	Method
convolutional	Method
layers	Method
to	O
extract	O
feature	O
maps	O
.	O

We	O
then	O
use	O
a	O
transposed	Method
convolutional	Method
layer	Method
for	O
upsampling	O
the	O
feature	O
maps	O
to	O
a	O
finer	O
level	O
.	O

Finally	O
,	O
we	O
use	O
a	O
convolutional	Method
layer	Method
to	O
predict	O
the	O
sub	O
-	O
band	O
residuals	O
(	O
the	O
differences	O
between	O
the	O
upsampled	O
image	O
and	O
the	O
ground	O
truth	O
HR	O
image	O
at	O
the	O
respective	O
level	O
)	O
.	O

The	O
predicted	O
residuals	O
at	O
each	O
level	O
are	O
used	O
to	O
efficiently	O
reconstruct	O
the	O
HR	O
image	O
through	O
upsampling	Method
and	Method
addition	Method
operations	Method
.	O

While	O
the	O
proposed	O
LapSRN	Method
consists	O
of	O
a	O
set	O
of	O
cascaded	Method
sub	Method
-	Method
networks	Method
,	O
we	O
train	O
the	O
network	O
with	O
a	O
robust	Method
Charbonnier	Method
loss	Method
function	Method
in	O
an	O
end	O
-	O
to	O
-	O
end	O
fashion	O
(	O
i.e.	O
,	O
without	O
stage	Method
-	Method
wise	Method
optimization	Method
)	O
.	O

As	O
depicted	O
in	O
Figure	O
[	O
reference	O
]	O
(	O
e	O
)	O
,	O
our	O
network	Method
architecture	Method
naturally	O
accommodates	O
deep	Task
supervision	Task
(	O
i.e.	O
,	O
supervisory	O
signals	O
can	O
be	O
applied	O
simultaneously	O
at	O
each	O
level	O
of	O
the	O
pyramid	O
)	O
.	O

Our	O
algorithm	O
differs	O
from	O
existing	O
CNN	Method
-	Method
based	Method
methods	Method
in	O
the	O
following	O
three	O
aspects	O
:	O
(	O
1	O
)	O
Accuracy	Metric
.	O

The	O
proposed	O
LapSRN	Method
extracts	O
feature	O
maps	O
directly	O
from	O
LR	Method
images	O
and	O
jointly	O
optimizes	O
the	O
upsampling	Method
filters	Method
with	O
deep	Method
convolutional	Method
layers	Method
to	O
predict	O
sub	O
-	O
band	O
residuals	O
.	O

The	O
deep	Method
supervision	Method
with	O
the	O
Charbonnier	Method
loss	Method
improves	O
the	O
performance	O
thanks	O
to	O
the	O
ability	O
to	O
better	O
handle	O
outliers	O
.	O

As	O
a	O
result	O
,	O
our	O
model	O
has	O
a	O
large	O
capacity	O
to	O
learn	O
complicated	O
mappings	O
and	O
effectively	O
reduces	O
the	O
undesired	O
visual	O
artifacts	O
.	O

(	O
2	O
)	O
Speed	Metric
.	O

Our	O
LapSRN	Method
embraces	O
both	O
fast	Metric
processing	Metric
speed	Metric
and	O
high	O
capacity	O
of	O
deep	Method
networks	Method
.	O

Experimental	O
results	O
demonstrate	O
that	O
our	O
method	O
is	O
faster	O
than	O
several	O
CNN	Method
based	Method
super	Method
-	Method
resolution	Method
models	Method
,	O
e.g.	O
,	O
SRCNN	Method
,	O
SCN	Method
,	O
VDSR	Method
,	O
and	O
DRCN	Method
.	O

Similar	O
to	O
FSRCNN	Method
,	O
our	O
LapSRN	Method
achieves	O
real	Metric
-	Metric
time	Metric
speed	Metric
on	O
most	O
of	O
the	O
evaluated	O
datasets	O
.	O

In	O
addition	O
,	O
our	O
method	O
provides	O
significantly	O
better	O
reconstruction	Metric
accuracy	Metric
.	O

(	O
3	O
)	O
Progressive	Task
reconstruction	Task
.	O

Our	O
model	O
generates	O
multiple	O
intermediate	Task
SR	Task
predictions	Task
in	O
one	O
feed	O
-	O
forward	O
pass	O
through	O
progressive	Method
reconstruction	Method
using	O
the	O
Laplacian	Method
pyramid	Method
.	O

This	O
characteristic	O
renders	O
our	O
technique	O
applicable	O
to	O
a	O
wide	O
range	O
of	O
applications	O
that	O
require	O
resource	Task
-	Task
aware	Task
adaptability	Task
.	O

For	O
example	O
,	O
the	O
same	O
network	O
can	O
be	O
used	O
to	O
enhance	O
the	O
spatial	O
resolution	O
of	O
videos	O
depending	O
on	O
the	O
available	O
computational	O
resources	O
.	O

For	O
scenarios	O
with	O
limited	O
computing	O
resources	O
,	O
our	O
model	O
can	O
still	O
perform	O
2	O
or	O
SR	Task
by	O
simply	O
bypassing	O
the	O
computation	O
of	O
residuals	O
at	O
finer	O
levels	O
.	O

Existing	O
CNN	Method
-	Method
based	Method
methods	Method
,	O
however	O
,	O
do	O
not	O
offer	O
such	O
flexibility	O
.	O

section	O
:	O
Related	O
Work	O
and	O
Problem	O
Context	O
Numerous	O
single	Task
-	Task
image	Task
super	Task
-	Task
resolution	Task
methods	O
have	O
been	O
proposed	O
in	O
the	O
literature	O
.	O

Here	O
we	O
focus	O
our	O
discussion	O
on	O
recent	O
example	Method
-	Method
based	Method
approaches	Method
.	O

paragraph	O
:	O
SR	Task
based	O
on	O
internal	O
databases	O
.	O

Several	O
methods	O
exploit	O
the	O
self	O
-	O
similarity	O
property	O
in	O
natural	O
images	O
and	O
construct	O
LR	Method
-	O
HR	O
patch	O
pairs	O
based	O
on	O
the	O
scale	Method
-	Method
space	Method
pyramid	Method
of	O
the	O
low	O
-	O
resolution	O
input	O
image	O
.	O

While	O
internal	O
databases	O
contain	O
more	O
relevant	O
training	O
patches	O
than	O
external	O
image	O
databases	O
,	O
the	O
number	O
of	O
LR	Method
-	O
HR	O
patch	O
pairs	O
may	O
not	O
be	O
sufficient	O
to	O
cover	O
large	O
textural	O
variations	O
in	O
an	O
image	O
.	O

Singh	O
et	O
al	O
.	O

decompose	O
patches	O
into	O
directional	O
frequency	O
sub	O
-	O
bands	O
and	O
determine	O
better	O
matches	O
in	O
each	O
sub	O
-	O
band	O
pyramid	O
independently	O
.	O

Huang	O
et	O
al	O
.	O

extend	O
the	O
patch	O
search	O
space	O
to	O
accommodate	O
the	O
affine	O
transform	O
and	O
perspective	O
deformation	O
.	O

The	O
main	O
drawback	O
of	O
SR	Task
methods	O
based	O
on	O
internal	O
databases	O
is	O
that	O
they	O
are	O
typically	O
slow	O
due	O
to	O
the	O
heavy	O
computational	Metric
cost	Metric
of	O
patch	Method
search	Method
in	O
the	O
scale	O
-	O
space	O
pyramid	O
.	O

paragraph	O
:	O
SR	Task
based	O
on	O
external	O
databases	O
.	O

Numerous	O
SR	Task
methods	O
learn	O
the	O
LR	Method
-	O
HR	O
mapping	O
with	O
image	O
pairs	O
collected	O
from	O
external	O
databases	O
using	O
supervised	Method
learning	Method
algorithms	Method
,	O
such	O
as	O
nearest	Method
neighbor	Method
,	O
manifold	Method
embedding	Method
,	O
kernel	Method
ridge	Method
regression	Method
,	O
and	O
sparse	Method
representation	Method
.	O

Instead	O
of	O
directly	O
modeling	O
the	O
complex	O
patch	O
space	O
over	O
the	O
entire	O
database	O
,	O
several	O
methods	O
partition	O
the	O
image	O
database	O
by	O
K	Method
-	Method
means	Method
,	O
sparse	Method
dictionary	Method
or	O
random	Method
forest	Method
,	O
and	O
learn	O
locally	Method
linear	Method
regressors	Method
for	O
each	O
cluster	O
.	O

paragraph	O
:	O
Convolutional	O
neural	O
networks	O
based	O
SR	Task
.	O

In	O
contrast	O
to	O
modeling	O
the	O
LR	Method
-	O
HR	O
mapping	O
in	O
the	O
patch	O
space	O
,	O
SRCNN	Method
jointly	O
optimize	O
all	O
the	O
steps	O
and	O
learn	O
the	O
non	Method
-	Method
linear	Method
mapping	Method
in	O
the	O
image	O
space	O
.	O

The	O
VDSR	Method
network	Method
demonstrates	O
significant	O
improvement	O
over	O
SRCNN	Method
by	O
increasing	O
the	O
network	O
depth	O
from	O
3	O
to	O
20	O
convolutional	O
layers	O
.	O

To	O
facilitate	O
training	O
a	O
deeper	Method
model	Method
with	O
a	O
fast	Metric
convergence	Metric
speed	Metric
,	O
VDSR	Method
trains	O
the	O
network	O
to	O
predict	O
the	O
residuals	O
rather	O
the	O
actual	O
pixel	O
values	O
.	O

Wang	O
et	O
al	O
.	O

combine	O
the	O
domain	Method
knowledge	Method
of	Method
sparse	Method
coding	Method
with	O
a	O
deep	Method
CNN	Method
and	O
train	O
a	O
cascade	Method
network	Method
(	O
SCN	Method
)	O
to	O
upsample	O
images	O
to	O
the	O
desired	O
scale	O
factor	O
progressively	O
.	O

Kim	O
et	O
al	O
.	O

propose	O
a	O
shallow	Method
network	Method
with	O
deeply	Method
recursive	Method
layers	Method
(	O
DRCN	Method
)	Method
to	O
reduce	O
the	O
number	O
of	O
parameters	O
.	O

To	O
achieve	O
real	O
-	O
time	O
performance	O
,	O
the	O
ESPCN	Method
network	Method
extracts	O
feature	O
maps	O
in	O
the	O
LR	Method
space	O
and	O
replaces	O
the	O
bicubic	Method
upsampling	Method
operation	Method
with	O
an	O
efficient	O
sub	Method
-	Method
pixel	Method
convolution	Method
.	O

The	O
FSRCNN	Method
network	Method
adopts	O
a	O
similar	O
idea	O
and	O
uses	O
a	O
hourglass	Method
-	Method
shaped	Method
CNN	Method
with	O
more	O
layers	O
but	O
fewer	O
parameters	O
than	O
that	O
in	O
ESPCN	Method
.	O

All	O
the	O
above	O
CNN	O
-	O
based	O
SR	Task
methods	O
optimize	O
networks	Method
with	O
an	O
loss	O
function	O
,	O
which	O
often	O
leads	O
to	O
overly	O
-	O
smooth	O
results	O
that	O
do	O
not	O
correlate	O
well	O
with	O
human	O
perception	O
.	O

In	O
the	O
context	O
of	O
SR	Task
,	O
we	O
demonstrate	O
that	O
the	O
loss	Method
is	O
less	O
effective	O
for	O
learning	Task
and	Task
predicting	Task
sparse	Task
residuals	Task
.	O

We	O
compare	O
the	O
network	O
structures	O
of	O
SRCNN	Method
,	O
FSRCNN	Method
,	O
VDSR	Method
,	O
DRCN	Method
and	O
our	O
LapSRN	Method
in	O
Figure	O
[	O
reference	O
]	O
and	O
list	O
the	O
main	O
differences	O
among	O
existing	O
CNN	Method
-	Method
based	Method
methods	Method
and	O
the	O
proposed	O
framework	O
in	O
Table	O
[	O
reference	O
]	O
.	O

Our	O
approach	O
builds	O
upon	O
existing	O
CNN	O
-	O
based	O
SR	Task
algorithms	O
with	O
three	O
main	O
differences	O
.	O

First	O
,	O
we	O
jointly	O
learn	O
residuals	Method
and	Method
upsampling	Method
filters	Method
with	O
convolutional	Method
and	Method
transposed	Method
convolutional	Method
layers	Method
.	O

Using	O
the	O
learned	O
upsampling	Method
filters	Method
not	O
only	O
effectively	O
suppresses	O
reconstruction	O
artifacts	O
caused	O
by	O
the	O
bicubic	Method
interpolation	Method
,	O
but	O
also	O
dramatically	O
reduces	O
the	O
computational	Metric
complexity	Metric
.	O

Second	O
,	O
we	O
optimize	O
the	O
deep	Method
network	Method
using	O
a	O
robust	O
Charbonnier	O
loss	O
function	O
instead	O
of	O
the	O
loss	O
to	O
handle	O
outliers	O
and	O
improve	O
the	O
reconstruction	Metric
accuracy	Metric
.	O

Third	O
,	O
as	O
the	O
proposed	O
LapSRN	Method
progressively	O
reconstructs	O
HR	O
images	O
,	O
the	O
same	O
model	O
can	O
be	O
used	O
for	O
applications	O
that	O
require	O
different	O
scale	O
factors	O
by	O
truncating	O
the	O
network	O
up	O
to	O
a	O
certain	O
level	O
.	O

paragraph	O
:	O
Laplacian	Method
pyramid	Method
.	O

The	O
Laplacian	Method
pyramid	Method
has	O
been	O
used	O
in	O
a	O
wide	O
range	O
of	O
applications	O
,	O
such	O
as	O
image	Task
blending	Task
,	O
texture	Task
synthesis	Task
,	O
edge	Task
-	Task
aware	Task
filtering	Task
and	O
semantic	Task
segmentation	Task
.	O

Denton	O
et	O
al	O
.	O

propose	O
a	O
generative	Method
model	Method
based	O
on	O
a	O
Laplacian	Method
pyramid	Method
framework	Method
(	O
LAPGAN	Method
)	O
to	O
generate	O
realistic	Task
images	Task
in	O
,	O
which	O
is	O
the	O
most	O
related	O
to	O
our	O
work	O
.	O

However	O
,	O
the	O
proposed	O
LapSRN	Method
differs	O
from	O
LAPGAN	Method
in	O
three	O
aspects	O
.	O

First	O
,	O
LAPGAN	Method
is	O
a	O
generative	Method
model	Method
which	O
is	O
designed	O
to	O
synthesize	O
diverse	O
natural	O
images	O
from	O
random	O
noise	O
and	O
sample	O
inputs	O
.	O

On	O
the	O
contrary	O
,	O
our	O
LapSRN	Method
is	O
a	O
super	Method
-	Method
resolution	Method
model	Method
that	O
predicts	O
a	O
particular	O
HR	O
image	O
based	O
on	O
the	O
given	O
LR	Method
image	O
.	O

LAPGAN	Method
uses	O
a	O
cross	Method
-	Method
entropy	Method
loss	Method
function	Method
to	O
encourage	O
the	O
output	O
images	O
to	O
respect	O
the	O
data	O
distribution	O
of	O
training	O
datasets	O
.	O

In	O
contrast	O
,	O
we	O
use	O
the	O
Charbonnier	O
penalty	O
function	O
to	O
penalize	O
the	O
deviation	O
of	O
the	O
prediction	O
from	O
the	O
ground	O
truth	O
sub	O
-	O
band	O
residuals	O
.	O

Second	O
,	O
the	O
sub	O
-	O
networks	O
of	O
LAPGAN	Method
are	O
independent	O
(	O
i.e.	O
,	O
no	O
weight	O
sharing	O
)	O
.	O

As	O
a	O
result	O
,	O
the	O
network	O
capacity	O
is	O
limited	O
by	O
the	O
depth	O
of	O
each	O
sub	O
-	O
network	O
.	O

Unlike	O
LAPGAN	Method
,	O
the	O
convolutional	Method
layers	Method
at	O
each	O
level	O
in	O
LapSRN	Method
are	O
connected	O
through	O
multi	Method
-	Method
channel	Method
transposed	Method
convolutional	Method
layers	Method
.	O

The	O
residual	O
images	O
at	O
a	O
higher	O
level	O
are	O
therefore	O
predicted	O
by	O
a	O
deeper	Method
network	Method
with	O
shared	Method
feature	Method
representations	Method
at	O
lower	O
levels	O
.	O

The	O
feature	O
sharing	O
at	O
lower	O
levels	O
increases	O
the	O
non	O
-	O
linearity	O
at	O
finer	O
convolutional	O
layers	O
to	O
learn	O
complex	O
mappings	O
.	O

Also	O
,	O
the	O
sub	Method
-	Method
networks	Method
in	O
LAPGAN	Method
are	O
independently	O
trained	O
.	O

On	O
the	O
other	O
hand	O
,	O
all	O
the	O
convolutional	Method
filters	Method
for	O
feature	Task
extraction	Task
,	O
upsampling	Task
,	O
and	O
residual	Task
prediction	Task
layers	Task
in	O
the	O
LapSRN	Method
are	O
jointly	O
trained	O
in	O
an	O
end	O
-	O
to	O
-	O
end	O
,	O
deeply	O
supervised	Method
fashion	Method
.	O

Third	O
,	O
LAPGAN	Method
applies	O
convolutions	Method
on	O
the	O
upsampled	O
images	O
,	O
so	O
the	O
speed	O
depends	O
on	O
the	O
size	O
of	O
HR	O
images	O
.	O

On	O
the	O
contrary	O
,	O
our	O
design	O
of	O
LapSRN	Method
effectively	O
increases	O
the	O
size	O
of	O
the	O
receptive	O
field	O
and	O
accelerates	O
the	O
speed	O
by	O
extracting	O
features	O
from	O
the	O
LR	Method
space	O
.	O

We	O
provide	O
comparisons	O
with	O
LAPGAN	Method
in	O
the	O
supplementary	O
material	O
.	O

paragraph	O
:	O
Adversarial	Method
training	Method
.	O

The	O
SRGAN	Method
method	Method
optimizes	O
the	O
network	O
using	O
the	O
perceptual	O
loss	O
and	O
the	O
adversarial	Method
loss	Method
for	O
photo	Task
-	Task
realistic	Task
SR	Task
.	O

We	O
note	O
that	O
our	O
LapSRN	Method
can	O
be	O
easily	O
extended	O
to	O
the	O
adversarial	Method
training	Method
framework	Method
.	O

As	O
it	O
is	O
not	O
our	O
contribution	O
,	O
we	O
provide	O
experiments	O
on	O
the	O
adversarial	O
loss	O
in	O
the	O
supplementary	O
material	O
.	O

section	O
:	O
Deep	Method
Laplacian	Method
Pyramid	Method
Network	Method
for	O
SR	Task
In	O
this	O
section	O
,	O
we	O
describe	O
the	O
design	O
methodology	O
of	O
the	O
proposed	O
Laplacian	Method
pyramid	Method
network	Method
,	O
the	O
optimization	Task
using	O
robust	Method
loss	Method
functions	Method
with	O
deep	O
supervision	O
,	O
and	O
the	O
details	O
for	O
network	Task
training	Task
.	O

subsection	O
:	O
Network	Method
architecture	Method
We	O
propose	O
to	O
construct	O
our	O
network	O
based	O
on	O
the	O
Laplacian	Method
pyramid	Method
framework	Method
,	O
as	O
shown	O
in	O
Figure	O
[	O
reference	O
]	O
(	O
e	O
)	O
.	O

Our	O
model	O
takes	O
an	O
LR	Method
image	O
as	O
input	O
(	O
rather	O
than	O
an	O
upscaled	Method
version	Method
of	O
the	O
LR	Method
image	O
)	O
and	O
progressively	O
predicts	O
residual	O
images	O
at	O
levels	O
where	O
is	O
the	O
scale	O
factor	O
.	O

For	O
example	O
,	O
the	O
network	O
consists	O
of	O
sub	Method
-	Method
networks	Method
for	O
super	Task
-	Task
resolving	Task
an	O
LR	Method
image	O
at	O
a	O
scale	O
factor	O
of	O
.	O

Our	O
model	O
has	O
two	O
branches	O
:	O
(	O
1	O
)	O
feature	Task
extraction	Task
and	O
(	O
2	O
)	O
image	Task
reconstruction	Task
.	O

Feature	Task
extraction	Task
.	O

At	O
level	O
,	O
the	O
feature	Method
extraction	Method
branch	Method
consists	O
of	O
convolutional	Method
layers	Method
and	O
one	O
transposed	Method
convolutional	Method
layer	Method
to	O
upsample	O
the	O
extracted	O
features	O
by	O
a	O
scale	O
of	O
2	O
.	O

The	O
output	O
of	O
each	O
transposed	Method
convolutional	Method
layer	Method
is	O
connected	O
to	O
two	O
different	O
layers	O
:	O
(	O
1	O
)	O
a	O
convolutional	Method
layer	Method
for	O
reconstructing	O
a	O
residual	O
image	O
at	O
level	O
,	O
and	O
(	O
2	O
)	O
a	O
convolutional	Method
layer	Method
for	O
extracting	O
features	O
at	O
the	O
finer	O
level	O
.	O

Note	O
that	O
we	O
perform	O
the	O
feature	Task
extraction	Task
at	O
the	O
coarse	O
resolution	O
and	O
generate	O
feature	O
maps	O
at	O
the	O
finer	O
resolution	O
with	O
only	O
one	O
transposed	Method
convolutional	Method
layer	Method
.	O

In	O
contrast	O
to	O
existing	O
networks	O
that	O
perform	O
all	O
feature	Task
extraction	Task
and	Task
reconstruction	Task
at	O
the	O
fine	O
resolution	O
,	O
our	O
network	Method
design	Method
significantly	O
reduces	O
the	O
computational	Metric
complexity	Metric
.	O

Note	O
that	O
the	O
feature	O
representations	O
at	O
lower	O
levels	O
are	O
shared	O
with	O
higher	O
levels	O
,	O
and	O
thus	O
can	O
increase	O
the	O
non	O
-	O
linearity	O
of	O
the	O
network	O
to	O
learn	O
complex	O
mappings	O
at	O
the	O
finer	O
levels	O
.	O

Image	Task
reconstruction	Task
.	O

At	O
level	O
,	O
the	O
input	O
image	O
is	O
upsampled	O
by	O
a	O
scale	O
of	O
2	O
with	O
a	O
transposed	Method
convolutional	Method
(	Method
upsampling	Method
)	Method
layer	Method
.	O

We	O
initialize	O
this	O
layer	O
with	O
the	O
bilinear	Method
kernel	Method
and	O
allow	O
it	O
to	O
be	O
jointly	O
optimized	O
with	O
all	O
the	O
other	O
layers	O
.	O

The	O
upsampled	O
image	O
is	O
then	O
combined	O
(	O
using	O
element	Method
-	Method
wise	Method
summation	Method
)	O
with	O
the	O
predicted	O
residual	O
image	O
from	O
the	O
feature	Method
extraction	Method
branch	Method
to	O
produce	O
a	O
high	O
-	O
resolution	O
output	O
image	O
.	O

The	O
output	O
HR	O
image	O
at	O
level	O
is	O
then	O
fed	O
into	O
the	O
image	O
reconstruction	O
branch	O
of	O
level	O
.	O

The	O
entire	O
network	O
is	O
a	O
cascade	Method
of	Method
CNNs	Method
with	O
a	O
similar	O
structure	O
at	O
each	O
level	O
.	O

subsection	O
:	O
Loss	Method
function	Method
Let	O
be	O
the	O
input	O
LR	Method
image	O
and	O
be	O
the	O
set	O
of	O
network	O
parameters	O
to	O
be	O
optimized	O
.	O

Our	O
goal	O
is	O
to	O
learn	O
a	O
mapping	Method
function	Method
for	O
generating	O
a	O
high	Task
-	Task
resolution	Task
image	Task
that	O
is	O
close	O
to	O
the	O
ground	O
truth	O
HR	O
image	O
.	O

We	O
denote	O
the	O
residual	O
image	O
at	O
level	O
by	O
,	O
the	O
upscaled	O
LR	Method
image	O
by	O
and	O
the	O
corresponding	O
HR	O
images	O
by	O
.	O

The	O
desired	O
output	O
HR	O
images	O
at	O
level	O
is	O
modeled	O
by	O
.	O

We	O
use	O
the	O
bicubic	Method
downsampling	Method
to	O
resize	O
the	O
ground	O
truth	O
HR	O
image	O
to	O
at	O
each	O
level	O
.	O

Instead	O
of	O
minimizing	O
the	O
mean	Metric
square	Metric
errors	Metric
between	O
and	O
,	O
we	O
propose	O
to	O
use	O
a	O
robust	Method
loss	Method
function	Method
to	O
handle	O
outliers	O
.	O

The	O
overall	Metric
loss	Metric
function	Metric
is	O
defined	O
as	O
:	O
where	O
is	O
the	O
Charbonnier	O
penalty	O
function	O
(	O
a	O
differentiable	O
variant	O
of	O
norm	Method
)	O
,	O
is	O
the	O
number	O
of	O
training	O
samples	O
in	O
each	O
batch	O
,	O
and	O
is	O
the	O
number	O
of	O
level	O
in	O
our	O
pyramid	O
.	O

We	O
empirically	O
set	O
to	O
.	O

In	O
the	O
proposed	O
LapSRN	Method
,	O
each	O
level	O
has	O
its	O
loss	O
function	O
and	O
the	O
corresponding	O
ground	O
truth	O
HR	O
image	O
.	O

This	O
multi	Method
-	Method
loss	Method
structure	Method
resembles	O
the	O
deeply	Method
-	Method
supervised	Method
nets	Method
for	O
classification	Task
and	Task
edge	Task
detection	Task
.	O

However	O
,	O
the	O
labels	O
used	O
to	O
supervise	O
intermediate	O
layers	O
in	O
are	O
the	O
same	O
across	O
the	O
networks	O
.	O

In	O
our	O
model	O
,	O
we	O
use	O
different	O
scales	O
of	O
HR	O
images	O
at	O
the	O
corresponding	O
level	O
as	O
supervision	O
.	O

The	O
deep	Method
supervision	Method
guides	O
the	O
network	Method
training	Method
to	O
predict	O
sub	O
-	O
band	O
residual	O
images	O
at	O
different	O
levels	O
and	O
produce	O
multi	O
-	O
scale	O
output	O
images	O
.	O

For	O
example	O
,	O
our	O
model	O
can	O
produce	O
,	O
and	O
super	O
-	O
resolution	O
results	O
in	O
one	O
feed	Method
-	Method
forward	Method
pass	Method
.	O

This	O
property	O
is	O
particularly	O
useful	O
for	O
resource	Task
-	Task
aware	Task
applications	Task
,	O
e.g.	O
,	O
mobile	Task
devices	Task
or	Task
network	Task
applications	Task
.	O

subsection	O
:	O
Implementation	O
and	O
training	O
details	O
In	O
the	O
proposed	O
LapSRN	Method
,	O
each	O
convolutional	Method
layer	Method
consists	O
of	O
64	O
filters	O
with	O
the	O
size	O
of	O
.	O

We	O
initialize	O
the	O
convolutional	Method
filters	Method
using	O
the	O
method	O
of	O
He	O
et	O
al	O
.	O

.	O

The	O
size	O
of	O
the	O
transposed	Method
convolutional	Method
filters	Method
is	O
and	O
the	O
weights	O
are	O
initialized	O
from	O
a	O
bilinear	Method
filter	Method
.	O

All	O
the	O
convolutional	Method
and	Method
transposed	Method
convolutional	Method
layers	Method
(	O
except	O
the	O
reconstruction	Method
layers	Method
)	O
are	O
followed	O
by	O
leaky	Method
rectified	Method
linear	Method
units	Method
(	O
LReLUs	Method
)	O
with	O
a	O
negative	O
slope	O
of	O
0.2	O
.	O

We	O
pad	O
zeros	O
around	O
the	O
boundaries	O
before	O
applying	O
convolution	Method
to	O
keep	O
the	O
size	O
of	O
all	O
feature	O
maps	O
the	O
same	O
as	O
the	O
input	O
of	O
each	O
level	O
.	O

The	O
convolutional	Method
filters	Method
have	O
small	O
spatial	O
supports	O
(	O
)	O
.	O

However	O
,	O
we	O
can	O
achieve	O
high	O
non	O
-	O
linearity	O
and	O
increase	O
the	O
size	O
of	O
receptive	O
fields	O
with	O
a	O
deep	O
structure	O
.	O

We	O
use	O
91	O
images	O
from	O
Yang	O
et	O
al	O
.	O

and	O
200	O
images	O
from	O
the	O
training	O
set	O
of	O
Berkeley	Material
Segmentation	Material
Dataset	Material
as	O
our	O
training	O
data	O
.	O

The	O
same	O
training	O
dataset	O
is	O
used	O
in	O
as	O
well	O
.	O

In	O
each	O
training	O
batch	O
,	O
we	O
randomly	O
sample	O
patches	O
with	O
the	O
size	O
of	O
.	O

An	O
epoch	O
has	O
iterations	O
of	O
back	Method
-	Method
propagation	Method
.	O

We	O
augment	O
the	O
training	O
data	O
in	O
three	O
ways	O
:	O
(	O
1	O
)	O
Scaling	Method
:	O
randomly	O
downscale	O
between	O
.	O

(	O
2	O
)	O
Rotation	O
:	O
randomly	O
rotate	O
image	O
by	O
,	O
,	O
or	O
.	O

(	O
3	O
)	O
Flipping	O
:	O
flip	O
images	O
horizontally	O
or	O
vertically	O
with	O
a	O
probability	O
of	O
.	O

Following	O
the	O
protocol	O
of	O
existing	O
methods	O
,	O
we	O
generate	O
the	O
LR	Method
training	O
patches	O
using	O
the	O
bicubic	Method
downsampling	Method
.	O

We	O
train	O
our	O
model	O
with	O
the	O
MatConvNet	Method
toolbox	Method
.	O

We	O
set	O
momentum	O
parameter	O
to	O
and	O
the	O
weight	O
decay	O
to	O
.	O

The	O
learning	Metric
rate	Metric
is	O
initialized	O
to	O
for	O
all	O
layers	O
and	O
decreased	O
by	O
a	O
factor	O
of	O
2	O
for	O
every	O
50	O
epochs	O
.	O

section	O
:	O
Experiment	O
Results	O
We	O
first	O
analyze	O
the	O
contributions	O
of	O
different	O
components	O
of	O
the	O
proposed	O
network	O
.	O

We	O
then	O
compare	O
our	O
LapSRN	Method
with	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
algorithms	O
on	O
five	O
benchmark	O
datasets	O
and	O
demonstrate	O
the	O
applications	O
of	O
our	O
method	O
on	O
super	Task
-	Task
resolving	Task
real	O
-	O
world	O
photos	O
and	O
videos	O
.	O

subsection	O
:	O
Model	O
analysis	O
Residual	Method
learning	Method
.	O

To	O
demonstrate	O
the	O
effect	O
of	O
residual	Method
learning	Method
,	O
we	O
remove	O
the	O
image	O
reconstruction	O
branch	O
and	O
directly	O
predict	O
the	O
HR	O
images	O
at	O
each	O
level	O
.	O

Figure	O
[	O
reference	O
]	O
shows	O
the	O
convergence	O
curves	O
in	O
terms	O
of	O
PSNR	Metric
on	O
the	O
Set14	Material
for	O
SR	Task
.	O

The	O
performance	O
of	O
the	O
“	O
non	Method
-	Method
residual	Method
”	Method
network	Method
(	O
blue	O
curve	O
)	O
converges	O
slowly	O
and	O
fluctuates	O
significantly	O
.	O

The	O
proposed	O
LapSRN	Method
(	O
red	O
curve	O
)	O
,	O
on	O
the	O
other	O
hand	O
,	O
outperforms	O
SRCNN	Method
within	O
10	O
epochs	O
.	O

Loss	O
function	O
.	O

To	O
validate	O
the	O
effect	O
of	O
the	O
Charbonnier	O
loss	O
function	O
,	O
we	O
train	O
the	O
proposed	O
network	O
with	O
the	O
loss	O
function	O
.	O

We	O
use	O
a	O
larger	O
learning	Metric
rate	Metric
(	O
)	O
since	O
the	O
gradient	Metric
magnitude	Metric
of	Metric
the	Metric
loss	Metric
is	O
smaller	O
.	O

As	O
illustrated	O
in	O
Figure	O
[	O
reference	O
]	O
,	O
the	O
network	O
optimized	O
with	O
loss	O
(	O
green	O
curve	O
)	O
requires	O
more	O
iterations	O
to	O
achieve	O
comparable	O
performance	O
with	O
SRCNN	Method
.	O

In	O
Figure	O
[	O
reference	O
]	O
(	O
d	O
)	O
,	O
we	O
show	O
that	O
the	O
network	O
trained	O
with	O
the	O
loss	Method
generates	O
SR	Task
results	O
with	O
more	O
ringing	O
artifacts	O
.	O

In	O
contrast	O
,	O
the	O
SR	Task
images	O
reconstruct	O
by	O
the	O
proposed	O
algorithm	O
(	O
Figure	O
[	O
reference	O
]	O
(	O
e	O
)	O
)	O
contain	O
relatively	O
clean	O
and	O
sharp	O
details	O
.	O

Pyramid	O
structure	O
.	O

By	O
removing	O
the	O
pyramid	O
structure	O
,	O
our	O
model	O
falls	O
back	O
to	O
a	O
network	O
similar	O
to	O
FSRCNN	Method
but	O
with	O
the	O
residual	Method
learning	Method
.	O

To	O
use	O
the	O
same	O
number	O
of	O
convolutional	O
layers	O
as	O
LapSRN	Method
,	O
we	O
train	O
a	O
network	O
with	O
10	O
convolutional	Method
layers	Method
and	O
one	O
transposed	Method
convolutional	Method
layer	Method
.	O

The	O
quantitative	O
results	O
in	O
Table	O
[	O
reference	O
]	O
shows	O
that	O
the	O
pyramid	O
structure	O
leads	O
to	O
moderate	O
performance	O
improvement	O
(	O
e.g.	O
0.7	O
dB	O
on	O
Set5	Material
and	O
0.4	O
dB	O
on	O
Set14	Material
)	O
.	O

Network	O
depth	O
.	O

We	O
train	O
the	O
proposed	O
model	O
with	O
different	O
depth	O
,	O
,	O
at	O
each	O
level	O
and	O
show	O
the	O
trade	O
-	O
offs	O
between	O
performance	O
and	O
speed	Metric
in	O
Table	O
[	O
reference	O
]	O
.	O

In	O
general	O
,	O
deep	Method
networks	Method
perform	O
better	O
shallow	O
ones	O
at	O
the	O
expense	O
of	O
increased	O
computational	Metric
cost	Metric
.	O

We	O
choose	O
for	O
our	O
and	O
SR	Task
models	O
to	O
strike	O
a	O
balance	O
between	O
performance	O
and	O
speed	Metric
.	O

We	O
show	O
that	O
the	O
speed	O
of	O
our	O
LapSRN	Method
with	O
is	O
faster	O
than	O
most	O
of	O
the	O
existing	O
CNN	O
-	O
based	O
SR	Task
algorithms	O
(	O
see	O
Figure	O
[	O
reference	O
]	O
)	O
.	O

For	O
model	O
,	O
we	O
choose	O
because	O
we	O
do	O
not	O
observe	O
significant	O
performance	O
gain	O
by	O
using	O
more	O
convolutional	Method
layers	Method
.	O

subsection	O
:	O
Comparisons	O
with	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
arts	O
We	O
compare	O
the	O
proposed	O
LapSRN	Method
with	O
8	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
SR	Task
algorithms	O
:	O
A	O
+	O
,	O
SRCNN	Method
,	O
FSRCNN	Method
,	O
SelfExSR	Method
,	O
RFL	Method
,	O
SCN	Method
,	O
VDSR	Method
and	O
DRCN	Method
.	O

We	O
carry	O
out	O
extensive	O
experiments	O
using	O
5	O
datasets	O
:	O
Set5	Material
,	O
Set14	Material
,	O
BSDS100	Material
,	O
Urban100	Material
and	O
manga109	O
.	O

Among	O
these	O
datasets	O
,	O
Set5	Material
,	O
Set14	Material
and	O
BSDS100	Material
consist	O
of	O
natural	O
scenes	O
;	O
Urban100	Material
contains	O
challenging	O
urban	O
scenes	O
images	O
with	O
details	O
in	O
different	O
frequency	O
bands	O
;	O
and	O
manga109	Material
is	O
a	O
dataset	O
of	O
Japanese	O
manga	O
.	O

We	O
train	O
the	O
LapSRN	Method
until	O
the	O
learning	Metric
rate	Metric
decreases	O
to	O
and	O
the	O
training	Metric
time	Metric
is	O
around	O
three	O
days	O
on	O
a	O
Titan	O
X	O
GPU	O
.	O

We	O
evaluate	O
the	O
SR	Task
images	O
with	O
three	O
commonly	O
used	O
image	Metric
quality	Metric
metrics	Metric
:	O
PSNR	Metric
,	O
SSIM	Metric
,	O
and	O
IFC	Metric
.	O

Table	O
[	O
reference	O
]	O
shows	O
quantitative	O
comparisons	O
for	O
,	O
and	O
SR	Task
.	O

Our	O
LapSRN	Method
performs	O
favorably	O
against	O
existing	O
methods	O
on	O
most	O
datasets	O
.	O

In	O
particular	O
,	O
our	O
algorithm	O
achieves	O
higher	O
IFC	Metric
values	O
,	O
which	O
has	O
been	O
shown	O
to	O
be	O
correlated	O
well	O
with	O
human	O
perception	O
of	O
image	Task
super	Task
-	Task
resolution	Task
.	O

We	O
note	O
that	O
the	O
best	O
results	O
can	O
be	O
achieved	O
by	O
training	O
with	O
specific	O
scale	O
factors	O
(	O
Ours	O
and	O
Ours	O
)	O
.	O

As	O
the	O
intermediate	Method
convolutional	Method
layers	Method
are	O
trained	O
to	O
minimize	O
the	O
prediction	O
errors	O
for	O
both	O
the	O
corresponding	O
level	O
and	O
higher	O
levels	O
,	O
the	O
intermediate	O
predictions	O
of	O
our	O
model	O
are	O
slightly	O
inferior	O
to	O
our	O
and	Method
models	Method
.	O

Nevertheless	O
,	O
our	O
model	O
provides	O
a	O
competitive	O
performance	O
to	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
methods	O
in	O
and	O
SR	Task
.	O

In	O
Figure	O
[	O
reference	O
]	O
,	O
we	O
show	O
visual	O
comparisons	O
on	O
Urban100	Material
,	O
BSDS100	Material
and	O
Manga109	Material
with	O
the	O
a	O
scale	O
factor	O
of	O
.	O

Our	O
method	O
accurately	O
reconstructs	O
parallel	O
straight	O
lines	O
and	O
grid	O
patterns	O
such	O
as	O
windows	O
and	O
the	O
stripes	O
on	O
tigers	O
.	O

We	O
observe	O
that	O
methods	O
using	O
the	O
bicubic	Method
upsampling	Method
for	O
pre	Task
-	Task
processing	Task
generate	O
results	O
with	O
noticeable	O
artifacts	O
.	O

In	O
contrast	O
,	O
our	O
approach	O
effectively	O
suppresses	O
such	O
artifacts	O
through	O
progressive	Method
reconstruction	Method
and	O
the	O
robust	Method
loss	Method
function	Method
.	O

For	O
SR	Task
,	O
we	O
re	O
-	O
train	O
the	O
model	O
of	O
A	O
+	O
,	O
SRCNN	Method
,	O
FSRCNN	Method
,	O
RFL	Method
and	O
VDSR	Method
using	O
the	O
publicly	O
available	O
code	O
.	O

Both	O
SelfExSR	Method
and	Method
SCN	Method
methods	Method
can	O
handle	O
different	O
scale	O
factors	O
using	O
progressive	Method
reconstruction	Method
.	O

We	O
show	O
SR	Task
results	O
on	O
BSDS100	Material
and	O
Urban100	Material
in	O
Figure	O
[	O
reference	O
]	O
.	O

For	O
SR	Task
,	O
it	O
is	O
challenging	O
to	O
predict	O
HR	O
images	O
from	O
bicubic	O
-	O
upsampled	O
images	O
or	O
using	O
one	Method
-	Method
step	Method
upsampling	Method
.	O

The	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
methods	O
do	O
not	O
super	O
-	O
resolve	O
the	O
fine	O
structures	O
well	O
.	O

In	O
contrast	O
,	O
the	O
LapSRN	Method
reconstructs	O
high	O
-	O
quality	O
HR	O
images	O
at	O
a	O
relatively	O
fast	O
speed	O
.	O

We	O
present	O
SR	Task
images	O
generated	O
by	O
all	O
the	O
evaluated	O
methods	O
in	O
the	O
supplementary	O
material	O
.	O

subsection	O
:	O
Execution	Metric
time	Metric
We	O
use	O
the	O
original	O
codes	O
of	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
methods	O
to	O
evaluate	O
the	O
runtime	Metric
on	O
the	O
same	O
machine	O
with	O
3.4	O
GHz	O
Intel	O
i7	O
CPU	O
(	O
64	O
G	O
RAM	O
)	O
and	O
NVIDIA	O
Titan	O
X	O
GPU	O
(	O
12	O
G	O
Memory	O
)	O
.	O

Since	O
the	O
codes	O
of	O
SRCNN	Method
and	O
FSRCNN	Method
for	O
testing	O
are	O
based	O
on	O
CPU	Method
implementations	Method
,	O
we	O
reconstruct	O
these	O
models	O
in	O
MatConvNet	Method
with	O
the	O
same	O
network	O
weights	O
to	O
measure	O
the	O
run	Metric
time	Metric
on	O
GPU	O
.	O

Figure	O
[	O
reference	O
]	O
shows	O
the	O
trade	O
-	O
offs	O
between	O
the	O
run	Metric
time	Metric
and	O
performance	O
(	O
in	O
terms	O
of	O
PSNR	Metric
)	O
on	O
Set14	Material
for	O
SR	Task
.	O

The	O
speed	O
of	O
the	O
proposed	O
LapSRN	Method
is	O
faster	O
than	O
all	O
the	O
existing	O
methods	O
except	O
FSRCNN	Method
.	O

We	O
present	O
detailed	O
evaluations	O
on	O
run	Metric
time	Metric
of	O
all	O
evaluated	O
datasets	O
in	O
the	O
supplementary	O
material	O
.	O

subsection	O
:	O
Super	Task
-	Task
resolving	Task
real	Task
-	Task
world	Task
photos	Task
We	O
demonstrate	O
an	O
application	O
of	O
super	Task
-	Task
resolving	Task
historical	Task
photographs	Task
with	O
JPEG	O
compression	O
artifacts	O
.	O

In	O
these	O
cases	O
,	O
neither	O
the	O
ground	O
-	O
truth	O
images	O
nor	O
the	O
downsampling	Method
kernels	Method
are	O
available	O
.	O

As	O
shown	O
in	O
Figure	O
[	O
reference	O
]	O
,	O
our	O
method	O
can	O
reconstruct	O
sharper	O
and	O
more	O
accurate	O
images	O
than	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
approaches	O
.	O

subsection	O
:	O
Super	Task
-	Task
resolving	Task
video	Task
sequences	Task
We	O
conduct	O
frame	Task
-	Task
based	Task
SR	Task
experiments	O
on	O
two	O
video	O
sequences	O
from	O
with	O
a	O
spatial	O
resolution	O
of	O
pixels	O
.	O

We	O
downsample	O
each	O
frame	O
by	O
,	O
and	O
then	O
apply	O
super	Method
-	Method
resolution	Method
frame	O
by	O
frame	O
for	O
,	O
and	O
,	O
respectively	O
.	O

The	O
computational	Metric
cost	Metric
depends	O
on	O
the	O
size	O
of	O
input	O
images	O
since	O
we	O
extract	O
features	O
from	O
the	O
LR	Method
space	O
.	O

On	O
the	O
contrary	O
,	O
the	O
speed	O
of	O
SRCNN	Method
and	O
VDSR	Method
is	O
limited	O
by	O
the	O
size	O
of	O
output	O
images	O
.	O

Both	O
FSRCNN	Method
and	O
our	O
approach	O
achieve	O
real	O
-	O
time	O
performance	O
(	O
i.e.	O
,	O
over	O
30	O
frames	O
per	O
second	O
)	O
on	O
all	O
upsampling	O
scales	O
.	O

In	O
contrast	O
,	O
the	O
FPS	Metric
is	O
8.43	O
for	O
SRCNN	Method
and	O
1.98	O
for	O
VDSR	Method
on	O
SR	Task
.	O

Figure	O
[	O
reference	O
]	O
visualizes	O
results	O
of	O
SR	Task
on	O
one	O
representative	O
frame	O
.	O

subsection	O
:	O
Limitations	O
While	O
our	O
model	O
is	O
capable	O
of	O
generating	O
clean	Task
and	Task
sharp	Task
HR	Task
images	Task
on	O
a	O
large	O
scale	O
factor	O
,	O
e.g.	O
,	O
,	O
it	O
does	O
not	O
“	O
hallucinate	O
”	O
fine	O
details	O
.	O

As	O
shown	O
in	O
Figure	O
[	O
reference	O
]	O
,	O
the	O
top	O
of	O
the	O
building	O
is	O
significantly	O
blurred	O
in	O
the	O
downscaled	O
LR	Method
image	O
.	O

All	O
SR	Task
algorithms	O
fail	O
to	O
recover	O
the	O
fine	O
structure	O
except	O
SelfExSR	O
,	O
which	O
explicitly	O
detects	O
the	O
3D	O
scene	O
geometry	O
and	O
uses	O
self	O
-	O
similarity	O
to	O
hallucinate	O
the	O
regular	O
structure	O
.	O

This	O
is	O
a	O
common	O
limitation	O
shared	O
by	O
parametric	O
SR	Task
methods	O
.	O

Another	O
limitation	O
of	O
the	O
proposed	O
network	O
is	O
the	O
relative	O
large	O
model	O
size	O
.	O

To	O
reduce	O
the	O
number	O
of	O
parameters	O
,	O
one	O
can	O
replace	O
the	O
deep	Method
convolutional	Method
layers	Method
at	O
each	O
level	O
with	O
recursive	Method
layers	Method
.	O

section	O
:	O
Conclusions	O
In	O
this	O
work	O
,	O
we	O
propose	O
a	O
deep	Method
convolutional	Method
network	Method
within	O
a	O
Laplacian	Method
pyramid	Method
framework	Method
for	O
fast	O
and	O
accurate	O
single	Task
-	Task
image	Task
super	Task
-	Task
resolution	Task
.	O

Our	O
model	O
progressively	O
predicts	O
high	O
-	O
frequency	O
residuals	O
in	O
a	O
coarse	O
-	O
to	O
-	O
fine	O
manner	O
.	O

By	O
replacing	O
the	O
pre	O
-	O
defined	O
bicubic	O
interpolation	O
with	O
the	O
learned	O
transposed	Method
convolutional	Method
layers	Method
and	O
optimizing	O
the	O
network	O
with	O
a	O
robust	O
loss	O
function	O
,	O
the	O
proposed	O
LapSRN	Method
alleviates	O
issues	O
with	O
undesired	O
artifacts	O
and	O
reduces	O
the	O
computational	Metric
complexity	Metric
.	O

Extensive	O
evaluations	O
on	O
benchmark	O
datasets	O
demonstrate	O
that	O
the	O
proposed	O
model	O
performs	O
favorably	O
against	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
SR	Task
algorithms	O
in	O
terms	O
of	O
visual	Metric
quality	Metric
and	O
run	Metric
time	Metric
.	O

section	O
:	O
Acknowledgments	O
This	O
work	O
is	O
supported	O
in	O
part	O
by	O
the	O
NSF	O
CAREER	O
Grant	O
,	O
gifts	O
from	O
Adobe	O
and	O
Nvidia	O
.	O

J.	O
-	O
B.	O
Huang	O
and	O
N.	O
Ahuja	O
are	O
supported	O
in	O
part	O
by	O
Office	O
of	O
Naval	O
Research	O
under	O
Grant	O
N00014	O
-	O
16	O
-	O
1	O
-	O
2314	O
.	O

bibliography	O
:	O
References	O
