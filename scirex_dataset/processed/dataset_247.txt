document	O
:	O
Coupled	Method
Generative	Method
Adversarial	Method
Networks	Method
We	O
propose	O
coupled	Method
generative	Method
adversarial	Method
network	Method
(	O
CoGAN	Method
)	O
for	O
learning	O
a	O
joint	Task
distribution	Task
of	Task
multi	Task
-	Task
domain	Task
images	Task
.	O

In	O
contrast	O
to	O
the	O
existing	O
approaches	O
,	O
which	O
require	O
tuples	O
of	O
corresponding	O
images	O
in	O
different	O
domains	O
in	O
the	O
training	O
set	O
,	O
CoGAN	Method
can	O
learn	O
a	O
joint	Method
distribution	Method
without	O
any	O
tuple	O
of	O
corresponding	O
images	O
.	O

It	O
can	O
learn	O
a	O
joint	O
distribution	O
with	O
just	O
samples	O
drawn	O
from	O
the	O
marginal	O
distributions	O
.	O

This	O
is	O
achieved	O
by	O
enforcing	O
a	O
weight	O
-	O
sharing	O
constraint	O
that	O
limits	O
the	O
network	O
capacity	O
and	O
favors	O
a	O
joint	Method
distribution	Method
solution	Method
over	O
a	O
product	Method
of	Method
marginal	Method
distributions	Method
one	O
.	O

We	O
apply	O
CoGAN	Method
to	O
several	O
joint	Task
distribution	Task
learning	Task
tasks	Task
,	O
including	O
learning	O
a	O
joint	O
distribution	O
of	O
color	O
and	O
depth	O
images	O
,	O
and	O
learning	O
a	O
joint	Task
distribution	Task
of	Task
face	Task
images	Task
with	O
different	O
attributes	O
.	O

For	O
each	O
task	O
it	O
successfully	O
learns	O
the	O
joint	O
distribution	O
without	O
any	O
tuple	O
of	O
corresponding	O
images	O
.	O

We	O
also	O
demonstrate	O
its	O
applications	O
to	O
domain	Task
adaptation	Task
and	O
image	Task
transformation	Task
.	O

section	O
:	O
Introduction	O
The	O
paper	O
concerns	O
the	O
problem	O
of	O
learning	O
a	O
joint	Task
distribution	Task
of	Task
multi	Task
-	Task
domain	Task
images	Task
from	O
data	O
.	O

A	O
joint	Method
distribution	Method
of	O
multi	O
-	O
domain	O
images	O
is	O
a	O
probability	Method
density	Method
function	Method
that	O
gives	O
a	O
density	O
value	O
to	O
each	O
joint	O
occurrence	O
of	O
images	O
in	O
different	O
domains	O
such	O
as	O
images	O
of	O
the	O
same	O
scene	O
in	O
different	O
modalities	O
(	O
color	O
and	O
depth	O
images	O
)	O
or	O
images	O
of	O
the	O
same	O
face	O
with	O
different	O
attributes	O
(	O
smiling	O
and	O
non	O
-	O
smiling	O
)	O
.	O

Once	O
a	O
joint	O
distribution	O
of	O
multi	O
-	O
domain	O
images	O
is	O
learned	O
,	O
it	O
can	O
be	O
used	O
to	O
generate	O
novel	O
tuples	O
of	O
images	O
.	O

In	O
addition	O
to	O
movie	Task
and	Task
game	Task
production	Task
,	O
joint	Task
image	Task
distribution	Task
learning	Task
finds	O
applications	O
in	O
image	Task
transformation	Task
and	O
domain	Task
adaptation	Task
.	O

When	O
training	O
data	O
are	O
given	O
as	O
tuples	O
of	O
corresponding	O
images	O
in	O
different	O
domains	O
,	O
several	O
existing	O
approaches	O
can	O
be	O
applied	O
.	O

However	O
,	O
building	O
a	O
dataset	O
with	O
tuples	O
of	O
corresponding	O
images	O
is	O
often	O
a	O
challenging	O
task	O
.	O

This	O
correspondence	O
dependency	O
greatly	O
limits	O
the	O
applicability	O
of	O
the	O
existing	O
approaches	O
.	O

To	O
overcome	O
the	O
limitation	O
,	O
we	O
propose	O
the	O
coupled	Method
generative	Method
adversarial	Method
networks	Method
(	O
CoGAN	Method
)	O
framework	O
.	O

It	O
can	O
learn	O
a	O
joint	O
distribution	O
of	O
multi	O
-	O
domain	O
images	O
without	O
existence	O
of	O
corresponding	O
images	O
in	O
different	O
domains	O
in	O
the	O
training	O
set	O
.	O

Only	O
a	O
set	O
of	O
images	O
drawn	O
separately	O
from	O
the	O
marginal	O
distributions	O
of	O
the	O
individual	O
domains	O
is	O
required	O
.	O

CoGAN	Method
is	O
based	O
on	O
the	O
generative	Method
adversarial	Method
networks	Method
(	O
GAN	Method
)	O
framework	O
,	O
which	O
has	O
been	O
established	O
as	O
a	O
viable	O
solution	O
for	O
image	Task
distribution	Task
learning	Task
tasks	Task
.	O

CoGAN	Method
extends	O
GAN	Method
for	O
joint	Task
image	Task
distribution	Task
learning	Task
tasks	Task
.	O

CoGAN	Method
consists	O
of	O
a	O
tuple	Method
of	Method
GANs	Method
,	O
each	O
for	O
one	O
image	O
domain	O
.	O

When	O
trained	O
naively	O
,	O
the	O
CoGAN	Method
learns	O
a	O
product	Method
of	Method
marginal	Method
distributions	Method
rather	O
than	O
a	O
joint	O
distribution	O
.	O

We	O
show	O
that	O
by	O
enforcing	O
a	O
weight	O
-	O
sharing	O
constraint	O
the	O
CoGAN	Method
can	O
learn	O
a	O
joint	O
distribution	O
without	O
existence	O
of	O
corresponding	O
images	O
in	O
different	O
domains	O
.	O

The	O
CoGAN	Method
framework	O
is	O
inspired	O
by	O
the	O
idea	O
that	O
deep	Method
neural	Method
networks	Method
learn	O
a	O
hierarchical	Method
feature	Method
representation	Method
.	O

By	O
enforcing	O
the	O
layers	O
that	O
decode	O
high	O
-	O
level	O
semantics	O
in	O
the	O
GANs	Method
to	O
share	O
the	O
weights	O
,	O
it	O
forces	O
the	O
GANs	Method
to	O
decode	O
the	O
high	O
-	O
level	O
semantics	O
in	O
the	O
same	O
way	O
.	O

The	O
layers	O
that	O
decode	O
low	O
-	O
level	O
details	O
then	O
map	O
the	O
shared	Method
representation	Method
to	O
images	O
in	O
individual	O
domains	O
for	O
confusing	O
the	O
respective	O
discriminative	Method
models	Method
.	O

CoGAN	Method
is	O
for	O
multi	Task
-	Task
image	Task
domains	Task
but	O
,	O
for	O
ease	O
of	O
presentation	O
,	O
we	O
focused	O
on	O
the	O
case	O
of	O
two	O
image	O
domains	O
in	O
the	O
paper	O
.	O

However	O
,	O
the	O
discussions	O
and	O
analyses	O
can	O
be	O
easily	O
generalized	O
to	O
multiple	O
image	O
domains	O
.	O

We	O
apply	O
CoGAN	Method
to	O
several	O
joint	Task
image	Task
distribution	Task
learning	Task
tasks	Task
.	O

Through	O
convincing	O
visualization	O
results	O
and	O
quantitative	O
evaluations	O
,	O
we	O
verify	O
its	O
effectiveness	O
.	O

We	O
also	O
show	O
its	O
applications	O
to	O
unsupervised	Task
domain	Task
adaptation	Task
and	O
image	Task
transformation	Task
.	O

section	O
:	O
Generative	Method
Adversarial	Method
Networks	Method
A	O
GAN	Method
consists	O
of	O
a	O
generative	Method
model	Method
and	O
a	O
discriminative	Method
model	Method
.	O

The	O
objective	O
of	O
the	O
generative	Method
model	Method
is	O
to	O
synthesize	O
images	O
resembling	O
real	O
images	O
,	O
while	O
the	O
objective	O
of	O
the	O
discriminative	Method
model	Method
is	O
to	O
distinguish	O
real	O
images	O
from	O
synthesized	O
ones	O
.	O

Both	O
the	O
generative	Method
and	Method
discriminative	Method
models	Method
are	O
realized	O
as	O
multilayer	Method
perceptrons	Method
.	O

Let	O
be	O
a	O
natural	O
image	O
drawn	O
from	O
a	O
distribution	O
,	O
,	O
and	O
be	O
a	O
random	O
vector	O
in	O
.	O

Note	O
that	O
we	O
only	O
consider	O
that	O
is	O
from	O
a	O
uniform	O
distribution	O
with	O
a	O
support	O
of	O
,	O
but	O
different	O
distributions	O
such	O
as	O
a	O
multivariate	Method
normal	Method
distribution	Method
can	O
be	O
applied	O
as	O
well	O
.	O

Let	O
and	O
be	O
the	O
generative	Method
and	Method
discriminative	Method
models	Method
,	O
respectively	O
.	O

The	O
generative	Method
model	Method
takes	O
as	O
input	O
and	O
outputs	O
an	O
image	O
,	O
,	O
that	O
has	O
the	O
same	O
support	O
as	O
.	O

Denote	O
the	O
distribution	O
of	O
as	O
.	O

The	O
discriminative	Method
model	Method
estimates	O
the	O
probability	O
that	O
an	O
input	O
image	O
is	O
drawn	O
from	O
.	O

Ideally	O
,	O
if	O
and	O
if	O
.	O

The	O
GAN	Method
framework	O
corresponds	O
to	O
a	O
minimax	Task
two	Task
-	Task
player	Task
game	Task
,	O
and	O
the	O
generative	Method
and	Method
discriminative	Method
models	Method
can	O
be	O
trained	O
jointly	O
via	O
solving	O
In	O
practice	O
(	O
[	O
reference	O
]	O
)	O
is	O
solved	O
by	O
alternating	O
the	O
following	O
two	O
gradient	Method
update	Method
steps	Method
:	O
where	O
and	O
are	O
the	O
parameters	O
of	O
and	O
,	O
is	O
the	O
learning	Metric
rate	Metric
,	O
and	O
is	O
the	O
iteration	O
number	O
.	O

Goodfellow	O
et	O
al	O
.	O

show	O
that	O
,	O
given	O
enough	O
capacity	O
to	O
and	O
and	O
sufficient	O
training	O
iterations	O
,	O
the	O
distribution	O
,	O
,	O
converges	O
to	O
.	O

In	O
other	O
words	O
,	O
from	O
a	O
random	O
vector	O
,	O
,	O
the	O
network	O
can	O
synthesize	O
an	O
image	O
,	O
,	O
that	O
resembles	O
one	O
that	O
is	O
drawn	O
from	O
the	O
true	O
distribution	O
,	O
.	O

section	O
:	O
Coupled	Method
Generative	Method
Adversarial	Method
Networks	Method
CoGAN	Method
as	O
illustrated	O
in	O
Figure	O
[	O
reference	O
]	O
is	O
designed	O
for	O
learning	O
a	O
joint	Task
distribution	Task
of	Task
images	Task
in	O
two	O
different	O
domains	O
.	O

It	O
consists	O
of	O
a	O
pair	O
of	O
GANs—	Method
and	O
;	O
each	O
is	O
responsible	O
for	O
synthesizing	O
images	O
in	O
one	O
domain	O
.	O

During	O
training	O
,	O
we	O
force	O
them	O
to	O
share	O
a	O
subset	O
of	O
parameters	O
.	O

This	O
results	O
in	O
that	O
the	O
GANs	Method
learn	O
to	O
synthesize	O
pairs	O
of	O
corresponding	O
images	O
without	O
correspondence	O
supervision	O
.	O

Generative	Method
Models	Method
:	O
Let	O
and	O
be	O
images	O
drawn	O
from	O
the	O
marginal	Method
distribution	Method
of	Method
the	Method
1st	Method
domain	Method
,	O
and	O
the	O
marginal	O
distribution	O
of	O
the	O
2nd	O
domain	O
,	O
,	O
respectively	O
.	O

Let	O
and	O
be	O
the	O
generative	Method
models	Method
of	O
and	O
,	O
which	O
map	O
a	O
random	O
vector	O
input	O
to	O
images	O
that	O
have	O
the	O
same	O
support	O
as	O
and	O
,	O
respectively	O
.	O

Denote	O
the	O
distributions	O
of	O
and	O
by	O
and	O
.	O

Both	O
and	O
are	O
realized	O
as	O
multilayer	Method
perceptrons	Method
:	O
where	O
and	O
are	O
the	O
th	O
layers	O
of	O
and	O
and	O
and	O
are	O
the	O
numbers	O
of	O
layers	O
in	O
and	O
.	O

Note	O
that	O
need	O
not	O
equal	O
.	O

Also	O
note	O
that	O
the	O
support	O
of	O
need	O
not	O
equal	O
to	O
that	O
of	O
.	O

Through	O
layers	O
of	O
perceptron	Method
operations	Method
,	O
the	O
generative	Method
models	Method
gradually	O
decode	O
information	O
from	O
more	O
abstract	O
concepts	O
to	O
more	O
material	O
details	O
.	O

The	O
first	O
layers	O
decode	O
high	O
-	O
level	O
semantics	O
and	O
the	O
last	O
layers	O
decode	O
low	O
-	O
level	O
details	O
.	O

Note	O
that	O
this	O
information	O
flow	O
direction	O
is	O
opposite	O
to	O
that	O
in	O
a	O
discriminative	Method
deep	Method
neural	Method
network	Method
where	O
the	O
first	O
layers	O
extract	O
low	O
-	O
level	O
features	O
while	O
the	O
last	O
layers	O
extract	O
high	O
-	O
level	O
features	O
.	O

Based	O
on	O
the	O
idea	O
that	O
a	O
pair	O
of	O
corresponding	O
images	O
in	O
two	O
domains	O
share	O
the	O
same	O
high	O
-	O
level	O
concepts	O
,	O
we	O
force	O
the	O
first	O
layers	O
of	O
and	O
to	O
have	O
identical	O
structure	O
and	O
share	O
the	O
weights	O
.	O

That	O
is	O
where	O
is	O
the	O
number	O
of	O
shared	O
layers	O
,	O
and	O
and	O
are	O
the	O
parameters	O
of	O
and	O
,	O
respectively	O
.	O

This	O
constraint	O
forces	O
the	O
high	O
-	O
level	O
semantics	O
to	O
be	O
decoded	O
in	O
the	O
same	O
way	O
in	O
and	O
.	O

No	O
constraints	O
are	O
enforced	O
to	O
the	O
last	O
layers	O
.	O

They	O
can	O
materialize	O
the	O
shared	O
high	O
-	O
level	O
representation	O
differently	O
for	O
fooling	O
the	O
respective	O
discriminators	O
.	O

Discriminative	Method
Models	Method
:	O
Let	O
and	O
be	O
the	O
discriminative	Method
models	Method
of	O
and	O
given	O
by	O
where	O
and	O
are	O
the	O
th	O
layers	O
of	O
and	O
and	O
and	O
are	O
the	O
numbers	O
of	O
layers	O
.	O

The	O
discriminative	Method
models	Method
map	O
an	O
input	O
image	O
to	O
a	O
probability	O
score	O
,	O
estimating	O
the	O
likelihood	O
that	O
the	O
input	O
is	O
drawn	O
from	O
a	O
true	O
data	O
distribution	O
.	O

The	O
first	O
layers	O
of	O
the	O
discriminative	Method
models	Method
extract	O
low	O
-	O
level	O
features	O
,	O
while	O
the	O
last	O
layers	O
extract	O
high	O
-	O
level	O
features	O
.	O

Because	O
the	O
input	O
images	O
are	O
realizations	O
of	O
the	O
same	O
high	O
-	O
level	O
semantics	O
in	O
two	O
different	O
domains	O
,	O
we	O
force	O
and	O
to	O
have	O
the	O
same	O
last	O
layers	O
,	O
which	O
is	O
achieved	O
by	O
sharing	O
the	O
weights	O
of	O
the	O
last	O
layers	O
via	O
where	O
is	O
the	O
number	O
of	O
weight	O
-	O
sharing	O
layers	O
in	O
the	O
discriminative	Method
models	Method
,	O
and	O
and	O
are	O
the	O
network	O
parameters	O
of	O
and	O
,	O
respectively	O
.	O

The	O
weight	O
-	O
sharing	O
constraint	O
in	O
the	O
discriminators	Method
helps	O
reduce	O
the	O
total	O
number	O
of	O
parameters	O
in	O
the	O
network	O
,	O
but	O
it	O
is	O
not	O
essential	O
for	O
learning	O
a	O
joint	Task
distribution	Task
.	O

Learning	Method
:	O
The	O
CoGAN	Method
framework	O
corresponds	O
to	O
a	O
constrained	Task
minimax	Task
game	Task
given	O
by	O
where	O
the	O
value	O
function	O
is	O
given	O
by	O
In	O
the	O
game	O
,	O
there	O
are	O
two	O
teams	O
and	O
each	O
team	O
has	O
two	O
players	O
.	O

The	O
generative	Method
models	Method
form	O
a	O
team	O
and	O
work	O
together	O
for	O
synthesizing	O
a	O
pair	O
of	O
images	O
in	O
two	O
different	O
domains	O
for	O
confusing	O
the	O
discriminative	Method
models	Method
.	O

The	O
discriminative	Method
models	Method
try	O
to	O
differentiate	O
images	O
drawn	O
from	O
the	O
training	O
data	O
distribution	O
in	O
the	O
respective	O
domains	O
from	O
those	O
drawn	O
from	O
the	O
respective	O
generative	Method
models	Method
.	O

The	O
collaboration	O
between	O
the	O
players	O
in	O
the	O
same	O
team	O
is	O
established	O
from	O
the	O
weight	O
-	O
sharing	O
constraint	O
.	O

Similar	O
to	O
GAN	Method
,	O
CoGAN	Method
can	O
be	O
trained	O
by	O
back	Method
propagation	Method
with	O
the	O
alternating	Method
gradient	Method
update	Method
steps	Method
.	O

The	O
details	O
of	O
the	O
learning	Method
algorithm	Method
are	O
given	O
in	O
the	O
supplementary	O
materials	O
.	O

Remarks	O
:	O
CoGAN	Method
learning	O
requires	O
training	O
samples	O
drawn	O
from	O
the	O
marginal	O
distributions	O
,	O
and	O
.	O

It	O
does	O
not	O
rely	O
on	O
samples	O
drawn	O
from	O
the	O
joint	O
distribution	O
,	O
,	O
where	O
corresponding	O
supervision	O
would	O
be	O
available	O
.	O

Our	O
main	O
contribution	O
is	O
in	O
showing	O
that	O
with	O
just	O
samples	O
drawn	O
separately	O
from	O
the	O
marginal	O
distributions	O
,	O
CoGAN	Method
can	O
learn	O
a	O
joint	O
distribution	O
of	O
images	O
in	O
the	O
two	O
domains	O
.	O

Both	O
weight	Method
-	Method
sharing	Method
constraint	Method
and	O
adversarial	Method
training	Method
are	O
essential	O
for	O
enabling	O
this	O
capability	O
.	O

Unlike	O
autoencoder	Method
learning	Method
,	O
which	O
encourages	O
a	O
generated	O
pair	O
of	O
images	O
to	O
be	O
identical	O
to	O
the	O
target	O
pair	O
of	O
corresponding	O
images	O
in	O
the	O
two	O
domains	O
for	O
minimizing	O
the	O
reconstruction	Task
loss	Task
,	O
the	O
adversarial	Method
training	Method
only	O
encourages	O
the	O
generated	O
pair	O
of	O
images	O
to	O
be	O
individually	O
resembling	O
to	O
the	O
images	O
in	O
the	O
respective	O
domains	O
.	O

With	O
this	O
more	O
relaxed	O
adversarial	O
training	O
setting	O
,	O
the	O
weight	O
-	O
sharing	O
constraint	O
can	O
then	O
kick	O
in	O
for	O
capturing	O
correspondences	O
between	O
domains	O
.	O

With	O
the	O
weight	O
-	O
sharing	O
constraint	O
,	O
the	O
generative	Method
models	Method
must	O
utilize	O
the	O
capacity	O
more	O
efficiently	O
for	O
fooling	O
the	O
discriminative	Method
models	Method
,	O
and	O
the	O
most	O
efficient	O
way	O
of	O
utilizing	O
the	O
capacity	O
for	O
generating	O
a	O
pair	O
of	O
realistic	O
images	O
in	O
two	O
domains	O
is	O
to	O
generate	O
a	O
pair	O
of	O
corresponding	O
images	O
since	O
the	O
neurons	O
responsible	O
for	O
decoding	Task
high	Task
-	Task
level	Task
semantics	Task
can	O
be	O
shared	O
.	O

CoGAN	Method
learning	O
is	O
based	O
on	O
existence	O
of	O
shared	O
high	Method
-	Method
level	Method
representations	Method
in	O
the	O
domains	O
.	O

If	O
such	O
a	O
representation	O
does	O
not	O
exist	O
for	O
the	O
set	O
of	O
domains	O
of	O
interest	O
,	O
it	O
would	O
fail	O
.	O

section	O
:	O
Experiments	O
In	O
the	O
experiments	O
,	O
we	O
emphasized	O
there	O
were	O
no	O
corresponding	O
images	O
in	O
the	O
different	O
domains	O
in	O
the	O
training	O
sets	O
.	O

CoGAN	Method
learned	O
the	O
joint	O
distributions	O
without	O
correspondence	O
supervision	O
.	O

We	O
were	O
unaware	O
of	O
existing	O
approaches	O
with	O
the	O
same	O
capability	O
and	O
hence	O
did	O
not	O
compare	O
CoGAN	Method
with	O
prior	O
works	O
.	O

Instead	O
,	O
we	O
compared	O
it	O
to	O
a	O
conditional	O
GAN	Method
to	O
demonstrate	O
its	O
advantage	O
.	O

Recognizing	O
that	O
popular	O
performance	Metric
metrics	Metric
for	O
evaluating	O
generative	Method
models	Method
all	O
subject	O
to	O
issues	O
,	O
we	O
adopted	O
a	O
pair	Metric
image	Metric
generation	Metric
performance	Metric
metric	Metric
for	O
comparison	O
.	O

Many	O
details	O
including	O
the	O
network	Method
architectures	Method
and	O
additional	O
experiment	O
results	O
are	O
given	O
in	O
the	O
supplementary	O
materials	O
.	O

An	O
implementation	O
of	O
CoGAN	Method
is	O
available	O
in	O
.	O

Digits	O
:	O
We	O
used	O
the	O
MNIST	Material
training	Material
set	Material
to	O
train	O
CoGANs	Method
for	O
the	O
following	O
two	O
tasks	O
.	O

Task	O
is	O
about	O
learning	O
a	O
joint	O
distribution	O
of	O
a	O
digit	O
and	O
its	O
edge	O
image	O
.	O

Task	O
is	O
about	O
learning	O
a	O
joint	O
distribution	O
of	O
a	O
digit	O
and	O
its	O
negative	O
image	O
.	O

In	O
Task	O
,	O
the	O
1st	O
domain	O
consisted	O
of	O
the	O
original	O
handwritten	O
digit	O
images	O
,	O
while	O
the	O
2nd	O
domain	O
consisted	O
of	O
their	O
edge	O
images	O
.	O

We	O
used	O
an	O
edge	Method
detector	Method
to	O
compute	O
training	O
edge	O
images	O
for	O
the	O
2nd	O
domain	O
.	O

In	O
the	O
supplementary	O
materials	O
,	O
we	O
also	O
showed	O
an	O
experiment	O
for	O
learning	O
a	O
joint	O
distribution	O
of	O
a	O
digit	O
and	O
its	O
90	O
-	O
degree	O
in	O
-	O
plane	O
rotation	O
.	O

We	O
used	O
deep	O
convolutional	Method
networks	O
to	O
realized	O
the	O
CoGAN	Method
.	O

The	O
two	O
generative	Method
models	Method
had	O
an	O
identical	O
structure	O
;	O
both	O
had	O
5	O
layers	O
and	O
were	O
fully	O
convolutional	Method
.	O

The	O
stride	O
lengths	O
of	O
the	O
convolutional	Method
layers	O
were	O
fractional	O
.	O

The	O
models	O
also	O
employed	O
the	O
batch	Method
normalization	Method
processing	O
and	O
the	O
parameterized	Method
rectified	Method
linear	Method
unit	Method
processing	O
.	O

We	O
shared	O
the	O
parameters	O
for	O
all	O
the	O
layers	O
except	O
for	O
the	O
last	O
convolutional	Method
layers	O
.	O

For	O
the	O
discriminative	Method
models	Method
,	O
we	O
used	O
a	O
variant	O
of	O
LeNet	Method
.	O

The	O
inputs	O
to	O
the	O
discriminative	Method
models	Method
were	O
batches	O
containing	O
output	O
images	O
from	O
the	O
generative	Method
models	Method
and	O
images	O
from	O
the	O
two	O
training	O
subsets	O
(	O
each	O
pixel	O
value	O
is	O
linearly	O
scaled	O
to	O
)	O
.	O

We	O
divided	O
the	O
training	O
set	O
into	O
two	O
equal	O
-	O
size	O
non	O
-	O
overlapping	O
subsets	O
.	O

One	O
was	O
used	O
to	O
train	O
and	O
the	O
other	O
was	O
used	O
to	O
train	O
.	O

We	O
used	O
the	O
ADAM	Method
algorithm	Method
for	O
training	O
and	O
set	O
the	O
learning	Metric
rate	Metric
to	O
0.0002	O
,	O
the	O
1st	O
momentum	O
parameter	O
to	O
0.5	O
,	O
and	O
the	O
2nd	O
momentum	O
parameter	O
to	O
0.999	O
as	O
suggested	O
in	O
.	O

The	O
mini	O
-	O
batch	O
size	O
was	O
128	O
.	O

We	O
trained	O
the	O
CoGAN	Method
for	O
25000	O
iterations	O
.	O

These	O
hyperparameters	O
were	O
fixed	O
for	O
all	O
the	O
visualization	Task
experiments	Task
.	O

The	O
CoGAN	Method
learning	O
results	O
are	O
shown	O
in	O
Figure	O
[	O
reference	O
]	O
.	O

We	O
found	O
that	O
although	O
the	O
CoGAN	Method
was	O
trained	O
without	O
corresponding	O
images	O
,	O
it	O
learned	O
to	O
render	O
corresponding	O
ones	O
for	O
both	O
Task	O
and	O
.	O

This	O
was	O
due	O
to	O
the	O
weight	O
-	O
sharing	O
constraint	O
imposed	O
to	O
the	O
layers	O
that	O
were	O
responsible	O
for	O
decoding	Task
high	Task
-	Task
level	Task
semantics	Task
.	O

Exploiting	O
the	O
correspondence	O
between	O
the	O
two	O
domains	O
allowed	O
and	O
to	O
utilize	O
more	O
capacity	O
in	O
the	O
networks	O
to	O
better	O
fit	O
the	O
training	O
data	O
.	O

Without	O
the	O
weight	O
-	O
sharing	O
constraint	O
,	O
the	O
two	O
GANs	Method
just	O
generated	O
two	O
unrelated	O
images	O
in	O
the	O
two	O
domains	O
.	O

Weight	Method
Sharing	Method
:	O
We	O
varied	O
the	O
numbers	O
of	O
weight	O
-	O
sharing	O
layers	O
in	O
the	O
generative	Method
and	Method
discriminative	Method
models	Method
to	O
create	O
different	O
CoGANs	O
for	O
analyzing	O
the	O
weight	O
-	O
sharing	O
effect	O
for	O
both	O
tasks	O
.	O

Due	O
to	O
lack	O
of	O
proper	O
validation	O
methods	O
,	O
we	O
did	O
a	O
grid	Method
search	Method
on	O
the	O
training	O
iteration	O
hyperparameter	O
and	O
reported	O
the	O
best	O
performance	O
achieved	O
by	O
each	O
network	O
.	O

For	O
quantifying	O
the	O
performance	O
,	O
we	O
transformed	O
the	O
image	O
generated	O
by	O
to	O
the	O
2nd	O
domain	O
using	O
the	O
same	O
method	O
employed	O
for	O
generating	O
the	O
training	O
images	O
in	O
the	O
2nd	O
domain	O
.	O

We	O
then	O
compared	O
the	O
transformed	O
image	O
with	O
the	O
image	O
generated	O
by	O
.	O

A	O
perfect	O
joint	Method
distribution	Method
learning	Method
should	O
render	O
two	O
identical	O
images	O
.	O

Hence	O
,	O
we	O
used	O
the	O
ratios	O
of	O
agreed	O
pixels	O
between	O
10	O
K	O
pairs	O
of	O
images	O
generated	O
by	O
each	O
network	O
(	O
10	O
K	O
randomly	O
sampled	O
)	O
as	O
the	O
performance	Metric
metric	Metric
.	O

We	O
trained	O
each	O
network	O
5	O
times	O
with	O
different	O
initialization	O
weights	O
and	O
reported	O
the	O
average	O
pixel	Metric
agreement	Metric
ratios	Metric
over	O
the	O
5	O
trials	O
for	O
each	O
network	O
.	O

The	O
results	O
are	O
shown	O
in	O
Figure	O
[	O
reference	O
]	O
.	O

We	O
observed	O
that	O
the	O
performance	O
was	O
positively	O
correlated	O
with	O
the	O
number	O
of	O
weight	O
-	O
sharing	O
layers	O
in	O
the	O
generative	Method
models	Method
.	O

With	O
more	O
sharing	O
layers	O
in	O
the	O
generative	Method
models	Method
,	O
the	O
rendered	O
pairs	O
of	O
images	O
resembled	O
true	O
pairs	O
drawn	O
from	O
the	O
joint	O
distribution	O
more	O
.	O

We	O
also	O
noted	O
that	O
the	O
performance	O
was	O
uncorrelated	O
to	O
the	O
number	O
of	O
weight	O
-	O
sharing	O
layers	O
in	O
the	O
discriminative	Method
models	Method
.	O

However	O
,	O
we	O
still	O
preferred	O
discriminator	Method
weight	Method
-	Method
sharing	Method
because	O
this	O
reduces	O
the	O
total	O
number	O
of	O
network	O
parameters	O
.	O

Comparison	O
with	O
Conditional	Method
GANs	Method
:	O
We	O
compared	O
the	O
CoGAN	Method
with	O
the	O
conditional	Method
GANs	Method
.	O

We	O
designed	O
a	O
conditional	O
GAN	Method
with	O
the	O
generative	Method
and	Method
discriminative	Method
models	Method
identical	O
to	O
those	O
in	O
the	O
CoGAN	Method
.	O

The	O
only	O
difference	O
was	O
the	O
conditional	O
GAN	Method
took	O
an	O
additional	O
binary	O
variable	O
as	O
input	O
,	O
which	O
controlled	O
the	O
domain	O
of	O
the	O
output	O
image	O
.	O

When	O
the	O
binary	O
variable	O
was	O
0	O
,	O
it	O
generated	O
an	O
image	O
resembling	O
images	O
in	O
the	O
1st	O
domain	O
;	O
otherwise	O
,	O
it	O
generated	O
an	O
image	O
resembling	O
images	O
in	O
the	O
2nd	O
domain	O
.	O

Similarly	O
,	O
no	O
pairs	O
of	O
corresponding	O
images	O
were	O
given	O
during	O
the	O
conditional	O
GAN	Method
training	O
.	O

We	O
applied	O
the	O
conditional	O
GAN	Method
to	O
both	O
Task	O
and	O
and	O
hoped	O
to	O
empirically	O
answer	O
whether	O
a	O
conditional	Method
model	Method
can	O
be	O
used	O
to	O
learn	O
to	O
render	O
corresponding	O
images	O
with	O
correspondence	O
supervision	O
.	O

The	O
pixel	Metric
agreement	Metric
ratio	Metric
was	O
used	O
as	O
the	O
performance	Metric
metric	Metric
.	O

The	O
experiment	O
results	O
showed	O
that	O
for	O
Task	Task
,	O
CoGAN	Method
achieved	O
an	O
average	Metric
ratio	Metric
of	O
0.952	Metric
,	O
outperforming	O
0.909	O
achieved	O
by	O
the	O
conditional	O
GAN	Method
.	O

For	O
Task	O
,	O
CoGAN	Method
achieved	O
a	O
score	O
of	O
0.967	O
,	O
which	O
was	O
much	O
better	O
than	O
0.778	O
achieved	O
by	O
the	O
conditional	O
GAN	Method
.	O

The	O
conditional	O
GAN	Method
just	O
generated	O
two	O
different	O
digits	O
with	O
the	O
same	O
random	O
noise	O
input	O
but	O
different	O
binary	O
variable	O
values	O
.	O

These	O
results	O
showed	O
that	O
the	O
conditional	Method
model	Method
failed	O
to	O
learn	O
a	O
joint	O
distribution	O
from	O
samples	O
drawn	O
from	O
the	O
marginal	O
distributions	O
.	O

We	O
note	O
that	O
for	O
the	O
case	O
that	O
the	O
supports	O
of	O
the	O
two	O
domains	O
are	O
different	O
such	O
as	O
the	O
color	O
and	O
depth	O
image	O
domains	O
,	O
the	O
conditional	Method
model	Method
can	O
not	O
even	O
be	O
applied	O
.	O

Faces	Material
:	O
We	O
applied	O
CoGAN	Method
to	O
learn	O
a	O
joint	O
distribution	O
of	O
face	O
images	O
with	O
different	O
.	O

We	O
trained	O
several	O
CoGANs	Method
,	O
each	O
for	O
generating	O
a	O
face	O
with	O
an	O
attribute	O
and	O
a	O
corresponding	O
face	O
without	O
the	O
attribute	O
.	O

We	O
used	O
the	O
CelebFaces	Material
Attributes	Material
dataset	Material
for	O
the	O
experiments	O
.	O

The	O
dataset	O
covered	O
large	O
pose	O
variations	O
and	O
background	O
clutters	O
.	O

Each	O
face	O
image	O
had	O
several	O
attributes	O
,	O
including	O
blond	O
hair	O
,	O
smiling	O
,	O
and	O
eyeglasses	O
.	O

The	O
face	O
images	O
with	O
an	O
attribute	O
constituted	O
the	O
1st	O
domain	O
;	O
and	O
those	O
without	O
the	O
attribute	O
constituted	O
the	O
2nd	O
domain	O
.	O

No	O
corresponding	O
face	O
images	O
between	O
the	O
two	O
domains	O
was	O
given	O
.	O

We	O
resized	O
the	O
images	O
to	O
a	O
resolution	O
of	O
and	O
randomly	O
sampled	O
regions	O
for	O
training	O
.	O

The	O
generative	Method
and	Method
discriminative	Method
models	Method
were	O
both	O
7	O
layer	O
deep	O
convolutional	Method
neural	O
networks	O
.	O

The	O
experiment	O
results	O
are	O
shown	O
in	O
Figure	O
[	O
reference	O
]	O
.	O

We	O
randomly	O
sampled	O
two	O
points	O
in	O
the	O
100	O
-	O
dimensional	O
input	O
noise	O
space	O
and	O
visualized	O
the	O
rendered	O
face	O
images	O
as	O
traveling	O
from	O
one	O
pint	O
to	O
the	O
other	O
.	O

We	O
found	O
CoGAN	Method
generated	O
pairs	O
of	O
corresponding	O
faces	O
,	O
resembling	O
those	O
from	O
the	O
same	O
person	O
with	O
and	O
without	O
an	O
attribute	O
.	O

As	O
traveling	O
in	O
the	O
space	O
,	O
the	O
faces	O
gradually	O
change	O
from	O
one	O
person	O
to	O
another	O
.	O

Such	O
deformations	O
were	O
consistent	O
for	O
both	O
domains	O
.	O

Note	O
that	O
it	O
is	O
difficult	O
to	O
create	O
a	O
dataset	O
with	O
corresponding	O
images	O
for	O
some	O
attribute	O
such	O
as	O
blond	O
hair	O
since	O
the	O
subjects	O
have	O
to	O
color	O
their	O
hair	O
.	O

It	O
is	O
more	O
ideal	O
to	O
have	O
an	O
approach	O
that	O
does	O
not	O
require	O
corresponding	O
images	O
like	O
CoGAN	Method
.	O

We	O
also	O
noted	O
that	O
the	O
number	O
of	O
faces	O
with	O
an	O
attribute	O
was	O
often	O
several	O
times	O
smaller	O
than	O
that	O
without	O
the	O
attribute	O
in	O
the	O
dataset	O
.	O

However	O
,	O
CoGAN	Method
learning	O
was	O
not	O
hindered	O
by	O
the	O
mismatches	O
.	O

Color	Material
and	Material
Depth	Material
Images	Material
:	O
We	O
used	O
the	O
RGBD	Material
dataset	Material
and	O
the	O
NYU	Material
dataset	Material
for	O
learning	Task
joint	Task
distribution	Task
of	Task
color	O
and	O
depth	O
images	O
.	O

The	O
RGBD	Material
dataset	Material
contains	O
registered	O
color	O
and	O
depth	O
images	O
of	O
300	O
objects	O
captured	O
by	O
the	O
Kinect	O
sensor	O
from	O
different	O
view	O
points	O
.	O

We	O
partitioned	O
the	O
dataset	O
into	O
two	O
equal	O
-	O
size	O
non	O
-	O
overlapping	O
subsets	O
.	O

The	O
color	O
images	O
in	O
the	O
1st	O
subset	O
were	O
used	O
for	O
training	O
,	O
while	O
the	O
depth	O
images	O
in	O
the	O
2nd	O
subset	O
were	O
used	O
for	O
training	O
.	O

There	O
were	O
no	O
corresponding	O
depth	O
and	O
color	O
images	O
in	O
the	O
two	O
subsets	O
.	O

The	O
images	O
in	O
the	O
RGBD	Material
dataset	Material
have	O
different	O
resolutions	O
.	O

We	O
resized	O
them	O
to	O
a	O
fixed	O
resolution	O
of	O
.	O

The	O
NYU	Material
dataset	Material
contains	O
color	O
and	O
depth	O
images	O
captured	O
from	O
indoor	O
scenes	O
using	O
the	O
Kinect	O
sensor	O
.	O

We	O
used	O
the	O
1449	O
processed	O
depth	O
images	O
for	O
the	O
depth	O
domain	O
.	O

The	O
training	O
images	O
for	O
the	O
color	O
domain	O
were	O
from	O
all	O
the	O
color	O
images	O
in	O
the	O
raw	O
dataset	O
except	O
for	O
those	O
registered	O
with	O
the	O
processed	O
depth	O
images	O
.	O

We	O
resized	O
both	O
the	O
depth	O
and	O
color	O
images	O
to	O
a	O
resolution	O
of	O
and	O
randomly	O
cropped	O
patches	O
for	O
training	O
.	O

Figure	O
[	O
reference	O
]	O
showed	O
the	O
generation	O
results	O
.	O

We	O
found	O
the	O
rendered	O
color	O
and	O
depth	O
images	O
resembled	O
corresponding	O
RGB	Material
and	O
depth	O
image	O
pairs	O
despite	O
of	O
no	O
registered	O
images	O
existed	O
in	O
the	O
two	O
domains	O
in	O
the	O
training	O
set	O
.	O

The	O
CoGAN	Method
recovered	O
the	O
appearance	O
–	O
depth	O
correspondence	O
unsupervisedly	O
.	O

section	O
:	O
Applications	O
In	O
addition	O
to	O
rendering	O
novel	O
pairs	O
of	O
corresponding	O
images	O
for	O
movie	Task
and	Task
game	Task
production	Task
,	O
the	O
CoGAN	Method
finds	O
applications	O
in	O
the	O
unsupervised	O
domain	O
adaptation	O
and	O
image	Task
transformation	Task
tasks	O
.	O

Unsupervised	Method
Domain	Method
Adaptation	Method
(	O
UDA	Method
)	O
:	O
UDA	Method
concerns	O
adapting	O
a	O
classifier	Method
trained	O
in	O
one	O
domain	O
to	O
classify	O
samples	O
in	O
a	O
new	O
domain	O
where	O
there	O
is	O
no	O
labeled	O
example	O
in	O
the	O
new	O
domain	O
for	O
re	O
-	O
training	O
the	O
classifier	Method
.	O

Early	O
works	O
have	O
explored	O
ideas	O
from	O
subspace	Method
learning	Method
to	O
deep	Method
discriminative	Method
network	Method
learning	Method
.	O

We	O
show	O
that	O
CoGAN	Method
can	O
be	O
applied	O
to	O
the	O
UDA	Task
problem	Task
.	O

We	O
studied	O
the	O
problem	O
of	O
adapting	O
a	O
digit	Method
classifier	Method
from	O
the	O
MNIST	Material
dataset	Material
to	O
the	O
USPS	Material
dataset	Material
.	O

Due	O
to	O
domain	O
shift	O
,	O
a	O
classifier	Method
trained	O
using	O
one	O
dataset	O
achieves	O
poor	O
performance	O
in	O
the	O
other	O
.	O

We	O
followed	O
the	O
experiment	O
protocol	O
in	O
,	O
which	O
randomly	O
samples	O
2000	O
images	O
from	O
the	O
MNIST	Material
dataset	Material
,	O
denoted	O
as	O
,	O
and	O
1800	O
images	O
from	O
the	O
USPS	Material
dataset	Material
,	O
denoted	O
as	O
,	O
to	O
define	O
an	O
UDA	Task
problem	Task
.	O

The	O
USPS	Material
digits	Material
have	O
a	O
different	O
resolution	O
.	O

We	O
resized	O
them	O
to	O
have	O
the	O
same	O
resolution	O
as	O
the	O
MNIST	Material
digits	Material
.	O

We	O
employed	O
the	O
CoGAN	Method
used	O
for	O
the	O
digit	Task
generation	Task
task	Task
.	O

For	O
classifying	Task
digits	Task
,	O
we	O
attached	O
a	O
softmax	O
layer	O
to	O
the	O
last	O
hidden	O
layer	O
of	O
the	O
discriminative	Method
models	Method
.	O

We	O
trained	O
the	O
CoGAN	Method
by	O
jointly	O
solving	O
the	O
digit	Task
classification	Task
problem	Task
in	O
the	O
MNIST	Material
domain	Material
which	O
used	O
the	O
images	O
and	O
labels	O
in	O
and	O
the	O
CoGAN	Method
learning	O
problem	O
which	O
used	O
the	O
images	O
in	O
both	O
and	O
.	O

This	O
produced	O
two	O
classifiers	Method
:	O
for	O
MNIST	Method
and	O
for	O
USPS	Method
.	O

No	O
label	O
information	O
in	O
was	O
used	O
.	O

Note	O
that	O
and	O
due	O
to	O
weight	O
sharing	O
and	O
denotes	O
the	O
softmax	Method
layer	Method
.	O

We	O
then	O
applied	O
to	O
classify	O
digits	O
in	O
the	O
USPS	Material
dataset	Material
.	O

The	O
classifier	Method
adaptation	Method
from	O
USPS	Method
to	O
MNIST	Task
can	O
be	O
achieved	O
in	O
the	O
same	O
way	O
.	O

The	O
learning	Method
hyperparameters	Method
were	O
determined	O
via	O
a	O
validation	O
set	O
.	O

We	O
reported	O
the	O
average	O
accuracy	Metric
over	O
5	O
trails	O
with	O
different	O
randomly	O
selected	O
and	O
.	O

Table	O
[	O
reference	O
]	O
reports	O
the	O
performance	O
of	O
the	O
proposed	O
CoGAN	Method
approach	O
with	O
comparison	O
to	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
methods	O
for	O
the	O
UDA	Task
task	Task
.	O

The	O
results	O
for	O
the	O
other	O
methods	O
were	O
duplicated	O
from	O
.	O

We	O
observed	O
that	O
CoGAN	Method
significantly	O
outperformed	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
methods	O
.	O

It	O
improved	O
the	O
accuracy	Metric
from	O
0.64	O
to	O
0.90	O
,	O
which	O
translates	O
to	O
a	O
72	O
%	O
error	Metric
reduction	Metric
rate	Metric
.	O

Cross	Task
-	Task
Domain	Task
Image	Task
Transformation	Task
:	O
Let	O
be	O
an	O
image	O
in	O
the	O
1st	O
domain	O
.	O

Cross	O
-	O
domain	O
image	Task
transformation	Task
is	O
about	O
finding	O
the	O
corresponding	O
image	O
in	O
the	O
2nd	O
domain	O
,	O
,	O
such	O
that	O
the	O
joint	O
probability	O
density	O
,	O
,	O
is	O
maximized	O
.	O

Let	O
be	O
a	O
loss	O
function	O
measuring	O
difference	O
between	O
two	O
images	O
.	O

Given	O
and	O
,	O
the	O
transformation	O
can	O
be	O
achieved	O
by	O
first	O
finding	O
the	O
random	O
vector	O
that	O
generates	O
the	O
query	O
image	O
in	O
the	O
1st	O
domain	O
After	O
finding	O
,	O
one	O
can	O
apply	O
to	O
obtain	O
the	O
transformed	O
image	O
,	O
.	O

In	O
Figure	O
[	O
reference	O
]	O
,	O
we	O
show	O
several	O
CoGAN	Method
cross	O
-	O
domain	O
transformation	O
results	O
,	O
computed	O
by	O
using	O
the	O
Euclidean	Method
loss	Method
function	Method
and	O
the	O
L	Method
-	Method
BFGS	Method
optimization	Method
algorithm	Method
.	O

We	O
found	O
the	O
transformation	O
was	O
successful	O
when	O
the	O
input	O
image	O
was	O
covered	O
by	O
(	O
The	O
input	O
image	O
can	O
be	O
generated	O
by	O
.	O

)	O
but	O
generated	O
blurry	O
images	O
when	O
it	O
is	O
not	O
the	O
case	O
.	O

To	O
improve	O
the	O
coverage	O
,	O
we	O
hypothesize	O
that	O
more	O
training	O
images	O
and	O
a	O
better	O
objective	Metric
function	Metric
are	O
required	O
,	O
which	O
are	O
left	O
as	O
future	O
work	O
.	O

Cross	O
-	O
domain	O
image	Task
transformation	Task
.	O

For	O
each	O
pair	O
,	O
left	O
is	O
the	O
input	O
;	O
right	O
is	O
the	O
transformed	O
image	O
.	O

section	O
:	O
Related	O
Work	O
Neural	Method
generative	Method
models	Method
has	O
recently	O
received	O
an	O
increasing	O
amount	O
of	O
attention	O
.	O

Several	O
approaches	O
,	O
including	O
generative	Method
adversarial	Method
networks	Method
,	O
variational	Method
autoencoders	Method
(	O
VAE	Method
)	O
,	O
attention	Method
models	Method
,	O
moment	Method
matching	Method
,	O
stochastic	Method
back	Method
-	Method
propagation	Method
,	O
and	O
diffusion	Method
processes	Method
,	O
have	O
shown	O
that	O
a	O
deep	Method
network	Method
can	O
learn	O
an	O
image	O
distribution	O
from	O
samples	O
.	O

The	O
learned	Method
networks	Method
can	O
be	O
used	O
to	O
generate	O
novel	O
images	O
.	O

Our	O
work	O
was	O
built	O
on	O
.	O

However	O
,	O
we	O
studied	O
a	O
different	O
problem	O
,	O
the	O
problem	O
of	O
learning	O
a	O
joint	Task
distribution	Task
of	Task
multi	Task
-	Task
domain	Task
images	Task
.	O

We	O
were	O
interested	O
in	O
whether	O
a	O
joint	O
distribution	O
of	O
images	O
in	O
different	O
domains	O
can	O
be	O
learned	O
from	O
samples	O
drawn	O
separately	O
from	O
its	O
marginal	O
distributions	O
of	O
the	O
individual	O
domains	O
.	O

We	O
showed	O
its	O
achievable	O
via	O
the	O
proposed	O
CoGAN	Method
framework	O
.	O

Note	O
that	O
our	O
work	O
is	O
different	O
to	O
the	O
Attribute2Image	Task
work	Task
,	O
which	O
is	O
based	O
on	O
a	O
conditional	O
VAE	Method
model	O
.	O

The	O
conditional	Method
model	Method
can	O
be	O
used	O
to	O
generate	O
images	O
of	O
different	O
styles	O
,	O
but	O
they	O
are	O
unsuitable	O
for	O
generating	O
images	O
in	O
two	O
different	O
domains	O
such	O
as	O
color	O
and	O
depth	O
image	O
domains	O
.	O

Following	O
,	O
several	O
works	O
improved	O
the	O
image	Metric
generation	Metric
quality	Metric
of	O
GAN	Method
,	O
including	O
a	O
Laplacian	Method
pyramid	Method
implementation	Method
,	O
a	O
deeper	Method
architecture	Method
,	O
and	O
conditional	Method
models	Method
.	O

Our	O
work	O
extended	O
GAN	Method
to	O
dealing	O
with	O
joint	O
distributions	O
of	O
images	O
.	O

Our	O
work	O
is	O
related	O
to	O
the	O
prior	O
works	O
in	O
multi	Task
-	Task
modal	Task
learning	Task
,	O
including	O
joint	Method
embedding	Method
space	Method
learning	Method
and	O
multi	Method
-	Method
modal	Method
Boltzmann	Method
machines	Method
.	O

These	O
approaches	O
can	O
be	O
used	O
for	O
generating	O
corresponding	O
samples	O
in	O
different	O
domains	O
only	O
when	O
correspondence	O
annotations	O
are	O
given	O
during	O
training	O
.	O

The	O
same	O
limitation	O
is	O
also	O
applied	O
to	O
dictionary	Method
learning	Method
-	Method
based	Method
approaches	Method
.	O

Our	O
work	O
is	O
also	O
related	O
to	O
the	O
prior	O
works	O
in	O
cross	Task
-	Task
domain	Task
image	Task
generation	Task
,	O
which	O
studied	O
transforming	O
an	O
image	O
in	O
one	O
style	O
to	O
the	O
corresponding	O
images	O
in	O
another	O
style	O
.	O

However	O
,	O
we	O
focus	O
on	O
learning	O
the	O
joint	O
distribution	O
in	O
an	O
unsupervised	Task
fashion	Task
,	O
while	O
focus	O
on	O
learning	O
a	O
transformation	O
function	O
directly	O
in	O
a	O
supervised	Method
fashion	Method
.	O

section	O
:	O
Conclusion	O
We	O
presented	O
the	O
CoGAN	Method
framework	O
for	O
learning	O
a	O
joint	Task
distribution	Task
of	Task
multi	Task
-	Task
domain	Task
images	Task
.	O

We	O
showed	O
that	O
via	O
enforcing	O
a	O
simple	O
weight	O
-	O
sharing	O
constraint	O
to	O
the	O
layers	O
that	O
are	O
responsible	O
for	O
decoding	Task
abstract	Task
semantics	Task
,	O
the	O
CoGAN	Method
learned	O
the	O
joint	O
distribution	O
of	O
images	O
by	O
just	O
using	O
samples	O
drawn	O
separately	O
from	O
the	O
marginal	O
distributions	O
.	O

In	O
addition	O
to	O
convincing	O
image	Task
generation	Task
results	O
on	O
faces	O
and	O
RGBD	Material
images	Material
,	O
we	O
also	O
showed	O
promising	O
results	O
of	O
the	O
CoGAN	Method
framework	O
for	O
the	O
image	Task
transformation	Task
and	O
unsupervised	Task
domain	Task
adaptation	Task
tasks	Task
.	O

bibliography	O
:	O
References	O
appendix	O
:	O
Additional	O
Experiment	O
Results	O
subsection	O
:	O
Rotation	O
We	O
applied	O
CoGAN	Method
to	O
a	O
task	O
of	O
learning	O
a	O
joint	Task
distribution	Task
of	Task
images	Task
with	O
different	O
in	O
-	O
plane	O
rotation	O
angles	O
.	O

We	O
note	O
that	O
this	O
task	O
is	O
very	O
different	O
to	O
the	O
other	O
tasks	O
discussed	O
in	O
the	O
paper	O
.	O

In	O
the	O
other	O
tasks	O
,	O
the	O
image	O
contents	O
in	O
the	O
same	O
spatial	O
region	O
in	O
the	O
corresponding	O
images	O
are	O
in	O
direct	O
correspondence	O
.	O

In	O
this	O
task	O
,	O
the	O
content	O
in	O
one	O
spatial	O
region	O
in	O
one	O
image	O
domain	O
is	O
related	O
to	O
the	O
content	O
in	O
a	O
different	O
spatial	O
region	O
in	O
the	O
other	O
image	O
domain	O
.	O

Through	O
this	O
experiment	O
,	O
we	O
planed	O
to	O
verify	O
whether	O
CoGAN	Method
can	O
learn	O
a	O
joint	O
distribution	O
of	O
images	O
related	O
by	O
a	O
global	O
transformation	O
.	O

For	O
this	O
task	O
,	O
we	O
partitioned	O
the	O
MNIST	Material
training	Material
set	Material
into	O
two	O
disjoint	O
subsets	O
.	O

The	O
first	O
set	O
consisted	O
of	O
the	O
original	O
digit	O
images	O
,	O
which	O
constitute	O
the	O
first	O
domain	O
.	O

We	O
applied	O
a	O
90	O
degree	O
rotation	O
to	O
all	O
the	O
digits	O
in	O
the	O
second	O
set	O
to	O
construct	O
the	O
second	O
domain	O
.	O

There	O
were	O
no	O
corresponding	O
images	O
in	O
the	O
two	O
domains	O
.	O

The	O
CoGAN	Method
architecture	O
used	O
for	O
this	O
task	O
is	O
shown	O
in	O
Table	O
[	O
reference	O
]	O
.	O

Different	O
to	O
the	O
other	O
tasks	O
,	O
the	O
generative	Method
models	Method
in	O
the	O
CoGAN	Method
were	O
based	O
on	O
fully	Method
connected	Method
layers	Method
,	O
and	O
the	O
discriminative	Method
models	Method
only	O
share	O
the	O
last	O
layer	O
.	O

This	O
design	O
was	O
due	O
to	O
lack	O
of	O
spatial	O
correspondence	O
between	O
the	O
two	O
domains	O
.	O

We	O
used	O
the	O
same	O
hyperparameters	O
to	O
train	O
the	O
CoGAN	Method
.	O

The	O
results	O
are	O
shown	O
in	O
Figure	O
[	O
reference	O
]	O
.	O

We	O
found	O
that	O
the	O
CoGAN	Method
was	O
able	O
to	O
capture	O
the	O
in	Task
-	Task
plane	Task
rotation	Task
.	O

For	O
the	O
same	O
noise	O
input	O
,	O
the	O
digit	O
generated	O
by	O
is	O
a	O
90	O
degree	O
rotated	O
version	O
of	O
the	O
digit	O
generated	O
by	O
.	O

subsection	O
:	O
Weight	Method
Sharing	Method
We	O
analyzed	O
the	O
effect	O
of	O
weight	O
sharing	O
in	O
the	O
CoGAN	Method
framework	O
.	O

We	O
conducted	O
an	O
experiment	O
where	O
we	O
varied	O
the	O
numbers	O
of	O
weight	O
-	O
sharing	O
layers	O
in	O
the	O
generative	Method
and	Method
discriminative	Method
models	Method
to	O
create	O
different	O
CoGAN	Method
architectures	O
and	O
trained	O
them	O
with	O
the	O
same	O
hyperparameters	O
.	O

Due	O
to	O
lack	O
of	O
proper	O
validation	Method
methods	Method
,	O
we	O
did	O
a	O
grid	Method
search	Method
on	O
the	O
training	O
iteration	O
and	O
reported	O
the	O
best	O
performance	O
achieved	O
by	O
each	O
network	Method
configuration	Method
for	O
both	O
Task	O
and	O
.	O

For	O
each	O
network	Method
architecture	Method
,	O
we	O
run	O
5	O
trails	O
with	O
different	O
random	O
network	O
initialization	O
weights	O
.	O

We	O
then	O
rendered	O
10000	O
pairs	O
of	O
images	O
for	O
each	O
learned	Method
network	Method
.	O

A	O
pair	O
of	O
images	O
consisted	O
of	O
an	O
image	O
in	O
the	O
first	O
domain	O
(	O
generated	O
by	O
)	O
and	O
an	O
image	O
in	O
the	O
second	O
domain	O
(	O
generated	O
by	O
)	O
,	O
which	O
were	O
rendered	O
using	O
the	O
same	O
.	O

For	O
quantifying	O
the	O
performance	O
of	O
each	O
weight	Method
-	Method
sharing	Method
scheme	Method
,	O
we	O
transformed	O
the	O
images	O
generated	O
by	O
to	O
the	O
second	O
domain	O
by	O
using	O
the	O
same	O
method	O
employed	O
for	O
generating	O
the	O
training	O
images	O
in	O
the	O
second	O
domain	O
.	O

We	O
then	O
compared	O
the	O
transformed	O
images	O
with	O
the	O
images	O
generated	O
by	O
.	O

The	O
performance	O
was	O
measured	O
by	O
the	O
average	O
of	O
the	O
ratios	O
of	O
agreed	O
pixels	O
between	O
the	O
transformed	O
image	O
and	O
the	O
corresponding	O
image	O
in	O
the	O
other	O
domain	O
.	O

Specifically	O
,	O
we	O
rounded	O
the	O
transformed	O
digit	O
image	O
to	O
a	O
binary	O
image	O
and	O
we	O
also	O
rounded	O
the	O
rendered	O
image	O
in	O
the	O
second	O
domain	O
to	O
a	O
binary	O
image	O
.	O

We	O
then	O
compared	O
the	O
pixel	Metric
agreement	Metric
ratio	Metric
—	O
the	O
number	O
of	O
corresponding	O
pixels	O
that	O
have	O
the	O
same	O
value	O
in	O
the	O
two	O
images	O
divided	O
by	O
the	O
total	O
image	O
size	O
.	O

The	O
performance	O
of	O
a	O
trail	O
was	O
given	O
by	O
the	O
pixel	Metric
agreement	Metric
ratio	Metric
of	O
the	O
10000	O
pairs	O
of	O
images	O
.	O

The	O
performance	O
of	O
a	O
network	Method
configuration	Method
was	O
given	O
by	O
the	O
average	O
pixel	Metric
agreement	Metric
ratio	Metric
over	O
the	O
5	O
trails	O
.	O

We	O
reported	O
the	O
performance	O
results	O
for	O
Task	O
in	O
Table	O
[	O
reference	O
]	O
and	O
the	O
performance	O
results	O
for	O
Task	O
in	O
Table	O
[	O
reference	O
]	O
.	O

From	O
the	O
tables	O
,	O
we	O
observed	O
that	O
the	O
pair	Task
image	Task
generation	Task
performance	O
was	O
positively	O
correlated	O
with	O
the	O
number	O
of	O
weight	O
-	O
sharing	O
layers	O
in	O
the	O
generative	Method
models	Method
.	O

With	O
more	O
shared	O
layers	O
in	O
the	O
generative	Method
models	Method
,	O
the	O
rendered	O
pairs	O
of	O
images	O
were	O
resembling	O
more	O
to	O
true	O
pairs	O
drawn	O
from	O
the	O
joint	O
distribution	O
.	O

We	O
noted	O
that	O
the	O
pair	Task
image	Task
generation	Task
performance	O
was	O
uncorrelated	O
to	O
the	O
number	O
of	O
weight	O
-	O
sharing	O
layers	O
in	O
the	O
discriminative	Method
models	Method
.	O

However	O
,	O
we	O
still	O
preferred	O
applying	O
discriminator	Method
weight	Method
sharing	Method
because	O
this	O
reduces	O
the	O
total	O
number	O
of	O
parameters	O
.	O

subsection	O
:	O
Comparison	O
with	O
the	O
Conditional	Method
Generative	Method
Adversarial	Method
Nets	Method
We	O
compared	O
the	O
CoGAN	Method
framework	O
with	O
the	O
conditional	O
generative	Method
adversarial	Method
networks	Method
(	O
GAN	Method
)	O
framework	O
for	O
joint	Task
image	Task
distribution	Task
learning	Task
.	O

We	O
designed	O
a	O
conditional	O
GAN	Method
where	O
the	O
generative	Method
and	Method
discriminative	Method
models	Method
were	O
identical	O
to	O
those	O
used	O
in	O
the	O
CoGAN	Method
in	O
the	O
digit	Task
experiments	Task
.	O

The	O
only	O
difference	O
was	O
that	O
the	O
conditional	O
GAN	Method
took	O
an	O
additional	O
binary	O
variable	O
as	O
input	O
,	O
which	O
controlled	O
the	O
domain	O
of	O
the	O
output	O
image	O
.	O

The	O
binary	O
variable	O
acted	O
as	O
a	O
switch	O
.	O

When	O
the	O
value	O
of	O
the	O
binary	O
variable	O
was	O
zero	O
,	O
it	O
generated	O
images	O
resembling	O
images	O
in	O
the	O
first	O
domain	O
.	O

Otherwise	O
,	O
it	O
generated	O
images	O
resembling	O
those	O
in	O
the	O
second	O
domain	O
.	O

The	O
output	O
layer	O
of	O
the	O
discriminative	Method
model	Method
was	O
a	O
softmax	Method
layer	Method
with	O
three	O
neurons	O
.	O

If	O
the	O
first	O
neuron	O
was	O
on	O
,	O
it	O
meant	O
the	O
input	O
to	O
the	O
discriminative	Method
model	Method
was	O
a	O
synthesized	O
image	O
from	O
the	O
generative	Method
model	Method
.	O

If	O
the	O
second	O
neuron	O
was	O
on	O
,	O
it	O
meant	O
the	O
input	O
was	O
a	O
real	O
image	O
from	O
the	O
first	O
domain	O
.	O

If	O
the	O
third	O
neuron	O
was	O
on	O
,	O
it	O
meant	O
the	O
input	O
was	O
a	O
real	O
image	O
from	O
the	O
second	O
domain	O
.	O

The	O
goal	O
of	O
the	O
generative	Method
model	Method
was	O
to	O
render	O
images	O
resembling	O
those	O
from	O
the	O
first	O
domain	O
when	O
the	O
binary	O
variable	O
was	O
zero	O
and	O
to	O
render	O
images	O
resembling	O
those	O
from	O
the	O
second	O
domain	O
when	O
the	O
binary	O
variable	O
was	O
one	O
.	O

The	O
details	O
of	O
the	O
conditional	Method
GAN	Method
network	Method
architecture	Method
is	O
shown	O
in	O
Table	O
[	O
reference	O
]	O
.	O

Similarly	O
to	O
CoGAN	Method
learning	O
,	O
no	O
correspondence	O
was	O
given	O
during	O
the	O
conditional	Method
GAN	Method
learning	Method
.	O

We	O
applied	O
the	O
conditional	O
GAN	Method
to	O
the	O
two	O
digit	Task
generation	Task
tasks	Task
and	O
hoped	O
to	O
answer	O
whether	O
a	O
conditional	Method
model	Method
can	O
be	O
used	O
to	O
render	O
corresponding	O
images	O
in	O
two	O
different	O
domains	O
without	O
pairs	O
of	O
corresponding	O
images	O
in	O
the	O
training	O
set	O
.	O

We	O
used	O
the	O
same	O
training	O
data	O
and	O
hyperparameters	O
as	O
those	O
used	O
in	O
the	O
CoGAN	Method
learning	O
.	O

We	O
trained	O
the	O
CoGAN	Method
for	O
25000	O
iterations	O
and	O
used	O
the	O
trained	O
network	O
to	O
render	O
10000	O
pairs	O
of	O
images	O
in	O
the	O
two	O
domains	O
.	O

Specifically	O
,	O
each	O
pair	O
of	O
images	O
was	O
rendered	O
with	O
the	O
same	O
but	O
with	O
different	O
conditional	O
variable	O
values	O
.	O

These	O
images	O
were	O
used	O
to	O
compute	O
the	O
pair	Task
image	Task
generation	Task
performance	O
of	O
the	O
conditional	O
GAN	Method
measured	O
by	O
the	O
average	O
of	O
the	O
pixel	Metric
agreement	Metric
ratios	Metric
.	O

For	O
each	O
task	O
,	O
we	O
trained	O
the	O
conditional	O
GAN	Method
for	O
5	O
times	O
,	O
each	O
with	O
a	O
different	O
random	O
initialization	O
of	O
the	O
network	O
weights	O
.	O

We	O
reported	O
the	O
average	O
scores	O
and	O
the	O
standard	O
deviations	O
.	O

The	O
performance	O
results	O
are	O
reported	O
in	O
Table	O
[	O
reference	O
]	O
.	O

It	O
can	O
be	O
seen	O
that	O
the	O
conditional	O
GAN	Method
achieved	O
0.909	O
for	O
Task	O
and	O
0.778	O
for	O
Task	O
,	O
respectively	O
.	O

They	O
were	O
much	O
lower	O
than	O
the	O
scores	O
of	O
0.952	O
and	O
0.967	O
achieved	O
by	O
the	O
CoGAN	Method
.	O

Figure	O
[	O
reference	O
]	O
visualized	O
the	O
conditional	O
GAN	Method
’s	O
pair	Task
generation	Task
results	O
,	O
which	O
suggested	O
that	O
the	O
conditional	O
GAN	Method
had	O
difficulties	O
in	O
learning	O
to	O
render	O
corresponding	O
images	O
in	O
two	O
different	O
domains	O
without	O
pairs	O
of	O
corresponding	O
images	O
in	O
the	O
training	O
set	O
.	O

appendix	O
:	O
CoGAN	Method
Learning	O
Algorithm	O
We	O
present	O
the	O
learning	Method
algorithm	Method
for	O
the	O
coupled	Method
generative	Method
adversarial	Method
networks	Method
in	O
Algorithm	O
[	O
reference	O
]	O
.	O

The	O
algorithm	O
is	O
an	O
extension	O
of	O
the	O
learning	Method
algorithm	Method
for	O
the	O
generative	Method
adversarial	Method
networks	Method
(	O
GAN	Method
)	O
to	O
the	O
case	O
of	O
training	O
two	O
GANs	Method
with	O
weight	O
sharing	O
constraints	O
.	O

The	O
convergence	O
property	O
follows	O
the	O
results	O
shown	O
in	O
.	O

[	O
th	O
!	O

]	O
Mini	Method
-	Method
batch	Method
stochastic	Method
gradient	Method
descent	Method
for	O
training	O
coupled	Task
generative	Task
adversarial	Task
nets	Task
.	O

[	O
1	O
]	O
Initialize	O
the	O
network	O
parameters	O
’s	O
’s	O
’s	O
and	O
’s	O
with	O
the	O
shared	O
network	O
connection	O
weights	O
set	O
to	O
the	O
same	O
values	O
.	O

Draw	O
samples	O
from	O
,	O
Draw	O
samples	O
from	O
,	O
Draw	O
samples	O
from	O
,	O
Compute	O
the	O
gradients	O
of	O
the	O
parameters	O
of	O
the	O
discriminative	Method
model	Method
,	O
,	O
;	O
Compute	O
the	O
gradients	O
of	O
the	O
parameters	O
of	O
the	O
discriminative	Method
model	Method
,	O
,	O
;	O
Average	O
the	O
gradients	O
of	O
the	O
shared	O
parameters	O
of	O
the	O
discriminative	Method
models	Method
.	O

Compute	O
and	O
according	O
to	O
the	O
gradients	O
.	O

Compute	O
the	O
gradients	O
of	O
the	O
parameters	O
of	O
the	O
generative	Method
model	Method
,	O
,	O
;	O
Compute	O
the	O
gradients	O
of	O
the	O
network	O
parameters	O
of	O
the	O
generative	Method
model	Method
,	O
,	O
;	O
Average	O
the	O
gradients	O
of	O
the	O
shared	O
parameters	O
of	O
the	O
generative	Method
models	Method
.	O

Compute	O
and	O
according	O
to	O
the	O
gradients	O
.	O

appendix	O
:	O
Training	O
Datasets	O
In	O
Figure	O
[	O
reference	O
]	O
,	O
Figure	O
[	O
reference	O
]	O
,	O
Figure	O
[	O
reference	O
]	O
,	O
and	O
Figure	O
[	O
reference	O
]	O
,	O
we	O
show	O
several	O
example	O
images	O
of	O
the	O
training	O
images	O
used	O
for	O
the	O
pair	Task
image	Task
generation	Task
tasks	Task
in	O
the	O
experiment	O
section	O
.	O

Table	O
[	O
reference	O
]	O
,	O
Table	O
[	O
reference	O
]	O
,	O
Table	O
[	O
reference	O
]	O
,	O
and	O
Table	O
[	O
reference	O
]	O
contain	O
the	O
statistics	O
of	O
the	O
training	O
datasets	O
for	O
the	O
experiments	O
.	O

appendix	O
:	O
Networks	O
In	O
CoGAN	Method
,	O
the	O
generative	Method
models	Method
are	O
based	O
on	O
the	O
fractional	Method
length	Method
convolutional	Method
(	O
FCONV	Method
)	O
layers	O
,	O
while	O
the	O
discriminative	Method
models	Method
are	O
based	O
on	O
the	O
standard	O
convolutional	Method
(	O
CONV	Method
)	O
layers	O
with	O
the	O
exceptions	O
that	O
the	O
last	O
two	O
layers	O
are	O
based	O
on	O
the	O
fully	Method
-	Method
connected	Method
(	O
FC	Method
)	O
layers	O
.	O

The	O
batch	Method
normalization	Method
(	O
BN	Method
)	O
layers	O
are	O
applied	O
after	O
each	O
convolutional	Method
layer	O
,	O
which	O
are	O
followed	O
by	O
the	O
parameterized	Method
rectified	Method
linear	Method
unit	Method
(	O
PReLU	Method
)	O
processing	O
.	O

The	O
sigmoid	Method
units	Method
and	O
the	O
hyperbolic	Method
tangent	Method
units	Method
are	O
applied	O
to	O
the	O
output	O
layers	O
of	O
the	O
generative	Method
models	Method
for	O
generating	O
images	O
with	O
desired	O
pixel	O
range	O
values	O
.	O

appendix	O
:	O
Visualization	Task
