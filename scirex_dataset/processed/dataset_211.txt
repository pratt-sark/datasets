document	O
:	O
Dynamic	Task
Integration	Task
of	Task
Background	Task
Knowledge	Task
in	O
Neural	O
NLU	Task
Systems	O
Common	O
-	O
sense	O
and	O
background	O
knowledge	O
is	O
required	O
to	O
understand	O
natural	O
language	O
,	O
but	O
in	O
most	O
neural	O
natural	Task
language	Task
understanding	Task
(	O
NLU	Task
)	O
systems	O
,	O
this	O
knowledge	O
must	O
be	O
acquired	O
from	O
training	O
corpora	O
during	O
learning	O
,	O
and	O
then	O
it	O
is	O
static	O
at	O
test	O
time	O
.	O

We	O
introduce	O
a	O
new	O
architecture	O
for	O
the	O
dynamic	Task
integration	Task
of	Task
explicit	Task
background	Task
knowledge	Task
in	O
NLU	Task
models	O
.	O

A	O
general	O
-	O
purpose	O
reading	Method
module	Method
reads	O
background	O
knowledge	O
in	O
the	O
form	O
of	O
free	O
-	O
text	O
statements	O
(	O
together	O
with	O
task	O
-	O
specific	O
text	O
inputs	O
)	O
and	O
yields	O
refined	O
word	Method
representations	Method
to	O
a	O
task	O
-	O
specific	O
NLU	Task
architecture	O
that	O
reprocesses	O
the	O
task	O
inputs	O
with	O
these	O
representations	O
.	O

Experiments	O
on	O
document	Task
question	Task
answering	Task
(	O
DQA	Task
)	O
and	O
recognizing	Task
textual	Task
entailment	Task
(	O
RTE	Task
)	O
demonstrate	O
the	O
effectiveness	O
and	O
flexibility	O
of	O
the	O
approach	O
.	O

Analysis	O
shows	O
that	O
our	O
model	O
learns	O
to	O
exploit	O
knowledge	O
in	O
a	O
semantically	O
appropriate	O
way	O
.	O

section	O
:	O
Introduction	O
Understanding	Task
natural	Task
language	Task
depends	O
crucially	O
on	O
common	O
-	O
sense	O
and	O
background	O
knowledge	O
,	O
for	O
example	O
,	O
knowledge	O
about	O
what	O
concepts	O
are	O
expressed	O
by	O
the	O
words	O
being	O
read	O
(	O
lexical	O
knowledge	O
)	O
,	O
and	O
what	O
relations	O
hold	O
between	O
these	O
concepts	O
(	O
relational	O
knowledge	O
)	O
.	O

As	O
a	O
simple	O
illustration	O
,	O
if	O
an	O
agent	O
needs	O
to	O
understand	O
that	O
the	O
statement	O
“	O
King	O
Farouk	O
signed	O
his	O
abdication	O
”	O
is	O
entailed	O
by	O
“	O
King	O
Farouk	O
was	O
exiled	O
to	O
France	O
in	O
1952	O
,	O
after	O
signing	O
his	O
resignation	O
”	O
,	O
it	O
must	O
know	O
(	O
among	O
other	O
things	O
)	O
that	O
abdication	O
means	O
resignation	O
of	O
a	O
king	O
.	O

In	O
most	O
neural	O
natural	Task
language	Task
understanding	Task
(	O
NLU	Task
)	O
systems	O
,	O
the	O
requisite	O
background	O
knowledge	O
is	O
implicitly	O
encoded	O
in	O
the	O
models	O
’	O
parameters	O
.	O

That	O
is	O
,	O
what	O
background	O
knowledge	O
is	O
present	O
has	O
been	O
learned	O
from	O
task	Task
supervision	Task
and	O
also	O
by	O
pre	O
-	O
training	O
word	Method
embeddings	Method
(	O
where	O
distributional	O
properties	O
correlate	O
with	O
certain	O
kinds	O
of	O
useful	O
background	O
knowledge	O
,	O
such	O
as	O
semantic	O
relatedness	O
)	O
.	O

However	O
,	O
acquisition	O
of	O
background	O
knowledge	O
from	O
static	O
training	O
corpora	O
is	O
limiting	O
for	O
two	O
reasons	O
.	O

First	O
,	O
it	O
is	O
unreasonable	O
to	O
expect	O
that	O
all	O
background	O
knowledge	O
that	O
could	O
be	O
important	O
for	O
solving	O
an	O
NLU	Task
task	O
can	O
be	O
extracted	O
from	O
a	O
limited	O
amount	O
of	O
training	O
data	O
.	O

Second	O
,	O
as	O
the	O
world	O
changes	O
,	O
the	O
facts	O
that	O
may	O
influence	O
how	O
a	O
text	O
is	O
understood	O
will	O
likewise	O
change	O
.	O

In	O
short	O
:	O
building	O
suitably	O
large	O
corpora	O
to	O
capture	O
all	O
relevant	O
information	O
,	O
and	O
keeping	O
the	O
corpus	O
and	O
derived	O
models	O
up	O
to	O
date	O
with	O
changes	O
to	O
the	O
world	O
would	O
be	O
impractical	O
.	O

In	O
this	O
paper	O
,	O
we	O
develop	O
a	O
new	O
architecture	O
for	O
dynamically	Task
incorporating	Task
external	Task
background	Task
knowledge	Task
in	O
NLU	Task
models	O
.	O

Rather	O
than	O
relying	O
only	O
on	O
static	O
knowledge	O
implicitly	O
present	O
in	O
the	O
training	O
data	O
,	O
supplementary	O
knowledge	O
is	O
retrieved	O
from	O
external	O
knowledge	O
sources	O
(	O
in	O
this	O
paper	O
,	O
ConceptNet	Material
and	O
Wikipedia	Material
)	O
to	O
assist	O
with	O
understanding	O
text	O
inputs	O
.	O

Since	O
NLU	Task
systems	O
must	O
already	O
read	O
and	O
understand	O
text	O
inputs	O
,	O
we	O
assume	O
that	O
background	O
knowledge	O
will	O
likewise	O
be	O
provided	O
in	O
text	O
form	O
(	O
§	O
[	O
reference	O
]	O
)	O
.	O

The	O
retrieved	O
supplementary	O
texts	O
are	O
read	O
together	O
with	O
the	O
task	O
inputs	O
by	O
an	O
initial	O
reading	Method
module	Method
whose	O
outputs	O
are	O
contextually	O
refined	O
word	O
embeddings	O
(	O
§	O
[	O
reference	O
]	O
)	O
.	O

These	O
refined	O
embeddings	O
are	O
then	O
used	O
as	O
input	O
to	O
a	O
task	O
-	O
specific	O
NLU	Task
architecture	O
(	O
any	O
architecture	O
that	O
reads	O
text	O
as	O
a	O
sequence	O
of	O
word	O
embeddings	O
can	O
be	O
used	O
here	O
)	O
.	O

The	O
initial	O
reading	Method
module	Method
and	O
the	O
task	Method
module	Method
are	O
learnt	O
jointly	O
,	O
end	O
-	O
to	O
-	O
end	O
.	O

We	O
experiment	O
with	O
several	O
different	O
datasets	O
on	O
the	O
tasks	O
of	O
document	Task
question	Task
answering	Task
(	O
DQA	Task
)	O
and	O
recognizing	Task
textual	Task
entailment	Task
(	O
RTE	Task
)	O
evaluating	O
the	O
impact	O
of	O
our	O
proposed	O
solution	O
with	O
both	O
basic	O
task	Method
architectures	Method
and	O
a	O
sophisticated	O
task	Method
architecture	Method
for	O
RTE	Task
(	O
§	O
[	O
reference	O
]	O
)	O
.	O

We	O
find	O
that	O
our	O
embedding	Method
refinement	Method
strategy	Method
is	O
effective	O
(	O
§	O
[	O
reference	O
]	O
)	O
.	O

On	O
four	O
competitive	O
benchmarks	O
,	O
we	O
show	O
that	O
refinement	Task
helps	O
.	O

First	O
,	O
simply	O
refining	O
the	O
embeddings	O
just	O
using	O
the	O
context	O
(	O
and	O
no	O
additional	O
background	O
information	O
)	O
can	O
improve	O
performance	O
significantly	O
,	O
but	O
adding	O
background	O
knowledge	O
helps	O
further	O
.	O

Our	O
results	O
are	O
competitive	O
with	O
the	O
best	O
systems	O
,	O
achieving	O
a	O
new	O
state	O
of	O
the	O
art	O
on	O
the	O
recent	O
TriviaQA	Material
benchmarks	Material
.	O

Our	O
success	O
on	O
this	O
task	O
is	O
especially	O
noteworthy	O
because	O
the	O
task	O
-	O
specific	O
architecture	O
is	O
a	O
simple	O
reading	Method
architecture	Method
,	O
in	O
particular	O
a	O
single	Method
layer	Method
BiLSTM	Method
with	O
a	O
feed	Method
-	Method
forward	Method
neural	Method
network	Method
for	O
span	Task
prediction	Task
.	O

Finally	O
,	O
we	O
provide	O
an	O
analysis	O
demonstrating	O
that	O
our	O
systems	O
are	O
able	O
to	O
exploit	O
background	O
knowledge	O
in	O
a	O
semantically	O
appropriate	O
manner	O
(	O
§	O
[	O
reference	O
]	O
)	O
.	O

It	O
includes	O
,	O
for	O
instance	O
,	O
an	O
experiment	O
showing	O
that	O
our	O
system	O
is	O
capable	O
of	O
making	O
appropriate	O
counterfactual	O
inferences	O
when	O
provided	O
with	O
“	O
alternative	O
facts	O
”	O
.	O

section	O
:	O
External	O
Knowledge	O
as	O
Supplementary	O
Text	O
Inputs	O
Knowledge	O
resources	O
make	O
information	O
that	O
could	O
potentially	O
be	O
useful	O
for	O
improving	O
NLU	Task
available	O
in	O
a	O
variety	O
different	O
formats	O
,	O
such	O
as	O
natural	O
language	O
text	O
,	O
(	O
subject	O
,	O
predicate	O
,	O
object	O
)-	O
triples	O
,	O
relational	O
databases	O
,	O
and	O
other	O
structured	O
formats	O
.	O

Rather	O
than	O
tailoring	O
our	O
solution	O
to	O
a	O
particular	O
structured	Method
representation	Method
,	O
we	O
assume	O
that	O
all	O
supplementary	O
information	O
either	O
already	O
exists	O
in	O
natural	O
language	O
statements	O
(	O
e.g.	O
,	O
encyclopedias	O
)	O
or	O
can	O
easily	O
be	O
recoded	O
as	O
natural	O
language	O
.	O

Furthermore	O
,	O
while	O
mapping	O
from	O
unstructured	Task
to	Task
structured	Task
representations	Task
is	O
hard	O
,	O
the	O
inverse	Task
problem	Task
is	O
easy	O
.	O

For	O
example	O
,	O
given	O
a	O
triple	O
we	O
can	O
construct	O
the	O
free	O
-	O
text	O
assertion	O
“	O
Abdication	Method
is	O
a	O
resignation	O
.	O

”	O
using	O
simple	O
rules	O
.	O

Finally	O
,	O
the	O
free	O
-	O
text	O
format	O
means	O
that	O
knowledge	O
that	O
exists	O
only	O
in	O
unstructured	O
text	O
form	O
such	O
as	O
encyclopedic	O
knowledge	O
(	O
e.g.	O
,	O
Wikipedia	Material
)	O
is	O
usable	O
by	O
our	O
system	O
.	O

An	O
important	O
question	O
that	O
remains	O
to	O
be	O
answered	O
is	O
:	O
given	O
some	O
text	O
that	O
is	O
to	O
be	O
understood	O
,	O
what	O
supplementary	O
knowledge	O
should	O
be	O
incorporated	O
?	O
The	O
retrieval	Task
and	Task
preparation	Task
of	Task
contextually	Task
relevant	Task
information	Task
from	O
knowledge	O
sources	O
is	O
a	O
complex	O
research	O
topic	O
by	O
itself	O
,	O
and	O
there	O
are	O
several	O
statistical	Method
Manning:2008	O
and	O
more	O
recently	O
neural	Method
approaches	Method
mitra2017neural	O
as	O
well	O
as	O
approaches	O
based	O
on	O
reinforcement	Method
learning	Method
nogueira2017	O
.	O

Rather	O
than	O
learning	O
both	O
how	O
to	O
incorporate	O
relevant	O
information	O
and	O
which	O
information	O
is	O
relevant	O
,	O
we	O
use	O
a	O
heuristic	Method
retrieval	Method
mechanism	Method
(	O
§	O
[	O
reference	O
]	O
)	O
and	O
focus	O
on	O
the	O
integration	Method
model	Method
.	O

In	O
the	O
next	O
section	O
,	O
we	O
turn	O
to	O
the	O
question	O
of	O
how	O
to	O
leverage	O
the	O
retrieved	O
supplementary	O
knowledge	O
(	O
encoded	O
as	O
text	O
)	O
in	O
a	O
NLU	Task
system	O
.	O

section	O
:	O
Refining	O
Word	Task
Embeddings	Task
by	O
Reading	O
Virtually	O
every	O
NLU	Task
task	O
—	O
from	O
document	Task
classification	Task
to	O
translation	Task
to	O
question	Task
answering	Task
—	O
should	O
in	O
theory	O
be	O
able	O
to	O
benefit	O
from	O
supplementary	O
knowledge	O
.	O

While	O
one	O
could	O
develop	O
custom	O
architectures	O
for	O
each	O
task	O
so	O
as	O
to	O
read	O
supplementary	O
inputs	O
,	O
we	O
would	O
like	O
ours	O
to	O
augment	O
any	O
existing	O
NLU	Task
task	O
architectures	O
with	O
the	O
ability	O
to	O
read	O
relevant	O
information	O
with	O
minimal	O
effort	O
.	O

To	O
realize	O
this	O
goal	O
,	O
we	O
adopt	O
the	O
strategy	O
of	O
refining	Task
word	Task
embeddings	Task
;	O
that	O
is	O
,	O
we	O
replace	O
static	Method
word	Method
embeddings	Method
with	O
embeddings	O
that	O
are	O
functions	O
of	O
the	O
task	O
inputs	O
and	O
any	O
supplementary	O
inputs	O
.	O

Word	Method
embeddings	Method
can	O
be	O
considered	O
a	O
simple	O
form	O
of	O
key	Method
-	Method
value	Method
memory	Method
stores	Method
that	O
,	O
in	O
our	O
case	O
,	O
not	O
only	O
contain	O
general	O
-	O
purpose	O
knowledge	O
(	O
as	O
in	O
typical	O
neural	O
NLU	Task
systems	O
)	O
but	O
also	O
contextual	O
information	O
(	O
including	O
background	O
knowledge	O
)	O
.	O

The	O
use	O
of	O
word	Method
-	Method
embeddings	Method
as	O
memory	O
has	O
the	O
advantage	O
that	O
it	O
is	O
transparent	O
to	O
the	O
task	O
-	O
architecture	O
which	O
kinds	O
of	O
embeddings	O
(	O
refined	O
or	O
unrefined	O
)	O
are	O
used	O
.	O

Our	O
incremental	Method
refinement	Method
process	Method
encodes	O
input	O
texts	O
followed	O
by	O
updates	O
on	O
the	O
word	Method
embedding	Method
matrix	Method
in	O
multiple	O
reading	O
steps	O
.	O

Words	O
are	O
first	O
represented	O
non	O
-	O
contextually	O
(	O
i.e.	O
,	O
standard	O
word	O
embeddings	O
)	O
,	O
which	O
can	O
be	O
conceived	O
of	O
as	O
the	O
columns	O
in	O
an	O
embedding	Method
matrix	Method
.	O

At	O
each	O
progressive	O
reading	O
step	O
,	O
a	O
new	O
embedding	O
matrix	O
is	O
constructed	O
by	O
refining	O
the	O
embeddings	O
from	O
the	O
previous	O
step	O
using	O
(	O
user	O
-	O
specified	O
)	O
contextual	O
information	O
for	O
reading	O
step	O
,	O
which	O
is	O
a	O
set	O
of	O
natural	O
language	O
sequences	O
(	O
i.e.	O
,	O
texts	O
)	O
.	O

An	O
illustration	O
of	O
our	O
incremental	Method
refinement	Method
strategy	Method
can	O
be	O
found	O
in	O
Figure	O
[	O
reference	O
]	O
.	O

In	O
the	O
following	O
,	O
we	O
define	O
this	O
procedure	O
formally	O
.	O

We	O
denote	O
the	O
hidden	O
dimensionality	O
of	O
our	O
model	O
by	O
and	O
a	O
fully	Method
-	Method
connected	Method
layer	Method
by	O
,	O
.	O

subsection	O
:	O
Unrefined	O
Word	O
Embeddings	O
(	O
)	O
The	O
first	O
representation	Method
level	Method
consists	O
of	O
non	Method
-	Method
contextual	Method
word	Method
representations	Method
,	O
that	O
is	O
,	O
word	Method
representations	Method
that	O
do	O
not	O
depend	O
on	O
any	O
input	O
;	O
these	O
can	O
be	O
conceived	O
of	O
as	O
an	O
embedding	O
matrix	O
whose	O
columns	O
are	O
indexed	O
by	O
words	O
in	O
.	O

The	O
non	Method
-	Method
contextual	Method
word	Method
representation	Method
for	O
a	O
single	O
word	O
is	O
computed	O
by	O
using	O
a	O
gated	Method
combination	Method
of	O
fixed	O
,	O
pre	O
-	O
trained	O
word	O
vectors	O
with	O
learned	O
character	Method
-	Method
based	Method
embeddings	Method
.	O

We	O
compute	O
using	O
a	O
single	Method
-	Method
layer	Method
convolutional	Method
neural	Method
network	Method
with	O
convolutional	Method
filters	Method
of	Method
width	Method
followed	O
by	O
a	O
-	Method
pooling	Method
operation	Method
over	O
time	O
Seo2017	O
,	O
Weissenborn2017	O
.	O

The	O
formal	O
definition	O
of	O
this	O
combination	O
is	O
given	O
in	O
Eq	O
.	O

[	O
reference	O
]	O
.	O

subsection	O
:	O
Refined	Task
Word	Task
Embeddings	Task
(	O
)	O
In	O
order	O
to	O
compute	O
contextually	Task
refined	Task
word	Task
embeddings	Task
given	O
prior	Method
representations	Method
we	O
assume	O
a	O
given	O
set	O
of	O
texts	O
that	O
are	O
to	O
be	O
read	O
at	O
refinement	O
iteration	O
.	O

Each	O
text	O
is	O
a	O
sequence	O
of	O
word	O
tokens	O
.	O

We	O
embed	O
all	O
tokens	O
of	O
every	O
using	O
the	O
embedding	O
matrix	O
from	O
the	O
previous	O
layer	O
,	O
.	O

To	O
each	O
word	O
,	O
we	O
concatenate	O
a	O
one	O
-	O
hot	O
vector	O
of	O
length	O
with	O
position	O
set	O
to	O
,	O
indicating	O
which	O
layer	O
is	O
currently	O
being	O
processed	O
.	O

Stacking	O
the	O
vectors	O
into	O
a	O
matrix	O
,	O
we	O
obtain	O
a	O
.	O

This	O
matrix	O
is	O
processed	O
by	O
a	O
bidirectional	Method
recurrent	Method
neural	Method
network	Method
,	O
a	O
hochreiter1997long	O
in	O
this	O
work	O
.	O

The	O
resulting	O
output	O
is	O
further	O
projected	O
to	O
by	O
a	O
fully	Method
-	Method
connected	Method
layer	Method
with	O
activation	Method
(	O
Eq	O
.	O

[	O
reference	O
]	O
)	O
.	O

To	O
finally	O
update	O
the	O
previous	O
embedding	O
of	O
word	O
,	O
we	O
initially	O
all	O
representations	O
of	O
occurrences	O
matching	O
the	O
lemma	O
of	O
in	O
every	O
resulting	O
in	O
(	O
Eq	O
.	O

[	O
reference	O
]	O
)	O
.	O

Finally	O
,	O
we	O
combine	O
the	O
previous	O
representation	O
with	O
to	O
form	O
an	O
updated	Method
representation	Method
via	O
a	O
gated	Method
addition	Method
.	O

This	O
lets	O
the	O
model	O
determine	O
how	O
much	O
to	O
revise	O
the	O
previous	O
embedding	O
with	O
the	O
newly	O
read	O
information	O
(	O
Eq	O
.	O

[	O
reference	O
]	O
)	O
.	O

Note	O
that	O
we	O
soften	O
the	O
matching	O
condition	O
for	O
using	O
lemmatization	O
,	O
,	O
during	O
the	O
pooling	O
operation	O
of	O
Eq	O
.	O

[	O
reference	O
]	O
because	O
contextual	O
information	O
about	O
certain	O
words	O
is	O
usually	O
independent	O
of	O
the	O
current	O
word	O
form	O
they	O
appear	O
in	O
.	O

As	O
a	O
consequence	O
,	O
this	O
minor	O
linguistic	Method
pre	Method
-	Method
processing	Method
step	Method
allows	O
for	O
additional	O
interaction	O
between	O
tokens	O
of	O
the	O
same	O
lemma	O
.	O

Pooling	O
over	O
lemma	O
-	O
occurrences	O
effectively	O
connects	O
different	O
text	O
passages	O
(	O
even	O
across	O
texts	O
)	O
that	O
are	O
otherwise	O
disconnected	O
,	O
mitigating	O
the	O
problems	O
arising	O
from	O
long	O
-	O
distance	O
dependencies	O
.	O

This	O
is	O
reminiscent	O
of	O
the	O
(	O
soft	O
)	O
attention	Method
mechanism	Method
used	O
in	O
reading	Method
comprehension	Method
models	Method
(	O
e.g.	O
,	O
Cheng2016	O
,	O
wang2017gated	O
)	O
.	O

However	O
,	O
our	O
setup	O
is	O
more	O
general	O
as	O
it	O
allows	O
for	O
the	O
connection	O
of	O
multiple	O
passages	O
(	O
via	O
pooling	Method
)	O
at	O
once	O
and	O
is	O
able	O
to	O
deal	O
with	O
multiple	O
inputs	O
which	O
is	O
necessary	O
to	O
make	O
use	O
of	O
additional	O
input	O
texts	O
such	O
as	O
relevant	O
background	O
knowledge	O
.	O

section	O
:	O
Experimental	O
Setup	O
We	O
run	O
experiments	O
on	O
four	O
benchmarks	O
for	O
two	O
standard	O
NLU	Task
tasks	O
:	O
recognizing	Task
textual	Task
entailment	Task
(	O
RTE	Task
)	O
and	O
document	Task
question	Task
answering	Task
(	O
DQA	Task
)	O
.	O

In	O
the	O
following	O
we	O
describe	O
our	O
experimental	O
setup	O
.	O

paragraph	O
:	O
Task	Method
-	Method
specific	Method
Models	Method
Since	O
we	O
wish	O
to	O
assess	O
the	O
value	O
of	O
the	O
proposed	O
embedding	Method
refinement	Method
strategy	Method
,	O
we	O
focus	O
on	O
relatively	O
simple	O
task	Method
architectures	Method
.	O

We	O
use	O
single	Method
-	Method
layer	Method
bidirectional	Method
LSTMs	Method
(	O
BiLSTMs	Method
)	O
as	O
encoders	Method
of	O
the	O
inputs	O
represented	O
by	O
the	O
refined	O
or	O
unrefined	O
embeddings	O
with	O
a	O
task	O
-	O
specific	O
,	O
feed	Method
-	Method
forward	Method
network	Method
for	O
the	O
final	O
prediction	Task
.	O

Such	O
models	O
are	O
general	Method
reading	Method
architectures	Method
.	O

To	O
demonstrate	O
that	O
our	O
reading	Method
module	Method
can	O
be	O
integrated	O
into	O
arbitrary	O
task	Method
architectures	Method
,	O
we	O
also	O
add	O
our	O
refinement	Method
module	Method
to	O
a	O
reimplementation	O
of	O
a	O
state	O
of	O
the	O
art	O
architecture	O
for	O
RTE	Task
called	O
ESIM	Method
Chen2017_ESIM	O
.	O

We	O
refer	O
the	O
interested	O
reader	O
to	O
the	O
ESIM	Method
paper	O
for	O
details	O
of	O
the	O
model	O
.	O

All	O
models	O
are	O
trained	O
end	O
-	O
to	O
-	O
end	O
jointly	O
with	O
the	O
refinement	Method
module	Method
using	O
a	O
dimensionality	O
of	O
for	O
all	O
but	O
the	O
TriviaQA	Task
experiments	Task
for	O
which	O
we	O
had	O
to	O
reduce	O
to	O
due	O
to	O
memory	O
constraints	O
.	O

All	O
baselines	O
operate	O
on	O
the	O
unrefined	O
word	O
embeddings	O
described	O
in	O
§	O
[	O
reference	O
]	O
.	O

For	O
the	O
DQA	Task
baseline	O
system	O
we	O
add	O
the	O
lemma	O
-	O
in	O
-	O
question	O
feature	O
(	O
liq	Method
)	O
suggested	O
in	O
Weissenborn2017	O
.	O

Implementation	O
details	O
for	O
the	O
BiLSTM	Method
task	Method
architectures	Method
,	O
as	O
well	O
as	O
training	O
details	O
,	O
are	O
available	O
in	O
Appendix	O
[	O
reference	O
]	O
.	O

paragraph	O
:	O
Question	Task
Answering	Task
We	O
use	O
2	O
recent	O
DQA	Task
benchmark	O
training	O
and	O
evaluation	O
datasets	O
,	O
SQuAD	Material
Rajpurkar2016	O
and	O
TriviaQA	Material
JoshiTriviaQA2017	O
.	O

The	O
task	O
is	O
to	O
predict	O
an	O
answer	O
span	O
within	O
a	O
provided	O
document	O
given	O
a	O
question	O
.	O

Both	O
datasets	O
are	O
large	O
-	O
scale	O
,	O
containing	O
on	O
the	O
order	O
of	O
100k	O
examples	O
,	O
however	O
,	O
TriviaQA	Material
is	O
more	O
complex	O
in	O
that	O
the	O
supporting	O
documents	O
are	O
much	O
larger	O
than	O
those	O
for	O
SQuAD	Material
.	O

Because	O
TriviaQA	Material
is	O
collected	O
via	O
distant	O
supervision	O
the	O
test	O
set	O
is	O
divided	O
into	O
a	O
large	O
but	O
noisy	O
distant	O
supervision	O
part	O
and	O
a	O
much	O
smaller	O
(	O
on	O
the	O
order	O
of	O
hundreds	O
)	O
human	O
verified	O
part	O
.	O

We	O
report	O
results	O
on	O
both	O
.	O

See	O
Appendix	O
[	O
reference	O
]	O
for	O
implementation	O
details	O
of	O
the	O
DQA	Task
system	O
.	O

paragraph	O
:	O
Recognizing	Task
Textual	Task
Entailment	Task
We	O
test	O
on	O
both	O
the	O
SNLI	Material
dataset	Material
Bowman2015	O
,	O
a	O
collection	O
of	O
sentence	O
pairs	O
,	O
and	O
the	O
more	O
recent	O
MultiNLI	Material
dataset	O
(	O
sentence	Material
pairs	Material
)	O
williams2017broad	O
.	O

Given	O
two	O
sentences	O
,	O
a	O
premise	O
and	O
a	O
hypothesis	O
,	O
the	O
task	O
is	O
to	O
determine	O
whether	O
either	O
entails	O
,	O
contradicts	O
or	O
is	O
neutral	O
to	O
.	O

See	O
Appendix	O
[	O
reference	O
]	O
for	O
implementation	O
details	O
of	O
the	O
RTE	Task
system	O
.	O

paragraph	O
:	O
Supplementary	O
Knowledge	O
Sources	O
We	O
use	O
ConceptNethttp:	O
//	O
conceptnet.io	O
/	O
Speer2012	O
,	O
a	O
freely	O
-	O
available	O
,	O
multi	Method
-	Method
lingual	Method
semantic	Method
network	Method
that	O
originated	O
from	O
the	O
Open	Material
Mind	Material
Common	Material
Sense	Material
project	Material
and	O
incorporates	O
selected	O
knowledge	O
from	O
various	O
other	O
knowledge	O
sources	O
,	O
such	O
as	O
Wiktionary	Material
,	O
Open	Material
Multilingual	Material
WordNet	Material
,	O
OpenCyc	Material
and	O
DBpedia	Material
.	O

It	O
presents	O
information	O
in	O
the	O
form	O
of	O
relational	O
triples	O
.	O

Additionally	O
,	O
we	O
exploit	O
Wikipedia	Material
abstracts	Material
in	O
our	O
DQA	Task
experiments	O
as	O
described	O
below	O
.	O

paragraph	O
:	O
ConceptNet	Method
Integration	Method
Here	O
we	O
describe	O
the	O
heuristic	O
we	O
use	O
to	O
obtain	O
plausibly	O
relevant	O
supplementary	O
knowledge	O
for	O
understanding	O
a	O
text	O
pair	O
from	O
ConceptNet	Material
.	O

Our	O
hypothesis	O
is	O
that	O
relations	O
that	O
link	O
words	O
and	O
phrases	O
across	O
and	O
are	O
likely	O
to	O
be	O
most	O
valuable	O
.	O

Because	O
assertions	O
in	O
ConceptNet	O
come	O
in	O
form	O
of	O
(	O
subject	O
,	O
predicate	O
,	O
object	O
)-	O
triples	O
,	O
we	O
retrieve	O
all	O
assertions	O
for	O
which	O
appears	O
in	O
and	O
appears	O
in	O
,	O
or	O
vice	O
versa	O
.	O

Because	O
still	O
too	O
many	O
such	O
assertions	O
might	O
be	O
retrieved	O
for	O
an	O
instance	O
,	O
we	O
rank	O
all	O
retrievals	O
based	O
on	O
their	O
respective	O
subject	O
and	O
object	O
.	O

The	O
ranking	Metric
score	Metric
we	O
use	O
is	O
the	O
inverse	O
product	O
of	O
appearances	O
of	O
the	O
subject	O
and	O
the	O
object	O
in	O
the	O
KB	O
,	O
that	O
is	O
,	O
where	O
denotes	O
the	O
indicator	O
function	O
.	O

During	O
training	O
and	O
evaluation	Task
we	O
retain	O
the	O
top	O
-	O
assertions	O
,	O
using	O
for	O
DQA	Task
and	O
for	O
RTE	Task
.	O

Note	O
that	O
fewer	O
or	O
even	O
no	O
assertions	O
might	O
be	O
retrieved	O
for	O
a	O
particular	O
instance	O
during	O
training	O
and	O
testing	O
.	O

paragraph	O
:	O
Wikipedia	Task
Integration	Task
Here	O
we	O
describe	O
the	O
heuristic	O
we	O
use	O
to	O
obtain	O
plausibly	O
relevant	O
supplementary	O
knowledge	O
from	O
Wikipedia	Material
.	O

We	O
wish	O
to	O
use	O
Wikipedia	Material
abstracts	Material
as	O
an	O
additional	O
knowledge	O
source	O
to	O
gather	O
more	O
information	O
about	O
the	O
top	O
answer	O
predictions	O
of	O
our	O
DQA	Task
model	O
.	O

To	O
this	O
end	O
,	O
we	O
let	O
the	O
system	O
first	O
predict	O
the	O
top	O
-	O
16	O
answer	O
spans	O
without	O
any	O
information	O
from	O
Wikipedia	Material
.	O

For	O
each	O
answer	O
candidate	O
string	O
,	O
we	O
collect	O
abstracts	O
for	O
their	O
3	O
most	O
frequently	O
linked	O
Wikipedia	O
entries	O
.	O

Using	O
more	O
than	O
only	O
the	O
most	O
frequently	O
linked	O
Wikipedia	O
entry	O
for	O
a	O
given	O
answer	O
string	O
,	O
lets	O
us	O
mitigate	O
problems	O
arising	O
from	O
polysemous	O
entity	O
names	O
,	O
although	O
it	O
does	O
mean	O
the	O
refinement	Method
model	Method
needs	O
to	O
be	O
selective	O
in	O
extracting	O
relevant	O
information	O
.	O

The	O
refinement	Method
module	Method
additionally	O
reads	O
the	O
initial	O
50	O
tokens	O
of	O
each	O
retrieved	O
Wikipedia	O
abstract	O
and	O
computes	O
the	O
final	O
predictions	O
.	O

paragraph	O
:	O
Refinement	O
Order	O
When	O
employing	O
our	O
embedding	Method
-	Method
refinement	Method
strategy	Method
,	O
we	O
first	O
read	O
the	O
document	O
(	O
)	O
followed	O
by	O
the	O
question	O
(	O
)	O
in	O
case	O
of	O
DQA	Task
,	O
and	O
the	O
premise	O
(	O
)	O
followed	O
by	O
the	O
hypothesis	O
(	O
)	O
for	O
RTE	Task
,	O
that	O
is	O
,	O
and	O
.	O

Additional	O
knowledge	O
in	O
the	O
form	O
of	O
a	O
set	O
of	O
assertions	O
is	O
integrated	O
after	O
reading	O
the	O
task	O
-	O
specific	O
input	O
for	O
both	O
DQA	Task
and	O
RTE	Task
,	O
that	O
is	O
,	O
.	O

Finally	O
,	O
for	O
DQA	Task
we	O
additionally	O
add	O
Wikipedia	Material
abstracts	Material
as	O
background	O
knowledge	O
as	O
described	O
previously	O
,	O
that	O
is	O
,	O
.	O

In	O
preliminary	O
experiments	O
we	O
found	O
that	O
the	O
final	O
performance	O
is	O
not	O
significantly	O
sensitive	O
to	O
the	O
order	O
of	O
presentation	O
so	O
we	O
decided	O
to	O
fix	O
our	O
order	O
as	O
defined	O
above	O
.	O

section	O
:	O
Results	O
This	O
section	O
presents	O
results	O
.	O

We	O
provide	O
ablations	O
for	O
a	O
total	O
of	O
7	O
task	O
-	O
dataset	O
-	O
model	O
combinations	O
and	O
compare	O
our	O
final	O
results	O
to	O
other	O
works	O
on	O
the	O
most	O
recent	O
benchmark	O
datasets	O
for	O
each	O
task	O
(	O
TriviaQA	Material
and	O
MultiNLI	Material
)	O
,	O
demonstrating	O
that	O
our	O
results	O
are	O
competitive	O
,	O
and	O
in	O
some	O
cases	O
,	O
state	O
of	O
the	O
art	O
,	O
even	O
without	O
sophisticated	O
task	Method
architectures	Method
.	O

subsection	O
:	O
Question	Task
Answering	Task
Table	O
[	O
reference	O
]	O
presents	O
our	O
results	O
on	O
two	O
question	Task
answering	Task
benchmarks	Task
.	O

The	O
results	O
demonstrate	O
that	O
the	O
introduction	O
of	O
the	O
refinement	Method
module	Method
helps	O
consistently	O
,	O
and	O
further	O
improvements	O
come	O
from	O
using	O
common	O
sense	O
knowledge	O
from	O
ConceptNet	O
(	O
)	O
.	O

Wikipedia	Method
(	O
)	O
yields	O
further	O
,	O
significant	O
improvements	O
on	O
TriviaQA	Material
,	O
slightly	O
outperforming	O
the	O
current	O
state	O
of	O
the	O
art	O
model	O
(	O
Table	O
[	O
reference	O
]	O
)	O
.	O

This	O
is	O
especially	O
noteworthy	O
given	O
the	O
simplicity	O
of	O
our	O
QA	Method
architecture	Method
(	O
i.e.	O
,	O
a	O
single	Method
layer	Method
BiLSTM	Method
)	O
compared	O
to	O
the	O
previous	O
SotA	Method
attained	O
by	O
clark2017simple	O
.	O

The	O
development	O
results	O
on	O
SQuAD	Material
show	O
the	O
same	O
pattern	O
of	O
improvement	O
,	O
but	O
here	O
the	O
results	O
are	O
slightly	O
worse	O
than	O
the	O
model	O
of	O
clark2017simple	O
,	O
and	O
they	O
are	O
way	O
off	O
from	O
the	O
current	O
best	O
-	O
known	O
results	O
(	O
currently	O
at	O
87	O
%	O
F1	Metric
)	O
;	O
however	O
,	O
our	O
intention	O
with	O
these	O
experiments	O
is	O
to	O
show	O
of	O
the	O
value	O
that	O
external	O
knowledge	O
and	O
our	O
refinement	Method
process	Method
can	O
bring	O
,	O
not	O
to	O
compete	O
with	O
highly	O
tuned	O
task	Method
architectures	Method
on	O
a	O
single	O
dataset	O
.	O

paragraph	O
:	O
Controlling	O
for	O
computation	Task
.	O

One	O
potential	O
explanation	O
for	O
the	O
improvement	O
obtained	O
using	O
the	O
refinement	Method
module	Method
is	O
that	O
we	O
are	O
enabling	O
more	O
computation	O
over	O
the	O
information	O
present	O
in	O
the	O
inputs	O
,	O
that	O
is	O
,	O
we	O
are	O
effectively	O
using	O
a	O
deeper	Method
architecture	Method
.	O

To	O
test	O
whether	O
this	O
might	O
be	O
the	O
case	O
,	O
we	O
also	O
ran	O
an	O
experiment	O
with	O
a	O
2	Method
-	Method
layer	Method
BiLSTM	Method
(	Method
+	Method
liq	Method
)	O
.	O

This	O
setup	O
exhibits	O
similar	O
computational	Metric
complexity	Metric
and	O
number	O
of	O
parameters	O
to	O
BiLSTM	Method
+	Method
+	Method
.	O

We	O
found	O
that	O
the	O
second	O
layer	O
did	O
not	O
improve	O
performance	O
,	O
suggesting	O
that	O
pooling	O
over	O
word	O
/	O
lemma	O
occurrences	O
in	O
a	O
given	O
context	O
between	O
layers	O
,	O
is	O
a	O
powerful	O
,	O
yet	O
simple	O
technique	O
.	O

subsection	O
:	O
Recognizing	Task
Textual	Task
Entailment	Task
Table	O
[	O
reference	O
]	O
shows	O
the	O
results	O
of	O
our	O
RTE	Task
experiments	O
.	O

In	O
general	O
,	O
the	O
introduction	O
of	O
our	O
refinement	Method
strategy	Method
almost	O
always	O
helps	O
,	O
both	O
with	O
and	O
without	O
external	O
knowledge	O
.	O

When	O
providing	O
additional	O
background	O
knowledge	O
from	O
ConceptNet	O
,	O
our	O
BiLSTM	Method
based	Method
models	Method
improve	O
substantially	O
,	O
while	O
the	O
ESIM	Method
-	O
based	O
models	O
improve	O
only	O
on	O
the	O
more	O
difficult	O
MultiNLI	Material
dataset	O
.	O

Compared	O
to	O
previously	O
published	O
state	O
of	O
the	O
art	O
systems	O
,	O
our	O
models	O
acquit	O
themselves	O
quite	O
well	O
on	O
the	O
MultiNLI	Material
benchmark	O
,	O
and	O
competitively	O
on	O
the	O
SNLI	Material
benchmark	Material
.	O

In	O
parallel	O
to	O
this	O
work	O
,	O
gong2017natural	O
developed	O
a	O
novel	O
task	Method
-	Method
specific	Method
architecture	Method
for	O
RTE	Task
that	O
achieves	O
slightly	O
better	O
performance	O
on	O
MultiNLI	Material
than	O
our	O
ESIM	Method
+	O
+	O
+	O
based	O
models	O
.	O

It	O
draws	O
attention	O
to	O
the	O
fact	O
that	O
when	O
using	O
our	O
knowledge	Method
-	Method
enhanced	Method
embedding	Method
module	Method
,	O
on	O
the	O
MultiNLI	Material
,	O
the	O
basic	O
BiLSTM	Method
task	Method
model	Method
outperforms	O
the	O
task	O
-	O
specific	O
ESIM	Method
model	O
,	O
which	O
is	O
architecturally	O
much	O
more	O
complex	O
and	O
designed	O
specifically	O
for	O
the	O
RTE	Task
task	O
.	O

We	O
do	O
find	O
that	O
there	O
is	O
little	O
impact	O
of	O
using	O
external	O
knowledge	O
on	O
the	O
RTE	Task
task	O
with	O
ESIM	Method
,	O
although	O
the	O
refinement	Method
strategy	Method
helps	O
using	O
just	O
+	O
.	O

A	O
more	O
detailed	O
set	O
of	O
experiments	O
reported	O
in	O
Appendix	O
[	O
reference	O
]	O
shows	O
that	O
by	O
impoverishing	O
the	O
amount	O
of	O
training	O
data	O
and	O
information	O
present	O
in	O
the	O
GloVe	O
embeddings	O
,	O
the	O
positive	O
impact	O
of	O
supplemental	O
information	O
becomes	O
much	O
more	O
pronounced	O
.	O

These	O
results	O
suggest	O
that	O
ESIM	Method
is	O
able	O
to	O
learn	O
important	O
background	O
information	O
from	O
the	O
large	O
-	O
scale	O
datasets	O
and	O
from	O
pretrained	Method
embeddings	Method
,	O
but	O
this	O
can	O
be	O
supplemented	O
when	O
necessary	O
.	O

Nevertheless	O
,	O
both	O
ESIM	Method
and	O
our	O
BiLSTM	Method
models	Method
when	O
trained	O
with	O
knowledge	O
from	O
ConceptNet	Method
are	O
sensitive	O
to	O
the	O
semantics	O
of	O
the	O
provided	O
assertions	O
as	O
demonstrated	O
in	O
our	O
analysis	O
in	O
§	O
[	O
reference	O
]	O
.	O

We	O
argue	O
that	O
this	O
is	O
a	O
desirable	O
side	O
effect	O
because	O
it	O
makes	O
the	O
predictions	O
of	O
our	O
model	O
more	O
interpretable	O
than	O
those	O
not	O
trained	O
with	O
knowledge	O
.	O

Furthermore	O
,	O
increasing	O
the	O
coverage	O
of	O
assertions	O
in	O
ConceptNet	O
would	O
most	O
likely	O
yield	O
improved	O
performance	O
even	O
without	O
retraining	O
our	O
models	O
.	O

Finally	O
,	O
we	O
remark	O
that	O
despite	O
careful	O
tuning	O
,	O
our	O
re	Method
-	Method
implementation	Method
of	O
ESIM	Method
fails	O
to	O
match	O
the	O
88	O
%	O
reported	O
in	O
Chen2017_ESIM	O
by	O
0.8	O
%	O
;	O
however	O
,	O
with	O
MultiNLI	Material
,	O
we	O
find	O
that	O
our	O
implementation	O
of	O
ESIM	Method
performs	O
considerably	O
better	O
(	O
by	O
approximately	O
5	O
%	O
)	O
.	O

The	O
instability	O
of	O
the	O
results	O
suggests	O
,	O
as	O
well	O
as	O
the	O
failure	O
of	O
a	O
custom	O
RTE	Task
-	O
architecture	O
to	O
consistently	O
perform	O
well	O
suggests	O
that	O
current	O
SotA	O
RTE	Task
models	O
may	O
be	O
overfit	O
to	O
the	O
SNLI	Material
dataset	Material
.	O

subsection	O
:	O
Qualitative	Method
Analysis	Method
Although	O
our	O
empirical	O
results	O
show	O
our	O
knowledge	Method
-	Method
incorporation	Method
approach	Method
improves	O
performance	O
,	O
in	O
this	O
section	O
we	O
attempt	O
to	O
assess	O
whether	O
we	O
are	O
learning	O
to	O
use	O
the	O
provided	O
knowledge	O
in	O
a	O
semantically	O
appropriate	O
way	O
.	O

paragraph	O
:	O
RTE	Task
To	O
test	O
our	O
models	O
sensitivity	O
towards	O
the	O
semantics	O
of	O
the	O
assertions	O
for	O
recognizing	Task
textual	Task
entailment	Task
,	O
we	O
run	O
an	O
experiment	O
in	O
which	O
we	O
swap	O
the	O
synonym	O
with	O
the	O
antonym	O
predicate	O
in	O
the	O
provided	O
assertions	O
during	O
test	O
time	O
.	O

We	O
hypothesize	O
that	O
in	O
many	O
cases	O
these	O
two	O
predicates	O
are	O
very	O
important	O
for	O
predicting	O
either	O
contradiction	Task
or	O
entailment	Task
.	O

Indeed	O
,	O
there	O
is	O
a	O
strong	O
performance	O
drop	O
of	O
about	O
10	O
%	O
on	O
MultiNLI	Material
examples	O
for	O
both	O
the	O
BiLSTM	Method
and	O
the	O
ESIM	Method
model	O
for	O
which	O
either	O
a	O
synonym	O
or	O
an	O
antonym	O
-	O
assertion	O
is	O
present	O
.	O

This	O
very	O
large	O
drop	O
clearly	O
shows	O
that	O
our	O
models	O
are	O
sensitive	O
to	O
the	O
semantics	O
of	O
the	O
provided	O
knowledge	O
.	O

Examples	O
of	O
prediction	O
changes	O
are	O
presented	O
in	O
Table	O
[	O
reference	O
]	O
.	O

They	O
demonstrate	O
that	O
the	O
system	O
has	O
learned	O
to	O
trust	O
the	O
presented	O
assertions	O
to	O
the	O
point	O
that	O
it	O
will	O
make	O
appropriate	O
counterfactual	O
inferences	O
—	O
that	O
is	O
,	O
the	O
change	O
in	O
knowledge	O
has	O
caused	O
the	O
change	O
in	O
prediction	Task
.	O

For	O
the	O
interested	O
reader	O
we	O
provide	O
additional	O
RTE	Task
analysis	O
results	O
in	O
Appendix	O
[	O
reference	O
]	O
paragraph	O
:	O
DQA	Task
The	O
following	O
is	O
an	O
example	O
question	O
from	O
the	O
TriviaQA	Material
dataset	O
:	O
[	O
roundcorner=2pt	O
]	O
Prince	O
Philip	O
[	O
…	O
]	O
was	O
born	O
on	O
which	O
island	O
?	O
Answer	O
candidates	O
with	O
corresponding	O
abstracts	O
:	O
Denmark	O
is	O
a	O
Scandinavian	O
country	O
with	O
territory	O
in	O
Europe	O
and	O
North	O
America	O
[	O
…	O
]	O
Corfu	O
is	O
a	O
Greek	O
island	O
in	O
the	O
Ionian	O
Sea	O
[	O
…	O
]	O
Greece	O
,	O
officially	O
the	O
Hellenic	O
Republic	O
,	O
[	O
…	O
]	O
is	O
a	O
transcontinental	O
country	O
[	O
…	O
]	O
Vanuatu	O
is	O
a	O
Pacific	O
island	O
nation	O
located	O
in	O
the	O
South	O
Pacific	O
Ocean	O
[	O
…	O
]	O
Answer	O
candidates	O
(	O
i.e.	O
,	O
Denmark	O
,	O
Corfu	O
,	O
Greece	O
,	O
Vanuata	O
)	O
were	O
obtained	O
from	O
the	O
top	O
predicted	O
answer	O
spans	O
computed	O
by	O
our	O
model	O
excluding	O
Wikipedia	Material
(	O
i.e.	O
,	O
BiLSTM	Method
+	Method
+	O
+	O
)	O
.	O

Their	O
corresponding	O
abstracts	O
were	O
retrieved	O
from	O
Wikipedia	O
and	O
then	O
given	O
to	O
our	O
model	O
in	O
a	O
second	O
pass	O
(	O
i.e.	O
,	O
BiLSTM	Method
+	O
+	O
+	O
+	O
)	O
.	O

In	O
this	O
example	O
,	O
the	O
final	O
best	O
prediction	O
of	O
the	O
model	O
changes	O
from	O
Denmark	O
to	O
Corfu	O
after	O
integrating	O
the	O
abstracts	O
(	O
here	O
,	O
the	O
abstract	O
clearly	O
states	O
that	O
Corfu	O
is	O
an	O
island	O
)	O
.	O

We	O
studied	O
a	O
total	O
of	O
25	O
similar	O
answer	O
changes	O
,	O
14	O
of	O
which	O
went	O
from	O
incorrect	O
to	O
correct	O
,	O
and	O
11	O
of	O
which	O
went	O
from	O
correct	O
to	O
incorrect	O
.	O

In	O
11	O
of	O
the	O
14	O
corrections	O
,	O
obvious	O
information	O
is	O
present	O
in	O
the	O
Wikipedia	Material
abstracts	Material
that	O
reinforced	O
the	O
correct	O
answer	O
.	O

Where	O
the	O
system	O
was	O
confused	O
by	O
the	O
answers	O
(	O
i.e.	O
,	O
when	O
the	O
abstracts	O
switched	O
the	O
production	O
from	O
correct	O
to	O
incorrect	O
)	O
,	O
no	O
obvious	O
information	O
was	O
present	O
in	O
8	O
of	O
the	O
11	O
cases	O
,	O
suggesting	O
that	O
the	O
model	O
had	O
difficulty	O
coping	O
with	O
unrelated	O
background	O
information	O
.	O

In	O
3	O
of	O
the	O
11	O
,	O
plausibly	O
relevant	O
information	O
was	O
present	O
in	O
the	O
abstract	O
of	O
the	O
correct	O
answer	O
,	O
yet	O
the	O
model	O
still	O
made	O
the	O
incorrect	O
answer	O
change	O
.	O

The	O
existence	O
of	O
counterfactual	O
inferences	O
in	O
RTE	Task
and	O
the	O
tendency	O
to	O
use	O
reinforcing	O
information	O
about	O
candidate	O
answers	O
in	O
DQA	Task
suggest	O
that	O
our	O
knowledge	Method
incorporating	Method
strategy	Method
is	O
exploiting	O
heterogeneous	O
knowledge	O
sources	O
in	O
semantically	O
sensible	O
ways	O
.	O

section	O
:	O
Related	O
Work	O
The	O
role	O
of	O
background	O
knowledge	O
in	O
natural	Task
language	Task
understanding	Task
has	O
long	O
been	O
remarked	O
on	O
,	O
especially	O
in	O
the	O
context	O
of	O
classical	O
models	O
of	O
AI	Method
schank:1977	O
,	O
minsky2000commonsense	O
;	O
however	O
,	O
it	O
has	O
only	O
recently	O
begun	O
to	O
play	O
a	O
role	O
in	O
neural	Method
network	Method
models	Method
of	O
NLU	Task
ahn2016neural	O
,	O
Xu2016	O
,	O
long2017world	O
,	O
Dhingra2017	O
.	O

Previous	O
efforts	O
have	O
focused	O
on	O
specific	O
tasks	O
or	O
certain	O
kinds	O
of	O
knowledge	O
,	O
whereas	O
we	O
take	O
a	O
step	O
towards	O
a	O
more	O
general	O
-	O
purpose	O
solution	O
for	O
the	O
integration	O
of	O
heterogeneous	Task
knowledge	Task
for	O
NLU	Task
systems	O
by	O
providing	O
a	O
simple	O
,	O
general	Method
-	Method
purpose	Method
reading	Method
architecture	Method
that	O
can	O
read	O
background	O
knowledge	O
encoded	O
in	O
simple	O
natural	O
language	O
statements	O
,	O
e.g.	O
,	O
“	O
abdication	Method
is	O
a	O
type	O
of	O
resignation	O
”	O
.	O

In	O
the	O
area	O
of	O
visual	Task
question	Task
answering	Task
Wu2016	O
utilize	O
external	O
knowledge	O
in	O
form	O
of	O
DBpedia	Material
comments	Material
(	O
short	O
abstracts	O
/	O
definitions	O
)	O
to	O
improve	O
the	O
answering	Task
ability	O
of	O
a	O
model	O
.	O

marino2016more	O
explicitly	O
incorporate	O
knowledge	O
graphs	O
into	O
an	O
image	Method
classification	Method
model	Method
.	O

Xu2016	O
created	O
a	O
recall	Method
mechanism	Method
into	O
a	O
standard	O
LSTM	Method
cell	Method
that	O
retrieves	O
pieces	O
of	O
external	O
knowledge	O
encoded	O
by	O
a	O
single	O
representation	O
for	O
a	O
conversation	Method
model	Method
.	O

Concurrently	O
,	O
Dhingra2017	O
exploit	O
linguistic	O
knowledge	O
using	O
MAGE	Method
-	Method
GRUs	Method
,	O
an	O
adapation	O
of	O
GRUs	Method
to	O
handle	O
graphs	O
,	O
however	O
,	O
external	O
knowledge	O
has	O
to	O
be	O
present	O
in	O
form	O
of	O
triples	O
.	O

ahn2016neural	O
exploit	O
knowledge	O
base	O
facts	O
about	O
mentioned	O
entities	O
for	O
neural	Method
language	Method
models	Method
.	O

bahdanau2017learning	O
and	O
long2017world	O
create	O
word	O
embeddings	O
on	O
-	O
the	O
-	O
fly	O
by	O
reading	O
word	O
definitions	O
prior	O
to	O
processing	O
the	O
task	O
at	O
hand	O
.	O

pilehvar2017towards	O
incorporate	O
information	O
about	O
word	O
senses	O
into	O
their	O
representations	O
before	O
solving	O
the	O
downstream	O
NLU	Task
task	O
,	O
which	O
is	O
similar	O
.	O

We	O
go	O
one	O
step	O
further	O
by	O
seamlessly	O
integrating	O
all	O
kinds	O
of	O
fine	O
-	O
grained	O
assertions	O
about	O
concepts	O
that	O
might	O
be	O
relevant	O
for	O
the	O
task	O
at	O
hand	O
.	O

Another	O
important	O
aspect	O
of	O
our	O
approach	O
is	O
the	O
notion	O
of	O
dynamically	Task
updating	Task
word	Task
-	Task
representations	Task
with	O
contextual	O
information	O
.	O

Tracking	Task
and	Task
updating	Task
concepts	Task
,	O
entities	O
or	O
sentences	O
with	O
dynamic	O
memories	O
is	O
a	O
very	O
active	O
research	O
direction	O
kumar2016ask	O
,	O
henaff2017tracking	O
,	O
ji2017dynamic	O
,	O
kobayashi2017neural	O
.	O

However	O
,	O
those	O
works	O
typically	O
focus	O
on	O
particular	O
tasks	O
whereas	O
our	O
approach	O
is	O
task	O
-	O
agnostic	O
and	O
most	O
importantly	O
allows	O
for	O
the	O
easy	O
integration	O
of	O
external	O
background	O
knowledge	O
.	O

Important	O
progress	O
has	O
also	O
been	O
made	O
in	O
creating	O
pre	O
-	O
trained	O
,	O
contextualized	Method
token	Method
representations	Method
.	O

section	O
:	O
Conclusion	O
We	O
have	O
presented	O
a	O
novel	O
reading	Method
architecture	Method
that	O
allows	O
for	O
the	O
dynamic	Task
integration	Task
of	Task
background	Task
knowledge	Task
into	O
neural	O
NLU	Task
models	O
.	O

Our	O
solution	O
,	O
which	O
is	O
based	O
on	O
the	O
incremental	Method
refinement	Method
of	Method
word	Method
representations	Method
by	O
reading	O
supplementary	O
inputs	O
,	O
is	O
flexible	O
and	O
can	O
be	O
used	O
with	O
virtually	O
any	O
existing	O
NLU	Task
architecture	O
that	O
rely	O
on	O
word	O
embeddings	O
as	O
input	O
.	O

Our	O
results	O
show	O
that	O
embedding	Task
refinement	Task
using	O
both	O
the	O
system	O
’s	O
text	O
inputs	O
,	O
as	O
well	O
as	O
supplementary	O
text	O
from	O
external	O
background	O
knowledge	O
can	O
yield	O
large	O
improvements	O
.	O

In	O
particular	O
,	O
we	O
have	O
shown	O
that	O
relatively	O
simple	O
task	Method
architectures	Method
(	O
e.g.	O
,	O
based	O
on	O
simple	O
BiLSTM	Method
readers	Method
)	O
can	O
become	O
competitive	O
with	O
state	O
of	O
the	O
art	O
,	O
task	Method
-	Method
specific	Method
architectures	Method
when	O
augmented	O
with	O
our	O
reading	Method
architecture	Method
.	O

Our	O
analysis	O
demonstrates	O
that	O
our	O
model	O
learns	O
to	O
exploit	O
provided	O
background	O
knowledge	O
in	O
a	O
semantically	O
appropriate	O
way	O
.	O

bibliography	O
:	O
References	O
appendix	O
:	O
Implementation	O
Details	O
All	O
our	O
models	O
were	O
trained	O
with	O
3	O
different	O
random	O
seeds	O
and	O
the	O
top	O
performance	O
is	O
reported	O
.	O

An	O
overview	O
of	O
hyper	O
-	O
parameters	O
used	O
in	O
our	O
experiments	O
can	O
be	O
found	O
in	O
Table	O
[	O
reference	O
]	O
.	O

In	O
the	O
following	O
we	O
explain	O
the	O
detailed	O
implementation	O
of	O
our	O
two	O
task	O
-	O
specific	O
,	O
baseline	Method
models	Method
.	O

We	O
assume	O
to	O
have	O
computed	O
the	O
contextually	Method
(	Method
un	Method
-)	Method
refined	Method
word	Method
representations	Method
depending	O
on	O
the	O
setup	O
and	O
embedded	O
our	O
input	O
sequences	O
and	O
to	O
and	O
,	O
respectively	O
.	O

The	O
word	Method
representation	Method
update	Method
gate	Method
in	O
Eq	O
.	O

[	O
reference	O
]	O
is	O
initialized	O
with	O
a	O
bias	O
of	O
to	O
refine	O
representations	O
only	O
slightly	O
in	O
the	O
beginning	O
of	O
training	O
.	O

In	O
the	O
following	O
as	O
before	O
,	O
we	O
denote	O
the	O
hidden	O
dimensionality	O
of	O
our	O
model	O
by	O
and	O
a	O
fully	Method
-	Method
connected	Method
layer	Method
by	O
,	O
.	O

subsection	O
:	O
Question	Task
Answering	Task
paragraph	O
:	O
Encoding	Task
In	O
the	O
DQA	Task
task	Task
refers	O
to	O
the	O
question	O
and	O
to	O
the	O
supporting	O
text	O
.	O

For	O
our	O
baseline	O
(	O
i.e.	O
,	O
BiLSTM	Method
+	Method
liq	Method
)	O
we	O
additionally	O
concatenate	O
a	O
binary	O
feature	O
to	O
and	O
indicating	O
whether	O
the	O
corresponding	O
token	O
lemma	O
appeared	O
in	O
the	O
question	O
.	O

However	O
,	O
it	O
is	O
omitted	O
in	O
the	O
following	O
for	O
the	O
sake	O
of	O
brevity	O
.	O

At	O
first	O
we	O
process	O
both	O
sequences	O
by	O
identical	O
s	O
in	O
parallel	O
(	O
Eq	O
.	O

[	O
reference	O
]	O
)	O
followed	O
by	O
a	O
linear	Method
projection	Method
and	O
a	O
non	Method
-	Method
linearity	Method
(	O
Eq	O
.	O

[	O
reference	O
]	O
)	O
.	O

is	O
initialized	O
by	O
where	O
is	O
the	O
identity	O
matrix	O
.	O

paragraph	O
:	O
Prediction	Task
Our	O
prediction–	Method
or	Method
answer	Method
layer	Method
is	O
similar	O
to	O
Weissenborn2017	O
.	O

We	O
first	O
compute	O
a	O
weighted	Method
,	Method
-	Method
dimensional	Method
representation	Method
of	O
the	O
processed	O
question	O
(	O
Eq	O
.	O

[	O
reference	O
]	O
)	O
.	O

The	O
probability	O
distributions	O
/	O
for	O
the	O
start	O
/	O
end	O
location	O
of	O
the	O
answer	O
is	O
computed	O
by	O
a	O
2	Method
-	Method
layer	Method
MLP	Method
with	O
a	O
ReLU	Method
activated	Method
,	O
hidden	Method
layer	Method
as	O
follows	O
:	O
The	O
model	O
is	O
trained	O
to	O
maximize	O
the	O
log	O
-	O
likelihood	O
of	O
the	O
correct	O
answer	O
spans	O
by	O
computing	O
the	O
sum	O
of	O
the	O
correct	O
span	O
probabilities	O
for	O
span	O
under	O
our	O
model	O
(	O
Eq	O
.	O

[	O
reference	O
]	O
)	O
.	O

During	O
evaluation	O
we	O
extract	O
the	O
span	O
with	O
the	O
best	O
score	O
and	O
maximum	O
token	O
length	O
for	O
SQuAD	Material
and	O
for	O
TriviaQA	Material
.	O

paragraph	O
:	O
TriviaQA	Material
Properly	O
training	O
a	O
QA	Method
system	Method
on	O
TriviaQA	Material
is	O
much	O
more	O
challenging	O
than	O
SQuAD	Material
because	O
of	O
the	O
large	O
document	O
sizes	O
and	O
the	O
use	O
of	O
multiple	O
paragraphs	O
.	O

Therefore	O
,	O
we	O
adopt	O
the	O
approach	O
of	O
clark2017simple	O
who	O
were	O
the	O
first	O
to	O
properly	O
train	O
neural	Method
QA	Method
models	Method
on	O
TriviaQA	Material
.	O

It	O
relies	O
on	O
splitting	O
documents	O
and	O
merging	O
paragraphs	O
up	O
to	O
a	O
certain	O
maximum	O
token	O
length	O
(	O
per	O
paragraph	O
in	O
our	O
experiments	O
)	O
,	O
and	O
only	O
retaining	O
the	O
top	O
-	O
paragraphs	O
(	O
in	O
our	O
case	O
)	O
for	O
prediction	Task
.	O

Paragraphs	O
are	O
ranked	O
using	O
the	O
tf	Metric
-	Metric
idf	Metric
cosine	Metric
similarity	Metric
between	O
question	O
and	O
paragraph	O
.	O

To	O
speed	O
up	O
training	Task
only	O
paragraphs	O
out	O
of	O
the	O
top	O
/	O
for	O
the	O
/	O
datasets	O
were	O
sampled	O
.	O

The	O
only	O
architectural	O
difference	O
for	O
this	O
multi	Task
-	Task
paragraph	Task
setup	Task
is	O
that	O
we	O
encode	O
multiple	O
for	O
each	O
question	O
and	O
the	O
of	O
Eq	O
.	O

[	O
reference	O
]	O
is	O
taken	O
over	O
all	O
tokens	O
of	O
all	O
paragraphs	O
instead	O
of	O
only	O
a	O
single	O
paragraph	O
.	O

For	O
further	O
details	O
,	O
we	O
refer	O
the	O
interested	O
reader	O
to	O
clark2017simple	O
who	O
explain	O
this	O
process	O
in	O
more	O
detail	O
.	O

subsection	O
:	O
Recognizing	Task
Textual	Task
Entailment	Task
paragraph	O
:	O
Encoding	Task
Analogous	O
to	O
DQA	Task
we	O
encode	O
our	O
input	O
sequences	O
by	O
BiLSTMs	Method
,	O
however	O
,	O
for	O
RTE	Task
we	O
use	O
conditional	Method
encoding	Method
Rocktschel2015	O
instead	O
.	O

Therefore	O
,	O
we	O
initially	O
process	O
the	O
embedded	O
hypothesis	O
by	O
a	O
BiLSTM	Method
and	O
use	O
the	O
respective	O
end	O
states	O
of	O
the	O
forward	Method
and	Method
backward	Method
LSTM	Method
as	O
initial	O
states	O
for	O
the	O
forward	Method
and	Method
backward	Method
LSTM	Method
that	O
processes	O
the	O
embedded	O
premise	O
.	O

paragraph	O
:	O
Prediction	Task
We	O
concatenate	O
the	O
outputs	O
of	O
the	O
forward	Method
and	Method
backward	Method
LSTMs	Method
processing	O
the	O
premise	O
,	O
i.e.	O
,	O
and	O
run	O
each	O
of	O
the	O
resulting	O
outputs	O
through	O
a	O
fully	Method
-	Method
connected	Method
layer	Method
with	O
activation	O
(	O
)	O
followed	O
by	O
a	O
-	O
pooling	O
operation	O
over	O
time	O
resulting	O
in	O
a	O
hidden	O
state	O
.	O

Finally	O
,	O
is	O
used	O
to	O
predict	O
the	O
RTE	Task
label	O
as	O
follows	O
:	O
The	O
probability	O
of	O
choosing	O
category	O
{	O
entailment	O
,	O
contradiction	O
,	O
neutral	O
}	O
is	O
defined	O
in	O
Eq	O
.	O

[	O
reference	O
]	O
.	O

Finally	O
,	O
the	O
model	O
is	O
trained	O
to	O
maximize	O
the	O
log	O
-	O
likelihood	O
of	O
the	O
correct	O
category	O
label	O
given	O
probability	O
distribution	O
.	O

appendix	O
:	O
Reducing	O
Training	O
Data	O
&	O
Dimensionality	Metric
of	O
Pre	O
-	O
trained	O
Word	Method
Embeddings	Method
We	O
find	O
that	O
there	O
is	O
only	O
little	O
impact	O
when	O
using	O
external	O
knowledge	O
on	O
the	O
RTE	Task
task	O
when	O
using	O
a	O
more	O
sophisticated	O
task	Method
model	Method
such	O
as	O
ESIM	Method
.	O

We	O
hypothesize	O
that	O
the	O
attention	Method
mechanisms	Method
within	O
ESIM	Method
together	O
with	O
powerful	O
,	O
pre	O
-	O
trained	O
word	Method
representations	Method
allow	O
for	O
the	O
recovery	O
of	O
some	O
important	O
lexical	O
relations	O
when	O
trained	O
on	O
a	O
large	O
dataset	O
.	O

It	O
follows	O
that	O
by	O
reducing	O
the	O
number	O
of	O
training	O
data	O
and	O
impoverishing	O
pre	O
-	O
trained	O
word	Method
representations	Method
the	O
impact	O
of	O
using	O
external	O
knowledge	O
should	O
become	O
larger	O
.	O

To	O
test	O
this	O
hypothesis	O
,	O
we	O
gradually	O
impoverish	O
pre	O
-	O
trained	O
word	O
embeddings	O
by	O
reducing	O
their	O
dimensionality	O
with	O
PCA	Method
while	O
reducing	O
the	O
number	O
of	O
training	O
instances	O
at	O
the	O
same	O
time	O
.	O

Our	O
joint	O
data	O
and	O
dimensionality	Task
reduction	Task
results	O
are	O
presented	O
in	O
Table	O
[	O
reference	O
]	O
.	O

They	O
show	O
that	O
there	O
is	O
indeed	O
a	O
slightly	O
larger	O
benefit	O
when	O
employing	O
background	O
knowledge	O
from	O
ConcepNet	Method
(	Method
)	Method
in	O
the	O
more	O
impoverished	O
settings	O
with	O
largest	O
improvements	O
when	O
using	O
around	O
10k	O
examples	O
and	O
reduced	O
dimensionality	O
to	O
10	O
.	O

However	O
,	O
we	O
observe	O
that	O
the	O
biggest	O
overall	O
impact	O
over	O
the	O
baseline	O
ESIM	Method
model	O
stems	O
from	O
our	O
contextual	Method
refinement	Method
strategy	Method
(	O
i.e.	O
,	O
reading	O
only	O
the	O
premise	O
and	O
hypothesis	O
)	O
which	O
is	O
especially	O
pronounced	O
for	O
the	O
1k	O
and	O
3k	O
experiments	O
.	O

This	O
highlights	O
once	O
more	O
the	O
usefulness	O
of	O
our	O
refinement	Method
strategy	Method
even	O
without	O
the	O
use	O
of	O
additional	O
knowledge	O
.	O

appendix	O
:	O
Further	O
Analysis	O
of	O
Knowledge	Task
Utilization	Task
in	O
RTE	Task
0.32	O
0.3	O
0.3	O
paragraph	O
:	O
Is	O
additional	O
knowledge	O
used	O
?	O
To	O
verify	O
whether	O
and	O
how	O
our	O
models	O
make	O
use	O
of	O
additional	O
knowledge	O
,	O
we	O
conducted	O
several	O
experiments	O
.	O

First	O
,	O
we	O
evaluated	O
models	O
trained	O
with	O
knowledge	O
on	O
our	O
tasks	O
while	O
not	O
providing	O
any	O
knowledge	O
at	O
test	O
time	O
.	O

This	O
ablation	O
drops	O
performance	O
by	O
3.7–3.9	O
%	O
accuracy	Metric
on	O
MultiNLI	Material
,	O
and	O
by	O
4	O
%	O
F1	Metric
on	O
SQuAD	Material
.	O

This	O
indicates	O
the	O
model	O
is	O
refining	O
the	O
representations	O
using	O
the	O
provided	O
assertions	O
in	O
a	O
useful	O
way	O
.	O

paragraph	O
:	O
What	O
knowledge	O
is	O
used	O
?	O
After	O
establishing	O
that	O
our	O
models	O
are	O
somehow	O
sensitive	O
to	O
semantics	O
we	O
wanted	O
to	O
find	O
out	O
which	O
type	O
of	O
knowledge	O
is	O
important	O
for	O
which	O
task	O
.	O

For	O
this	O
analysis	O
we	O
exclude	O
assertions	O
including	O
the	O
most	O
prominent	O
predicates	O
in	O
our	O
knowledge	O
base	O
individually	O
when	O
evaluating	O
our	O
models	O
.	O

The	O
results	O
are	O
presented	O
in	O
Figure	O
[	O
reference	O
]	O
.	O

They	O
demonstrate	O
that	O
the	O
biggest	O
performance	O
drop	O
in	O
total	O
(	O
blue	O
bars	O
)	O
stems	O
from	O
related	O
to	O
assertions	O
.	O

This	O
very	O
prominent	O
predicate	O
appears	O
much	O
more	O
frequently	O
than	O
other	O
assertions	O
and	O
helps	O
connecting	O
related	O
parts	O
of	O
the	O
2	O
input	O
sequences	O
with	O
each	O
other	O
.	O

We	O
believe	O
that	O
related	O
to	O
assertions	O
offer	O
benefits	O
mainly	O
from	O
a	O
modeling	O
perspective	O
by	O
strongly	O
connecting	O
the	O
input	O
sequences	O
with	O
each	O
other	O
and	O
thus	O
bridging	O
long	O
-	O
range	O
dependencies	O
similar	O
to	O
attention	O
.	O

Looking	O
at	O
the	O
relative	O
drops	O
obtained	O
by	O
normalizing	O
the	O
performance	O
differences	O
on	O
the	O
actually	O
affected	O
examples	O
(	O
green	O
)	O
we	O
find	O
that	O
our	O
models	O
depend	O
highly	O
on	O
the	O
presence	O
of	O
antonym	O
and	O
synonym	O
assertions	O
for	O
all	O
tasks	O
as	O
well	O
as	O
partially	O
on	O
is	O
a	O
and	O
derived	O
from	O
assertions	O
.	O

This	O
is	O
an	O
interesting	O
finding	O
which	O
shows	O
that	O
the	O
sensitivity	O
of	O
our	O
models	O
is	O
selective	O
wrt	O
.	O

the	O
type	O
of	O
knowledge	O
and	O
task	O
.	O

The	O
fact	O
that	O
the	O
largest	O
relative	O
impact	O
stems	O
from	O
antonyms	O
is	O
very	O
interesting	O
because	O
it	O
is	O
known	O
that	O
such	O
information	O
is	O
hard	O
to	O
capture	O
with	O
distributional	O
semantics	O
contained	O
in	O
pre	O
-	O
trained	O
word	Method
embeddings	Method
.	O

