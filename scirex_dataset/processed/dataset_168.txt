document	O
:	O
Multi	Task
-	Task
style	Task
Generative	Task
Reading	Task
Comprehension	Task
This	O
study	O
focuses	O
on	O
the	O
task	O
of	O
multi	Task
-	Task
passage	Task
reading	Task
comprehension	Task
(	Task
RC	Task
)	O
where	O
an	O
answer	O
is	O
provided	O
in	O
natural	Material
language	Material
.	O

Current	O
mainstream	O
approaches	O
treat	O
RC	Method
by	O
extracting	O
the	O
answer	O
span	O
from	O
the	O
provided	O
passages	O
and	O
can	O
not	O
generate	O
an	O
abstractive	O
summary	O
from	O
the	O
given	O
question	O
and	O
passages	O
.	O

Moreover	O
,	O
they	O
can	O
not	O
utilize	O
and	O
control	O
different	O
styles	O
of	O
answers	O
,	O
such	O
as	O
concise	O
phrases	O
and	O
well	O
-	O
formed	O
sentences	O
,	O
within	O
a	O
model	O
.	O

In	O
this	O
study	O
,	O
we	O
propose	O
a	O
style	Method
-	Method
controllable	Method
Multi	Method
-	Method
source	Method
Abstractive	Method
Summarization	Method
model	Method
for	O
QUEstion	Task
answering	Task
,	O
called	O
Masque	Method
.	O

The	O
model	O
is	O
an	O
end	Method
-	Method
to	Method
-	Method
end	Method
deep	Method
neural	Method
network	Method
that	O
can	O
generate	O
answers	O
conditioned	O
on	O
a	O
given	O
style	O
.	O

Experiments	O
with	O
MS	Material
MARCO	Material
2.1	Material
show	O
that	O
our	O
model	O
achieved	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
performance	O
on	O
two	O
tasks	O
with	O
different	O
answer	O
styles	O
.	O

tabular	O
table	O
section	O
:	O
Introduction	O
Question	Task
answering	Task
has	O
been	O
a	O
long	O
-	O
standing	O
research	O
problem	O
.	O

Recently	O
,	O
reading	Task
comprehension	Task
(	O
RC	Task
)	O
,	O
a	O
challenge	O
to	O
answer	O
a	O
question	O
given	O
textual	O
evidence	O
provided	O
in	O
a	O
document	O
set	O
,	O
has	O
received	O
much	O
attention	O
.	O

Here	O
,	O
current	O
mainstream	O
studies	O
have	O
treated	O
RC	Method
as	O
a	O
process	O
of	O
extracting	O
an	O
answer	O
span	O
from	O
one	O
passage	O
RajpurkarZLL16	O
,	O
RajpurkarJL18	O
or	O
multiple	O
passages	O
JoshiCWZ17	O
,	O
which	O
is	O
usually	O
done	O
by	O
predicting	O
the	O
start	O
and	O
end	O
positions	O
of	O
the	O
answer	O
Yu18	Method
,	Method
DevlinCLT18	Method
.	O

The	O
demand	O
for	O
answering	Task
questions	Task
in	Task
natural	Task
language	Task
is	O
increasing	O
rapidly	O
,	O
and	O
this	O
has	O
led	O
to	O
the	O
development	O
of	O
smart	O
devices	O
such	O
as	O
Siri	Material
and	O
Alexa	Material
.	O

However	O
,	O
in	O
comparison	O
with	O
answer	Task
span	Task
extraction	Task
,	O
the	O
natural	Task
language	Task
generation	Task
(	O
NLG	Method
)	Method
ability	Method
for	O
RC	Method
has	O
been	O
less	O
studied	O
.	O

While	O
datasets	O
such	O
as	O
MS	Method
MARCO	Method
Bajaj18	Method
have	O
been	O
proposed	O
for	O
providing	O
abstractive	O
answers	O
in	O
natural	Material
language	Material
,	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
methods	O
WuWLHWLLL18	Method
,	Method
YanAAAI19	Method
are	O
based	O
on	O
answer	Method
span	Method
extraction	Method
,	O
even	O
for	O
the	O
datasets	O
.	O

Generative	Method
models	Method
such	O
as	O
S	Method
-	Method
Net	Method
TanWYDLZ18	Method
suffer	O
from	O
a	O
dearth	O
of	O
training	Material
data	Material
to	O
cover	O
open	Material
-	Material
domain	Material
questions	Material
.	O

Moreover	O
,	O
to	O
satisfy	O
various	O
information	O
needs	O
,	O
intelligent	Method
agents	Method
should	O
be	O
capable	O
of	O
answering	O
one	O
question	O
in	O
multiple	O
styles	O
,	O
such	O
as	O
concise	O
phrases	O
that	O
do	O
not	O
contain	O
the	O
context	O
of	O
the	O
question	O
and	O
well	O
-	O
formed	O
sentences	O
that	O
make	O
sense	O
even	O
without	O
the	O
context	O
of	O
the	O
question	O
.	O

These	O
capabilities	O
complement	O
each	O
other	O
;	O
however	O
,	O
the	O
methods	O
used	O
in	O
previous	O
studies	O
can	O
not	O
utilize	O
and	O
control	O
different	O
answer	O
styles	O
within	O
a	O
model	O
.	O

In	O
this	O
study	O
,	O
we	O
propose	O
a	O
generative	Method
model	Method
,	O
called	O
Masque	Method
,	O
for	O
multi	Task
-	Task
passage	Task
RC	Task
.	O

On	O
the	O
MS	Material
MARCO	Material
2.1	Material
dataset	Material
,	O
Masque	Method
achieves	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
performance	O
on	O
the	O
dataset	O
’s	O
two	O
tasks	O
,	O
Q	Task
&	Task
A	Task
and	O
NLG	Task
,	O
with	O
different	O
answer	O
styles	O
.	O

The	O
main	O
contributions	O
of	O
this	O
study	O
are	O
that	O
our	O
model	O
enables	O
the	O
following	O
two	O
abilities	O
.	O

paragraph	O
:	O
Multi	Task
-	Task
source	Task
abstractive	Task
summarization	Task
based	O
RC	Task
.	O

The	O
first	O
idea	O
is	O
to	O
use	O
a	O
pointer	Method
-	Method
generator	Method
mechanism	Method
for	O
multi	Task
-	Task
passage	Task
RC	Task
,	O
which	O
was	O
originally	O
proposed	O
for	O
text	Task
summarization	Task
SeeLM17	O
.	O

HasselqvistHK17	O
and	O
McCannKXS18	Method
had	O
introduced	O
its	O
RNN	Method
-	Method
based	Method
mechanism	Method
to	O
query	Task
-	Task
based	Task
abstractive	Task
summarization	Task
and	O
question	Task
answering	Task
,	O
respectively	O
;	O
however	O
,	O
their	O
models	O
can	O
not	O
handle	O
multiple	O
passages	O
effectively	O
.	O

We	O
extend	O
the	O
mechanism	O
to	O
a	O
Transformer	Method
VaswaniSPUJGKP17	Method
based	Method
one	Method
that	O
allows	O
words	O
to	O
be	O
generated	O
from	O
a	O
fixed	O
vocabulary	O
and	O
words	O
to	O
be	O
copied	O
from	O
both	O
the	O
question	O
and	O
multiple	O
passages	O
.	O

paragraph	O
:	O
Style	O
-	O
controllable	O
RC	O
.	O

The	O
second	O
novel	O
idea	O
is	O
to	O
introduce	O
a	O
method	O
to	O
control	O
multiple	O
answer	O
styles	O
using	O
a	O
single	O
model	O
,	O
taking	O
advantage	O
of	O
multi	O
-	O
style	O
answers	O
to	O
improve	O
RC	Task
for	O
all	O
styles	O
involved	O
.	O

We	O
also	O
extend	O
the	O
pointer	Method
-	Method
generator	Method
mechanism	Method
to	O
a	O
conditional	Method
decoder	Method
simply	O
by	O
introducing	O
an	O
artificial	O
token	O
corresponding	O
to	O
the	O
target	O
style	O
,	O
like	O
JohnsonSLKWCTVW17	Method
,	Method
TakenoNY17	Method
.	O

It	O
controls	O
the	O
mixture	O
weights	O
over	O
three	O
probability	O
distributions	O
with	O
the	O
given	O
style	O
at	O
each	O
decoding	O
step	O
,	O
as	O
shown	O
in	O
Figure	O
[	O
reference	O
]	O
.	O

section	O
:	O
Problem	O
Formulation	O
The	O
task	O
considered	O
in	O
this	O
paper	O
,	O
is	O
defined	O
as	O
:	O
theorem	O
:	O
.	O

Given	O
a	O
question	O
with	O
words	O
,	O
a	O
set	O
of	O
passages	O
,	O
where	O
each	O
-	O
th	O
passage	O
is	O
composed	O
of	O
words	O
,	O
and	O
an	O
answer	O
style	O
,	O
an	O
RC	Method
system	Method
outputs	O
an	O
answer	O
conditioned	O
on	O
the	O
style	O
.	O

In	O
short	O
,	O
for	O
inference	Task
,	O
given	O
a	O
set	O
of	O
3	O
-	O
tuples	O
,	O
the	O
system	O
predicts	O
.	O

The	O
training	O
data	O
is	O
a	O
set	O
of	O
6	O
-	O
tuples	O
:	O
,	O
where	O
is	O
if	O
the	O
question	O
is	O
answerable	O
with	O
the	O
provided	O
passages	O
and	O
otherwise	O
,	O
and	O
is	O
if	O
the	O
-	O
th	O
passage	O
is	O
required	O
to	O
formulate	O
the	O
answer	O
and	O
otherwise	O
.	O

section	O
:	O
Proposed	O
Model	O
Our	O
proposed	O
model	O
,	O
Masque	Method
,	O
is	O
based	O
on	O
multi	Task
-	Task
source	Task
abstractive	Task
summarization	Task
;	O
the	O
answer	O
our	O
model	O
generates	O
can	O
be	O
viewed	O
as	O
a	O
summary	O
from	O
the	O
question	O
and	O
multiple	O
passages	O
.	O

It	O
is	O
also	O
style	O
-	O
controllable	O
;	O
one	O
model	O
can	O
generate	O
the	O
answer	O
with	O
the	O
target	O
style	O
.	O

Masque	Method
directly	O
models	O
the	O
conditional	O
probability	O
.	O

In	O
addition	O
to	O
multi	Method
-	Method
style	Method
learning	Method
,	O
it	O
considers	O
passage	Task
ranking	Task
and	O
answer	Task
possibility	Task
classification	Task
together	O
as	O
multi	Task
-	Task
task	Task
learning	Task
in	O
order	O
to	O
improve	O
accuracy	Metric
.	O

Figure	O
[	O
reference	O
]	O
shows	O
the	O
model	O
architecture	O
.	O

It	O
consists	O
of	O
the	O
following	O
modules	O
.	O

theorem	O
:	O
.	O

The	O
question	O
-	O
passages	O
reader	O
(	O
§	O
[	O
reference	O
]	O
)	O
models	O
interactions	O
between	O
the	O
question	O
and	O
passages	O
.	O

theorem	O
:	O
.	O

The	O
passage	O
ranker	O
(	O
§	O
[	O
reference	O
]	O
)	O
finds	O
relevant	O
passages	O
to	O
the	O
question	O
.	O

theorem	O
:	O
.	O

The	O
answer	Method
possibility	Method
classifier	Method
(	O
§	O
[	O
reference	O
]	O
)	O
identifies	O
answerable	O
questions	O
.	O

theorem	O
:	O
.	O

The	O
answer	Method
sentence	Method
decoder	Method
(	O
§	O
[	O
reference	O
]	O
)	O
outputs	O
a	O
sequence	O
of	O
words	O
conditioned	O
on	O
the	O
style	O
.	O

subsection	O
:	O
Question	O
-	O
Passages	O
Reader	O
Given	O
a	O
question	O
and	O
passages	O
,	O
the	O
question	O
-	O
passages	O
reader	O
matches	O
them	O
so	O
that	O
the	O
interactions	O
among	O
the	O
question	O
(	O
passage	O
)	O
words	O
conditioned	O
on	O
the	O
passages	O
(	O
question	O
)	O
can	O
be	O
captured	O
.	O

subsubsection	Method
:	O
Word	Method
Embedding	Method
Layer	Method
Let	O
and	O
represent	O
one	O
-	O
hot	O
vectors	O
of	O
words	O
in	O
the	O
question	O
and	O
-	O
th	O
passage	O
.	O

First	O
,	O
this	O
layer	O
projects	O
each	O
of	O
the	O
one	O
-	O
hot	O
vectors	O
(	O
of	O
size	O
)	O
into	O
a	O
-	O
dimensional	O
continuous	O
vector	O
space	O
with	O
a	O
pre	O
-	O
trained	O
weight	O
matrix	O
such	O
as	O
GloVe	Method
PenningtonSM14	Method
.	O

Next	O
,	O
it	O
uses	O
contextualized	Method
word	Method
representations	Method
,	O
ELMo	Method
PetersNIGCLZ18	Method
,	O
which	O
is	O
a	O
character	Method
-	Method
level	Method
two	Method
-	Method
layer	Method
bidirectional	Method
language	Method
model	Method
pre	O
-	O
trained	O
on	O
a	O
large	O
-	O
scale	Material
corpus	Material
.	O

ELMo	Method
representations	Method
allow	O
our	O
model	O
to	O
use	O
morphological	O
clues	O
to	O
form	O
robust	Method
representations	Method
for	O
out	Task
-	Task
of	Task
-	Task
vocabulary	Task
words	Task
unseen	O
in	O
training	O
.	O

Then	O
,	O
the	O
concatenation	O
of	O
the	O
word	O
and	O
contextualized	O
embedding	O
vectors	O
is	O
passed	O
to	O
a	O
two	O
-	O
layer	Method
highway	Method
network	Method
SrivastavaGS15	O
that	O
is	O
shared	O
for	O
the	O
question	O
and	O
passages	O
.	O

subsubsection	Method
:	O
Shared	Method
Encoder	Method
Layer	Method
This	O
layer	O
uses	O
a	O
stack	O
of	O
Transformer	Method
blocks	Method
,	O
which	O
are	O
shared	O
for	O
the	O
question	O
and	O
passages	O
,	O
on	O
top	O
of	O
the	O
embeddings	O
provided	O
by	O
the	O
word	Method
embedding	Method
layer	Method
.	O

The	O
input	O
of	O
the	O
first	O
block	O
is	O
immediately	O
mapped	O
to	O
a	O
-	O
dimensional	O
vector	O
by	O
a	O
linear	Method
transformation	Method
.	O

The	O
outputs	O
of	O
this	O
layer	O
are	O
sequences	O
of	O
-	O
dimensional	O
vectors	O
:	O
for	O
the	O
-	O
th	O
passage	O
and	O
for	O
the	O
question	O
.	O

paragraph	O
:	O
Transformer	Method
encoder	Method
block	Method
.	O

It	O
consists	O
of	O
two	O
sub	O
-	O
layers	O
:	O
a	O
self	Method
-	Method
attention	Method
layer	Method
and	O
a	O
position	Method
-	Method
wise	Method
feed	Method
-	Method
forward	Method
network	Method
.	O

For	O
the	O
self	Task
-	Task
attention	Task
layer	Task
,	O
we	O
adopt	O
the	O
multi	Method
-	Method
head	Method
attention	Method
mechanism	Method
defined	O
in	O
VaswaniSPUJGKP17	Method
.	O

The	O
feed	Method
-	Method
forward	Method
network	Method
consists	O
of	O
two	O
linear	Method
transformations	Method
with	O
a	O
GELU	O
HendrycksG16	O
activation	O
in	O
between	O
,	O
following	O
OpenAI	Method
GPT	Method
RadfordNSS18	Method
.	O

Each	O
sub	O
-	O
layer	O
is	O
placed	O
inside	O
a	O
residual	O
block	O
HeZRS16	O
.	O

For	O
an	O
input	O
and	O
a	O
given	O
sub	O
-	O
layer	O
function	O
,	O
the	O
output	O
is	O
,	O
where	O
indicates	O
the	O
layer	Method
normalization	Method
proposed	O
in	O
BaKH16	O
.	O

To	O
facilitate	O
these	O
residual	O
connections	O
,	O
all	O
sub	O
-	O
layers	O
produce	O
outputs	O
of	O
dimension	O
.	O

Note	O
that	O
our	O
model	O
does	O
not	O
use	O
any	O
position	O
embeddings	O
because	O
ELMo	Method
gives	O
the	O
positional	O
information	O
of	O
the	O
words	O
in	O
each	O
sequence	O
.	O

subsubsection	Method
:	O
Dual	Method
Attention	Method
Layer	Method
This	O
layer	O
fuses	O
information	O
from	O
the	O
passages	O
to	O
the	O
question	O
as	O
well	O
as	O
from	O
the	O
question	O
to	O
the	O
passages	O
in	O
a	O
dual	O
mechanism	O
.	O

It	O
first	O
computes	O
a	O
similarity	O
matrix	O
between	O
the	O
question	O
and	O
-	O
th	O
passage	O
,	O
as	O
is	O
done	O
in	O
SeoKFH17	O
,	O
where	O
indicates	O
the	O
similarity	O
between	O
the	O
-	O
th	O
word	O
of	O
the	O
-	O
th	O
passage	O
and	O
the	O
-	O
th	O
question	O
word	O
.	O

are	O
learnable	O
parameters	O
.	O

The	O
operator	O
denotes	O
the	O
Hadamard	O
product	O
,	O
and	O
the	O
operator	O
means	O
vector	O
concatenation	O
across	O
the	O
rows	O
.	O

Next	O
,	O
it	O
obtains	O
the	O
row	O
and	O
column	O
normalized	O
similarity	O
matrices	O
and	O
.	O

We	O
use	O
DCN	Method
XiongZS17	Method
as	O
the	O
dual	Method
attention	Method
mechanism	Method
to	O
obtain	O
question	Task
-	Task
to	Task
-	Task
passage	Task
representations	Task
:	O
and	O
passage	Task
-	Task
to	Task
-	Task
question	Task
ones	Task
:	O
subsubsection	Method
:	O
Modeling	O
Encoder	Method
Layer	Method
This	O
layer	O
uses	O
a	O
stack	Method
of	Method
Transformer	Method
encoder	Method
blocks	Method
for	O
question	Method
representations	Method
and	O
obtains	O
from	O
.	O

It	O
also	O
uses	O
an	O
another	O
stack	O
for	O
passage	Task
representations	Task
and	O
obtains	O
from	O
for	O
each	O
-	O
th	O
passage	O
.	O

The	O
outputs	O
of	O
this	O
layer	O
,	O
and	O
,	O
are	O
passed	O
on	O
to	O
the	O
answer	Method
sentence	Method
decoder	Method
;	O
the	O
are	O
also	O
passed	O
on	O
to	O
the	O
passage	Method
ranker	Method
and	O
answer	Method
possibility	Method
classifier	Method
.	O

subsection	O
:	O
Passage	Method
Ranker	Method
The	O
passage	Method
ranker	Method
maps	O
the	O
output	O
of	O
the	O
modeling	Method
layer	Method
,	O
,	O
to	O
the	O
relevance	O
score	O
of	O
each	O
passage	O
.	O

To	O
obtain	O
a	O
fixed	O
-	O
dimensional	Method
pooled	Method
representation	Method
of	O
each	O
passage	O
sequence	O
,	O
this	O
layer	O
takes	O
the	O
output	O
for	O
the	O
first	O
passage	O
word	O
,	O
,	O
which	O
corresponds	O
to	O
the	O
beginning	O
-	O
of	O
-	O
sentence	O
token	O
.	O

It	O
calculates	O
the	O
relevance	O
of	O
each	O
-	O
th	O
passage	O
to	O
the	O
question	O
as	O
:	O
where	O
are	O
learnable	O
parameters	O
.	O

subsection	O
:	O
Answer	Method
Possibility	Method
Classifier	Method
The	O
answer	Method
possibility	Method
classifier	Method
maps	O
the	O
output	O
of	O
the	O
modeling	Method
layer	Method
,	O
,	O
to	O
the	O
probability	O
of	O
the	O
answer	O
possibility	O
.	O

The	O
classifier	Method
takes	O
the	O
output	O
for	O
the	O
first	O
word	O
,	O
,	O
for	O
all	O
passages	O
and	O
concatenates	O
them	O
to	O
obtain	O
a	O
fixed	Method
-	Method
dimensional	Method
representation	Method
.	O

It	O
calculates	O
the	O
answer	O
possibility	O
to	O
the	O
question	O
as	O
:	O
where	O
are	O
learnable	O
parameters	O
.	O

subsection	O
:	O
Answer	Method
Sentence	Method
Decoder	Method
Given	O
the	O
outputs	O
provided	O
by	O
the	O
reader	O
,	O
the	O
decoder	Method
generates	O
a	O
sequence	O
of	O
answer	O
words	O
one	O
element	O
at	O
a	O
time	O
.	O

It	O
is	O
auto	Method
-	Method
regressive	Method
Graves13	Method
,	O
consuming	O
the	O
previously	O
generated	O
words	O
as	O
additional	O
input	O
at	O
each	O
decoding	O
step	O
.	O

subsubsection	Method
:	O
Word	Method
Embedding	Method
Layer	Method
Let	O
represent	O
one	O
-	O
hot	O
vectors	O
of	O
words	O
in	O
the	O
answer	O
.	O

This	O
layer	O
has	O
the	O
same	O
components	O
as	O
the	O
word	Method
embedding	Method
layer	Method
of	O
the	O
question	Task
-	Task
passages	Task
reader	Task
,	O
except	O
that	O
it	O
uses	O
a	O
unidirectional	O
ELMo	O
in	O
order	O
to	O
ensure	O
that	O
the	O
predictions	O
for	O
position	O
depend	O
only	O
on	O
the	O
known	O
outputs	O
at	O
positions	O
less	O
than	O
.	O

Moreover	O
,	O
to	O
be	O
able	O
to	O
make	O
use	O
of	O
multiple	O
answer	O
styles	O
within	O
a	O
single	O
system	O
,	O
our	O
model	O
introduces	O
an	O
artificial	O
token	O
corresponding	O
to	O
the	O
target	O
style	O
at	O
the	O
beginning	O
of	O
the	O
answer	O
sentence	O
(	O
)	O
,	O
like	O
TakenoNY17	O
.	O

At	O
test	O
time	O
,	O
the	O
user	O
can	O
specify	O
the	O
first	O
token	O
to	O
control	O
the	O
answer	O
styles	O
.	O

This	O
modification	O
does	O
not	O
require	O
any	O
changes	O
to	O
the	O
model	Method
architecture	Method
.	O

Note	O
that	O
introducing	O
the	O
tokens	O
on	O
the	O
decoder	O
side	O
prevents	O
the	O
passage	Method
ranker	Method
and	O
answer	Method
possibility	Method
classifier	Method
from	O
depending	O
on	O
the	O
answer	O
style	O
.	O

subsubsection	Method
:	O
Attentional	Method
Decoder	Method
Layer	Method
This	O
layer	O
uses	O
a	O
stack	Method
of	Method
Transformer	Method
decoder	Method
blocks	Method
on	O
top	O
of	O
the	O
embeddings	O
provided	O
by	O
the	O
word	Method
embedding	Method
layer	Method
.	O

The	O
input	O
is	O
immediately	O
mapped	O
to	O
a	O
-	O
dimensional	O
vector	O
by	O
a	O
linear	Method
transformation	Method
,	O
and	O
the	O
output	O
of	O
this	O
layer	O
is	O
a	O
sequence	O
of	O
-	O
dimensional	O
vectors	O
:	O
.	O

paragraph	O
:	O
Transformer	Method
decoder	Method
block	Method
.	O

In	O
addition	O
to	O
the	O
encoder	Method
block	Method
,	O
this	O
block	O
consists	O
of	O
second	O
and	O
third	O
sub	O
-	O
layers	O
after	O
the	O
self	Method
-	Method
attention	Method
block	Method
and	O
before	O
the	O
feed	Method
-	Method
forward	Method
network	Method
,	O
as	O
shown	O
in	O
Figure	O
[	O
reference	O
]	O
.	O

As	O
in	O
VaswaniSPUJGKP17	O
,	O
the	O
self	Method
-	Method
attention	Method
sub	Method
-	Method
layer	Method
uses	O
a	O
sub	O
-	O
sequent	O
mask	O
to	O
prevent	O
positions	O
from	O
attending	O
to	O
subsequent	O
positions	O
.	O

The	O
second	O
and	O
third	O
sub	O
-	O
layers	O
perform	O
the	O
multi	Task
-	Task
head	Task
attention	Task
over	O
and	O
,	O
respectively	O
.	O

The	O
is	O
the	O
concatenated	O
outputs	O
of	O
the	O
encoder	Method
stack	Method
for	O
the	O
passages	O
,	O
The	O
operator	O
means	O
vector	Method
concatenation	Method
across	O
the	O
columns	O
.	O

This	O
attention	O
for	O
the	O
concatenated	O
passages	O
enables	O
our	O
model	O
to	O
produce	O
attention	O
weights	O
that	O
are	O
comparable	O
between	O
passages	O
.	O

subsubsection	O
:	O
Multi	Method
-	Method
source	Method
Pointer	Method
-	Method
Generator	Method
Our	O
extended	O
mechanism	O
allows	O
both	O
words	O
to	O
be	O
generated	O
from	O
a	O
fixed	O
vocabulary	O
and	O
words	O
to	O
be	O
copied	O
from	O
both	O
the	O
question	O
and	O
multiple	O
passages	O
.	O

Figure	O
[	O
reference	O
]	O
shows	O
the	O
overview	O
.	O

paragraph	O
:	O
Extended	Method
vocabulary	Method
distribution	Method
.	O

Let	O
the	O
extended	O
vocabulary	O
,	O
,	O
be	O
the	O
union	O
of	O
the	O
common	O
words	O
(	O
a	O
small	O
subset	O
of	O
the	O
full	O
vocabulary	O
,	O
,	O
defined	O
by	O
the	O
reader	O
-	O
side	O
word	O
embedding	O
matrix	O
)	O
and	O
all	O
words	O
appearing	O
in	O
the	O
input	O
question	O
and	O
passages	O
.	O

denotes	O
the	O
probability	O
distribution	O
of	O
the	O
-	O
th	O
answer	O
word	O
,	O
,	O
over	O
the	O
extended	Material
vocabulary	Material
.	O

It	O
is	O
defined	O
as	O
:	O
where	O
the	O
output	O
embedding	O
is	O
tied	O
with	O
the	O
corresponding	O
part	O
of	O
the	O
input	O
embedding	O
InanKS17	O
,	O
and	O
and	O
are	O
learnable	O
parameters	O
.	O

is	O
zero	O
if	O
is	O
an	O
out	O
-	O
of	O
-	O
vocabulary	O
word	O
for	O
.	O

paragraph	O
:	O
Copy	O
distribution	O
.	O

The	O
copy	Method
mechanism	Method
used	O
in	O
the	O
original	O
pointer	Method
-	Method
generator	Method
is	O
based	O
on	O
the	O
attention	O
weights	O
of	O
a	O
single	Method
-	Method
layer	Method
attentional	Method
RNN	Method
decoder	Method
SeeLM17	Method
.	O

The	O
attention	O
weights	O
in	O
our	O
decoder	Method
stack	Method
are	O
the	O
intermediate	O
outputs	O
in	O
multi	O
-	O
head	O
attentions	O
and	O
are	O
not	O
suitable	O
for	O
the	O
copy	Method
mechanism	Method
.	O

Therefore	O
,	O
our	O
model	O
also	O
uses	O
additive	O
attentions	O
for	O
the	O
question	O
and	O
multiple	O
passages	O
on	O
top	O
of	O
the	O
decoder	O
stack	O
.	O

The	O
layer	O
takes	O
as	O
the	O
query	O
and	O
outputs	O
(	O
)	O
as	O
the	O
attention	O
weights	O
and	O
(	O
)	O
as	O
the	O
context	O
vectors	O
for	O
the	O
question	O
(	O
passages	O
)	O
:	O
where	O
,	O
,	O
,	O
,	O
,	O
,	O
and	O
,	O
are	O
learnable	O
parameters	O
.	O

and	O
are	O
the	O
copy	O
distributions	O
over	O
the	O
extended	Material
vocabulary	Material
,	O
defined	O
as	O
:	O
where	O
means	O
the	O
passage	O
index	O
corresponding	O
to	O
the	O
-	O
th	O
word	O
in	O
the	O
concatenated	O
passages	O
.	O

paragraph	O
:	O
Final	O
distribution	O
.	O

The	O
final	O
distribution	O
of	O
the	O
-	O
th	O
answer	O
word	O
,	O
,	O
is	O
defined	O
as	O
a	O
mixture	O
of	O
the	O
three	O
distributions	O
:	O
where	O
the	O
mixture	O
weights	O
are	O
given	O
by	O
,	O
are	O
learnable	O
parameters	O
.	O

subsubsection	Method
:	O
Combined	Method
Attention	Method
In	O
order	O
not	O
to	O
use	O
words	O
in	O
irrelevant	O
passages	O
,	O
our	O
model	O
introduces	O
the	O
concept	O
of	O
combined	Method
attention	Method
SunHLLMT18	Method
.	O

While	O
the	O
original	O
technique	O
combines	O
the	O
word	O
and	O
sentence	O
level	O
attentions	O
,	O
our	O
model	O
combines	O
the	O
passage	O
-	O
level	O
relevance	O
and	O
word	O
-	O
level	O
attentions	O
by	O
using	O
simple	O
scalar	Method
multiplication	Method
and	O
re	Method
-	Method
normalization	Method
.	O

The	O
updated	O
word	O
attention	O
is	O
:	O
subsection	O
:	O
Loss	Method
Function	Method
We	O
define	O
the	O
training	Metric
loss	Metric
as	O
the	O
sum	O
of	O
losses	O
in	O
where	O
is	O
the	O
set	O
of	O
all	O
learnable	O
parameters	O
,	O
and	O
and	O
are	O
balancing	O
parameters	O
.	O

The	O
loss	O
of	O
the	O
decoder	Method
,	O
,	O
is	O
the	O
negative	O
log	O
likelihood	O
of	O
the	O
whole	O
target	O
answer	O
sentence	O
averaged	O
over	O
answerable	O
examples	O
:	O
where	O
is	O
the	O
training	O
dataset	O
.	O

The	O
losses	Metric
of	O
the	O
passage	Method
ranker	Method
,	O
,	O
and	O
the	O
answer	Method
possibility	Method
classifier	Method
,	O
,	O
are	O
the	O
binary	Metric
cross	Metric
entropy	Metric
between	O
the	O
true	O
and	O
predicted	O
values	O
averaged	O
over	O
all	O
examples	O
:	O
section	O
:	O
Experiments	O
subsection	O
:	O
Setup	O
paragraph	O
:	O
Datasets	O
and	O
styles	O
.	O

We	O
conducted	O
experiments	O
on	O
the	O
two	O
tasks	O
of	O
MS	Material
MARCO	Material
2.1	O
Bajaj18	O
.	O

The	O
answer	O
styles	O
considered	O
in	O
the	O
experiments	O
corresponded	O
to	O
the	O
two	O
tasks	O
.	O

The	O
NLG	Task
task	Task
requires	O
a	O
well	O
-	O
formed	O
answer	O
that	O
is	O
an	O
abstractive	O
summary	O
of	O
the	O
question	O
and	O
ten	O
passages	O
,	O
averaging	O
16.6	O
words	O
.	O

The	O
Q	Task
&	Task
A	Task
task	Task
also	O
requires	O
an	O
abstractive	O
answer	O
but	O
prefers	O
a	O
more	O
concise	O
answer	O
than	O
the	O
NLG	Task
task	Task
,	O
averaging	O
13.1	O
words	O
,	O
where	O
many	O
of	O
the	O
answers	O
do	O
not	O
contain	O
the	O
context	O
of	O
the	O
question	O
.	O

For	O
instance	O
,	O
for	O
the	O
question	O
“	O
tablespoon	O
in	O
cup	O
”	O
,	O
the	O
answer	O
in	O
the	O
Q	Task
&	Task
A	Task
task	Task
will	O
be	O
“	O
16	O
”	O
,	O
and	O
the	O
answer	O
in	O
the	O
NLG	Task
task	Task
will	O
be	O
“	O
There	O
are	O
16	O
tablespoons	O
in	O
a	O
cup	O
.	O

”	O
In	O
addition	O
to	O
the	O
ALL	O
dataset	O
,	O
we	O
prepared	O
two	O
subsets	O
(	O
Table	O
[	O
reference	O
]	O
)	O
.	O

The	O
ANS	Material
set	Material
consists	O
of	O
answerable	Material
questions	Material
,	O
and	O
the	O
WFA	Material
set	Material
consists	O
of	O
the	O
answerable	O
questions	O
and	O
well	O
-	O
formed	O
answers	O
,	O
where	O
WFA	Method
ANS	Method
ALL	O
.	O

paragraph	O
:	O
Model	O
configurations	O
.	O

We	O
trained	O
our	O
model	O
on	O
a	O
machine	O
with	O
eight	O
NVIDIA	Method
P100	Method
GPUs	Method
.	O

Our	O
model	O
was	O
jointly	O
trained	O
with	O
the	O
two	O
answer	O
styles	O
in	O
the	O
ALL	O
set	O
for	O
a	O
total	O
of	O
eight	O
epochs	O
with	O
a	O
batch	O
size	O
of	O
80	O
.	O

The	O
training	O
took	O
roughly	O
six	O
days	O
.	O

The	O
ensemble	Method
model	Method
consists	O
of	O
six	O
training	O
runs	O
with	O
the	O
identical	O
architecture	O
and	O
hyperparameters	O
.	O

The	O
hidden	O
size	O
was	O
304	O
,	O
and	O
the	O
number	O
of	O
attention	O
heads	O
was	O
8	O
.	O

The	O
inner	O
state	O
size	O
of	O
the	O
feed	Method
-	Method
forward	Method
networks	Method
was	O
256	O
.	O

The	O
numbers	O
of	O
shared	O
encoding	O
blocks	O
,	O
modeling	O
blocks	O
for	O
question	O
,	O
modeling	O
blocks	O
for	O
passages	O
,	O
and	O
decoder	O
blocks	O
were	O
3	O
,	O
2	O
,	O
5	O
,	O
and	O
8	O
,	O
respectively	O
.	O

We	O
used	O
the	O
pre	O
-	O
trained	O
uncased	Material
300	Material
-	Material
dimensional	Material
GloVe	Material
PenningtonSM14	Material
and	O
the	O
original	O
512	Method
-	Method
dimensional	Method
ELMo	Method
PetersNIGCLZ18	Method
.	O

We	O
used	O
the	O
spaCy	Method
tokenizer	Method
,	O
and	O
all	O
words	O
were	O
lowercased	O
except	O
the	O
input	O
for	O
ELMo	Method
.	O

The	O
number	O
of	O
common	O
words	O
in	O
was	O
5	O
,	O
000	O
.	O

paragraph	O
:	O
Optimizer	O
.	O

We	O
used	O
the	O
Adam	Method
optimization	Method
KingmaB15	Method
with	O
,	O
,	O
and	O
.	O

Weights	O
were	O
initialized	O
using	O
,	O
except	O
that	O
the	O
biases	O
of	O
all	O
the	O
linear	Method
transformations	Method
were	O
initialized	O
with	O
zero	O
vectors	O
.	O

The	O
learning	Metric
rate	Metric
was	O
increased	O
linearly	O
from	O
zero	O
to	O
in	O
the	O
first	O
2	O
,	O
000	O
steps	O
and	O
annealed	O
to	O
0	O
using	O
a	O
cosine	Method
schedule	Method
.	O

All	O
parameter	O
gradients	O
were	O
clipped	O
to	O
a	O
maximum	O
norm	O
of	O
.	O

An	O
exponential	Method
moving	Method
average	Method
was	O
applied	O
to	O
all	O
trainable	O
variables	O
with	O
a	O
decay	Metric
rate	Metric
0.9995	O
.	O

The	O
balancing	O
factors	O
of	O
joint	Method
learning	Method
,	O
and	O
,	O
were	O
set	O
to	O
0.5	O
and	O
0.1	O
.	O

paragraph	O
:	O
Regularization	Task
.	O

We	O
used	O
a	O
modified	O
version	O
of	O
the	O
L	Method
regularization	Method
proposed	O
in	O
LoshchilovH17	Method
,	O
with	O
.	O

We	O
additionally	O
used	O
a	O
dropout	Metric
SrivastavaHKSS14	Metric
rate	Metric
of	Metric
0.3	Metric
for	O
all	O
highway	Method
networks	Method
and	O
residual	O
and	O
scaled	Method
dot	Method
-	Method
product	Method
attention	Method
operations	Method
in	O
the	O
multi	Method
-	Method
head	Method
attention	Method
mechanism	Method
.	O

We	O
also	O
used	O
one	O
-	O
sided	Method
label	Method
smoothing	Method
SzegedyVISW16	Method
for	O
the	O
passage	Task
relevance	Task
and	Task
answer	Task
possibility	Task
labels	Task
.	O

We	O
smoothed	O
only	O
the	O
positive	O
labels	O
to	O
0.9	O
.	O

subsection	O
:	O
Results	O
paragraph	O
:	O
Does	O
our	O
model	O
achieve	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
performance	O
for	O
generative	Task
RC	Task
?	O
Table	O
[	O
reference	O
]	O
shows	O
that	O
our	O
ensemble	Method
model	Method
,	O
controlled	O
with	O
the	O
NLG	Method
and	Method
Q	Method
&	Method
A	Method
styles	Method
,	O
achieved	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
performance	O
on	O
the	O
NLG	Task
and	Task
Q	Task
&	Task
A	Task
tasks	Task
in	O
terms	O
of	O
Rouge	Metric
-	Metric
L.	Metric
In	O
particular	O
,	O
for	O
the	O
NLG	Task
task	Task
,	O
our	O
single	O
model	O
outperformed	O
competing	O
models	O
in	O
terms	O
of	O
both	O
Rouge	Metric
-	Metric
L	Metric
and	Metric
Bleu	Metric
-	Metric
1	Metric
.	O

The	O
capability	O
of	O
creating	O
abstractive	O
summaries	O
from	O
the	O
question	O
and	O
passages	O
contributed	O
to	O
its	O
improvements	O
over	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
extractive	Method
approaches	Method
WuWLHWLLL18	O
,	O
YanAAAI19	O
.	O

paragraph	O
:	O
Does	O
our	O
multi	Method
-	Method
style	Method
learning	Method
improve	O
NLG	Task
performance	O
?	O
Table	O
[	O
reference	O
]	O
shows	O
the	O
results	O
of	O
the	O
ablation	Metric
test	Metric
for	O
our	O
model	O
(	O
controlled	O
with	O
the	O
NLG	O
style	O
)	O
on	O
the	O
well	O
-	O
formed	O
answers	O
of	O
the	O
WFA	Material
dev	Material
.	O

set	O
.	O

Our	O
model	O
,	O
which	O
was	O
trained	O
with	O
the	O
ALL	O
set	O
consisting	O
of	O
the	O
two	O
styles	O
,	O
outperformed	O
the	O
model	O
trained	O
with	O
the	O
WFA	Material
set	Material
consisting	O
of	O
the	O
single	O
style	O
.	O

Multi	Method
-	Method
style	Method
learning	Method
allowed	O
our	O
model	O
to	O
improve	O
NLG	Task
performance	O
by	O
also	O
using	O
non	O
-	O
sentence	O
answers	O
.	O

paragraph	O
:	O
Does	O
our	O
Transformer	Method
-	Method
based	Method
pointer	Method
-	Method
generator	Method
improve	O
NLG	Method
performance	O
?	O
Table	O
[	O
reference	O
]	O
shows	O
that	O
our	O
model	O
outperformed	O
the	O
model	O
that	O
used	O
RNNs	Method
and	O
self	O
-	O
attentions	O
instead	O
of	O
Transformer	O
blocks	O
as	O
in	O
MCAN	Method
McCannKXS18	Method
.	O

Our	O
deep	Method
Transformer	Method
decoder	Method
captured	O
the	O
interaction	O
among	O
the	O
question	O
,	O
the	O
passages	O
,	O
and	O
the	O
answer	O
better	O
than	O
a	O
single	Method
-	Method
layer	Method
LSTM	Method
decoder	Method
.	O

paragraph	O
:	O
Does	O
our	O
joint	Method
learning	Method
with	O
the	O
ranker	Method
and	Method
classifier	Method
improve	O
NLG	Task
performance	O
?	O
Table	O
[	O
reference	O
]	O
shows	O
that	O
our	O
model	O
(	O
jointly	O
trained	O
with	O
the	O
passage	Method
ranker	Method
and	Method
answer	Method
possibility	Method
classifier	Method
)	O
outperformed	O
the	O
model	O
that	O
did	O
not	O
use	O
the	O
ranker	Method
and	Method
classifier	Method
.	O

The	O
joint	Method
learning	Method
has	O
a	O
regularization	O
effect	O
on	O
the	O
question	Task
-	Task
passages	Task
reader	Task
.	O

We	O
also	O
confirmed	O
that	O
the	O
gold	Method
passage	Method
ranker	Method
,	O
which	O
can	O
predict	O
passage	O
relevances	O
perfectly	O
,	O
improves	O
RC	Task
performance	O
significantly	O
.	O

Passage	Task
re	Task
-	Task
ranking	Task
will	O
be	O
a	O
key	O
to	O
developing	O
a	O
system	O
that	O
can	O
outperform	O
humans	O
.	O

paragraph	O
:	O
Does	O
our	O
joint	Method
learning	Method
improve	O
the	O
passage	Task
re	Task
-	Task
ranking	Task
performance	O
?	O
Table	O
[	O
reference	O
]	O
shows	O
the	O
passage	Task
re	Task
-	Task
ranking	Task
performance	O
for	O
the	O
ten	O
given	O
passages	O
on	O
the	O
ANS	Material
dev	Material
.	O

set	O
.	O

Our	O
ranker	Method
improved	O
the	O
initial	O
ranking	Metric
provided	O
by	O
Bing	Method
by	O
a	O
significant	O
margin	O
.	O

Also	O
,	O
the	O
ranker	Method
shares	O
the	O
question	Method
-	Method
passages	Method
reader	Method
with	O
the	O
answer	Method
decoder	Method
,	O
and	O
this	O
sharing	O
contributed	O
to	O
the	O
improvements	O
over	O
the	O
ranker	Method
trained	O
without	O
the	O
answer	Method
decoder	Method
.	O

This	O
result	O
is	O
similar	O
to	O
those	O
reported	O
in	O
NishidaSOAT18	O
.	O

Moreover	O
,	O
the	O
joint	Method
learning	Method
with	O
the	O
answer	Method
possibility	Method
classifier	Method
and	O
multiple	O
answer	O
styles	O
,	O
which	O
enables	O
our	O
model	O
to	O
learn	O
from	O
a	O
larger	O
number	O
of	O
data	O
,	O
improved	O
the	O
re	Task
-	Task
ranking	Task
.	O

paragraph	O
:	O
Does	O
our	O
model	O
accurately	O
identify	O
answerable	O
questions	O
?	O
Figure	O
[	O
reference	O
]	O
shows	O
the	O
precision	Metric
-	Metric
recall	Metric
curve	Metric
of	O
answer	Task
possibility	Task
classification	Task
on	O
the	O
ALL	O
dev	O
.	O

set	O
,	O
where	O
the	O
positive	O
class	O
is	O
the	O
answerable	Material
data	Material
.	O

Our	O
model	O
identified	O
the	O
answerable	O
questions	O
well	O
.	O

The	O
maximum	O
score	O
was	O
0.7893	O
.	O

This	O
is	O
the	O
first	O
report	O
on	O
answer	Task
possibility	Task
classification	Task
with	O
MS	Material
MARCO	Material
2.1	Material
.	O

paragraph	O
:	O
Does	O
our	O
model	O
accurately	O
control	O
answers	O
with	O
different	O
styles	O
?	O
Figure	O
[	O
reference	O
]	O
shows	O
the	O
lengths	O
of	O
the	O
answers	O
generated	O
by	O
our	O
model	O
,	O
which	O
are	O
broken	O
down	O
by	O
answer	O
style	O
and	O
query	O
type	O
.	O

The	O
generated	O
answers	O
were	O
relatively	O
shorter	O
than	O
the	O
reference	O
answers	O
but	O
well	O
controlled	O
with	O
the	O
target	O
style	O
in	O
every	O
query	O
type	O
.	O

Also	O
,	O
we	O
should	O
note	O
that	O
our	O
model	O
does	O
not	O
guarantee	O
the	O
consistency	O
in	O
terms	O
of	O
meaning	O
across	O
the	O
answer	O
styles	O
.	O

We	O
randomly	O
selected	O
100	O
questions	O
and	O
compared	O
the	O
answers	O
our	O
model	O
generated	O
with	O
the	O
NLG	Method
and	Method
Q	Method
&	Method
A	Method
styles	Method
.	O

The	O
consistency	Metric
ratio	Metric
was	O
0.81	O
,	O
where	O
major	O
errors	O
were	O
due	O
to	O
copying	O
words	O
from	O
different	O
parts	O
of	O
the	O
passages	O
and	O
generating	O
different	O
words	O
,	O
especially	O
yes	O
/	O
no	O
,	O
from	O
a	O
fixed	O
vocabulary	O
.	O

paragraph	O
:	O
Error	Method
analysis	Method
.	O

Appendix	O
[	O
reference	O
]	O
shows	O
examples	O
of	O
generated	O
answers	O
.	O

We	O
found	O
(	O
d	O
)	O
style	O
errors	O
;	O
(	O
e	O
)	O
yes	O
/	O
no	O
classification	O
errors	O
;	O
(	O
f	O
)	O
copy	O
errors	O
with	O
respect	O
to	O
numerical	O
values	O
;	O
and	O
(	O
c	O
,	O
e	O
)	O
grammatical	O
errors	O
that	O
were	O
originally	O
contained	O
in	O
the	O
inputs	O
.	O

section	O
:	O
Related	O
Work	O
and	O
Discussion	O
paragraph	O
:	O
RC	O
with	O
NLG	Method
.	O

MCAN	Method
McCannKXS18	Method
frames	O
various	O
tasks	O
as	O
question	Task
answering	Task
tasks	Task
that	O
take	O
a	O
3	O
-	O
tuple	O
(	O
question	O
,	O
context	O
,	O
answer	O
)	O
as	O
inputs	O
.	O

It	O
uses	O
a	O
pointer	Method
-	Method
generator	Method
decoder	Method
to	O
jointly	O
learn	O
all	O
tasks	O
without	O
any	O
task	O
-	O
specific	O
parameters	O
;	O
unlike	O
ours	O
,	O
it	O
can	O
not	O
modify	O
answers	O
with	O
the	O
target	O
style	O
or	O
handle	O
multiple	O
passages	O
.	O

S	Method
-	Method
Net	Method
TanWYDLZ18	Method
uses	O
a	O
generative	Method
model	Method
for	O
multi	Task
-	Task
passage	Task
RC	Task
.	O

It	O
uses	O
answer	Method
extraction	Method
to	O
predict	O
the	O
most	O
important	O
spans	O
from	O
the	O
passage	O
as	O
evidence	O
;	O
then	O
it	O
uses	O
the	O
evidence	O
to	O
generate	O
the	O
final	O
answers	O
.	O

However	O
,	O
it	O
does	O
not	O
handle	O
the	O
extended	O
vocabulary	O
in	O
order	O
to	O
generate	O
words	O
appearing	O
in	O
the	O
question	O
and	O
passages	O
.	O

To	O
the	O
best	O
of	O
our	O
knowledge	O
,	O
there	O
are	O
no	O
datasets	O
for	O
providing	O
answers	O
in	O
natural	Material
language	Material
with	O
multiple	O
styles	O
except	O
MS	Material
MARCO	Material
2.1	Material
,	O
although	O
there	O
are	O
some	O
datasets	O
that	O
provide	O
abstractive	O
answers	O
.	O

DuReader	O
HeLLLZXLWWSLWW18	Method
,	O
a	O
Chinese	Material
multi	Material
-	Material
document	Material
RC	Material
dataset	Material
,	O
provides	O
the	O
top	O
-	O
10	O
ranked	O
entire	O
documents	O
from	O
Baidu	Material
Search	Material
and	O
Zhidao	O
.	O

Many	O
of	O
the	O
answers	O
are	O
long	O
and	O
relatively	O
far	O
from	O
the	O
source	O
documents	O
compared	O
with	O
those	O
from	O
MS	Method
MARCO	Method
.	O

NarrativeQA	Material
KociskySBDHMG18	Material
proposed	O
a	O
dataset	O
about	O
stories	Material
or	Material
summaries	Material
of	Material
books	Material
or	O
movie	Material
scripts	Material
.	O

The	O
documents	O
are	O
long	O
,	O
averaging	O
62	O
,	O
528	O
(	O
659	O
)	O
words	O
in	O
stories	O
(	O
summaries	O
)	O
,	O
while	O
the	O
answers	O
are	O
relatively	O
short	O
,	O
averaging	O
4.73	O
words	O
.	O

Moreover	O
,	O
DuoRC	Material
KhapraSSA18	Material
and	O
CoQA	Material
ReddyCM18	Material
contain	O
abstractive	O
answers	O
;	O
most	O
of	O
the	O
answers	O
are	O
short	O
phrases	O
.	O

paragraph	O
:	O
Controllable	Task
text	Task
generation	Task
.	O

Many	O
studies	O
have	O
been	O
carried	O
out	O
in	O
the	O
framework	O
of	O
style	Task
transfer	Task
,	O
which	O
is	O
the	O
task	O
of	O
rephrasing	O
the	O
text	O
so	O
that	O
it	O
contains	O
specific	O
styles	O
such	O
as	O
sentiment	O
.	O

Recent	O
work	O
uses	O
artificial	O
tokens	O
SennrichHB16	O
,	O
JohnsonSLKWCTVW17	O
,	O
variational	Method
auto	Method
-	Method
encoders	Method
HuYLSX17	Method
,	O
adversarial	Method
training	Method
FuTPZY18	Method
,	Method
TsvetkovBSP18	Method
,	O
or	O
prior	O
knowledge	O
LiJHL18	O
to	O
separate	O
the	O
content	O
and	O
style	O
on	O
the	O
encoder	O
side	O
.	O

On	O
the	O
decoder	O
side	O
,	O
conditional	Method
language	Method
modeling	Method
has	O
been	O
used	O
to	O
generate	O
output	O
sentence	O
with	O
the	O
target	O
style	O
.	O

In	O
addition	O
to	O
style	Task
transfer	Task
,	O
output	Method
length	Method
control	Method
with	O
conditional	Method
language	Method
modeling	Method
has	O
been	O
well	O
studied	O
KikuchiNSTO16	O
,	O
TakenoNY17	O
,	O
FanGA18	O
.	O

Our	O
style	Method
-	Method
controllable	Method
RC	Method
relies	O
on	O
conditional	Method
language	Method
modeling	Method
on	O
the	O
decoder	O
side	O
.	O

paragraph	O
:	O
Multi	Task
-	Task
passage	Task
RC	Task
.	O

The	O
simplest	O
approach	O
is	O
to	O
concatenate	O
the	O
passages	O
and	O
find	O
the	O
answer	O
from	O
the	O
concatenated	O
one	O
as	O
in	O
WangYWCZ17	O
.	O

Earlier	O
pipeline	Method
models	Method
find	O
a	O
small	O
number	O
of	O
relevant	O
passages	O
with	O
a	O
TF	Method
-	Method
IDF	Method
based	Method
ranker	Method
and	O
pass	O
them	O
to	O
a	O
neural	Method
reader	Method
ChenFWB17	Method
,	Method
GardnerC18	Method
,	O
while	O
more	O
recent	O
pipeline	Method
models	Method
use	O
a	O
neural	Method
re	Method
-	Method
ranker	Method
to	O
more	O
accurately	O
select	O
the	O
relevant	O
passages	O
WangAAAI2018	O
,	O
NishidaSOAT18	O
.	O

Also	O
,	O
non	O
-	O
pipelined	Method
models	Method
(	O
including	O
ours	O
)	O
consider	O
all	O
the	O
provided	O
passages	O
and	O
find	O
the	O
answer	O
by	O
comparing	O
scores	O
between	O
passages	O
TanWYDLZ18	O
,	O
WuWLHWLLL18	O
.	O

The	O
most	O
recent	O
models	O
make	O
a	O
proper	O
trade	O
-	O
off	O
between	O
efficiency	Metric
and	O
accuracy	Metric
YanAAAI19	O
,	O
MinZSX18	O
.	O

paragraph	O
:	O
RC	Method
with	O
unanswerable	Task
question	Task
identification	Task
.	O

The	O
previous	O
work	O
of	O
LevySCZ17	O
,	O
GardnerC18	O
outputs	O
a	O
no	O
-	O
answer	O
score	O
depending	O
on	O
the	O
probability	O
of	O
all	O
answer	O
spans	O
.	O

HuWPHYZ18	O
HuWPHYZ18	O
proposed	O
an	O
answer	Method
verifier	Method
to	O
compare	O
the	O
answer	O
sentence	O
with	O
the	O
question	O
.	O

SunLQL18	Method
SunLQL18	Method
proposed	O
a	O
unified	Method
model	Method
that	O
jointly	O
learns	O
an	O
RC	Method
model	Method
and	O
an	O
answer	Method
verifier	Method
.	O

Our	O
model	O
introduces	O
a	O
classifier	Method
on	O
the	O
basis	O
of	O
question	Task
-	Task
passages	Task
matching	Task
,	O
which	O
is	O
not	O
dependent	O
on	O
the	O
generated	O
answer	O
,	O
unlike	O
the	O
previous	O
methods	O
.	O

paragraph	O
:	O
Abstractive	Task
summarization	Task
.	O

Current	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
models	O
use	O
pointer	Method
-	Method
generator	Method
mechanisms	Method
SeeLM17	O
.	O

In	O
particular	O
,	O
content	Method
selection	Method
approaches	Method
,	O
which	O
decide	O
what	O
to	O
summarize	O
,	O
have	O
recently	O
been	O
used	O
with	O
abstractive	Method
models	Method
.	O

Most	O
methods	O
select	O
content	O
at	O
the	O
sentence	O
level	O
HsuLLMTS18	O
,	O
ChenB18	O
and	O
the	O
word	Method
level	Method
PasunuruB18	Method
,	Method
LiXLG18	Method
,	Method
GehrmannDR18	Method
;	O
our	O
model	O
incorporates	O
content	Method
selection	Method
at	O
the	O
passage	O
level	O
in	O
the	O
combined	Method
attention	Method
.	O

Query	Task
-	Task
based	Task
abstractive	Task
summarization	Task
has	O
been	O
rarely	O
studied	O
.	O

NemaKLR17	O
proposed	O
an	O
attentional	Method
encoder	Method
-	Method
decoder	Method
model	Method
,	O
and	O
KhapraSSA18	O
reported	O
that	O
it	O
performed	O
worse	O
than	O
BiDAF	Method
on	O
DuoRC	Material
.	O

HasselqvistHK17	O
proposed	O
a	O
pointer	Method
-	Method
generator	Method
based	Method
model	Method
;	O
however	O
,	O
it	O
does	O
not	O
consider	O
copying	O
words	O
from	O
the	O
question	O
and	O
multiple	O
passages	O
.	O

section	O
:	O
Conclusion	O
We	O
believe	O
our	O
study	O
makes	O
two	O
contributions	O
to	O
the	O
study	O
of	O
multi	Task
-	Task
passage	Task
RC	Task
with	O
NLG	Task
.	O

Our	O
model	O
enables	O
1	O
)	O
multi	Method
-	Method
source	Method
abstractive	Method
summarization	Method
based	Method
RC	Method
and	O
2	O
)	O
style	Method
-	Method
controllable	Method
RC	Method
.	O

The	O
key	O
strength	O
of	O
our	O
model	O
is	O
its	O
high	O
accuracy	Metric
of	O
generating	O
abstractive	O
summaries	O
from	O
the	O
question	O
and	O
passages	O
;	O
our	O
model	O
achieved	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
performance	O
in	O
terms	O
of	O
Rouge	Metric
-	Metric
L	Metric
on	O
the	O
Q	Task
&	Task
A	Task
and	Task
NLG	Task
tasks	Task
of	O
MS	Task
MARCO	Task
2.1	O
that	O
have	O
different	O
answer	O
styles	O
Bajaj18	O
.	O

The	O
styles	O
considered	O
in	O
this	O
paper	O
are	O
only	O
related	O
to	O
the	O
context	O
of	O
the	O
question	O
in	O
the	O
answer	O
sentence	O
;	O
our	O
model	O
will	O
be	O
promising	O
for	O
controlling	O
other	O
styles	O
such	O
as	O
length	O
and	O
speaking	O
styles	O
.	O

Future	O
work	O
will	O
involve	O
exploring	O
the	O
potential	O
of	O
hybrid	Method
models	Method
combining	O
extractive	Method
and	Method
abstractive	Method
approaches	Method
and	O
improving	O
the	O
passage	Task
re	Task
-	Task
ranking	Task
and	O
answerable	Task
question	Task
identification	Task
.	O

bibliography	O
:	O
References	O
appendix	O
:	O
Reading	Material
Comprehension	Material
Examples	Material
generated	O
by	O
Masque	O
from	O
MS	O
MARCO	O
2.1	O
