document	O
:	O
SVDNet	Method
for	O
Pedestrian	Task
Retrieval	Task
This	O
paper	O
proposes	O
the	O
SVDNet	Method
for	O
retrieval	Task
problems	Task
,	O
with	O
focus	O
on	O
the	O
application	O
of	O
person	Task
re	Task
-	Task
identification	Task
(	O
re	Task
-	Task
ID	Task
)	O
.	O

We	O
view	O
each	O
weight	O
vector	O
within	O
a	O
fully	Method
connected	Method
(	O
FC	Method
)	O
layer	O
in	O
a	O
convolutional	Method
neuron	Method
network	Method
(	O
CNN	Method
)	O
as	O
a	O
projection	O
basis	O
.	O

It	O
is	O
observed	O
that	O
the	O
weight	O
vectors	O
are	O
usually	O
highly	O
correlated	O
.	O

This	O
problem	O
leads	O
to	O
correlations	O
among	O
entries	O
of	O
the	O
FC	Method
descriptor	O
,	O
and	O
compromises	O
the	O
retrieval	Task
performance	O
based	O
on	O
the	O
Euclidean	O
distance	O
.	O

To	O
address	O
the	O
problem	O
,	O
this	O
paper	O
proposes	O
to	O
optimize	O
the	O
deep	Method
representation	Method
learning	Method
process	Method
with	O
Singular	Method
Vector	Method
Decomposition	Method
(	O
SVD	Method
)	O
.	O

Specifically	O
,	O
with	O
the	O
restraint	Method
and	Method
relaxation	Method
iteration	Method
(	O
RRI	Method
)	O
training	O
scheme	O
,	O
we	O
are	O
able	O
to	O
iteratively	O
integrate	O
the	O
orthogonality	O
constraint	O
in	O
CNN	Method
training	O
,	O
yielding	O
the	O
so	O
-	O
called	O
SVDNet	Method
.	O

We	O
conduct	O
experiments	O
on	O
the	O
Market	Material
-	Material
1501	Material
,	O
CUHK03	O
,	O
and	O
DukeMTMC	Material
-	Material
reID	Material
datasets	Material
,	O
and	O
show	O
that	O
RRI	Method
effectively	O
reduces	O
the	O
correlation	O
among	O
the	O
projection	O
vectors	O
,	O
produces	O
more	O
discriminative	O
FC	Method
descriptors	O
,	O
and	O
significantly	O
improves	O
the	O
re	Task
-	Task
ID	Task
accuracy	O
.	O

On	O
the	O
Market	Material
-	Material
1501	Material
dataset	Material
,	O
for	O
instance	O
,	O
rank	Metric
-	Metric
1	Metric
accuracy	Metric
is	O
improved	O
from	O
55.3	O
%	O
to	O
80.5	O
%	O
for	O
CaffeNet	Method
,	O
and	O
from	O
73.8	O
%	O
to	O
82.3	O
%	O
for	O
ResNet	Method
-	Method
50	Method
.	O

section	O
:	O
Introduction	O
This	O
paper	O
considers	O
the	O
problem	O
of	O
pedestrian	Task
retrieval	Task
,	O
also	O
called	O
person	Task
re	Task
-	Task
identification	Task
(	O
re	Task
-	Task
ID	Task
)	O
.	O

This	O
task	O
aims	O
at	O
retrieving	O
images	O
containing	O
the	O
same	O
person	O
to	O
the	O
query	O
.	O

Person	O
re	Task
-	Task
ID	Task
is	O
different	O
from	O
image	Task
classification	Task
in	O
that	O
the	O
training	O
and	O
testing	O
sets	O
contain	O
entirely	O
different	O
classes	O
.	O

So	O
a	O
popular	O
deep	Method
learning	Method
method	Method
for	O
re	Task
-	Task
ID	Task
consists	O
of	O
1	O
)	O
training	O
a	O
classification	Method
deep	Method
model	Method
on	O
the	O
training	O
set	O
,	O
2	O
)	O
extracting	O
image	O
descriptors	O
using	O
the	O
fully	Method
-	Method
connected	Method
(	O
FC	Method
)	O
layer	O
for	O
the	O
query	O
and	O
gallery	O
images	O
,	O
and	O
3	O
)	O
computing	O
similarities	O
based	O
on	O
Euclidean	O
distance	O
before	O
returning	O
the	O
sorted	O
list	O
.	O

Our	O
work	O
is	O
motivated	O
by	O
the	O
observation	O
that	O
after	O
training	O
a	O
convolutional	O
neural	O
network	O
(	O
CNN	Method
)	O
for	O
classification	Task
,	O
the	O
weight	O
vectors	O
within	O
a	O
fully	Method
-	Method
connected	Method
layer	O
(	O
FC	Method
)	O
are	O
usually	O
highly	O
correlated	O
.	O

This	O
problem	O
can	O
be	O
attributed	O
to	O
two	O
major	O
reasons	O
.	O

The	O
first	O
reason	O
is	O
related	O
to	O
the	O
non	O
-	O
uniform	O
distribution	O
of	O
training	O
samples	O
.	O

This	O
problem	O
is	O
especially	O
obvious	O
when	O
focusing	O
on	O
the	O
last	O
FC	Method
layer	O
.	O

The	O
output	O
of	O
each	O
neuron	O
in	O
the	O
last	O
FC	Method
layer	O
represents	O
the	O
similarity	O
between	O
the	O
input	O
image	O
and	O
a	O
corresponding	O
identity	O
.	O

After	O
training	O
,	O
neurons	O
corresponding	O
to	O
similar	O
persons	O
(	O
,	O
the	O
persons	O
who	O
wear	O
red	O
and	O
pink	O
clothes	O
)	O
learns	O
highly	O
correlated	O
weight	O
vectors	O
,	O
as	O
shown	O
in	O
Fig	O
.	O

[	O
reference	O
]	O
.	O

The	O
second	O
is	O
that	O
during	O
the	O
training	O
of	O
CNN	Method
,	O
there	O
exists	O
few	O
,	O
if	O
any	O
,	O
constraints	O
for	O
learning	Task
orthogonalization	Task
.	O

Thus	O
the	O
learned	O
weight	O
vectors	O
may	O
be	O
naturally	O
correlated	O
.	O

Correlation	O
among	O
weight	O
vectors	O
of	O
the	O
FC	Method
layer	O
compromises	O
the	O
descriptor	O
significantly	O
when	O
we	O
consider	O
the	O
retrieval	Task
task	Task
under	O
the	O
Euclidean	O
distance	O
.	O

In	O
fact	O
,	O
a	O
critical	O
assumption	O
of	O
using	O
Euclidean	O
distance	O
(	O
or	O
equivalently	O
the	O
cosine	Method
distance	Method
after	O
-	O
normalization	O
)	O
for	O
retrieval	Task
is	O
that	O
the	O
entries	O
in	O
the	O
feature	O
vector	O
should	O
be	O
possibly	O
independent	O
.	O

However	O
,	O
when	O
the	O
weight	O
vectors	O
are	O
correlated	O
,	O
the	O
FC	Method
descriptor	O
–	O
the	O
projection	O
on	O
these	O
weight	O
vectors	O
of	O
the	O
output	O
of	O
a	O
previous	O
CNN	Method
layer	O
–	O
will	O
have	O
correlated	O
entries	O
.	O

This	O
might	O
finally	O
lead	O
to	O
some	O
entries	O
of	O
the	O
descriptor	O
dominating	O
the	O
Euclidean	O
distance	O
,	O
and	O
cause	O
poor	O
ranking	Metric
results	O
.	O

For	O
example	O
,	O
during	O
testing	O
,	O
the	O
images	O
of	O
two	O
different	O
persons	O
are	O
passed	O
through	O
the	O
network	O
to	O
generate	O
the	O
green	O
and	O
black	O
dotted	O
feature	O
vectors	O
and	O
then	O
projected	O
onto	O
the	O
red	O
,	O
pink	O
and	O
blue	O
weight	O
vectors	O
to	O
form	O
the	O
descriptors	O
,	O
as	O
shown	O
in	O
Fig	O
.	O

[	O
reference	O
]	O
.	O

The	O
projection	O
values	O
on	O
both	O
red	O
and	O
pink	O
vectors	O
are	O
close	O
,	O
making	O
the	O
two	O
descriptors	O
appear	O
similar	O
despite	O
of	O
the	O
difference	O
projected	O
on	O
the	O
blue	O
vector	O
.	O

As	O
a	O
consequence	O
,	O
it	O
is	O
of	O
vital	O
importance	O
to	O
reduce	O
the	O
redundancy	O
in	O
the	O
FC	Method
descriptor	O
to	O
make	O
it	O
work	O
under	O
the	O
Euclidean	O
distance	O
.	O

To	O
address	O
the	O
correlation	Task
problem	Task
,	O
we	O
proposes	O
SVDNet	Method
,	O
which	O
is	O
featured	O
by	O
an	O
FC	Method
layer	O
containing	O
decorrelated	O
weight	O
vectors	O
.	O

We	O
also	O
introduce	O
a	O
novel	O
three	Method
-	Method
step	Method
training	Method
scheme	Method
.	O

In	O
the	O
first	O
step	O
,	O
the	O
weight	Method
matrix	Method
undergoes	O
the	O
singular	Method
vector	Method
decomposition	Method
(	O
SVD	Method
)	O
and	O
is	O
replaced	O
by	O
the	O
product	O
of	O
the	O
left	O
unitary	O
matrix	O
and	O
the	O
singular	O
value	O
matrix	O
.	O

Second	O
,	O
we	O
keep	O
the	O
orthogonalized	O
weight	O
matrix	O
fixed	O
and	O
only	O
fine	O
-	O
tune	O
the	O
remaining	O
layers	O
.	O

Third	O
,	O
the	O
weight	O
matrix	O
is	O
unfixed	O
and	O
the	O
network	O
is	O
trained	O
for	O
overall	Task
optimization	Task
.	O

The	O
three	O
steps	O
are	O
iterated	O
to	O
approximate	O
orthogonality	O
on	O
the	O
weight	O
matrix	O
.	O

Experimental	O
results	O
on	O
three	O
large	Task
-	Task
scale	Task
re	Task
-	Task
ID	Task
datasets	Task
demonstrate	O
significant	O
improvement	O
over	O
the	O
baseline	O
network	O
,	O
and	O
our	O
results	O
are	O
on	O
par	O
with	O
the	O
state	O
of	O
the	O
art	O
.	O

section	O
:	O
Related	O
Work	O
Deep	Method
learning	Method
for	O
person	O
re	Task
-	Task
ID	Task
.	O

In	O
person	Task
re	Task
-	Task
ID	Task
task	Task
,	O
deep	Method
learning	Method
methods	Method
can	O
be	O
classified	O
into	O
two	O
classes	O
:	O
similarity	Method
learning	Method
and	O
representation	Method
learning	Method
.	O

The	O
former	O
is	O
also	O
called	O
deep	Method
metric	Method
learning	Method
,	O
in	O
which	O
image	O
pairs	O
or	O
triplets	O
are	O
used	O
as	O
input	O
to	O
the	O
network	O
.	O

In	O
the	O
two	O
early	O
works	O
,	O
Yi	O
and	O
Li	O
use	O
image	O
pairs	O
and	O
inject	O
part	O
priors	O
into	O
the	O
learning	Method
process	Method
.	O

In	O
later	O
works	O
,	O
Varior	Method
incorporate	O
long	Method
short	Method
-	Method
term	Method
memory	Method
(	O
LSTM	Method
)	O
modules	O
into	O
a	O
siamese	Method
network	Method
.	O

LSTMs	Method
process	O
image	O
parts	O
sequentially	O
so	O
that	O
the	O
spatial	O
connections	O
can	O
be	O
memorized	O
to	O
enhance	O
the	O
discriminative	Metric
ability	Metric
of	O
the	O
deep	O
features	O
.	O

Varior	Method
insert	O
a	O
gating	O
function	O
after	O
each	O
convolutional	Method
layer	Method
to	O
capture	O
effective	O
subtle	O
patterns	O
between	O
image	O
pairs	O
.	O

The	O
above	O
-	O
mentioned	O
methods	O
are	O
effective	O
in	O
learning	Task
image	Task
similarities	Task
in	O
an	O
adaptive	O
manner	O
,	O
but	O
may	O
have	O
efficiency	O
problems	O
under	O
large	Task
-	Task
scale	Task
galleries	Task
.	O

The	O
second	O
type	O
of	O
CNN	Method
-	O
based	O
re	Task
-	Task
ID	Task
methods	O
focuses	O
on	O
feature	Method
learning	Method
,	O
which	O
categorizes	O
the	O
training	O
samples	O
into	O
pre	O
-	O
defined	O
classes	O
and	O
the	O
FC	Method
descriptor	O
is	O
used	O
for	O
retrieval	Task
.	O

In	O
,	O
the	O
classification	O
CNN	Method
model	O
is	O
fine	O
-	O
tuned	O
using	O
either	O
the	O
video	O
frames	O
or	O
image	O
bounding	O
boxes	O
to	O
learn	O
a	O
discriminative	Method
embedding	Method
for	O
pedestrian	Task
retrieval	Task
.	O

Xiao	O
propose	O
learning	O
generic	Method
feature	Method
representations	Method
from	O
multiple	O
re	Task
-	Task
ID	Task
datasets	O
jointly	O
.	O

To	O
deal	O
with	O
spatial	O
misalignment	O
,	O
Zheng	O
propose	O
the	O
PoseBox	O
structure	O
similar	O
to	O
the	O
pictorial	O
structure	O
to	O
learn	O
pose	O
invariant	O
embeddings	O
.	O

To	O
take	O
advantage	O
of	O
both	O
the	O
feature	Method
learning	Method
and	O
similarity	Method
learning	Method
,	O
Zheng	O
and	O
Geng	Method
combine	O
the	O
contrastive	Method
loss	Method
and	O
the	O
identification	Method
loss	Method
to	O
improve	O
the	O
discriminative	Metric
ability	Metric
of	O
the	O
learned	O
feature	Method
embedding	Method
,	O
following	O
the	O
success	O
in	O
face	Task
verification	Task
.	O

This	O
paper	O
adopts	O
the	O
classification	Method
mode	Method
,	O
which	O
is	O
shown	O
to	O
produce	O
competitive	Metric
accuracy	Metric
without	O
losing	O
efficiency	O
potentials	O
.	O

PCANet	Method
and	O
truncated	O
SVD	Method
for	O
CNN	Method
.	O

We	O
clarify	O
the	O
difference	O
between	O
SVDNet	Method
and	O
several	O
“	O
look	O
-	O
alike	O
”	O
works	O
.	O

The	O
PCANet	Method
is	O
proposed	O
for	O
image	Task
classification	Task
.	O

It	O
is	O
featured	O
by	O
cascaded	O
principal	Method
component	Method
analysis	Method
(	O
PCA	Method
)	O
filters	O
.	O

PCANet	Method
is	O
related	O
to	O
SVDNet	Method
in	O
that	O
it	O
also	O
learns	O
orthogonal	O
projection	O
directions	O
to	O
produce	O
the	O
filters	O
.	O

The	O
proposed	O
SVDNet	Method
differs	O
from	O
PCANet	Method
in	O
two	O
major	O
aspects	O
.	O

First	O
,	O
SVDNet	Method
performs	O
SVD	Method
on	O
the	O
weight	O
matrix	O
of	O
CNN	Method
,	O
while	O
PCANet	Method
performs	O
PCA	Method
on	O
the	O
raw	O
data	O
and	O
feature	O
.	O

Second	O
,	O
the	O
filters	O
in	O
PCANet	Method
are	O
learned	O
in	O
an	O
unsupervised	Method
manner	Method
,	O
which	O
does	O
not	O
rely	O
on	O
back	Method
propagation	Method
as	O
in	O
the	O
case	O
of	O
SVDNet	Method
.	O

In	O
fact	O
,	O
SVDNet	Method
manages	O
a	O
stronger	O
connection	O
between	O
CNN	Method
and	O
SVD	Method
.	O

SVDNet	Method
’s	O
parameters	O
are	O
learned	O
through	O
back	Method
propagation	Method
and	O
decorrelated	Method
iteratively	O
using	O
SVD	Method
.	O

Truncated	O
SVD	Method
is	O
widely	O
used	O
for	O
CNN	Method
model	O
compression	O
.	O

SVDNet	Method
departs	O
from	O
it	O
in	O
two	O
aspects	O
.	O

First	O
,	O
truncated	O
SVD	Method
decomposes	O
the	O
weight	O
matrix	O
in	O
FC	Method
layers	O
and	O
reconstructs	O
it	O
with	O
several	O
dominant	O
singular	O
vectors	O
and	O
values	O
.	O

SVDNet	Method
does	O
not	O
reconstruct	O
the	O
weight	O
matrix	O
but	O
replaces	O
it	O
with	O
an	O
orthogonal	O
matrix	O
,	O
which	O
is	O
the	O
product	O
of	O
the	O
left	O
unitary	O
matrix	O
and	O
the	O
singular	O
value	O
matrix	O
.	O

Second	O
,	O
Truncated	O
SVD	Method
reduces	O
the	O
model	Metric
size	Metric
and	O
testing	Metric
time	Metric
at	O
the	O
cost	O
of	O
acceptable	O
precision	Metric
loss	Metric
,	O
while	O
SVDNet	Method
significantly	O
improves	O
the	O
retrieval	Metric
accuracy	Metric
without	O
impact	O
on	O
the	O
model	Metric
size	Metric
.	O

Orthogonality	O
in	O
the	O
weight	O
matrix	O
.	O

We	O
note	O
a	O
concurrent	O
work	O
which	O
also	O
aims	O
to	O
orthogonalize	O
the	O
CNN	Method
filters	O
,	O
yet	O
our	O
work	O
is	O
different	O
from	O
.	O

In	O
,	O
the	O
regularization	O
effect	O
of	O
orthogonalization	Method
benefits	O
the	O
back	Method
-	Method
propagation	Method
of	Method
very	Method
deep	Method
networks	Method
,	O
thus	O
improving	O
the	O
classification	Metric
accuracy	Metric
.	O

The	O
regularization	Method
proposed	O
in	O
may	O
not	O
directly	O
benefit	O
the	O
embedding	Method
learning	Method
process	Method
.	O

But	O
in	O
this	O
paper	O
,	O
orthogonalization	Method
is	O
used	O
to	O
generate	O
decorrelated	O
descriptors	O
suitable	O
for	O
retrieval	Task
.	O

Our	O
network	O
may	O
not	O
be	O
suitable	O
for	O
improving	O
classification	Task
.	O

section	O
:	O
Proposed	O
Method	O
This	O
section	O
describes	O
the	O
structure	O
of	O
SVDNet	Method
,	O
its	O
training	Method
strategy	Method
,	O
and	O
its	O
working	O
mechanism	O
.	O

subsection	O
:	O
Architecture	O
SVDNet	Method
mostly	O
follows	O
the	O
backbone	Method
networks	Method
,	O
,	O
CaffeNet	O
and	O
ResNet	O
-	O
50	O
.	O

The	O
only	O
difference	O
is	O
that	O
SVDNet	Method
uses	O
the	O
Eigenlayer	Method
as	O
the	O
second	O
last	O
FC	Method
layer	O
,	O
as	O
shown	O
in	O
Fig	O
.	O

[	O
reference	O
]	O
,	O
the	O
Eigenlayer	Method
contains	O
an	O
orthogonal	O
weight	O
matrix	O
and	O
is	O
a	O
linear	Method
layer	Method
without	O
bias	Method
.	O

The	O
reason	O
for	O
not	O
using	O
bias	O
is	O
that	O
the	O
bias	O
will	O
disrupt	O
the	O
learned	O
orthogonality	O
.	O

In	O
fact	O
,	O
our	O
preliminary	O
experiments	O
indicate	O
that	O
adding	O
the	O
ReLU	O
activation	O
and	O
the	O
bias	O
term	O
slightly	O
compromises	O
the	O
re	Task
-	Task
ID	Task
performance	O
,	O
so	O
we	O
choose	O
to	O
implement	O
the	O
Eigenlayer	Method
based	O
on	O
a	O
linear	Method
layer	Method
.	O

The	O
reason	O
for	O
positioning	O
Eigenlayer	O
at	O
the	O
second	O
last	O
FC	Method
layer	O
,	O
rather	O
than	O
the	O
last	O
one	O
is	O
that	O
the	O
model	O
fails	O
to	O
converge	O
when	O
orthogonality	O
is	O
enforced	O
on	O
the	O
last	O
FC	Method
layer	O
,	O
which	O
might	O
be	O
due	O
to	O
that	O
the	O
correlation	O
of	O
weight	O
vectors	O
in	O
the	O
last	O
FC	Method
layer	O
is	O
determined	O
by	O
the	O
training	O
sample	O
distribution	O
,	O
as	O
explained	O
in	O
the	O
introduction	O
.	O

During	O
training	O
,	O
the	O
input	O
feature	O
from	O
a	O
previous	O
layer	O
is	O
passed	O
through	O
the	O
Eigenlayer	Method
.	O

Its	O
inner	O
products	O
with	O
the	O
weight	O
vectors	O
of	O
the	O
Eigenlayer	O
form	O
the	O
output	O
feature	O
,	O
which	O
is	O
fully	Method
connected	Method
to	O
the	O
last	O
layer	O
of	O
-	O
dim	O
,	O
where	O
denotes	O
the	O
number	O
of	O
training	O
classes	O
.	O

During	O
testing	O
,	O
we	O
extract	O
the	O
learned	O
embeddings	O
for	O
the	O
query	O
and	O
gallery	O
images	O
.	O

In	O
this	O
step	O
,	O
we	O
can	O
use	O
either	O
the	O
input	O
or	O
the	O
output	O
of	O
Eigenlayer	Method
for	O
feature	Task
representation	Task
,	O
as	O
shown	O
in	O
Fig	O
.	O

[	O
reference	O
]	O
.	O

Our	O
experiment	O
shows	O
that	O
using	O
the	O
two	O
features	O
can	O
achieve	O
similar	O
performance	O
,	O
indicating	O
that	O
the	O
orthogonality	O
of	O
Eigenlayer	O
improves	O
the	O
performance	O
of	O
not	O
only	O
output	O
but	O
also	O
input	O
.	O

The	O
reason	O
is	O
a	O
bit	O
implicit	O
,	O
and	O
we	O
believe	O
it	O
originates	O
from	O
the	O
back	O
-	O
propagation	O
training	O
of	O
CNN	Method
,	O
during	O
which	O
the	O
orthogonal	O
characteristic	O
of	O
weight	O
matrix	O
within	O
the	O
Eigenlayer	O
will	O
directly	O
impact	O
the	O
characteristic	O
of	O
its	O
input	O
feature	O
.	O

subsection	O
:	O
Training	O
SVDNet	Method
The	O
algorithm	O
of	O
training	O
SVDNet	Method
is	O
presented	O
in	O
Alg	O
.	O

[	O
reference	O
]	O
.	O

We	O
first	O
briefly	O
introduce	O
Step	O
0	O
and	O
then	O
describe	O
the	O
restraint	Method
and	Method
relaxation	Method
Iteration	Method
(	O
RRI	Method
)	O
(	O
Step	O
1	O
,	O
2	O
,	O
3	O
)	O
.	O

Step	O
0	O
.	O

We	O
first	O
add	O
a	O
linear	Method
layer	Method
to	O
the	O
network	O
.	O

Then	O
the	O
network	O
is	O
fine	O
-	O
tuned	O
till	O
convergence	O
.	O

Note	O
that	O
after	O
Step	O
0	O
,	O
the	O
weight	O
vectors	O
in	O
the	O
linear	Method
layer	Method
are	O
still	O
highly	O
correlated	O
.	O

In	O
the	O
experiment	O
,	O
we	O
will	O
present	O
the	O
re	Task
-	Task
ID	Task
performance	O
of	O
the	O
CNN	Method
model	O
after	O
Step	O
0	O
.	O

Various	O
output	O
dimensions	O
of	O
the	O
linear	Method
layer	Method
will	O
be	O
evaluated	O
.	O

Restraint	Method
and	Method
Relaxation	Method
Iteration	Method
(	O
RRI	Method
)	O
.	O

It	O
is	O
the	O
key	O
procedure	O
in	O
training	O
SVDNet	Method
.	O

Three	O
steps	O
are	O
involved	O
.	O

Decorrelation	Method
.	O

We	O
perform	O
SVD	Method
on	O
the	O
weight	O
matrix	O
as	O
follows	O
:	O
where	O
is	O
the	O
weight	O
matrix	O
of	O
the	O
linear	O
layer	O
,	O
is	O
the	O
left	O
-	O
unitary	O
matrix	O
,	O
is	O
the	O
singular	O
value	O
matrix	O
,	O
and	O
is	O
the	O
right	O
-	O
unitary	O
matrix	O
.	O

After	O
the	O
decomposition	O
,	O
we	O
replace	O
with	O
.	O

Then	O
the	O
linear	Method
layer	Method
uses	O
all	O
the	O
eigenvectors	O
of	O
as	O
weight	O
vectors	O
and	O
is	O
named	O
as	O
Eigenlayer	Method
.	O

Restraint	O
.	O

The	O
backbone	Method
model	Method
is	O
fine	O
-	O
tuned	O
till	O
convergence	O
,	O
but	O
the	O
Eigenlayer	Method
is	O
fixed	O
.	O

Relaxation	Task
.	O

The	O
fine	O
-	O
tuning	O
goes	O
on	O
for	O
some	O
more	O
epochs	O
with	O
Eigenlayer	O
unfixed	O
.	O

After	O
Step	O
1	O
and	O
Step	O
2	O
,	O
the	O
weight	O
vectors	O
are	O
orthogonal	O
,	O
,	O
in	O
an	O
eigen	O
state	O
.	O

But	O
after	O
Step	O
3	O
,	O
,	O
relaxation	Method
training	Method
,	O
shifts	O
away	O
from	O
the	O
eigen	O
state	O
.	O

So	O
the	O
training	O
procedure	O
enters	O
another	O
iteration	O
of	O
“	O
restraint	Task
and	Task
relaxation	Task
”	O
.	O

[	O
t	O
]	O
Training	O
SVDNet	Method
Input	O
:	O
a	O
pre	O
-	O
trained	O
CNN	Method
model	O
,	O
re	Task
-	Task
ID	Task
training	O
data	O
.	O

0	O
.	O

Add	O
the	O
Eigenlayer	Method
and	O
fine	O
-	O
tune	O
the	O
network	O
.	O

1	O
.	O

Decorrelation	Method
:	O
Decompose	O
with	O
SVD	Method
decomposition	O
,	O
and	O
then	O
update	O
it	O
:	O
2	O
.	O

Restraint	O
:	O
Fine	O
-	O
tune	O
the	O
network	O
with	O
the	O
Eigenlayer	O
fixed	O
3	O
.	O

Relaxation	Method
:	O
Fine	O
-	O
tune	O
the	O
network	O
with	O
the	O
Eigenlayer	O
unfixed	O
Output	O
:	O
a	O
fine	O
-	O
tuned	O
CNN	Method
model	O
,	O
,	O
SVDNet	Method
.	O

Albeit	O
simple	O
,	O
the	O
mechanism	O
behind	O
the	O
method	O
is	O
interesting	O
.	O

We	O
will	O
try	O
to	O
provide	O
insight	O
into	O
the	O
mechanism	O
in	O
Section	O
[	O
reference	O
]	O
.	O

During	O
all	O
the	O
analysis	O
involved	O
,	O
CaffeNet	Method
pre	Method
-	O
trained	O
on	O
ImageNet	O
is	O
chosen	O
as	O
the	O
backbone	O
.	O

subsection	O
:	O
Mechanism	O
Study	O
Why	O
is	O
SVD	Method
employed	O
?	O
Our	O
key	O
idea	O
is	O
to	O
find	O
a	O
set	O
of	O
orthogonal	O
projection	O
directions	O
based	O
on	O
what	O
CNN	Method
has	O
already	O
learned	O
from	O
training	O
set	O
.	O

Basically	O
,	O
for	O
a	O
linear	Method
layer	Method
,	O
a	O
set	O
of	O
basis	O
in	O
the	O
range	O
space	O
of	O
(	O
,	O
linear	O
subspace	O
spanned	O
by	O
column	O
vectors	O
of	O
)	O
is	O
a	O
potential	O
solution	O
.	O

In	O
fact	O
,	O
there	O
exists	O
numerous	O
sets	O
of	O
orthogonal	O
basis	O
.	O

So	O
we	O
decide	O
to	O
use	O
the	O
singular	O
vectors	O
of	O
as	O
new	O
projection	O
directions	O
and	O
to	O
weight	O
the	O
projection	O
results	O
with	O
the	O
corresponding	O
singular	O
values	O
.	O

That	O
is	O
,	O
we	O
replace	O
with	O
.	O

By	O
doing	O
this	O
,	O
the	O
discriminative	O
ability	O
of	O
feature	Method
representation	Method
over	O
the	O
whole	O
sample	O
space	O
will	O
be	O
maintained	O
.	O

We	O
make	O
a	O
mathematical	O
proof	O
as	O
follows	O
:	O
Given	O
two	O
images	O
and	O
,	O
we	O
denote	O
and	O
as	O
the	O
corresponding	O
features	O
before	O
the	O
Eigenlayer	Method
,	O
respectively	O
.	O

and	O
are	O
their	O
output	O
features	O
from	O
the	O
Eigenlayer	Method
.	O

The	O
Euclidean	O
distance	O
between	O
the	O
features	O
of	O
and	O
is	O
calculated	O
by	O
:	O
where	O
,	O
and	O
are	O
defined	O
in	O
Eq	O
.	O

[	O
reference	O
]	O
.	O

Since	O
is	O
a	O
unit	O
orthogonal	O
matrix	O
,	O
Eq	O
.	O

[	O
reference	O
]	O
is	O
equal	O
to	O
:	O
Eq	O
.	O

[	O
reference	O
]	O
suggests	O
that	O
when	O
changing	O
to	O
,	O
remains	O
unchanged	O
.	O

Therefore	O
,	O
in	O
Step	O
1	O
of	O
Alg	O
.	O

,	O
the	O
discriminative	Metric
ability	Metric
(	O
re	Task
-	Task
ID	Task
accuracy	O
)	O
of	O
the	O
fine	O
-	O
tuned	O
CNN	Method
model	O
is	O
100	O
%	O
preserved	O
.	O

There	O
are	O
some	O
other	O
decorrelation	Method
methods	Method
in	O
addition	O
to	O
SVD	Method
.	O

But	O
these	O
methods	O
do	O
not	O
preserve	O
the	O
discriminative	O
ability	O
of	O
the	O
CNN	Method
model	O
.	O

To	O
illustrate	O
this	O
point	O
,	O
we	O
compare	O
SVD	Method
with	O
several	O
competitors	O
below	O
.	O

Use	O
the	O
originally	O
learned	O
(	O
denoted	O
by	O
)	O
.	O

Replace	O
with	O
(	O
denoted	O
by	O
)	O
.	O

Replace	O
with	O
(	O
denoted	O
by	O
)	O
.	O

Replace	O
with	O
(	O
denoted	O
by	O
)	O
.	O

Replace	O
(	O
Q	Method
-	Method
R	Method
decomposition	Method
)	O
with	O
,	O
where	O
is	O
the	O
diagonal	O
matrix	O
extracted	O
from	O
the	O
upper	O
triangle	O
matrix	O
(	O
denoted	O
by	O
)	O
.	O

Comparisons	O
on	O
Market	Material
-	Material
1501	Material
are	O
provided	O
in	O
Table	O
[	O
reference	O
]	O
.	O

We	O
replace	O
the	O
FC	Method
layer	O
with	O
a	O
1	Method
,	Method
024	Method
-	Method
dim	Method
linear	Method
layer	Method
and	O
fine	O
-	O
tune	O
the	O
model	O
till	O
convergence	O
(	O
Step	O
0	O
in	O
Alg	O
.	O

[	O
reference	O
]	O
)	O
.	O

We	O
then	O
replace	O
the	O
fine	O
-	O
tuned	O
with	O
methods	O
2	O
-	O
5	O
.	O

All	O
the	O
four	O
decorrelation	Method
methods	Method
2	O
-	O
5	O
update	O
to	O
be	O
an	O
orthogonal	O
matrix	O
,	O
but	O
Table	O
[	O
reference	O
]	O
indicates	O
that	O
only	O
replacing	O
with	O
retains	O
the	O
re	Task
-	Task
ID	Task
accuracy	O
,	O
while	O
the	O
others	O
degrade	O
the	O
performance	O
.	O

When	O
does	O
performance	O
improvement	O
happen	O
?	O
As	O
proven	O
above	O
,	O
Step	O
1	O
in	O
Alg	O
.	O

[	O
reference	O
]	O
,	O
,	O
replacing	O
with	O
,	O
does	O
not	O
bring	O
an	O
immediate	O
accuracy	Metric
improvement	O
,	O
but	O
keeps	O
it	O
unchanged	O
.	O

Nevertheless	O
,	O
after	O
this	O
operation	O
,	O
the	O
model	O
has	O
been	O
pulled	O
away	O
from	O
the	O
original	O
fine	Method
-	Method
tuned	Method
solution	Method
,	O
and	O
the	O
classification	Metric
loss	Metric
on	O
the	O
training	O
set	O
will	O
increase	O
by	O
a	O
certain	O
extent	O
.	O

Therefore	O
,	O
Step	O
2	O
and	O
Step	O
3	O
in	O
Alg	O
.	O

[	O
reference	O
]	O
aim	O
to	O
fix	O
this	O
problem	O
.	O

The	O
major	O
effect	O
of	O
these	O
two	O
steps	O
is	O
to	O
improve	O
the	O
discriminative	Metric
ability	Metric
of	O
the	O
input	O
feature	O
as	O
well	O
as	O
the	O
output	O
feature	O
of	O
the	O
Eigenlayer	O
(	O
Fig	O
.	O

[	O
reference	O
]	O
)	O
.	O

On	O
the	O
one	O
hand	O
,	O
the	O
restraint	O
step	O
learns	O
the	O
upstream	O
and	O
downstream	O
layers	O
of	O
the	O
Eigenlayer	O
,	O
which	O
still	O
preserves	O
the	O
orthogonal	O
property	O
.	O

We	O
show	O
in	O
Fig	O
.	O

[	O
reference	O
]	O
that	O
this	O
step	O
improves	O
the	O
accuracy	Metric
.	O

On	O
the	O
other	O
hand	O
,	O
the	O
relaxation	O
step	O
will	O
make	O
the	O
model	O
deviate	O
from	O
orthogonality	O
again	O
,	O
but	O
it	O
reaches	O
closer	O
to	O
convergence	O
.	O

This	O
step	O
,	O
as	O
shown	O
in	O
Fig	O
.	O

[	O
reference	O
]	O
,	O
deteriorates	O
the	O
performance	O
.	O

But	O
within	O
an	O
RRI	Method
,	O
the	O
overall	O
performance	O
improves	O
.	O

Interestingly	O
,	O
when	O
educating	O
children	O
,	O
an	O
alternating	O
rhythm	O
of	O
relaxation	O
and	O
restraint	O
is	O
also	O
encouraged	O
.	O

Correlation	Method
diagnosing	Method
.	O

Till	O
now	O
,	O
we	O
have	O
not	O
provided	O
a	O
metric	O
how	O
to	O
evaluate	O
vector	O
correlations	O
.	O

In	O
fact	O
,	O
the	O
correlation	O
between	O
two	O
vectors	O
can	O
be	O
estimated	O
by	O
the	O
correlation	Metric
coefficient	Metric
.	O

However	O
,	O
to	O
the	O
best	O
of	O
our	O
knowledge	O
,	O
it	O
lacks	O
an	O
evaluation	O
protocol	O
for	O
diagnosing	O
the	O
overall	Metric
correlation	Metric
of	O
a	O
vector	O
set	O
.	O

In	O
this	O
paper	O
,	O
we	O
propose	O
to	O
evaluate	O
the	O
overall	Metric
correlation	Metric
as	O
below	O
.	O

Given	O
a	O
weight	O
matrix	O
,	O
we	O
define	O
the	O
gram	O
matrix	O
of	O
as	O
,	O
where	O
is	O
the	O
number	O
of	O
weight	O
vectors	O
in	O
(	O
=	O
4	O
,	O
096	O
in	O
FC7	O
of	O
CaffeNet	O
)	O
,	O
are	O
the	O
entries	O
in	O
,	O
and	O
are	O
the	O
weight	O
vectors	O
in	O
.	O

Given	O
,	O
we	O
define	O
as	O
a	O
metric	O
to	O
denote	O
the	O
extent	O
of	O
correlation	O
between	O
all	O
the	O
column	O
vectors	O
of	O
:	O
From	O
Eq	O
.	O

[	O
reference	O
]	O
,	O
we	O
can	O
see	O
that	O
the	O
value	O
of	O
falls	O
within	O
.	O

achieves	O
the	O
largest	O
value	O
only	O
when	O
is	O
an	O
orthogonal	O
matrix	O
,	O
,	O
.	O

has	O
the	O
smallest	O
value	O
when	O
all	O
the	O
weight	O
vectors	O
are	O
totally	O
the	O
same	O
,	O
,	O
.	O

So	O
when	O
is	O
close	O
to	O
or	O
is	O
very	O
small	O
,	O
the	O
weight	O
matrix	O
has	O
a	O
high	O
correlation	O
extent	O
.	O

For	O
example	O
,	O
in	O
our	O
baseline	O
,	O
when	O
directly	O
fine	Task
-	Task
tuning	Task
a	O
CNN	Method
model	O
(	O
without	O
SVDNet	Method
training	Method
)	O
using	O
CaffeNet	Method
,	O
,	O
indicating	O
that	O
the	O
weight	O
vectors	O
in	O
the	O
FC7	Method
layer	Method
are	O
highly	O
correlated	O
.	O

As	O
we	O
will	O
show	O
in	O
Section	O
[	O
reference	O
]	O
,	O
is	O
an	O
effective	O
indicator	O
to	O
the	O
convergence	O
of	O
SVDNet	Method
training	Method
.	O

Convergence	Metric
Criteria	Metric
for	O
RRI	Method
.	O

When	O
to	O
stop	O
RRI	Method
is	O
a	O
non	O
-	O
trivial	O
problem	O
,	O
especially	O
in	O
application	O
.	O

We	O
employ	O
Eq	O
.	O

[	O
reference	O
]	O
to	O
evaluate	O
the	O
orthogonality	O
of	O
after	O
the	O
relaxation	O
step	O
and	O
find	O
that	O
increases	O
as	O
the	O
iteration	O
goes	O
on	O
.	O

It	O
indicates	O
that	O
the	O
correlation	O
among	O
the	O
weight	O
vectors	O
in	O
is	O
reduced	O
step	O
-	O
by	O
-	O
step	O
with	O
RRI	Method
.	O

So	O
when	O
becomes	O
stable	O
,	O
the	O
model	O
converges	O
,	O
and	O
RRI	Method
stops	O
.	O

Detailed	O
observations	O
can	O
be	O
accessed	O
in	O
Fig	O
.	O

[	O
reference	O
]	O
.	O

section	O
:	O
Experiment	O
subsection	O
:	O
Datasets	O
and	O
Settings	O
Datasets	O
.	O

This	O
paper	O
uses	O
three	O
datasets	O
for	O
evaluation	Task
,	O
,	O
Market	Material
-	Material
1501	Material
,	O
CUHK03	O
and	O
DukeMTMC	Material
-	Material
reID	Material
.	O

The	O
Market	Material
-	Material
1501	Material
dataset	Material
contains	O
1	O
,	O
501	O
identities	O
,	O
19	O
,	O
732	O
gallery	O
images	O
and	O
12	O
,	O
936	O
training	O
images	O
captured	O
by	O
6	O
cameras	O
.	O

All	O
the	O
bounding	O
boxes	O
are	O
generated	O
by	O
the	O
DPM	Method
detector	Method
.	O

Most	O
experiments	O
relevant	O
to	O
mechanism	O
study	O
are	O
carried	O
out	O
on	O
Market	Material
-	Material
1501	Material
.	O

The	O
CUHK03	O
dataset	O
contains	O
13	O
,	O
164	O
images	O
of	O
1	O
,	O
467	O
identities	O
.	O

Each	O
identity	O
is	O
observed	O
by	O
2	O
cameras	O
.	O

CUHK03	O
offers	O
both	O
hand	O
-	O
labeled	O
and	O
DPM	O
-	O
detected	O
bounding	O
boxes	O
,	O
and	O
we	O
use	O
the	O
latter	O
in	O
this	O
paper	O
.	O

For	O
CUHK03	O
,	O
20	O
random	O
train	O
/	O
test	O
splits	O
are	O
performed	O
,	O
and	O
the	O
averaged	O
results	O
are	O
reported	O
.	O

The	O
DukeMTMC	Material
-	Material
reID	Material
dataset	Material
is	O
collected	O
with	O
8	O
cameras	O
and	O
used	O
for	O
cross	Task
-	Task
camera	Task
tracking	Task
.	O

We	O
adopt	O
its	O
re	Task
-	Task
ID	Task
version	O
benchmarked	O
in	O
.	O

It	O
contains	O
1	O
,	O
404	O
identities	O
(	O
one	O
half	O
for	O
training	O
,	O
and	O
the	O
other	O
for	O
testing	O
)	O
,	O
16	O
,	O
522	O
training	O
images	O
,	O
2	O
,	O
228	O
queries	O
,	O
and	O
17	O
,	O
661	O
gallery	O
images	O
.	O

For	O
Market	Material
-	Material
1501	Material
and	O
DukeMTMC	Material
-	Material
reID	Material
,	O
we	O
use	O
the	O
evaluation	O
packages	O
provided	O
by	O
and	O
,	O
respectively	O
.	O

For	O
performance	O
evaluation	O
on	O
all	O
the	O
3	O
datasets	O
,	O
we	O
use	O
both	O
the	O
Cumulative	Metric
Matching	Metric
Characteristics	Metric
(	O
CMC	Metric
)	O
curve	O
and	O
the	O
mean	Metric
Average	Metric
Precision	Metric
(	O
mAP	Metric
)	O
.	O

Backbones	O
.	O

We	O
mainly	O
use	O
two	O
networks	O
pre	O
-	O
trained	O
on	O
ImageNet	O
as	O
backbones	O
,	O
,	O
CaffeNet	Method
and	O
ResNet	Method
-	Method
50	Method
.	O

When	O
using	O
CaffeNet	Method
as	O
the	O
backbone	O
,	O
we	O
directly	O
replace	O
the	O
original	O
FC7	Method
layer	Method
with	O
the	O
Eigenlayer	Method
,	O
in	O
case	O
that	O
one	O
might	O
argue	O
that	O
the	O
performance	O
gain	O
is	O
brought	O
by	O
deeper	Method
architecture	Method
.	O

When	O
using	O
ResNet	Method
-	Method
50	Method
as	O
the	O
backbone	O
,	O
we	O
have	O
to	O
insert	O
the	O
Eigenlayer	O
before	O
the	O
last	O
FC	Method
layer	O
because	O
ResNet	Method
has	O
no	O
hidden	O
FC	Method
layer	O
and	O
the	O
influence	O
of	O
adding	O
a	O
layer	O
into	O
a	O
50	Method
-	Method
layer	Method
architecture	Method
can	O
be	O
neglected	O
.	O

In	O
several	O
experiments	O
on	O
Market	Material
-	Material
1501	Material
,	O
we	O
additionally	O
use	O
VGGNet	Method
and	O
a	O
Tiny	O
CaffeNet	Method
as	O
backbones	O
to	O
demonstrate	O
the	O
effectiveness	O
of	O
SVDNet	Method
on	O
different	O
architectures	O
.	O

The	O
Tiny	O
CaffeNet	O
is	O
generated	O
by	O
reducing	O
the	O
FC6	Method
and	Method
FC7	Method
layers	Method
of	O
CaffeNet	Method
to	O
containing	O
1024	O
and	O
512	O
dimensions	O
,	O
respectively	O
.	O

subsection	O
:	O
Implementation	O
Details	O
Baseline	O
.	O

Following	O
the	O
practice	O
in	O
,	O
baselines	O
using	O
CaffeNet	Method
and	O
ResNet	Method
-	Method
50	Method
are	O
fine	O
-	O
tuned	O
with	O
the	O
default	O
parameter	O
settings	O
except	O
that	O
the	O
output	O
dimension	O
of	O
the	O
last	O
FC	Method
layer	O
is	O
set	O
to	O
the	O
number	O
of	O
training	O
identities	O
.	O

The	O
CaffeNet	Method
Baseline	Method
is	O
trained	O
for	O
60	O
epochs	O
with	O
a	O
learning	Metric
rate	Metric
of	O
0.001	O
and	O
then	O
for	O
another	O
20	O
epochs	O
with	O
a	O
learning	Metric
rate	Metric
of	O
0.0001	O
.	O

The	O
ResNet	Method
Baseline	Method
is	O
trained	O
for	O
60	O
epochs	O
with	O
learning	Metric
rate	Metric
initialized	O
at	O
0.001	O
and	O
reduced	O
by	O
10	O
on	O
25	O
and	O
50	O
epochs	O
.	O

During	O
testing	O
,	O
the	O
FC6	Method
or	Method
FC7	Method
descriptor	Method
of	O
CaffeNet	Method
and	O
the	O
Pool5	O
or	O
FC	Method
descriptor	O
of	O
ResNet	Method
-	Method
50	Method
are	O
used	O
for	O
feature	Method
representation	Method
.	O

On	O
Market	Material
-	Material
1501	Material
,	O
CaffeNet	O
and	O
Resnet	Method
-	Method
50	Method
achieves	O
rank	Metric
-	Metric
1	Metric
accuracy	Metric
of	O
55.3	O
%	O
(	O
73.8	O
%	O
)	O
with	O
the	O
FC6	Method
(	O
Pool5	O
)	O
descriptor	O
,	O
which	O
is	O
consistent	O
with	O
the	O
results	O
in	O
.	O

Detailed	O
settings	O
.	O

CaffeNet	O
-	O
backboned	O
SVDNet	Method
takes	O
25	O
RRIs	O
to	O
reach	O
final	O
convergence	O
.	O

For	O
both	O
the	O
restraint	Task
stage	Task
and	O
the	O
relaxation	Method
stage	Method
within	O
each	O
RRI	Method
except	O
the	O
last	O
one	O
,	O
we	O
use	O
2000	O
iterations	O
and	O
fix	O
the	O
learning	Metric
rate	Metric
at	O
0.001	O
.	O

For	O
the	O
last	O
restraint	Task
training	Task
,	O
we	O
use	O
5000	O
iterations	O
(	O
learning	Metric
rate	Metric
0.001	O
)	O
+	O
3000	O
iterations	O
(	O
learning	Metric
rate	Metric
0.0001	Metric
)	O
.	O

The	O
batch	O
size	O
is	O
set	O
to	O
64	O
.	O

ResNet	O
-	O
backboned	O
SVDNet	Method
takes	O
7	O
RRIs	Method
to	O
reach	O
final	O
convergence	O
.	O

For	O
both	O
the	O
restraint	Task
stage	Task
and	O
the	O
relaxation	Method
stage	Method
within	O
each	O
RRI	Method
,	O
we	O
use	O
8000	O
iterations	O
and	O
divide	O
the	O
learning	Metric
rate	Metric
by	O
10	O
after	O
5000	O
iterations	O
.	O

The	O
initial	O
learning	Metric
rate	Metric
for	O
the	O
1st	O
to	O
the	O
3rd	O
RRI	Method
is	O
set	O
to	O
0.001	O
,	O
and	O
the	O
initial	O
learning	Metric
rate	Metric
for	O
the	O
rest	O
RRIs	O
is	O
set	O
to	O
0.0001	O
.	O

The	O
batch	O
size	O
is	O
set	O
to	O
32	O
.	O

The	O
output	O
dimension	O
of	O
Eigenlayer	O
is	O
set	O
to	O
be	O
1024	O
in	O
all	O
models	O
,	O
yet	O
the	O
influence	O
of	O
this	O
hyper	O
-	O
parameter	O
is	O
to	O
be	O
analyzed	O
in	O
Section	O
[	O
reference	O
]	O
.	O

The	O
reason	O
of	O
using	O
different	O
times	O
of	O
RRIs	O
for	O
different	O
backbones	O
is	O
to	O
be	O
illustrated	O
in	O
Section	O
[	O
reference	O
]	O
.	O

subsection	O
:	O
Performance	O
Evaluation	O
The	O
effectiveness	O
of	O
SVDNet	Method
.	O

We	O
comprehensively	O
evaluate	O
the	O
proposed	O
SVDNet	Method
on	O
all	O
the	O
three	O
re	Task
-	Task
ID	Task
benchmarks	O
.	O

The	O
overall	O
results	O
are	O
shown	O
in	O
Table	O
[	O
reference	O
]	O
.	O

(	O
a	O
)	O
CaffeNet	O
-	O
backboned	O
SVDNet	Method
(	O
b	O
)	O
ResNet	O
-	O
backboned	O
SVDNet	Method
The	O
improvements	O
achieved	O
on	O
both	O
backbones	O
are	O
significant	O
:	O
When	O
using	O
CaffeNet	Method
as	O
the	O
backbone	O
,	O
the	O
Rank	Metric
-	Metric
1	Metric
accuracy	Metric
on	O
Market	Material
-	Material
1501	Material
rises	O
from	O
55.3	O
%	O
to	O
80.5	O
%	O
,	O
and	O
the	O
mAP	Metric
rises	O
from	O
30.4	O
%	O
to	O
55.9	O
%	O
.	O

On	O
CUHK03	O
(	O
DukeMTMC	Material
-	Material
reID	Material
)	O
dataset	O
,	O
the	O
Rank	Metric
-	Metric
1	Metric
accuracy	Metric
rises	O
by	O
+	O
26.3	O
%	O
(	O
+	O
20.7	O
%	O
)	O
,	O
and	O
the	O
mAP	Metric
rises	O
by	O
+	O
24.7	O
%	O
(	O
+	O
17.5	O
%	O
)	O
.	O

When	O
using	O
ResNet	Method
as	O
the	O
backbone	O
,	O
the	O
Rank	Metric
-	Metric
1	Metric
accuracy	Metric
rises	O
by	O
+	O
8.4	O
%	O
,	O
+	O
15.6	O
%	O
and	O
+	O
11.2	O
%	O
respectively	O
on	O
Market	Material
-	Material
1501	Material
,	O
CUHK03	O
and	O
DukeMTMC	Material
-	Material
reID	Material
dataset	Material
.	O

The	O
mAP	Metric
rises	O
by	O
+	O
14.2	O
%	O
,	O
+	O
13.7	O
%	O
and	O
+	O
12.7	O
%	O
correspondingly	O
.	O

Some	O
retrieval	O
examples	O
on	O
Market	Material
-	Material
1501	Material
are	O
shown	O
in	O
Fig	O
.	O

[	O
reference	O
]	O
.	O

Comparison	O
with	O
state	O
of	O
the	O
art	O
.	O

We	O
compare	O
SVDNet	Method
with	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
methods	O
.	O

Comparisons	O
on	O
Market	Material
-	Material
1501	Material
and	O
CUHK03	O
are	O
shown	O
in	O
Table	O
[	O
reference	O
]	O
.	O

Comparing	O
with	O
already	O
published	O
papers	O
,	O
SVDNet	Method
achieves	O
competitive	O
performance	O
.	O

We	O
report	O
rank	Metric
-	Metric
1	Metric
=	O
82.3	O
%	O
,	O
mAP	Metric
=	O
62.1	O
%	O
on	O
Market	Material
-	Material
1501	Material
,	O
and	O
rank	Metric
-	Metric
1	Metric
=	O
81.8	O
%	O
,	O
mAP	Metric
=	O
84.8	O
%	O
on	O
CUHK03	O
.	O

The	O
re	Method
-	Method
ranking	Method
method	Method
is	O
higher	O
than	O
ours	O
in	O
mAP	Metric
on	O
Market	Material
-	Material
1501	Material
,	O
because	O
re	Task
-	Task
ranking	Task
exploits	O
the	O
relationship	O
among	O
the	O
gallery	O
images	O
and	O
results	O
in	O
a	O
high	O
recall	Metric
.	O

We	O
speculate	O
that	O
this	O
re	Method
-	Method
ranking	Method
method	Method
will	O
also	O
bring	O
improvement	O
for	O
SVDNet	Method
.	O

Comparing	O
with	O
the	O
unpublished	O
Arxiv	O
papers	O
,	O
(	O
some	O
of	O
)	O
our	O
numbers	O
are	O
slightly	O
lower	O
than	O
and	O
.	O

Both	O
works	O
and	O
combine	O
the	O
verification	Metric
and	Metric
classification	Metric
losses	Metric
,	O
and	O
we	O
will	O
investigate	O
into	O
integrating	O
this	O
strategy	O
into	O
SVDNet	Method
.	O

Moreover	O
,	O
the	O
performance	O
of	O
SVDNet	Method
based	O
on	O
relatively	O
simple	O
CNN	Method
architecture	O
is	O
impressive	O
.	O

On	O
Market	Material
-	Material
1501	Material
,	O
CaffeNet	O
-	O
backboned	O
SVDNet	Method
achieves	O
80.5	O
%	O
rank	Metric
-	Metric
1	Metric
accuracy	Metric
and	O
55.9	O
%	O
mAP	Metric
,	O
exceeding	O
other	O
CaffeNet	Method
-	Method
based	Method
methods	Method
by	O
a	O
large	O
margin	O
.	O

Additionally	O
,	O
using	O
VGGNet	Method
and	Method
Tiny	Method
CaffeNet	Method
as	O
backbone	Method
achieves	O
79.7	O
%	O
and	O
77.4	O
%	O
rank	Metric
-	Metric
1	Metric
accuracy	Metric
respectively	O
.	O

On	O
CUHK03	O
,	O
CaffeNet	O
-	O
backboned	O
SVDNet	Method
even	O
exceeds	O
some	O
ResNet	Method
-	Method
based	Method
competing	Method
methods	Method
except	O
DLCE	Method
(	Method
R	Method
)	O
.	O

This	O
observation	O
suggests	O
that	O
our	O
method	O
can	O
achieve	O
acceptable	O
performance	O
with	O
high	O
computing	Metric
effectiveness	Metric
.	O

In	O
Table	O
[	O
reference	O
]	O
,	O
comparisons	O
on	O
DukeMTMC	Material
-	Material
reID	Material
and	O
CUHK03	O
under	O
a	O
new	O
training	O
/	O
testing	O
protocol	O
(	O
denoted	O
as	O
CUHK03	O
-	O
NP	O
)	O
raised	O
by	O
are	O
summarized	O
.	O

Relatively	O
fewer	O
results	O
are	O
reported	O
because	O
both	O
DukeMTMC	Material
-	Material
reID	Material
and	O
CUHK03	O
-	O
NP	O
have	O
only	O
been	O
recently	O
benchmarked	O
.	O

On	O
DukeMTMC	Material
-	Material
reID	Material
,	O
this	O
paper	O
reports	O
rank	Metric
-	Metric
1	Metric
=	O
76.7	O
%	O
,	O
mAP	Metric
=	O
56.8	O
%	O
,	O
which	O
is	O
higher	O
than	O
the	O
several	O
competing	O
methods	O
including	O
a	O
recent	O
GAN	Method
approach	Method
.	O

On	O
CUHK03	O
-	O
NP	O
,	O
this	O
paper	O
reports	O
rank	Metric
-	Metric
1	Metric
=	O
41.5	O
%	O
,	O
mAP	Metric
=	O
37.3	O
%	O
,	O
which	O
is	O
also	O
the	O
highest	O
among	O
all	O
the	O
methods	O
.	O

subsection	O
:	O
Impact	O
of	O
Output	Metric
Dimension	Metric
We	O
vary	O
the	O
dimension	O
of	O
the	O
output	O
of	O
Eigenlayer	Method
.	O

Results	O
of	O
CaffeNet	O
and	O
ResNet	O
-	O
50	O
are	O
drawn	O
in	O
Fig	O
.	O

[	O
reference	O
]	O
.	O

When	O
trained	O
without	O
RRI	Method
,	O
the	O
model	O
has	O
no	O
intrinsic	O
difference	O
with	O
a	O
baseline	O
model	O
.	O

It	O
can	O
be	O
observed	O
that	O
the	O
output	O
dimension	O
of	O
the	O
penultimate	Method
layer	Method
significantly	O
influences	O
the	O
performance	O
.	O

As	O
the	O
output	O
dimension	O
increases	O
,	O
the	O
re	Task
-	Task
ID	Task
performance	O
first	O
increases	O
,	O
reaches	O
a	O
peak	O
and	O
then	O
drops	O
quickly	O
.	O

In	O
this	O
scenario	O
,	O
we	O
find	O
that	O
lowering	O
the	O
dimension	O
is	O
usually	O
beneficial	O
,	O
probably	O
due	O
to	O
the	O
reduced	O
redundancy	O
in	O
filters	O
of	O
FC	Method
layer	O
.	O

The	O
influence	O
of	O
the	O
output	O
dimension	O
on	O
the	O
final	O
performance	O
of	O
SVDNet	Method
presents	O
another	O
trend	O
.	O

As	O
the	O
output	O
dimension	O
increases	O
,	O
the	O
performance	O
gradually	O
increases	O
until	O
reaching	O
a	O
stable	O
level	O
,	O
which	O
suggests	O
that	O
our	O
method	O
is	O
immune	O
to	O
harmful	O
redundancy	O
.	O

subsection	O
:	O
RRI	Method
Boosting	O
Procedure	O
This	O
experiment	O
reveals	O
how	O
the	O
re	Task
-	Task
ID	Task
performance	O
changes	O
after	O
each	O
restraint	O
step	O
and	O
each	O
relaxation	O
step	O
,	O
and	O
how	O
SVDNet	Method
reaches	O
the	O
stable	O
performance	O
step	O
by	O
step	O
.	O

In	O
our	O
experiment	O
,	O
we	O
use	O
25	O
epochs	O
for	O
both	O
the	O
restraint	O
phase	O
and	O
the	O
relaxation	O
phase	O
in	O
one	O
RRI	Method
.	O

The	O
output	O
dimension	O
of	O
Eigenlayer	Method
is	O
set	O
to	O
2	O
,	O
048	O
.	O

Exhaustively	O
,	O
we	O
test	O
re	Task
-	Task
ID	Task
performance	O
and	O
values	O
of	O
all	O
the	O
intermediate	O
CNN	Method
models	O
.	O

We	O
also	O
increase	O
the	O
training	O
epochs	O
of	O
baseline	O
models	O
to	O
be	O
equivalent	O
of	O
training	O
SVDNet	Method
,	O
to	O
compare	O
of	O
models	O
trained	O
with	O
and	O
without	O
RRI	Method
.	O

Results	O
are	O
shown	O
in	O
Fig	O
.	O

[	O
reference	O
]	O
,	O
from	O
which	O
four	O
conclusions	O
can	O
be	O
drawn	O
.	O

First	O
,	O
within	O
each	O
RRI	Method
,	O
rank	Metric
-	Metric
1	Metric
accuracy	Metric
takes	O
on	O
a	O
pattern	O
of	O
“	O
increase	O
and	O
decrease	O
”	O
echoing	O
the	O
restraint	O
and	O
relaxation	O
steps	O
:	O
When	O
is	O
fixed	O
to	O
maintain	O
orthogonality	O
during	O
restraint	O
training	O
,	O
the	O
performance	O
increases	O
,	O
implying	O
a	O
boosting	O
in	O
the	O
discriminative	Metric
ability	Metric
of	O
the	O
learned	O
feature	O
.	O

Then	O
during	O
relaxation	Task
training	Task
,	O
is	O
unfixed	O
,	O
and	O
the	O
performance	O
stagnates	O
or	O
even	O
decreases	O
slightly	O
.	O

Second	O
,	O
as	O
the	O
RRI	Method
goes	O
,	O
the	O
overall	O
accuracy	Metric
increases	O
,	O
and	O
reaches	O
a	O
stable	O
level	O
when	O
the	O
model	O
converges	O
.	O

Third	O
,	O
it	O
is	O
reliable	O
to	O
use	O
–	O
the	O
degree	O
of	O
orthogonality	O
–	O
as	O
the	O
convergence	Metric
criteria	Metric
for	O
RRI	Method
.	O

During	O
RRI	Method
training	O
,	O
gradually	O
increases	O
until	O
reaching	O
stability	O
,	O
while	O
without	O
RRI	Method
training	O
,	O
fluctuates	O
slightly	O
around	O
a	O
relatively	O
low	O
value	O
,	O
indicating	O
high	O
correlation	O
among	O
weight	O
vectors	O
.	O

Fourth	O
,	O
ResNet	O
-	O
backboned	O
SVDNet	Method
needs	O
much	O
fewer	O
RRIs	O
to	O
converge	O
than	O
CaffeNet	O
-	O
backboned	O
SVDNet	Method
.	O

subsection	O
:	O
Comparison	O
of	O
Decorrelation	Method
Methods	Method
In	O
Section	O
[	O
reference	O
]	O
,	O
several	O
decorrelation	Method
methods	Method
are	O
introduced	O
.	O

We	O
show	O
that	O
only	O
the	O
proposed	O
method	O
of	O
replacing	O
with	O
maintains	O
the	O
discriminative	O
ability	O
of	O
the	O
output	O
feature	O
of	O
Eigenlayer	O
,	O
while	O
all	O
the	O
other	O
three	O
methods	O
lead	O
to	O
performance	O
degradation	O
to	O
some	O
extent	O
.	O

Here	O
,	O
we	O
report	O
their	O
final	O
performance	O
when	O
RRI	Method
training	O
is	O
used	O
.	O

Results	O
on	O
Market	Material
-	Material
1501	Material
are	O
shown	O
in	O
Table	O
[	O
reference	O
]	O
.	O

It	O
can	O
be	O
observed	O
that	O
the	O
proposed	O
decorrelating	Method
method	Method
,	O
,	O
replacing	O
with	O
,	O
achieves	O
the	O
highest	O
performance	O
,	O
followed	O
by	O
the	O
“	O
”	O
,	O
“	O
”	O
and	O
“	O
”	O
methods	O
.	O

In	O
fact	O
,	O
the	O
“	O
”	O
method	O
does	O
not	O
bring	O
about	O
observable	O
improvement	O
compared	O
with	O
“	O
”	O
.	O

This	O
experiment	O
demonstrates	O
that	O
not	O
only	O
the	O
orthogonality	O
itself	O
,	O
but	O
also	O
the	O
decorrelation	Method
approach	Method
,	O
are	O
vital	O
for	O
SVDNet	Method
.	O

section	O
:	O
Conclusions	O
In	O
this	O
paper	O
,	O
SVDNet	Method
is	O
proposed	O
for	O
representation	Task
learning	Task
in	O
pedestrian	Task
retrieval	Task
,	O
or	O
re	Task
-	Task
identification	Task
.	O

Decorrelation	Method
is	O
enforced	O
among	O
the	O
projection	O
vectors	O
in	O
the	O
weight	O
matrix	O
of	O
the	O
FC	Method
layer	O
.	O

Through	O
iterations	O
of	O
“	O
restraint	Method
and	Method
relaxation	Method
”	O
,	O
the	O
extent	O
of	O
vector	O
correlation	O
is	O
gradually	O
reduced	O
.	O

In	O
this	O
process	O
,	O
the	O
re	Task
-	Task
ID	Task
performance	O
undergoes	O
iterative	O
“	O
increase	O
and	O
decrease	O
”	O
,	O
and	O
finally	O
reaches	O
a	O
stable	O
accuracy	Metric
.	O

Due	O
to	O
elimination	O
of	O
correlation	O
of	O
the	O
weight	O
vectors	O
,	O
the	O
learned	O
embedding	Method
better	O
suits	O
the	O
retrieval	Task
task	Task
under	O
the	O
Euclidean	O
distance	O
.	O

Significant	O
performance	O
improvement	O
is	O
achieved	O
on	O
the	O
Market	Material
-	Material
1501	Material
,	O
CUHK03	O
,	O
and	O
DukeMTMC	Material
-	Material
reID	Material
datasets	O
,	O
and	O
the	O
re	Task
-	Task
ID	Task
accuracy	O
is	O
competitive	O
with	O
the	O
state	O
of	O
the	O
art	O
.	O

In	O
the	O
future	O
study	O
,	O
we	O
will	O
investigate	O
more	O
extensions	O
of	O
SVDNet	Method
to	O
find	O
out	O
more	O
about	O
its	O
working	O
mechanism	O
.	O

We	O
will	O
also	O
apply	O
SVDNet	Method
on	O
the	O
generic	Task
instance	Task
retrieval	Task
problem	Task
.	O

bibliography	O
:	O
References	O
