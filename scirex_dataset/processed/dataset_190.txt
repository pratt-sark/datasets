Neural	Method
Aggregation	Method
Network	Method
for	O
Video	Task
Face	Task
Recognition	Task
section	O
:	O
Abstract	O
This	O
paper	O
presents	O
a	O
Neural	Method
Aggregation	Method
Network	Method
(	O
NAN	Method
)	O
for	O
video	Task
face	Task
recognition	Task
.	O

The	O
network	O
takes	O
a	O
face	O
video	O
or	O
face	O
image	O
set	O
of	O
a	O
person	O
with	O
a	O
variable	O
number	O
of	O
face	O
images	O
as	O
its	O
input	O
,	O
and	O
produces	O
a	O
compact	Method
,	O
fixed	Method
-	Method
dimension	Method
feature	Method
representation	Method
for	O
recognition	Task
.	O

The	O
whole	O
network	O
is	O
composed	O
of	O
two	O
modules	O
.	O

The	O
feature	Method
embedding	Method
module	Method
is	O
a	O
deep	O
Convolutional	Method
Neural	Method
Network	Method
(	O
CNN	Method
)	O
which	O
maps	O
each	O
face	O
image	O
to	O
a	O
feature	O
vector	O
.	O

The	O
aggregation	Method
module	Method
consists	O
of	O
two	O
attention	Method
blocks	Method
which	O
adaptively	O
aggregate	O
the	O
feature	O
vectors	O
to	O
form	O
a	O
single	O
feature	O
inside	O
the	O
convex	O
hull	O
spanned	O
by	O
them	O
.	O

Due	O
to	O
the	O
attention	Method
mechanism	Method
,	O
the	O
aggregation	Method
is	O
invariant	O
to	O
the	O
image	O
order	O
.	O

Our	O
NAN	Method
is	O
trained	O
with	O
a	O
standard	O
classification	Metric
or	Metric
verification	Metric
loss	Metric
without	O
any	O
extra	O
supervision	O
signal	O
,	O
and	O
we	O
found	O
that	O
it	O
automatically	O
learns	O
to	O
advocate	O
high	O
-	O
quality	O
face	O
images	O
while	O
repelling	O
low	O
-	O
quality	O
ones	O
such	O
as	O
blurred	O
,	O
occluded	O
and	O
improperly	O
exposed	O
faces	O
.	O

The	O
experiments	O
on	O
IJB	Material
-	Material
A	Material
,	O
YouTube	Material
Face	Material
,	O
Celebrity	Task
-	Task
1000	Task
video	Task
face	Task
recognition	Task
benchmarks	Task
show	O
that	O
it	O
consistently	O
outperforms	O
naive	Method
aggregation	Method
methods	Method
and	O
achieves	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
accuracy	Metric
.	O

section	O
:	O
Introduction	O
Video	Task
face	Task
recognition	Task
has	O
caught	O
more	O
and	O
more	O
attention	O
from	O
the	O
community	O
in	O
recent	O
years	O
[	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
.	O

Compared	O
to	O
image	Task
-	Task
based	Task
face	Task
recognition	Task
,	O
more	O
information	O
of	O
the	O
subjects	O
can	O
be	O
exploited	O
from	O
the	O
input	O
videos	O
,	O
which	O
naturally	O
incorporate	O
faces	O
of	O
the	O
same	O
subject	O
in	O
varying	O
poses	O
and	O
illumination	O
conditions	O
.	O

The	O
key	O
issue	O
in	O
video	Task
face	Task
recognition	Task
is	O
to	O
build	O
an	O
appropriate	O
representation	O
of	O
the	O
video	O
face	O
,	O
such	O
that	O
it	O
can	O
effectively	O
integrate	O
the	O
information	O
across	O
different	O
frames	O
together	O
,	O
maintaining	O
beneficial	O
while	O
discarding	O
noisy	O
information	O
.	O

*	O
Part	O
of	O
this	O
work	O
was	O
done	O
when	O
J.	O
Yang	O
was	O
an	O
intern	O
at	O
MSR	O
supervised	O
by	O
G.	O
Hua	O
.	O

Figure	O
1	O
.	O

Our	O
network	Method
architecture	Method
for	O
video	Task
face	Task
recognition	Task
.	O

All	O
input	O
face	O
images	O
{	O
x	O
k	O
}	O
are	O
processed	O
by	O
a	O
feature	Method
embedding	Method
module	Method
with	O
a	O
deep	O
CNN	Method
,	O
yielding	O
a	O
set	O
of	O
feature	O
vectors	O
{	O
f	O
k	O
}	O
.	O

These	O
features	O
are	O
passed	O
to	O
the	O
aggregation	Method
module	Method
,	O
producing	O
a	O
single	O
128	O
-	O
dimensional	O
vector	O
r	O
1	O
to	O
represent	O
the	O
input	O
faces	O
images	O
.	O

This	O
compact	Method
representation	Method
is	O
used	O
for	O
recognition	Task
.	O

One	O
naive	O
approach	O
would	O
be	O
representing	O
a	O
video	O
face	O
as	O
a	O
set	O
of	O
frame	O
-	O
level	O
face	O
features	O
such	O
as	O
those	O
extracted	O
from	O
deep	Method
neural	Method
networks	Method
[	O
reference	O
][	O
reference	O
]	O
,	O
which	O
have	O
dominated	O
face	Task
recognition	Task
recently	O
[	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
.	O

Such	O
a	O
representation	O
comprehensively	O
maintains	O
the	O
information	O
across	O
all	O
frames	O
.	O

However	O
,	O
to	O
compare	O
two	O
video	O
faces	O
,	O
one	O
needs	O
to	O
fuse	O
the	O
matching	O
results	O
across	O
all	O
pairs	O
of	O
frames	O
between	O
the	O
two	O
face	O
videos	O
.	O

Let	O
n	O
be	O
the	O
average	Method
number	O
of	O
video	O
frames	O
,	O
then	O
the	O
computational	Metric
complexity	Metric
is	O
O	O
(	O
n	O
2	O
)	O
per	O
match	Task
operation	Task
,	O
which	O
is	O
not	O
desirable	O
especially	O
for	O
large	Task
-	Task
scale	Task
recognition	Task
.	O

Besides	O
,	O
such	O
a	O
setbased	Method
representation	Method
would	O
incur	O
O	O
(	O
n	O
)	O
space	Metric
complexity	Metric
per	O
video	O
face	O
example	O
,	O
which	O
demands	O
a	O
lot	O
of	O
memory	O
storage	O
and	O
confronts	O
efficient	O
indexing	Task
.	O

We	O
argue	O
that	O
it	O
is	O
more	O
desirable	O
to	O
come	O
with	O
a	O
compact	Method
,	O
fixed	Method
-	Method
size	Method
feature	Method
representation	Method
at	O
the	O
video	O
level	O
,	O
irrespective	O
of	O
the	O
varied	O
length	O
of	O
the	O
videos	O
.	O

Such	O
a	O
representation	O
would	O
allow	O
direct	O
,	O
constant	Task
-	Task
time	Task
computation	Task
of	O
the	O
similarity	Metric
or	Metric
distance	Metric
without	O
the	O
need	O
for	O
frame	Method
-	Method
to	Method
-	Method
frame	Method
matching	Method
.	O

A	O
straightforward	O
solution	O
might	O
be	O
extracting	O
a	O
feature	O
at	O
each	O
frame	O
and	O
then	O
conducting	O
a	O
certain	O
type	O
of	O
pooling	Method
to	O
aggregate	O
the	O
frame	O
-	O
level	O
features	O
together	O
to	O
form	O
a	O
video	Method
-	Method
level	Method
representation	Method
.	O

The	O
most	O
commonly	O
adopted	O
pooling	Method
strategies	O
may	O
be	O
average	Method
and	O
max	Method
pooling	Method
[	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
.	O

While	O
these	O
naive	Method
pooling	Method
strategies	Method
were	O
shown	O
to	O
be	O
effective	O
in	O
the	O
previous	O
works	O
,	O
we	O
believe	O
that	O
a	O
good	O
pooling	Method
or	O
aggregation	Method
strategy	Method
should	O
adaptively	O
weigh	O
and	O
combine	O
the	O
framelevel	O
features	O
across	O
all	O
frames	O
.	O

The	O
intuition	O
is	O
simple	O
:	O
a	O
video	O
(	O
especially	O
a	O
long	O
video	O
sequence	O
)	O
or	O
an	O
image	O
set	O
may	O
contain	O
face	O
images	O
captured	O
at	O
various	O
conditions	O
of	O
lighting	O
,	O
resolution	O
,	O
head	O
pose	O
etc	O
.	O

,	O
and	O
a	O
smart	O
algorithm	O
should	O
favor	O
face	O
images	O
that	O
are	O
more	O
discriminative	O
(	O
or	O
more	O
"	O
memorizable	O
"	O
)	O
and	O
prevent	O
poor	O
face	O
images	O
from	O
jeopardizing	O
the	O
recognition	Task
.	O

To	O
this	O
end	O
,	O
we	O
look	O
for	O
an	O
adaptive	Method
weighting	Method
scheme	Method
to	O
linearly	O
combine	O
all	O
frame	O
-	O
level	O
features	O
from	O
a	O
video	O
together	O
to	O
form	O
a	O
compact	Method
and	O
discriminative	Method
face	Method
representation	Method
.	O

Different	O
from	O
the	O
previous	O
methods	O
,	O
we	O
neither	O
fix	O
the	O
weights	O
nor	O
rely	O
on	O
any	O
particular	O
heuristics	O
to	O
set	O
them	O
.	O

Instead	O
,	O
we	O
designed	O
a	O
neural	Method
network	Method
to	O
adaptively	O
calculate	O
the	O
weights	O
.	O

We	O
named	O
our	O
network	O
the	O
Neural	Method
Aggregation	Method
Network	Method
(	Method
NAN	Method
)	O
,	O
whose	O
coefficients	O
can	O
be	O
trained	O
through	O
supervised	Method
learning	Method
in	O
a	O
normal	Task
face	Task
recognition	Task
training	Task
task	Task
without	O
the	O
need	O
for	O
extra	O
supervision	O
signals	O
.	O

The	O
proposed	O
NAN	Method
is	O
composed	O
of	O
two	O
major	O
modules	O
that	O
could	O
be	O
trained	O
end	O
-	O
to	O
-	O
end	O
or	O
one	O
by	O
one	O
separately	O
.	O

The	O
first	O
one	O
is	O
a	O
feature	Method
embedding	Method
module	Method
which	O
serves	O
as	O
a	O
frame	Method
-	Method
level	Method
feature	Method
extractor	Method
using	O
a	O
deep	O
CNN	Method
model	O
.	O

The	O
other	O
is	O
the	O
aggregation	Method
module	Method
that	O
adaptively	O
fuses	O
the	O
feature	O
vectors	O
of	O
all	O
the	O
video	O
frames	O
together	O
.	O

Our	O
neural	Method
aggregation	Method
network	Method
is	O
designed	O
to	O
inherit	O
the	O
main	O
advantages	O
of	O
pooling	Method
techniques	O
,	O
including	O
the	O
ability	O
to	O
handle	O
arbitrary	O
input	O
size	O
and	O
producing	O
orderinvariant	Method
representations	Method
.	O

The	O
key	O
component	O
of	O
this	O
network	O
is	O
inspired	O
by	O
the	O
Neural	Method
Turing	Method
Machine	Method
[	O
reference	O
]	O
and	O
the	O
work	O
of	O
[	O
reference	O
]	O
,	O
both	O
of	O
which	O
applied	O
an	O
attention	Method
mechanism	Method
to	O
organize	O
the	O
input	O
through	O
accessing	O
an	O
external	O
memory	O
.	O

This	O
mechanism	O
can	O
take	O
an	O
input	O
of	O
arbitrary	O
size	O
and	O
work	O
as	O
a	O
tailor	O
emphasizing	O
or	O
suppressing	O
each	O
input	O
element	O
just	O
via	O
a	O
weighted	Method
averaging	Method
,	O
and	O
very	O
importantly	O
it	O
is	O
order	O
independent	O
and	O
has	O
trainable	O
parameters	O
.	O

In	O
this	O
work	O
,	O
we	O
design	O
a	O
simple	O
network	Method
structure	Method
of	O
two	O
cascaded	Method
attention	Method
blocks	Method
associated	O
with	O
this	O
attention	Method
mechanism	Method
for	O
face	Task
feature	Task
aggregation	Task
.	O

Apart	O
from	O
building	O
a	O
video	Method
-	Method
level	Method
representation	Method
,	O
the	O
neural	Method
aggregation	Method
network	Method
can	O
also	O
serve	O
as	O
a	O
subject	Method
level	Method
feature	Method
extractor	Method
to	O
fuse	O
multiple	O
data	O
sources	O
.	O

For	O
example	O
,	O
one	O
can	O
feed	O
it	O
with	O
all	O
available	O
images	O
and	O
videos	O
,	O
or	O
the	O
aggregated	O
video	O
-	O
level	O
features	O
of	O
multiple	O
videos	O
from	O
the	O
same	O
subject	O
,	O
to	O
obtain	O
a	O
single	O
feature	Method
representation	Method
with	O
fixed	O
size	O
.	O

In	O
this	O
way	O
,	O
the	O
face	Method
recognition	Method
system	Method
not	O
only	O
enjoys	O
the	O
time	Metric
and	Metric
memory	Metric
efficiency	Metric
due	O
to	O
the	O
compact	Method
representation	Method
,	O
but	O
also	O
exhibits	O
superior	O
performance	O
,	O
as	O
we	O
will	O
show	O
in	O
our	O
experiments	O
.	O

We	O
evaluated	O
the	O
proposed	O
NAN	Method
for	O
both	O
the	O
tasks	O
of	O
video	O
face	Task
verification	Task
and	O
identification	Task
.	O

We	O
observed	O
consistent	O
margins	O
in	O
three	O
challenging	O
datasets	O
,	O
including	O
the	O
YouTube	Material
Face	Material
dataset	O
[	O
reference	O
]	O
,	O
the	O
IJB	Material
-	Material
A	Material
dataset	Material
[	O
reference	O
]	O
,	O
and	O
the	O
Celebrity	Material
-	Material
1000	Material
dataset	Material
[	O
reference	O
]	O
,	O
compared	O
to	O
the	O
baseline	O
strategies	O
and	O
other	O
competing	O
methods	O
.	O

Last	O
but	O
not	O
least	O
,	O
we	O
shall	O
point	O
out	O
that	O
our	O
proposed	O
NAN	Method
can	O
serve	O
as	O
a	O
general	O
framework	O
for	O
learning	O
contentadaptive	O
pooling	Method
.	O

Therefore	O
,	O
it	O
may	O
also	O
serve	O
as	O
a	O
feature	Method
aggregation	Method
scheme	Method
for	O
other	O
computer	Task
vision	Task
tasks	Task
.	O

section	O
:	O
Related	O
Works	O
Face	Task
recognition	Task
based	O
on	O
videos	O
or	O
image	O
sets	O
has	O
been	O
actively	O
studied	O
in	O
the	O
past	O
.	O

This	O
paper	O
is	O
concerned	O
with	O
the	O
input	O
being	O
an	O
orderless	O
set	O
of	O
face	O
images	O
.	O

Existing	O
methods	O
exploiting	O
temporal	O
dynamics	O
will	O
not	O
be	O
considered	O
here	O
.	O

For	O
set	Task
based	Task
face	Task
recognition	Task
,	O
many	O
previous	O
methods	O
have	O
attempted	O
to	O
represent	O
the	O
set	O
of	O
face	O
images	O
with	O
appearance	O
subspaces	O
or	O
manifolds	O
and	O
perform	O
recognition	Task
via	O
computing	O
manifold	O
similarity	O
or	O
distance	Method
[	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
.	O

These	O
traditional	O
methods	O
may	O
work	O
well	O
under	O
constrained	O
settings	O
but	O
usually	O
can	O
not	O
handle	O
the	O
challenging	O
unconstrained	O
scenarios	O
where	O
large	O
appearance	O
variations	O
are	O
present	O
.	O

Along	O
a	O
different	O
axis	O
,	O
some	O
methods	O
build	O
video	Method
feature	Method
representation	Method
based	O
on	O
local	O
features	O
[	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
.	O

For	O
example	O
,	O
the	O
PEP	Method
methods	Method
[	O
reference	O
][	O
reference	O
]	O
Recently	O
,	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
face	Method
recognition	Method
methods	Method
has	O
been	O
dominated	O
by	O
deep	O
convolution	Method
neural	Method
networks	Method
[	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
.	O

For	O
video	Task
face	Task
recognition	Task
,	O
most	O
of	O
these	O
methods	O
either	O
use	O
pairwise	Method
frame	Method
feature	Method
similarity	Method
computation	Method
[	O
reference	O
][	O
reference	O
]	O
or	O
naive	O
(	O
average	Method
/	O
max	O
)	O
frame	Method
feature	Method
pooling	Method
[	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
.	O

This	O
motivated	O
us	O
to	O
seek	O
for	O
an	O
adaptive	Method
aggregation	Method
approach	Method
.	O

As	O
previously	O
mentioned	O
,	O
this	O
work	O
is	O
also	O
related	O
to	O
the	O
Neural	Method
Turing	Method
Machine	Method
[	O
reference	O
]	O
and	O
the	O
work	O
of	O
[	O
reference	O
]	O
.	O

However	O
,	O
it	O
is	O
worth	O
noting	O
that	O
while	O
they	O
use	O
Recurrent	Method
Neural	Method
Networks	Method
(	O
RNN	Method
)	O
to	O
handle	O
sequential	O
inputs	O
/	O
outputs	O
,	O
there	O
is	O
no	O
RNN	Method
structure	Method
in	O
our	O
method	O
.	O

We	O
only	O
borrow	O
their	O
differentiable	Method
memory	Method
addressing	Method
/	O
attention	Method
scheme	Method
for	O
our	O
feature	Task
aggregation	Task
.	O

section	O
:	O
Neural	Method
Aggregation	Method
Network	Method
As	O
shown	O
in	O
Fig	O
.	O

1	O
,	O
the	O
NAN	Method
network	O
takes	O
a	O
set	O
of	O
face	O
images	O
of	O
a	O
person	O
as	O
input	O
and	O
outputs	O
a	O
single	O
feature	O
vector	O
as	O
its	O
representation	O
for	O
the	O
recognition	Task
task	Task
.	O

It	O
is	O
built	O
upon	O
a	O
modern	O
deep	O
CNN	Method
model	O
for	O
frame	Method
feature	Method
embedding	Method
,	O
and	O
becomes	O
more	O
powerful	O
for	O
video	Task
face	Task
recognition	Task
by	O
adaptively	O
aggregating	O
all	O
frames	O
in	O
the	O
video	O
into	O
a	O
compact	Method
vector	Method
representation	Method
.	O

Figure	O
2	O
.	O

Face	O
images	O
in	O
the	O
IJB	Material
-	Material
A	Material
dataset	Material
,	O
sorted	O
by	O
their	O
scores	O
(	O
values	O
of	O
e	O
in	O
Eq	O
.	O

2	O
)	O
from	O
a	O
single	O
attention	Method
block	Method
trained	O
in	O
the	O
face	Task
recognition	Task
task	Task
.	O

The	O
faces	O
in	O
the	O
top	O
,	O
middle	O
and	O
bottom	O
rows	O
are	O
sampled	O
from	O
the	O
faces	O
with	O
scores	O
in	O
the	O
highest	O
5	O
%	O
,	O
a	O
10	O
%	O
window	O
centered	O
at	O
the	O
median	O
,	O
and	O
the	O
lowest	O
5	O
%	O
,	O
respectively	O
.	O

section	O
:	O
Image	Metric
ID	Metric
Score	Metric
section	O
:	O
Feature	Method
embedding	Method
module	Method
The	O
image	Method
embedding	Method
module	Method
of	O
our	O
NAN	Method
is	O
a	O
deep	O
Convolution	Method
Neural	Method
Network	Method
(	O
CNN	Method
)	O
,	O
which	O
embeds	O
each	O
frame	O
of	O
a	O
video	O
to	O
a	O
face	Method
feature	Method
representation	Method
.	O

To	O
leverage	O
modern	O
deep	O
CNN	Method
networks	O
with	O
high	O
-	O
end	O
performances	O
,	O
in	O
this	O
paper	O
we	O
adopt	O
the	O
GoogLeNet	Method
[	O
reference	O
]	O
with	O
the	O
Batch	Method
Normalization	Method
(	O
BN	Method
)	O
technique	O
[	O
reference	O
]	O
.	O

Certainly	O
,	O
other	O
network	Method
architectures	Method
are	O
equally	O
applicable	O
here	O
as	O
well	O
.	O

The	O
GoogLeNet	Material
produces	O
128	O
-	O
dimension	O
image	O
features	O
,	O
which	O
are	O
first	O
normalized	O
to	O
be	O
unit	O
vectors	O
then	O
fed	O
into	O
the	O
aggregation	Method
module	Method
.	O

In	O
the	O
rest	O
of	O
this	O
paper	O
,	O
we	O
will	O
simply	O
refer	O
to	O
the	O
employed	O
GoogLeNet	O
-	O
BN	Method
network	O
as	O
CNN	Method
.	O

section	O
:	O
Aggregation	Method
module	Method
Consider	O
the	O
video	Task
face	Task
recognition	Task
task	Task
on	O
n	O
pairs	O
of	O
video	O
face	O
data	O
(	O
,	O
where	O
X	O
i	O
is	O
a	O
face	O
video	O
sequence	O
or	O
a	O
image	O
set	O
with	O
varying	O
image	O
number	O
K	O
i	O
,	O
i.e.	O
,	O
so	O
that	O
the	O
aggregated	Method
feature	Method
representation	Method
becomes	O
In	O
this	O
way	O
,	O
the	O
aggregated	O
feature	O
vector	O
has	O
the	O
same	O
size	O
as	O
a	O
single	O
face	O
image	O
feature	O
extracted	O
by	O
the	O
CNN	Method
.	O

Obviously	O
,	O
the	O
key	O
of	O
Eq	O
.	O

1	O
is	O
its	O
weights	O
{	O
a	O
k	O
}	O
.	O

If	O
a	O
k	O
≡	O
1	O
K	O
,	O
Eq	O
.	O

1	O
will	O
degrades	O
to	O
naive	Task
averaging	Task
,	O
which	O
is	O
usually	O
non	O
-	O
optimal	O
as	O
we	O
will	O
show	O
in	O
our	O
experiments	O
.	O

We	O
instead	O
try	O
to	O
design	O
a	O
better	O
weighting	Method
scheme	Method
.	O

Three	O
main	O
principles	O
have	O
been	O
considered	O
in	O
designing	O
our	O
aggregation	Method
module	Method
.	O

First	O
,	O
the	O
module	O
should	O
be	O
able	O
to	O
process	O
different	O
numbers	O
of	O
images	O
(	O
i.e.	O
different	O
K	O
i	O
'	O
s	O
)	O
,	O
as	O
the	O
video	O
data	O
source	O
varies	O
from	O
person	O
to	O
person	O
.	O

Second	O
,	O
the	O
aggregation	Method
should	O
be	O
invariant	O
to	O
the	O
image	O
order	O
-	O
we	O
prefer	O
the	O
result	O
unchanged	O
when	O
the	O
image	O
sequence	O
are	O
reversed	O
or	O
reshuffled	O
.	O

This	O
way	O
,	O
the	O
aggregation	Method
module	Method
can	O
handle	O
an	O
arbitrary	O
set	O
of	O
image	O
or	O
video	O
faces	O
without	O
temporal	O
information	O
(	O
e.g.	O
that	O
collected	O
from	O
different	O
Internet	O
locations	O
)	O
.	O

Third	O
,	O
the	O
module	O
should	O
be	O
adaptive	O
to	O
the	O
input	O
faces	O
and	O
has	O
parameters	O
trainable	O
through	O
supervised	Method
learning	Method
in	O
a	O
standard	O
face	Task
recognition	Task
training	Task
task	Task
.	O

Our	O
solution	O
is	O
inspired	O
by	O
the	O
memory	Method
attention	Method
mechanism	Method
described	O
in	O
[	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
.	O

The	O
idea	O
therein	O
is	O
to	O
use	O
a	O
neural	Method
model	Method
to	O
read	O
external	O
memories	O
through	O
a	O
differentiable	Method
addressing	Method
/	O
attention	Method
scheme	Method
.	O

Such	O
models	O
are	O
often	O
coupled	O
with	O
Recurrent	Method
Neural	Method
Networks	Method
(	O
RNN	Method
)	O
to	O
handle	O
sequential	O
inputs	O
/	O
outputs	O
[	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
.	O

Although	O
an	O
RNN	Method
structure	Method
is	O
not	O
needed	O
for	O
our	O
purpose	O
,	O
its	O
memory	Method
attention	Method
mechanism	Method
is	O
applicable	O
to	O
our	O
aggregation	Task
task	Task
.	O

In	O
this	O
work	O
,	O
we	O
treat	O
the	O
face	O
features	O
as	O
the	O
memory	O
and	O
cast	O
feature	Method
weighting	Method
as	O
a	O
memory	Method
addressing	Method
procedure	Method
.	O

We	O
employ	O
in	O
the	O
aggregation	Method
module	Method
the	O
"	O
attention	O
blocks	O
"	O
,	O
to	O
be	O
described	O
as	O
follows	O
.	O

section	O
:	O
Attention	O
blocks	O
An	O
attention	Method
block	Method
reads	O
all	O
feature	O
vectors	O
from	O
the	O
feature	Method
embedding	Method
module	Method
,	O
and	O
generate	O
linear	O
weights	O
for	O
them	O
.	O

Specifically	O
,	O
let	O
{	O
f	O
k	O
}	O
be	O
the	O
face	O
feature	O
vectors	O
,	O
then	O
an	O
attention	Method
block	Method
filters	O
them	O
with	O
a	O
kernel	Method
q	Method
via	O
dot	Method
product	Method
,	O
yielding	O
a	O
set	O
of	O
corresponding	O
significances	O
{	O
e	O
k	O
}	O
.	O

They	O
are	O
then	O
passed	O
to	O
a	O
softmax	Method
operator	Method
to	O
generate	O
positive	O
weights	O
{	O
a	O
k	O
}	O
with	O
k	O
a	O
k	O
=	O
1	O
.	O

These	O
two	O
operations	O
can	O
be	O
described	O
by	O
the	O
following	O
equations	O
,	O
respectively	O
:	O
It	O
can	O
be	O
seen	O
that	O
our	O
algorithm	O
essentially	O
selects	O
one	O
point	O
inside	O
of	O
the	O
convex	O
hull	O
spanned	O
by	O
all	O
the	O
feature	O
vectors	O
.	O

One	O
related	O
work	O
is	O
[	O
reference	O
]	O
where	O
each	O
face	O
image	O
set	O
is	O
approximated	O
with	O
a	O
convex	O
hull	O
and	O
set	O
similarities	O
are	O
defined	O
as	O
the	O
shortest	O
path	O
between	O
two	O
convex	O
hulls	O
.	O

In	O
this	O
way	O
,	O
the	O
number	O
of	O
inputs	O
{	O
f	O
k	O
}	O
does	O
not	O
affect	O
the	O
size	O
of	O
aggregation	Metric
r	Metric
,	O
which	O
is	O
of	O
the	O
same	O
dimension	O
as	O
a	O
single	O
feature	O
f	O
k	O
.	O

Besides	O
,	O
the	O
aggregation	O
result	O
is	O
invariant	O
to	O
the	O
input	O
order	O
of	O
f	O
k	O
:	O
according	O
to	O
Eq	O
.	O

1	O
,	O
2	O
,	O
and	O
3	O
,	O
permuting	O
f	O
k	O
and	O
f	O
k	O
has	O
no	O
effects	O
on	O
the	O
aggregated	Method
representation	Method
r.	Method
Furthermore	O
,	O
an	O
attention	Method
block	Method
is	O
modulated	O
by	O
the	O
filter	Method
kernel	Method
q	Method
,	O
which	O
is	O
trainable	O
through	O
standard	Method
backpropagation	Method
and	O
gradient	Method
descent	Method
.	O

Single	Method
attention	Method
block	Method
-	Method
Universal	Method
face	Method
feature	Method
quality	Method
measurement	Method
.	O

We	O
first	O
try	O
using	O
one	O
attention	Method
block	Method
for	O
aggregation	Task
.	O

In	O
this	O
case	O
,	O
vector	O
q	O
is	O
the	O
parameter	O
to	O
learn	O
.	O

It	O
has	O
the	O
same	O
size	O
as	O
a	O
single	O
feature	O
f	O
and	O
serves	O
as	O
a	O
universal	O
prior	O
measuring	O
the	O
face	Metric
feature	Metric
quality	Metric
.	O

We	O
train	O
the	O
network	O
to	O
perform	O
video	O
face	Task
verification	Task
(	O
see	O
Section	O
2.3	O
and	O
Section	O
3	O
for	O
details	O
)	O
in	O
the	O
IJB	Material
-	Material
A	Material
dataset	Material
[	O
reference	O
]	O
on	O
the	O
extracted	O
face	O
features	O
,	O
and	O
Figure	O
2	O
shows	O
the	O
sorted	O
scores	O
of	O
all	O
the	O
faces	O
images	O
in	O
the	O
dataset	O
.	O

It	O
can	O
be	O
seen	O
that	O
after	O
training	O
,	O
the	O
network	O
favors	O
highquality	O
face	O
images	O
,	O
such	O
as	O
those	O
of	O
high	O
resolutions	O
and	O
with	O
relatively	O
simple	O
backgrounds	O
.	O

It	O
down	O
-	O
weights	O
face	O
images	O
with	O
blur	O
,	O
occlusion	O
,	O
improper	O
exposure	O
and	O
extreme	O
poses	O
.	O

Table	O
1	O
shows	O
that	O
the	O
network	O
achieves	O
higher	O
accuracy	Metric
than	O
the	O
average	Method
pooling	Method
baseline	Method
in	O
the	O
verification	O
and	O
identification	Task
tasks	O
.	O

Cascaded	O
two	O
attention	Method
blocks	Method
-	O
Content	O
-	O
aware	Method
aggregation	Method
.	O

We	O
believe	O
a	O
content	Method
-	Method
aware	Method
aggregation	Method
can	O
perform	O
even	O
better	O
.	O

The	O
intuition	O
behind	O
is	O
that	O
face	O
image	O
variation	O
may	O
be	O
expressed	O
differently	O
at	O
different	O
geo	O
-	O
section	O
:	O
High	O
weight	O
Low	O
weight	O
Samples	O
from	O
a	O
video	O
/	O
image	O
set	O
All	O
weights	O
graphic	O
locations	O
in	O
the	O
feature	O
space	O
(	O
i.e.	O
for	O
different	O
persons	O
)	O
,	O
and	O
content	Method
-	Method
aware	Method
aggregation	Method
can	O
learn	O
to	O
select	O
features	O
that	O
are	O
more	O
discriminative	O
for	O
the	O
identity	O
of	O
the	O
input	O
image	O
set	O
.	O

To	O
this	O
end	O
,	O
we	O
employ	O
two	O
attention	Method
blocks	Method
in	O
a	O
cascaded	O
and	O
end	O
-	O
to	O
-	O
end	O
fashion	O
described	O
as	O
follows	O
.	O

where	O
W	O
and	O
b	O
are	O
the	O
weight	O
matrix	O
and	O
bias	O
vector	O
of	O
the	O
neurons	O
respectively	O
,	O
and	O
tanh	O
(	O
x	O
)	O
=	O
We	O
train	O
the	O
network	O
on	O
the	O
IJB	Material
-	Material
A	Material
dataset	Material
again	O
,	O
and	O
Table	O
1	O
shows	O
that	O
the	O
network	O
obtained	O
better	O
results	O
than	O
using	O
single	O
attention	O
block	O
.	O

Figure	O
3	O
shows	O
some	O
typical	O
examples	O
of	O
the	O
weights	O
computed	O
by	O
the	O
trained	O
network	O
for	O
different	O
videos	O
or	O
image	O
sets	O
.	O

Our	O
current	O
full	O
solution	O
of	O
NAN	Method
,	O
based	O
on	O
which	O
all	O
the	O
remaining	O
experimental	O
results	O
are	O
obtained	O
,	O
adopts	O
such	O
a	O
cascaded	Method
two	Method
attention	Method
block	Method
design	Method
(	O
as	O
per	O
Fig	O
.	O

1	O
)	O
.	O

section	O
:	O
Network	Method
training	Method
The	O
NAN	Method
network	O
can	O
be	O
trained	O
either	O
for	O
face	Task
verification	Task
and	O
identification	Task
tasks	Task
with	O
standard	O
configurations	O
.	O

section	O
:	O
Training	Metric
loss	Metric
For	O
verification	Task
,	O
we	O
build	O
a	O
siamese	Method
neural	Method
aggregation	Method
network	Method
structure	Method
[	O
reference	O
]	O
with	O
two	O
NANs	O
sharing	O
weights	O
,	O
and	O
minimize	O
the	O
average	Method
contrastive	O
loss	O
[	O
reference	O
]	O
For	O
identification	Task
,	O
we	O
add	O
on	O
top	O
of	O
NAN	Method
a	O
fullyconnected	O
layer	O
followed	O
by	O
a	O
softmax	Method
and	O
minimize	O
the	O
average	Method
classification	O
loss	O
.	O

section	O
:	O
Module	O
training	O
The	O
two	O
modules	O
can	O
be	O
trained	O
either	O
simultaneously	O
in	O
an	O
end	O
-	O
to	O
-	O
end	O
fashion	O
,	O
or	O
separately	O
one	O
by	O
one	O
.	O

The	O
latter	O
option	O
is	O
chosen	O
in	O
this	O
work	O
.	O

Specifically	O
,	O
we	O
first	O
train	O
the	O
CNN	Method
on	O
single	O
images	O
with	O
the	O
identification	Task
task	O
,	O
then	O
we	O
train	O
the	O
aggregation	Method
module	Method
on	O
top	O
of	O
the	O
features	O
extracted	O
by	O
CNN	Method
.	O

More	O
details	O
can	O
be	O
found	O
in	O
Section	O
3.1	O
.	O

We	O
chose	O
this	O
separate	O
training	Method
strategy	Method
mainly	O
for	O
two	O
reasons	O
.	O

First	O
,	O
in	O
this	O
work	O
we	O
would	O
like	O
to	O
focus	O
on	O
analyzing	O
the	O
effectiveness	O
and	O
performance	O
of	O
the	O
aggregation	Method
module	Method
with	O
the	O
attention	Method
mechanism	Method
.	O

Despite	O
the	O
huge	O
success	O
of	O
applying	O
deep	O
CNN	Method
in	O
image	Task
-	Task
based	Task
face	Task
recognition	Task
task	Task
,	O
little	O
attention	O
has	O
been	O
drawn	O
to	O
CNN	Method
feature	Method
aggregation	Method
to	O
our	O
knowledge	O
.	O

Second	O
,	O
training	O
a	O
deep	O
CNN	Method
usually	O
necessitates	O
a	O
large	O
volume	O
of	O
labeled	O
data	O
.	O

While	O
millions	O
of	O
still	O
images	O
can	O
be	O
obtained	O
for	O
training	O
nowadays	O
[	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
]	O
,	O
it	O
appears	O
not	O
practical	O
to	O
collect	O
such	O
amount	O
of	O
distinctive	O
face	O
videos	O
or	O
sets	O
.	O

We	O
leave	O
an	O
endto	O
-	O
end	O
training	O
of	O
the	O
NAN	Method
as	O
our	O
future	O
work	O
.	O

section	O
:	O
Experiments	O
This	O
section	O
evaluates	O
the	O
performance	O
of	O
the	O
proposed	O
NAN	Method
network	O
.	O

We	O
will	O
begin	O
with	O
introducing	O
our	O
training	O
details	O
and	O
the	O
baseline	O
methods	O
,	O
followed	O
by	O
reporting	O
the	O
results	O
on	O
three	O
video	O
face	O
recognition	O
datasets	O
:	O
the	O
IARPA	Material
Janus	Material
Benchmark	Material
A	Material
(	O
IJB	Material
-	Material
A	Material
)	O
[	O
reference	O
]	O
,	O
the	O
YouTube	Material
Face	Material
dataset	O
[	O
reference	O
]	O
,	O
and	O
the	O
Celebrity	Material
-	Material
1000	Material
dataset	Material
[	O
reference	O
]	O
.	O

section	O
:	O
Training	O
details	O
As	O
mentioned	O
in	O
Section	O
2.3	O
,	O
two	O
networks	O
are	O
trained	O
separately	O
in	O
this	O
work	O
.	O

To	O
train	O
the	O
CNN	Method
,	O
we	O
use	O
about	O
3	O
M	O
face	O
images	O
of	O
50	O
K	O
identities	O
crawled	O
from	O
the	O
Internet	O
to	O
perform	O
image	O
-	O
based	O
identification	Task
.	O

The	O
faces	O
are	O
detected	O
using	O
the	O
JDA	Method
method	Method
[	O
reference	O
]	O
,	O
and	O
aligned	O
with	O
the	O
LBF	Method
method	Method
[	O
reference	O
]	O
.	O

The	O
input	O
image	O
size	O
is	O
224x224	O
.	O

After	O
training	O
,	O
the	O
CNN	Method
is	O
fixed	O
and	O
we	O
focus	O
on	O
analyzing	O
the	O
effectiveness	O
of	O
the	O
neural	Method
aggregation	Method
module	Method
.	O

The	O
aggregation	Method
module	Method
is	O
trained	O
on	O
each	O
video	O
face	O
dataset	O
we	O
tested	O
on	O
with	O
standard	Method
backpropagation	Method
and	O
an	O
RMSProp	Method
solver	Method
[	O
reference	O
]	O
.	O

An	O
all	O
-	O
zero	Method
parameter	Method
initialization	Method
is	O
used	O
,	O
i.e.	O
,	O
we	O
start	O
from	O
average	Method
pooling	Method
.	O

The	O
batch	Metric
size	Metric
,	O
learning	Metric
rate	Metric
,	O
and	O
iteration	O
are	O
tuned	O
for	O
each	O
dataset	O
.	O

As	O
the	O
network	O
is	O
quite	O
simple	O
and	O
image	O
features	O
are	O
compact	Method
(	O
128	O
-	O
d	O
)	O
,	O
the	O
training	O
process	O
is	O
quite	O
efficient	O
:	O
training	O
on	O
5	O
K	O
video	O
pairs	O
with	O
∼1	O
M	O
images	O
in	O
total	O
only	O
takes	O
less	O
than	O
2	O
minutes	O
on	O
a	O
CPU	O
of	O
a	O
desktop	O
PC	O
.	O

section	O
:	O
Baseline	O
methods	O
Since	O
our	O
goal	O
is	O
compact	Method
video	O
face	Method
representation	Method
,	O
we	O
compare	O
the	O
results	O
with	O
simple	O
aggregation	Method
strategies	Method
such	O
as	O
average	Method
pooling	Method
.	O

We	O
also	O
compare	O
with	O
some	O
set	Method
-	Method
toset	Method
similarity	Method
measurements	Method
leveraging	O
pairwise	Metric
comparison	Metric
on	O
the	O
image	Metric
level	Metric
.	O

To	O
keep	O
it	O
simple	O
,	O
we	O
simply	O
use	O
the	O
L	O
2	O
feature	O
distances	O
for	O
face	Task
recognition	Task
(	O
all	O
features	O
are	O
normalized	O
)	O
,	O
although	O
it	O
is	O
possible	O
to	O
combine	O
with	O
an	O
extra	O
metric	Method
learning	Method
or	O
template	Method
adaption	Method
technique	Method
[	O
reference	O
]	O
to	O
further	O
boost	O
the	O
performance	O
on	O
each	O
dataset	O
.	O

In	O
the	O
baseline	O
methods	O
,	O
CNN	Method
+	O
Min	O
L	O
2	O
,	O
CNN	Method
+	O
Max	O
L	O
2	O
,	O
CNN	Method
+	O
Mean	O
L	O
2	O
and	O
CNN	Method
+	O
SoftMin	O
L	O
2	O
measure	O
the	O
similarity	Metric
of	O
two	O
video	O
faces	O
based	O
on	O
the	O
L	O
2	O
feature	O
distances	O
of	O
all	O
frame	O
pairs	O
.	O

They	O
necessitate	O
storing	O
all	O
image	O
features	O
of	O
a	O
video	O
,	O
i.e.	O
,	O
with	O
O	O
(	O
n	O
)	O
space	Metric
complexity	Metric
.	O

The	O
first	O
three	O
use	O
the	O
minimum	O
,	O
maximum	O
and	O
mean	O
pairwise	O
distance	O
respectively	O
,	O
thus	O
having	O
O	O
(	O
n	O
2	O
)	O
complexity	Metric
for	O
similarity	Task
computation	Task
.	O

CNN	Method
+	O
SoftMin	O
L	O
2	O
corresponds	O
to	O
the	O
SoftMax	Metric
similarity	Metric
score	Metric
advocated	O
in	O
some	O
works	O
such	O
as	O
[	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
.	O

It	O
has	O
O	O
(	O
m·n	O
2	O
)	O
complexity	Metric
for	O
computation	Task
[	O
reference	O
]	O
.	O

CNN	Method
+	O
MaxPool	O
and	O
CNN	Method
+	O
AvePool	O
are	O
respectively	O
max	O
-	O
pooling	Method
and	O
average	Method
-	O
pooling	Method
along	O
each	O
feature	O
dimension	O
for	O
aggregation	Task
.	O

These	O
two	O
methods	O
as	O
well	O
as	O
our	O
NAN	Method
produce	O
a	O
128	O
-	O
d	O
feature	Method
representation	Method
for	O
each	O
video	O
and	O
compute	O
the	O
similarity	Metric
in	O
O	Metric
(	Metric
1	Metric
)	Metric
time	Metric
.	O

section	O
:	O
Results	O
on	O
IJB	Material
-	Material
A	Material
dataset	Material
The	O
IJB	Material
-	Material
A	Material
dataset	Material
[	O
reference	O
]	O
contains	O
face	O
images	O
and	O
videos	O
captured	O
from	O
unconstrained	O
environments	O
.	O

It	O
features	O
full	O
pose	O
variation	O
and	O
wide	O
variations	O
in	O
imaging	O
conditions	O
[	O
reference	O
]	O
0	O
thus	O
is	O
very	O
challenging	O
.	O

There	O
are	O
500	O
subjects	O
with	O
5	O
,	O
397	O
images	O
and	O
2	O
,	O
042	O
videos	O
in	O
total	O
and	O
11.4	O
images	O
and	O
4.2	O
videos	O
per	O
subject	O
on	O
average	Method
.	O

We	O
detect	O
the	O
faces	O
with	O
landmarks	O
using	O
STN	Method
[	O
reference	O
]	O
face	Method
detector	Method
,	O
and	O
then	O
align	O
the	O
face	O
image	O
with	O
similarity	Method
transformation	Method
.	O

In	O
this	O
dataset	O
,	O
each	O
training	O
and	O
testing	O
instance	O
is	O
called	O
a	O
'	O
template	O
'	O
,	O
which	O
comprises	O
1	O
to	O
190	O
mixed	O
still	O
images	O
and	O
video	O
frames	O
.	O

Since	O
one	O
template	O
may	O
contain	O
multiple	O
medias	O
and	O
the	O
dataset	O
provides	O
the	O
media	O
i	O
d	O
for	O
each	O
image	O
,	O
another	O
possible	O
aggregation	Method
strategy	Method
is	O
first	O
aggregating	O
the	O
frame	O
features	O
in	O
each	O
media	O
then	O
the	O
media	O
features	O
in	O
the	O
template	O
[	O
reference	O
][	O
reference	O
]	O
.	O

This	O
strategy	O
is	O
also	O
tested	O
in	O
this	O
work	O
with	O
CNN	Method
+	O
AvePool	O
and	O
our	O
NAN	Method
.	O

Note	O
that	O
media	O
i	O
d	O
may	O
not	O
be	O
always	O
available	O
in	O
practice	O
.	O

We	O
test	O
the	O
proposed	O
method	O
on	O
both	O
the	O
'	O
compare	Metric
'	Metric
protocol	Metric
for	O
1:1	O
face	Task
verification	Task
and	O
the	O
'	Method
search	Method
'	Method
protocol	Method
for	O
1:N	O
face	O
identification	Task
.	O

For	O
verification	Task
,	O
the	O
true	Metric
accept	Metric
rates	Metric
(	O
TAR	Metric
)	O
vs.	O
false	Metric
positive	Metric
rates	Metric
(	O
FAR	Metric
)	O
are	O
reported	O
.	O

For	O
identification	Task
,	O
the	O
true	O
positive	O
identification	Task
rate	O
(	O
TPIR	Metric
)	O
vs.	O
false	O
positive	O
identification	Task
rate	O
(	O
FPIR	Metric
)	O
and	O
the	O
Rank	Metric
-	Metric
N	Metric
accuracies	Metric
are	O
reported	O
.	O

Table	O
2	O
presents	O
the	O
numerical	O
results	O
of	O
different	O
methods	O
,	O
and	O
Figure	O
4	O
shows	O
the	O
receiver	Metric
operating	Metric
characteristics	Metric
(	O
ROC	Metric
)	O
curves	O
for	O
verification	Task
as	O
well	O
as	O
the	O
cumulative	Metric
match	Metric
characteristic	Metric
(	O
CMC	Metric
)	O
and	O
decision	Metric
error	Metric
trade	Metric
-	Metric
off	Metric
(	O
DET	Metric
)	O
curves	O
for	O
identification	Task
.	O

The	O
metrics	O
are	O
calculated	O
according	O
to	O
[	O
reference	O
][	O
reference	O
]	O
on	O
the	O
10	O
splits	O
.	O

In	O
general	O
,	O
the	O
CNN	Method
+	O
Max	O
L	O
2	O
,	O
CNN	Method
+	O
Min	O
L	O
2	O
and	O
CNN	Method
+	O
MaxPool	O
perform	O
worst	O
among	O
the	O
baseline	O
methods	O
.	O

CNN	Method
+	O
SoftMin	O
L	O
2	O
performs	O
slightly	O
better	O
than	O
CNN	Method
+	O
MaxPool	O
.	O

The	O
use	O
of	O
media	O
i	O
d	O
significantly	O
improves	O
Table	O
3	O
.	O

Verification	Metric
accuracy	Metric
comparison	O
of	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
methods	O
,	O
our	O
baselines	O
and	O
NAN	Method
network	O
on	O
the	O
YTF	Material
dataset	O
.	O

Method	O
Accuracy	Metric
(	O
%	O
)	O
AUC	Metric
LM3L	O
[	O
reference	O
]	O
81.3	O
±	O
1.2	O
89.3	O
DDML	O
(	O
combined	O
)	O
[	O
reference	O
]	O
82.3	O
±	O
1.5	O
90.1	O
EigenPEP	O
[	O
reference	O
]	O
84.8	O
±	O
1.4	O
92.6	O
DeepFace	O
-	O
single	O
[	O
reference	O
]	O
91.4	O
±	O
1.1	O
96.3	O
DeepID2	O
+	O
[	O
reference	O
]	O
93.2	O
±	O
0.2	O
-	O
Wen	O
et	O
al	O
.	O

[	O
reference	O
]	O
94.9	O
-	O
FaceNet	O
[	O
reference	O
]	O
95.12	O
±	O
0.39	O
-	O
VGG	O
-	O
Face	O
[	O
reference	O
]	O
97	O
Figure	O
3	O
has	O
shown	O
some	O
typical	O
examples	O
of	O
the	O
weighting	O
results	O
.	O

NAN	Method
exhibits	O
the	O
ability	O
to	O
choose	O
high	O
-	O
quality	O
and	O
more	O
discriminative	O
face	O
images	O
while	O
repelling	O
poor	O
face	O
images	O
.	O

section	O
:	O
Results	O
on	O
YouTube	Material
Face	Material
dataset	O
We	O
then	O
test	O
our	O
method	O
on	O
the	O
YouTube	Material
Face	Material
(	O
YTF	Material
)	O
dataset	O
[	O
reference	O
]	O
which	O
is	O
designed	O
for	O
unconstrained	O
face	Task
verification	Task
in	O
videos	O
.	O

It	O
contains	O
3	O
,	O
425	O
videos	O
of	O
1	O
,	O
595	O
different	O
people	O
,	O
and	O
the	O
video	O
lengths	O
vary	O
from	O
48	O
to	O
6	O
,	O
070	O
frames	O
with	O
an	O
average	Method
length	O
of	O
181.3	O
frames	O
.	O

Ten	O
folds	O
of	O
500	O
video	O
pairs	O
are	O
available	O
,	O
and	O
we	O
follow	O
the	O
standard	O
verification	O
protocol	O
to	O
report	O
the	O
average	Method
accuracy	O
with	O
crossvalidation	Method
.	O

We	O
again	O
use	O
the	O
STN	Method
and	Method
similarity	Method
transformation	Method
to	O
align	O
the	O
face	O
images	O
.	O

The	O
results	O
of	O
our	O
NAN	Method
,	O
its	O
baselines	O
,	O
and	O
other	O
methods	O
are	O
presented	O
in	O
Table	O
3	O
,	O
with	O
their	O
ROC	Metric
curves	O
shown	O
in	O
Fig	O
.	O

5	O
.	O

It	O
can	O
be	O
seen	O
that	O
the	O
NAN	Method
again	O
outperforms	O
all	O
its	O
section	O
:	O
High	O
weight	O
Low	O
weight	O
Samples	O
from	O
a	O
video	O
All	O
weights	O
Figure	O
6	O
.	O

Typical	O
examples	O
on	O
the	O
YTF	Material
dataset	O
showing	O
the	O
weights	O
of	O
the	O
video	O
frames	O
computed	O
by	O
our	O
NAN	Method
.	O

In	O
each	O
row	O
,	O
five	O
frames	O
are	O
sampled	O
from	O
a	O
video	O
and	O
sorted	O
based	O
on	O
their	O
weights	O
(	O
numbers	O
in	O
the	O
rectangles	O
)	O
;	O
the	O
rightmost	O
bar	O
chart	O
shows	O
the	O
sorted	O
weights	O
of	O
all	O
the	O
frames	O
(	O
heights	O
scaled	O
)	O
.	O

baselines	O
.	O

The	O
gaps	O
between	O
NAN	Method
and	O
the	O
best	O
-	O
performing	O
baselines	O
are	O
smaller	O
compared	O
to	O
the	O
results	O
on	O
IJB	Material
-	Material
A.	Material
This	O
is	O
because	O
the	O
face	O
variations	O
in	O
this	O
dataset	O
are	O
relatively	O
small	O
(	O
compare	O
the	O
examples	O
in	O
Fig	O
.	O

6	O
and	O
Fig	O
.	O

3	O
)	O
,	O
thus	O
no	O
much	O
beneficial	O
information	O
can	O
be	O
extracted	O
compared	O
to	O
naive	Method
average	Method
pooling	Method
or	O
computing	O
mean	O
L	O
2	O
distances	O
.	O

Compared	O
to	O
previous	O
methods	O
,	O
our	O
NAN	Method
achieves	O
a	O
mean	Metric
accuracy	Metric
of	O
95.72	O
%	O
,	O
reducing	O
the	O
error	Metric
of	O
FaceNet	Metric
by	O
12.3	O
%	O
.	O

Note	O
that	O
FaceNet	Material
is	O
also	O
based	O
on	O
a	O
GoogLeNet	Method
style	Method
network	Method
,	O
and	O
the	O
average	Method
similarity	O
of	O
all	O
pairs	O
of	O
100	O
frames	O
in	O
each	O
video	O
(	O
i.e.	O
,	O
10	O
K	O
pairs	O
)	O
was	O
used	O
[	O
reference	O
]	O
.	O

To	O
our	O
knowledge	O
,	O
only	O
the	O
VGG	Method
-	Method
Face	Method
[	O
reference	O
]	O
achieves	O
an	O
accuracy	Metric
(	O
97.3	O
%	O
)	O
higher	O
than	O
ours	O
.	O

However	O
,	O
that	O
result	O
is	O
based	O
on	O
a	O
further	O
discriminative	Method
metric	Method
learning	Method
on	O
YTF	Material
,	O
without	O
which	O
the	O
accuracy	Metric
is	O
only	O
91.5	O
%	O
[	O
reference	O
]	O
.	O

section	O
:	O
Results	O
on	O
Celebrity	Material
-	Material
1000	Material
dataset	Material
The	O
Celebrity	Material
-	Material
1000	Material
dataset	Material
[	O
reference	O
]	O
is	O
designed	O
to	O
study	O
the	O
unconstrained	O
video	O
-	O
based	O
face	O
identification	Task
problem	O
.	O

It	O
contains	O
159	O
,	O
726	O
video	O
sequences	O
of	O
1	O
,	O
000	O
human	O
subjects	O
,	O
with	O
2.4	O
M	O
frames	O
in	O
total	O
(	O
∼15	O
frames	O
per	O
sequence	O
)	O
.	O

We	O
use	O
the	O
provided	O
5	O
facial	O
landmarks	O
to	O
align	O
the	O
face	O
images	O
.	O

Two	O
types	O
of	O
protocols	O
-	O
open	O
-	O
set	O
and	O
close	O
-	O
set	O
-	O
exist	O
on	O
this	O
dataset	O
.	O

More	O
details	O
about	O
the	O
protocols	O
and	O
the	O
dataset	O
can	O
be	O
found	O
in	O
[	O
reference	O
]	O
.	O

Close	O
-	O
set	O
tests	O
.	O

For	O
the	O
close	Task
-	Task
set	Task
protocol	Task
,	O
we	O
first	O
train	O
the	O
network	O
on	O
the	O
video	O
sequences	O
with	O
the	O
identification	Task
loss	O
.	O

We	O
take	O
the	O
FC	O
layer	O
output	O
values	O
as	O
the	O
scores	O
and	O
the	O
subject	O
with	O
the	O
maximum	O
score	O
as	O
the	O
result	O
.	O

We	O
also	O
train	O
a	O
linear	Method
classifier	Method
for	O
CNN	Method
+	O
AvePool	O
to	O
classify	O
each	O
video	O
feature	O
.	O

As	O
the	O
features	O
are	O
built	O
on	O
video	O
sequences	O
,	O
we	O
call	O
this	O
approach	O
'	O
VideoAggr	O
'	O
to	O
distinguish	O
it	O
from	O
another	O
approach	O
to	O
be	O
described	O
next	O
.	O

Each	O
subject	O
in	O
the	O
dataset	O
has	O
multiple	O
video	O
sequences	O
,	O
thus	O
we	O
can	O
build	O
a	O
single	O
representation	O
for	O
a	O
subject	O
by	O
aggregating	O
all	O
available	O
images	O
in	O
all	O
the	O
training	O
(	O
gallery	O
)	O
video	O
sequences	O
.	O

We	O
call	O
this	O
approach	O
'	O
SubjectAggr	Material
'	O
.	O

This	O
way	O
,	O
the	O
linear	Method
classifier	Method
can	O
be	O
bypassed	O
,	O
and	O
identification	Task
can	O
be	O
achieved	O
simply	O
by	O
comparing	O
the	O
feature	O
L	O
2	O
distances	O
.	O

The	O
results	O
are	O
presented	O
in	O
Table	O
4	O
.	O

Note	O
that	O
[	O
reference	O
]	O
and	O
[	O
reference	O
]	O
are	O
not	O
using	O
deep	Method
learning	Method
and	O
no	O
deep	Method
network	Method
based	Method
method	Method
reported	O
result	O
on	O
this	O
dataset	O
.	O

So	O
we	O
mainly	O
compare	O
with	O
our	O
baselines	O
in	O
the	O
following	O
.	O

It	O
can	O
be	O
seen	O
from	O
Table	O
4	O
and	O
Fig	O
.	O

7	O
(	O
a	O
)	O
that	O
NAN	Method
consistently	O
outperforms	O
the	O
baseline	O
methods	O
for	O
both	O
'	O
VideoAggr	Material
'	Material
and	O
'	O
SubjectAggr	Material
'	O
.	O

Significant	O
improvements	O
upon	O
the	O
baseline	O
are	O
achieved	O
for	O
the	O
'	O
SubjectAggr	Material
'	O
approach	O
.	O

It	O
is	O
interesting	O
to	O
see	O
that	O
,	O
'	O
SubjectAggr	Material
'	O
leads	O
to	O
a	O
clear	O
performance	O
drop	O
for	O
CNN	Method
+	O
AvePool	O
compared	O
to	O
its	O
'	O
VideoAggr	O
'	O
.	O

This	O
indicates	O
that	O
the	O
naive	Method
aggregation	Method
gets	O
even	O
worse	O
when	O
applied	O
on	O
the	O
subject	O
level	O
with	O
multiple	O
videos	O
.	O

However	O
,	O
our	O
NAN	Method
can	O
benefit	O
from	O
'	O
SubjectAggr	Material
'	O
,	O
yielding	O
results	O
consistently	O
better	O
than	O
or	O
on	O
par	O
with	O
the	O
'	O
VideoAggr	Method
'	Method
approach	Method
and	O
delivers	O
a	O
considerable	O
accuracy	Metric
boost	O
compared	O
to	O
the	O
baseline	O
.	O

This	O
suggests	O
our	O
NAN	Method
works	O
quite	O
well	O
on	O
handling	O
large	Task
data	Task
variations	Task
.	O

CNN	Method
+	O
AvePool	O
-	O
SubjectAggr	Material
NAN	Method
-	O
SubjectAggr	Material
(	O
a	O
)	O
Close	O
-	O
set	O
tests	O
on	O
1000	O
subjects	O
(	O
b	O
)	O
Open	O
-	O
set	O
tests	O
on	O
800	O
subjects	O
Open	O
-	O
set	O
tests	O
.	O

We	O
then	O
test	O
our	O
NAN	Method
with	O
the	O
close	Method
-	Method
set	Method
protocol	Method
.	O

We	O
first	O
train	O
the	O
network	O
on	O
the	O
provided	O
training	O
video	O
sequences	O
.	O

In	O
the	O
testing	O
stage	O
,	O
we	O
take	O
the	O
'	O
SubjectAggr	Material
'	O
approach	O
described	O
before	O
to	O
build	O
a	O
highly	O
-	O
compact	Method
face	Method
representation	Method
for	O
each	O
gallery	O
subject	O
.	O

Identification	Task
is	O
perform	O
simply	O
by	O
comparing	O
the	O
L	Method
2	Method
distances	Method
between	O
aggregated	Method
face	Method
representations	Method
.	O

The	O
results	O
in	O
both	O
Table	O
5	O
and	O
Fig	O
.	O

7	O
(	O
b	O
)	O
show	O
that	O
our	O
NAN	Method
significantly	O
reduces	O
the	O
error	Metric
of	O
the	O
baseline	O
CNN	Method
+	O
AvePool	O
.	O

This	O
again	O
suggests	O
that	O
in	O
the	O
presence	O
of	O
large	O
face	O
variances	O
,	O
the	O
widely	O
used	O
strategies	O
such	O
as	O
average	Method
-	Method
pooling	Method
aggregation	Method
and	O
the	O
pairwise	Method
distance	Method
computation	Method
are	O
far	O
from	O
optimal	O
.	O

In	O
such	O
cases	O
,	O
our	O
learned	O
NAN	Method
model	O
is	O
clearly	O
more	O
powerful	O
,	O
and	O
the	O
aggregated	Method
feature	Method
representation	Method
by	O
it	O
is	O
more	O
favorable	O
for	O
the	O
video	Task
face	Task
recognition	Task
task	Task
.	O

section	O
:	O
Conclusions	O
We	O
have	O
presented	O
a	O
Neural	Method
Aggregation	Method
Network	Method
for	O
video	O
face	Method
representation	Method
and	O
recognition	O
.	O

It	O
fuses	O
all	O
input	O
frames	O
with	O
a	O
set	O
of	O
content	O
adaptive	O
weights	O
,	O
resulting	O
in	O
a	O
compact	Method
representation	Method
that	O
is	O
invariant	O
to	O
the	O
input	O
frame	O
order	O
.	O

The	O
aggregation	Method
scheme	Method
is	O
simple	O
with	O
small	O
computation	O
and	O
memory	O
footprints	O
,	O
but	O
can	O
generate	O
quality	O
face	Method
representations	Method
after	O
training	O
.	O

The	O
proposed	O
NAN	Method
can	O
be	O
used	O
for	O
general	Task
video	Task
or	Task
set	Task
representation	Task
,	O
and	O
we	O
plan	O
to	O
apply	O
it	O
to	O
other	O
vision	Task
tasks	Task
in	O
our	O
future	O
work	O
.	O

section	O
:	O
section	O
:	O
Acknowledgments	O
GH	O
was	O
partly	O
supported	O
by	O
NSFC	O
Grant	O
61629301	O
.	O

HL	O
's	O
work	O
was	O
supported	O
in	O
part	O
by	O
Australia	O
ARC	O
Centre	O
of	O
Excellence	O
for	O
Robotic	Task
Vision	Task
(	O
CE140100016	O
)	O
and	O
by	O
CSIRO	O
Data61	O
.	O

section	O
:	O
