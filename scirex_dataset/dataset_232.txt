document O
: O
Recurrent Method
Pixel Method
Embedding Method
for O
Instance Task
Grouping Task
We O
introduce O
a O
differentiable O
, O
end O
- O
to O
- O
end Method
trainable Method
framework Method
for O
solving O
pixel Task
- Task
level Task
grouping Task
problems Task
such O
as O
instance Task
segmentation Task
consisting O
of O
two O
novel O
components O
. O
First O
, O
we O
regress O
pixels O
into O
a O
hyper O
- O
spherical O
embedding O
space O
so O
that O
pixels O
from O
the O
same O
group O
have O
high O
cosine O
similarity O
while O
those O
from O
different O
groups O
have O
similarity O
below O
a O
specified O
margin O
. O
We O
analyze O
the O
choice O
of O
embedding O
dimension O
and O
margin O
, O
relating O
them O
to O
theoretical O
results O
on O
the O
problem O
of O
distributing O
points O
uniformly O
on O
the O
sphere O
. O
Second O
, O
to O
group O
instances O
, O
we O
utilize O
a O
variant O
of O
mean Method
- Method
shift Method
clustering Method
, O
implemented O
as O
a O
recurrent Method
neural Method
network Method
parameterized O
by O
kernel Method
bandwidth Method
. O
This O
recurrent Method
grouping Method
module Method
is O
differentiable O
, O
enjoys O
convergent O
dynamics O
and O
probabilistic O
interpretability O
. O
Backpropagating O
the O
group Method
- Method
weighted Method
loss Method
through O
this O
module O
allows O
learning O
to O
focus O
on O
only O
correcting O
embedding O
errors O
that O
wo O
n’t O
be O
resolved O
during O
subsequent O
clustering Task
. O
Our O
framework O
, O
while O
conceptually O
simple O
and O
theoretically O
abundant O
, O
is O
also O
practically O
effective O
and O
computationally O
efficient O
. O
We O
demonstrate O
substantial O
improvements O
over O
state O
- O
of O
- O
the O
- O
art O
instance Method
segmentation Method
for O
object Task
proposal Task
generation Task
, O
as O
well O
as O
demonstrating O
the O
benefits O
of O
grouping Task
loss Task
for O
classification Task
tasks Task
such O
as O
boundary Task
detection Task
and O
semantic Task
segmentation Task
. O
section O
: O
Introduction O
The O
successes O
of O
deep Method
convolutional Method
neural Method
nets Method
( O
CNNs Method
) O
at O
image Task
classification Task
has O
spawned O
a O
flurry O
of O
work O
in O
computer Task
vision Task
on O
adapting O
these O
models O
to O
pixel Task
- Task
level Task
image Task
understanding Task
tasks Task
, O
such O
as O
boundary Task
detection Task
, O
semantic Task
segmentation Task
, O
optical Task
flow Task
, O
and O
pose Task
estimation Task
. O
The O
key O
ideas O
that O
have O
enabled O
this O
adaption O
thus O
far O
are O
: O
( O
1 O
) O
deconvolution Method
schemes Method
that O
allow O
for O
upsampling O
coarse O
pooled O
feature O
maps O
to O
make O
detailed O
predictions O
at O
the O
spatial O
resolution O
of O
individual O
pixels O
, O
( O
2 O
) O
skip O
connections O
and O
hyper O
- O
columns O
which O
concatenate O
representations O
across O
multi O
- O
resolution O
feature O
maps O
, O
( O
3 O
) O
atrous Method
convolution Method
which O
allows O
efficient O
computation Task
with O
large O
receptive O
fields O
while O
maintaining O
spatial O
resolution O
, O
and O
( O
4 O
) O
fully Method
convolutional Method
operation Method
which O
handles O
variable O
sized O
input O
images O
. O
In O
contrast O
, O
there O
has O
been O
less O
innovation O
in O
the O
development O
of O
specialized O
loss O
functions O
for O
training Task
. O
Pixel Task
- Task
level Task
labeling Task
tasks Task
fall O
into O
the O
category O
of O
structured Task
output Task
prediction Task
, O
where O
the O
model O
outputs O
a O
structured O
object O
( O
e.g. O
, O
a O
whole O
image O
parse O
) O
rather O
than O
a O
scalar O
or O
categorical O
variable O
. O
However O
, O
most O
CNN Method
pixel Method
- Method
labeling Method
architectures Method
are O
simply O
trained O
with O
loss Method
functions Method
that O
decompose O
into O
a O
simple O
( O
weighted Method
) Method
sum Method
of Method
classification Method
or Method
regression Method
losses Method
over O
individual O
pixel O
labels O
. O
The O
need O
to O
address O
the O
output O
space O
structure O
is O
more O
apparent O
when O
considering O
problems O
where O
the O
set O
of O
output O
labels O
is O
n’t O
fixed O
. O
Our O
motivating O
example O
is O
object Task
instance Task
segmentation Task
, O
where O
the O
model O
generates O
a O
collection O
of O
segments O
corresponding O
to O
object O
instances O
. O
This O
problem O
ca O
n’t O
be O
treated O
as O
k Task
- Task
way Task
classification Task
since O
the O
number O
of O
objects O
is O
n’t O
known O
in O
advance O
. O
Further O
, O
the O
loss O
should O
be O
invariant O
to O
permutations O
of O
the O
instance O
labels O
within O
the O
same O
semantic O
category O
. O
As O
a O
result O
, O
most O
recent O
successful O
approaches O
to O
instance Task
segmentation Task
have O
adopted O
more O
heuristic Method
approaches Method
that O
first O
use O
an O
object Method
detector Method
to O
enumerate O
candidate O
instances O
and O
then O
perform O
pixel Method
- Method
level Method
segmentation Method
of O
each O
instance O
. O
Alternately O
one O
can O
generate O
generic Method
proposal Method
segments Method
and O
then O
label O
each O
one O
with O
a O
semantic Method
detector Method
. O
In O
either O
case O
the O
detection Task
and Task
segmentation Task
steps Task
can O
both O
be O
mapped O
to O
standard O
binary Method
classification Method
losses Method
. O
While O
effective O
, O
these O
approaches O
are O
somewhat O
unsatisfying O
since O
: O
( O
1 O
) O
they O
rely O
on O
the O
object Method
detector Method
and O
non Method
- Method
maximum Method
suppression Method
heuristics Method
to O
accurately O
“ O
count O
” O
the O
number O
of O
instances O
, O
( O
2 O
) O
they O
are O
difficult O
to O
train O
in O
an O
end O
- O
to O
- O
end O
manner O
since O
the O
interface O
between O
instance Method
segmentation Method
and O
detection Task
is O
non O
- O
differentiable O
, O
and O
( O
3 O
) O
they O
underperform O
in O
cluttered O
scenes O
as O
the O
assignment O
of O
pixels O
to O
detections O
is O
carried O
out O
independently O
for O
each O
detection Task
. O
Here O
we O
propose O
to O
directly O
tackle O
the O
instance Task
grouping Task
problem Task
in O
a O
unified Method
architecture Method
by O
training O
a O
model O
that O
labels O
pixels O
with O
unit O
- O
length O
vectors O
that O
live O
in O
some O
fixed O
- O
dimension O
embedding O
space O
( O
Fig O
. O
[ O
reference O
] O
) O
. O
Unlike O
k Method
- Method
way Method
classification Method
where O
the O
target O
vectors O
for O
each O
pixel O
are O
specified O
in O
advance O
( O
i.e. O
, O
one O
- O
hot O
vectors O
at O
the O
vertices O
of O
a O
k O
- O
1 O
dimensional O
simplex O
) O
we O
allow O
each O
instance O
to O
be O
labeled O
with O
an O
arbitrary O
embedding O
vector O
on O
the O
sphere O
. O
Our O
loss Method
function Method
simply O
enforces O
the O
constraint O
that O
the O
embedding O
vectors O
used O
to O
label O
different O
instances O
are O
far O
apart O
. O
Since O
neither O
the O
number O
of O
labels O
, O
nor O
the O
target O
label O
vectors O
are O
specified O
in O
advance O
, O
we O
ca O
n’t O
use O
standard O
soft Method
- Method
max Method
thresholding Method
to O
produce O
a O
discrete Task
labeling Task
. O
Instead O
, O
we O
utilize O
a O
variant O
of O
mean Method
- Method
shift Method
clustering Method
which O
can O
be O
viewed O
as O
a O
recurrent Method
network Method
whose O
fixed O
point O
identifies O
a O
small O
, O
discrete O
set O
of O
instance O
label O
vectors O
and O
concurrently O
labels O
each O
pixel O
with O
one O
of O
the O
vectors O
from O
this O
set O
. O
This O
framework O
is O
largely O
agnostic O
to O
the O
underlying O
CNN Method
architecture Method
and O
can O
be O
applied O
to O
a O
range O
of O
low Task
, Task
mid Task
and Task
high Task
level Task
visual Task
tasks Task
. O
Specifically O
, O
we O
carry O
out O
experiments O
showing O
how O
this O
method O
can O
be O
used O
for O
boundary Task
detection Task
, O
object Task
proposal Task
generation Task
and O
semantic Task
instance Task
segmentation Task
. O
Even O
when O
a O
task O
can O
be O
modeled O
by O
a O
binary Task
pixel Task
classification Task
loss Task
( O
e.g. O
, O
boundary Task
detection Task
) O
we O
find O
that O
the O
grouping Method
loss Method
guides O
the O
model O
towards O
higher O
- O
quality O
feature Method
representations Method
that O
yield O
superior O
performance O
to O
classification Method
loss Method
alone O
. O
The O
model O
really O
shines O
for O
instance Task
segmentation Task
, O
where O
we O
demonstrate O
a O
substantial O
boost O
in O
object Task
proposal Task
generation Task
( O
improving O
the O
state O
- O
of O
- O
the O
- O
art O
average Metric
recall Metric
for O
10 O
proposals O
per O
image O
from O
0.56 O
to O
0.77 O
) O
. O
To O
summarize O
our O
contributions O
: O
( O
1 O
) O
we O
introduce O
a O
simple O
, O
easily O
interpreted O
end Method
- Method
to Method
- Method
end Method
model Method
for O
pixel Task
- Task
level Task
instance Task
labeling Task
which O
is O
widely O
applicable O
and O
highly O
effective O
, O
( O
2 O
) O
we O
provide O
theoretical O
analysis O
that O
offers O
guidelines O
on O
setting O
hyperparameters O
, O
and O
( O
3 O
) O
benchmark O
results O
show O
substantial O
improvements O
over O
existing O
approaches O
. O
section O
: O
Related O
Work O
Common O
approaches O
to O
instance Task
segmentation Task
first O
generate O
region O
proposals O
or O
class O
- O
agnostic O
bounding O
boxes O
, O
segment O
the O
foreground O
objects O
within O
each O
proposal O
and O
classify O
the O
objects O
in O
the O
bounding O
box O
. O
introduce O
a O
fully Method
convolutional Method
approach Method
that O
includes O
bounding Method
box Method
proposal Method
generation Method
in O
end Task
- Task
to Task
- Task
end Task
training Task
. O
Recently O
, O
“ O
box Method
- Method
free Method
” Method
methods Method
avoid O
some O
limitations O
of O
box Method
proposals Method
( O
e.g. O
for O
wiry O
or O
articulated O
objects O
) O
. O
They O
commonly O
use O
Faster O
RCNN Method
to O
produce O
“ O
centeredness O
” O
score O
on O
each O
pixel O
and O
then O
predict O
binary O
instance O
masks O
and O
class O
labels O
. O
Other O
approaches O
have O
been O
explored O
for O
modeling O
joint Task
segmentation Task
and Task
instance Task
labeling Task
jointly Task
in O
a O
combinatorial Method
framework Method
( O
e.g. O
, O
) O
but O
typically O
do O
n’t O
address O
end Task
- Task
to Task
- Task
end Task
learning Task
. O
Alternately O
, O
recurrent Method
models Method
that O
sequentially O
produce O
a O
list O
of O
instances O
offer O
another O
approach O
to O
address O
variable O
sized O
output O
structures O
in O
a O
unified O
manner O
. O
The O
most O
closely O
related O
to O
ours O
is O
the O
associative Method
embedding Method
work O
of O
, O
which O
demonstrated O
strong O
results O
for O
grouping Task
multi Task
- Task
person Task
keypoints Task
, O
and O
unpublished O
work O
from O
on O
metric Method
learning Method
for O
instance Task
segmentation Task
. O
Our O
approach O
extends O
on O
these O
ideas O
substantially O
by O
integrating O
recurrent Method
mean Method
- Method
shift Method
to O
directly O
generate O
the O
final O
instances O
( O
rather O
than O
heuristic Method
decoding Method
or O
thresholding O
distance O
to O
seed O
proposals O
) O
. O
There O
is O
also O
an O
important O
and O
interesting O
connection O
to O
work O
that O
has O
used O
embedding O
to O
separate O
instances O
where O
the O
embedding O
is O
directly O
learned O
using O
a O
supervised Method
regression Method
loss Method
rather O
than O
a O
pairwise Method
associative Method
loss Method
. O
train O
a O
regressor Method
that O
predicts O
the O
distance O
to O
the O
contour O
centerline O
for O
boundary Task
detection Task
, O
while O
predict O
the O
distance O
transform O
of O
the O
instance O
masks O
which O
is O
then O
post O
- O
processed O
with O
watershed Method
transform Method
to O
generate O
segments O
. O
predict O
an O
embedding O
based O
on O
scene O
depth O
and O
direction O
towards O
the O
instance O
center O
( O
like O
Hough Method
voting Method
) O
. O
Finally O
, O
we O
note O
that O
these O
ideas O
are O
related O
to O
work O
on O
using O
embedding Task
for O
solving O
pairwise Task
clustering Task
problems Task
. O
For O
example O
, O
normalized O
cuts O
clusters O
embedding O
vectors O
given O
by O
the O
eigenvectors O
of O
the O
normalized Method
graph Method
Laplacian O
and O
the O
spatial O
gradient O
of O
these O
embedding O
vectors O
was O
used O
in O
as O
a O
feature O
for O
boundary Task
detection Task
. O
Rather O
than O
learning O
pairwise O
similarity O
from O
data O
and O
then O
embedding O
prior O
to O
clustering Task
( O
e.g. O
, O
) O
, O
we O
use O
a O
pairwise O
loss O
but O
learn O
the O
embedding O
directly O
. O
Our O
recurrent Method
mean Method
- Method
shift Method
grouping O
is O
reminiscent O
of O
other O
efforts O
that O
use O
unrolled Method
implementations Method
of Method
iterative Method
algorithms Method
such O
as O
CRF Method
inference Method
or O
bilateral Method
filtering Method
. O
Unlike O
general O
RNNs Method
which O
are O
often O
difficult O
to O
train O
, O
our O
recurrent Method
model Method
has O
fixed O
parameters O
that O
assure O
interpretable O
convergent O
dynamics O
and O
meaningful O
gradients O
during O
learning Task
. O
section O
: O
Pairwise Metric
Loss Metric
for O
Pixel Task
Embeddings Task
In O
this O
section O
we O
introduce O
and O
analyze O
the O
loss Metric
we O
use O
for O
learning Task
pixel Task
embeddings Task
. O
This O
problem O
is O
broadly O
related O
to O
supervised Task
distance Task
metric Task
learning Task
and O
clustering Task
but O
adapted O
to O
the O
specifics O
of O
instance Task
labeling Task
where O
the O
embedding O
vectors O
are O
treated O
as O
labels O
for O
a O
variable O
number O
of O
objects O
in O
each O
image O
. O
Our O
goal O
is O
to O
learn O
a O
mapping O
from O
an O
input O
image O
to O
a O
set O
of O
- O
dimensional O
embedding O
vectors O
( O
one O
for O
each O
pixel O
) O
. O
Let O
be O
the O
embeddings O
of O
pixels O
and O
respectively O
with O
corresponding O
labels O
and O
that O
denote O
ground O
- O
truth O
instance O
- O
level O
semantic O
labels O
( O
e.g. O
, O
car.1 O
and O
car.2 O
) O
. O
We O
will O
measure O
the O
similarity O
of O
the O
embedding O
vectors O
using O
the O
cosine O
similarity O
, O
been O
scaled O
and O
offset O
to O
lie O
in O
the O
interval O
for O
notational O
convenience O
: O
In O
the O
discussion O
that O
follows O
we O
think O
of O
the O
similarity O
in O
terms O
of O
the O
inner O
product O
between O
the O
projected O
embedding O
vectors O
( O
e.g. O
, O
) O
which O
live O
on O
the O
surface O
of O
a O
dimensional O
sphere O
. O
Other O
common O
similarity Metric
metrics Metric
utilize O
Euclidean O
distance O
with O
a O
squared O
exponential O
kernel O
or O
sigmoid Method
function Method
. O
We O
prefer O
the O
cosine O
metric O
since O
it O
is O
invariant O
to O
the O
scale O
of O
the O
embedding O
vectors O
, O
decoupling O
the O
loss O
from O
model Method
design Method
choices Method
such O
as O
weight Method
decay Method
or O
regularization Method
that O
limit O
the O
dynamic O
range O
of O
Euclidean O
distances O
. O
Our O
goal O
is O
to O
learn O
an O
embedding O
so O
that O
pixels O
with O
the O
same O
label O
( O
positive O
pairs O
with O
) O
have O
the O
same O
embedding O
( O
i.e. O
) O
. O
To O
avoid O
a O
trivial O
solution O
where O
all O
the O
embedding O
vectors O
are O
the O
same O
, O
we O
impose O
the O
additional O
constraint O
that O
pairs O
from O
different O
instances O
( O
negative O
pairs O
with O
) O
are O
placed O
far O
apart O
. O
To O
provide O
additional O
flexibility O
, O
we O
include O
a O
weight O
in O
the O
definition O
of O
the O
loss O
which O
specifies O
the O
importance O
of O
a O
given O
pixel O
. O
The O
total O
loss O
over O
all O
pairs O
and O
training O
images O
is O
: O
where O
is O
the O
number O
of O
pixels O
in O
the O
- O
th O
image O
( O
images O
in O
total O
) O
, O
and O
is O
the O
pixel O
pair O
weight O
associated O
with O
pixel O
in O
image O
. O
The O
hyper O
- O
parameter O
controls O
the O
maximum O
margin O
for O
negative O
pairs O
of O
pixels O
, O
incurring O
a O
penalty O
if O
the O
embeddings O
for O
pixels O
belonging O
to O
the O
same O
group O
have O
an O
angular O
separation O
of O
less O
than O
. O
Positive O
pairs O
pay O
a O
penalty O
if O
they O
have O
a O
similarity O
less O
than O
. O
Fig O
. O
[ O
reference O
] O
shows O
a O
graph O
of O
the O
loss O
function O
. O
argue O
that O
the O
constant O
slope O
of O
the O
margin O
loss O
is O
more O
robust O
, O
e.g. O
, O
than O
squared O
loss O
. O
We O
carry O
out O
a O
simple O
theoretical O
analysis O
which O
provides O
a O
guide O
for O
setting O
the O
weights O
and O
margin O
hyperparameter O
in O
the O
loss O
function O
. O
Proofs O
can O
be O
found O
in O
the O
appendix O
. O
subsection O
: O
Instance Method
- Method
aware Method
Pixel Method
Weighting Method
We O
first O
examine O
the O
role O
of O
embedding O
dimension O
and O
instance O
size O
on O
the O
training Metric
loss Metric
. O
theorem O
: O
For O
n O
vectors O
{ O
x1 O
, O
… O
, O
xn O
} O
, O
the O
total O
intra Metric
- Metric
pixel Metric
similarity Metric
is O
bounded O
as O
≥∑≠ij⁢xiTxj O
- O
∑=i1n∥xi∥22 O
. O
In O
particular O
, O
for O
n O
vectors O
on O
the O
hypersphere O
where O
= O
∥xi∥21 O
, O
we O
have O
≥∑≠ij⁢xiTxj O
- O
n O
. O
This O
proposition O
indicates O
that O
the O
total Metric
cosine Metric
similarity Metric
( O
and O
hence O
the O
loss Metric
) O
for O
a O
set O
of O
embedding O
vectors O
has O
a O
constant O
lower Metric
bound Metric
that O
does O
not O
depend O
on O
the O
dimension O
of O
the O
embedding O
space O
( O
a O
feature O
lacking O
in O
Euclidean O
embeddings O
) O
. O
In O
particular O
, O
this O
type O
of O
analysis O
suggests O
a O
natural O
choice O
of O
pixel Task
weighting Task
. O
Suppose O
a O
training O
example O
contains O
instances O
and O
denotes O
the O
set O
of O
pixels O
belonging O
to O
a O
particular O
ground O
- O
truth O
instance O
. O
We O
can O
write O
where O
the O
first O
term O
on O
the O
r.h.s O
. O
corresponds O
to O
contributions O
to O
the O
loss O
function O
for O
positive O
pairs O
while O
the O
second O
corresponds O
to O
contributions O
from O
negative O
pairs O
. O
Setting O
for O
pixels O
belonging O
to O
ground O
- O
truth O
instance O
assures O
that O
each O
instance O
contributes O
equally O
to O
the O
loss O
independent O
of O
size O
. O
Furthermore O
, O
when O
the O
embedding O
dimension O
, O
we O
can O
simply O
embed O
the O
data O
so O
that O
the O
instance O
means O
are O
along O
orthogonal O
axes O
on O
the O
sphere O
. O
This O
zeros O
out O
the O
second O
term O
on O
the O
r.h.s O
. O
, O
leaving O
only O
the O
first O
term O
which O
is O
bounded O
, O
and O
translates O
to O
corresponding O
upper O
and O
lower O
bounds O
on O
the O
loss Metric
that O
are O
independent O
of O
the O
number O
of O
pixels O
and O
embedding O
dimension O
( O
so O
long O
as O
) O
. O
Pairwise Method
weighting Method
schemes Method
have O
been O
shown O
important O
empirically O
and O
class O
imbalance O
can O
have O
a O
substantial O
effect O
on O
the O
performance O
of O
different O
architectures O
( O
see O
e.g. O
, O
) O
. O
While O
other O
work O
has O
advocated O
online Method
bootstrapping Method
methods Method
for O
hard Task
- Task
pixel Task
mining Task
or O
mini Task
- Task
batch Task
selection Task
, O
our O
approach O
is O
much O
simpler O
. O
Guided O
by O
this O
result O
we O
simply O
use O
uniform Method
random Method
sampling Method
of Method
pixels Method
during O
training O
, O
appropriately O
weighted O
by O
instance O
size O
in O
order O
to O
estimate O
the O
loss O
. O
subsection O
: O
Margin Task
Selection Task
To O
analyze O
the O
appropriate O
margin O
, O
let O
’s O
first O
consider O
the O
problem O
of O
distributing O
labels O
for O
different O
instances O
as O
far O
apart O
as O
possible O
on O
a O
3D O
sphere O
, O
sometimes O
referred O
to O
as O
Tammes Task
’s Task
problem Task
, O
or O
the O
hard Task
- Task
spheres Task
problem Task
. O
This O
can O
be O
formalized O
as O
maximizing O
the O
smallest O
distance O
among O
points O
on O
a O
sphere O
: O
. O
Asymptotic O
results O
in O
provide O
the O
following O
proposition O
( O
see O
proof O
in O
the O
appendix O
) O
: O
theorem O
: O
Given O
N O
vectors O
{ O
x1 O
, O
… O
, O
xn O
} O
on O
a O
2 O
- O
sphere O
, O
i.e. O
∈xiR3 O
, O
= O
∥xi∥21 O
, O
=∀i⁢1 O
… O
n O
, O
choosing O
≤α O
- O
1 O
( O
⁢2π⁢3N O
) O
, O
guarantees O
that O
≥ O
[- O
s⁢ijα O
]+ O
0 O
for O
some O
pair O
≠ij O
. O
Choosing O
> O
α O
- O
1⁢14 O
(-( O
⁢8π⁢3N O
) O
12⁢CN O
- O
23 O
) O
2 O
, O
guarantees O
the O
existence O
of O
an O
embedding O
with O
= O
[ O
- O
s⁢ijα O
]+ O
0 O
for O
all O
pairs O
≠ij O
. O
Proposition O
[ O
reference O
] O
gives O
the O
maximum O
margin O
for O
a O
separation O
of O
groups O
of O
pixels O
in O
a O
three O
dimensional O
embedding O
space O
( O
sphere O
) O
. O
For O
example O
, O
if O
an O
image O
has O
at O
most O
instances O
, O
can O
be O
set O
as O
small O
as O
, O
respectively O
. O
For O
points O
in O
a O
higher O
dimension O
embedding O
space O
, O
it O
is O
a O
non O
- O
trivial O
problem O
to O
establish O
a O
tight O
analytic O
bound O
for O
the O
margin O
. O
Despite O
its O
simple O
description O
, O
distributing O
points O
on O
a O
- O
dimensional O
hypersphere O
is O
considered O
a O
serious O
mathematical O
challenge O
for O
which O
there O
is O
no O
general O
solutions O
. O
We O
adopt O
a O
safe O
( O
trivial O
) O
strategy O
. O
For O
instances O
embedded O
in O
dimensions O
one O
can O
use O
value O
of O
which O
allows O
for O
zero O
loss O
by O
placing O
a O
pair O
of O
groups O
antipodally O
along O
each O
of O
the O
orthogonal O
axes O
. O
We O
adopt O
this O
setting O
for O
the O
majority O
of O
experiments O
in O
the O
paper O
where O
the O
embedding Metric
dimension Metric
is O
set O
to O
. O
section O
: O
Recurrent Method
Mean Method
- Method
Shift Method
Grouping Method
While O
we O
can O
directly O
train O
a O
model O
to O
predict O
embeddings Task
as O
described O
in O
the O
previous O
section O
, O
it O
is O
not O
clear O
how O
to O
generate O
the O
final O
instance Task
segmentation Task
from O
the O
resulting O
( O
imperfect O
) O
embeddings O
. O
One O
can O
utilize O
heuristic Method
post Method
- Method
processing Method
or O
utilize O
clustering Method
algorithms Method
that O
estimate O
the O
number O
of O
instances O
, O
but O
these O
are O
not O
differentiable O
and O
thus O
unsatisfying O
. O
Instead O
, O
we O
introduce O
a O
mean Method
- Method
shift Method
grouping Method
model Method
( O
Fig O
. O
[ O
reference O
] O
) O
which O
operates O
recurrently O
on O
the O
embedding O
space O
in O
order O
to O
congeal O
the O
embedding O
vectors O
into O
a O
small O
number O
of O
instance O
labels O
. O
Mean Method
- Method
shift Method
and O
closely O
related O
algorithms O
use O
kernel Method
density Method
estimation Method
to O
approximate O
the O
probability O
density O
from O
a O
set O
of O
samples O
and O
then O
perform O
clustering Method
on O
the O
input O
data O
by O
assigning O
or O
moving O
each O
sample O
to O
the O
nearest O
mode O
( O
local O
maxima O
) O
. O
From O
our O
perspective O
, O
the O
advantages O
of O
this O
approach O
are O
( O
1 O
) O
the O
final O
instance O
labels O
( O
modes O
) O
live O
in O
the O
same O
embedding O
space O
as O
the O
initial O
data O
, O
( O
2 O
) O
the O
recurrent Method
dynamics Method
of O
the O
clustering Method
process Method
depend O
smoothing O
on O
the O
input O
allowing O
for O
easy O
backpropagation Method
, O
( O
3 O
) O
the O
behavior O
depends O
on O
a O
single O
parameter O
, O
the O
kernel O
bandwidth O
, O
which O
is O
easily O
interpretable O
and O
can O
be O
related O
to O
the O
margin O
used O
for O
the O
embedding O
loss O
. O
subsection O
: O
Mean Method
Shift Method
Clustering Method
A O
common O
choice O
for O
non Task
- Task
parametric Task
density Task
estimation Task
is O
to O
use O
the O
isotropic Method
multivariate Method
normal Method
kernel Method
and O
approximate O
the O
data O
density O
non O
- O
parametrically O
as O
. O
Since O
our O
embedding O
vectors O
are O
unit O
norm O
, O
we O
instead O
use O
the O
von Method
Mises Method
- Method
Fisher Method
distribution Method
which O
is O
the O
natural O
extension O
of O
the O
multivariate O
normal O
to O
the O
hypersphere O
, O
and O
is O
given O
by O
. O
The O
kernel O
bandwidth O
, O
determines O
the O
smoothness O
of O
the O
kernel Method
density Method
estimate Method
and O
is O
closely O
related O
to O
the O
margin O
used O
for O
learning Task
the Task
embedding Task
space Task
. O
While O
it O
is O
straightforward O
to O
learn O
during O
training Task
, O
we O
instead O
set O
it O
to O
satisfy O
throughout O
our O
experiments O
, O
such O
that O
the O
cluster O
separation O
( O
margin O
) O
in O
the O
learned O
embedding O
space O
is O
three O
standard O
deviations O
. O
We O
formulate O
the O
mean Method
shift Method
algorithm Method
in O
a O
matrix Method
form Method
. O
Let O
denote O
the O
stacked O
pixel O
embedding O
vectors O
of O
an O
image O
. O
The O
kernel O
matrix O
is O
given O
by O
. O
Let O
denote O
the O
diagonal O
matrix O
of O
total O
affinities O
, O
referred O
to O
as O
the O
degree O
when O
is O
viewed O
as O
a O
weighted O
graph O
adjacency O
matrix O
. O
At O
each O
iteration O
, O
we O
compute O
the O
mean O
shift O
, O
which O
is O
the O
difference O
vector O
between O
and O
the O
kernel Method
weighted Method
average Method
of O
. O
We O
then O
modify O
the O
embedding O
vectors O
by O
moving O
them O
in O
the O
mean O
shift O
direction O
with O
step O
size O
: O
Note O
that O
unlike O
standard O
mean Method
- Method
shift Method
mode Method
finding Method
, O
we O
recompute O
at O
each O
iteration O
. O
These O
update Method
dynamics Method
are O
termed O
the O
explicit Method
- Method
method Method
and O
were O
analyzed O
by O
. O
When O
and O
the O
kernel O
is O
Gaussian O
, O
this O
is O
also O
referred O
to O
as O
Gaussian Method
Blurring Method
Mean Method
Shift Method
( O
GBMS Method
) O
and O
has O
been O
shown O
to O
have O
cubic O
convergence Metric
under O
appropriate O
conditions O
. O
Unlike O
deep Method
RNNs Method
, O
the O
parameters O
of O
our O
recurrent Method
module Method
are O
not O
learned O
and O
the O
forward Method
dynamics Method
are O
convergent O
under O
general O
conditions O
. O
In O
practice O
, O
we O
do O
not O
observe O
issues O
with O
exploding O
or O
vanishing O
gradients O
during O
back Method
- Method
propagation Method
through O
a O
finite O
number O
of O
iterations O
. O
Fig O
. O
[ O
reference O
] O
demonstrates O
a O
toy O
example O
of O
applying O
the O
method O
to O
perform O
digit Task
instance Task
segmentation Task
on O
synthetic O
images O
from O
MNIST Material
. O
We O
learn O
3 Method
- Method
dimensional Method
embedding Method
in O
order O
to O
visualize O
the O
results O
before O
and O
after O
the O
mean Method
shift Method
grouping Method
module Method
. O
From O
the O
figure O
, O
we O
can O
see O
the O
mean Method
shift Method
grouping Method
transforms O
the O
initial O
embedding O
vectors O
to O
yield O
a O
small O
set O
of O
instance O
labels O
which O
are O
distinct O
( O
for O
negative O
pairs O
) O
and O
compact O
( O
for O
positive O
pairs O
) O
. O
subsection O
: O
End Task
- Task
to Task
- Task
end Task
training Task
It O
’s O
straightforward O
to O
compute O
the O
derivatives O
of O
the O
recurrent Method
mean Method
shift Method
grouping O
module O
w.r.t O
based O
on O
the O
the O
chain Method
rule Method
so O
our O
whole O
system O
is O
end O
- O
to O
- O
end O
trainable O
through O
back Method
- Method
propagation Method
. O
Details O
about O
the O
derivative Task
computation Task
can O
be O
found O
in O
the O
appendix O
. O
To O
understand O
the O
benefit O
of O
end Task
- Task
to Task
- Task
end Task
training Task
, O
we O
visualize O
the O
embedding O
gradient O
with O
and O
without O
the O
grouping Method
module Method
( O
Fig O
. O
[ O
reference O
] O
) O
. O
Interestingly O
, O
we O
observe O
that O
the O
gradient O
backpropagated O
through O
mean Method
shift Method
focuses O
on O
fixing O
the O
embedding O
in O
uncertain O
regions O
, O
e.g. O
instance O
boundaries O
, O
while O
suggesting O
small O
magnitude O
updates O
for O
those O
errors O
which O
will O
be O
easily O
fixed O
by O
the O
mean Method
- Method
shift Method
iteration Method
. O
While O
we O
could O
simply O
apply O
the O
pairwise O
embedding O
loss O
to O
the O
final O
output O
of O
the O
mean Method
- Method
shift Method
grouping Method
, O
in O
practice O
we O
accumulate O
the O
loss O
over O
all O
iterations O
( O
including O
the O
initial O
embedding Method
regression Method
) O
. O
We O
unroll O
the O
recurrent Method
grouping Method
module Method
into O
loops O
, O
and O
accumulate O
the O
same O
loss O
function O
at O
the O
unrolled O
loop O
- O
: O
section O
: O
Experiments O
We O
now O
describe O
experiments O
in O
training O
our O
framework O
to O
deal O
a O
variety O
of O
pixel Task
- Task
labeling Task
problems Task
, O
including O
boundary Task
detection Task
, O
object Task
proposal Task
detection Task
, O
semantic Task
segmentation Task
and O
instance Task
- Task
level Task
semantic Task
segmentation Task
. O
subsection O
: O
Tasks O
, O
Datasets O
and O
Implementation O
We O
illustrate O
the O
advantages O
of O
the O
proposed O
modules O
on O
several O
large O
- O
scale O
datasets O
. O
First O
, O
to O
illustrate O
the O
ability O
of O
the O
instance Method
- Method
aware Method
weighting Method
and Method
uniform Method
sampling Method
mechanism Method
to O
handle O
imbalanced O
data O
and O
low O
embedding O
dimension O
, O
we O
use O
the O
BSDS500 Material
dataset Material
to O
train O
a O
boundary Method
detector Method
for O
boundary Task
detection Task
( O
pixels O
are O
non O
- O
boundary O
pixels O
) O
. O
We O
train O
with O
the O
standard O
split O
, O
using O
300 O
train O
- O
val O
images O
to O
train O
our O
model O
based O
on O
ResNet50 Method
and O
evaluate O
on O
the O
remaining O
200 O
test O
images O
. O
Second O
, O
to O
explore O
instance Task
segmentation Task
and O
object Task
proposal Task
generation Task
, O
we O
use O
PASCAL Material
VOC Material
2012 Material
dataset Material
with O
additional O
instance O
mask O
annotations O
provided O
by O
. O
This O
provides O
10 O
, O
582 O
and O
1 O
, O
449 O
images O
for O
training O
and O
evaluation Task
, O
respectively O
. O
We O
implement O
our O
approach O
using O
the O
toolbox O
MatConvNet Method
, O
and O
train O
using O
SGD Method
on O
a O
single O
Titan O
X O
GPU O
. O
. O
To O
compute O
calibrated O
cosine O
similarity O
, O
we O
utilize O
an O
L2 Method
- Method
normalization Method
layer Method
before O
matrix Method
multiplication Method
, O
which O
also O
contains O
random Method
sampling Method
with O
a O
hyper O
- O
parameter O
to O
control O
the O
ratio O
of O
pixels O
to O
be O
sampled O
for O
an O
image O
. O
In O
practice O
, O
we O
observe O
that O
performance O
does O
not O
depend O
strongly O
on O
this O
ratio O
and O
hence O
set O
it O
based O
on O
available O
( O
GPU O
) O
memory O
. O
While O
our O
modules O
are O
architecture O
agnostic O
, O
we O
use O
the O
ResNet50 Method
and O
ResNet101 Method
models Method
pre O
- O
trained O
over O
ImageNet Material
as O
the O
backbone O
. O
Similar O
to O
, O
we O
increase O
the O
output Metric
resolution Metric
of O
ResNet Method
by O
removing O
the O
top O
global O
pooling O
layer O
and O
the O
last O
two O
pooling Method
layers Method
, O
replacing O
them O
with O
atrous Method
convolution Method
with O
dilation O
rate O
2 O
and O
4 O
, O
respectively O
to O
maintain O
a O
spatial O
sampling O
rate O
. O
Our O
model O
thus O
outputs O
predictions O
at O
the O
input O
resolution O
which O
are O
upsampled O
for O
benchmarking O
. O
We O
augment O
the O
training O
set O
using O
random O
scaling O
by O
, O
in O
- O
plane O
rotation O
by O
degrees O
, O
random O
left O
- O
right O
flips O
, O
random O
crops O
with O
20 O
- O
pixel O
margin O
and O
of O
size O
divisible O
by O
8 O
, O
and O
color O
jittering O
. O
When O
training O
the O
model O
, O
we O
fix O
the O
batch O
normalization O
in O
ResNet Method
backbone Method
, O
using O
the O
same O
constant O
global O
moments O
in O
both O
training O
and O
testing Task
. O
Throughout O
training Task
, O
we O
set O
batch O
size O
to O
one O
where O
the O
batch O
is O
a O
single O
input O
image O
. O
We O
use O
the O
“ O
poly Method
” Method
learning Method
rate Method
policy Method
with O
a O
base O
learning Metric
rate Metric
of O
scaled O
as O
a O
function O
of O
iteration O
by O
. O
subsection O
: O
Boundary Task
Detection Task
For O
boundary Task
detection Task
, O
we O
first O
train O
a O
model O
to O
group O
the O
pixels O
into O
boundary O
or O
non O
- O
boundary O
groups O
. O
Similar O
to O
COB Method
and O
HED Method
, O
we O
include O
multiple O
branches O
over O
ResBlock O
for O
training O
. O
Since O
the O
number O
of O
instances O
labels O
is O
2 O
, O
we O
learn O
a O
simple O
3 Method
- Method
dimensional Method
embedding Method
space Method
which O
has O
the O
advantage O
of O
easy O
visualization Task
as O
an O
RGB Material
image Material
. O
Fig O
. O
[ O
reference O
] O
shows O
the O
resulting O
embeddings O
in O
the O
first O
row O
of O
each O
panel O
. O
Note O
that O
even O
though O
we O
did O
n’t O
utilize O
mean Method
- Method
shift Method
grouping Method
, O
the O
trained O
embedding Method
already O
produces O
compact O
clusters O
. O
To O
compare O
quantitatively O
to O
the O
state O
- O
of O
- O
the O
- O
art O
, O
we O
learn O
a O
fusion Method
layer Method
that O
combines O
predictions O
from O
multiple O
levels O
of O
the O
feature O
hierarchy O
fine O
- O
tuned O
with O
a O
logistic Method
loss Method
to O
match O
the O
binary O
output O
. O
Fig O
. O
[ O
reference O
] O
shows O
the O
results O
in O
the O
second O
row O
. O
Interestingly O
, O
we O
can O
see O
that O
the O
fine Method
- Method
tuned Method
model Method
embeddings Method
encode O
not O
only O
boundary O
presence O
/ O
absence O
but O
also O
the O
orientation O
and O
signed O
distance O
to O
nearby O
boundaries O
. O
Quantitatively O
, O
we O
compare O
our O
model O
to O
COB Method
, O
HED Method
, O
CEDN Method
, O
LEP Method
, O
UCM Method
, O
ISCRA Method
, O
NCuts Method
, O
EGB Method
, O
and O
the O
original Method
mean Method
shift Method
( Method
MShift Method
) Method
segmentation Method
algorithm Method
. O
Fig O
. O
[ O
reference O
] O
shows O
standard O
benchmark O
precision Metric
- Metric
recall Metric
for O
all O
the O
methods O
, O
demonstrating O
our O
model O
achieves O
state O
- O
of O
- O
the O
- O
art O
performance O
. O
Note O
that O
our O
model O
has O
the O
same O
architecture O
of O
COB Method
except O
with O
a O
different O
loss O
functions O
and O
no O
explicit O
branches O
to O
compute O
boundary O
orientation O
. O
Our O
embedding O
loss O
by O
naturally O
pushes O
boundary O
pixel O
embeddings O
to O
be O
similar O
which O
is O
also O
the O
desirable O
property O
for O
detecting Task
boundaries Task
using O
logistic Method
loss Method
. O
Note O
that O
it O
is O
possible O
to O
surpass O
human O
performance O
with O
several O
sophisticated O
techniques O
, O
we O
do O
n’t O
pursue O
this O
as O
it O
is O
out O
the O
scope O
of O
this O
paper O
. O
subsection O
: O
Object Task
Proposal Task
Detection Task
Object Method
proposals Method
are O
an O
integral O
part O
of O
current O
object Method
detection Method
and Method
semantic Method
segmentation Method
pipelines Method
, O
as O
they O
provide O
a O
reduced O
search O
space O
of O
locations O
, O
scales O
and O
shapes O
for O
subsequent O
recognition Task
. O
State O
- O
of O
- O
the O
- O
art O
methods O
usually O
involve O
training Method
models Method
that O
output O
large O
numbers O
of O
proposals O
, O
particularly O
those O
based O
on O
bounding O
boxes O
. O
Here O
we O
demonstrate O
that O
by O
training O
our O
framework O
with O
64 Method
- Method
dimensional Method
embedding Method
space Method
on O
the O
object O
instance O
level O
annotations O
, O
we O
are O
able O
to O
produce O
very O
high O
quality O
object O
proposals O
by O
grouping O
the O
pixels O
into O
instances O
. O
It O
is O
worth O
noting O
that O
due O
to O
the O
nature O
of O
our O
grouping Method
module Method
, O
far O
fewer O
number O
of O
proposals O
are O
produced O
with O
much O
higher O
quality O
. O
We O
compare O
against O
the O
most O
recent O
techniques O
including O
POISE Method
, O
LPO Method
, O
CPMC Method
, O
GOP Method
, O
SeSe Method
, O
GLS Method
, O
RIGOR Method
. O
Fig O
. O
[ O
reference O
] O
shows O
the O
Average Metric
Recall Metric
( O
AR Metric
) O
with O
respect O
to O
the O
number O
of O
object O
proposals O
. O
Our O
model O
performs O
remarkably O
well O
compared O
to O
other O
methods O
, O
achieving O
high O
average Metric
recall Metric
of O
ground Metric
- Metric
truth Metric
objects Metric
with O
two O
orders O
of O
magnitude O
fewer O
proposals O
. O
We O
also O
plot O
the O
curves O
for O
SharpMask O
and O
DeepMask O
using O
the O
proposals O
released O
by O
the O
authors O
. O
Despite O
only O
training O
on O
PASCAL Material
, O
we O
outperform O
these O
models O
which O
were O
trained O
on O
the O
much O
larger O
COCO Material
dataset O
. O
In O
Table O
[ O
reference O
] O
we O
report O
the O
total O
average Metric
recall Metric
at O
IoU Metric
for O
some O
recently O
proposed O
proposal Method
detection Method
methods Method
, O
including O
unpublished O
work O
inst O
- O
DML Method
which O
is O
similar O
in O
spirit O
to O
our O
model O
but O
learns O
a O
Euclidean Method
distance Method
based Method
metric Method
to O
group O
pixels O
. O
We O
can O
clearly O
see O
that O
our O
method O
achieves O
significantly O
better O
results O
than O
existing O
methods O
. O
plane O
bike O
bird O
boat O
bottle O
bus O
car O
cat O
chair O
cow O
table O
dog O
horse O
motor O
person O
plant O
sheep O
sofa O
train O
tv Metric
mean Metric
subsection O
: O
Semantic Task
Instance Task
Detection Task
As O
a O
final O
test O
of O
our O
method O
, O
we O
also O
train O
it O
to O
produce O
semantic O
labels O
which O
are O
combined O
with O
our O
instance Method
proposal Method
method Method
to O
recognize O
the O
detected O
proposals O
. O
For O
semantic Task
segmentation Task
which O
is O
a O
k Task
- Task
way Task
classification Task
problem Task
, O
we O
train O
a O
model O
using O
cross Method
- Method
entropy Method
loss Method
alongside O
our O
embedding Method
loss Method
. O
Similar O
to O
our O
proposal Method
detection Method
model Method
, O
we O
use O
a O
64 O
- O
dimension O
embedding O
space O
on O
top O
of O
DeepLab Method
- Method
v3 Method
as O
our O
base O
model O
. O
While O
there O
are O
more O
complex O
methods O
in O
literature O
such O
as O
PSPNet Method
and O
which O
augment O
training O
with O
additional O
data O
( O
e.g. O
, O
COCO Material
or O
JFT Material
- Material
300 Material
M Material
dataset Material
) O
and O
utilize O
ensembles Method
and O
post Method
- Method
processing Method
, O
we O
focus O
on O
a O
simple O
experiment O
training O
the O
base O
model O
with O
/ O
without O
the O
proposed O
pixel Method
pair Method
embedding Method
loss Method
to O
demonstrate O
the O
effectiveness O
. O
In O
addition O
to O
reporting O
mean Metric
intersection Metric
over Metric
union Metric
( O
mIoU Method
) O
over O
all O
classes O
, O
we O
also O
computed O
mIoU Method
restricted O
to O
a O
narrow O
band O
of O
pixels O
around O
the O
ground O
- O
truth O
boundaries O
. O
This O
partition O
into O
figure O
/ O
boundary O
/ O
background O
is O
sometimes O
referred O
to O
as O
a O
tri O
- O
map O
in O
the O
matting O
literature O
and O
has O
been O
previously O
utilized O
in O
analyzing O
semantic Task
segmentation Task
performance O
. O
Fig O
. O
[ O
reference O
] O
shows O
the O
mIoU Metric
as O
a O
function O
of O
the O
width O
of O
the O
tri O
- O
map O
boundary O
zone O
. O
This O
demonstrates O
that O
with O
embedding O
loss O
yields O
performance O
gains O
over O
cross Metric
- Metric
entropy Metric
primarily O
far O
from O
ground O
- O
truth O
boundaries O
where O
it O
successfully O
fills O
in O
holes O
in O
the O
segments O
output O
( O
see O
also O
qualitative O
results O
in O
Fig O
. O
[ O
reference O
] O
) O
. O
This O
is O
in O
spirit O
similar O
to O
the O
model O
in O
, O
which O
considers O
local O
consistency O
to O
improve O
spatial Metric
precision Metric
. O
However O
, O
our O
uniform Method
sampling Method
allows O
for O
long O
- O
range O
interactions O
between O
pixels O
. O
To O
label O
detected O
instances O
with O
semantic O
labels O
, O
we O
use O
the O
semantic Method
segmentation Method
model Method
described O
above O
to O
generate O
labels O
and O
then O
use O
a O
simple O
voting Method
strategy Method
to O
transfer O
these O
predictions O
to O
the O
instance O
proposals O
. O
In O
order O
to O
produce O
a O
final O
confidence Metric
score Metric
associated O
with O
each O
proposed O
object O
, O
we O
train O
a O
linear Method
regressor Method
to O
score O
each O
object O
instance O
based O
on O
its O
morphology O
( O
e.g. O
, O
size O
, O
connectedness O
) O
and O
the O
consistency Metric
w.r.t Metric
. O
the O
semantic Task
segmentation Task
prediction Task
. O
We O
note O
this O
is O
substantially O
simpler O
than O
approaches O
based O
, O
e.g. O
on O
Faster O
- O
RCNN Method
which O
use O
much O
richer O
convolutional O
features O
to O
rescore O
segmented O
instances O
. O
Comparison O
of O
instance Metric
detection Metric
performance O
are O
displayed O
in O
Table O
[ O
reference O
] O
. O
We O
use O
a O
standard O
IoU Metric
threshold Metric
of O
0.5 O
to O
identify O
true O
positives O
, O
unless O
an O
ground O
- O
truth O
instance O
has O
already O
been O
detected O
by O
a O
higher O
scoring O
proposal O
in O
which O
case O
it O
is O
a O
false O
positive O
. O
We O
report O
the O
average Metric
precision Metric
per O
- O
class O
as O
well O
as O
the O
average O
all O
classes O
( O
as O
in O
) O
. O
Our O
approach O
yields O
competitive O
performance O
on O
VOC Task
validation Task
despite O
our O
simple O
re Method
- Method
scoring Method
. O
Among O
the O
competing O
methods O
, O
the O
one O
closest O
to O
our O
model O
is O
inst Method
- Method
DML Method
, O
that O
learns O
Euclidean Metric
distance Metric
based Metric
metric Metric
with O
logistic Method
loss Method
. O
The O
inst Method
- Method
DML Method
approach Method
relies O
on O
generating O
pixel O
seeds O
to O
derive O
instance O
masks O
. O
The O
pixel O
seeds O
may O
fail O
to O
correctly O
detect O
thin O
structures O
which O
perhaps O
explains O
why O
this O
method O
performs O
10x O
worse O
than O
our O
method O
on O
the O
bike Task
category Task
. O
In O
contrast O
, O
our O
mean Method
- Method
shift Method
grouping Method
approach Method
does O
n’t O
make O
strong O
assumptions O
about O
the O
object O
shape O
or O
topology O
. O
For O
visualization Task
purposes Task
, O
we O
generate O
three O
random Method
matrices Method
projections Method
of Method
the Method
64 Method
- Method
dimensional Method
embedding Method
and O
display O
them O
in O
the O
spatial O
domain O
as O
RGB Material
images Material
. O
Fig O
. O
[ O
reference O
] O
shows O
the O
embedding Task
visualization Task
, O
as O
well O
as O
predicted Task
semantic Task
segmentation Task
and O
instance Task
- Task
level Task
segmentation Task
. O
From O
the O
visualization O
, O
we O
can O
see O
the O
instance O
- O
level O
semantic Task
segmentation Task
outputs O
complete O
object O
instances O
even O
though O
semantic Task
segmentation Task
results O
are O
noisy O
, O
such O
as O
the O
bike O
in O
the O
first O
image O
in O
Fig O
. O
[ O
reference O
] O
. O
The O
instance Method
embedding Method
provides O
important O
details O
that O
resolve O
both O
inter O
- O
and O
intra O
- O
class O
instance O
overlap O
which O
are O
not O
emphasized O
in O
the O
semantic Task
segmentation Task
loss Task
. O
section O
: O
Conclusion O
and O
Future O
Work O
We O
have O
presented O
an O
end O
- O
to O
- O
end Method
trainable Method
framework Method
for O
solving O
pixel Task
- Task
labeling Task
vision Task
problems Task
based O
on O
two O
novel O
contributions O
: O
a O
pixel Method
- Method
pairwise Method
loss Method
based O
on O
spherical Method
max Method
- Method
margin Method
embedding Method
and O
a O
variant O
of O
mean Method
shift Method
grouping Method
embedded O
in O
a O
recurrent Method
architecture Method
. O
These O
two O
components O
mesh O
closely O
to O
provide O
a O
framework O
for O
robustly Task
recognizing Task
variable Task
numbers Task
of Task
instances Task
without O
requiring O
heuristic Method
post Method
- Method
processing Method
or O
hyperparameter Method
tuning Method
to O
account O
for O
widely O
varying O
instance O
size O
or O
class O
- O
imbalance O
. O
The O
approach O
is O
simple O
and O
amenable O
to O
theoretical O
analysis O
, O
and O
when O
coupled O
with O
standard O
architectures O
yields O
instance Method
proposal Method
generation Method
which O
substantially O
outperforms O
state O
- O
of O
- O
the O
- O
art O
. O
Our O
experiments O
demonstrate O
the O
potential O
for O
instance Task
embedding Task
and O
open O
many O
opportunities O
for O
future O
work O
including O
learn O
- O
able O
variants O
of O
mean Method
- Method
shift Method
grouping Method
, O
extension O
to O
other O
pixel Task
- Task
level Task
domains Task
such O
as O
encoding O
surface O
shape O
, O
depth O
and O
figure O
- O
ground O
and O
multi Task
- Task
task Task
embeddings Task
. O
section O
: O
Acknowledgement O
This O
project O
is O
supported O
by O
NSF O
grants O
IIS O
- O
1618806 O
, O
IIS O
- O
1253538 O
, O
DBI O
- O
1262547 O
and O
a O
hardware O
donation O
from O
NVIDIA O
. O
Shu O
Kong O
personally O
thanks O
Mr. O
Kevis O
- O
Kokitsi O
Maninis O
, O
Dr. O
Alireza O
Fathi O
, O
Dr. O
Kevin O
Murphy O
and O
Dr. O
Rahul O
Sukthankar O
for O
the O
helpful O
discussion O
, O
advice O
and O
encouragement O
. O
bibliography O
: O
References O
Appendix O
In O
this O
appendix O
, O
we O
provide O
proofs O
of O
the O
propositions O
introduced O
in O
the O
main O
paper O
for O
understanding O
our O
objective Metric
function Metric
and O
grouping Method
mechanism Method
. O
Then O
, O
we O
provide O
the O
details O
of O
the O
mean Method
- Method
shift Method
algorithm Method
, O
computation Task
of Task
gradients Task
and O
how O
it O
is O
adapted O
for O
recurrent Task
grouping Task
. O
We O
illustrate O
how O
the O
gradients O
are O
back O
- O
propagated O
to O
the O
input O
embedding O
using O
a O
toy O
example O
. O
Finally O
, O
we O
include O
more O
qualitative O
results O
on O
boundary Task
detection Task
and O
instance Task
segmentation Task
. O
section O
: O
Analysis O
of O
Pairwise Metric
Loss Metric
for O
Spherical Task
Embedding Task
In O
this O
section O
, O
we O
provide O
proofs O
for O
the O
propositions O
presented O
in O
the O
paper O
which O
provide O
some O
analytical O
understanding O
of O
our O
proposed O
objective Metric
function Metric
, O
and O
the O
mechanism O
for O
subsequent O
pixel Method
grouping Method
mechanism Method
. O
theorem O
: O
For O
n O
vectors O
{ O
x1 O
, O
… O
, O
xn O
} O
, O
the O
total O
intra Metric
- Metric
pixel Metric
similarity Metric
is O
bounded O
as O
≥∑≠ij⁢xiTxj O
- O
∑=i1n∥xi∥22 O
. O
In O
particular O
, O
for O
n O
vectors O
on O
the O
hypersphere O
where O
= O
∥xi∥21 O
, O
we O
have O
≥∑≠ij⁢xiTxj O
- O
n O
. O
theorem O
: O
First O
note O
that O
≥∥ O
+ O
x1 O
… O
xn∥220 O
. O
We O
expand O
the O
square O
and O
collect O
all O
the O
cross O
terms O
so O
we O
have O
≥ O
+ O
∑i⁢xiTxi∑≠ij⁢xiTxj0 O
. O
Therefore O
, O
≥∑≠ij⁢xiTxj O
- O
∑=i1n∥xi∥22 O
. O
When O
all O
the O
vectors O
are O
on O
the O
hyper O
- O
sphere O
, O
i.e. O
= O
∥xi∥21 O
, O
then O
∑≠ij⁢xiTxj≥ O
- O
∑=i1n∥xi∥22= O
- O
n O
. O
■ O
theorem O
: O
If O
n O
vectors O
{ O
x1 O
, O
… O
, O
xn O
} O
are O
distributed O
on O
a O
2 O
- O
sphere O
( O
i.e. O
∈xiR3 O
with O
= O
∥xi∥21 O
, O
=∀i⁢1 O
… O
n O
) O
then O
the O
similarity O
between O
any O
pair O
is O
lower O
- O
bounded O
by O
≥s⁢ij O
- O
1 O
( O
⁢2π⁢3n O
) O
. O
Therefore O
, O
choosing O
the O
parameter O
α O
in O
the O
maximum O
margin O
term O
in O
objective Metric
function Metric
to O
be O
less O
than O
- O
1 O
( O
⁢2π⁢3n O
) O
results O
in O
positive O
loss O
even O
for O
a O
perfect O
embedding O
of O
n O
instances O
. O
We O
treat O
all O
the O
vectors O
as O
representatives O
of O
different O
instances O
in O
the O
image O
and O
seek O
to O
minimize O
pairwise O
similarity O
, O
or O
equivalently O
maximize O
pairwise O
distance O
( O
referred O
to O
as O
Tammes Task
’s Task
problem Task
, O
or O
the O
hard Task
- Task
spheres Task
problem Task
) O
. O
theorem O
: O
Let O
= O
d⁢max{xi}min≠ij∥ O
- O
xixj∥2 O
be O
the O
distance O
between O
the O
closest O
point O
pair O
of O
the O
optimally O
distributed O
points O
. O
Asymptotic O
results O
in O
[ O
] O
show O
that O
, O
for O
some O
constant O
> O
C0 O
, O
Since O
= O
∥ O
- O
xixj∥22 O
- O
2⁢2xiTxj O
, O
we O
can O
rewrite O
this O
bound O
in O
terms O
of O
the O
similarity O
= O
s⁢ij⁢12 O
(+ O
1⁢xiTxj⁢∥xi∥2∥xj∥2 O
) O
, O
so O
that O
for O
any O
≠ij O
: O
Therefore O
, O
choosing O
≤α O
- O
1 O
( O
⁢2π⁢3N O
) O
, O
guarantees O
that O
≥ O
[- O
s⁢ijα O
]+ O
0 O
for O
some O
pair O
≠ij O
. O
Choosing O
> O
α O
- O
1⁢14 O
(-( O
⁢8π⁢3N O
) O
12⁢CN O
- O
23 O
) O
2 O
, O
guarantees O
the O
existence O
of O
an O
embedding O
with O
= O
[ O
- O
s⁢ijα O
]+ O
0 O
. O
■ O
section O
: O
Details O
of O
Recurrent Method
Mean Method
Shift Method
Grouping O
There O
are O
two O
commonly O
used O
multivariate Method
kernels Method
in O
mean Method
shift Method
algorithm Method
. O
The O
first O
, O
Epanechnikov Method
kernel Method
, O
has O
the O
following O
profile O
where O
is O
the O
volume O
of O
the O
unit O
- O
dimensional O
sphere O
. O
The O
standard Method
mean Method
- Method
shift Method
algorithm Method
computes O
the O
gradient Method
of Method
the Method
kernel Method
density Method
estimate Method
given O
by O
and O
identifies O
modes O
( O
local O
maxima O
) O
where O
. O
The O
scale O
parameter O
is O
known O
as O
the O
kernel O
bandwidth O
and O
determines O
the O
smoothness O
of O
the O
estimator O
. O
The O
gradient O
of O
can O
be O
elegantly O
computed O
as O
the O
difference O
between O
and O
the O
mean O
of O
all O
data O
points O
with O
, O
hence O
the O
name O
“ O
mean Method
- Method
shift Method
” O
for O
performing O
gradient Method
ascent Method
. O
Since O
the O
Epanechnikov O
profile O
is O
not O
differentiable O
at O
the O
boundary O
, O
we O
use O
the O
squared Method
exponential Method
kernel Method
adapted O
to O
vectors O
on O
the O
sphere O
: O
which O
can O
be O
viewed O
as O
a O
natural O
extension O
of O
the O
Gaussian Method
to O
spherical O
data O
( O
known O
as O
the O
von Method
Mises Method
Fisher Method
( O
vMF Method
) O
distribution O
) O
. O
In O
our O
experiments O
we O
set O
the O
bandwidth O
based O
on O
the O
margin O
so O
that O
. O
Our O
proposed O
algorithm O
also O
differs O
from O
the O
standard O
mean Method
- Method
shift Method
clustering Method
( O
i.e. O
, O
) O
in O
that O
rather O
than O
performing O
gradient Method
ascent Method
on O
a O
fixed O
kernel Method
density Method
estimate Method
, O
at O
every O
iteration O
we O
alternate O
between O
updating O
the O
embedding O
vectors O
using O
gradient Method
ascent Method
on O
and O
re O
- O
estimating O
the O
density O
for O
the O
updated O
vectors O
. O
This O
approach O
is O
termed O
Gaussian Method
Blurring Method
Mean Method
Shift Method
( O
GBMS Method
) O
in O
and O
has O
converge Metric
rate Metric
guarantees Metric
for O
data O
which O
starts O
in O
compact O
clusters O
. O
In O
the O
paper O
we O
visualized O
embedding O
vectors O
after O
GBMS Method
for O
specific O
examples O
. O
Figure O
[ O
reference O
] O
shows O
aggregate O
statistics O
over O
a O
collection O
of O
images O
( O
in O
the O
experiment O
of O
instance Task
segmentation Task
) O
. O
We O
plot O
the O
distribution O
of O
pairwise O
similarities O
for O
positive O
and O
negative O
pairs O
during O
forward Method
propagation Method
through O
10 O
iterations O
. O
We O
can O
observe O
that O
the O
mean Method
shift Method
module Method
produces O
sharper O
distributions O
, O
driving O
the O
similarity O
between O
positive O
pairs O
to O
1 O
making O
it O
trivial O
to O
identify O
instances O
. O
subsection O
: O
Gradient Method
Calculation Method
for O
Recurrent Method
Mean Method
Shift Method
To O
backpropagate Task
gradients Task
through O
an O
iteration O
of O
GBMS Method
, O
we O
break O
the O
calculation O
into O
a O
sequence O
of O
steps O
below O
where O
we O
assume O
the O
vectors O
in O
the O
data O
matrix O
have O
already O
been O
normalized O
to O
unit O
length O
. O
where O
is O
the O
updated O
data O
after O
one O
iteration O
which O
is O
subsequently O
renormalized O
to O
project O
back O
onto O
the O
sphere O
. O
Let O
denote O
the O
loss O
and O
denote O
element O
- O
wise O
product O
. O
Backpropagation O
gradients O
are O
then O
given O
by O
: O
subsection O
: O
Toy O
Example O
of O
Mean Method
Shift Method
Backpropagation Method
In O
the O
paper O
we O
show O
examples O
of O
the O
gradient O
vectors O
backpropagated O
through O
recurrent Method
mean Method
shift Method
to O
the O
initial O
embedding O
space O
. O
Backpropagation Method
through O
this O
fixed O
model O
modulates O
the O
loss O
on O
the O
learned O
embedding O
, O
increasing O
the O
gradient O
for O
initial O
embedding O
vectors O
whose O
instance O
membership O
is O
ambiguous O
and O
decreasing O
the O
gradient O
for O
embedding O
vectors O
that O
will O
be O
correctly O
resolved O
by O
the O
recurrent Method
grouping Method
phase Method
. O
Figure O
[ O
reference O
] O
shows O
a O
toy O
example O
highlighting O
the O
difference O
between O
supervised Method
and Method
unsupervised Method
clustering Method
. O
We O
generate O
a O
set O
of O
1 O
- O
D O
data O
points O
drawn O
from O
three O
Gaussian Method
distributions Method
with O
mean O
and O
standard O
deviation O
as O
, O
and O
, O
respectively O
, O
as O
shown O
in O
Figure O
[ O
reference O
] O
( O
a O
) O
. O
We O
use O
mean Metric
squared Metric
error Metric
for O
the O
loss Task
with O
a O
fixed O
linear O
regressor O
and O
fixed O
target O
labels O
. O
The O
optimal O
embedding O
would O
set O
if O
, O
and O
if O
. O
We O
perform O
30 O
gradient Method
updates Method
of O
the O
embedding O
vectors O
with O
a O
step O
size O
as O
0.1 O
. O
We O
analyze O
the O
behavior O
of O
Gaussian Method
Blurring Method
Mean Method
Shift Method
( O
GBMS Method
) O
with O
bandwidth Method
as O
. O
If O
running O
GBMS Method
for O
unsupervised Task
clustering Task
on O
these O
data O
with O
the O
default O
setting O
( O
bandwidth O
is O
0.2 O
) O
, O
we O
can O
see O
they O
are O
grouped O
into O
three O
piles O
, O
as O
shown O
in O
Figure O
[ O
reference O
] O
( O
b O
) O
. O
If O
updating O
the O
data O
using O
gradient Method
descent Method
without O
GBMS Method
inserted O
, O
we O
end O
up O
with O
three O
visible O
clusters O
even O
though O
the O
data O
move O
towards O
the O
ideal O
embedding O
in O
terms O
of O
classification Task
. O
Figure O
[ O
reference O
] O
( O
c O
) O
and O
( O
d O
) O
depict O
the O
trajectories O
of O
100 O
random O
data O
points O
during O
the O
30 O
updates O
and O
the O
final O
result O
, O
respectively O
. O
Now O
we O
insert O
the O
GBMS Method
module O
to O
update O
these O
data O
with O
different O
loops O
, O
and O
compare O
how O
this O
effects O
the O
performance O
. O
We O
show O
the O
updated O
data O
distributions O
and O
those O
after O
five O
loops O
of O
GBMS Method
grouping O
in O
column O
( O
e O
) O
and O
( O
f O
) O
of O
Figure O
[ O
reference O
] O
, O
respectively O
. O
We O
notice O
that O
, O
with O
GBMS Method
, O
all O
the O
data O
are O
grouped O
into O
two O
clusters O
; O
while O
with O
GBMS Method
grouping O
they O
become O
more O
compact O
and O
are O
located O
exactly O
on O
the O
“ O
ideal O
spot O
” O
for O
mapping O
into O
label O
space O
( O
i.e. O
3 O
and O
5 O
) O
and O
achieving O
zero O
loss O
. O
On O
the O
other O
hand O
, O
we O
also O
observe O
that O
, O
even O
though O
these O
settings O
incorporates O
different O
number O
of O
GBMS Method
loops O
, O
they O
achieve O
similar O
visual O
results O
in O
terms O
of O
clustering Task
the O
data O
. O
To O
dive O
into O
the O
subtle O
difference O
, O
we O
randomly O
select O
100 O
data O
and O
depict O
their O
trajectories O
in O
column O
( O
g O
) O
and O
( O
h O
) O
of O
Figure O
[ O
reference O
] O
, O
using O
a O
single O
loss O
on O
top O
of O
the O
last O
GBMS Method
loop O
or O
multiple O
losses O
over O
every O
GBMS Method
loops O
, O
respectively O
. O
We O
have O
the O
following O
observations O
: O
By O
comparing O
with O
Figure O
[ O
reference O
] O
( O
c O
) O
, O
which O
depicts O
update O
trajectories O
without O
GBMS Method
, O
GBMS Method
module O
provides O
larger O
gradient O
to O
update O
those O
data O
further O
from O
their O
“ O
ideal O
spot O
” O
under O
both O
scenarios O
. O
From O
( O
g O
) O
, O
we O
can O
see O
the O
final O
data O
are O
not O
updated O
into O
tight O
groups O
. O
This O
is O
because O
that O
the O
updating Method
mechanism Method
only O
sees O
data O
after O
( O
some O
loops O
of O
) O
GBMS Method
, O
and O
knows O
that O
these O
data O
will O
be O
clustered O
into O
tight O
groups O
through O
GBMS Method
. O
A O
single O
loss O
with O
more O
loops O
of O
GBMS Method
provides O
greater O
gradient O
than O
that O
with O
fewer O
loops O
to O
update O
data O
, O
as O
seen O
in O
( O
g O
) O
. O
With O
more O
losses O
over O
every O
loops O
of O
GBMS Method
, O
the O
gradients O
become O
even O
larger O
that O
the O
data O
are O
grouped O
more O
tightly O
and O
more O
quickly O
. O
This O
is O
because O
that O
the O
updating Method
mechanism Method
also O
incorporates O
the O
gradients O
from O
the O
loss O
over O
the O
original O
data O
, O
along O
with O
those O
through O
these O
loops O
of O
GBMS Method
. O
To O
summarize O
, O
our O
GBMS Method
based O
recurrent O
grouping O
module O
indeed O
provides O
meaningful O
gradient O
during O
training O
with O
back Method
- Method
propagation Method
. O
With O
the O
convergent O
dynamics O
of O
GBMS Method
, O
our O
grouping Method
module Method
becomes O
especially O
more O
powerful O
in O
learning O
to O
group O
data O
with O
suitable O
supervision O
. O
section O
: O
Additional O
Boundary Task
Detection Task
Results O
We O
show O
additional O
boundary Task
detection Task
results O
on O
BSDS500 Material
dataset Material
based O
on O
our O
model O
in O
Figure O
[ O
reference O
] O
, O
[ O
reference O
] O
, O
[ O
reference O
] O
and O
[ O
reference O
] O
. O
Specifically O
, O
besides O
showing O
the O
boundary Task
detection Task
result O
, O
we O
also O
show O
3 O
- O
dimensional O
pixel O
embeddings O
as O
RGB Material
images Material
before O
and O
after O
fine Method
- Method
tuning Method
using O
logistic Method
loss Method
. O
From O
the O
consistent O
colors O
, O
we O
can O
see O
( O
1 O
) O
our O
model O
essentially O
carries O
out O
binary Task
classification Task
even O
using O
the O
pixel O
pair O
embedding O
loss O
; O
( O
2 O
) O
after O
fine O
- O
tuning O
with O
logistic Method
loss Method
, O
our O
model O
captures O
also O
boundary O
orientation O
and O
signed O
distance O
to O
the O
boundary O
. O
Figure O
[ O
reference O
] O
highlights O
this O
observation O
for O
an O
example O
image O
containing O
round O
objects O
. O
By O
zooming O
in O
one O
plate O
, O
we O
can O
observe O
a O
“ O
colorful O
Mobius O
ring O
” O
, O
indicating O
the O
embedding O
features O
for O
the O
boundary O
also O
capture O
boundary O
orientation O
and O
the O
signed O
distance O
to O
the O
boundary O
. O
section O
: O
Additional O
Results O
on O
Instance Task
- Task
Level Task
Semantic Task
Segmentation Task
We O
show O
more O
instance O
- O
level O
semantic Task
segmentation Task
results O
on O
PASCAL Material
VOC Material
2012 Material
dataset Material
based O
on O
our O
model O
in O
Figure O
[ O
reference O
] O
, O
[ O
reference O
] O
and O
[ O
reference O
] O
. O
As O
we O
learn O
64 O
- O
dimensional O
embedding O
( O
hyper O
- O
sphere O
) O
space O
, O
to O
visualize O
the O
results O
, O
we O
randomly O
generate O
three O
matrices O
to O
project O
the O
embeddings O
to O
3 O
- O
dimension O
vectors O
to O
be O
treated O
as O
RGB Material
images Material
. O
Besides O
showing O
the O
randomly O
projected O
embedding O
results O
, O
we O
also O
visualize O
the O
semantic Task
segmentation Task
results O
used O
to O
product O
instance Task
- Task
level Task
segmentation Task
. O
From O
these O
figures O
, O
we O
observe O
the O
embedding O
for O
background O
pixels O
are O
consistent O
, O
as O
the O
backgrounds O
have O
almost O
the O
same O
color O
. O
Moreover O
, O
we O
can O
see O
the O
embeddings O
( O
e.g. O
in O
Figure O
[ O
reference O
] O
, O
the O
horses O
in O
row O
- O
7 O
and O
row O
- O
13 O
, O
and O
the O
motorbike O
in O
row O
- O
14 O
) O
are O
able O
to O
connect O
the O
disconnected O
regions O
belonging O
to O
the O
same O
instance O
. O
Dealing O
with O
disconnected O
regions O
of O
one O
instance O
is O
an O
unsolved O
problem O
for O
many O
methods O
, O
e.g. O
, O
yet O
our O
approach O
has O
no O
problem O
with O
this O
situation O
. O
