Local Method
Decorrelation Method
For O
Improved O
Pedestrian Task
Detection Task
Even O
with O
the O
advent O
of O
more O
sophisticated O
, O
data Method
- Method
hungry Method
methods Method
, O
boosted Method
decision Method
trees Method
remain O
extraordinarily O
successful O
for O
fast O
rigid Task
object Task
detection Task
, O
achieving O
top O
accuracy Metric
on O
numerous O
datasets O
. O
While O
effective O
, O
most O
boosted Method
detectors Method
use O
decision Method
trees Method
with O
orthogonal O
( O
single O
feature O
) O
splits O
, O
and O
the O
topology O
of O
the O
resulting O
decision O
boundary O
may O
not O
be O
well O
matched O
to O
the O
natural O
topology O
of O
the O
data O
. O
Given O
highly O
correlated O
data O
, O
decision Method
trees Method
with O
oblique O
( O
multiple O
feature O
) O
splits O
can O
be O
effective O
. O
Use O
of O
oblique O
splits O
, O
however O
, O
comes O
at O
considerable O
computational Metric
expense Metric
. O
Inspired O
by O
recent O
work O
on O
discriminative Task
decorrelation Task
of Task
HOG Task
features Task
, O
we O
instead O
propose O
an O
efficient O
feature Method
transform Method
that O
removes O
correlations O
in O
local O
neighborhoods O
. O
The O
result O
is O
an O
overcomplete Method
but Method
locally Method
decorrelated Method
representation Method
ideally O
suited O
for O
use O
with O
orthogonal O
decision O
trees O
. O
In O
fact O
, O
orthogonal O
trees O
with O
our O
locally O
decorrelated O
features O
outperform O
oblique Method
trees Method
trained O
over O
the O
original O
features O
at O
a O
fraction O
of O
the O
computational Metric
cost Metric
. O
The O
overall O
improvement O
in O
accuracy Metric
is O
dramatic O
: O
on O
the O
Caltech Material
Pedestrian Material
Dataset Material
, O
we O
reduce O
false Metric
positives Metric
nearly O
tenfold O
over O
the O
previous O
state O
- O
of O
- O
the O
- O
art O
. O
1 O
Introduction O
In O
recent O
years O
object Method
detectors Method
have O
undergone O
an O
impressive O
transformation O
[ O
11 O
, O
32 O
, O
14 O
] O
. O
Nevertheless O
, O
boosted Method
detectors Method
remain O
extraordinarily O
successful O
for O
fast Task
detection Task
of Task
quasi Task
- Task
rigid Task
objects Task
. O
Such O
detectors O
were O
first O
proposed O
by O
Viola O
and O
Jones O
in O
their O
landmark O
work O
on O
efficient O
sliding Method
window Method
detection Method
that O
made O
face Task
detection Task
practical O
and O
commercially O
viable O
[ O
35 O
] O
. O
This O
initial O
architecture O
remains O
largely O
intact O
today O
: O
boosting Method
[ O
31 O
, O
12 O
] O
is O
used O
to O
train O
and O
combine O
decision Method
trees Method
and O
a O
cascade Method
is O
employed O
to O
allow O
for O
fast Task
rejection Task
of Task
negative Task
samples Task
. O
Details O
, O
however O
, O
have O
evolved O
considerably O
; O
in O
particular O
, O
significant O
progress O
has O
been O
made O
on O
the O
feature Method
representation Method
[ O
6 O
, O
9 O
, O
2 O
] O
and O
cascade Method
architecture Method
[ O
3 O
, O
8 O
] O
. O
Recent O
boosted Method
detectors Method
[ O
1 O
, O
7 O
] O
achieve O
state O
- O
of O
- O
the O
- O
art O
accuracy Metric
on O
modern O
benchmarks O
[ O
10 O
, O
22 O
] O
while O
retaining O
computational Metric
efficiency Metric
. O
While O
boosted Method
detectors Method
have O
evolved O
considerably O
over O
the O
past O
decade O
, O
decision Method
trees Method
with O
orthogonal O
( O
single O
feature O
) O
splits O
– O
also O
known O
as O
axis Method
- Method
aligned Method
decision Method
trees Method
– O
remain O
popular O
and O
predominant O
. O
A O
possible O
explanation O
for O
the O
persistence O
of O
orthogonal O
splits O
is O
their O
efficiency O
: O
oblique O
( O
multiple O
feature O
) O
splits O
incur O
considerable O
computational Metric
cost Metric
during O
both O
training Task
and O
detection Task
. O
Nevertheless O
, O
oblique O
trees O
can O
hold O
considerable O
advantages O
. O
In O
particular O
, O
Menze O
et O
al O
. O
[ O
23 O
] O
recently O
demonstrated O
that O
oblique Method
trees Method
used O
in O
conjunction O
with O
random Method
forests Method
are O
quite O
effective O
given O
high O
dimensional O
data O
with O
heavily O
correlated O
features O
. O
To O
achieve O
similar O
advantages O
while O
avoiding O
the O
computational Metric
expense Metric
of O
oblique O
trees O
, O
we O
instead O
take O
inspiration O
from O
recent O
work O
by O
Hariharan O
et O
al O
. O
[ O
15 O
] O
and O
propose O
to O
decorrelate O
features O
prior O
to O
applying O
orthogonal O
trees O
. O
To O
do O
so O
we O
introduce O
an O
efficient O
feature Method
transform Method
that O
removes O
correlations O
in O
local O
image O
neighborhoods O
( O
as O
opposed O
to O
decorrelating O
features O
globally O
as O
in O
[ O
15 O
] O
) O
. O
The O
result O
is O
an O
overcomplete Method
but Method
locally Method
decorrelated Method
representation Method
that O
is O
ideally O
suited O
for O
use O
with O
orthogonal O
trees O
. O
In O
fact O
, O
orthogonal O
trees O
with O
our O
locally O
decorrelated O
features O
require O
estimation O
of O
fewer O
parameters O
and O
actually O
outperform O
oblique Method
trees Method
trained O
over O
the O
original O
features O
. O
∗This O
research O
was O
performed O
while O
W.N. O
was O
a O
postdoctoral O
researcher O
at O
POSTECH O
. O
We O
evaluate O
boosted Method
decision Method
tree Method
learning Method
with O
decorrelated O
features O
in O
the O
context O
of O
pedestrian Task
detection Task
. O
As O
our O
baseline O
we O
utilize O
the O
aggregated Method
channel Method
features Method
( Method
ACF Method
) Method
detector Method
[ O
7 O
] O
, O
a O
popular O
, O
top O
- O
performing O
detector O
for O
which O
source O
code O
is O
available O
online O
. O
Coupled O
with O
use O
of O
deeper O
trees O
and O
a O
denser O
sampling O
of O
the O
data O
, O
the O
improvement O
obtained O
using O
our O
locally Method
decorrelated Method
channel Method
features Method
( O
LDCF Method
) O
is O
substantial O
. O
While O
in O
the O
past O
year O
the O
use O
of O
deep Method
learning Method
[ O
25 O
] O
, O
motion O
features O
[ O
27 O
] O
, O
and O
multi Method
- Method
resolution Method
models Method
[ O
36 O
] O
has O
brought O
down O
log Metric
- Metric
average Metric
miss Metric
rate Metric
( Metric
MR Metric
) O
to O
under O
40 O
% O
on O
the O
Caltech Material
Pedestrian Material
Dataset Material
[ O
10 O
] O
, O
LDCF Method
reduces O
MR Metric
to O
under O
25 O
% O
. O
This O
translates O
to O
a O
nearly O
tenfold O
reduction O
in O
false Metric
positives Metric
over O
the O
( O
very O
recent O
) O
state O
- O
of O
- O
the O
- O
art O
. O
The O
paper O
is O
organized O
as O
follows O
. O
In O
§ O
2 O
we O
review O
orthogonal Method
and Method
oblique Method
trees Method
and O
demonstrate O
that O
orthogonal Method
trees Method
trained O
on O
decorrelated O
data O
may O
be O
equally O
or O
more O
effective O
as O
oblique Method
trees Method
trained O
on O
the O
original O
data O
. O
We O
introduce O
the O
baseline O
in O
§ O
3 O
and O
in O
§ O
4 O
show O
that O
use O
of O
oblique O
trees O
improves O
results O
but O
at O
considerable O
computational Metric
expense Metric
. O
Next O
, O
in O
§ O
5 O
, O
we O
demonstrate O
that O
orthogonal Method
trees Method
trained O
with O
locally O
decorrelated O
features O
are O
efficient O
and O
effective O
. O
Experiments O
and O
results O
are O
presented O
in O
§ O
6 O
. O
We O
begin O
by O
briefly O
reviewing O
related O
work O
next O
. O
1.1 O
Related O
Work O
Pedestrian Task
Detection Task
: O
Recent O
work O
in O
pedestrian Task
detection Task
includes O
use O
of O
deformable Method
part Method
models Method
and O
their O
extensions O
[ O
11 O
, O
36 O
, O
26 O
] O
, O
convolutional Method
nets Method
and O
deep Method
learning Method
[ O
33 O
, O
37 O
, O
25 O
] O
, O
and O
approaches O
that O
focus O
on O
optimization Task
and O
learning Task
[ O
20 O
, O
18 O
, O
34 O
] O
. O
Boosted Method
detectors Method
are O
also O
widely O
used O
. O
In O
particular O
, O
the O
channel Method
features Method
detectors Method
[ O
9 O
, O
1 O
, O
2 O
, O
7 O
] O
are O
a O
family O
of O
conceptually O
straightforward O
and O
efficient O
detectors Method
based O
on O
boosted Method
decision Method
trees Method
computed O
over O
multiple O
feature O
channels O
such O
as O
color O
, O
gradient O
magnitude O
, O
gradient O
orientation O
and O
others O
. O
Current O
top O
results O
on O
the O
INRIA O
[ O
6 O
] O
and O
Caltech Material
[ O
10 O
] O
Pedestrian O
Datasets O
include O
instances O
of O
the O
channel Method
features Method
detector Method
with O
additional O
mid O
- O
level O
edge O
features O
[ O
19 O
] O
and O
motion O
features O
[ O
27 O
] O
, O
respectively O
. O
Oblique Method
Decision Method
Trees Method
: O
Typically O
, O
decision Method
trees Method
are O
trained O
with O
orthogonal O
( O
single O
feature O
) O
splits O
; O
however O
, O
the O
extension O
to O
oblique O
( O
multiple O
feature O
) O
splits O
is O
fairly O
intuitive O
and O
well O
known O
, O
see O
e.g. O
[ O
24 O
] O
. O
In O
fact O
, O
Breiman O
’s O
foundational O
work O
on O
random Task
forests Task
[ O
5 O
] O
experimented O
with O
oblique O
trees O
. O
Recently O
there O
has O
been O
renewed O
interest O
in O
random Task
forests Task
with O
oblique O
splits O
[ O
23 O
, O
30 O
] O
and O
Marin O
et O
al O
. O
[ O
20 O
] O
even O
applied O
such O
a O
technique O
to O
pedestrian Task
detection Task
. O
Likewise O
, O
while O
typically O
orthogonal Method
trees Method
are O
used O
with O
boosting Method
[ O
12 O
] O
, O
oblique Method
trees Method
can O
easily O
be O
used O
instead O
. O
The O
contribution O
of O
this O
work O
is O
not O
the O
straightforward O
coupling O
of O
oblique Method
trees Method
with O
boosting Method
, O
rather O
, O
we O
propose O
a O
local Method
decorrelation Method
transform Method
that O
eliminates O
the O
necessity O
of O
oblique O
splits O
altogether O
. O
Decorrelation Method
: O
Decorrelation Method
is O
a O
common O
pre Method
- Method
processing Method
step Method
for O
classification Task
[ O
17 O
, O
15 O
] O
. O
In O
recent O
work O
, O
Hariharan O
et O
al O
. O
[ O
15 O
] O
proposed O
an O
efficient O
scheme O
for O
estimating Task
covariances Task
between Task
HOG Task
features Task
[ O
6 O
] O
with O
the O
goal O
of O
replacing O
linear Method
SVMs Method
with O
LDA Method
and O
thus O
allowing O
for O
fast Task
training Task
. O
Hariharan O
et O
al O
. O
demonstrated O
that O
the O
global O
covariance O
matrix O
for O
a O
detection O
window O
can O
be O
estimated O
efficiently O
as O
the O
covariance O
between O
two O
features O
should O
depend O
only O
on O
their O
relative O
offset O
. O
Inspired O
by O
[ O
15 O
] O
, O
we O
likewise O
exploit O
the O
stationarity O
of O
natural O
image O
statistics O
, O
but O
instead O
propose O
to O
estimate O
a O
local O
covariance O
matrix O
shared O
across O
all O
image O
patches O
. O
Next O
, O
rather O
than O
applying O
global Method
decorrelation Method
, O
which O
would O
be O
computationally O
prohibitive O
for O
sliding Task
window Task
detection Task
with O
a O
nonlinear Method
classifier1 Method
, O
we O
instead O
propose O
to O
apply O
an O
efficient O
local Method
decorrelation Method
transform Method
. O
The O
result O
is O
an O
overcomplete Method
representation Method
well O
suited O
for O
use O
with O
orthogonal O
trees O
. O
1Global O
decorrelation Method
coupled O
with O
a O
linear Method
classifier Method
is O
efficient O
as O
the O
two O
linear Method
operations Method
can O
be O
merged O
. O
2 O
Boosted Method
Decision Method
Trees Method
with O
Correlated Method
Data Method
Boosting Method
is O
a O
simple O
yet O
powerful O
tool O
for O
classification Task
and O
can O
model O
complex O
non O
- O
linear O
functions O
[ O
31 O
, O
12 O
] O
. O
The O
general O
idea O
is O
to O
train O
and O
combine O
a O
number O
of O
weak Method
learners Method
into O
a O
more O
powerful O
strong Method
classifier Method
. O
Decision Method
trees Method
are O
frequently O
used O
as O
the O
weak Method
learner Method
in O
conjunction O
with O
boosting Task
, O
and O
in O
particular O
orthogonal Method
decision Method
trees Method
, O
that O
is O
trees O
in O
which O
every O
split O
is O
a O
threshold O
on O
a O
single O
feature O
, O
are O
especially O
popular O
due O
to O
their O
speed O
and O
simplicity O
[ O
35 O
, O
7 O
, O
1 O
] O
. O
The O
representational O
power O
obtained O
by O
boosting Method
orthogonal Method
trees Method
is O
not O
limited O
by O
use O
of O
orthogonal O
splits O
; O
however O
, O
the O
number O
and O
depth O
of O
the O
trees O
necessary O
to O
fit O
the O
data O
may O
be O
large O
. O
This O
can O
lead O
to O
complex O
decision O
boundaries O
and O
poor O
generalization Task
, O
especially O
given O
highly O
correlated O
features O
. O
Figure O
1 O
( O
a O
)-( O
c O
) O
shows O
the O
result O
of O
boosted Method
orthogonal Method
trees Method
on O
correlated O
data O
. O
Observe O
that O
the O
orthogonal O
trees O
generalize O
poorly O
even O
as O
we O
vary O
the O
number O
and O
depth O
of O
the O
trees O
. O
Decision Method
trees Method
with O
oblique O
splits O
can O
more O
effectively O
model O
data O
with O
correlated O
features O
as O
the O
topology O
of O
the O
resulting O
classifier Method
can O
better O
match O
the O
natural O
topology O
of O
the O
data O
[ O
23 O
] O
. O
In O
oblique O
trees O
, O
every O
split O
is O
based O
on O
a O
linear Method
projection Method
of O
the O
data O
z O
= O
wᵀx O
followed O
by O
thresholding Method
. O
The O
projection O
w O
can O
be O
sparse O
( O
and O
orthogonal O
splits O
are O
a O
special O
case O
with O
‖w‖0 O
= O
1 O
) O
. O
While O
in O
principle O
numerous O
approaches O
can O
be O
used O
to O
obtain O
w O
, O
in O
practice O
linear Method
discriminant Method
analysis Method
( O
LDA Method
) O
is O
a O
natural O
choice O
for O
obtaining O
discriminative O
splits O
efficiently O
[ O
16 O
] O
. O
LDA Method
aims O
to O
minimize O
within O
- O
class O
scatter O
while O
maximizing O
between O
- O
class O
scatter O
. O
w O
is O
computed O
from O
class O
- O
conditional O
mean O
vectors O
µ O
+ O
and O
µ− O
and O
a O
class O
- O
independent O
covariance O
matrix O
Σ O
as O
follows O
: O
w O
= O
Σ−1 O
( O
µ O
+ O
− O
µ− O
) O
. O
( O
1 O
) O
The O
covariance O
may O
be O
degenerate O
if O
the O
amount O
or O
underlying O
dimension O
of O
the O
data O
is O
low O
; O
in O
this O
case O
LDA Method
can O
be O
regularized O
by O
using O
( O
1− O
) O
Σ O
+ O
I O
in O
place O
of O
Σ. O
In O
Figure O
1 O
( O
d O
) O
we O
apply O
boosted Method
oblique Method
trees Method
trained O
with O
LDA Method
on O
the O
same O
data O
as O
before O
. O
Observe O
the O
resulting O
decision O
boundary O
better O
matches O
the O
underlying O
data O
distribution O
and O
shows O
improved O
generalization Task
. O
The O
connection O
between O
whitening Method
and O
LDA Method
is O
well O
known O
[ O
15 O
] O
. O
Specifically O
, O
LDA Method
simplifies O
to O
a O
trivial O
classification Method
rule Method
on O
whitened O
data O
( O
data O
whose O
covariance O
is O
the O
identity O
) O
. O
Let O
Σ O
= O
QΛQᵀ O
be O
the O
eigendecomposition Method
of Method
Σ Method
where O
Q O
is O
an O
orthogonal O
matrix O
and O
Λ O
is O
a O
diagonal O
matrix O
of O
eigenvalues O
. O
W O
= O
QΛ− O
1 O
2 O
Qᵀ O
= O
Σ− O
1 O
2 O
is O
known O
as O
a O
whitening O
matrix O
because O
the O
covariance O
of O
x′ O
= O
Wx Method
is O
the O
identity O
matrix O
. O
Given O
whitened O
data O
and O
means O
, O
LDA Method
can O
be O
interpreted O
as O
learning O
the O
trivial O
projection O
w′ O
= O
µ′ O
+ O
− O
µ′− O
= O
Wµ O
+ O
−Wµ− O
since O
w′ O
ᵀ O
x′ O
= O
w′ O
ᵀ O
Wx O
= O
wᵀx O
. O
Can O
whitening O
or O
a O
related O
transform O
likewise O
simplify O
learning Task
of Task
boosted Task
decision Task
trees Task
? O
Using O
standard O
terminology O
[ O
17 O
] O
, O
we O
define O
the O
following O
related O
transforms O
: O
decorrelation Method
( O
Qᵀ O
) O
, O
PCA Method
- Method
whitening Method
( O
Λ− O
1 O
2 O
Qᵀ O
) O
, O
and O
ZCA Method
- Method
whitening Method
( O
QΛ− O
1 O
2 O
Qᵀ O
) O
. O
Figure O
2 O
shows O
the O
result O
of O
boosting Method
orthogonal Method
trees Method
on O
the O
variously O
transformed O
features O
, O
using O
the O
same O
data O
as O
before O
. O
Observe O
that O
with O
decorrelated O
and O
PCA O
- O
whitened O
features O
orthogonal O
trees O
show O
improved O
generalization Task
. O
In O
fact O
, O
as O
each O
split O
is O
invariant O
to O
scaling O
of O
individual O
features O
, O
orthogonal O
trees O
with O
PCA O
- O
whitened O
and O
decorrelated O
features O
give O
identical O
results O
. O
Decorrelating O
the O
features O
is O
critical O
, O
while O
scaling Method
is O
not O
. O
The O
intuition O
is O
clear O
: O
each O
split O
operates O
on O
a O
single O
feature O
, O
which O
is O
most O
effective O
if O
the O
features O
are O
decorrelated O
. O
Interestingly O
, O
the O
standard O
ZCA Method
- Method
whitened Method
transform Method
used O
by O
LDA Method
is O
ineffective O
: O
while O
the O
resulting O
features O
are O
not O
technically O
correlated O
, O
due O
to O
the O
additional O
rotation O
by O
Q O
each O
resulting O
feature O
is O
a O
linear O
combination O
of O
features O
obtained O
by O
PCA Method
- Method
whitening Method
. O
3 O
Baseline Method
Detector Method
( O
ACF Method
) O
We O
next O
briefly O
review O
our O
baseline O
detector O
and O
evaluation Metric
benchmark Metric
. O
This O
will O
allow O
us O
to O
apply O
the O
ideas O
from O
§ O
2 O
to O
object Task
detection Task
in O
subsequent O
sections O
. O
In O
this O
work O
we O
utilize O
the O
channel Method
features Method
detectors Method
[ O
9 O
, O
7 O
, O
1 O
, O
2 O
] O
, O
a O
family O
of O
conceptually O
straightforward O
and O
efficient O
detectors O
for O
which O
variants O
have O
been O
utilized O
for O
diverse O
tasks O
such O
as O
pedestrian Task
detection Task
[ O
10 O
] O
, O
sign Task
recognition Task
[ O
22 O
] O
and O
edge Task
detection Task
[ O
19 O
] O
. O
Specifically O
, O
for O
our O
experiments O
we O
focus O
on O
pedestrian Task
detection Task
and O
employ O
the O
aggregate O
channel O
features O
( O
ACF Method
) Method
variant Method
[ O
7 O
] O
for O
which O
code O
is O
available O
online2 O
. O
Given O
an O
input O
image O
, O
ACF Method
computes O
several O
feature O
channels O
, O
where O
each O
channel O
is O
a O
per O
- O
pixel O
feature O
map O
such O
that O
output O
pixels O
are O
computed O
from O
corresponding O
patches O
of O
input O
pixels O
( O
thus O
preserving O
image O
layout O
) O
. O
We O
use O
the O
same O
channels O
as O
[ O
7 O
] O
: O
normalized O
gradient O
magnitude O
( O
1 O
channel O
) O
, O
histogram O
of O
oriented O
gradients O
( O
6 O
channels O
) O
, O
and O
LUV O
color O
channels O
( O
3 O
channels O
) O
, O
for O
a O
total O
of O
10 O
channels O
. O
We O
downsample O
the O
channels O
by O
2x O
and O
features O
are O
single O
pixel O
lookups O
in O
the O
aggregated O
channels O
. O
Thus O
, O
given O
a O
h O
× O
w O
detection O
window O
, O
there O
are O
h O
/ O
2 O
· O
w O
/ O
2 O
· O
10 O
candidate O
features O
( O
channel O
pixel O
lookups O
) O
. O
We O
use O
RealBoost Method
[ O
12 O
] O
with O
multiple O
rounds O
of O
bootstrapping Method
to O
train O
and O
combine O
2048 O
depth Method
- Method
3 Method
decision Method
trees Method
over O
these O
features O
to O
distinguish O
object O
from O
background O
. O
Soft Method
- Method
cascades Method
[ O
3 O
] O
and O
an O
efficient O
multiscale Method
sliding Method
- Method
window Method
approach Method
are O
employed O
. O
Our O
baseline O
uses O
slightly O
altered O
parameters O
from O
[ O
7 O
] O
( O
RealBoost O
, O
deeper O
trees O
, O
and O
less O
downsampling O
) O
; O
this O
increases O
model O
capacity O
and O
benefits O
our O
final O
approach O
as O
we O
report O
in O
detail O
in O
§ O
6 O
. O
Current O
practice O
is O
to O
use O
the O
INRIA O
Pedestrian O
Dataset O
[ O
6 O
] O
for O
parameter Task
tuning Task
, O
with O
the O
test O
set O
serving O
as O
a O
validation O
set O
, O
see O
e.g. O
[ O
20 O
, O
2 O
, O
9 O
] O
. O
We O
utilize O
this O
dataset O
in O
much O
the O
same O
way O
and O
report O
full O
results O
on O
the O
more O
challenging O
Caltech Material
Pedestrian Material
Dataset Material
[ O
10 O
] O
. O
Following O
the O
methodology O
of O
[ O
10 O
] O
, O
we O
summarize O
performance O
using O
the O
log O
- O
average O
miss O
rate O
( O
MR Metric
) O
between O
10−2 O
and O
100 O
false Metric
positives Metric
per O
image O
. O
We O
repeat O
all O
experiments O
10 O
times O
and O
report O
the O
mean O
MR Metric
and O
standard O
error O
for O
every O
result O
. O
Due O
to O
the O
use O
of O
a O
log O
- O
log O
scale O
, O
even O
small O
improvements O
in O
( O
log O
- O
average O
) O
MR Metric
correspond O
to O
large O
reductions O
in O
false Metric
- Metric
positives Metric
. O
On O
INRIA O
, O
our O
( O
slightly O
modified O
) O
baseline O
version O
of O
ACF Metric
scores Metric
at O
17.3 O
% O
MR Metric
compared O
to O
17.0 O
% O
MR Metric
for O
the O
model O
reported O
in O
[ O
7 O
] O
. O
4 O
Detection Task
with O
Oblique O
Splits O
( O
ACF Method
- Method
LDA Method
) O
In O
this O
section O
we O
modify O
the O
ACF Method
detector Method
to O
enable O
oblique O
splits O
and O
report O
the O
resulting O
gains O
. O
Recall O
that O
given O
input O
x O
, O
at O
each O
split O
of O
an O
oblique O
decision O
tree O
we O
need O
to O
compute O
z O
= O
wᵀx O
for O
some O
projection O
w O
and O
threshold O
the O
result O
. O
For O
our O
baseline Method
pedestrian Method
detector Method
, O
we O
use O
128 O
× O
64 O
windows O
where O
each O
window O
is O
represented O
by O
a O
feature O
vector O
x O
of O
size O
128 O
/ O
2 O
· O
64 O
/ O
2 O
· O
10 O
= O
20480 O
( O
see O
§ O
3 O
) O
. O
Given O
the O
high O
dimensionality O
of O
the O
input O
x O
coupled O
with O
the O
use O
of O
thousands O
of O
trees O
in O
a O
typical O
boosted Method
classifier Method
, O
for O
efficiency O
w O
must O
be O
sparse O
. O
Local O
w O
: O
We O
opt O
to O
use O
w O
’s O
that O
correspond O
to O
localm×m O
blocks O
of O
pixels O
. O
In O
other O
words O
, O
we O
treat O
x O
as O
a O
h O
/ O
2×w O
/ O
2× O
10 O
tensor O
and O
allow O
w O
to O
operate O
over O
any O
m×m× O
1 O
patch O
in O
a O
single O
channel O
of O
x. O
Doing O
so O
holds O
multiple O
advantages O
. O
Most O
importantly O
, O
each O
pixel O
has O
strongest O
correlations O
to O
spatially O
nearby O
pixels O
[ O
15 O
] O
. O
Since O
oblique O
splits O
are O
expected O
to O
help O
most O
when O
features O
are O
strongly O
correlated O
, O
operating O
over O
local O
neighborhoods O
is O
a O
natural O
choice O
. O
In O
addition O
, O
using O
local O
w O
allows O
for O
faster O
lookups O
due O
to O
the O
locality O
of O
adjacent O
pixels O
in O
memory O
. O
Complexity Metric
: O
First O
, O
let O
us O
consider O
the O
complexity Metric
of O
training O
the O
oblique O
splits O
. O
Let O
d O
= O
h O
/ O
2·w O
/ O
2 O
be O
the O
window O
size O
of O
a O
single O
channel O
. O
The O
number O
of O
patches O
per O
channel O
in O
x O
is O
about O
d O
, O
thus O
naively O
training O
a O
single O
split O
means O
applying O
LDA Method
d O
times O
– O
once O
per O
patch O
– O
and O
keeping O
w O
with O
lowest O
error O
. O
Instead O
of O
computing O
d O
independent O
matrices O
Σ O
per O
channel O
, O
for O
efficiency O
, O
we O
compute O
Σ Method
, O
a O
d× O
d O
covariance O
matrix O
for O
the O
entire O
window O
, O
and O
reconstruct O
individual O
m2 O
×m2 O
Σ O
’s O
by O
fetching O
appropriate O
entries O
from O
Σ. O
A O
similar O
trick O
can O
be O
used O
for O
the O
µ O
’s O
. O
Computing Method
Σ Method
is O
O O
( O
nd2 O
) O
given O
n O
training O
examples O
( O
and O
could O
be O
made O
faster O
by O
omitting O
unnecessary O
elements O
) O
. O
Inverting O
each O
Σ O
, O
the O
bottleneck O
of O
computing Task
Eq Task
. O
( O
1 O
) O
, O
is O
O O
( O
dm6 O
) O
but O
independent O
of O
n O
and O
thus O
fairly O
small O
as O
n O
m. O
Finally O
computing O
z O
= O
wᵀx O
over O
all O
n O
training O
examples O
and O
d O
projections O
is O
O O
( O
ndm2 O
) O
. O
Given O
the O
high O
complexity Metric
of O
each O
step O
, O
a O
naive Method
brute Method
- Method
force Method
approach Method
for O
training Task
is O
infeasible O
. O
Speedup O
: O
While O
the O
weights O
over O
training O
examples O
change O
at O
every O
boosting O
iteration O
and O
after O
every O
tree O
split O
, O
in O
practice O
we O
find O
it O
is O
unnecessary O
to O
recompute O
the O
projections O
that O
frequently O
. O
Table O
1 O
, O
rows O
2 O
- O
4 O
, O
shows O
the O
results O
of O
ACF Method
with O
oblique O
splits O
, O
updated O
every O
T O
boosting O
iterations O
2http: O
// O
vision.ucsd.edu O
/ O
˜pdollar O
/ O
toolbox O
/ O
doc O
/ O
( O
denoted O
by O
ACF Method
- Method
LDA Method
- Method
T Method
) O
. O
While O
more O
frequent O
updates O
improve O
accuracy Metric
, O
ACF Method
- Method
LDA Method
- Method
16 Method
has O
negligibly O
higher O
MR Metric
than O
ACF Method
- Method
LDA Method
- Method
4 Method
but O
a O
nearly O
fourfold O
reduction O
in O
training Metric
time Metric
( O
timed O
using O
12 O
cores O
) O
. O
Training O
the O
brute Method
force Method
version Method
of Method
ACF Method
- Method
LDA Method
, O
updated O
at O
every O
iteration O
and O
each O
tree O
split O
( O
7 O
interior O
nodes O
per O
depth O
- O
3 O
tree O
) O
would O
have O
taken O
about O
5 O
· O
4 O
· O
7 O
= O
140 O
hours O
. O
For O
these O
results O
we O
used O
regularization O
of O
= O
.1 O
and O
patch O
size O
of O
m O
= O
5 O
( O
effect O
of O
varying O
m O
is O
explored O
in O
§ O
6 O
) O
. O
Shared Method
Σ Method
: O
The O
crux O
and O
computational Metric
bottleneck Metric
of O
ACF Method
- Method
LDA Method
is O
the O
computation O
and O
application O
of O
a O
separate O
covariance Method
Σ Method
at O
each O
local O
neighborhood O
. O
In O
recent O
work O
on O
training O
linear Task
object Task
detectors Task
using O
LDA Method
, O
Hariharan O
et O
al O
. O
[ O
15 O
] O
exploited O
the O
observation O
that O
the O
statistics O
of O
natural O
images O
are O
translationally O
invariant O
and O
therefore O
the O
covariance O
between O
two O
features O
should O
depend O
only O
on O
their O
relative O
offset O
. O
Furthermore O
, O
as O
positives O
are O
rare O
, O
[ O
15 O
] O
showed O
that O
the O
covariances O
can O
be O
precomputed O
using O
natural O
images O
. O
Inspired O
by O
these O
observations O
, O
we O
propose O
to O
use O
a O
single O
, O
fixed O
covariance O
Σ O
shared O
across O
all O
local O
image O
neighborhoods O
. O
We O
precompute O
one O
Σ O
per O
channel O
and O
do O
not O
allow O
it O
to O
vary O
spatially O
or O
with O
boosting O
iteration O
. O
Table O
1 O
, O
rows O
5 O
- O
7 O
, O
shows O
the O
results O
of O
ACF Method
with O
oblique O
splits O
using O
fixed O
Σ O
, O
denoted O
by O
ACF Method
- Method
LDA∗. Method
As O
before O
, O
the O
µ O
’s O
and O
resulting O
w O
are O
updated O
every O
T O
iterations O
. O
As O
expected O
, O
training Metric
time Metric
is O
reduced O
relative O
to O
ACF Method
- Method
LDA Method
. O
Surprisingly O
, O
however O
, O
accuracy Metric
improves O
as O
well O
, O
presumably O
due O
to O
the O
implicit O
regularization O
effect O
of O
using O
a O
fixed O
Σ. O
This O
is O
a O
powerful O
result O
we O
will O
exploit O
further O
. O
Summary O
: O
ACF Method
with O
local Method
oblique Method
splits Method
and O
a O
single O
shared Method
Σ Method
( O
ACF Method
- Method
LDA∗ Method
- Method
4 Method
) O
achieves O
14.7 O
% O
MR Metric
compared O
to O
17.3 O
% O
MR Metric
for O
ACF Method
with O
orthogonal O
splits O
. O
The O
2.6 O
% O
improvement O
in O
log Metric
- Metric
average Metric
MR Metric
corresponds O
to O
a O
nearly O
twofold O
reduction O
in O
false Metric
positives Metric
but O
comes O
at O
considerable O
computational Metric
cost Metric
. O
In O
the O
next O
section O
, O
we O
propose O
an O
alternative O
, O
more O
efficient O
approach O
for O
exploiting O
the O
use O
of O
a O
single O
shared Method
Σ Method
capturing O
correlations O
in O
local O
neighborhoods O
. O
5 O
Locally O
Decorrelated O
Channel O
Features O
( O
LDCF Method
) O
We O
now O
have O
all O
the O
necessary O
ingredients O
to O
introduce O
our O
approach O
. O
We O
have O
made O
the O
following O
observations O
: O
( O
1 O
) O
oblique O
splits O
learned O
with O
LDA Method
over O
local O
m O
×m O
patches O
improve O
results O
over O
orthogonal O
splits O
, O
( O
2 O
) O
a O
single O
covariance O
matrix O
Σ O
can O
be O
shared O
across O
all O
patches O
per O
channel O
, O
and O
( O
3 O
) O
orthogonal O
trees O
with O
decorrelated O
features O
can O
potentially O
be O
used O
in O
place O
of O
oblique O
trees O
. O
This O
suggests O
the O
following O
approach O
: O
for O
every O
m×m O
patch O
p O
in O
x O
, O
we O
can O
create O
a O
decorrelated Method
representation Method
by O
computing O
Qᵀp Method
, O
where O
QΛQᵀ O
is O
the O
eigendecomposition Method
of Method
Σ Method
as O
before O
, O
followed O
by O
use O
of O
orthogonal Method
trees Method
. O
However O
, O
such O
an O
approach O
is O
computationally O
expensive O
. O
First O
, O
due O
to O
use O
of O
overlapping O
patches O
, O
computing O
Qᵀp O
for O
every O
overlapping O
patch O
results O
in O
an O
overcomplete Method
representation Method
with O
a O
factor O
m2 O
increase O
in O
feature Metric
dimensionality Metric
. O
To O
reduce O
dimensionality O
, O
we O
only O
utilize O
the O
top O
k O
eigenvectors O
in O
Q O
, O
resulting O
in O
k O
< O
m2 O
features O
per O
pixel O
. O
The O
intuition O
is O
that O
the O
top O
eigenvectors O
capture O
the O
salient O
neighborhood O
structure O
. O
Our O
experiments O
in O
§ O
6 O
confirm O
this O
: O
using O
as O
few O
as O
k O
= O
4 O
eigenvectors O
per O
channel O
for O
patches O
of O
size O
m O
= O
5 O
is O
sufficient O
. O
As O
our O
second O
speedup O
, O
we O
observe O
that O
the O
projection O
Qᵀp O
can O
be O
computed O
by O
a O
series O
of O
k Method
convolutions Method
between O
a O
channel O
image O
and O
each O
m×m Method
filter Method
reshaped O
from O
its O
corresponding O
eigenvector O
( O
column O
of O
Q O
) O
. O
This O
is O
possible O
because O
the O
covariance O
matrix O
Σ O
is O
shared O
across O
all O
patches O
per O
channel O
and O
hence O
the O
derived O
Q Method
is O
likewise O
spatially O
invariant O
. O
Decorrelating O
all O
10 O
channels O
in O
an O
entire O
feature Method
pyramid Method
for O
a O
640× O
480 O
image O
takes O
about O
.5 O
seconds O
. O
In O
summary O
, O
we O
modify O
ACF Method
by O
taking O
the O
original O
10 O
channels O
and O
applying O
k O
= O
4 O
decorrelating Method
( Method
linear Method
) Method
filters Method
per O
channel O
. O
The O
result O
is O
a O
set O
of O
40 O
locally Method
decorrelated Method
channel Method
features Method
( O
LDCF Method
) O
. O
To O
further O
increase O
efficiency O
, O
we O
downsample O
the O
decorrelated O
channels O
by O
a O
factor O
of O
2x O
which O
has O
negligible O
impact O
on O
accuracy Metric
but O
reduces O
feature O
dimension O
to O
the O
original O
value O
. O
Given O
the O
new O
locally O
decorrelated O
channels O
, O
all O
other O
steps O
of O
ACF Task
training Task
and O
testing Task
are O
identical O
. O
The O
extra O
implementation O
effort O
is O
likewise O
minimal O
: O
given O
the O
decorrelation Method
filters Method
, O
a O
few O
lines O
of O
code O
suffice O
to O
convert O
ACF Method
into O
LDCF Method
. O
To O
further O
improve O
clarity O
, O
all O
source O
code O
for O
LDCF Method
will O
be O
released O
. O
Results O
of O
the O
LDCF Method
detector O
on O
the O
INRIA O
dataset O
are O
given O
in O
the O
last O
row O
of O
Table O
1 O
. O
The O
LCDF Method
detector Method
( O
which O
uses O
orthogonal O
splits O
) O
improves O
accuracy Metric
over O
ACF Method
with O
oblique O
splits O
by O
an O
additional O
1 O
% O
MR Metric
. O
Training Metric
time Metric
is O
significantly O
faster O
, O
and O
indeed O
, O
is O
only O
∼1 O
minute O
longer O
than O
for O
the O
original O
ACF Method
detector Method
. O
More O
detailed O
experiments O
and O
results O
are O
reported O
in O
§ O
6 O
. O
We O
conclude O
by O
( O
1 O
) O
describing O
the O
estimation O
of O
Σ O
for O
each O
channel O
, O
( O
2 O
) O
showing O
various O
visualizations O
, O
and O
( O
3 O
) O
discussing O
the O
filters O
themselves O
and O
connections O
to O
known O
filters O
. O
Estimating Task
Σ Task
: O
We O
can O
estimate O
a O
spatially O
constant O
Σ O
for O
each O
channel O
using O
any O
large O
collection O
of O
natural O
images O
. O
Σ O
for O
each O
channel O
is O
represented O
by O
a O
spatial Method
autocorrelation Method
function Method
Σ O
( O
x O
, O
y O
),( O
x O
+ O
∆x O
, O
y O
+ O
∆y O
) O
= O
C O
( O
∆x O
, O
∆y O
) O
. O
Given O
a O
collection O
of O
natural O
images O
, O
we O
first O
estimate O
a O
separate O
autocorrelation Method
function Method
for O
each O
image O
and O
then O
average O
the O
results O
. O
Naive O
computation O
of O
the O
final O
function O
is O
O O
( O
np2 O
) O
but O
the O
Wiener Method
- Method
Khinchin Method
theorem Method
reduces O
the O
complexity Metric
to O
O O
( O
np O
log O
p O
) O
via O
the O
FFT Method
[ O
4 O
] O
, O
where O
n O
and O
p O
denote O
the O
number O
of O
images O
and O
pixels O
per O
image O
, O
respectively O
. O
Visualization Task
: O
Fig O
. O
3 O
, O
top O
- O
left O
, O
illustrates O
the O
estimated O
autocorrelations O
for O
each O
channel O
. O
Nearby O
features O
are O
highly O
correlated O
and O
oriented O
gradients O
are O
spatially O
correlated O
along O
their O
orientation O
due O
to O
curvilinear O
continuity O
[ O
15 O
] O
. O
Fig O
. O
3 O
, O
bottom O
- O
left O
, O
shows O
the O
decorrelation Method
filters Method
for O
each O
channel O
obtained O
by O
reshaping O
the O
largest O
eigenvectors O
of O
Σ. O
The O
largest O
eigenvectors O
are O
smoothing Method
filters Method
while O
the O
smaller O
ones O
resemble O
increasingly O
higher O
- O
frequency Method
filters Method
. O
The O
corresponding O
eigenvalues O
decay O
rapidly O
and O
in O
practice O
we O
use O
the O
top O
k O
= O
4 O
filters O
. O
Observe O
that O
the O
decorrelation Method
filters Method
for O
oriented O
gradients O
are O
aligned O
to O
their O
orientation O
. O
Finally O
, O
Fig O
. O
3 O
, O
right O
, O
shows O
original O
and O
decorrelated O
channels O
averaged O
over O
positive O
training O
examples O
. O
Discussion O
: O
Our O
decorrelation Method
filters Method
are O
closely O
related O
to O
sinusoidal Method
, Method
DCT Method
basis Method
, O
and O
Gaussian Method
derivative Method
filters Method
. O
Spatial O
interactions O
in O
natural O
images O
are O
often O
well O
- O
described O
by O
Markov Method
models Method
[ O
13 O
] O
and O
first Method
- Method
order Method
stationary Method
Markov Method
processes Method
are O
known O
to O
have O
sinusoidal Method
KLT Method
bases Method
[ O
29 O
] O
. O
In O
particular O
, O
for O
the O
LUV O
color O
channels O
, O
our O
filters O
are O
similar O
to O
the O
discrete Method
cosine Method
transform Method
( Method
DCT Method
) Method
bases Method
that O
are O
often O
used O
to O
approximate O
the O
KLT Method
. O
For O
oriented O
gradients O
, O
however O
, O
the O
decorrelation Method
filters Method
are O
no O
longer O
well O
modeled O
by O
the O
DCT Method
bases Method
( O
note O
also O
that O
our O
filters O
are O
applied O
densely O
whereas O
the O
DCT Method
typically O
uses O
block Method
processing Method
) O
. O
Alternatively O
, O
we O
can O
interpret O
our O
filters O
as O
Gaussian Method
derivative Method
filters Method
. O
Assume O
that O
the O
autocorrelation O
is O
modeled O
by O
a O
squared Method
- Method
exponential Method
functionC Method
( Method
∆x Method
) O
= O
exp O
( O
−∆x2 O
/ O
2l2 O
) O
, O
which O
is O
fairly O
reasonable O
given O
the O
estimation O
results O
in O
Fig O
. O
3 O
. O
In O
1D O
, O
the O
kth O
largest O
eigenfunction O
of O
such O
an O
autocorrelation Method
function Method
is O
a O
k Method
− Method
1 Method
order Method
Gaussian Method
derivative Method
filter Method
[ O
28 O
] O
. O
It O
is O
straightforward O
to O
extend O
the O
result O
to O
an O
anisotropic Task
multivariate Task
case Task
in O
which O
case O
the O
eigenfunctions O
are O
Gaussian Method
directional Method
derivative Method
filters Method
similar O
to O
our O
filters O
. O
6 O
Experiments O
In O
this O
section O
, O
we O
demonstrate O
the O
effectiveness O
of O
locally Method
decorrelated Method
channel Method
features Method
( O
LDCF Method
) O
in O
the O
context O
of O
pedestrian Task
detection Task
. O
We O
: O
( O
1 O
) O
study O
the O
effect O
of O
parameter O
settings O
, O
( O
2 O
) O
test O
variations O
of O
our O
approach O
, O
and O
finally O
( O
3 O
) O
compare O
our O
results O
with O
the O
state O
- O
of O
- O
the O
- O
art O
. O
Parameters O
: O
LDCF Method
has O
two O
parameters O
: O
the O
count O
and O
size O
of O
the O
decorrelation Method
filters Method
. O
Fig O
. O
4 O
( O
a O
) O
and O
( O
b O
) O
show O
the O
results O
of O
LDCF Method
on O
the O
INRIA O
dataset O
while O
varying O
the O
filter O
count O
( O
k O
) O
and O
size O
( O
m O
) O
, O
respectively O
. O
Use O
of O
k O
= O
4 O
decorrelation Method
filters Method
of O
size O
m O
= O
5 O
improves O
performance O
up O
to O
∼4 O
% O
MR Metric
compared O
to O
ACF Method
. O
Inclusion O
of O
additional O
higher Method
- Method
frequency Method
filters Method
or O
use O
of O
larger O
filters O
can O
cause O
performance O
degradation O
. O
For O
all O
remaining O
experiments O
we O
fix O
k O
= O
4 O
and O
m O
= O
5 O
. O
Variations O
: O
We O
test O
variants O
of O
LDCF Method
and O
report O
results O
on O
INRIA O
in O
Table O
2 O
. O
LDCF Method
( O
row O
7 O
) O
outperforms O
all O
variants O
, O
including O
the O
baseline O
( O
1 O
) O
. O
Filtering O
the O
channels O
with O
the O
smallest O
k O
eigenvectors O
( O
2 O
) O
or O
k O
random Method
filters Method
( O
3 O
) O
performs O
worse O
. O
Local Method
decorrelation Method
of O
only O
the O
color O
channels O
( O
4 O
) O
or O
only O
the O
gradient O
channels O
( O
5 O
) O
is O
inferior O
to O
decorrelation O
of O
all O
channels O
. O
Finally O
, O
we O
test O
constant Method
decorrelation Method
filters Method
obtained O
from O
the O
intensity O
channel O
L O
that O
resemble O
the O
first O
k O
DCT Method
basis Method
filters Method
. O
Use O
of O
unique Method
filters Method
per O
channel O
outperforms O
use O
of O
constant Method
filters Method
across O
all O
channels O
( O
6 O
) O
. O
Model Method
Capacity Method
: O
Use O
of O
locally O
decorrelated O
features O
implicitly O
allows O
for O
richer O
, O
more O
effective O
splitting O
functions O
, O
increasing O
modeling Metric
capacity Metric
and O
generalization Metric
ability Metric
. O
Inspired O
by O
their O
success O
, O
we O
explore O
additional O
strategies O
for O
augmenting O
model Task
capacity Task
. O
For O
the O
following O
experiments O
, O
we O
rely O
solely O
on O
the O
training O
set O
of O
the O
Caltech Material
Pedestrian Material
Dataset Material
[ O
10 O
] O
. O
Of O
the O
71 O
minute O
long O
training O
videos O
( O
∼128k O
images O
) O
, O
we O
use O
every O
fourth O
video O
as O
validation O
data O
and O
the O
rest O
for O
training O
. O
On O
the O
validation O
set O
, O
LDCF Method
outperforms O
ACF Method
by O
a O
considerable O
margin O
, O
reducing O
MR Metric
from O
46.2 O
% O
to O
41.7 O
% O
. O
We O
first O
augment O
model O
capacity O
by O
increasing O
the O
number O
of O
trees O
twofold O
( O
to O
4096 O
) O
and O
the O
sampled O
negatives O
fivefold O
( O
to O
50k O
) O
. O
Surprisingly O
, O
doing O
so O
reduces O
MR Metric
by O
an O
additional O
4 O
% O
. O
Next O
, O
we O
experiment O
with O
increasing O
maximum O
tree O
depth O
while O
simultaneously O
enlarging O
the O
amount O
of O
data O
available O
for O
training O
. O
Typically O
, O
every O
30th O
image O
in O
the O
Caltech Material
dataset O
is O
used O
for O
training O
and O
testing O
. O
Instead O
, O
Figure O
4 O
( O
c O
) O
shows O
validation Metric
performance O
of O
LDCF Method
with O
different O
tree O
depths O
while O
varying O
the O
training O
data O
sampling O
interval O
. O
The O
impact O
of O
maximum O
depth O
on O
performance O
is O
quite O
large O
. O
At O
a O
dense O
sampling O
interval O
of O
every O
4th O
frame O
, O
use O
of O
depth O
- O
5 O
trees O
( O
up O
from O
depth O
- O
2 O
for O
the O
original O
approach O
) O
improves O
performance O
by O
an O
additional O
5 O
% O
to O
32.6 O
% O
MR Metric
. O
Note O
that O
consistent O
with O
the O
generalization O
bounds O
of O
boosting Method
[ O
31 O
] O
, O
use O
of O
deeper O
trees O
requires O
more O
data O
. O
INRIA O
Results O
: O
In O
Figure O
5 O
( O
a O
) O
we O
compare O
LDCF Method
with O
state O
- O
of O
- O
the O
- O
art O
detectors O
on O
INRIA Method
[ O
6 O
] O
using O
benchmark O
code O
maintained O
by O
[ O
10 O
] O
. O
Since O
the O
INRIA O
dataset O
is O
oft O
- O
used O
as O
a O
validation O
set O
, O
including O
in O
this O
work O
, O
we O
include O
these O
results O
for O
completeness O
only O
. O
LDCF Method
is O
essentially O
tied O
for O
second O
place O
with O
Roerei O
[ O
2 O
] O
and O
Franken O
[ O
21 O
] O
and O
outperformed O
by O
∼1 O
% O
MR Metric
by O
SketchTokens O
[ O
19 O
] O
. O
These O
approaches O
all O
belong O
to O
the O
family O
of O
channel Method
features Method
detectors Method
, O
and O
as O
the O
improvements O
proposed O
in O
this O
work O
are O
orthogonal O
, O
the O
methods O
could O
potentially O
be O
combined O
. O
Caltech Material
Results O
: O
We O
present O
our O
main O
result O
on O
the O
Caltech Material
Pedestrian Material
Dataset Material
[ O
10 O
] O
, O
see O
Fig O
. O
5 O
( O
b O
) O
, O
generated O
using O
the O
official O
evaluation O
code O
available O
online3 O
. O
The O
Caltech Material
dataset O
has O
become O
the O
standard O
for O
evaluating Task
pedestrian Task
detectors Task
and O
the O
latest O
methods O
based O
on O
deep Method
learning Method
( O
JointDeep Method
) O
[ O
25 O
] O
, O
multi Method
- Method
resolution Method
models Method
( O
MT Method
- Method
DPM Method
) O
[ O
36 O
] O
and O
motion O
features O
( O
ACF Method
+ Method
SDt Method
) O
[ O
27 O
] O
achieve O
under O
40 O
% O
log Metric
- Metric
average Metric
MR Metric
. O
For O
a O
complete O
comparison O
, O
we O
first O
present O
results O
for O
an O
augmented Method
capacity Method
ACF Method
model Method
which O
uses O
more O
( O
4096 O
) O
and O
deeper O
( O
depth O
- O
5 O
) O
trees O
trained O
with O
RealBoost Method
using O
dense Method
sampling Method
of O
the O
training O
data O
( O
every O
4th O
image O
) O
. O
See O
preceding O
note O
on O
model O
capacity O
for O
details O
and O
motivation O
. O
This O
augmented Method
model Method
( O
ACF O
- O
Caltech Material
+ O
) O
achieves O
29.8 O
% O
MR Metric
, O
a O
considerable O
nearly O
10 O
% O
MR Metric
gain O
over O
previous O
methods O
, O
including O
the O
baseline Method
version Method
of O
ACF Method
( O
ACFCaltech Method
) O
. O
With O
identical O
parameters O
, O
locally Method
decorrelated Method
channel Method
features Method
( O
LDCF Method
) O
further O
reduce O
error Metric
to O
24.9 O
% O
MR Metric
with O
substantial O
gains O
at O
higher O
recall Metric
. O
Overall O
, O
this O
is O
a O
massive O
improvement O
and O
represents O
a O
nearly O
10x O
reduction O
in O
false Metric
positives Metric
over O
the O
previous O
state O
- O
of O
- O
the O
- O
art O
. O
7 O
Conclusion O
In O
this O
work O
we O
have O
presented O
a O
simple O
, O
principled O
approach O
for O
improving O
boosted Task
object Task
detectors Task
. O
Our O
core O
observation O
was O
that O
effective O
but O
expensive O
oblique O
splits O
in O
decision Method
trees Method
can O
be O
replaced O
by O
orthogonal O
splits O
over O
locally O
decorrelated O
data O
. O
Moreover O
, O
due O
to O
the O
stationary O
statistics O
of O
image O
features O
, O
the O
local O
decorrelation O
can O
be O
performed O
efficiently O
via O
convolution Method
with O
a O
fixed Method
filter Method
bank Method
precomputed O
from O
natural O
images O
. O
Our O
approach O
is O
general O
, O
simple O
and O
fast O
. O
Our O
method O
showed O
dramatic O
improvement O
over O
previous O
state O
- O
of O
- O
the O
- O
art O
. O
While O
some O
of O
the O
gain O
was O
from O
increasing O
model O
capacity O
, O
use O
of O
local Method
decorrelation Method
gave O
a O
clear O
and O
significant O
boost O
. O
Overall O
, O
we O
reduced O
false Metric
- Metric
positives Metric
tenfold O
on O
Caltech Material
. O
Such O
large O
gains O
are O
fairly O
rare O
. O
In O
the O
present O
work O
we O
did O
not O
decorrelate O
features O
across O
channels O
( O
decorrelation O
was O
applied O
independently O
per O
channel O
) O
. O
This O
is O
a O
clear O
future O
direction O
. O
Testing O
local O
decorrelation O
in O
the O
context O
of O
other O
classifiers Method
( O
e.g. O
convolutional Method
nets Method
or O
linear Method
classifiers Method
as O
in O
[ O
15 O
] O
) O
would O
also O
be O
interesting O
. O
While O
the O
proposed O
locally Method
decorrelated Method
channel Method
features Method
( O
LDCF Method
) O
require O
only O
modest O
modification O
to O
existing O
code O
, O
we O
will O
release O
all O
source O
code O
used O
in O
this O
work O
to O
ease O
reproducibility O
. O
3http: O
// O
www.vision.caltech.edu O
/ O
Image_Datasets O
/ O
CaltechPedestrians O
/ O
