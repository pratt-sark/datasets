document O
: O
An O
Effective O
Approach O
to O
Unsupervised Task
Machine Task
Translation Task
While O
machine Task
translation Task
has O
traditionally O
relied O
on O
large O
amounts O
of O
parallel O
corpora O
, O
a O
recent O
research O
line O
has O
managed O
to O
train O
both O
Neural Method
Machine Method
Translation Method
( O
NMT Method
) O
and O
Statistical Method
Machine Method
Translation Method
( O
SMT Method
) O
systems O
using O
monolingual O
corpora O
only O
. O
In O
this O
paper O
, O
we O
identify O
and O
address O
several O
deficiencies O
of O
existing O
unsupervised O
SMT Method
approaches O
by O
exploiting O
subword O
information O
, O
developing O
a O
theoretically O
well O
founded O
unsupervised Method
tuning Method
method Method
, O
and O
incorporating O
a O
joint Method
refinement Method
procedure Method
. O
Moreover O
, O
we O
use O
our O
improved O
SMT Method
system O
to O
initialize O
a O
dual O
NMT Method
model O
, O
which O
is O
further O
fine O
- O
tuned O
through O
on O
- O
the O
- O
fly O
back Method
- Method
translation Method
. O
Together O
, O
we O
obtain O
large O
improvements O
over O
the O
previous O
state O
- O
of O
- O
the O
- O
art O
in O
unsupervised Task
machine Task
translation Task
. O
For O
instance O
, O
we O
get O
22.5 O
BLEU Metric
points Metric
in O
English Material
- Material
to Material
- Material
German Material
WMT Material
2014 Material
, O
5.5 O
points O
more O
than O
the O
previous O
best O
unsupervised Method
system Method
, O
and O
0.5 O
points O
more O
than O
the O
( O
supervised O
) O
shared O
task O
winner O
back O
in O
2014 O
. O
section O
: O
Introduction O
The O
recent O
advent O
of O
neural Method
sequence Method
- Method
to Method
- Method
sequence Method
modeling Method
has O
resulted O
in O
significant O
progress O
in O
the O
field O
of O
machine Task
translation Task
, O
with O
large O
improvements O
in O
standard O
benchmarks O
vaswani2017attention O
, O
edunov2018understanding O
and O
the O
first O
solid O
claims O
of O
human Metric
parity Metric
in O
certain O
settings O
hassan2018achieving O
. O
Unfortunately O
, O
these O
systems O
rely O
on O
large O
amounts O
of O
parallel O
corpora O
, O
which O
are O
only O
available O
for O
a O
few O
combinations O
of O
major O
languages O
like O
English Material
, O
German Material
and O
French Material
. O
Aiming O
to O
remove O
this O
dependency O
on O
parallel O
data O
, O
a O
recent O
research O
line O
has O
managed O
to O
train O
unsupervised Task
machine Task
translation Task
systems Task
using O
monolingual O
corpora O
only O
. O
The O
first O
such O
systems O
were O
based O
on O
Neural Method
Machine Method
Translation Method
( O
NMT Method
) O
, O
and O
combined O
denoising Method
autoencoding Method
and O
back Method
- Method
translation Method
to O
train O
a O
dual Method
model Method
initialized O
with O
cross Method
- Method
lingual Method
embeddings Method
artetxe2018unmt O
, O
lample2018unsupervised O
. O
Nevertheless O
, O
these O
early O
systems O
were O
later O
superseded O
by O
Statistical Method
Machine Method
Translation Method
( O
SMT Method
) O
based O
approaches O
, O
which O
induced O
an O
initial O
phrase O
- O
table O
through O
cross Method
- Method
lingual Method
embedding Method
mappings Method
, O
combined O
it O
with O
an O
n Method
- Method
gram Method
language Method
model Method
, O
and O
further O
improved O
the O
system O
through O
iterative Method
back Method
- Method
translation Method
lample2018phrase O
, O
artetxe2018usmt O
. O
In O
this O
paper O
, O
we O
develop O
a O
more O
principled O
approach O
to O
unsupervised Task
SMT Task
, O
addressing O
several O
deficiencies O
of O
previous O
systems O
by O
incorporating O
subword O
information O
, O
applying O
a O
theoretically O
well O
founded O
unsupervised Method
tuning Method
method Method
, O
and O
developing O
a O
joint Method
refinement Method
procedure Method
. O
In O
addition O
to O
that O
, O
we O
use O
our O
improved O
SMT Method
approach O
to O
initialize O
an O
unsupervised O
NMT Method
system O
, O
which O
is O
further O
improved O
through O
on O
- O
the O
- O
fly O
back Method
- Method
translation Method
. O
Our O
experiments O
on O
WMT Material
2014 Material
/ Material
2016 Material
French Material
- Material
English Material
and O
German Material
- Material
English Material
show O
the O
effectiveness O
of O
our O
approach O
, O
as O
our O
proposed O
system O
outperforms O
the O
previous O
state O
- O
of O
- O
the O
- O
art O
in O
unsupervised Task
machine Task
translation Task
by O
5 O
- O
7 O
BLEU Metric
points Metric
in O
all O
these O
datasets O
and O
translation O
directions O
. O
Our O
system O
also O
outperforms O
the O
supervised O
WMT Material
2014 O
shared O
task O
winner O
in O
English Material
- Material
to Material
- Material
German Material
, O
and O
is O
around O
2 O
BLEU Metric
points Metric
behind O
it O
in O
the O
rest O
of O
translation Task
directions Task
, O
suggesting O
that O
unsupervised Task
machine Task
translation Task
can O
be O
a O
usable O
alternative O
in O
practical O
settings O
. O
The O
remaining O
of O
this O
paper O
is O
organized O
as O
follows O
. O
Section O
[ O
reference O
] O
first O
discusses O
the O
related O
work O
in O
the O
topic O
. O
Section O
[ O
reference O
] O
then O
describes O
our O
principled Method
unsupervised Method
SMT Method
method Method
, O
while O
Section O
[ O
reference O
] O
discusses O
our O
hybridization Method
method Method
with O
NMT Method
. O
We O
then O
present O
the O
experiments O
done O
and O
the O
results O
obtained O
in O
Section O
[ O
reference O
] O
, O
and O
Section O
[ O
reference O
] O
concludes O
the O
paper O
. O
section O
: O
Related O
work O
Early O
attempts O
to O
build O
machine Task
translation Task
systems Task
with O
monolingual O
corpora O
go O
back O
to O
statistical Task
decipherment Task
ravi2011deciphering O
, O
dou2012large O
. O
These O
methods O
see O
the O
source O
language O
as O
ciphertext O
produced O
by O
a O
noisy Method
channel Method
model Method
that O
first O
generates O
the O
original O
English O
text O
and O
then O
probabilistically O
replaces O
the O
words O
in O
it O
. O
The O
English Method
generative Method
process Method
is O
modeled O
using O
an O
n Method
- Method
gram Method
language Method
model Method
, O
and O
the O
channel Method
model Method
parameters Method
are O
estimated O
using O
either O
expectation Method
maximization Method
or O
Bayesian Method
inference Method
. O
This O
basic O
approach O
was O
later O
improved O
by O
incorporating O
syntactic O
knowledge O
dou2013dependency O
and O
word O
embeddings O
dou2015unifying O
. O
Nevertheless O
, O
these O
methods O
were O
only O
shown O
to O
work O
in O
limited O
settings O
, O
being O
most O
often O
evaluated O
in O
word Task
- Task
level Task
translation Task
. O
More O
recently O
, O
the O
task O
got O
a O
renewed O
interest O
after O
the O
concurrent O
work O
of O
artetxe2018unmt O
and O
lample2018unsupervised O
on O
unsupervised Method
NMT Method
which O
, O
for O
the O
first O
time O
, O
obtained O
promising O
results O
in O
standard O
machine Task
translation Task
benchmarks Task
using O
monolingual O
corpora O
only O
. O
Both O
methods O
build O
upon O
the O
recent O
work O
on O
unsupervised Task
cross Task
- Task
lingual Task
embedding Task
mappings Task
, O
which O
independently O
train O
word O
embeddings O
in O
two O
languages O
and O
learn O
a O
linear Method
transformation Method
to O
map O
them O
to O
a O
shared O
space O
through O
self Method
- Method
learning Method
artetxe2017learning O
, O
artetxe2018robust Method
or Method
adversarial Method
training Method
conneau2018word O
. O
The O
resulting O
cross Method
- Method
lingual Method
embeddings Method
are O
used O
to O
initialize O
a O
shared Method
encoder Method
for O
both O
languages O
, O
and O
the O
entire O
system O
is O
trained O
using O
a O
combination O
of O
denoising Method
autoencoding Method
, O
back Method
- Method
translation Method
and O
, O
in O
the O
case O
of O
lample2018unsupervised Method
, Method
adversarial Method
training Method
. O
This O
method O
was O
further O
improved O
by O
yang2018unsupervised O
, O
who O
use O
two O
language Method
- Method
specific Method
encoders Method
sharing O
only O
a O
subset O
of O
their O
parameters O
, O
and O
incorporate O
a O
local Method
and Method
a Method
global Method
generative Method
adversarial Method
network Method
. O
Nevertheless O
, O
it O
was O
later O
argued O
that O
the O
modular Method
architecture Method
of O
phrase O
- O
based O
SMT Method
was O
more O
suitable O
for O
this O
problem O
, O
and O
lample2018phrase O
and O
artetxe2018usmt O
adapted O
the O
same O
principles O
discussed O
above O
to O
train O
an O
unsupervised O
SMT Method
model O
, O
obtaining O
large O
improvements O
over O
the O
original O
unsupervised O
NMT Method
systems O
. O
More O
concretely O
, O
both O
approaches O
learn O
cross Method
- Method
lingual Method
n Method
- Method
gram Method
embeddings Method
from O
monolingual O
corpora O
based O
on O
the O
mapping Method
method Method
discussed O
earlier O
, O
and O
use O
them O
to O
induce O
an O
initial O
phrase O
- O
table O
that O
is O
combined O
with O
an O
n Method
- Method
gram Method
language Method
model Method
and O
a O
distortion Method
model Method
. O
This O
initial O
system O
is O
then O
refined O
through O
iterative Method
back Method
- Method
translation Method
sennrich2016improving O
which O
, O
in O
the O
case O
of O
artetxe2018usmt O
, O
is O
preceded O
by O
an O
unsupervised Method
tuning Method
step Method
. O
Our O
work O
identifies O
some O
deficiencies O
in O
these O
previous O
systems O
, O
and O
proposes O
a O
more O
principled Method
approach Method
to O
unsupervised Task
SMT Task
that O
incorporates O
subword O
information O
, O
uses O
a O
theoretically O
better O
founded O
unsupervised Method
tuning Method
method Method
, O
and O
applies O
a O
joint Method
refinement Method
procedure Method
, O
outperforming O
these O
previous O
systems O
by O
a O
substantial O
margin O
. O
Very O
recently O
, O
some O
authors O
have O
tried O
to O
combine O
both O
SMT Method
and O
NMT Method
to O
build O
hybrid Task
unsupervised Task
machine Task
translation Task
systems Task
. O
This O
idea O
was O
already O
explored O
by O
lample2018phrase O
, O
who O
aided O
the O
training O
of O
their O
unsupervised O
NMT Method
system O
by O
combining O
standard O
back Method
- Method
translation Method
with O
synthetic O
parallel O
data O
generated O
by O
unsupervised Task
SMT Task
. O
marie2018unsupervised O
go O
further O
and O
use O
synthetic O
parallel O
data O
from O
unsupervised Task
SMT Task
to O
train O
a O
conventional O
NMT Method
system O
from O
scratch O
. O
The O
resulting O
NMT Method
model O
is O
then O
used O
to O
augment O
the O
synthetic O
parallel O
corpus O
through O
back Method
- Method
translation Method
, O
and O
a O
new O
NMT Method
model O
is O
trained O
on O
top O
of O
it O
from O
scratch O
, O
repeating O
the O
process O
iteratively O
. O
ren2019unsupervised O
follow O
a O
similar O
approach O
, O
but O
use O
SMT Method
as O
posterior Method
regularization Method
at O
each O
iteration O
. O
As O
shown O
later O
in O
our O
experiments O
, O
our O
proposed O
NMT Method
hybridization O
obtains O
substantially O
larger O
absolute O
gains O
than O
all O
these O
previous O
approaches O
, O
even O
if O
our O
initial O
SMT Method
system O
is O
stronger O
and O
thus O
more O
challenging O
to O
improve O
upon O
. O
section O
: O
Principled O
unsupervised O
SMT Method
Phrase O
- O
based O
SMT Method
is O
formulated O
as O
a O
log Method
- Method
linear Method
combination Method
of O
several O
statistical Method
models Method
: O
a O
translation Method
model Method
, O
a O
language Method
model Method
, O
a O
reordering Method
model Method
and O
a O
word Method
/ Method
phrase Method
penalty Method
. O
As O
such O
, O
building O
an O
unsupervised O
SMT Method
system O
requires O
learning O
these O
different O
components O
from O
monolingual O
corpora O
. O
As O
it O
turns O
out O
, O
this O
is O
straightforward O
for O
most O
of O
them O
: O
the O
language Method
model Method
is O
learned O
from O
monolingual O
corpora O
by O
definition O
; O
the O
word O
and O
phrase O
penalties O
are O
parameterless O
; O
and O
one O
can O
drop O
the O
standard O
lexical Method
reordering Method
model Method
at O
a O
small O
cost O
and O
do O
with O
the O
distortion Method
model Method
alone O
, O
which O
is O
also O
parameterless O
. O
This O
way O
, O
the O
main O
challenge O
left O
is O
learning O
the O
translation Method
model Method
, O
that O
is O
, O
building O
the O
phrase O
- O
table O
. O
Our O
proposed O
method O
starts O
by O
building O
an O
initial O
phrase O
- O
table O
through O
cross Method
- Method
lingual Method
embedding Method
mappings Method
( O
Section O
[ O
reference O
] O
) O
. O
This O
initial O
phrase O
- O
table O
is O
then O
extended O
by O
incorporating O
subword O
information O
, O
addressing O
one O
of O
the O
main O
limitations O
of O
previous O
unsupervised O
SMT Method
systems O
( O
Section O
[ O
reference O
] O
) O
. O
Having O
done O
that O
, O
we O
adjust O
the O
weights O
of O
the O
underlying O
log Method
- Method
linear Method
model Method
through O
a O
novel O
unsupervised Method
tuning Method
procedure Method
( O
Section O
[ O
reference O
] O
) O
. O
Finally O
, O
we O
further O
improve O
the O
system O
by O
jointly O
refining O
two O
models O
in O
opposite O
directions O
( O
Section O
[ O
reference O
] O
) O
. O
subsection O
: O
Initial O
phrase O
- O
table O
So O
as O
to O
build O
our O
initial O
phrase O
- O
table O
, O
we O
follow O
artetxe2018usmt O
and O
learn O
n Method
- Method
gram Method
embeddings Method
for O
each O
language O
independently O
, O
map O
them O
to O
a O
shared O
space O
through O
self Method
- Method
learning Method
, O
and O
use O
the O
resulting O
cross Method
- Method
lingual Method
embeddings Method
to O
extract O
and O
score O
phrase O
pairs O
. O
More O
concretely O
, O
we O
train O
our O
n Method
- Method
gram Method
embeddings Method
using O
phrase2vechttps: O
// O
github.com O
/ O
artetxem O
/ O
phrase2vec O
, O
a O
simple O
extension O
of O
skip Method
- Method
gram Method
that O
applies O
the O
standard O
negative Method
sampling Method
loss Method
of O
mikolov2013distributed O
to O
bigram O
- O
context O
and O
trigram O
- O
context O
pairs O
in O
addition O
to O
the O
usual O
word O
- O
context O
pairs O
. O
Having O
done O
that O
, O
we O
map O
the O
embeddings O
to O
a O
cross O
- O
lingual O
space O
using O
VecMap Method
with O
identical Method
initialization Method
artetxe2018robust O
, O
which O
builds O
an O
initial O
solution O
by O
aligning O
identical O
words O
and O
iteratively O
improves O
it O
through O
self Method
- Method
learning Method
. O
Finally O
, O
we O
extract O
translation O
candidates O
by O
taking O
the O
100 O
nearest O
- O
neighbors O
of O
each O
source O
phrase O
, O
and O
score O
them O
by O
applying O
the O
softmax Method
function Method
over O
their O
cosine O
similarities O
: O
where O
the O
temperature O
is O
estimated O
using O
maximum Method
likelihood Method
estimation Method
over O
a O
dictionary O
induced O
in O
the O
reverse O
direction O
. O
In O
addition O
to O
the O
phrase O
translation O
probabilities O
in O
both O
directions O
, O
the O
forward O
and O
reverse O
lexical O
weightings O
are O
also O
estimated O
by O
aligning O
each O
word O
in O
the O
target O
phrase O
with O
the O
one O
in O
the O
source O
phrase O
most O
likely O
generating O
it O
, O
and O
taking O
the O
product O
of O
their O
respective O
translation O
probabilities O
. O
The O
reader O
is O
referred O
to O
artetxe2018usmt O
for O
more O
details O
. O
subsection O
: O
Adding O
subword O
information O
An O
inherent O
limitation O
of O
existing O
unsupervised O
SMT Method
systems O
is O
that O
words O
are O
taken O
as O
atomic O
units O
, O
making O
it O
impossible O
to O
exploit O
character O
- O
level O
information O
. O
This O
is O
reflected O
in O
the O
known O
difficulty O
of O
these O
models O
to O
translate O
named O
entities O
, O
as O
it O
is O
very O
challenging O
to O
discriminate O
among O
related O
proper O
nouns O
based O
on O
distributional O
information O
alone O
, O
yielding O
to O
translation O
errors O
like O
‘ O
‘ O
Sunday O
Telegraph O
’ O
’ O
‘ O
‘ O
The O
Times O
of O
London O
’ O
’ O
artetxe2018usmt O
. O
So O
as O
to O
overcome O
this O
issue O
, O
we O
propose O
to O
incorporate O
subword O
information O
once O
the O
initial O
alignment O
is O
done O
at O
the O
word O
/ O
phrase O
level O
. O
For O
that O
purpose O
, O
we O
add O
two O
additional O
weights O
to O
the O
initial O
phrase O
- O
table O
that O
are O
analogous O
to O
the O
lexical O
weightings O
, O
but O
use O
a O
character O
- O
level O
similarity Method
function Method
instead O
of O
word O
translation O
probabilities O
: O
where O
guarantees O
a O
minimum Metric
similarity Metric
score Metric
, O
as O
we O
want O
to O
favor O
translation O
candidates O
that O
are O
similar O
at O
the O
character O
level O
without O
excessively O
penalizing O
those O
that O
are O
not O
. O
In O
our O
case O
, O
we O
use O
a O
simple O
similarity Method
function Method
that O
normalizes O
the O
Levenshtein O
distance O
levenshtein1966binary O
by O
the O
length O
of O
the O
words O
: O
We O
leave O
the O
exploration O
of O
more O
elaborated O
similarity Method
functions Method
and O
, O
in O
particular O
, O
learnable Metric
metrics Metric
mccallum2005conditional O
, O
for O
future O
work O
. O
subsection O
: O
Unsupervised Method
tuning Method
Having O
trained O
the O
underlying O
statistical Method
models Method
independently O
, O
SMT Method
tuning O
aims O
to O
adjust O
the O
weights O
of O
their O
resulting O
log Method
- Method
linear Method
combination Method
to O
optimize O
some O
evaluation Metric
metric Metric
like O
BLEU Metric
in O
a O
parallel O
validation O
corpus O
, O
which O
is O
typically O
done O
through O
Minimum Metric
Error Metric
Rate Metric
Training Metric
or O
MERT Metric
och2003MERT O
. O
Needless O
to O
say O
, O
this O
can O
not O
be O
done O
in O
strictly O
unsupervised Task
settings Task
, O
but O
we O
argue O
that O
it O
would O
still O
be O
desirable O
to O
optimize O
some O
unsupervised Metric
criterion Metric
that O
is O
expected O
to O
correlate O
well O
with O
test O
performance O
. O
Unfortunately O
, O
neither O
of O
the O
existing O
unsupervised O
SMT Method
systems O
do O
so O
: O
artetxe2018usmt O
use O
a O
heuristic O
that O
builds O
two O
initial O
models O
in O
opposite O
directions O
, O
uses O
one O
of O
them O
to O
generates O
a O
synthetic O
parallel O
corpus O
through O
back Method
- Method
translation Method
sennrich2016improving O
, O
and O
applies O
MERT Metric
to O
tune O
the O
model O
in O
the O
reverse O
direction O
, O
iterating O
until O
convergence O
, O
whereas O
lample2018phrase O
do O
not O
perform O
any O
tuning O
at O
all O
. O
In O
what O
follows O
, O
we O
propose O
a O
more O
principled O
approach O
to O
tuning Task
that O
defines O
an O
unsupervised Metric
criterion Metric
and O
an O
optimization Method
procedure Method
that O
is O
guaranteed O
to O
converge O
to O
a O
local O
optimum O
of O
it O
. O
Inspired O
by O
the O
previous O
work O
on O
CycleGANs Method
zhu2017unpaired O
and O
dual Method
learning Method
he2016dual O
, O
our O
method O
takes O
two O
initial O
models O
in O
opposite O
directions O
, O
and O
defines O
an O
unsupervised Method
optimization Method
objective Method
that O
combines O
a O
cyclic Method
consistency Method
loss Method
and O
a O
language Method
model Method
loss Method
over O
the O
two O
monolingual O
corpora O
and O
: O
The O
cyclic O
consistency O
loss O
captures O
the O
intuition O
that O
the O
translation O
of O
a O
translation O
should O
be O
close O
to O
the O
original O
text O
. O
So O
as O
to O
quantify O
this O
, O
we O
take O
a O
monolingual O
corpus O
in O
the O
source O
language O
, O
translate O
it O
to O
the O
target O
language O
and O
back O
to O
the O
source O
language O
, O
and O
compute O
its O
BLEU Metric
score Metric
taking O
the O
original O
text O
as O
reference O
: O
At O
the O
same O
time O
, O
the O
language Method
model Method
loss Method
captures O
the O
intuition O
that O
machine Task
translation Task
should O
produce O
fluent O
text O
in O
the O
target O
language O
. O
For O
that O
purpose O
, O
we O
estimate O
the O
per O
- O
word O
entropy O
in O
the O
target O
language O
corpus O
using O
an O
n Method
- Method
gram Method
language Method
model Method
, O
and O
penalize O
higher O
per O
- O
word O
entropies O
in O
machine O
translated O
text O
as O
follows O
: O
where O
the O
length O
penalty O
penalizes O
excessively O
long O
translations O
: O
So O
as O
to O
minimize O
the O
combined O
loss O
function O
, O
we O
adapt O
MERT Metric
to O
jointly O
optimize O
the O
parameters O
of O
the O
two O
models O
. O
In O
its O
basic O
form O
, O
MERT Metric
approximates O
the O
search O
space O
for O
each O
source O
sentence O
through O
an O
n O
- O
best O
list O
, O
and O
performs O
a O
form O
of O
coordinate Method
descent Method
by O
computing O
the O
optimal O
value O
for O
each O
parameter O
through O
an O
efficient O
line Method
search Method
method Method
and O
greedily O
taking O
the O
step O
that O
leads O
to O
the O
largest O
gain O
. O
The O
process O
is O
repeated O
iteratively O
until O
convergence O
, O
augmenting O
the O
n O
- O
best O
list O
with O
the O
updated O
parameters O
at O
each O
iteration O
so O
as O
to O
obtain O
a O
better O
approximation O
of O
the O
full O
search O
space O
. O
Given O
that O
our O
optimization Task
objective Task
combines O
two O
translation Method
systems Method
, O
this O
would O
require O
generating O
an O
n O
- O
best O
list O
for O
first O
and O
, O
for O
each O
entry O
on O
it O
, O
generating O
a O
new O
n O
- O
best O
list O
with O
, O
yielding O
a O
combined O
n O
- O
best O
list O
with O
entries O
. O
So O
as O
to O
make O
it O
more O
efficient O
, O
we O
propose O
an O
alternating Method
optimization Method
approach Method
where O
we O
fix O
the O
parameters O
of O
one O
model O
and O
optimize O
the O
other O
with O
standard O
MERT Metric
. O
Thanks O
to O
this O
, O
we O
do O
not O
need O
to O
expand O
the O
search O
space O
of O
the O
fixed Method
model Method
, O
so O
we O
can O
do O
with O
an O
n O
- O
best O
list O
of O
entries O
alone O
. O
Having O
done O
that O
, O
we O
fix O
the O
parameters O
of O
the O
opposite O
model O
and O
optimize O
the O
other O
, O
iterating O
until O
convergence O
. O
subsection O
: O
Joint Task
refinement Task
Constrained O
by O
the O
lack O
of O
parallel O
corpora O
, O
the O
procedure O
described O
so O
far O
makes O
important O
simplifications O
that O
could O
compromise O
its O
potential O
performance O
: O
its O
phrase O
- O
table O
is O
somewhat O
unnatural O
( O
e.g. O
the O
translation O
probabilities O
are O
estimated O
from O
cross Method
- Method
lingual Method
embeddings Method
rather O
than O
actual O
frequency O
counts O
) O
and O
it O
lacks O
a O
lexical Method
reordering Method
model Method
altogether O
. O
So O
as O
to O
overcome O
this O
issue O
, O
existing O
unsupervised O
SMT Method
methods O
generate O
a O
synthetic O
parallel O
corpus O
through O
back Method
- Method
translation Method
and O
use O
it O
to O
train O
a O
standard O
SMT Method
system O
from O
scratch O
, O
iterating O
until O
convergence O
. O
An O
obvious O
drawback O
of O
this O
approach O
is O
that O
the O
back O
- O
translated O
side O
will O
contain O
ungrammatical O
n O
- O
grams O
that O
will O
end O
up O
in O
the O
induced O
phrase O
- O
table O
. O
One O
could O
argue O
that O
this O
should O
be O
innocuous O
as O
long O
as O
the O
ungrammatical O
n O
- O
grams O
are O
in O
the O
source O
side O
, O
as O
they O
should O
never O
occur O
in O
real O
text O
and O
their O
corresponding O
entries O
in O
the O
phrase O
- O
table O
should O
therefore O
not O
be O
used O
. O
However O
, O
ungrammatical O
source O
phrases O
do O
ultimately O
affect O
the O
estimation O
of O
the O
backward O
translation O
probabilities O
, O
including O
those O
of O
grammatical O
phrases O
. O
For O
instance O
, O
let O
’s O
say O
that O
the O
target O
phrase O
‘ O
‘ O
dos O
gatos O
’ O
’ O
has O
been O
aligned O
10 O
times O
with O
‘ O
‘ O
two O
cats O
’ O
’ O
and O
90 O
times O
with O
‘ O
‘ O
two O
cat O
’ O
’ O
. O
While O
the O
ungrammatical O
phrase O
- O
table O
entry O
two O
cat O
- O
dos O
gatos O
should O
never O
be O
picked O
, O
the O
backward Method
probability Method
estimation Method
of O
two O
cats O
- O
dos O
gatos O
is O
still O
affected O
by O
it O
( O
it O
would O
be O
0.1 O
instead O
of O
1.0 O
in O
this O
example O
) O
. O
We O
argue O
that O
, O
ultimately O
, O
the O
backward Method
probability Method
estimations Method
can O
only O
be O
meaningful O
when O
all O
source O
phrases O
are O
grammatical O
( O
so O
the O
probabilities O
of O
all O
plausible O
translations O
sum O
to O
one O
) O
and O
, O
similarly O
, O
the O
forward Method
probability Method
estimations Method
can O
only O
be O
meaningful O
when O
all O
target O
phrases O
are O
grammatical O
. O
Following O
this O
observation O
, O
we O
propose O
an O
alternative O
approach O
that O
jointly O
refines O
both O
translation O
directions O
. O
More O
concretely O
, O
we O
use O
the O
initial O
systems O
to O
build O
two O
synthetic O
corpora O
in O
opposite O
directions O
. O
Having O
done O
that O
, O
we O
independently O
extract O
phrase O
pairs O
from O
each O
synthetic O
corpus O
, O
and O
build O
a O
phrase O
- O
table O
by O
taking O
their O
intersection O
. O
The O
forward O
probabilities O
are O
estimated O
in O
the O
parallel O
corpus O
with O
the O
synthetic O
source O
side O
, O
while O
the O
backward O
probabilities O
are O
estimated O
in O
the O
one O
with O
the O
synthetic O
target O
side O
. O
This O
does O
not O
only O
guarantee O
that O
the O
probability O
estimates O
are O
meaningful O
as O
discussed O
previously O
, O
but O
it O
also O
discards O
the O
ungrammatical O
phrases O
altogether O
, O
as O
both O
the O
source O
and O
the O
target O
n O
- O
grams O
must O
have O
occurred O
in O
the O
original O
monolingual O
texts O
to O
be O
present O
in O
the O
resulting O
phrase O
- O
table O
. O
We O
repeat O
this O
process O
for O
a O
total O
of O
3 O
iterations O
. O
section O
: O
NMT Method
hybridization O
While O
the O
rigid O
and O
modular O
design O
of O
SMT Method
provides O
a O
very O
suitable O
framework O
for O
unsupervised Task
machine Task
translation Task
, O
NMT Method
has O
shown O
to O
be O
a O
fairly O
superior O
paradigm O
in O
supervised Task
settings Task
, O
outperforming O
SMT Method
by O
a O
large O
margin O
in O
standard O
benchmarks O
. O
As O
such O
, O
the O
choice O
of O
SMT Method
over O
NMT Method
also O
imposes O
a O
hard O
ceiling O
on O
the O
potential O
performance O
of O
these O
approaches O
, O
as O
unsupervised O
SMT Method
systems O
inherit O
the O
very O
same O
limitations O
of O
their O
supervised Method
counterparts Method
( O
e.g. O
the O
locality Task
and Task
sparsity Task
problems Task
) O
. O
For O
that O
reason O
, O
we O
argue O
that O
SMT Method
provides O
a O
more O
appropriate O
architecture O
to O
find O
an O
initial O
alignment O
between O
the O
languages O
, O
but O
NMT Method
is O
ultimately O
a O
better O
architecture O
to O
model O
the O
translation Task
process Task
. O
Following O
this O
observation O
, O
we O
propose O
a O
hybrid Method
approach Method
that O
uses O
unsupervised Task
SMT Task
to O
warm O
up O
a O
dual O
NMT Method
model O
trained O
through O
iterative Method
back Method
- Method
translation Method
. O
More O
concretely O
, O
we O
first O
train O
two O
SMT Method
systems O
in O
opposite O
directions O
as O
described O
in O
Section O
[ O
reference O
] O
, O
and O
use O
them O
to O
assist O
the O
training O
of O
another O
two O
NMT Method
systems O
in O
opposite O
directions O
. O
These O
NMT Method
systems O
are O
trained O
following O
an O
iterative O
process O
where O
, O
at O
each O
iteration O
, O
we O
alternately O
update O
the O
model O
in O
each O
direction O
by O
performing O
a O
single O
pass O
over O
a O
synthetic O
parallel O
corpus O
built O
through O
back Method
- Method
translation Method
sennrich2016improving O
. O
In O
the O
first O
iteration O
, O
the O
synthetic O
parallel O
corpus O
is O
entirely O
generated O
by O
the O
SMT Method
system O
in O
the O
opposite O
direction O
but O
, O
as O
training O
progresses O
and O
the O
NMT Method
models O
get O
better O
, O
we O
progressively O
switch O
to O
a O
synthetic O
parallel O
corpus O
generated O
by O
the O
reverse O
NMT Method
model O
. O
More O
concretely O
, O
iteration Method
uses O
synthetic O
parallel O
sentences O
from O
the O
reverse O
SMT Method
system O
, O
where O
the O
parameter O
controls O
the O
number O
of O
transition O
iterations O
from O
SMT Method
to O
NMT Method
back Method
- Method
translation Method
. O
The O
remaining O
sentences O
are O
generated O
by O
the O
reverse O
NMT Method
model O
. O
Inspired O
by O
edunov2018understanding O
, O
we O
use O
greedy Method
decoding Method
for O
half O
of O
them O
, O
which O
produces O
more O
fluent O
and O
predictable O
translations O
, O
and O
random Method
sampling Method
for O
the O
other O
half O
, O
which O
produces O
more O
varied O
translations O
. O
In O
our O
experiments O
, O
we O
use O
and O
, O
and O
perform O
a O
total O
of O
60 O
such O
iterations O
. O
At O
test O
time O
, O
we O
use O
beam Method
search Method
decoding Method
with O
an O
ensemble O
of O
all O
checkpoints O
from O
every O
10 O
iterations O
. O
section O
: O
Experiments O
and O
results O
SMT Method
+ O
NMT Method
In O
order O
to O
make O
our O
experiments O
comparable O
to O
previous O
work O
, O
we O
use O
the O
French Material
- Material
English Material
and O
German Material
- Material
English Material
datasets O
from O
the O
WMT Material
2014 Material
shared Material
task Material
. O
More O
concretely O
, O
our O
training O
data O
consists O
of O
the O
concatenation O
of O
all O
News Material
Crawl Material
monolingual Material
corpora Material
from O
2007 O
to O
2013 O
, O
which O
make O
a O
total O
of O
749 O
million O
tokens O
in O
French O
, O
1 O
, O
606 O
millions O
in O
German Material
, O
and O
2 O
, O
109 O
millions O
in O
English Material
, O
from O
which O
we O
take O
a O
random O
subset O
of O
2 O
, O
000 O
sentences O
for O
tuning O
( O
Section O
[ O
reference O
] O
) O
. O
Preprocessing Task
is O
done O
using O
standard O
Moses Method
tools O
, O
and O
involves O
punctuation Method
normalization Method
, O
tokenization Method
with O
aggressive Method
hyphen Method
splitting Method
, O
and O
truecasing Method
. O
Our O
SMT Method
implementation O
is O
based O
on O
Moses Method
, O
and O
we O
use O
the O
KenLM Method
heafield2013scalable O
tool O
included O
in O
it O
to O
estimate O
our O
5 Method
- Method
gram Method
language Method
model Method
with O
modified O
Kneser Method
- Method
Ney Method
smoothing Method
. O
Our O
unsupervised Method
tuning Method
implementation Method
is O
based O
on O
Z O
- O
MERT Metric
zaidan2009zmert O
, O
and O
we O
use O
FastAlign Method
dyer2013simple O
for O
word Task
alignment Task
within O
the O
joint Method
refinement Method
procedure Method
. O
Finally O
, O
we O
use O
the O
big Method
transformer Method
implementation Method
from O
fairseq Method
for O
our O
NMT Method
system O
, O
training O
with O
a O
total O
batch O
size O
of O
20 O
, O
000 O
tokens O
across O
8 O
GPUs O
with O
the O
exact O
same O
hyperparameters O
as O
ott2018scaling O
. O
We O
use O
newstest2014 O
as O
our O
test O
set O
for O
French Material
- Material
English Material
, O
and O
both O
newstest2014 O
and O
newstest2016 O
( O
from O
WMT Material
2016 Material
) O
for O
German Material
- Material
English Material
. O
Following O
common O
practice O
, O
we O
report O
tokenized Metric
BLEU Metric
scores Metric
as O
computed O
by O
the O
multi Method
- Method
bleu.perl Method
script Method
included O
in O
Moses Method
. O
In O
addition O
to O
that O
, O
we O
also O
report O
detokenized Metric
BLEU Metric
scores Metric
as O
computed O
by O
SacreBLEU O
post2018call O
, O
which O
is O
equivalent O
to O
the O
official O
mteval O
- O
v13a.pl O
script O
. O
We O
next O
present O
the O
results O
of O
our O
proposed O
system O
in O
comparison O
to O
previous O
work O
in O
Section O
[ O
reference O
] O
. O
Section O
[ O
reference O
] O
then O
compares O
the O
obtained O
results O
to O
those O
of O
different O
supervised Method
systems Method
. O
Finally O
, O
Section O
[ O
reference O
] O
presents O
some O
translation O
examples O
from O
our O
system O
. O
subsection O
: O
Main O
results O
Table O
[ O
reference O
] O
reports O
the O
results O
of O
the O
proposed O
system O
in O
comparison O
to O
previous O
work O
. O
As O
it O
can O
be O
seen O
, O
our O
full O
system O
obtains O
the O
best O
published O
results O
in O
all O
cases O
, O
outperforming O
the O
previous O
state O
- O
of O
- O
the O
- O
art O
by O
5 O
- O
7 O
BLEU Metric
points Metric
in O
all O
datasets O
and O
translation O
directions O
. O
A O
substantial O
part O
of O
this O
improvement O
comes O
from O
our O
more O
principled O
unsupervised O
SMT Method
approach O
, O
which O
outperforms O
all O
previous O
SMT Method
- O
based O
systems O
by O
around O
2 O
BLEU Metric
points Metric
. O
Nevertheless O
, O
it O
is O
the O
NMT Method
hybridization O
that O
brings O
the O
largest O
gains O
, O
improving O
the O
results O
of O
this O
initial O
SMT Method
systems O
by O
5 O
- O
9 O
BLEU Metric
points Metric
. O
As O
shown O
in O
Table O
[ O
reference O
] O
, O
our O
absolute O
gains O
are O
considerably O
larger O
than O
those O
of O
previous O
hybridization Method
methods Method
, O
even O
if O
our O
initial O
SMT Method
system O
is O
substantially O
better O
and O
thus O
more O
difficult O
to O
improve O
upon O
. O
This O
way O
, O
our O
initial O
SMT Method
system O
is O
about O
4 O
- O
5 O
BLEU Metric
points Metric
above O
that O
of O
marie2018unsupervised O
, O
yet O
our O
absolute O
gain O
on O
top O
of O
it O
is O
around O
2.5 O
BLEU Metric
points Metric
higher O
. O
When O
compared O
to O
lample2018phrase O
, O
we O
obtain O
an O
absolute O
gain O
of O
5 O
- O
6 O
BLEU Metric
points Metric
in O
both O
French Material
- Material
English Material
directions O
while O
they O
do O
not O
get O
any O
clear O
improvement O
, O
and O
we O
obtain O
an O
improvement O
of O
7 O
- O
9 O
BLEU Metric
points Metric
in O
both O
German Material
- Material
English Material
directions O
, O
in O
contrast O
with O
the O
2.3 O
BLEU Metric
points Metric
they O
obtain O
. O
More O
generally O
, O
it O
is O
interesting O
that O
pure O
SMT Method
systems O
perform O
better O
than O
pure O
NMT Method
systems O
, O
yet O
the O
best O
results O
are O
obtained O
by O
initializing O
an O
NMT Method
system O
with O
an O
SMT Method
system O
. O
This O
suggests O
that O
the O
rigid Method
and Method
modular Method
architecture Method
of O
SMT Method
might O
be O
more O
suitable O
to O
find O
an O
initial O
alignment O
between O
the O
languages O
, O
but O
the O
final O
system O
should O
be O
ultimately O
based O
on O
NMT Method
for O
optimal O
results O
. O
subsection O
: O
Comparison O
with O
supervised Method
systems Method
So O
as O
to O
put O
our O
results O
into O
perspective O
, O
Table O
[ O
reference O
] O
reports O
the O
results O
of O
different O
supervised Method
systems Method
in O
the O
same O
WMT Material
2014 Material
test Material
set Material
. O
More O
concretely O
, O
we O
include O
the O
best O
results O
from O
the O
shared O
task O
itself O
, O
which O
reflect O
the O
state O
- O
of O
- O
the O
- O
art O
in O
machine Task
translation Task
back O
in O
2014 O
; O
those O
of O
vaswani2017attention O
, O
who O
introduced O
the O
now O
predominant O
transformer Method
architecture Method
; O
and O
those O
of O
edunov2018understanding Method
, O
who O
apply O
back Method
- Method
translation Method
at O
a O
large O
scale O
and O
hold O
the O
current O
best O
results O
in O
the O
test O
set O
. O
As O
it O
can O
be O
seen O
, O
our O
unsupervised Method
system Method
outperforms O
the O
WMT Material
2014 O
shared O
task O
winner O
in O
English Material
- Material
to Material
- Material
German Material
, O
and O
is O
around O
2 O
BLEU Metric
points Metric
behind O
it O
in O
the O
other O
translation O
directions O
. O
This O
shows O
that O
unsupervised Task
machine Task
translation Task
is O
already O
competitive O
with O
the O
state O
- O
of O
- O
the O
- O
art O
in O
supervised Task
machine Task
translation Task
in O
2014 O
. O
While O
the O
field O
of O
machine Task
translation Task
has O
undergone O
great O
progress O
in O
the O
last O
5 O
years O
, O
and O
the O
gap O
between O
our O
unsupervised Method
system Method
and O
the O
current O
state O
- O
of O
- O
the O
- O
art O
in O
supervised Task
machine Task
translation Task
is O
still O
large O
as O
reflected O
by O
the O
other O
results O
, O
this O
suggests O
that O
unsupervised Task
machine Task
translation Task
can O
be O
a O
usable O
alternative O
in O
practical O
settings O
. O
subsection O
: O
Qualitative O
results O
Table O
[ O
reference O
] O
shows O
some O
translation O
examples O
from O
our O
proposed O
system O
in O
comparison O
to O
those O
reported O
by O
artetxe2018usmt O
. O
We O
choose O
the O
exact O
same O
sentences O
reported O
by O
artetxe2018usmt O
, O
which O
were O
randomly O
taken O
from O
newstest2014 O
, O
so O
they O
should O
be O
representative O
of O
the O
general O
behavior O
of O
both O
systems O
. O
While O
not O
perfect O
, O
our O
proposed O
system O
produces O
generally O
fluent O
translations O
that O
accurately O
capture O
the O
meaning O
of O
the O
original O
text O
. O
Just O
in O
line O
with O
our O
quantitative O
results O
, O
this O
suggests O
that O
unsupervised Task
machine Task
translation Task
can O
be O
a O
usable O
alternative O
in O
practical O
settings O
. O
Compared O
to O
artetxe2018usmt O
, O
our O
translations O
are O
generally O
more O
fluent O
, O
which O
is O
not O
surprising O
given O
that O
they O
are O
produced O
by O
an O
NMT Method
system O
rather O
than O
an O
SMT Method
system O
. O
In O
addition O
to O
that O
, O
the O
system O
of O
artetxe2018usmt O
has O
some O
adequacy O
issues O
when O
translating O
named O
entities O
and O
numerals O
( O
e.g. O
34 O
32 O
, O
Sunday O
Telegraph O
The O
Times O
of O
London O
) O
, O
which O
we O
do O
not O
observe O
for O
our O
proposed O
system O
in O
these O
examples O
. O
section O
: O
Conclusions O
and O
future O
work O
In O
this O
paper O
, O
we O
identify O
several O
deficiencies O
in O
previous O
unsupervised O
SMT Method
systems O
, O
and O
propose O
a O
more O
principled O
approach O
that O
addresses O
them O
by O
incorporating O
subword O
information O
, O
using O
a O
theoretically O
well O
founded O
unsupervised Method
tuning Method
method Method
, O
and O
developing O
a O
joint Method
refinement Method
procedure Method
. O
In O
addition O
to O
that O
, O
we O
use O
our O
improved O
SMT Method
approach O
to O
initialize O
a O
dual O
NMT Method
model O
that O
is O
further O
improved O
through O
on O
- O
the O
- O
fly O
back Method
- Method
translation Method
. O
Our O
experiments O
show O
the O
effectiveness O
of O
our O
approach O
, O
as O
we O
improve O
the O
previous O
state O
- O
of O
- O
the O
- O
art O
in O
unsupervised Task
machine Task
translation Task
by O
5 O
- O
7 O
BLEU Metric
points Metric
in O
French Material
- Material
English Material
and O
German Material
- Material
English Material
WMT Material
2014 Material
and O
2016 Material
. O
In O
the O
future O
, O
we O
would O
like O
to O
explore O
learnable O
similarity Method
functions Method
like O
the O
one O
proposed O
by O
mccallum2005conditional O
to O
compute O
the O
character O
- O
level O
scores O
in O
our O
initial O
phrase O
- O
table O
. O
In O
addition O
to O
that O
, O
we O
would O
like O
to O
incorporate O
a O
language Method
modeling Method
loss Method
during O
NMT Method
training O
similar O
to O
he2016dual O
. O
Finally O
, O
we O
would O
like O
to O
adapt O
our O
approach O
to O
more O
relaxed O
scenarios O
with O
multiple O
languages O
and O
/ O
or O
small O
parallel O
corpora O
. O
section O
: O
Acknowledgments O
This O
research O
was O
partially O
supported O
by O
the O
Spanish O
MINECO O
( O
UnsupNMT O
TIN2017‐91692‐EXP O
, O
cofunded O
by O
EU O
FEDER O
) O
, O
the O
UPV O
/ O
EHU O
( O
excellence O
research O
group O
) O
, O
and O
the O
NVIDIA O
GPU O
grant O
program O
. O
Mikel O
Artetxe O
enjoys O
a O
doctoral O
grant O
from O
the O
Spanish O
MECD O
. O
bibliography O
: O
References O
