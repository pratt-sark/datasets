document O
: O
LiteFlowNet Method
: O
A O
Lightweight Method
Convolutional Method
Neural Method
Network Method
for O
Optical Task
Flow Task
Estimation Task
FlowNet2 Method
, O
the O
state O
- O
of O
- O
the O
- O
art O
convolutional Method
neural Method
network Method
( Method
CNN Method
) Method
for O
optical Task
flow Task
estimation O
, O
requires O
over O
160 O
M O
parameters O
to O
achieve O
accurate O
flow Task
estimation Task
. O
In O
this O
paper O
we O
present O
an O
alternative O
network O
that O
outperforms O
FlowNet2 Method
on O
the O
challenging O
Sintel Material
final Material
pass Material
and O
KITTI O
benchmarks O
, O
while O
being O
30 O
times O
smaller O
in O
the O
model Metric
size Metric
and O
1.36 O
times O
faster O
in O
the O
running Metric
speed Metric
. O
This O
is O
made O
possible O
by O
drilling O
down O
to O
architectural O
details O
that O
might O
have O
been O
missed O
in O
the O
current O
frameworks O
: O
( O
1 O
) O
We O
present O
a O
more O
effective O
flow Method
inference Method
approach Method
at O
each O
pyramid O
level O
through O
a O
lightweight Method
cascaded Method
network Method
. O
It O
not O
only O
improves O
flow Metric
estimation Metric
accuracy Metric
through O
early Task
correction Task
, O
but O
also O
permits O
seamless O
incorporation O
of O
descriptor Task
matching Task
in O
our O
network O
. O
( O
2 O
) O
We O
present O
a O
novel O
flow Method
regularization Method
layer Method
to O
ameliorate O
the O
issue O
of O
outliers O
and O
vague O
flow O
boundaries O
by O
using O
a O
feature Method
- Method
driven Method
local Method
convolution Method
. O
( O
3 O
) O
Our O
network O
owns O
an O
effective O
structure O
for O
pyramidal Task
feature Task
extraction Task
and O
embraces O
feature Task
warping Task
rather O
than O
image Task
warping Task
as O
practiced O
in O
FlowNet2 Method
. O
Our O
code O
and O
trained O
models O
are O
available O
at O
. O
section O
: O
Introduction O
Optical Task
flow Task
estimation Task
is O
a O
long O
- O
standing O
problem O
in O
computer Task
vision Task
. O
Due O
to O
the O
well O
- O
known O
aperture Task
problem Task
, O
optical Task
flow Task
is O
not O
directly O
measurable O
. O
Hence O
, O
the O
estimation Task
is O
typically O
solved O
by O
energy Method
minimization Method
in O
a O
coarse Method
- Method
to Method
- Method
fine Method
framework Method
. O
This O
class O
of O
techniques O
, O
however O
, O
involves O
complex O
energy Task
optimization Task
and O
thus O
it O
is O
not O
scalable O
for O
applications O
that O
demand O
real Task
- Task
time Task
estimation Task
. O
FlowNet Method
and O
its O
successor O
FlowNet2 Method
, O
have O
marked O
a O
milestone O
by O
using O
CNN Method
for O
optical Task
flow Task
estimation O
. O
Their O
accuracies Metric
especially O
the O
successor O
are O
approaching O
that O
of O
state O
- O
of O
- O
the O
- O
art O
energy Method
minimization Method
approaches Method
, O
while O
the O
speed O
is O
several O
orders O
of O
magnitude O
faster O
. O
To O
push O
the O
envelop O
of O
accuracy Metric
, O
FlowNet2 Method
is O
designed O
as O
a O
cascade Method
of Method
variants Method
of O
FlowNet Method
that O
each O
network O
in O
the O
cascade O
refines O
the O
preceding O
flow O
field O
by O
contributing O
on O
the O
flow O
increment O
between O
the O
first O
image O
and O
the O
warped O
second O
image O
. O
The O
model O
, O
as O
a O
result O
, O
comprises O
over O
160 O
M O
parameters O
, O
which O
could O
be O
formidable O
in O
many O
applications O
. O
A O
recent O
network O
termed O
SPyNet Method
attempts O
a O
network O
with O
smaller O
size O
of O
1.2 O
M O
parameters O
by O
adopting O
image O
warping O
in O
each O
pyramid O
level O
. O
Nonetheless O
, O
the O
accuracy Metric
can O
only O
match O
that O
of O
FlowNet Method
but O
not O
FlowNet2 Method
. O
The O
objective O
of O
this O
study O
is O
to O
explore O
alternative O
CNN Method
architectures Method
for O
accurate Task
flow Task
estimation Task
yet O
with O
high O
efficiency O
. O
Our O
work O
is O
inspired O
by O
the O
successes O
of O
FlowNet2 Method
and O
SPyNet Method
, O
but O
we O
further O
drill O
down O
the O
key O
elements O
to O
fully O
unleash O
the O
potential O
of O
deep Method
convolutional Method
network Method
combined O
with O
classical Method
principles Method
. O
There O
are O
two O
general O
principles O
to O
improve O
the O
design O
of O
FlowNet2 Method
and O
SPyNet Method
. O
The O
first O
principle O
is O
pyramidal Task
feature Task
extraction Task
. O
The O
proposed O
network O
, O
dubbed O
LiteFlowNet Method
, O
consists O
of O
an O
encoder Method
and O
a O
decoder Method
. O
The O
encoder O
maps O
the O
given O
image O
pair O
, O
respectively O
, O
into O
two O
pyramids O
of O
multi O
- O
scale O
high O
- O
dimensional O
features O
. O
The O
decoder O
then O
estimates O
the O
flow Task
field Task
in O
a O
coarse Method
- Method
to Method
- Method
fine Method
framework Method
. O
At O
each O
pyramid O
level O
, O
the O
decoder Method
infers O
the O
flow O
field O
by O
selecting O
and O
using O
the O
features O
of O
the O
same O
resolution O
from O
the O
feature O
pyramids O
. O
This O
design O
leads O
to O
a O
lighter O
network O
compared O
to O
FlowNet2 Method
that O
adopts O
U Method
- Method
Net Method
architecture Method
for O
flow Task
inference Task
. O
In O
comparison O
to O
SPyNet Method
, O
our O
network O
separates O
the O
process O
of O
feature Task
extraction Task
and O
flow Task
estimation Task
. O
This O
helps O
us O
to O
better O
pinpoint O
the O
bottleneck O
of O
accuracy Metric
and O
model Metric
size Metric
. O
The O
second O
general O
principle O
is O
feature Method
warping Method
. O
FlowNet2 Method
and O
SPyNet Method
warp O
the O
second O
image O
towards O
the O
first O
image O
in O
the O
pair O
using O
the O
previous O
flow Method
estimate Method
, O
and O
then O
refine O
the O
estimate O
using O
the O
feature O
maps O
generated O
by O
the O
warped O
and O
the O
first O
images O
. O
Warping O
an O
image O
and O
then O
generating O
the O
feature O
maps O
of O
the O
warped O
image O
are O
two O
ordered O
steps O
. O
We O
find O
that O
the O
two O
steps O
can O
be O
reduced O
to O
a O
single O
one O
by O
directly O
warping O
the O
feature O
maps O
of O
the O
second O
image O
, O
which O
have O
been O
computed O
by O
the O
encoder Method
. O
This O
one O
- O
step O
feature Method
warping Method
process Method
reduces O
the O
more O
discriminative O
feature O
- O
space O
distance O
instead O
of O
the O
RGB O
- O
space O
distance O
between O
the O
two O
images O
. O
This O
makes O
our O
network O
more O
powerful O
and O
efficient O
in O
addressing O
the O
flow Task
problem Task
. O
We O
now O
highlight O
the O
more O
specific O
differences O
between O
our O
network O
and O
existing O
CNN O
- O
based O
optical Task
flow Task
estimation O
frameworks O
: O
1 O
) O
Cascaded Method
flow Method
inference Method
– O
At O
each O
pyramid O
level O
, O
we O
introduce O
a O
novel O
cascade Method
of Method
two Method
lightweight Method
networks Method
. O
Each O
of O
them O
has O
a O
feature Method
warping Method
( Method
f Method
- Method
warp Method
) Method
layer Method
to O
displace O
the O
feature O
maps O
of O
the O
second O
image O
towards O
the O
first O
image O
using O
the O
flow Method
estimate Method
from O
the O
previous O
level O
. O
Flow O
residue O
is O
computed O
to O
further O
reduce O
the O
feature O
- O
space O
distance O
between O
the O
images O
. O
This O
design O
is O
advantageous O
to O
the O
conventional O
design O
of O
using O
a O
single Method
network Method
for O
flow Task
inference Task
. O
First O
, O
the O
cascade Method
progressively O
improves O
flow Metric
accuracy Metric
thus O
allowing O
an O
early O
correction O
of O
the O
estimate O
without O
passing O
more O
errors O
to O
the O
next O
level O
. O
Second O
, O
this O
design O
allows O
seamless O
integration O
with O
descriptor Task
matching Task
. O
We O
assign O
a O
matching Method
network Method
to O
the O
first O
inference Task
. O
Consequently O
, O
pixel O
- O
accuracy O
flow O
field O
can O
be O
generated O
first O
and O
then O
refined O
to O
sub O
- O
pixel O
accuracy O
in O
the O
subsequent O
inference Method
network Method
. O
Since O
at O
each O
pyramid O
level O
the O
feature O
- O
space O
distance O
between O
the O
images O
has O
been O
reduced O
by O
feature Method
warping Method
, O
we O
can O
use O
a O
rather O
short O
displacement O
than O
to O
establish O
the O
cost O
volume O
. O
Besides O
, O
matching Task
is O
performed O
only O
at O
sampled O
positions O
and O
thus O
a O
sparse O
cost O
- O
volume O
is O
aggregated O
. O
This O
effectively O
reduces O
the O
computational Metric
burden Metric
raised O
by O
the O
explicit Method
matching Method
. O
2 O
) O
Flow Method
regularization Method
– O
The O
cascaded Method
flow Method
inference Method
resembles O
the O
role O
of O
data O
fidelity O
in O
energy Method
minimization Method
methods Method
. O
Using O
data O
term O
alone O
, O
vague O
flow O
boundaries O
and O
undesired O
artifacts O
exist O
in O
flow O
fields O
. O
To O
tackle O
this O
problem O
, O
local O
flow O
consistency O
and O
co O
- O
occurrence O
between O
flow O
boundaries O
and O
intensity O
edges O
are O
commonly O
used O
as O
the O
cues O
to O
regularize O
flow O
field O
. O
Some O
of O
the O
representative O
methods O
include O
anisotropic Task
image Task
- Task
driven Task
, O
image Task
- Task
and Task
flow Task
- Task
driven Task
, O
and O
complementary Method
regularizations Method
. O
After O
cascaded Method
flow Method
inference Method
, O
we O
allow O
the O
flow O
field O
to O
be O
further O
regularized O
by O
our O
novel O
feature Method
- Method
driven Method
local Method
convolution Method
( Method
f Method
- Method
lconv Method
) Method
layer Method
at O
each O
pyramid O
level O
. O
The O
kernels O
of O
such O
a O
local Method
convolution Method
are O
adaptive O
to O
the O
pyramidal O
features O
from O
the O
encoder Method
, O
flow Method
estimate Method
and O
occlusion O
probability O
map O
. O
This O
makes O
the O
flow Method
regularization Method
to O
be O
both O
flow O
- O
and O
image Task
- Task
aware Task
. O
To O
our O
best O
knowledge O
, O
state O
- O
of O
- O
the O
- O
art O
CNNs Method
do O
not O
explore O
such O
a O
flow Method
regularization Method
. O
The O
effectiveness O
of O
the O
aforementioned O
contributions O
are O
depicted O
in O
Figure O
[ O
reference O
] O
. O
In O
summary O
, O
we O
propose O
a O
compact O
LiteFlowNet Method
to O
estimate O
optical Task
flow Task
. O
Our O
network O
innovates O
the O
useful O
elements O
from O
conventional O
methods O
. O
, O
brightness O
constraint O
in O
data O
fidelity O
to O
pyramidal O
CNN O
features O
and O
image Task
warping Task
to O
CNN Method
feature Method
warping Method
. O
More O
specifically O
, O
we O
present O
a O
cascaded Method
flow Method
inference Method
with O
feature Method
warping Method
and O
flow Method
regularization Method
in O
each O
pyramid O
level O
, O
which O
are O
new O
in O
the O
literature O
. O
Overall O
, O
our O
network O
outperforms O
FlowNet Method
and O
SPyNet Method
and O
is O
on O
par O
with O
or O
outperforms O
the O
recent O
FlowNet2 Method
on O
public O
benchmarks O
, O
while O
having O
30 O
times O
fewer O
parameters O
and O
being O
1.36 O
times O
faster O
than O
FlowNet2 Method
. O
section O
: O
Related O
Work O
Here O
, O
we O
briefly O
review O
some O
of O
the O
major O
approaches O
for O
optical Task
flow Task
estimation O
. O
Variational Method
methods Method
. O
Since O
the O
pioneering O
work O
by O
Horn O
and O
Schunck O
, O
variational Method
methods Method
have O
dominated O
optical Task
flow Task
estimation O
. O
Brox O
address O
illumination O
changes O
by O
combining O
the O
brightness O
and O
gradient O
constancy O
assumptions O
. O
Brox O
integrate O
rich O
descriptors O
into O
variational Method
formulation Method
. O
In O
DeepFlow Method
, O
Weinzaepfel O
propose O
to O
correlate O
multi O
- O
scale O
patches O
and O
incorporate O
this O
as O
the O
matching O
term O
in O
functional O
. O
In O
PatchMatch Method
Filter Method
, O
Lu O
establish O
dense Task
correspondence Task
using O
the O
superpixel Method
- Method
based Method
PatchMatch Method
. O
Revaud Method
propose O
a O
method O
EpicFlow Method
that O
uses O
externally O
matched O
flows O
as O
initialization O
and O
then O
performs O
interpolation Method
. O
Zimmer O
design O
the O
complementary Method
regularization Method
that O
exploits O
directional O
information O
from O
the O
constraints O
imposed O
in O
data O
term O
. O
Our O
network O
that O
infers O
optical Task
flow Task
and O
performs O
flow Method
regularization Method
is O
inspired O
by O
the O
use O
of O
data Method
fidelity Method
and O
regularization Method
in O
variational Method
methods Method
. O
Machine Method
learning Method
methods Method
. O
Black O
propose O
to O
represent O
complex O
image O
motion O
as O
a O
linear Method
combination Method
of O
the O
learned O
basis O
vectors O
. O
Roth O
formulates O
the O
prior O
probability O
of O
flow O
field O
as O
Field Method
- Method
of Method
- Method
Experts Method
model Method
that O
captures O
higher O
order O
spatial O
statistics O
. O
Sun O
study O
the O
probabilistic Method
model Method
of O
brightness Task
inconstancy Task
in O
a O
high Method
- Method
order Method
random Method
field Method
framework Method
. O
Nir O
represent O
image O
motion O
using O
the O
over Method
- Method
parameterization Method
model Method
. O
Rosenbaum Method
model Method
the O
local O
statistics O
of O
optical Task
flow Task
using O
Gaussian Method
mixtures Method
. O
Given O
a O
set O
of O
sparse O
matches O
, O
Wulff O
propose O
to O
regress O
them O
to O
a O
dense O
flow O
field O
using O
a O
set O
of O
basis Method
flow Method
fields Method
( O
PCA Method
- Method
Flow Method
) O
. O
It O
can O
be O
shown O
that O
the O
parameterized Method
model Method
can O
be O
efficiently O
implemented O
using O
CNN Method
. O
CNN Method
- Method
based Method
methods Method
. O
In O
the O
work O
of O
Fischer O
termed O
FlowNet Method
, O
a O
post Method
- Method
processing Method
step Method
that O
involves O
energy Method
minimization Method
is O
required O
to O
reduce O
smoothing O
effect O
across O
flow O
boundaries O
. O
This O
process O
is O
not O
end O
- O
to O
- O
end O
trainable O
. O
In O
our O
work O
, O
we O
present O
an O
end Method
- Method
to Method
- Method
end Method
approach Method
that O
performs O
in Task
- Task
network Task
flow Task
regularization Task
using O
the O
proposed O
f Method
- Method
lconv Method
layer Method
, O
which O
plays O
similar O
role O
as O
the O
regularization O
term O
in O
variational Method
methods Method
. O
In O
FlowNet2 Method
, O
Ilg Method
introduce O
a O
huge O
network Method
cascade Method
( O
over O
160 O
M O
parameters O
) O
that O
consists O
of O
variants O
of O
FlowNet Method
. O
The O
cascade Method
improves O
flow Metric
accuracy Metric
with O
an O
expense O
of O
model Metric
size Metric
and O
computational Metric
complexity Metric
. O
Our O
model O
uses O
a O
more O
efficient O
architecture O
containing O
30 O
times O
fewer O
parameters O
than O
FlowNet2 Method
while O
the O
performance O
is O
on O
par O
with O
it O
. O
A O
compact Method
network Method
termed O
SPyNet Method
from O
Ranjan Method
is O
inspired O
from O
spatial O
pyramid O
. O
Nevertheless O
, O
the O
accuracy Metric
is O
far O
below O
FlowNet2 Method
. O
A O
small O
- O
sized O
variant O
of O
our O
network O
outperforms O
SPyNet Method
while O
being O
1.33 O
times O
smaller O
in O
the O
model Metric
size Metric
. O
Zweig Method
present O
a O
network O
to O
interpolate O
third O
- O
party O
sparse O
flows O
but O
requiring O
off O
- O
the O
- O
shelf O
edge Method
detector Method
. O
DeepFlow Method
that O
involves O
convolution Method
and Method
pooling Method
operations Method
is O
however O
not O
a O
CNN Method
, O
since O
the O
“ O
filter O
weights O
” O
are O
non O
- O
trainable O
image O
patches O
. O
According O
to O
the O
terminology O
used O
in O
FlowNet Method
, O
DeepFlow Method
uses O
correlation Method
. O
An O
alternative O
approach O
for O
establishing O
point Task
correspondence Task
is O
to O
match O
image O
patches O
. O
Zagoruyko O
first O
introduce O
to O
CNN Method
- Method
feature Method
matching Method
. O
Güney O
find O
feature Method
representation Method
and O
formulate O
optical Task
flow Task
estimation O
in O
MRF Method
. O
Bailer O
use O
multi O
- O
scale O
features O
and O
then O
perform O
feature Method
matching Method
as O
Flow O
Fields O
. O
Although O
pixel Method
- Method
wise Method
matching Method
can O
establish O
accurate O
point Task
correspondence Task
, O
the O
computational Metric
demand Metric
is O
too O
high O
for O
practical O
use O
( O
it O
takes O
several O
seconds O
even O
a O
GPU O
is O
used O
) O
. O
As O
a O
tradeoff O
, O
Fischer Method
and O
Ilg Method
perform O
feature Method
matching Method
only O
at O
a O
reduced O
spatial O
resolution O
. O
We O
reduce O
the O
computational Metric
burden Metric
of O
feature Task
matching Task
by O
using O
a O
short Method
- Method
ranged Method
matching Method
of Method
warped Method
CNN Method
features Method
at O
sampled O
positions O
and O
a O
sub Method
- Method
pixel Method
refinement Method
at O
every O
pyramid O
level O
. O
We O
are O
inspired O
by O
the O
feature Method
transformation Method
used O
in O
Spatial Method
Transformer Method
. O
Our O
network O
uses O
the O
proposed O
f Method
- Method
warp Method
layer Method
to O
displace O
each O
channel O
of O
the O
given O
vector O
- O
valued O
feature O
according O
to O
the O
provided O
flow O
field O
. O
Unlike O
Spatial Method
Transformer Method
, O
f Method
- Method
warp Method
layer Method
is O
not O
fully O
constrained O
and O
is O
a O
relaxed O
version O
of O
it O
as O
the O
flow O
field O
is O
not O
parameterized O
. O
While O
transformation Task
in O
FlowNet2 Method
and O
SPyNet Method
is O
limited O
to O
images O
, O
our O
decider Method
network Method
is O
a O
more O
generic O
warping Method
network Method
that O
warps O
high O
- O
level O
CNN O
features O
. O
section O
: O
LiteFlowNet Method
LiteFlowNet Method
is O
composed O
of O
two O
compact Method
sub Method
- Method
networks Method
that O
are O
specialized O
in O
pyramidal Task
feature Task
extraction Task
and O
optical Task
flow Task
estimation O
as O
shown O
in O
Figure O
[ O
reference O
] O
. O
Since O
the O
spatial O
dimension O
of O
feature O
maps O
is O
contracting O
in O
feature Task
extraction Task
and O
that O
of O
flow O
fields O
is O
expanding O
in O
flow Task
estimation Task
, O
we O
call O
the O
two O
sub Method
- Method
networks Method
as O
NetC Method
and O
NetE Method
respectively O
. O
NetC Method
transforms O
any O
given O
image O
pair O
into O
two O
pyramids O
of O
multi O
- O
scale O
high O
- O
dimensional O
features O
. O
NetE Method
consists O
of O
cascaded Method
flow Method
inference Method
and O
regularization Method
modules Method
that O
estimate O
coarse Task
- Task
to Task
- Task
fine Task
flow Task
fields Task
. O
Pyramidal Method
Feature Method
Extraction Method
. O
As O
shown O
in O
Figure O
[ O
reference O
] O
, O
NetC Method
is O
a O
two O
- O
stream Method
network Method
in O
which O
the O
filter O
weights O
are O
shared O
across O
the O
two O
streams O
. O
Each O
of O
them O
functions O
as O
a O
feature Method
descriptor Method
that O
transforms O
an O
image O
to O
a O
pyramid O
of O
multi O
- O
scale O
high O
- O
dimensional O
features O
from O
the O
highest O
spatial O
resolution O
( O
) O
to O
the O
lowest O
spatial O
resolution O
( O
) O
. O
The O
pyramidal O
features O
are O
generated O
by O
stride Method
- Method
convolutions Method
with O
the O
reduction O
of O
spatial O
resolution O
by O
a O
factor O
up O
the O
pyramid O
. O
In O
the O
following O
, O
we O
omit O
the O
subscript O
that O
indicates O
the O
level O
of O
pyramid O
for O
brevity O
. O
We O
use O
to O
represent O
CNN O
features O
for O
. O
When O
we O
discuss O
the O
operations O
in O
a O
pyramid O
level O
, O
the O
same O
operations O
are O
applicable O
to O
other O
levels O
. O
Feature Method
Warping Method
. O
At O
each O
pyramid O
level O
, O
a O
flow O
field O
is O
inferred O
from O
high O
- O
level O
features O
and O
of O
images O
and O
. O
Flow Task
inference Task
becomes O
more O
challenging O
if O
and O
are O
captured O
far O
away O
from O
each O
other O
. O
With O
the O
motivation O
of O
image Task
warping Task
used O
in O
conventional O
methods O
and O
recent O
CNNs Method
for O
addressing Task
large Task
- Task
displacement Task
flow Task
, O
we O
propose O
to O
reduce O
feature O
- O
space O
distance O
between O
and O
by O
feature Method
warping Method
( O
f Method
- Method
warp Method
) O
. O
Specifically O
, O
is O
warped O
towards O
by O
f Method
- Method
warp Method
via O
flow Method
estimate Method
to O
. O
This O
allows O
our O
network O
to O
infer O
residual O
flow O
between O
and O
that O
has O
smaller O
flow O
magnitude O
( O
more O
details O
in O
Section O
[ O
reference O
] O
) O
but O
not O
the O
complete O
flow O
field O
that O
is O
more O
difficult O
to O
infer O
. O
Unlike O
conventional O
methods O
, O
f Method
- Method
warp Method
is O
performed O
on O
high O
- O
level O
CNN O
features O
but O
not O
on O
images O
. O
This O
makes O
our O
network O
more O
powerful O
and O
efficient O
in O
addressing O
the O
optical Task
flow Task
problem O
. O
To O
allow O
end Task
- Task
to Task
- Task
end Task
training Task
, O
is O
interpolated O
to O
for O
any O
sub O
- O
pixel O
displacement O
as O
follows O
: O
where O
denotes O
the O
source O
coordinates O
in O
the O
input O
feature O
map O
that O
defines O
the O
sample O
point O
, O
denotes O
the O
target O
coordinates O
of O
the O
regular O
grid O
in O
the O
interpolated O
feature O
map O
, O
and O
denotes O
the O
four O
pixel O
neighbors O
of O
. O
The O
above O
bilinear Method
interpolation Method
allows O
back Method
- Method
propagation Method
during O
training Task
as O
its O
gradients O
can O
be O
efficiently O
computed O
. O
subsection O
: O
Cascaded Task
Flow Task
Inference Task
At O
each O
pyramid O
level O
of O
NetE O
, O
pixel Method
- Method
by Method
- Method
pixel Method
matching Method
of O
high O
- O
level O
features O
yields O
coarse Task
flow Task
estimate Task
. O
A O
subsequent O
refinement O
on O
the O
coarse O
flow O
further O
improves O
it O
to O
sub Metric
- Metric
pixel Metric
accuracy Metric
. O
First Task
Flow Task
Inference Task
( O
descriptor Task
matching Task
) O
. O
Point O
correspondence O
between O
and O
is O
established O
through O
computing O
correlation O
of O
high O
- O
level O
feature O
vectors O
in O
individual O
pyramidal O
features O
and O
as O
follows O
: O
where O
is O
the O
matching O
cost O
between O
point O
in O
and O
point O
in O
, O
is O
the O
displacement O
vector O
from O
, O
and O
is O
the O
length O
of O
the O
feature O
vector O
. O
A O
cost O
volume O
is O
built O
by O
aggregating O
all O
the O
matching Metric
costs Metric
into O
a O
3D O
grid O
. O
We O
reduce O
the O
computational Metric
burden Metric
raised O
by O
cost Method
- Method
volume Method
processing Method
in O
three O
ways O
: O
1 O
) O
We O
perform O
short Method
- Method
range Method
matching Method
at O
every O
pyramid O
level O
instead O
of O
long Method
- Method
range Method
matching Method
at O
a O
single O
level O
. O
2 O
) O
We O
reduce O
feature O
- O
space O
distance O
between O
and O
by O
warping O
towards O
using O
our O
proposed O
f Method
- Method
warp Method
through O
flow Method
estimate Method
from O
previous O
level O
. O
3 O
) O
We O
perform O
matching Task
only O
at O
the O
sampled O
positions O
in O
the O
pyramid O
levels O
of O
high O
- O
spatial O
resolution O
. O
The O
sparse O
cost O
volume O
is O
interpolated O
in O
the O
spatial O
dimension O
to O
fill O
the O
missed O
matching O
costs O
for O
the O
unsampled O
positions O
. O
The O
first O
two O
techniques O
effectively O
reduce O
the O
searching O
space O
needed O
, O
while O
the O
last O
technique O
reduces O
the O
frequency O
of O
matching O
per O
pyramid O
level O
. O
In O
the O
descriptor Task
matching Task
unit Task
, O
residual O
flow O
is O
inferred O
by O
filtering O
the O
cost O
volume O
as O
illustrated O
in O
Figure O
[ O
reference O
] O
. O
A O
complete O
flow O
field O
is O
computed O
as O
follows O
: O
Second O
Flow Method
Inference Method
( O
sub Task
- Task
pixel Task
refinement Task
) O
. O
Since O
the O
cost O
volume O
in O
descriptor Method
matching Method
unit Method
is O
aggregated O
by O
measuring O
pixel O
- O
by O
- O
pixel O
correlation O
, O
flow Method
estimate Method
from O
the O
previous O
inference O
is O
only O
up O
to O
pixel Metric
- Metric
level Metric
accuracy Metric
. O
We O
introduce O
the O
second O
flow Method
inference Method
in O
the O
wake O
of O
descriptor Task
matching Task
as O
shown O
in O
Figure O
[ O
reference O
] O
. O
It O
aims O
to O
refine O
the O
pixel O
- O
level O
flow O
field O
to O
sub O
- O
pixel Metric
accuracy Metric
. O
This O
prevents O
erroneous O
flows O
being O
amplified O
by O
upsampling O
and O
passing O
to O
the O
next O
pyramid O
level O
. O
Specifically O
, O
is O
warped O
to O
via O
flow Method
estimate Method
. O
Sub Method
- Method
pixel Method
refinement Method
unit Method
yields O
a O
more O
accurate O
flow O
field O
by O
minimizing O
feature O
- O
space O
distance O
between O
and O
through O
computing O
residual O
flow O
as O
the O
following O
: O
subsection O
: O
Flow Method
Regularization Method
Cascaded Method
flow Method
inference Method
resembles O
the O
role O
of O
data Metric
fidelity Metric
in O
conventional O
minimization Method
methods Method
. O
Using O
data O
term O
alone O
, O
vague O
flow O
boundaries O
and O
undesired O
artifacts O
commonly O
exist O
in O
flow O
field O
. O
To O
tackle O
this O
problem O
, O
we O
propose O
to O
use O
a O
feature Method
- Method
driven Method
local Method
convolution Method
( Method
f Method
- Method
lcon Method
) O
to O
regularize O
flow O
field O
from O
the O
cascaded Method
flow Method
inference Method
. O
The O
operation O
of O
f Method
- Method
lcon Method
is O
well O
- O
governed O
by O
the O
Laplacian Method
formulation Method
of Method
diffusion Method
of Method
pixel Method
values Method
. O
In O
contrast O
to O
local Method
convolution Method
( O
lcon Method
) O
used O
in O
conventional O
CNNs Method
, O
f Method
- Method
lcon Method
is O
more O
generalized O
. O
Not O
only O
is O
a O
distinct O
filter Method
used O
for O
each O
position O
of O
feature O
map O
, O
but O
the O
filter O
is O
adaptively O
constructed O
for O
individual O
flow O
patches O
. O
Consider O
a O
general O
case O
, O
a O
vector O
- O
valued O
feature O
that O
has O
to O
be O
regularized O
has O
channels O
and O
a O
spatial O
dimension O
. O
Define O
as O
the O
set O
of O
filters O
used O
in O
f Method
- Method
lcon Method
layer Method
. O
The O
operation O
of O
f Method
- Method
lcon Method
to O
can O
be O
formulated O
as O
follow O
: O
where O
“ O
” O
denotes O
convolution O
, O
is O
a O
patch O
centered O
at O
position O
of O
channel O
in O
, O
is O
the O
corresponding O
regularization Method
filter Method
, O
and O
is O
a O
scalar O
output O
for O
and O
. O
To O
be O
specific O
for O
regularizing Task
flow Task
field Task
from O
the O
cascaded Task
flow Task
inference Task
, O
we O
replace O
to O
. O
Flow Method
regularization Method
module Method
is O
defined O
as O
follows O
: O
The O
f Method
- Method
lcon Method
filters Method
need O
to O
be O
specialized O
for O
smoothing Task
flow Task
field Task
. O
It O
should O
behave O
as O
an O
averaging Method
filter Method
if O
the O
variation O
of O
flow O
vectors O
over O
the O
patch O
is O
smooth O
. O
It O
should O
also O
not O
over O
- O
smooth O
flow O
field O
across O
flow O
boundary O
. O
We O
define O
a O
feature Method
- Method
driven Method
CNN Method
distance Method
metric Method
that O
estimates O
local O
flow O
variation O
using O
pyramidal O
feature O
, O
flow O
field O
from O
the O
cascaded Method
flow Method
inference Method
, O
and O
occlusion Method
probability Method
map Method
. O
In O
summary O
, O
is O
adaptively O
constructed O
by O
a O
CNN Method
unit Method
as O
follows O
: O
With O
the O
introduction O
of O
feature Method
- Method
driven Method
distance Method
metric Method
, O
each O
filter Method
of Method
f Method
- Method
lcon Method
is O
constructed O
as O
follows O
: O
where O
denotes O
the O
neighborhood O
containing O
pixels O
centered O
at O
position O
. O
Here O
, O
we O
provide O
a O
mechanism O
to O
perform O
f Method
- Method
lcon Method
efficiently O
. O
For O
a O
- O
channel O
input O
, O
we O
use O
tensors O
to O
store O
f O
- O
lcon O
filter O
set O
. O
As O
illustrated O
in O
Figure O
[ O
reference O
] O
, O
each O
f Method
- Method
lcon Method
filter Method
is O
folded O
into O
a O
3D O
column O
and O
then O
packed O
into O
the O
- O
entry O
of O
a O
3D O
tensor O
. O
Same O
folding Method
and Method
packing Method
operations Method
are O
also O
applied O
to O
each O
patch O
in O
each O
channel O
of O
. O
This O
results O
tensors O
for O
. O
In O
this O
way O
, O
Equation O
( O
[ O
reference O
] O
) O
can O
be O
reformulated O
to O
: O
where O
“ O
” O
denotes O
element O
- O
wise O
dot O
product O
between O
the O
corresponding O
columns O
of O
the O
tensors O
. O
With O
the O
abuse O
of O
notation O
, O
means O
the O
- O
th O
- O
slice O
of O
the O
regularized O
- O
channel O
feature O
. O
Equation O
( O
[ O
reference O
] O
) O
reduces O
the O
dimension O
of O
tensors O
from O
( O
right O
- O
hand O
side O
in O
prior O
to O
the O
dot O
product O
) O
to O
( O
left O
- O
hand O
side O
) O
. O
section O
: O
Experiments O
Network O
Details O
. O
In O
LiteFlowNet Method
, O
NetC Method
generates O
6 O
- O
level O
pyramidal O
features O
and O
NetE Task
predicts Task
flow Task
fields Task
for O
levels O
6 O
to O
2 O
. O
Flow O
field O
in O
level O
2 O
is O
upsampled O
to O
yield O
flow O
field O
in O
level O
1 O
. O
We O
set O
the O
maximum O
searching O
radius O
in O
cost O
- O
volume O
to O
3 O
pixels O
( O
levels O
6 O
to O
4 O
) O
or O
6 O
pixels O
( O
levels O
3 O
to O
2 O
) O
. O
Matching Task
is O
performed O
at O
each O
position O
in O
pyramidal O
features O
, O
except O
for O
levels O
3 O
to O
2 O
that O
it O
is O
performed O
at O
a O
regularly O
sampled O
grid O
( O
a O
stride O
of O
2 O
) O
. O
All O
convolution Method
layers Method
use O
filters Method
, O
except O
each O
last O
layer O
in O
descriptor Task
matching Task
, O
sub Task
- Task
pixel Task
refinement Task
, O
and O
flow Method
regularization Method
units Method
uses O
( O
levels O
4 O
to O
3 O
) O
or O
( O
level O
2 O
) O
filters O
. O
Each O
convolution Method
layer Method
is O
followed O
by O
a O
leaky Method
rectified Method
linear Method
unit Method
layer Method
, O
except O
f Method
- Method
lcon Method
and O
the O
last O
layer O
in O
, O
and O
CNN Method
units Method
. O
More O
details O
can O
be O
found O
in O
the O
supplementary O
material O
. O
Training O
Details O
. O
We O
train O
our O
network O
stage O
- O
wise O
by O
the O
following O
steps O
: O
1 O
) O
NetC Method
and O
: O
of O
NetE Method
is O
trained O
for O
300k O
iterations O
. O
2 O
) O
together O
with O
the O
trained O
network O
in O
step O
1 O
is O
trained O
for O
300k O
iterations O
. O
3 O
) O
For O
levels O
, O
: O
followed O
by O
is O
added O
into O
the O
trained O
network O
each O
time O
. O
The O
new O
network Method
cascade Method
is O
trained O
for O
200k O
( O
level O
2 O
: O
300k O
) O
iterations O
. O
Filter O
weights O
are O
initialized O
from O
previous O
level O
. O
Learning Metric
rates Metric
are O
initially O
set O
to O
1e O
- O
4 O
, O
5e O
- O
5 O
, O
and O
4e O
- O
5 O
for O
levels O
6 O
to O
4 O
, O
3 O
and O
2 O
respectively O
. O
We O
reduce O
it O
by O
a O
factor O
of O
2 O
starting O
at O
120k O
, O
160k O
, O
200k O
, O
and O
240k O
iterations O
. O
We O
use O
the O
same O
loss O
weight O
, O
L2 O
training O
loss O
, O
Adam Method
optimization Method
, O
data Method
augmentation Method
( O
including O
noise O
injection O
) O
, O
and O
training Method
schedule Method
( O
Chairs O
Things3D O
) O
as O
FlowNet2 Method
. O
We O
denote O
LiteFlowNet Method
- Method
pre Method
and O
LiteFlowNet Method
as O
the O
networks O
trained O
on O
Chairs O
and O
Chairs O
Things3D O
, O
respectively O
. O
subsection O
: O
Results O
We O
compare O
several O
variants O
of O
LiteFlowNet Method
to O
state O
- O
of O
- O
the O
- O
art O
methods O
on O
public O
benchmarks O
including O
FlyingChairs O
( O
Chairs O
) O
, O
Sintel Material
clean Material
and O
final Material
, O
KITTI12 O
, O
KITTI15 O
, O
and O
Middlebury O
. O
Conventional O
Hybrid O
Heavyweight O
CNN O
Lightweight O
CNN O
FlyingChairs O
. O
We O
first O
compare O
the O
intermediate O
results O
of O
different O
well O
- O
performing O
networks O
trained O
on O
Chairs O
alone O
in O
Table O
[ O
reference O
] O
. O
Average Metric
end Metric
- Metric
point Metric
error Metric
( O
AEE Metric
) O
is O
reported O
. O
LiteFlowNet Method
- Method
pre Method
outperforms O
the O
compared O
networks O
. O
No O
intermediate O
result O
is O
available O
for O
FlowNet2 Method
as O
each O
cascade Method
is O
trained O
on O
the O
Chairs O
Things3D O
schedule O
individually O
. O
Since O
FlowNetC Method
, O
FlowNetS Method
( O
variants O
of O
FlowNet Method
) O
, O
and O
SPyNet Method
have O
fewer O
parameters O
than O
FlowNet2 Method
and O
the O
later O
two O
models O
do O
not O
perform O
feature Method
matching Method
, O
we O
also O
construct O
a O
small O
- O
size O
counterpart O
LiteFlowNetX Method
- Method
pre Method
by O
removing O
the O
matching O
part O
and O
shrinking O
the O
model O
sizes O
of O
NetC Method
and O
NetE Method
by O
about O
4 O
and O
5 O
times O
, O
respectively O
. O
Despite O
that O
LiteFlowNetX Method
- Method
pre Method
is O
43 O
and O
1.33 O
times O
smaller O
than O
FlowNetC Method
and O
SPyNet Method
, O
respectively O
, O
it O
still O
outperforms O
these O
networks O
and O
is O
on O
par O
with O
FlowNetC Method
that O
uses O
explicit Method
matching Method
. O
MPI O
Sintel Material
. O
In O
Table O
[ O
reference O
] O
, O
LiteFlowNetX Method
- Method
pre Method
outperforms O
FlowNetS Method
( O
and O
C O
) O
and O
SPyNet Method
that O
are O
trained O
on O
Chairs O
on O
all O
cases O
except O
the O
Middlebury O
benchmark O
. O
LiteFlowNet Method
, O
trained O
on O
the O
Chairs O
Things3D O
schedule O
, O
performs O
better O
than O
LiteFlowNet Method
- Method
pre Method
as O
expected O
. O
LiteFlowNet Method
also O
outperforms O
SPyNet Method
, O
FlowNet2 Method
- Method
S Method
( O
and O
- O
C O
) O
. O
We O
also O
fine O
- O
tuned O
LiteFlowNet Method
on O
a O
mixture O
of O
Sintel Material
clean Material
and O
final Material
training O
data O
( O
LiteFlowNet Method
- O
ft O
) O
using O
the O
generalized Method
Charbonnier Method
loss Method
. O
No O
noise Method
augmentation Method
was O
performed O
but O
we O
introduced O
image O
mirroring O
to O
improve O
the O
diversity O
of O
the O
training O
set O
. O
LiteFlowNet Method
- O
ft O
outperforms O
FlowNet2 Method
- Method
ft Method
- Method
sintel Method
and O
EpicFlow Method
for O
Sintel Material
final Material
testing O
set O
. O
Despite O
DC Method
Flow Method
( O
a O
hybrid Method
method Method
consists O
of O
CNN Method
and Method
post Method
- Method
processing Method
) O
performs O
better O
than O
LiteFlowNet Method
, O
its O
GPU Metric
runtime Metric
requires O
several O
seconds O
that O
makes O
it O
formidable O
in O
many O
applications O
. O
Figure O
[ O
reference O
] O
shows O
some O
examples O
of O
flow O
fields O
on O
Sintel Material
dataset Material
. O
LiteFlowNet Method
- O
ft O
and O
FlowNet2 Method
- Method
ft Method
- O
sintel O
perform O
the O
best O
among O
the O
compared O
methods O
. O
As O
LiteFlowNet Method
has O
flow Method
regularization Method
module Method
, O
sharper O
flow O
boundaries O
and O
lesser O
artifacts O
can O
be O
observed O
in O
the O
generated O
flow O
fields O
. O
KITTI O
. O
LiteFlowNet Method
consistently O
performs O
better O
than O
LiteFlowNet Method
- Method
pre Method
especially O
on O
KITTI15 O
as O
shown O
in O
Table O
[ O
reference O
] O
. O
It O
also O
outperforms O
SPyNet Method
and O
FlowNet2 Method
- Method
S Method
( O
and O
C O
) O
. O
We O
also O
fine O
- O
tuned O
LiteFlowNet Method
on O
a O
mixture O
of O
KITTI12 O
and O
KITTI15 O
training O
data O
( O
LiteFlowNet Method
- O
ft O
) O
using O
the O
same O
augmentation O
as O
the O
case O
of O
Sintel Material
except O
that O
we O
reduced O
the O
amount O
of O
augmentation O
for O
spatial O
motion O
to O
fit O
the O
driving O
scene O
. O
After O
fine O
- O
tuning O
, O
LiteFlowNet Method
generalizes O
well O
to O
real O
- O
world O
data O
. O
LiteFlowNet Method
- O
ft O
outperforms O
FlowNet2 Method
- Method
ft Method
- Method
kitti Method
. O
Figure O
[ O
reference O
] O
shows O
some O
examples O
of O
flow O
fields O
on O
KITTI O
. O
As O
in O
the O
case O
for O
Sintel Material
, O
LiteFlowNet Method
- O
ft O
and O
FlowNet2 Method
- Method
ft Method
- Method
kitti Method
performs O
the O
best O
among O
the O
compared O
methods O
. O
Even O
though O
LiteFlowNet Method
and O
its O
variants O
perform O
pyramidal Method
descriptor Method
matching Method
in O
a O
limited O
searching O
range O
, O
it O
yields O
reliable O
large Task
- Task
displacement Task
flow Task
fields Task
for O
real O
- O
world O
data O
due O
to O
the O
feature Method
warping Method
( Method
f Method
- Method
warp Method
) Method
layer Method
introduced O
. O
More O
analysis O
will O
be O
presented O
in O
Section O
[ O
reference O
] O
. O
Middlebury O
. O
LiteFlowNet Method
has O
comparable O
performance O
with O
conventional O
methods O
. O
It O
outperforms O
FlowNetS Method
( O
and O
C O
) O
, O
FlowNet2 Method
- Method
S Method
( O
and O
C O
) O
, O
SPyNet Method
, O
and O
FlowNet2 Method
. O
On O
the O
benchmark O
, O
LiteFlowNet Method
- O
ft O
refers O
to O
the O
one O
fine O
- O
tuned O
on O
Sintel Material
. O
subsection O
: O
Runtime O
and O
Parameters O
We O
measure O
runtime Metric
of O
a O
CNN Method
using O
a O
machine O
equipped O
with O
an O
Intel O
Xeon O
E5 O
2.2GHz O
and O
an O
NVIDIA O
GTX O
1080 O
. O
Timings O
are O
averaged O
over O
100 O
runs O
for O
Sintel Material
image Material
pairs Material
of O
size O
. O
As O
summarized O
in O
Table O
[ O
reference O
] O
, O
LiteFlowNet Method
has O
about O
30 O
times O
fewer O
parameters O
than O
FlowNet2 Method
and O
is O
1.36 O
times O
faster O
in O
runtime Metric
. O
LiteFlowNetX Method
, O
a O
variant O
of O
LiteFlowNet Method
having O
a O
smaller O
model Metric
size Metric
and O
without O
descriptor Method
matching Method
, O
has O
about O
43 O
times O
fewer O
parameters O
than O
FlowNetC Method
and O
a O
comparable O
runtime Metric
. O
LiteFlowNetX Method
also O
has O
1.33 O
times O
fewer O
parameters O
than O
SPyNet Method
. O
LiteFlowNet Method
and O
its O
variants O
are O
currently O
the O
most O
compact O
CNNs Method
for O
flow Task
estimation Task
. O
subsection O
: O
Ablation Task
Study Task
We O
investigate O
the O
role O
of O
each O
component O
in O
LiteFlowNet Method
- Method
pre Method
trained O
on O
Chairs O
by O
evaluating O
the O
performance O
of O
different O
variants O
with O
some O
of O
the O
components O
disabled O
. O
The O
AEE Metric
results O
are O
summarized O
in O
Table O
[ O
reference O
] O
and O
examples O
of O
flow O
fields O
are O
illustrated O
in O
Figure O
[ O
reference O
] O
. O
Feature Method
Warping Method
. O
We O
consider O
two O
variants O
LiteFlowNet Method
- Method
pre Method
( O
WM O
and O
WMS O
) O
and O
compare O
them O
to O
the O
counterparts O
with O
warping O
disabled O
( O
M O
and O
MS O
) O
. O
Flow O
fields O
from O
M O
and O
MS Method
are O
more O
vague O
. O
Large O
degradation O
in O
AEE Metric
is O
noticed O
especially O
for O
KITTI12 O
( O
) O
and O
KITTI15 O
( O
) O
. O
With O
feature Method
warping Method
, O
pyramidal O
features O
that O
input O
to O
flow Task
inference Task
are O
closer O
to O
each O
other O
. O
This O
facilitates O
flow Task
estimation Task
in O
subsequent O
pyramid O
level O
by O
computing O
residual O
flow O
. O
Descriptor Task
Matching Task
. O
We O
compare O
the O
variant O
WSR Method
without Method
descriptor Method
matching Method
for O
which O
the O
flow Method
inference Method
part Method
is O
made O
as O
deep O
as O
that O
in O
the O
unamended O
LiteFlowNet Method
- Method
pre Method
( O
ALL O
) O
. O
No O
noticeable O
difference O
between O
the O
flow O
fields O
from O
WSR Method
and O
ALL O
. O
Since O
the O
maximum O
displacement O
of O
the O
example O
flow O
field O
is O
not O
very O
large O
( O
only O
14.7 O
pixels O
) O
, O
accurate O
flow O
field O
can O
still O
be O
yielded O
from O
WSR Method
. O
For O
evaluation O
covering O
a O
wide O
range O
of O
flow O
displacement O
( O
especially O
large O
- O
displacement O
benchmark O
, O
KITTI O
) O
, O
degradation O
in O
AEE Metric
is O
noticed O
for O
WSR Method
. O
This O
suggests O
that O
descriptor Method
matching Method
is O
useful O
in O
addressing O
large Task
- Task
displacement Task
flow Task
. O
Sub Task
- Task
Pixel Task
Refinement Task
. O
The O
flow O
field O
generated O
from O
WMS Method
is O
more O
crisp O
and O
contains O
more O
fine O
details O
than O
that O
generated O
from O
WM Method
with O
sub Method
- Method
pixel Method
refinement Method
disabled O
. O
Less O
small O
- O
magnitude O
flow O
artifacts O
( O
represented O
by O
light O
color O
on O
the O
background O
) O
are O
also O
observed O
. O
Besides O
, O
WMS Method
achieves O
smaller O
AEE Metric
. O
Since O
descriptor Method
matching Method
establishes O
pixel O
- O
by O
- O
pixel O
correspondence O
, O
sub Method
- Method
pixel Method
refinement Method
is O
necessary O
to O
yield O
detail O
- O
preserving O
flow O
field O
. O
Regularization Method
. O
In O
comparison O
WMS Method
with O
regularization O
disabled O
to O
ALL O
, O
undesired O
artifacts O
exist O
in O
homogeneous O
regions O
( O
represented O
by O
very O
dim O
color O
on O
the O
background O
) O
of O
the O
flow O
field O
generated O
from O
WMS Method
. O
Flow O
bleeding O
and O
vague O
flow O
boundaries O
are O
observed O
. O
Degradation O
in O
AEE Metric
is O
also O
noticed O
. O
This O
suggests O
that O
the O
proposed O
feature Method
- Method
driven Method
local Method
convolution Method
( Method
f Method
- Method
lcon Method
) Method
plays O
the O
vital O
role O
to O
smooth O
flow O
field O
and O
maintain O
crisp O
flow O
boundaries O
as O
regularization O
term O
in O
conventional O
variational Method
methods Method
. O
section O
: O
Conclusion O
We O
have O
presented O
a O
compact Method
network Method
for O
accurate Task
flow Task
estimation Task
. O
LiteFlowNet Method
outperforms O
FlowNet Method
and O
is O
on O
par O
with O
or O
outperforms O
the O
state O
- O
of O
- O
the O
- O
art O
FlowNet2 Method
on O
public O
benchmarks O
while O
being O
faster O
in O
runtime Metric
and O
30 O
times O
smaller O
in O
model Metric
size Metric
. O
Pyramidal Method
feature Method
extraction Method
and O
feature Method
warping Method
( O
f Method
- Method
warp Method
) O
help O
us O
to O
break O
the O
de O
facto O
rule O
of O
accurate O
flow Method
network Method
requiring O
large O
model O
size O
. O
To O
address O
large Task
- Task
displacement Task
and Task
detail Task
- Task
preserving Task
flows Task
, O
LiteFlowNet Method
exploits O
short Method
- Method
range Method
matching Method
to O
generate O
pixel O
- O
level O
flow O
field O
and O
further O
improves O
the O
estimate O
to O
sub Metric
- Metric
pixel Metric
accuracy Metric
in O
the O
cascaded Method
flow Method
inference Method
. O
To O
result O
crisp O
flow O
boundaries O
, O
LiteFlowNet Method
regularizes O
flow O
field O
through O
feature Method
- Method
driven Method
local Method
convolution Method
( O
f Method
- Method
lcon Method
) O
. O
With O
its O
lightweight O
, O
accurate O
, O
and O
fast O
flow Task
computation Task
, O
we O
expect O
that O
LiteFlowNet Method
can O
be O
deployed O
to O
many O
applications O
such O
as O
motion Task
segmentation Task
, O
action Task
recognition Task
, O
SLAM Task
, O
3D Task
reconstruction Task
and O
more O
. O
Acknowledgement O
. O
This O
work O
is O
supported O
by O
SenseTime O
Group O
Limited O
and O
the O
General O
Research O
Fund O
sponsored O
by O
the O
Research O
Grants O
Council O
of O
the O
Hong O
Kong O
SAR O
( O
CUHK O
14241716 O
, O
14224316 O
, O
14209217 O
) O
. O
section O
: O
Appendix O
LiteFlowNet Method
consists O
of O
two O
compact Method
sub Method
- Method
networks Method
, O
namely O
NetC Method
and Method
NetE. Method
NetC Method
is O
a O
two O
- O
steam Method
network Method
in O
which O
the O
two O
network O
streams O
share O
the O
same O
set O
of O
filters O
. O
The O
input O
to O
NetC Method
is O
an O
image O
pair O
( O
, O
) O
. O
The O
network Method
architectures Method
of O
the O
6 O
- O
level O
NetC O
and O
NetE Method
at O
pyramid O
level O
5 O
are O
provided O
in O
Table O
[ O
reference O
] O
and O
Tables O
[ O
reference O
] O
to O
[ O
reference O
] O
, O
respectively O
. O
We O
use O
suffixes O
“ O
M O
” O
, O
“ O
S O
” O
and O
“ O
R O
” O
to O
highlight O
the O
layers O
that O
are O
used O
in O
descriptor Task
matching Task
, O
sub Task
- Task
pixel Task
refinement Task
, O
and O
flow Method
regularization Method
units Method
in O
NetE Method
, O
respectively O
. O
We O
declare O
a O
layer O
as O
“ O
flow O
” O
to O
highlight O
when O
the O
output O
is O
a O
flow O
field O
. O
Our O
code O
and O
trained O
models O
are O
available O
at O
. O
A O
video O
clip O
( O
) O
and O
a O
supplementary O
material O
are O
available O
on O
our O
project O
page O
( O
) O
to O
showcase O
the O
performance O
of O
LiteFlowNet Method
and O
the O
effectiveness O
of O
the O
proposed O
components O
in O
our O
network O
. O
bibliography O
: O
References O
