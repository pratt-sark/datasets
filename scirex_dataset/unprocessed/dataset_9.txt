document	O
:	O
Stacked	Method
Generative	Method
Adversarial	Method
Networks	Method
In	O
this	O
paper	O
,	O
we	O
propose	O
a	O
novel	O
generative	Method
model	Method
named	O
Stacked	Method
Generative	Method
Adversarial	Method
Networks	Method
(	O
SGAN	Method
)	Method
,	O
which	O
is	O
trained	O
to	O
invert	O
the	O
hierarchical	Method
representations	Method
of	O
a	O
bottom	Method
-	Method
up	Method
discriminative	Method
network	Method
.	O
Our	O
model	O
consists	O
of	O
a	O
top	Method
-	Method
down	Method
stack	Method
of	Method
GANs	Method
,	O
each	O
learned	O
to	O
generate	O
lower	O
-	O
level	O
representations	O
conditioned	O
on	O
higher	O
-	O
level	O
representations	O
.	O
A	O
representation	Method
discriminator	Method
is	O
introduced	O
at	O
each	O
feature	O
hierarchy	O
to	O
encourage	O
the	O
representation	O
manifold	O
of	O
the	O
generator	Method
to	O
align	O
with	O
that	O
of	O
the	O
bottom	Method
-	Method
up	Method
discriminative	Method
network	Method
,	O
leveraging	O
the	O
powerful	O
discriminative	Method
representations	Method
to	O
guide	O
the	O
generative	Method
model	Method
.	O
In	O
addition	O
,	O
we	O
introduce	O
a	O
conditional	Method
loss	Method
that	O
encourages	O
the	O
use	O
of	O
conditional	O
information	O
from	O
the	O
layer	O
above	O
,	O
and	O
a	O
novel	O
entropy	Method
loss	Method
that	O
maximizes	O
a	O
variational	Metric
lower	Metric
bound	Metric
on	O
the	O
conditional	O
entropy	O
of	O
generator	O
outputs	O
.	O
We	O
first	O
train	O
each	O
stack	O
independently	O
,	O
and	O
then	O
train	O
the	O
whole	O
model	O
end	O
-	O
to	O
-	O
end	O
.	O
Unlike	O
the	O
original	O
GAN	Method
that	O
uses	O
a	O
single	O
noise	O
vector	O
to	O
represent	O
all	O
the	O
variations	O
,	O
our	O
SGAN	Method
decomposes	O
variations	O
into	O
multiple	O
levels	O
and	O
gradually	O
resolves	O
uncertainties	O
in	O
the	O
top	Method
-	Method
down	Method
generative	Method
process	Method
.	O
Based	O
on	O
visual	Metric
inspection	Metric
,	O
Inception	Metric
scores	Metric
and	O
visual	Metric
Turing	Metric
test	Metric
,	O
we	O
demonstrate	O
that	O
SGAN	Method
is	O
able	O
to	O
generate	O
images	O
of	O
much	O
higher	O
quality	Metric
than	O
GANs	Method
without	O
stacking	O
.	O
section	O
:	O
Introduction	O
Recent	O
years	O
have	O
witnessed	O
tremendous	O
success	O
of	O
deep	Method
neural	Method
networks	Method
(	O
DNNs	Method
)	O
,	O
especially	O
the	O
kind	O
of	O
bottom	Method
-	Method
up	Method
neural	Method
networks	Method
trained	O
for	O
discriminative	Task
tasks	Task
.	O
In	O
particular	O
,	O
Convolutional	Method
Neural	Method
Networks	Method
(	O
CNNs	Method
)	O
have	O
achieved	O
impressive	O
accuracy	Metric
on	O
the	O
challenging	O
ImageNet	Task
classification	Task
benchmark	Task
.	O
Interestingly	O
,	O
it	O
has	O
been	O
shown	O
that	O
CNNs	Method
trained	O
on	O
ImageNet	O
for	O
classification	Task
can	O
learn	O
representations	O
that	O
are	O
transferable	O
to	O
other	O
tasks	O
,	O
and	O
even	O
to	O
other	O
modalities	O
.	O
However	O
,	O
bottom	Method
-	Method
up	Method
discriminative	Method
models	Method
are	O
focused	O
on	O
learning	O
useful	O
representations	O
from	O
data	O
,	O
being	O
incapable	O
of	O
capturing	O
the	O
data	O
distribution	O
.	O
Learning	O
top	Method
-	Method
down	Method
generative	Method
models	Method
that	O
can	O
explain	O
complex	O
data	Task
distribution	Task
is	O
a	O
long	O
-	O
standing	O
problem	O
in	O
machine	Task
learning	Task
research	Task
.	O
The	O
expressive	O
power	O
of	O
deep	Method
neural	Method
networks	Method
makes	O
them	O
natural	O
candidates	O
for	O
generative	Method
models	Method
,	O
and	O
several	O
recent	O
works	O
have	O
shown	O
promising	O
results	O
.	O
While	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
DNNs	Method
can	O
rival	O
human	O
performance	O
in	O
certain	O
discriminative	Task
tasks	Task
,	O
current	O
best	O
deep	Method
generative	Method
models	Method
still	O
fail	O
when	O
there	O
are	O
large	O
variations	O
in	O
the	O
data	O
distribution	O
.	O
A	O
natural	O
question	O
therefore	O
arises	O
:	O
can	O
we	O
leverage	O
the	O
hierarchical	Method
representations	Method
in	O
a	O
discriminatively	Method
trained	Method
model	Method
to	O
help	O
the	O
learning	O
of	O
top	Method
-	Method
down	Method
generative	Method
models	Method
?	O
In	O
this	O
paper	O
,	O
we	O
propose	O
a	O
generative	Method
model	Method
named	O
Stacked	Method
Generative	Method
Adversarial	Method
Networks	Method
(	O
SGAN	Method
)	Method
.	O
Our	O
model	O
consists	O
of	O
a	O
top	Method
-	Method
down	Method
stack	Method
of	Method
GANs	Method
,	O
each	O
trained	O
to	O
generate	O
“	O
plausible	O
”	O
lower	O
-	O
level	O
representations	O
conditioned	O
on	O
higher	O
-	O
level	O
representations	O
.	O
Similar	O
to	O
the	O
image	Method
discriminator	Method
in	O
the	O
original	O
GAN	Method
model	O
which	O
is	O
trained	O
to	O
distinguish	O
“	O
fake	O
”	O
images	O
from	O
“	O
real	O
”	O
ones	O
,	O
we	O
introduce	O
a	O
set	O
of	O
representation	Method
discriminators	Method
that	O
are	O
trained	O
to	O
distinguish	O
“	O
fake	O
”	O
representations	O
from	O
“	O
real	O
”	O
representations	O
.	O
The	O
adversarial	O
loss	O
introduced	O
by	O
the	O
representation	Method
discriminator	Method
forces	O
the	O
intermediate	Method
representations	Method
of	O
the	O
SGAN	Method
to	O
lie	O
on	O
the	O
manifold	O
of	O
the	O
bottom	Method
-	Method
up	Method
DNN	Method
’s	Method
representation	Method
space	Method
.	O
In	O
addition	O
to	O
the	O
adversarial	O
loss	O
,	O
we	O
also	O
introduce	O
a	O
conditional	O
loss	O
that	O
imposes	O
each	O
generator	O
to	O
use	O
the	O
higher	O
-	O
level	O
conditional	O
information	O
,	O
and	O
a	O
novel	O
entropy	Method
loss	Method
that	O
encourages	O
each	O
generator	O
to	O
generate	O
diverse	O
representations	O
.	O
By	O
stacking	O
several	O
GANs	Method
in	O
a	O
top	O
-	O
down	O
way	O
and	O
using	O
the	O
top	Method
-	Method
most	Method
GAN	Method
to	O
receive	O
labels	O
and	O
the	O
bottom	Method
-	Method
most	Method
GAN	Method
to	O
generate	O
images	O
,	O
SGAN	Method
can	O
be	O
trained	O
to	O
model	O
the	O
data	O
distribution	O
conditioned	O
on	O
class	O
labels	O
.	O
Through	O
extensive	O
experiments	O
,	O
we	O
demonstrate	O
that	O
our	O
SGAN	Method
is	O
able	O
to	O
generate	O
images	O
of	O
much	O
higher	O
quality	Metric
than	O
a	O
vanilla	O
GAN	Method
.	O
In	O
particular	O
,	O
our	O
model	O
obtains	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
Inception	Metric
scores	Metric
on	O
CIFAR	Material
-	Material
10	Material
dataset	Material
.	O
section	O
:	O
Related	O
Work	O
Deep	Method
Generative	Method
Image	Method
Models	Method
.	O
There	O
has	O
been	O
a	O
large	O
body	O
of	O
work	O
on	O
generative	Task
image	Task
modeling	Task
with	O
deep	Method
learning	Method
.	O
Some	O
early	O
efforts	O
include	O
Restricted	Method
Boltzmann	Method
Machines	Method
and	O
Deep	Method
Belief	Method
Networks	Method
.	O
More	O
recently	O
,	O
several	O
successful	O
paradigms	O
of	O
deep	Method
generative	Method
models	Method
have	O
emerged	O
,	O
including	O
the	O
auto	Method
-	Method
regressive	Method
models	Method
,	O
Variational	Method
Auto	Method
-	Method
encoders	Method
(	O
VAEs	Method
)	O
,	O
and	O
Generative	Method
Adversarial	Method
Networks	Method
(	O
GANs	Method
)	O
.	O
Our	O
work	O
builds	O
upon	O
the	O
GAN	Method
framework	O
,	O
which	O
employs	O
a	O
generator	Method
that	O
transforms	O
a	O
noise	O
vector	O
into	O
an	O
image	O
and	O
a	O
discriminator	Method
that	O
distinguishes	O
between	O
real	O
and	O
generated	O
images	O
.	O
However	O
,	O
due	O
to	O
the	O
vast	O
variations	O
in	O
image	O
content	O
,	O
it	O
is	O
still	O
challenging	O
for	O
GANs	Method
to	O
generate	O
diverse	O
images	O
with	O
sufficient	O
details	O
.	O
To	O
this	O
end	O
,	O
several	O
works	O
have	O
attempted	O
to	O
factorize	O
a	O
GAN	Method
into	O
a	O
series	O
of	O
GANs	Method
,	O
decomposing	O
the	O
difficult	O
task	O
into	O
several	O
more	O
tractable	O
sub	Task
-	Task
tasks	Task
.	O
Denton	O
propose	O
a	O
LAPGAN	Method
model	Method
that	O
factorizes	O
the	O
generative	Method
process	Method
into	O
multi	Method
-	Method
resolution	Method
GANs	Method
,	O
with	O
each	O
GAN	Method
generating	O
a	O
higher	O
-	O
resolution	O
residual	O
conditioned	O
on	O
a	O
lower	O
-	O
resolution	O
image	O
.	O
Although	O
both	O
LAPGAN	Method
and	O
SGAN	Method
consist	O
of	O
a	O
sequence	O
of	O
GANs	Method
each	O
working	O
at	O
one	O
scale	O
,	O
LAPGAN	Method
focuses	O
on	O
generating	O
multi	Task
-	Task
resolution	Task
images	Task
from	O
coarse	O
to	O
fine	O
while	O
our	O
SGAN	Method
aims	O
at	O
modeling	O
multi	Method
-	Method
level	Method
representations	Method
from	O
abstract	O
to	O
specific	O
.	O
Wang	O
and	O
Gupta	O
propose	O
a	O
-	O
GAN	Method
,	O
using	O
one	O
GAN	Method
to	O
generate	O
surface	O
normals	O
and	O
another	O
GAN	Method
to	O
generate	O
images	O
conditioned	O
on	O
surface	O
normals	O
.	O
Surface	O
normals	O
can	O
be	O
viewed	O
as	O
a	O
specific	O
type	O
of	O
image	Method
representations	Method
,	O
capturing	O
the	O
underlying	O
3D	O
structure	O
of	O
an	O
indoor	O
scene	O
.	O
On	O
the	O
other	O
hand	O
,	O
our	O
framework	O
can	O
leverage	O
the	O
more	O
general	O
and	O
powerful	O
multi	Method
-	Method
level	Method
representations	Method
in	O
a	O
pre	O
-	O
trained	O
discriminative	Method
DNN	Method
.	O
There	O
are	O
several	O
works	O
that	O
use	O
a	O
pre	Method
-	Method
trained	Method
discriminative	Method
model	Method
to	O
aid	O
the	O
training	O
of	O
a	O
generator	Method
.	O
add	O
a	O
regularization	Method
term	Method
that	O
encourages	O
the	O
reconstructed	O
image	O
to	O
be	O
similar	O
to	O
the	O
original	O
image	O
in	O
the	O
feature	O
space	O
of	O
a	O
discriminative	Method
network	Method
.	O
use	O
an	O
additional	O
“	O
style	O
loss	O
”	O
based	O
on	O
Gram	O
matrices	O
of	O
feature	O
activations	O
.	O
Different	O
from	O
our	O
method	O
,	O
all	O
the	O
works	O
above	O
only	O
add	O
loss	O
terms	O
to	O
regularize	O
the	O
generator	O
’s	O
output	O
,	O
without	O
regularizing	O
its	O
internal	Method
representations	Method
.	O
Matching	Task
Intermediate	Task
Representations	Task
Between	O
Two	O
DNNs	Method
.	O
There	O
have	O
been	O
some	O
works	O
that	O
attempt	O
to	O
“	O
match	O
”	O
the	O
intermediate	Method
representations	Method
between	O
two	O
DNNs	Method
.	O
use	O
the	O
intermediate	Method
representations	Method
of	O
one	O
pre	Method
-	Method
trained	Method
DNN	Method
to	O
guide	O
another	O
DNN	Method
in	O
the	O
context	O
of	O
knowledge	Task
transfer	Task
.	O
Our	O
method	O
can	O
be	O
considered	O
as	O
a	O
special	O
kind	O
of	O
knowledge	Task
transfer	Task
.	O
However	O
,	O
we	O
aim	O
at	O
transferring	O
the	O
knowledge	O
in	O
a	O
bottom	Method
-	Method
up	Method
DNN	Method
to	O
a	O
top	Method
-	Method
down	Method
generative	Method
model	Method
,	O
instead	O
of	O
another	O
bottom	Method
-	Method
up	Method
DNN	Method
.	O
Also	O
,	O
some	O
auto	Method
-	Method
encoder	Method
architectures	Method
employ	O
layer	Method
-	Method
wise	Method
reconstruction	Method
loss	Method
.	O
The	O
layer	O
-	O
wise	O
loss	O
is	O
usually	O
accompanied	O
by	O
lateral	O
connections	O
from	O
the	O
encoder	Method
to	O
the	O
decodery	O
.	O
On	O
the	O
other	O
hand	O
,	O
SGAN	Method
is	O
a	O
generative	Method
model	Method
and	O
does	O
not	O
require	O
any	O
information	O
from	O
the	O
encoder	Method
once	O
training	O
completes	O
.	O
Another	O
important	O
difference	O
is	O
that	O
we	O
use	O
adversarial	O
loss	O
instead	O
of	O
reconstruction	O
loss	O
to	O
match	O
intermediate	O
representations	O
.	O
Visualizing	Task
Deep	Task
Representations	Task
.	O
Our	O
work	O
is	O
also	O
related	O
to	O
the	O
recent	O
efforts	O
in	O
visualizing	O
the	O
internal	Task
representations	Task
of	Task
DNNs	Task
.	O
One	O
popular	O
approach	O
uses	O
gradient	Method
-	Method
based	Method
optimization	Method
to	O
find	O
an	O
image	O
whose	O
representation	O
is	O
close	O
to	O
the	O
one	O
we	O
want	O
to	O
visualize	O
.	O
Other	O
approaches	O
,	O
such	O
as	O
,	O
train	O
a	O
top	Method
-	Method
down	Method
deconvolutional	Method
network	Method
to	O
reconstruct	O
the	O
input	O
image	O
from	O
a	O
feature	Method
representation	Method
by	O
minimizing	O
the	O
Euclidean	Metric
reconstruction	Metric
error	Metric
in	O
image	O
space	O
.	O
However	O
,	O
there	O
is	O
inherent	O
uncertainty	O
in	O
the	O
reconstruction	Task
process	Task
,	O
since	O
the	O
representations	O
in	O
higher	O
layers	O
of	O
the	O
DNN	Method
are	O
trained	O
to	O
be	O
invariant	O
to	O
irrelevant	O
transformations	O
and	O
to	O
ignore	O
low	O
-	O
level	O
details	O
.	O
With	O
Euclidean	Metric
training	Metric
objective	Metric
,	O
the	O
deconvolutional	Method
network	Method
tends	O
to	O
produce	O
blurry	O
images	O
.	O
To	O
alleviate	O
this	O
problem	O
,	O
Dosovitskiy	O
abd	O
Brox	O
further	O
propose	O
a	O
feature	Method
loss	Method
and	O
an	O
adversarial	Method
loss	Method
that	O
enables	O
much	O
sharper	Task
reconstructions	Task
.	O
However	O
,	O
it	O
still	O
does	O
not	O
tackle	O
the	O
problem	O
of	O
uncertainty	Task
in	Task
reconstruction	Task
.	O
Given	O
a	O
high	O
-	O
level	Method
feature	Method
representation	Method
,	O
the	O
deconvolutional	Method
network	Method
deterministically	O
generates	O
a	O
single	O
image	O
,	O
despite	O
the	O
fact	O
that	O
there	O
exist	O
many	O
images	O
having	O
the	O
same	O
representation	O
.	O
Also	O
,	O
there	O
is	O
no	O
obvious	O
way	O
to	O
sample	O
images	O
because	O
the	O
feature	O
prior	O
distribution	O
is	O
unknown	O
.	O
Concurrent	O
to	O
our	O
work	O
,	O
Nguyen	O
incorporate	O
the	O
feature	Method
prior	Method
with	O
a	O
variant	O
of	O
denoising	Method
auto	Method
-	Method
encoder	Method
(	Method
DAE	Method
)	O
.	O
Their	O
sampling	O
relies	O
on	O
an	O
iterative	Method
optimization	Method
procedure	Method
,	O
while	O
we	O
are	O
focused	O
on	O
efficient	O
feed	Method
-	Method
forward	Method
sampling	Method
.	O
section	O
:	O
Methods	O
In	O
this	O
section	O
we	O
introduce	O
our	O
model	O
architecture	O
.	O
In	O
Sec	O
.	O
[	O
reference	O
]	O
we	O
briefly	O
overview	O
the	O
framework	O
of	O
Generative	Method
Adversarial	Method
Networks	Method
.	O
We	O
then	O
describe	O
our	O
proposal	O
for	O
Stacked	Method
Generative	Method
Adversarial	Method
Networks	Method
in	O
Sec	O
.	O
[	O
reference	O
]	O
.	O
In	O
Sect	O
.	O
[	O
reference	O
]	O
and	O
[	O
reference	O
]	O
we	O
will	O
focus	O
on	O
our	O
two	O
novel	O
loss	Metric
functions	Metric
,	O
conditional	O
loss	O
and	O
entropy	Method
loss	Method
,	O
respectively	O
.	O
subsection	O
:	O
Background	O
:	O
Generative	Method
Adversarial	Method
Network	Method
As	O
shown	O
in	O
Fig	O
.	O
[	O
reference	O
]	O
(	O
a	O
)	O
,	O
the	O
original	O
GAN	Method
is	O
trained	O
using	O
a	O
two	O
-	O
player	Method
min	Method
-	Method
max	Method
game	Method
:	O
a	O
discriminator	Method
trained	O
to	O
distinguish	O
generated	O
images	O
from	O
real	O
images	O
,	O
and	O
a	O
generator	Method
trained	O
to	O
fool	O
.	O
The	O
discriminator	Metric
loss	Metric
and	O
the	O
generator	Metric
loss	Metric
are	O
defined	O
as	O
follows	O
:	O
In	O
practice	O
,	O
and	O
are	O
usually	O
updated	O
alternately	O
.	O
The	O
training	O
process	O
matches	O
the	O
generated	O
image	O
distribution	O
with	O
the	O
real	O
image	O
distribution	O
in	O
the	O
training	O
set	O
.	O
In	O
other	O
words	O
,	O
The	O
adversarial	Method
training	Method
forces	O
to	O
generate	O
images	O
that	O
reside	O
on	O
the	O
natural	O
images	O
manifold	O
.	O
subsection	O
:	O
Stacked	Method
Generative	Method
Adversarial	Method
Networks	Method
Pre	O
-	O
trained	O
Encoder	Method
.	O
We	O
first	O
consider	O
a	O
bottom	Method
-	Method
up	Method
DNN	Method
pre	Method
-	Method
trained	O
for	O
classification	Task
,	O
which	O
is	O
referred	O
to	O
as	O
the	O
encoder	O
throughout	O
.	O
We	O
define	O
a	O
stack	Method
of	Method
bottom	Method
-	Method
up	Method
deterministic	Method
nonlinear	Method
mappings	Method
:	O
,	O
where	O
,	O
consists	O
of	O
a	O
sequence	O
of	O
neural	O
layers	O
(	O
e.g.	O
,	O
convolution	Method
,	O
pooling	Method
)	O
,	O
is	O
the	O
number	O
of	O
hierarchies	O
(	O
stacks	O
)	O
,	O
are	O
intermediate	Method
representations	Method
,	O
is	O
the	O
classification	O
result	O
,	O
and	O
is	O
the	O
input	O
image	O
.	O
Note	O
that	O
in	O
our	O
formulation	O
,	O
each	O
can	O
contain	O
multiple	O
layers	O
and	O
the	O
way	O
of	O
grouping	O
layers	O
together	O
into	O
is	O
determined	O
by	O
us	O
.	O
The	O
number	O
of	O
stacks	O
is	O
therefore	O
less	O
than	O
the	O
number	O
of	O
layers	O
in	O
and	O
is	O
also	O
determined	O
by	O
us	O
.	O
Stacked	Method
Generators	Method
.	O
Provided	O
with	O
a	O
pre	O
-	O
trained	O
encoder	Method
,	O
our	O
goal	O
is	O
to	O
train	O
a	O
top	Method
-	Method
down	Method
generator	Method
that	O
inverts	O
.	O
Specifically	O
,	O
consists	O
of	O
a	O
top	Method
-	Method
down	Method
stack	Method
of	Method
generators	Method
,	O
each	O
trained	O
to	O
invert	O
a	O
bottom	Method
-	Method
up	Method
mapping	Method
.	O
Each	O
takes	O
in	O
a	O
higher	O
-	O
level	O
feature	O
and	O
a	O
noise	O
vector	O
as	O
inputs	O
,	O
and	O
outputs	O
the	O
lower	O
-	O
level	O
feature	O
.	O
We	O
first	O
train	O
each	O
GAN	Method
independently	O
and	O
then	O
train	O
them	O
jointly	O
in	O
an	O
end	O
-	O
to	O
-	O
end	O
manner	O
,	O
as	O
shown	O
in	O
Fig	O
.	O
[	O
reference	O
]	O
.	O
Each	O
generator	O
receives	O
conditional	O
input	O
from	O
encoders	Method
in	O
the	O
independent	Method
training	Method
stage	Method
,	O
and	O
from	O
the	O
upper	Method
generators	Method
in	O
the	O
joint	Method
training	Method
stage	Method
.	O
In	O
other	O
words	O
,	O
during	O
independent	Task
training	Task
and	O
during	O
joint	Task
training	Task
.	O
The	O
loss	Method
equations	Method
shown	O
in	O
this	O
section	O
are	O
for	O
independent	Task
training	Task
stage	Task
but	O
can	O
be	O
easily	O
modified	O
to	O
joint	Task
training	Task
by	O
replacing	O
with	O
.	O
Intuitively	O
,	O
the	O
total	O
variations	O
of	O
images	O
could	O
be	O
decomposed	O
into	O
multiple	O
levels	O
,	O
with	O
higher	O
-	O
level	O
semantic	O
variations	O
(	O
e.g.	O
,	O
attributes	O
,	O
object	O
categories	O
,	O
rough	O
shapes	O
)	O
and	O
lower	O
-	O
level	O
variations	O
(	O
e.g.	O
,	O
detailed	O
contours	O
and	O
textures	O
,	O
background	O
clutters	O
)	O
.	O
Our	O
model	O
allows	O
using	O
different	O
noise	O
variables	O
to	O
represent	O
different	O
levels	O
of	O
variations	O
.	O
The	O
training	O
procedure	O
is	O
shown	O
in	O
Fig	O
.	O
[	O
reference	O
]	O
(	O
b	O
)	O
.	O
Each	O
generator	O
is	O
trained	O
with	O
a	O
linear	Method
combination	Method
of	Method
three	Method
loss	Method
terms	Method
:	O
adversarial	O
loss	O
,	O
conditional	Method
loss	Method
,	O
and	O
entropy	Method
loss	Method
.	O
where	O
,	O
,	O
denote	O
adversarial	O
loss	O
,	O
conditional	O
loss	O
,	O
and	O
entropy	O
loss	O
respectively	O
.	O
,	O
,	O
are	O
the	O
weights	O
associated	O
with	O
different	O
loss	O
terms	O
.	O
In	O
practice	O
,	O
we	O
find	O
it	O
sufficient	O
to	O
set	O
the	O
weights	O
such	O
that	O
the	O
magnitude	O
of	O
different	O
terms	O
are	O
of	O
similar	O
scales	O
.	O
In	O
this	O
subsection	O
we	O
first	O
introduce	O
the	O
adversarial	O
loss	O
.	O
We	O
will	O
then	O
introduce	O
and	O
in	O
Sec	O
.	O
[	O
reference	O
]	O
and	O
[	O
reference	O
]	O
respectively	O
.	O
For	O
each	O
generator	O
,	O
we	O
introduce	O
a	O
representation	Method
discriminator	Method
that	O
distinguishes	O
generated	Method
representations	Method
,	O
from	O
“	O
real	Method
”	Method
representations	Method
.	O
Specifically	O
,	O
the	O
discriminator	Method
is	O
trained	O
with	O
the	O
loss	O
function	O
:	O
And	O
is	O
trained	O
to	O
“	O
fool	O
”	O
the	O
representation	Method
discriminator	Method
,	O
with	O
the	O
adversarial	O
loss	O
defined	O
by	O
:	O
During	O
joint	Method
training	Method
,	O
the	O
adversarial	O
loss	O
provided	O
by	O
representational	Method
discriminators	Method
can	O
also	O
be	O
regarded	O
as	O
a	O
type	O
of	O
deep	Method
supervision	Method
,	O
providing	O
intermediate	O
supervision	O
signals	O
.	O
In	O
our	O
current	O
formulation	O
,	O
is	O
a	O
discriminative	Method
model	Method
,	O
and	O
is	O
a	O
generative	Method
model	Method
conditioned	O
on	O
labels	O
.	O
However	O
,	O
it	O
is	O
also	O
possible	O
to	O
train	O
SGAN	Method
without	O
using	O
label	O
information	O
:	O
can	O
be	O
trained	O
with	O
an	O
unsupervised	O
objective	O
and	O
can	O
be	O
cast	O
into	O
an	O
unconditional	Method
generative	Method
model	Method
by	O
removing	O
the	O
label	O
input	O
from	O
the	O
top	Method
generator	Method
.	O
We	O
leave	O
this	O
for	O
future	O
exploration	O
.	O
Sampling	Task
.	O
To	O
sample	O
images	O
,	O
all	O
s	O
are	O
stacked	O
together	O
in	O
a	O
top	O
-	O
down	O
manner	O
,	O
as	O
shown	O
in	O
Fig	O
.	O
[	O
reference	O
]	O
(	O
c	O
)	O
.	O
Our	O
SGAN	Method
is	O
capable	O
of	O
modeling	O
the	O
data	O
distribution	O
conditioned	O
on	O
the	O
class	O
label	O
:	O
,	O
where	O
each	O
is	O
modeled	O
by	O
a	O
generator	Method
.	O
From	O
an	O
information	O
-	O
theoretic	O
perspective	O
,	O
SGAN	Method
factorizes	O
the	O
total	O
entropy	O
of	O
the	O
image	O
distribution	O
into	O
multiple	O
(	O
smaller	O
)	O
conditional	O
entropy	O
terms	O
:	O
,	O
thereby	O
decomposing	O
one	O
difficult	O
task	O
into	O
multiple	O
easier	O
tasks	O
.	O
subsection	O
:	O
Conditional	O
Loss	O
At	O
each	O
stack	O
,	O
a	O
generator	Method
is	O
trained	O
to	O
capture	O
the	O
distribution	O
of	O
lower	O
-	O
level	O
representations	O
,	O
conditioned	O
on	O
higher	O
-	O
level	O
representations	O
.	O
However	O
,	O
in	O
the	O
above	O
formulation	O
,	O
the	O
generator	Method
might	O
choose	O
to	O
ignore	O
,	O
and	O
generate	O
plausible	O
from	O
scratch	O
.	O
Some	O
previous	O
works	O
tackle	O
this	O
problem	O
by	O
feeding	O
the	O
conditional	O
information	O
to	O
both	O
the	O
generator	Method
and	Method
discriminator	Method
.	O
This	O
approach	O
,	O
however	O
,	O
might	O
introduce	O
unnecessary	O
complexity	O
to	O
the	O
discriminator	Method
and	O
increase	O
model	O
instability	O
.	O
Here	O
we	O
adopt	O
a	O
different	O
approach	O
:	O
we	O
regularize	O
the	O
generator	O
by	O
adding	O
a	O
loss	Method
term	Method
named	O
conditional	O
loss	O
.	O
We	O
feed	O
the	O
generated	O
lower	O
-	O
level	O
representations	O
back	O
to	O
the	O
encoder	Method
,	O
and	O
compute	O
the	O
recovered	O
higher	Method
-	Method
level	Method
representations	Method
.	O
We	O
then	O
enforce	O
the	O
recovered	O
representations	O
to	O
be	O
similar	O
to	O
the	O
conditional	Method
representations	Method
.	O
Formally	O
:	O
where	O
is	O
a	O
distance	Metric
measure	Metric
.	O
We	O
define	O
to	O
be	O
the	O
Euclidean	O
distance	O
for	O
intermediate	Method
representations	Method
and	O
cross	O
-	O
entropy	O
for	O
labels	O
.	O
Our	O
conditional	Method
loss	Method
is	O
similar	O
to	O
the	O
“	O
feature	O
loss	O
”	O
used	O
by	O
and	O
the	O
“	O
FCN	Method
loss	Method
”	O
in	O
.	O
subsection	O
:	O
Entropy	Metric
Loss	Metric
Simply	O
adding	O
the	O
conditional	O
loss	O
leads	O
to	O
another	O
issue	O
:	O
the	O
generator	Method
learns	O
to	O
ignore	O
the	O
noise	O
,	O
and	O
compute	O
deterministically	O
from	O
.	O
This	O
problem	O
has	O
been	O
encountered	O
in	O
various	O
applications	O
of	O
conditional	O
GANs	Method
,	O
e.g.	O
,	O
synthesizing	O
future	O
frames	O
conditioned	O
on	O
previous	O
frames	O
,	O
generating	O
images	O
conditioned	O
on	O
label	O
maps	O
,	O
and	O
most	O
related	O
to	O
our	O
work	O
,	O
synthesizing	O
images	O
conditioned	O
on	O
feature	Method
representations	Method
.	O
All	O
the	O
above	O
works	O
attempted	O
to	O
generate	O
diverse	O
images	O
/	O
videos	O
by	O
feeding	O
noise	O
to	O
the	O
generator	O
,	O
but	O
failed	O
because	O
the	O
conditional	Method
generator	Method
simply	O
ignores	O
the	O
noise	O
.	O
To	O
our	O
knowledge	O
,	O
there	O
is	O
still	O
no	O
principled	O
way	O
to	O
deal	O
with	O
this	O
issue	O
.	O
It	O
might	O
be	O
tempting	O
to	O
think	O
that	O
minibatch	Method
discrimination	Method
,	O
which	O
encourages	O
sample	O
diversity	O
in	O
each	O
minibatch	O
,	O
could	O
solve	O
this	O
problem	O
.	O
However	O
,	O
even	O
if	O
the	O
generator	Method
generates	O
deterministically	O
from	O
,	O
the	O
generated	O
samples	O
in	O
each	O
minibatch	O
are	O
still	O
diverse	O
since	O
generators	O
are	O
conditioned	O
on	O
different	O
.	O
Thus	O
,	O
there	O
is	O
no	O
obvious	O
way	O
minibatch	Method
discrimination	Method
could	O
penalize	O
a	O
collapsed	Method
conditional	Method
generator	Method
.	O
Variational	Method
Conditional	Method
Entropy	Method
Maximization	Method
.	O
To	O
tackle	O
this	O
problem	O
,	O
we	O
would	O
like	O
to	O
encourage	O
the	O
generated	O
representation	O
to	O
be	O
sufficiently	O
diverse	O
when	O
conditioned	O
on	O
,	O
i.e.	O
,	O
the	O
conditional	O
entropy	O
should	O
be	O
as	O
high	O
as	O
possible	O
.	O
Since	O
directly	O
maximizing	O
is	O
intractable	O
,	O
we	O
propose	O
to	O
maximize	O
instead	O
a	O
variational	O
lower	O
bound	O
on	O
the	O
conditional	O
entropy	O
.	O
Specifically	O
,	O
we	O
use	O
an	O
auxiliary	O
distribution	O
to	O
approximate	O
the	O
true	O
posterior	O
,	O
and	O
augment	O
the	O
training	Metric
objective	Metric
with	O
a	O
loss	O
term	O
named	O
entropy	Metric
loss	Metric
:	O
Below	O
we	O
give	O
a	O
proof	O
that	O
minimizing	Task
is	O
equivalent	O
to	O
maximizing	O
a	O
variational	O
lower	O
bound	O
for	O
.	O
In	O
practice	O
,	O
we	O
parameterize	O
with	O
a	O
deep	Method
network	Method
that	O
predicts	O
the	O
posterior	O
distribution	O
of	O
given	O
.	O
shares	O
most	O
of	O
the	O
parameters	O
with	O
.	O
We	O
treat	O
the	O
posterior	O
as	O
a	O
diagonal	Method
Gaussian	Method
with	O
fixed	O
standard	O
deviations	O
,	O
and	O
use	O
the	O
network	O
to	O
only	O
predict	O
the	O
posterior	O
mean	O
,	O
making	O
equivalent	O
to	O
the	O
Euclidean	Metric
reconstruction	Metric
error	Metric
.	O
In	O
each	O
iteration	O
we	O
update	O
both	O
and	O
to	O
minimize	O
.	O
Our	O
method	O
is	O
similar	O
to	O
the	O
variational	Method
mutual	Method
information	Method
maximization	Method
technique	Method
proposed	O
by	O
Chen	O
.	O
A	O
key	O
difference	O
is	O
that	O
uses	O
the	O
-	O
network	O
to	O
predict	O
only	O
a	O
small	O
set	O
of	O
deliberately	O
constructed	O
“	O
latent	O
code	O
”	O
,	O
while	O
our	O
tries	O
to	O
predict	O
all	O
the	O
noise	O
variables	O
in	O
each	O
stack	O
.	O
The	O
loss	O
used	O
in	O
therefore	O
maximizes	O
the	O
mutual	O
information	O
between	O
the	O
output	O
and	O
the	O
latent	O
code	O
,	O
while	O
ours	O
maximizes	O
the	O
entropy	O
of	O
the	O
output	O
,	O
conditioned	O
on	O
.	O
also	O
train	O
a	O
separate	O
network	O
to	O
map	O
images	O
back	O
to	O
latent	O
space	O
to	O
perform	O
unsupervised	Task
feature	Task
learning	Task
.	O
Independent	O
of	O
our	O
work	O
,	O
proposes	O
to	O
regularize	O
EBGAN	Method
with	O
entropy	Method
maximization	Method
in	O
order	O
to	O
prevent	O
the	O
discriminator	O
from	O
degenerating	O
to	O
uniform	Task
prediction	Task
.	O
Our	O
entropy	Method
loss	Method
is	O
motivated	O
from	O
generating	O
multiple	O
possible	O
outputs	O
from	O
the	O
same	O
conditional	O
input	O
.	O
section	O
:	O
Experiments	O
In	O
this	O
section	O
,	O
we	O
perform	O
experiments	O
on	O
a	O
variety	O
of	O
datasets	O
including	O
MNIST	O
,	O
SVHN	O
,	O
and	O
CIFAR	Material
-	Material
10	Material
.	O
Code	O
and	O
pre	O
-	O
trained	O
models	O
are	O
available	O
at	O
:	O
.	O
Readers	O
may	O
refer	O
to	O
our	O
code	O
repository	O
for	O
more	O
details	O
about	O
experimental	O
setup	O
,	O
hyper	O
-	O
parameters	O
,	O
etc	O
.	O
Encoder	Method
:	O
For	O
all	O
datasets	O
we	O
use	O
a	O
small	O
CNN	Method
with	O
two	O
convolutional	Method
layers	Method
as	O
our	O
encoder	O
:	O
conv1	Method
-	Method
pool1	Method
-	Method
conv2	Method
-	Method
pool2	Method
-	Method
fc3	Method
-	Method
fc4	Method
,	O
where	O
fc3	Method
is	O
a	O
fully	Method
connected	Method
layer	Method
and	O
fc4	Method
outputs	O
classification	O
scores	O
before	O
softmax	O
.	O
On	O
CIFAR	Material
-	Material
10	Material
we	O
apply	O
horizontal	Method
flipping	Method
to	O
train	O
the	O
encoder	O
.	O
No	O
data	Method
augmentation	Method
is	O
used	O
on	O
other	O
datasets	O
.	O
Generator	O
:	O
We	O
use	O
generators	O
with	O
two	O
stacks	O
throughout	O
our	O
experiments	O
.	O
Note	O
that	O
our	O
framework	O
is	O
generally	O
applicable	O
to	O
the	O
setting	O
with	O
multiple	O
stacks	O
,	O
and	O
we	O
hypothesize	O
that	O
using	O
more	O
stacks	O
would	O
be	O
helpful	O
for	O
large	Task
-	Task
scale	Task
and	Task
high	Task
-	Task
resolution	Task
datasets	Task
.	O
For	O
all	O
datasets	O
,	O
our	O
top	Method
GAN	Method
generates	O
fc3	O
features	O
from	O
some	O
random	O
noise	O
,	O
conditioned	O
on	O
label	O
.	O
The	O
bottom	O
GAN	Method
generates	O
images	O
from	O
some	O
noise	O
,	O
conditioned	O
on	O
fc3	O
features	O
generated	O
from	O
GAN	Method
.	O
We	O
set	O
the	O
loss	O
coefficient	O
parameters	O
and	O
.	O
subsection	O
:	O
Datasets	O
We	O
thoroughly	O
evaluate	O
SGAN	Method
on	O
three	O
widely	O
adopted	O
datasets	O
:	O
MNIST	O
,	O
SVHN	O
,	O
and	O
CIFAR	Material
-	Material
10	Material
.	O
The	O
details	O
of	O
each	O
dataset	O
is	O
described	O
in	O
the	O
following	O
.	O
MNIST	O
:	O
The	O
MNIST	O
dataset	O
contains	O
labeled	O
images	O
of	O
hand	O
-	O
written	O
digits	O
with	O
in	O
the	O
training	O
set	O
and	O
in	O
the	O
test	O
set	O
.	O
Each	O
image	O
is	O
sized	O
by	O
.	O
SVHN	O
:	O
The	O
SVHN	O
dataset	O
is	O
composed	O
of	O
real	O
-	O
world	O
color	O
images	O
of	O
house	O
numbers	O
collected	O
by	O
Google	O
Street	O
View	O
.	O
Each	O
image	O
is	O
of	O
size	O
and	O
the	O
task	O
is	O
to	O
classify	O
the	O
digit	O
at	O
the	O
center	O
of	O
the	O
image	O
.	O
The	O
dataset	O
contains	O
training	O
images	O
and	O
test	O
images	O
.	O
CIFAR	Material
-	Material
10	Material
:	O
The	O
CIFAR	Material
-	Material
10	Material
dataset	Material
consists	O
of	O
colored	O
natural	O
scene	O
images	O
sized	O
at	O
pixels	O
.	O
There	O
are	O
50	O
,	O
000	O
training	O
images	O
and	O
10	O
,	O
000	O
test	O
images	O
in	O
classes	O
.	O
subsection	O
:	O
Samples	O
In	O
Fig	O
.	O
[	O
reference	O
]	O
(	O
a	O
)	O
,	O
we	O
show	O
MNIST	O
samples	O
generated	O
by	O
SGAN	Method
.	O
Each	O
row	O
corresponds	O
to	O
samples	O
conditioned	O
on	O
a	O
given	O
digit	O
class	O
label	O
.	O
SGAN	Method
is	O
able	O
to	O
generate	O
diverse	O
images	O
with	O
different	O
characteristics	O
.	O
The	O
samples	O
are	O
visually	O
indistinguishable	O
from	O
real	O
MNIST	O
images	O
shown	O
in	O
Fig	O
.	O
[	O
reference	O
]	O
(	O
b	O
)	O
,	O
but	O
still	O
have	O
differences	O
compared	O
with	O
corresponding	O
nearest	O
neighbor	O
training	O
images	O
.	O
We	O
further	O
examine	O
the	O
effect	O
of	O
entropy	O
loss	O
.	O
In	O
Fig	O
.	O
[	O
reference	O
]	O
(	O
c	O
)	O
we	O
show	O
the	O
samples	O
generated	O
by	O
bottom	O
GAN	Method
when	O
conditioned	O
on	O
a	O
fixed	O
fc3	O
feature	O
generated	O
by	O
the	O
top	Method
GAN	Method
.	O
The	O
samples	O
(	O
per	O
row	O
)	O
have	O
sufficient	O
low	O
-	O
level	O
variations	O
,	O
which	O
reassures	O
that	O
bottom	O
GAN	Method
learns	O
to	O
generate	O
images	O
without	O
ignoring	O
the	O
noise	O
.	O
In	O
contrast	O
,	O
in	O
Fig	O
.	O
[	O
reference	O
]	O
(	O
d	O
)	O
,	O
we	O
show	O
samples	O
generated	O
without	O
using	O
entropy	O
loss	O
for	O
bottom	Method
generator	Method
,	O
where	O
we	O
observe	O
that	O
the	O
bottom	O
GAN	Method
ignores	O
the	O
noise	O
and	O
instead	O
deterministically	O
generates	O
images	O
from	O
fc3	O
features	O
.	O
An	O
advantage	O
of	O
SGAN	Method
compared	O
with	O
a	O
vanilla	O
GAN	Method
is	O
its	O
interpretability	O
:	O
it	O
decomposes	O
the	O
total	O
variations	O
of	O
an	O
image	O
into	O
different	O
levels	O
.	O
For	O
example	O
,	O
in	O
MNIST	Method
it	O
decomposes	O
the	O
variations	O
into	O
that	O
represents	O
the	O
high	O
-	O
level	O
digit	O
label	O
,	O
that	O
captures	O
the	O
mid	O
-	O
level	O
coarse	O
pose	O
of	O
the	O
digit	O
and	O
that	O
represents	O
the	O
low	O
-	O
level	O
spatial	O
details	O
.	O
The	O
samples	O
generated	O
on	O
SVHN	O
and	O
CIFAR	Material
-	Material
10	Material
datasets	O
can	O
be	O
seen	O
in	O
Fig	O
.	O
[	O
reference	O
]	O
and	O
Fig	O
.	O
[	O
reference	O
]	O
,	O
respectively	O
.	O
Provided	O
with	O
the	O
same	O
fc3	O
feature	O
,	O
we	O
see	O
in	O
each	O
row	O
of	O
panel	O
(	O
c	O
)	O
that	O
SGAN	Method
is	O
able	O
to	O
generate	O
samples	O
with	O
similar	O
coarse	O
outline	O
but	O
different	O
lighting	O
conditions	O
and	O
background	O
clutters	O
.	O
Also	O
,	O
the	O
nearest	O
neighbor	O
images	O
in	O
the	O
training	O
set	O
indicate	O
that	O
SGAN	Method
is	O
not	O
simply	O
memorizing	O
training	O
data	O
,	O
but	O
can	O
truly	O
generate	O
novel	O
images	O
.	O
subsection	O
:	O
Comparison	O
with	O
the	O
state	O
of	O
the	O
art	O
Here	O
,	O
we	O
compare	O
SGAN	Method
with	O
other	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
generative	Method
models	Method
on	O
CIFAR	Material
-	Material
10	Material
dataset	Material
.	O
The	O
visual	Metric
quality	Metric
of	O
generated	O
images	O
is	O
measured	O
by	O
the	O
widely	O
used	O
metric	O
,	O
Inception	Metric
score	Metric
.	O
Following	O
,	O
we	O
sample	O
images	O
from	O
our	O
model	O
and	O
use	O
the	O
code	O
provided	O
by	O
to	O
compute	O
the	O
score	O
.	O
As	O
shown	O
in	O
Tab	O
.	O
[	O
reference	O
]	O
,	O
SGAN	Method
obtains	O
a	O
score	O
of	O
,	O
outperforming	O
AC	Method
-	Method
GAN	Method
(	Method
)	O
and	O
Improved	O
GAN	Method
(	O
)	O
.	O
Also	O
,	O
note	O
that	O
the	O
techniques	O
introduced	O
in	O
are	O
not	O
used	O
in	O
our	O
implementations	O
.	O
Incorporating	O
these	O
techniques	O
might	O
further	O
boost	O
the	O
performance	O
of	O
our	O
model	O
.	O
Trained	O
with	O
labels	O
.	O
subsection	O
:	O
Visual	Task
Turing	Task
test	Task
To	O
further	O
verify	O
the	O
effectiveness	O
of	O
SGAN	Method
,	O
we	O
conduct	O
human	Task
visual	Task
Turing	Task
test	Task
in	O
which	O
we	O
ask	O
AMT	Method
workers	Method
to	O
distinguish	O
between	O
real	O
images	O
and	O
images	O
generated	O
by	O
our	O
networks	O
.	O
We	O
exactly	O
follow	O
the	O
interface	O
used	O
in	O
Improved	O
GAN	Method
,	O
in	O
which	O
the	O
workers	O
are	O
given	O
images	O
at	O
each	O
time	O
and	O
can	O
receive	O
feedback	O
about	O
whether	O
their	O
answers	O
are	O
correct	O
.	O
With	O
votes	O
for	O
each	O
evaluated	O
model	O
,	O
our	O
AMT	Method
workers	Method
got	O
error	Metric
rate	Metric
for	O
samples	O
from	O
SGAN	Method
and	O
for	O
samples	O
from	O
DCGAN	Method
.	O
This	O
further	O
confirms	O
that	O
our	O
stacked	Method
design	Method
can	O
significantly	O
improve	O
the	O
image	Metric
quality	Metric
over	O
GAN	Method
without	O
stacking	O
.	O
subsection	O
:	O
More	O
ablation	Task
studies	Task
In	O
Sec	O
.	O
[	O
reference	O
]	O
we	O
have	O
examined	O
the	O
effect	O
of	O
entropy	O
loss	O
.	O
In	O
order	O
to	O
further	O
understand	O
the	O
effect	O
of	O
different	O
model	Method
components	Method
,	O
we	O
conduct	O
extensive	O
ablation	Task
studies	Task
by	O
evaluating	O
several	O
baseline	O
methods	O
on	O
CIFAR	Material
-	Material
10	Material
dataset	Material
.	O
If	O
not	O
mentioned	O
otherwise	O
,	O
all	O
models	O
below	O
use	O
the	O
same	O
training	O
hyper	O
-	O
parameters	O
as	O
the	O
full	Method
SGAN	Method
model	Method
.	O
SGAN	Method
:	O
The	O
full	O
model	O
,	O
as	O
described	O
in	O
Sec	O
.	O
[	O
reference	O
]	O
.	O
SGAN	Method
-	Method
no	Method
-	Method
joint	Method
:	O
Same	O
architecture	O
as	O
(	O
a	O
)	O
,	O
but	O
each	O
GAN	Method
is	O
trained	O
independently	O
,	O
and	O
there	O
is	O
no	O
final	O
joint	Method
training	Method
stage	Method
.	O
DCGAN	Method
(	O
)	O
:	O
This	O
is	O
a	O
single	O
GAN	Method
model	O
with	O
the	O
same	O
architecture	O
as	O
the	O
bottom	O
GAN	Method
in	O
SGAN	Method
,	O
except	O
that	O
the	O
generator	Method
is	O
conditioned	O
on	O
labels	O
instead	O
of	O
fc3	O
features	O
.	O
Note	O
that	O
other	O
techniques	O
proposed	O
in	O
this	O
paper	O
,	O
including	O
conditional	O
loss	O
and	O
entropy	Method
loss	Method
,	O
are	O
still	O
employed	O
.	O
We	O
also	O
tried	O
to	O
use	O
the	O
full	Method
generator	Method
in	O
SGAN	Method
as	O
the	O
baseline	O
,	O
instead	O
of	O
only	O
the	O
bottom	Method
generator	Method
.	O
However	O
,	O
we	O
failed	O
to	O
make	O
it	O
converge	O
,	O
possibly	O
because	O
is	O
too	O
deep	O
to	O
be	O
trained	O
without	O
intermediate	O
supervision	O
from	O
representation	Method
discriminators	Method
.	O
DCGAN	Method
(	O
)	O
:	O
Same	O
architecture	O
as	O
(	O
c	O
)	O
,	O
but	O
trained	O
without	O
entropy	O
loss	O
.	O
DCGAN	Method
(	O
)	O
:	O
Same	O
architecture	O
as	O
(	O
c	O
)	O
,	O
but	O
trained	O
without	O
conditional	O
loss	O
.	O
This	O
model	O
therefore	O
does	O
not	O
use	O
label	O
information	O
.	O
DCGAN	Method
(	O
)	O
:	O
Same	O
architecture	O
as	O
(	O
c	O
)	O
,	O
but	O
trained	O
with	O
neither	O
conditional	O
loss	O
nor	O
entropy	O
loss	O
.	O
This	O
model	O
also	O
does	O
not	O
use	O
label	O
information	O
.	O
It	O
can	O
be	O
viewed	O
as	O
a	O
plain	O
unconditional	Method
DCGAN	Method
model	Method
and	O
serves	O
as	O
the	O
ultimate	O
baseline	O
.	O
We	O
compare	O
the	O
generated	O
samples	O
(	O
Fig	O
.	O
[	O
reference	O
]	O
)	O
and	O
Inception	Metric
scores	Metric
(	O
Tab	O
.	O
[	O
reference	O
]	O
)	O
of	O
the	O
baseline	O
methods	O
.	O
Below	O
we	O
summarize	O
some	O
of	O
our	O
results	O
:	O
SGAN	Method
obtains	O
slightly	O
higher	O
Inception	Metric
score	Metric
than	O
SGAN	Method
-	Method
no	Method
-	Method
joint	Method
.	O
Yet	O
SGAN	Method
-	Method
no	Method
-	Method
joint	Method
also	O
generates	O
very	O
high	O
quality	O
samples	O
and	O
outperforms	O
all	O
previous	O
methods	O
in	O
terms	O
of	O
Inception	Metric
scores	Metric
.	O
SGAN	Method
,	O
either	O
with	O
or	O
without	O
joint	Method
training	Method
,	O
achieves	O
significantly	O
higher	O
Inception	Metric
score	Metric
and	O
better	O
sample	Metric
quality	Metric
than	O
the	O
baseline	O
DCGANs	Method
.	O
This	O
demonstrates	O
the	O
effectiveness	O
of	O
the	O
proposed	O
stacked	Method
approach	Method
.	O
As	O
shown	O
in	O
Fig	O
.	O
[	O
reference	O
]	O
(	O
d	O
)	O
,	O
DCGAN	Method
(	Method
)	O
collapses	O
to	O
generating	O
a	O
single	O
image	O
per	O
category	O
,	O
while	O
adding	O
the	O
entropy	O
loss	O
enables	O
it	O
to	O
generate	O
diverse	O
images	O
(	O
Fig	O
.	O
[	O
reference	O
]	O
(	O
c	O
)	O
)	O
.	O
This	O
further	O
demonstrates	O
that	O
entropy	O
loss	O
is	O
effective	O
at	O
improving	O
output	O
diversity	O
.	O
The	O
single	Method
DCGAN	Method
(	Method
)	Method
model	Method
obtains	O
higher	O
Inception	Metric
score	Metric
than	O
the	O
conditional	Method
DCGAN	Method
reported	O
in	O
.	O
This	O
suggests	O
that	O
might	O
offer	O
some	O
advantages	O
compared	O
to	O
a	O
plain	O
conditional	Method
DCGAN	Method
,	O
even	O
without	O
stacking	Method
.	O
In	O
general	O
,	O
Inception	Metric
score	Metric
correlates	O
well	O
with	O
visual	Metric
quality	Metric
of	Metric
images	Metric
.	O
However	O
,	O
it	O
seems	O
to	O
be	O
insensitive	O
to	O
diversity	O
issues	O
.	O
For	O
example	O
,	O
it	O
gives	O
the	O
same	O
score	O
to	O
Fig	O
.	O
[	O
reference	O
]	O
(	O
d	O
)	O
and	O
(	O
e	O
)	O
while	O
(	O
d	O
)	O
has	O
clearly	O
collapsed	O
.	O
This	O
is	O
consistent	O
with	O
results	O
in	O
.	O
section	O
:	O
Discussion	O
and	O
Future	O
Work	O
This	O
paper	O
introduces	O
a	O
top	Method
-	Method
down	Method
generative	Method
framework	Method
named	O
SGAN	Method
,	O
which	O
effectively	O
leverages	O
the	O
representational	O
information	O
from	O
a	O
pre	Method
-	Method
trained	Method
discriminative	Method
network	Method
.	O
Our	O
approach	O
decomposes	O
the	O
hard	O
problem	O
of	O
estimating	Task
image	Task
distribution	Task
into	O
multiple	O
relatively	O
easier	O
tasks	O
–	O
each	O
generating	O
plausible	Method
representations	Method
conditioned	O
on	O
higher	O
-	O
level	Method
representations	Method
.	O
The	O
key	O
idea	O
is	O
to	O
use	O
representation	Method
discriminators	Method
at	O
different	O
training	O
hierarchies	O
to	O
provide	O
intermediate	O
supervision	O
.	O
We	O
also	O
propose	O
a	O
novel	O
entropy	Method
loss	Method
to	O
tackle	O
the	O
problem	O
that	O
conditional	O
GANs	Method
tend	O
to	O
ignore	O
the	O
noise	O
.	O
Our	O
entropy	Method
loss	Method
could	O
be	O
employed	O
in	O
other	O
applications	O
of	O
conditional	O
GANs	Method
,	O
e.g.	O
,	O
synthesizing	O
different	O
future	O
frames	O
given	O
the	O
same	O
past	O
frames	O
,	O
or	O
generating	O
a	O
diverse	O
set	O
of	O
images	O
conditioned	O
on	O
the	O
same	O
label	O
map	O
.	O
We	O
believe	O
this	O
is	O
an	O
interesting	O
research	O
direction	O
in	O
the	O
future	O
.	O
subsubsection	O
:	O
Acknowledgments	O
We	O
would	O
like	O
to	O
thank	O
Danlu	O
Chen	O
for	O
the	O
help	O
with	O
Fig	O
.	O
[	O
reference	O
]	O
.	O
Also	O
,	O
we	O
want	O
to	O
thank	O
Danlu	O
Chen	O
,	O
Shuai	O
Tang	O
,	O
Saining	O
Xie	O
,	O
Zhuowen	O
Tu	O
,	O
Felix	O
Wu	O
and	O
Kilian	O
Weinberger	O
for	O
helpful	O
discussions	O
.	O
Yixuan	O
Li	O
is	O
supported	O
by	O
US	O
Army	O
Research	O
Office	O
W911NF	O
-	O
14	O
-	O
1	O
-	O
0477	O
.	O
Serge	O
Belongie	O
is	O
supported	O
in	O
part	O
by	O
a	O
Google	O
Focused	O
Research	O
Award	O
.	O
bibliography	O
:	O
References	O
