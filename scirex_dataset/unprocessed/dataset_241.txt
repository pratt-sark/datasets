document	O
:	O
Passage	Task
Re	Task
-	Task
ranking	Task
with	O
BERT	Method
Recently	O
,	O
neural	Method
models	Method
pretrained	O
on	O
a	O
language	Task
modeling	Task
task	Task
,	O
such	O
as	O
ELMo	Method
peters2017semi	O
,	O
OpenAI	Method
GPT	Method
radford2018improving	O
,	O
and	O
BERT	Method
devlin2018bert	O
,	O
have	O
achieved	O
impressive	O
results	O
on	O
various	O
natural	Task
language	Task
processing	Task
tasks	Task
such	O
as	O
question	Task
-	Task
answering	Task
and	O
natural	Task
language	Task
inference	Task
.	O
In	O
this	O
paper	O
,	O
we	O
describe	O
a	O
simple	O
re	O
-	O
implementation	O
of	O
BERT	Method
for	O
query	Task
-	Task
based	Task
passage	Task
re	Task
-	Task
ranking	Task
.	O
Our	O
system	O
is	O
the	O
state	O
of	O
the	O
art	O
on	O
the	O
TREC	Material
-	Material
CAR	Material
dataset	O
and	O
the	O
top	O
entry	O
in	O
the	O
leaderboard	O
of	O
the	O
MS	Material
MARCO	Material
passage	O
retrieval	O
task	O
,	O
outperforming	O
the	O
previous	O
state	O
of	O
the	O
art	O
by	O
27	O
%	O
(	O
relative	O
)	O
in	O
MRR@10	Metric
.	O
The	O
code	O
to	O
reproduce	O
our	O
results	O
is	O
available	O
at	O
section	O
:	O
Introduction	O
We	O
have	O
seen	O
rapid	O
progress	O
in	O
machine	Task
reading	Task
compression	Task
in	O
recent	O
years	O
with	O
the	O
introduction	O
of	O
large	O
-	O
scale	O
datasets	O
,	O
such	O
as	O
SQuAD	Material
rajpurkar2016squad	O
,	O
MS	Material
MARCO	Material
nguyen2016ms	O
,	O
SearchQA	Material
dunn2017searchqa	O
,	O
TriviaQA	Material
joshi2017triviaqa	O
,	O
and	O
QUASAR	Material
-	Material
T	Material
dhingra2017quasar	O
,	O
and	O
the	O
broad	O
adoption	O
of	O
neural	Method
models	Method
,	O
such	O
as	O
BiDAF	Method
seo2016bidirectional	O
,	O
DrQA	Method
chen2017reading	O
,	O
DocumentQA	Method
clark2017simple	O
,	O
and	O
QAnet	Method
yu2018qanet	O
.	O
The	O
information	Task
retrieval	Task
(	O
IR	Task
)	O
community	O
has	O
also	O
experienced	O
a	O
flourishing	O
development	O
of	O
neural	Method
ranking	Method
models	Method
,	O
such	O
as	O
DRMM	Method
guo2016deep	O
,	O
KNRM	Method
xiong2017end	O
,	O
Co	Method
-	Method
PACRR	Method
hui2018co	O
,	O
and	O
DUET	Method
mitra2017learning	O
.	O
However	O
,	O
until	O
recently	O
,	O
there	O
were	O
only	O
a	O
few	O
large	O
datasets	O
for	O
passage	Task
ranking	Task
,	O
with	O
the	O
notable	O
exception	O
of	O
the	O
TREC	Material
-	Material
CAR	Material
dietz2017trec	O
.	O
This	O
,	O
at	O
least	O
in	O
part	O
,	O
prevented	O
the	O
neural	Method
ranking	Method
models	Method
from	O
being	O
successful	O
when	O
compared	O
to	O
more	O
classical	O
IR	Method
techniques	Method
lin2019neural	O
.	O
We	O
argue	O
that	O
the	O
same	O
two	O
ingredients	O
that	O
made	O
possible	O
much	O
progress	O
on	O
the	O
reading	Task
comprehension	Task
task	Task
are	O
now	O
available	O
for	O
passage	Task
ranking	Task
task	Task
.	O
Namely	O
,	O
the	O
MS	Material
MARCO	Material
passage	Material
ranking	Material
dataset	Material
,	O
which	O
contains	O
one	O
million	O
queries	O
from	O
real	O
users	O
and	O
their	O
respective	O
relevant	O
passages	O
annotated	O
by	O
humans	O
,	O
and	O
BERT	Method
,	O
a	O
powerful	O
general	Method
purpose	Method
natural	Method
language	Method
processing	Method
model	Method
.	O
In	O
this	O
paper	O
,	O
we	O
describe	O
in	O
detail	O
how	O
we	O
have	O
re	O
-	O
purposed	O
BERT	Method
as	O
a	O
passage	Task
re	Task
-	Task
ranker	Task
and	O
achieved	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
results	O
on	O
the	O
MS	Material
MARCO	Material
passage	O
re	Task
-	Task
ranking	Task
task	Task
.	O
section	O
:	O
Passage	Task
Re	Task
-	Task
Ranking	Task
with	O
BERT	Method
paragraph	O
:	O
Task	O
A	O
simple	O
question	Task
-	Task
answering	Task
pipeline	Task
consists	O
of	O
three	O
main	O
stages	O
.	O
First	O
,	O
a	O
large	O
number	O
(	O
for	O
example	O
,	O
a	O
thousand	O
)	O
of	O
possibly	O
relevant	O
documents	O
to	O
a	O
given	O
question	O
are	O
retrieved	O
from	O
a	O
corpus	O
by	O
a	O
standard	O
mechanism	O
,	O
such	O
as	O
BM25	Method
.	O
In	O
the	O
second	O
stage	O
,	O
passage	Task
re	Task
-	Task
ranking	Task
,	O
each	O
of	O
these	O
documents	O
is	O
scored	O
and	O
re	O
-	O
ranked	O
by	O
a	O
more	O
computationally	O
-	O
intensive	O
method	O
.	O
Finally	O
,	O
the	O
top	O
ten	O
or	O
fifty	O
of	O
these	O
documents	O
will	O
be	O
the	O
source	O
for	O
the	O
candidate	O
answers	O
by	O
an	O
answer	Method
generation	Method
module	Method
.	O
In	O
this	O
paper	O
,	O
we	O
describe	O
how	O
we	O
implemented	O
the	O
second	O
stage	O
of	O
this	O
pipeline	O
,	O
passage	Task
re	Task
-	Task
ranking	Task
.	O
paragraph	O
:	O
Method	O
The	O
job	O
of	O
the	O
re	Task
-	Task
ranker	Task
is	O
to	O
estimate	O
a	O
score	O
of	O
how	O
relevant	O
a	O
candidate	O
passage	O
is	O
to	O
a	O
query	O
.	O
We	O
use	O
BERT	Method
as	O
our	O
re	Task
-	Task
ranker	Task
.	O
Using	O
the	O
same	O
notation	O
used	O
by	O
devlin2018bert	O
,	O
we	O
feed	O
the	O
query	O
as	O
sentence	O
A	O
and	O
the	O
passage	O
text	O
as	O
sentence	O
B.	O
We	O
truncate	O
the	O
query	O
to	O
have	O
at	O
most	O
64	O
tokens	O
.	O
We	O
also	O
truncate	O
the	O
passage	Material
text	Material
such	O
that	O
the	O
concatenation	O
of	O
query	O
,	O
passage	O
,	O
and	O
separator	O
tokens	O
have	O
the	O
maximum	O
length	O
of	O
512	O
tokens	O
.	O
We	O
use	O
a	O
model	O
as	O
a	O
binary	Method
classification	Method
model	Method
,	O
that	O
is	O
,	O
we	O
use	O
the	O
vector	O
as	O
input	O
to	O
a	O
single	Method
layer	Method
neural	Method
network	Method
to	O
obtain	O
the	O
probability	O
of	O
the	O
passage	O
being	O
relevant	O
.	O
We	O
compute	O
this	O
probability	O
for	O
each	O
passage	O
independently	O
and	O
obtain	O
the	O
final	O
list	O
of	O
passages	O
by	O
ranking	O
them	O
with	O
respect	O
to	O
these	O
probabilities	O
.	O
We	O
start	O
training	O
from	O
a	O
pre	O
-	O
trained	O
BERT	Method
model	O
and	O
fine	O
-	O
tune	O
it	O
to	O
our	O
re	Task
-	Task
ranking	Task
task	Task
using	O
the	O
cross	Metric
-	Metric
entropy	Metric
loss	Metric
:	O
where	O
is	O
the	O
set	O
of	O
indexes	O
of	O
the	O
relevant	O
passages	O
and	O
is	O
the	O
set	O
of	O
indexes	O
of	O
non	O
-	O
relevant	O
passages	O
in	O
top	O
-	O
1	O
,	O
000	O
documents	O
retrieved	O
with	O
BM25	Method
.	O
section	O
:	O
Experiments	O
We	O
train	O
and	O
evaluate	O
our	O
models	O
on	O
two	O
passage	O
-	O
ranking	O
datasets	O
,	O
MS	Material
MARCO	Material
and	O
TREC	Material
-	Material
CAR	Material
.	O
subsection	O
:	O
MS	Material
MARCO	Material
The	O
training	O
set	O
contains	O
approximately	O
400	O
M	O
tuples	O
of	O
a	O
query	O
,	O
relevant	O
and	O
non	O
-	O
relevant	O
passages	O
.	O
The	O
development	O
set	O
contains	O
approximately	O
6	O
,	O
900	O
queries	O
,	O
each	O
paired	O
with	O
the	O
top	O
1	O
,	O
000	O
passages	O
retrieved	O
with	O
BM25	Method
from	O
the	O
MS	Material
MARCO	Material
corpus	O
.	O
On	O
average	O
,	O
each	O
query	O
has	O
one	O
relevant	O
passage	O
.	O
However	O
,	O
some	O
have	O
no	O
relevant	O
passage	O
because	O
the	O
corpus	O
was	O
initially	O
constructed	O
by	O
retrieving	O
the	O
top	O
-	O
10	O
passages	O
from	O
the	O
Bing	Method
search	Method
engine	Method
and	O
then	O
annotated	O
.	O
Hence	O
,	O
some	O
of	O
the	O
relevant	O
passages	O
might	O
not	O
be	O
retrieved	O
by	O
BM25	Method
.	O
An	O
evaluation	O
set	O
with	O
approximately	O
6	O
,	O
800	O
queries	O
and	O
their	O
top	O
1	O
,	O
000	O
retrieved	O
passages	O
without	O
relevance	O
annotations	O
is	O
also	O
provided	O
.	O
paragraph	O
:	O
Training	O
We	O
fine	O
-	O
tune	O
the	O
model	O
using	O
TPUs	Method
with	O
a	O
batch	O
size	O
of	O
32	O
(	O
32	O
sequences	O
*	O
512	O
tokens	O
=	O
16	O
,	O
384	O
tokens	O
/	O
batch	O
)	O
for	O
400k	O
iterations	O
,	O
which	O
takes	O
approximately	O
70	O
hours	O
.	O
This	O
corresponds	O
to	O
training	O
on	O
12.8	O
M	O
(	O
400k	O
*	O
32	O
)	O
query	O
-	O
passage	O
pairs	O
or	O
less	O
than	O
2	O
%	O
of	O
the	O
full	O
training	O
set	O
.	O
We	O
could	O
not	O
see	O
any	O
improvement	O
in	O
the	O
dev	O
set	O
when	O
training	O
for	O
another	O
10	O
days	O
,	O
which	O
equivalent	O
to	O
seeing	O
50	O
M	O
pairs	O
in	O
total	O
.	O
We	O
use	O
ADAM	Method
kingma2014adam	Method
with	O
the	O
initial	O
learning	Metric
rate	Metric
set	O
to	O
,	O
,	O
,	O
L2	O
weight	O
decay	O
of	O
0.01	O
,	O
learning	Metric
rate	Metric
warmup	Metric
over	O
the	O
first	O
10	O
,	O
000	O
steps	O
,	O
and	O
linear	O
decay	O
of	O
the	O
learning	Metric
rate	Metric
.	O
We	O
use	O
a	O
dropout	O
probability	O
of	O
on	O
all	O
layers	O
.	O
subsection	O
:	O
TREC	Material
-	Material
CAR	Material
Introduced	O
by	O
dietz2017trec	O
,	O
in	O
this	O
dataset	O
,	O
the	O
input	O
query	O
is	O
the	O
concatenation	O
of	O
a	O
Wikipedia	O
article	O
title	O
with	O
the	O
title	O
of	O
one	O
of	O
its	O
section	O
.	O
The	O
relevant	O
passages	O
are	O
the	O
paragraphs	O
within	O
that	O
section	O
.	O
The	O
corpus	O
consists	O
of	O
all	O
of	O
the	O
English	Material
Wikipedia	Material
paragraphs	Material
,	O
except	O
the	O
abstracts	O
.	O
The	O
released	O
dataset	O
has	O
five	O
predefined	O
folds	O
,	O
and	O
we	O
use	O
the	O
first	O
four	O
as	O
a	O
training	O
set	O
(	O
approximately	O
3	O
M	O
queries	O
)	O
,	O
and	O
the	O
remaining	O
as	O
a	O
validation	O
set	O
(	O
approximately	O
700k	O
queries	O
)	O
.	O
The	O
test	O
set	O
is	O
the	O
same	O
one	O
used	O
to	O
evaluate	O
the	O
submissions	O
to	O
TREC	Material
-	Material
CAR	Material
2017	O
(	O
approx	O
.	O
1	O
,	O
800	O
queries	O
)	O
.	O
Although	O
TREC	Material
-	Material
CAR	Material
2017	O
organizers	O
provide	O
manual	O
annotations	O
for	O
the	O
test	O
set	O
,	O
only	O
the	O
top	O
five	O
passages	O
retrieved	O
by	O
the	O
systems	O
submitted	O
to	O
the	O
competition	O
have	O
manual	O
annotations	O
.	O
This	O
means	O
that	O
true	O
relevant	O
passages	O
are	O
not	O
annotated	O
if	O
they	O
rank	O
low	O
.	O
Hence	O
,	O
we	O
evaluate	O
using	O
the	O
automatic	O
annotations	O
,	O
which	O
provide	O
relevance	O
scores	O
for	O
all	O
possible	O
query	O
-	O
passage	O
pairs	O
.	O
paragraph	O
:	O
Training	O
We	O
follow	O
the	O
same	O
procedure	O
described	O
for	O
the	O
MS	Material
MARCO	Material
dataset	O
to	O
fine	O
-	O
tune	O
our	O
models	O
on	O
TREC	Material
-	Material
CAR	Material
.	O
However	O
,	O
there	O
is	O
an	O
important	O
difference	O
.	O
The	O
official	O
pre	O
-	O
trained	O
BERT	Method
models	O
were	O
pre	O
-	O
trained	O
on	O
the	O
full	O
Wikipedia	O
,	O
and	O
therefore	O
they	O
have	O
seen	O
,	O
although	O
in	O
an	O
unsupervised	O
way	O
,	O
Wikipedia	O
documents	O
that	O
are	O
used	O
in	O
the	O
test	O
set	O
of	O
TREC	Material
-	Material
CAR	Material
.	O
Thus	O
,	O
to	O
avoid	O
this	O
leak	O
of	O
test	O
data	O
into	O
training	O
,	O
we	O
pre	O
-	O
trained	O
the	O
BERT	Method
re	O
-	O
ranker	O
only	O
on	O
the	O
half	O
of	O
Wikipedia	O
used	O
by	O
TREC	Material
-	Material
CAR	Material
â€™s	O
training	O
set	O
.	O
For	O
the	O
fine	Task
-	Task
tuning	Task
data	Task
,	O
we	O
generate	O
our	O
query	O
-	O
passage	O
pairs	O
by	O
retrieving	O
the	O
top	O
ten	O
passages	O
from	O
the	O
entire	O
TREC	Material
-	Material
CAR	Material
corpus	O
using	O
BM25	Method
.	O
This	O
means	O
that	O
we	O
end	O
up	O
with	O
30	O
M	O
example	O
pairs	O
(	O
3	O
M	O
queries	O
*	O
10	O
passages	O
/	O
query	O
)	O
to	O
train	O
our	O
model	O
.	O
We	O
train	O
it	O
for	O
400k	O
iterations	O
,	O
or	O
12.8	O
M	O
examples	O
(	O
400k	O
iterations	O
*	O
32	O
pairs	O
/	O
batch	O
)	O
,	O
which	O
corresponds	O
to	O
only	O
40	O
%	O
of	O
the	O
training	O
set	O
.	O
Similarly	O
to	O
MS	Material
MARCO	Material
experiments	O
,	O
we	O
did	O
not	O
see	O
any	O
gain	O
on	O
the	O
dev	O
set	O
by	O
training	O
the	O
models	O
longer	O
.	O
subsection	O
:	O
Results	O
We	O
show	O
the	O
main	O
result	O
in	O
Table	O
[	O
reference	O
]	O
.	O
Despite	O
training	O
on	O
a	O
fraction	O
of	O
the	O
data	O
available	O
,	O
the	O
proposed	O
BERT	Method
-	O
based	O
models	O
surpass	O
the	O
previous	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
models	O
by	O
a	O
large	O
margin	O
on	O
both	O
of	O
the	O
tasks	O
.	O
paragraph	O
:	O
Training	Metric
size	Metric
vs	O
performance	O
:	O
We	O
found	O
that	O
the	O
pretrained	Method
models	Method
used	O
in	O
this	O
work	O
require	O
few	O
training	O
examples	O
from	O
the	O
end	O
task	O
to	O
achieve	O
a	O
good	O
performance	O
[	O
reference	O
]	O
.	O
For	O
example	O
,	O
a	O
trained	O
on	O
100k	O
question	O
-	O
passage	O
pairs	O
(	O
less	O
than	O
0.3	O
%	O
of	O
the	O
MS	Material
MARCO	Material
training	O
data	O
)	O
is	O
already	O
1.4	O
MRR@10	Metric
points	O
better	O
than	O
the	O
previous	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
,	O
IR	Task
-	O
NET	O
.	O
section	O
:	O
Conclusion	O
We	O
have	O
described	O
a	O
simple	O
adaptation	O
of	O
BERT	Method
as	O
a	O
passage	Task
re	Task
-	Task
ranker	Task
that	O
has	O
become	O
the	O
state	O
of	O
the	O
art	O
on	O
two	O
different	O
tasks	O
,	O
which	O
are	O
TREC	Material
-	Material
CAR	Material
and	O
MS	Material
MARCO	Material
.	O
We	O
have	O
made	O
the	O
code	O
to	O
reproduce	O
our	O
MS	Material
MARCO	Material
entry	O
publicly	O
available	O
.	O
bibliography	O
:	O
References	O
