Full	Method
-	Method
Resolution	Method
Residual	Method
Networks	Method
for	O
Semantic	Task
Segmentation	Task
in	O
Street	O
Scenes	O
section	O
:	O
Abstract	O
Semantic	Task
image	Task
segmentation	Task
is	O
an	O
essential	O
component	O
of	O
modern	O
autonomous	Task
driving	Task
systems	Task
,	O
as	O
an	O
accurate	Task
understanding	Task
of	Task
the	Task
surrounding	Task
scene	Task
is	O
crucial	O
to	O
navigation	Task
and	Task
action	Task
planning	Task
.	O
Current	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
approaches	O
in	O
semantic	Task
image	Task
segmentation	Task
rely	O
on	O
pretrained	Method
networks	Method
that	O
were	O
initially	O
developed	O
for	O
classifying	Task
images	Task
as	O
a	O
whole	O
.	O
While	O
these	O
networks	O
exhibit	O
outstanding	O
recognition	Metric
performance	Metric
(	O
i.e.	O
,	O
what	O
is	O
visible	O
?	O
)	O
,	O
they	O
lack	O
localization	Metric
accuracy	O
(	O
i.e.	O
,	O
where	O
precisely	O
is	O
something	O
located	O
?	O
)	O
.	O
Therefore	O
,	O
additional	O
processing	O
steps	O
have	O
to	O
be	O
performed	O
in	O
order	O
to	O
obtain	O
pixel	O
-	O
accurate	O
segmentation	O
masks	O
at	O
the	O
full	O
image	O
resolution	O
.	O
To	O
alleviate	O
this	O
problem	O
we	O
propose	O
a	O
novel	O
ResNet	Method
-	O
like	O
architecture	O
that	O
exhibits	O
strong	O
localization	Metric
and	O
recognition	Metric
performance	Metric
.	O
We	O
combine	O
multi	O
-	O
scale	O
context	O
with	O
pixel	Metric
-	Metric
level	Metric
accuracy	Metric
by	O
using	O
two	O
processing	Method
streams	Method
within	O
our	O
network	O
:	O
One	O
stream	O
carries	O
information	O
at	O
the	O
full	O
image	O
resolution	O
,	O
enabling	O
precise	O
adherence	O
to	O
segment	O
boundaries	O
.	O
The	O
other	O
stream	O
undergoes	O
a	O
sequence	O
of	O
pooling	Method
operations	O
to	O
obtain	O
robust	O
features	O
for	O
recognition	Task
.	O
The	O
two	O
streams	O
are	O
coupled	O
at	O
the	O
full	O
image	O
resolution	O
using	O
residuals	O
.	O
Without	O
additional	O
processing	O
steps	O
and	O
without	O
pretraining	Method
,	O
our	O
approach	O
achieves	O
an	O
intersection	Metric
-	Metric
over	Metric
-	Metric
union	Metric
score	Metric
of	O
71.8	O
%	O
on	O
the	O
Cityscapes	Material
dataset	O
.	O
section	O
:	O
Introduction	O
Recent	O
years	O
have	O
seen	O
an	O
increasing	O
interest	O
in	O
self	Task
driving	Task
cars	Task
and	O
in	O
driver	Task
assistance	Task
systems	Task
.	O
A	O
crucial	O
aspect	O
of	O
autonomous	Task
driving	Task
is	O
to	O
acquire	O
a	O
comprehensive	O
understanding	O
of	O
the	O
surroundings	O
in	O
which	O
a	O
car	O
is	O
moving	O
.	O
Semantic	Task
image	Task
segmentation	Task
[	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
,	O
the	O
task	O
of	O
assigning	O
a	O
set	O
of	O
predefined	O
class	O
labels	O
to	O
image	O
pixels	O
,	O
is	O
an	O
important	O
tool	O
for	O
modeling	O
the	O
complex	O
relationships	O
of	O
the	O
semantic	O
entities	O
usually	O
found	O
in	O
street	O
scenes	O
,	O
such	O
as	O
cars	O
,	O
pedestrians	O
,	O
road	O
,	O
or	O
sidewalks	O
.	O
In	O
automotive	Task
scenarios	Task
it	O
is	O
used	O
in	O
various	O
ways	O
,	O
e.g.	O
as	O
a	O
pre	Task
-	Task
processing	Task
step	Task
to	O
discard	O
image	O
regions	O
that	O
are	O
unlikely	O
to	O
contain	O
objects	O
of	O
interest	O
[	O
reference	O
][	O
reference	O
]	O
,	O
to	O
improve	O
object	Task
detection	Task
[	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
.	O
Example	O
output	O
and	O
the	O
abstract	O
structure	O
of	O
our	O
fullresolution	Method
residual	Method
network	Method
.	O
The	O
network	O
has	O
two	O
processing	O
streams	O
.	O
The	O
residual	O
stream	O
(	O
blue	O
)	O
stays	O
at	O
the	O
full	O
image	O
resolution	O
,	O
the	O
pooling	Method
stream	O
(	O
red	O
)	O
undergoes	O
a	O
sequence	O
of	O
pooling	Method
and	O
unpooling	Method
operations	Method
.	O
The	O
two	O
processing	O
streams	O
are	O
coupled	O
using	O
full	Method
-	Method
resolution	Method
residual	Method
units	Method
[	O
reference	O
]	O
or	O
in	O
combination	O
with	O
3D	O
scene	O
geometry	O
[	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
.	O
Many	O
of	O
those	O
applications	O
require	O
precise	O
region	O
boundaries	O
[	O
reference	O
]	O
.	O
In	O
this	O
work	O
,	O
we	O
therefore	O
pursue	O
the	O
goal	O
of	O
achieving	O
high	O
-	O
quality	O
semantic	Task
segmentation	Task
with	O
precise	O
boundary	O
adherence	O
.	O
Current	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
approaches	O
for	O
image	Task
segmentation	Task
all	O
employ	O
some	O
form	O
of	O
fully	Method
convolutional	Method
network	Method
(	O
FCNs	Method
)	O
[	O
reference	O
]	O
that	O
takes	O
the	O
image	O
as	O
input	O
and	O
outputs	O
a	O
probability	O
map	O
for	O
each	O
class	O
.	O
Many	O
papers	O
rely	O
on	O
network	Method
architectures	Method
that	O
have	O
already	O
been	O
proven	O
successful	O
for	O
image	Task
classification	Task
such	O
as	O
variants	O
of	O
the	O
ResNet	Method
[	O
reference	O
]	O
or	O
the	O
VGG	Method
architecture	Method
[	O
reference	O
]	O
.	O
Starting	O
from	O
pre	O
-	O
trained	O
nets	O
,	O
where	O
a	O
large	O
number	O
of	O
weights	O
for	O
the	O
target	O
task	O
can	O
be	O
pre	O
-	O
set	O
by	O
an	O
auxiliary	Task
classification	Task
task	Task
,	O
reduces	O
training	Metric
time	Metric
and	O
often	O
yields	O
superior	O
performance	O
compared	O
to	O
training	O
a	O
network	O
from	O
scratch	O
using	O
the	O
(	O
possibly	O
limited	O
amount	O
of	O
)	O
data	O
of	O
the	O
target	O
application	O
.	O
However	O
,	O
a	O
main	O
limitation	O
of	O
using	O
such	O
pre	Method
-	Method
trained	Method
networks	Method
is	O
that	O
they	O
severely	O
restrict	O
the	O
design	O
space	O
of	O
novel	O
approaches	O
,	O
since	O
new	O
network	O
elements	O
such	O
as	O
batch	Method
normalization	Method
[	O
reference	O
]	O
or	O
new	O
activation	O
functions	O
often	O
can	O
not	O
be	O
added	O
into	O
an	O
existing	O
architecture	O
.	O
When	O
performing	O
semantic	Task
segmentation	Task
using	O
FCNs	Method
,	O
a	O
common	O
strategy	O
is	O
to	O
successively	O
reduce	O
the	O
spatial	O
size	O
of	O
the	O
feature	O
maps	O
using	O
pooling	Method
operations	O
or	O
strided	Method
convolutions	Method
.	O
This	O
is	O
done	O
for	O
two	O
reasons	O
:	O
First	O
,	O
it	O
significantly	O
increases	O
the	O
size	O
of	O
the	O
receptive	O
field	O
and	O
second	O
,	O
it	O
makes	O
the	O
network	O
robust	O
against	O
small	O
translations	O
in	O
the	O
image	O
.	O
While	O
pooling	Method
operations	O
are	O
highly	O
desirable	O
for	O
recognizing	Task
objects	Task
in	Task
images	Task
,	O
they	O
significantly	O
deteriorate	O
localization	Metric
performance	O
of	O
the	O
networks	O
when	O
applied	O
to	O
semantic	Task
image	Task
segmentation	Task
.	O
Several	O
approaches	O
exist	O
to	O
overcome	O
this	O
problem	O
and	O
obtain	O
pixel	Task
-	Task
accurate	Task
segmentations	Task
.	O
Noh	O
et	O
al	O
.	O
[	O
reference	O
]	O
learn	O
a	O
mirrored	Method
VGG	Method
network	Method
as	O
a	O
decoder	Method
,	O
Yu	O
and	O
Koltun	O
[	O
reference	O
]	O
introduce	O
dilated	Method
convolutions	Method
to	O
reduce	O
the	O
pooling	Method
factor	O
of	O
their	O
pre	Method
-	Method
trained	Method
network	Method
.	O
Ghiasi	O
et	O
al	O
.	O
[	O
reference	O
]	O
use	O
multi	O
-	O
scale	O
predictions	O
to	O
successively	O
improve	O
their	O
boundary	O
adherence	O
.	O
An	O
alternative	O
approach	O
used	O
by	O
several	O
methods	O
is	O
to	O
apply	O
post	Method
-	Method
processing	Method
steps	Method
such	O
as	O
CRF	Method
-	Method
smoothing	Method
[	O
reference	O
]	O
.	O
In	O
this	O
paper	O
,	O
we	O
propose	O
a	O
novel	O
network	Method
architecture	Method
that	O
achieves	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
segmentation	Task
performance	O
without	O
the	O
need	O
for	O
additional	O
post	Task
-	Task
processing	Task
steps	Task
and	O
without	O
the	O
limitations	O
imposed	O
by	O
pre	Method
-	Method
trained	Method
architectures	Method
.	O
Our	O
proposed	O
ResNet	Method
-	O
like	O
architecture	O
unites	O
strong	O
recognition	Metric
performance	Metric
with	O
precise	O
localization	Metric
capabilities	O
by	O
combining	O
two	O
distinct	O
processing	Method
streams	Method
.	O
One	O
stream	O
undergoes	O
a	O
sequence	O
of	O
pooling	Method
operations	O
and	O
is	O
responsible	O
for	O
understanding	O
large	Task
-	Task
scale	Task
relationships	Task
of	Task
image	Task
elements	Task
;	O
the	O
other	O
stream	O
carries	O
feature	O
maps	O
at	O
the	O
full	O
image	O
resolution	O
,	O
resulting	O
in	O
precise	O
boundary	O
adherence	O
.	O
This	O
idea	O
is	O
visualized	O
in	O
Figure	O
1	O
,	O
where	O
the	O
two	O
processing	O
streams	O
are	O
shown	O
in	O
blue	O
and	O
red	O
.	O
The	O
blue	O
residual	O
lane	O
reflects	O
the	O
high	O
-	O
resolution	O
stream	O
.	O
It	O
can	O
be	O
combined	O
with	O
classical	Method
residual	Method
units	Method
(	O
left	O
and	O
right	O
)	O
,	O
as	O
well	O
as	O
with	O
our	O
new	O
full	Method
-	Method
resolution	Method
residual	Method
units	Method
(	O
FRRU	Method
)	O
.	O
The	O
FRRUs	Method
from	O
the	O
red	O
pooling	Method
lane	O
act	O
as	O
residual	O
units	O
for	O
the	O
blue	O
stream	O
,	O
but	O
also	O
undergo	O
pooling	Method
operations	O
and	O
carry	O
high	O
-	O
level	O
information	O
through	O
the	O
network	O
.	O
This	O
results	O
in	O
a	O
network	O
that	O
successively	O
combines	O
and	O
computes	O
features	O
at	O
two	O
resolutions	O
.	O
This	O
paper	O
makes	O
the	O
following	O
contributions	O
:	O
(	O
i	O
)	O
We	O
propose	O
a	O
novel	O
network	Method
architecture	Method
geared	O
towards	O
precise	O
semantic	Task
segmentation	Task
in	O
street	Task
scenes	Task
which	O
is	O
not	O
limited	O
to	O
pre	O
-	O
trained	Method
architectures	Method
and	O
achieves	O
state	O
-	O
ofthe	O
-	O
art	O
results	O
.	O
(	O
ii	O
)	O
We	O
propose	O
to	O
use	O
two	O
processing	Method
streams	Method
to	O
realize	O
strong	O
recognition	Task
and	O
strong	O
localization	Metric
performance	O
:	O
One	O
stream	O
undergoes	O
a	O
sequence	O
of	O
pooling	Method
operations	O
while	O
the	O
other	O
stream	O
stays	O
at	O
the	O
full	O
image	O
resolution	O
.	O
(	O
iii	O
)	O
In	O
order	O
to	O
foster	O
further	O
research	O
in	O
this	O
area	O
,	O
we	O
publish	O
our	O
code	O
and	O
the	O
trained	O
models	O
in	O
Theano	O
/	O
Lasagne	O
[	O
reference	O
][	O
reference	O
]	O
1	O
.	O
1	O
https:	O
//	O
github.com	O
/	O
TobyPDE	O
/	O
FRRN	O
section	O
:	O
Related	O
Work	O
The	O
dramatic	O
performance	O
improvements	O
from	O
using	O
CNNs	Method
for	O
semantic	Task
segmentation	Task
have	O
brought	O
about	O
an	O
increasing	O
demand	O
for	O
such	O
algorithms	O
in	O
the	O
context	O
of	O
autonomous	Task
driving	Task
scenarios	Task
.	O
As	O
a	O
large	O
amount	O
of	O
annotated	O
data	O
is	O
crucial	O
in	O
order	O
to	O
train	O
such	O
deep	Method
networks	Method
,	O
multiple	O
new	O
datasets	O
have	O
been	O
released	O
to	O
encourage	O
further	O
research	O
in	O
this	O
area	O
,	O
including	O
Synthia	Material
[	O
reference	O
]	O
,	O
Virtual	Material
KITTI	Material
[	O
reference	O
]	O
,	O
and	O
Cityscapes	Material
[	O
reference	O
]	O
.	O
In	O
this	O
work	O
,	O
we	O
focus	O
on	O
Cityscapes	Material
,	O
a	O
recent	O
large	O
-	O
scale	O
dataset	O
consisting	O
of	O
real	O
-	O
world	O
imagery	O
with	O
well	O
-	O
curated	O
annotations	O
.	O
Given	O
their	O
success	O
,	O
we	O
will	O
constrain	O
our	O
literature	O
review	O
to	O
deep	Method
learning	Method
based	Method
semantic	Method
segmentation	Method
approaches	Method
and	O
deep	Method
learning	Method
network	Method
architectures	Method
.	O
Semantic	Task
Segmentation	Task
Approaches	O
.	O
Over	O
the	O
last	O
years	O
,	O
the	O
most	O
successful	O
semantic	Task
segmentation	Task
approaches	O
have	O
been	O
based	O
on	O
convolutional	Method
neural	Method
networks	Method
(	O
CNNs	Method
)	O
.	O
Early	O
approaches	O
constrained	O
their	O
output	O
to	O
a	O
bottom	Task
-	Task
up	Task
segmentation	Task
followed	O
by	O
a	O
CNN	Method
based	Method
region	Method
classification	Method
[	O
reference	O
]	O
.	O
Rather	O
than	O
classifying	O
entire	O
regions	O
in	O
the	O
first	O
place	O
,	O
the	O
approach	O
by	O
Farabet	O
et	O
al	O
.	O
performs	O
pixel	Method
-	Method
wise	Method
classification	Method
using	O
CNN	Method
features	Method
originating	O
from	O
multiple	O
scales	O
,	O
followed	O
by	O
aggregation	Method
of	O
these	O
noisy	O
pixel	O
predictions	O
over	O
superpixel	O
regions	O
[	O
reference	O
]	O
.	O
The	O
introduction	O
of	O
so	O
-	O
called	O
fully	Method
convolutional	Method
networks	Method
(	O
FCNs	Method
)	O
for	O
semantic	Task
image	Task
segmentation	Task
by	O
Long	O
et	O
al	O
.	O
[	O
reference	O
]	O
opened	O
a	O
wide	O
range	O
of	O
semantic	Task
segmentation	Task
research	O
using	O
end	O
-	O
to	O
-	O
end	O
training	O
[	O
reference	O
]	O
.	O
Long	O
et	O
al	O
.	O
further	O
reformulated	O
the	O
popular	O
VGG	Method
architecture	Method
[	O
reference	O
]	O
as	O
a	O
fully	Method
convolutional	Method
network	Method
(	O
FCN	Method
)	O
,	O
enabling	O
the	O
use	O
of	O
pretrained	Method
models	Method
for	O
this	O
architecture	O
.	O
To	O
improve	O
segmentation	Task
performance	O
at	O
object	O
boundaries	O
,	O
skip	O
connections	O
were	O
added	O
which	O
allow	O
information	O
to	O
propagate	O
directly	O
from	O
early	O
,	O
high	O
-	O
resolution	O
layers	O
to	O
deeper	O
layers	O
.	O
Pooling	Method
layers	Method
in	O
FCNs	Method
fulfill	O
a	O
crucial	O
role	O
in	O
order	O
to	O
increase	O
the	O
receptive	O
field	O
size	O
of	O
later	O
units	O
and	O
with	O
it	O
the	O
classification	Task
performance	O
.	O
However	O
,	O
they	O
have	O
the	O
downside	O
that	O
the	O
resulting	O
network	O
outputs	O
are	O
at	O
a	O
lower	O
resolution	O
.	O
To	O
overcome	O
this	O
,	O
various	O
strategies	O
have	O
been	O
proposed	O
.	O
Some	O
approaches	O
extract	O
features	O
from	O
intermediate	O
layers	O
via	O
some	O
sort	O
of	O
skip	O
connections	O
[	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
.	O
Noh	O
et	O
al	O
.	O
propose	O
an	O
encoder	Method
/	Method
decoder	Method
network	Method
[	O
reference	O
]	O
.	O
The	O
encoder	Method
computes	O
low	Method
-	Method
dimensional	Method
feature	Method
representations	Method
via	O
a	O
sequence	O
of	O
pooling	Method
and	O
convolution	Method
operations	Method
.	O
The	O
decoder	Method
,	O
which	O
is	O
stacked	O
on	O
top	O
of	O
the	O
encoder	Method
,	O
then	O
learns	O
an	O
upscaling	O
of	O
these	O
low	O
-	O
dimensional	O
features	O
via	O
subsequent	O
unpooling	Method
and	O
deconvolution	Method
operations	Method
[	O
reference	O
]	O
.	O
Similarly	O
,	O
Badrinarayanan	O
et	O
al	O
.	O
[	O
reference	O
][	O
reference	O
]	O
use	O
convolutions	Method
instead	O
of	O
deconvolutions	Method
in	O
the	O
decoder	Method
network	Method
.	O
In	O
contrast	O
,	O
our	O
approach	O
preserves	O
high	O
-	O
resolution	O
information	O
throughout	O
the	O
entire	O
network	O
by	O
keeping	O
a	O
separate	O
high	Method
-	Method
resolution	Method
processing	Method
stream	Method
.	O
Many	O
approaches	O
apply	O
smoothing	Method
operations	Method
to	O
the	O
output	O
of	O
a	O
CNN	Method
in	O
order	O
to	O
obtain	O
more	O
consistent	O
predictions	O
.	O
Most	O
commonly	O
,	O
conditional	Method
random	Method
fields	Method
(	O
CRFs	Method
)	O
[	O
reference	O
]	O
are	O
applied	O
on	O
the	O
network	O
output	O
[	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
.	O
More	O
recently	O
,	O
some	O
papers	O
approximate	O
the	O
mean	Method
-	Method
field	Method
inference	Method
of	Method
CRFs	Method
using	O
specialized	Method
network	Method
architectures	Method
[	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
.	O
Other	O
approaches	O
to	O
smoothing	O
the	O
network	Task
predictions	Task
include	O
domain	Method
transform	Method
[	O
reference	O
][	O
reference	O
]	O
and	O
superpixel	Method
-	Method
based	Method
smoothing	Method
[	O
reference	O
][	O
reference	O
]	O
.	O
Our	O
approach	O
is	O
able	O
to	O
swiftly	O
combine	O
high	O
-	O
and	O
low	O
-	O
resolution	O
information	O
,	O
resulting	O
in	O
already	O
smooth	O
output	O
predictions	O
.	O
Experiments	O
with	O
additional	O
CRF	Method
smoothing	Method
therefore	O
did	O
not	O
result	O
in	O
significant	O
performance	O
improvements	O
.	O
Network	Method
architectures	Method
.	O
Since	O
the	O
success	O
of	O
the	O
AlexNet	Method
architecture	Method
[	O
reference	O
]	O
in	O
the	O
ImageNet	Task
Large	Task
-	Task
Scale	Task
Visual	Task
Classification	Task
Challenge	Task
(	O
ILSVRC	Task
)	O
[	O
reference	O
]	O
,	O
the	O
vision	Task
community	Task
has	O
seen	O
several	O
milestones	O
with	O
respect	O
to	O
CNN	Method
architectures	Method
.	O
The	O
network	O
depth	O
has	O
been	O
constantly	O
increased	O
,	O
first	O
with	O
the	O
popular	O
VGG	Method
net	Method
[	O
reference	O
]	O
,	O
then	O
by	O
using	O
batch	Method
normalization	Method
with	O
GoogleNet	Method
[	O
reference	O
]	O
.	O
Lately	O
,	O
many	O
computer	Task
vision	Task
applications	Task
have	O
adopted	O
the	O
ResNet	Method
architecture	O
[	O
reference	O
]	O
,	O
which	O
often	O
leads	O
to	O
signification	O
performance	O
boosts	O
compared	O
to	O
earlier	O
network	Method
architectures	Method
.	O
All	O
of	O
these	O
developments	O
show	O
how	O
important	O
a	O
proper	O
architecture	O
is	O
.	O
However	O
,	O
so	O
far	O
most	O
of	O
these	O
networks	O
have	O
been	O
specifically	O
tailored	O
towards	O
the	O
task	O
of	O
classification	Task
,	O
in	O
many	O
cases	O
including	O
a	O
pre	Method
-	Method
training	Method
step	Method
on	O
ILSVRC	Task
.	O
As	O
a	O
result	O
,	O
some	O
of	O
their	O
design	O
choices	O
may	O
contribute	O
to	O
a	O
suboptimal	O
performance	O
when	O
performing	O
pixel	Task
-	Task
to	Task
-	Task
pixel	Task
tasks	Task
such	O
as	O
semantic	Task
segmentation	Task
.	O
In	O
contrast	O
,	O
our	O
proposed	O
architecture	O
has	O
been	O
specifically	O
designed	O
for	O
segmentation	Task
tasks	Task
and	O
reaches	O
competitive	O
performance	O
on	O
the	O
Cityscapes	Material
dataset	O
without	O
requiring	O
ILSVRC	Method
pre	Method
-	Method
training	Method
.	O
section	O
:	O
Network	Method
Architectures	Method
for	O
Segmentation	Task
Feed	Method
-	Method
Forward	Method
Networks	Method
.	O
Until	O
recently	O
,	O
the	O
majority	O
of	O
feedforward	Method
networks	Method
,	O
such	O
as	O
the	O
VGG	Method
-	Method
variants	Method
[	O
reference	O
]	O
,	O
were	O
composed	O
of	O
a	O
linear	Method
sequence	Method
of	Method
layers	Method
.	O
Each	O
layer	O
in	O
such	O
a	O
network	O
computes	O
a	O
function	O
F	O
and	O
the	O
output	O
x	O
n	O
of	O
the	O
n	O
-	O
th	O
layer	O
is	O
computed	O
as	O
where	O
W	O
n	O
are	O
the	O
parameters	O
of	O
the	O
layer	O
(	O
see	O
2a	O
)	O
.	O
We	O
refer	O
to	O
this	O
class	O
of	O
network	Method
architectures	Method
as	O
traditional	O
feedforward	Method
networks	Method
.	O
Residual	Method
Networks	Method
(	O
ResNets	Method
)	O
.	O
He	O
et	O
al	O
.	O
observed	O
that	O
deepening	O
traditional	O
feedforward	Method
networks	Method
often	O
results	O
in	O
an	O
increased	O
training	Metric
loss	Metric
[	O
reference	O
]	O
.	O
In	O
theory	O
,	O
however	O
,	O
the	O
training	Metric
loss	Metric
of	O
a	O
shallow	Method
network	Method
should	O
be	O
an	O
upper	O
bound	O
on	O
the	O
training	Metric
loss	Metric
of	O
a	O
corresponding	O
deep	Method
network	Method
.	O
This	O
is	O
due	O
to	O
the	O
fact	O
that	O
increasing	O
the	O
depth	O
by	O
adding	O
layers	O
strictly	O
increases	O
the	O
expressive	O
power	O
of	O
the	O
model	O
.	O
A	O
deep	Method
network	Method
can	O
express	O
all	O
functions	O
that	O
the	O
original	O
shallow	Method
network	Method
can	O
express	O
by	O
using	O
identity	O
mappings	O
for	O
the	O
added	O
layers	O
.	O
Hence	O
a	O
deep	Method
network	Method
should	O
perform	O
at	O
least	O
as	O
well	O
as	O
the	O
shallower	Method
model	Method
on	O
the	O
training	O
data	O
.	O
The	O
violation	O
of	O
this	O
principle	O
implied	O
that	O
current	O
training	Method
algorithms	Method
have	O
difficulties	O
optimizing	O
very	O
deep	O
traditional	O
feedforward	Method
networks	Method
.	O
He	O
et	O
al	O
.	O
proposed	O
residual	Method
networks	Method
(	O
ResNets	Method
)	O
that	O
exhibit	O
significantly	O
improved	O
training	Metric
characteristics	Metric
,	O
allowing	O
network	O
depths	O
that	O
were	O
previously	O
unattainable	O
.	O
A	O
ResNet	Method
is	O
composed	O
of	O
a	O
sequence	O
of	O
residual	Method
units	Method
(	O
RUs	O
)	O
.	O
As	O
depicted	O
in	O
Figure	O
2b	O
,	O
the	O
output	O
x	O
n	O
of	O
the	O
n	O
-	O
th	O
RU	O
in	O
a	O
ResNet	Method
is	O
computed	O
as	O
where	O
F	O
(	O
x	O
n−1	O
;	O
W	O
n	O
)	O
is	O
the	O
residual	O
,	O
which	O
is	O
parametrized	O
by	O
W	O
n	O
.	O
Thus	O
,	O
instead	O
of	O
computing	O
the	O
output	O
x	O
n	O
directly	O
,	O
F	O
only	O
computes	O
a	O
residual	O
that	O
is	O
added	O
to	O
the	O
input	O
x	O
n−1	O
.	O
One	O
commonly	O
refers	O
to	O
this	O
design	O
as	O
skip	O
connection	O
,	O
because	O
there	O
is	O
a	O
connection	O
from	O
the	O
input	O
x	O
n−1	O
to	O
the	O
output	O
x	O
n	O
that	O
skips	O
the	O
actual	O
computation	O
F.	O
It	O
has	O
been	O
empirically	O
observed	O
that	O
ResNets	Method
have	O
superior	O
training	Metric
properties	Metric
over	O
traditional	O
feedforward	Method
networks	Method
.	O
This	O
can	O
be	O
explained	O
by	O
an	O
improved	O
gradient	O
flow	O
within	O
the	O
network	O
.	O
In	O
oder	O
to	O
understand	O
this	O
,	O
consider	O
the	O
n	O
-	O
th	O
and	O
m	O
-	O
th	O
residual	O
units	O
in	O
a	O
ResNet	Method
where	O
m	O
>	O
n	O
(	O
i.e.	O
,	O
the	O
m	O
-	O
th	O
unit	O
is	O
closer	O
to	O
the	O
output	O
layer	O
of	O
the	O
network	O
)	O
.	O
By	O
applying	O
the	O
recursion	O
(	O
2	O
)	O
several	O
times	O
,	O
He	O
et	O
al	O
.	O
showed	O
in	O
[	O
reference	O
]	O
that	O
the	O
output	O
of	O
the	O
m	O
-	O
th	O
residual	O
unit	O
admits	O
a	O
representation	O
of	O
the	O
form	O
Furthermore	O
,	O
if	O
l	O
is	O
the	O
loss	O
that	O
is	O
used	O
to	O
train	O
the	O
network	O
,	O
we	O
can	O
use	O
the	O
chain	Method
rule	Method
of	Method
calculus	Method
and	O
express	O
the	O
derivative	O
of	O
the	O
loss	O
l	O
with	O
respect	O
to	O
the	O
output	O
x	O
n	O
of	O
the	O
n	O
-	O
th	O
RU	O
as	O
Thus	O
,	O
we	O
find	O
We	O
see	O
that	O
the	O
weight	O
updates	O
depend	O
on	O
two	O
sources	O
of	O
information	O
,	O
.	O
While	O
the	O
amount	O
of	O
information	O
that	O
is	O
contained	O
in	O
the	O
latter	O
may	O
depend	O
crucially	O
on	O
the	O
depth	O
n	O
,	O
the	O
former	O
allows	O
a	O
gradient	Method
flow	Method
that	O
is	O
independent	O
of	O
the	O
depth	O
.	O
Hence	O
,	O
gradients	O
can	O
flow	O
unhindered	O
from	O
the	O
deeper	O
unit	O
to	O
the	O
shallower	O
unit	O
.	O
This	O
makes	O
training	O
even	O
extremely	O
deep	Task
ResNets	Task
possible	O
.	O
section	O
:	O
Full	Method
-	Method
Resolution	Method
Residual	Method
Networks	Method
(	O
FRRNs	Method
)	O
.	O
In	O
this	O
paper	O
,	O
we	O
unify	O
the	O
two	O
above	O
-	O
mentioned	O
principles	O
of	O
network	Method
design	Method
and	O
propose	O
full	Method
-	Method
resolution	Method
residual	Method
networks	Method
(	O
FRRNs	Method
)	O
that	O
exhibit	O
the	O
same	O
superior	O
training	Metric
properties	Metric
as	O
ResNets	Method
but	O
have	O
two	O
processing	O
streams	O
.	O
The	O
features	O
on	O
one	O
stream	O
,	O
the	O
residual	O
stream	O
,	O
are	O
computed	O
by	O
adding	O
successive	O
residuals	O
,	O
while	O
the	O
features	O
on	O
the	O
other	O
stream	O
,	O
the	O
pooling	Method
stream	O
,	O
are	O
the	O
direct	O
result	O
of	O
a	O
sequence	O
of	O
convolution	O
and	O
pooling	Method
operations	O
applied	O
to	O
the	O
input	O
.	O
Our	O
design	O
is	O
motivated	O
by	O
the	O
need	O
to	O
have	O
networks	O
that	O
can	O
jointly	O
compute	O
good	O
high	O
-	O
level	O
features	O
for	O
recognition	Task
and	O
good	O
low	O
-	O
level	O
features	O
for	O
localization	Metric
.	O
Regardless	O
of	O
the	O
specific	O
network	Method
design	Method
,	O
obtaining	O
good	O
highlevel	O
features	O
requires	O
a	O
sequence	O
of	O
pooling	Method
operations	O
.	O
The	O
pooling	Method
operations	O
reduce	O
the	O
size	O
of	O
the	O
feature	O
maps	O
and	O
increase	O
the	O
network	O
's	O
receptive	O
field	O
,	O
as	O
well	O
as	O
its	O
robustness	O
against	O
small	O
translations	O
in	O
the	O
image	O
.	O
While	O
this	O
is	O
crucial	O
to	O
obtaining	O
robust	O
high	Task
-	Task
level	Task
features	Task
,	O
networks	O
that	O
employ	O
a	O
deep	O
pooling	Method
hierarchy	O
have	O
difficulties	O
tracking	O
low	O
-	O
level	O
features	O
,	O
such	O
as	O
edges	O
and	O
boundaries	O
,	O
in	O
deeper	O
layers	O
.	O
This	O
makes	O
them	O
good	O
at	O
recognizing	O
the	O
elements	O
in	O
a	O
scene	O
but	O
bad	O
at	O
localizing	O
them	O
to	O
pixel	Metric
accuracy	Metric
.	O
On	O
the	O
other	O
hand	O
,	O
a	O
network	O
that	O
does	O
not	O
employ	O
any	O
pooling	Method
operations	O
behaves	O
the	O
opposite	O
way	O
.	O
It	O
is	O
good	O
at	O
localizing	Task
object	Task
boundaries	Task
,	O
but	O
performs	O
poorly	O
at	O
recognizing	O
the	O
actual	O
objects	O
.	O
By	O
using	O
the	O
two	O
processing	O
streams	O
together	O
,	O
we	O
are	O
able	O
to	O
compute	O
both	O
kinds	O
of	O
features	O
simultaneously	O
.	O
While	O
the	O
residual	Method
stream	Method
of	O
an	O
FRRN	Method
computes	O
successive	O
residuals	O
at	O
the	O
full	O
image	O
resolution	O
,	O
allowing	O
low	O
level	O
features	O
to	O
propagate	O
effortlessly	O
through	O
the	O
network	O
,	O
the	O
pooling	Method
stream	O
undergoes	O
a	O
sequence	O
of	O
pooling	Method
and	O
unpooling	Method
operations	Method
resulting	O
in	O
good	O
high	O
-	O
level	O
features	O
.	O
Figure	O
1	O
visualizes	O
the	O
concept	O
of	O
having	O
two	O
distinct	O
processing	Method
streams	Method
.	O
An	O
FRRN	Method
is	O
composed	O
of	O
a	O
sequence	O
of	O
full	Method
-	Method
resolution	Method
residual	Method
units	Method
(	O
FRRUs	Method
)	O
.	O
Each	O
FRRU	Method
has	O
two	O
inputs	O
and	O
two	O
outputs	O
,	O
because	O
it	O
simultaneously	O
operates	O
on	O
both	O
streams	O
.	O
Figure	O
2c	O
shows	O
the	O
structure	O
of	O
an	O
FRRU	Method
.	O
Let	O
z	O
n−1	O
be	O
the	O
residual	O
input	O
to	O
the	O
n	O
-	O
th	O
FRRU	Method
and	O
let	O
y	O
n−1	O
be	O
its	O
pooling	Method
input	O
.	O
Then	O
the	O
outputs	O
are	O
computed	O
as	O
where	O
W	O
n	O
are	O
the	O
parameters	O
of	O
the	O
functions	O
G	O
and	O
H	O
,	O
respectively	O
.	O
If	O
G	O
≡	O
0	O
,	O
then	O
an	O
FRRU	Method
corresponds	O
to	O
an	O
RU	O
since	O
it	O
disregards	O
the	O
pooling	Method
input	O
y	O
n	O
,	O
and	O
the	O
network	O
effectively	O
becomes	O
an	O
ordinary	O
ResNet	Method
.	O
On	O
the	O
other	O
hand	O
,	O
if	O
H	O
≡	O
0	O
,	O
then	O
the	O
output	O
of	O
an	O
FRRU	Method
only	O
depends	O
on	O
its	O
input	O
via	O
the	O
function	O
G.	O
Hence	O
,	O
no	O
residuals	O
are	O
computed	O
and	O
we	O
obtain	O
a	O
traditional	O
feedforward	Method
network	Method
.	O
By	O
carefully	O
constructing	O
G	O
and	O
H	O
,	O
we	O
can	O
combine	O
the	O
two	O
network	Method
principles	Method
.	O
In	O
order	O
to	O
show	O
that	O
FRRNs	Method
have	O
similar	O
training	O
characteristics	O
as	O
ResNets	Method
,	O
we	O
adapt	O
the	O
analysis	O
presented	O
in	O
[	O
reference	O
]	O
to	O
our	O
case	O
.	O
Using	O
the	O
same	O
recursive	O
argument	O
as	O
before	O
,	O
we	O
find	O
that	O
for	O
m	O
>	O
n	O
,	O
z	O
m	O
has	O
the	O
representation	O
We	O
can	O
then	O
express	O
the	O
derivative	O
of	O
the	O
loss	O
l	O
with	O
respect	O
to	O
the	O
weights	O
W	O
n	O
as	O
Hence	O
,	O
the	O
weight	Method
updates	Method
depend	O
on	O
three	O
sources	O
of	O
information	O
.	O
Analogous	O
to	O
the	O
analysis	O
of	O
ResNets	Task
,	O
the	O
two	O
sources	O
∂H	O
(	O
yi	O
,	O
zi;Wi	O
+	O
1	O
)	O
∂zn	O
depend	O
crucially	O
on	O
the	O
depth	O
n	O
,	O
while	O
the	O
term	O
∂l	O
∂zm	O
is	O
independent	O
of	O
the	O
depth	O
.	O
Thus	O
,	O
we	O
achieve	O
a	O
depth	O
-	O
independent	O
gradient	O
flow	O
for	O
all	O
parameters	O
that	O
are	O
used	O
by	O
the	O
residual	O
function	O
H.	O
If	O
we	O
use	O
some	O
of	O
these	O
weights	O
in	O
order	O
to	O
compute	O
the	O
output	O
of	O
G	O
,	O
all	O
weights	O
of	O
the	O
unit	O
benefit	O
from	O
the	O
improved	O
gradient	Method
flow	Method
.	O
This	O
is	O
most	O
easily	O
achieved	O
by	O
reusing	O
the	O
output	O
of	O
G	O
in	O
order	O
to	O
compute	O
H.	O
However	O
,	O
we	O
note	O
that	O
other	O
designs	O
are	O
possible	O
.	O
Figure	O
3	O
shows	O
our	O
proposed	O
FRRU	Method
design	Method
.	O
The	O
unit	O
first	O
concatenates	O
the	O
two	O
incoming	O
streams	O
by	O
using	O
a	O
pooling	Method
layer	O
in	O
order	O
to	O
reduce	O
the	O
size	O
of	O
the	O
residual	O
stream	O
.	O
Then	O
the	O
concatenated	O
features	O
are	O
fed	O
through	O
two	O
convolution	Method
units	Method
.	O
Each	O
convolution	Method
unit	Method
consists	O
of	O
a	O
3	Method
×	Method
3	Method
convolution	Method
layer	Method
followed	O
by	O
a	O
batch	Method
normalization	Method
layer	Method
[	O
reference	O
]	O
and	O
a	O
ReLU	Method
activation	Method
function	Method
.	O
The	O
result	O
of	O
the	O
second	O
convolution	Method
unit	Method
is	O
used	O
in	O
two	O
ways	O
.	O
First	O
,	O
it	O
forms	O
the	O
pooling	Method
stream	O
input	O
of	O
the	O
next	O
FRRU	Method
in	O
the	O
network	O
and	O
second	O
it	O
is	O
the	O
basis	O
for	O
the	O
computed	O
residual	O
.	O
To	O
this	O
end	O
,	O
we	O
first	O
adjust	O
the	O
number	O
of	O
feature	O
channels	O
using	O
a	O
1	O
×	Method
1	Method
convolution	Method
and	O
then	O
upscale	O
the	O
spatial	O
dimensions	O
using	O
an	O
unpooling	Method
layer	O
.	O
Because	O
the	O
features	O
might	O
have	O
to	O
be	O
upscaled	O
significantly	O
(	O
e.g.	O
,	O
by	O
a	O
factor	O
of	O
16	O
)	O
,	O
we	O
found	O
that	O
simply	O
upscaling	O
by	O
repeating	O
the	O
entries	O
along	O
the	O
spatial	O
dimensions	O
performed	O
superior	O
to	O
bilinear	Method
interpolation	Method
.	O
In	O
Figure	O
3	O
,	O
the	O
inner	O
red	O
box	O
corresponds	O
to	O
the	O
function	O
G	O
while	O
the	O
outer	O
blue	O
box	O
corresponds	O
to	O
the	O
function	O
H.	O
We	O
can	O
see	O
that	O
the	O
output	O
of	O
G	O
is	O
used	O
in	O
order	O
to	O
compute	O
H	O
,	O
because	O
the	O
red	O
box	O
is	O
entirely	O
contained	O
within	O
the	O
blue	O
box	O
.	O
As	O
shown	O
above	O
,	O
this	O
design	O
choice	O
results	O
in	O
superior	O
gradient	O
flow	O
properties	O
for	O
all	O
weights	O
of	O
the	O
unit	O
.	O
Table	O
1	O
shows	O
the	O
two	O
network	Method
architectures	Method
that	O
we	O
used	O
in	O
order	O
to	O
assess	O
our	O
approach	O
's	O
segmentation	Task
performance	O
.	O
The	O
proposed	O
architectures	O
are	O
based	O
on	O
several	O
principles	O
employed	O
by	O
other	O
authors	O
.	O
We	O
follow	O
Noh	O
et	O
al	O
.	O
[	O
reference	O
]	O
and	O
use	O
an	O
encoder	Method
/	Method
decoder	Method
formulation	Method
.	O
In	O
the	O
encoder	Method
,	O
we	O
reduce	O
the	O
size	O
of	O
the	O
pooling	Method
stream	O
using	O
max	O
pooling	Method
operations	O
.	O
The	O
pooled	O
feature	O
maps	O
are	O
then	O
successively	O
upscaled	O
using	O
bilinear	Method
interpolation	Method
in	O
the	O
decoder	Method
.	O
Furthermore	O
,	O
similar	O
to	O
Simonyan	O
and	O
Zisserman	O
[	O
reference	O
]	O
,	O
we	O
define	O
a	O
number	O
of	O
base	O
channels	O
that	O
we	O
double	O
after	O
each	O
pooling	Method
operation	O
(	O
up	O
to	O
a	O
certain	O
upper	O
limit	O
)	O
.	O
Instead	O
of	O
choosing	O
64	O
base	O
channels	O
as	O
in	O
VGG	Method
net	Method
,	O
we	O
use	O
48	O
channels	O
in	O
order	O
to	O
have	O
a	O
manageable	O
number	O
of	O
trainable	O
parameters	O
.	O
Depending	O
on	O
the	O
input	O
image	O
resolution	O
,	O
we	O
use	O
FRRN	O
A	O
or	O
FRRN	O
B	O
to	O
keep	O
the	O
relative	O
size	O
of	O
the	O
receptive	O
fields	O
consistent	O
.	O
section	O
:	O
Training	O
Procedure	O
Following	O
Wu	O
et	O
al	O
.	O
,	O
we	O
train	O
our	O
network	O
by	O
minimizing	O
a	O
bootstrapped	Method
cross	Method
-	Method
entropy	Method
loss	Method
[	O
reference	O
]	O
.	O
Let	O
c	O
be	O
the	O
number	O
of	O
classes	O
,	O
y	O
1	O
,	O
...	O
,	O
y	O
N	O
∈	O
{	O
1	O
,	O
...	O
,	O
c	O
}	O
be	O
the	O
target	O
class	O
labels	O
for	O
the	O
pixels	O
1	O
,	O
...	O
,	O
N	O
,	O
and	O
let	O
p	O
i	O
,	O
j	O
be	O
the	O
posterior	O
class	O
+	O
Bias	O
Softmax	O
probability	O
for	O
class	O
j	O
and	O
pixel	O
i.	O
Then	O
,	O
the	O
bootstrapped	Metric
cross	Metric
-	Metric
entropy	Metric
loss	Metric
over	O
K	O
pixels	O
is	O
defined	O
as	O
where	O
1	O
[	O
x	O
]	O
=	O
1	O
iff	O
x	O
is	O
true	O
and	O
t	O
k	O
∈	O
R	O
is	O
chosen	O
such	O
that	O
|{i	O
∈	O
{	O
1	O
,	O
...	O
,	O
N	O
}	O
:	O
p	O
i	O
,	O
yi	O
<	O
t	O
k	O
}	O
|	O
=	O
K.	O
The	O
threshold	O
parameter	O
t	O
k	O
can	O
easily	O
be	O
determined	O
by	O
sorting	O
the	O
predicted	O
log	O
probabilities	O
and	O
choosing	O
the	O
K	O
+	O
1	O
-	O
th	O
one	O
as	O
threshold	O
.	O
Figure	O
4	O
visualizes	O
the	O
concept	O
.	O
Depending	O
on	O
the	O
number	O
of	O
pixels	O
K	O
that	O
we	O
consider	O
,	O
we	O
select	O
misclassified	O
pixels	O
or	O
pixels	O
where	O
we	O
predict	O
the	O
correct	O
label	O
with	O
a	O
small	O
probability	O
.	O
We	O
minimize	O
the	O
loss	Metric
using	O
ADAM	Method
[	O
reference	O
]	O
.	O
Because	O
each	O
FRRU	Method
processes	O
features	O
at	O
the	O
full	O
image	O
resolution	O
,	O
training	O
a	O
full	Method
-	Method
resolution	Method
residual	Method
network	Method
is	O
very	O
memory	O
intensive	O
.	O
Recall	O
that	O
in	O
order	O
for	O
the	O
backpropagation	Method
algorithm	Method
[	O
reference	O
]	O
to	O
work	O
,	O
the	O
entire	O
forward	O
pass	O
has	O
to	O
be	O
stored	O
in	O
memory	O
.	O
If	O
the	O
memory	O
required	O
to	O
store	O
the	O
forward	O
pass	O
for	O
a	O
given	O
network	O
exceeds	O
the	O
available	O
GPU	O
memory	O
,	O
we	O
can	O
no	O
longer	O
use	O
the	O
standard	O
backpropagation	Method
algorithm	Method
.	O
In	O
order	O
to	O
alleviate	O
this	O
problem	O
,	O
Figure	O
4	O
.	O
Pixels	O
used	O
by	O
the	O
bootstrapped	Method
cross	Method
-	Method
entropy	Method
loss	Method
for	O
varying	O
values	O
of	O
K.	O
The	O
images	O
and	O
ground	O
truth	O
annotations	O
originate	O
from	O
the	O
twice	O
-	O
subsampled	O
Cityscapes	Material
validation	O
set	O
[	O
reference	O
]	O
.	O
Pixels	O
that	O
are	O
labeled	O
void	O
are	O
not	O
considered	O
for	O
the	O
bootstrapping	Method
process	Method
.	O
we	O
partition	O
the	O
computation	O
graph	O
into	O
several	O
subsequent	O
blocks	O
by	O
manually	O
placing	O
cut	O
points	O
in	O
the	O
graph	O
.	O
We	O
then	O
compute	O
the	O
derivatives	O
for	O
each	O
block	O
individually	O
.	O
To	O
this	O
end	O
,	O
we	O
perform	O
one	O
(	O
partial	O
)	O
forward	Method
pass	Method
per	O
block	O
and	O
only	O
store	O
the	O
feature	O
maps	O
for	O
the	O
block	O
whose	O
derivatives	O
are	O
computed	O
given	O
the	O
derivative	O
of	O
the	O
subsequent	O
block	O
.	O
This	O
simple	O
scheme	O
allows	O
us	O
to	O
manually	O
control	O
a	O
spacetime	O
trade	O
-	O
off	O
.	O
The	O
idea	O
of	O
recomputing	O
some	O
intermediate	O
results	O
on	O
demand	O
is	O
also	O
used	O
in	O
[	O
reference	O
]	O
and	O
[	O
reference	O
]	O
.	O
Note	O
that	O
these	O
memory	O
limitations	O
only	O
apply	O
during	O
training	Task
.	O
During	O
testing	O
,	O
there	O
is	O
no	O
need	O
to	O
store	O
results	O
of	O
each	O
operation	O
in	O
the	O
network	O
and	O
our	O
architecture	O
's	O
memory	Metric
footprint	Metric
is	O
comparable	O
to	O
that	O
of	O
a	O
ResNet	Method
encoder	Method
/	Method
decoder	Method
architecture	Method
.	O
We	O
will	O
make	O
code	O
for	O
the	O
gradient	Task
computation	Task
for	O
arbitrary	Task
networks	Task
publicly	O
available	O
in	O
Theano	O
/	O
Lasagne	O
.	O
In	O
order	O
to	O
reduce	O
overfitting	O
,	O
we	O
used	O
two	O
methods	O
of	O
data	Task
augmentation	Task
:	O
translation	Task
augmentation	Task
and	O
gamma	Task
augmentation	Task
.	O
The	O
former	O
method	O
randomly	O
translates	O
an	O
image	O
and	O
its	O
annotations	O
.	O
In	O
order	O
to	O
keep	O
consistent	O
image	O
dimensions	O
,	O
we	O
have	O
to	O
pad	O
the	O
translated	O
images	O
and	O
annotations	O
.	O
To	O
this	O
end	O
,	O
we	O
use	O
reflection	O
padding	O
on	O
the	O
image	O
and	O
constant	O
padding	O
with	O
void	O
labels	O
on	O
the	O
annotations	O
.	O
Our	O
second	O
method	O
of	O
data	Task
augmentation	Task
is	O
gamma	Task
augmentation	Task
.	O
We	O
use	O
a	O
slightly	O
modified	O
gamma	Method
augmentation	Method
method	Method
detailed	O
in	O
Appendix	O
A.	O
section	O
:	O
Experimental	O
Evaluation	O
We	O
evaluate	O
our	O
approach	O
on	O
the	O
recently	O
released	O
Cityscapes	Material
benchmark	O
[	O
reference	O
]	O
containing	O
images	O
recorded	O
in	O
50	O
different	O
cities	O
.	O
This	O
benchmark	O
provides	O
5	O
,	O
000	O
images	O
with	O
high	O
-	O
quality	O
annotations	O
split	O
up	O
into	O
a	O
training	O
,	O
validation	O
,	O
and	O
test	O
set	O
(	O
2	O
,	O
975	O
,	O
500	O
,	O
and	O
1	O
,	O
525	O
images	O
,	O
respectively	O
)	O
.	O
The	O
dense	O
pixel	O
annotations	O
span	O
30	O
classes	O
frequently	O
occurring	O
in	O
urban	O
street	O
scenes	O
,	O
out	O
of	O
which	O
19	O
are	O
used	O
for	O
actual	O
training	O
and	O
evaluation	Task
.	O
Annotations	O
for	O
the	O
test	O
set	O
remain	O
private	O
and	O
comparison	O
to	O
other	O
methods	O
is	O
performed	O
via	O
a	O
dedicated	O
evaluation	O
server	O
.	O
We	O
report	O
the	O
results	O
of	O
our	O
FRRNs	Method
for	O
two	O
settings	O
:	O
FRRN	Method
A	Method
trained	O
on	O
quarter	O
-	O
resolution	O
(	O
256	O
×	O
512	O
)	O
Cityscapes	Material
images	O
;	O
and	O
FRRN	Method
B	Method
trained	O
on	O
half	O
-	O
resolution	O
(	O
512	O
×	O
1024	O
)	O
images	O
.	O
We	O
then	O
upsample	O
our	O
predictions	O
using	O
bilinear	Method
interpolation	Method
in	O
order	O
to	O
report	O
scores	O
at	O
the	O
full	O
image	O
resolution	O
of	O
1024	O
×	O
2048	O
pixels	O
.	O
Directly	O
training	O
at	O
the	O
full	O
Cityscapes	Material
resolution	O
turned	O
out	O
to	O
be	O
too	O
memory	O
intensive	O
with	O
our	O
current	O
design	O
.	O
However	O
,	O
as	O
our	O
experimental	O
results	O
will	O
show	O
,	O
even	O
when	O
trained	O
only	O
on	O
halfresolution	O
images	O
,	O
our	O
FRRN	Method
B	Method
's	O
results	O
are	O
competitive	O
with	O
the	O
best	O
published	O
methods	O
trained	O
on	O
full	O
-	O
resolution	O
data	O
.	O
Unless	O
specified	O
otherwise	O
,	O
the	O
reported	O
results	O
are	O
based	O
on	O
the	O
Cityscapes	Material
test	O
set	O
.	O
Qualitative	O
results	O
are	O
shown	O
in	O
Figure	O
7	O
,	O
in	O
Appendix	O
C	O
,	O
and	O
in	O
our	O
result	O
video	O
2	O
.	O
section	O
:	O
Residual	Method
Network	Method
Baseline	O
Our	O
network	Method
architecture	Method
can	O
be	O
described	O
as	O
a	O
ResNet	Method
[	O
reference	O
]	O
encoder	Method
/	Method
decoder	Method
architecture	Method
,	O
where	O
the	O
residuals	O
remain	O
at	O
the	O
full	O
input	O
resolution	O
throughout	O
the	O
network	O
.	O
A	O
natural	O
baseline	O
is	O
thus	O
a	O
traditional	O
ResNet	Method
encoder	Method
/	Method
decoder	Method
architecture	Method
with	O
long	Method
-	Method
range	Method
skip	Method
connections	Method
[	O
reference	O
][	O
reference	O
]	O
.	O
In	O
fact	O
,	O
such	O
an	O
architecture	O
resembles	O
a	O
single	O
deep	Method
hourglass	Method
module	Method
in	O
the	O
stacked	Method
hourglass	Method
network	Method
architecture	Method
[	O
reference	O
]	O
.	O
This	O
baseline	O
differs	O
from	O
our	O
proposed	O
architecture	O
in	O
two	O
important	O
ways	O
:	O
While	O
the	O
feature	O
maps	O
on	O
our	O
residual	O
stream	O
are	O
processed	O
by	O
each	O
FRRU	Method
,	O
the	O
feature	O
maps	O
on	O
the	O
long	O
-	O
range	O
skip	O
connections	O
are	O
not	O
processed	O
by	O
intermediate	Method
layers	Method
.	O
Furthermore	O
,	O
long	O
-	O
range	O
skip	O
connections	O
are	O
scale	O
dependent	O
,	O
meaning	O
that	O
features	O
at	O
one	O
scale	O
travel	O
over	O
a	O
different	O
skip	O
connection	O
than	O
features	O
at	O
another	O
scale	O
.	O
This	O
is	O
in	O
contrast	O
to	O
our	O
network	Method
design	Method
,	O
where	O
the	O
residual	O
stream	O
can	O
carry	O
upscaled	O
features	O
from	O
several	O
pooling	Method
stages	O
simultaneously	O
.	O
In	O
order	O
to	O
illustrate	O
the	O
benefits	O
of	O
our	O
approach	O
over	O
the	O
natural	O
baseline	O
,	O
we	O
converted	O
the	O
architecture	O
FRRN	Method
A	O
(	O
Table	O
1a	O
)	O
to	O
a	O
ResNet	Method
as	O
follows	O
:	O
We	O
first	O
replaced	O
all	O
FRRUs	Method
by	O
RUs	O
and	O
then	O
added	O
skip	O
connections	O
that	O
connect	O
the	O
input	O
of	O
each	O
pooling	Method
layer	O
to	O
the	O
output	O
of	O
the	O
corresponding	O
unpooling	Method
layer	O
.	O
The	O
resulting	O
ResNet	Method
has	O
slightly	O
fewer	O
parameters	O
than	O
the	O
original	O
FRRN	Method
(	O
16.7	O
×	O
10	O
6	O
vs.	O
17.7	O
×	O
10	O
6	O
)	O
.	O
This	O
is	O
due	O
to	O
the	O
fact	O
that	O
RUs	O
lack	O
the	O
1	Method
×	Method
1	Method
convolutions	Method
that	O
connect	O
the	O
pooling	Method
to	O
the	O
residual	O
Table	O
2	O
.	O
IoU	Metric
scores	Metric
from	O
the	O
cityscapes	Material
test	Material
set	Material
.	O
We	O
highlight	O
the	O
best	O
published	O
baselines	O
for	O
the	O
different	O
sampling	Metric
rates	Metric
.	O
(	O
Additional	O
anonymous	O
submissions	O
exist	O
as	O
concurrent	O
work	O
.	O
)	O
Bold	O
numbers	O
represent	O
the	O
best	O
,	O
italic	O
numbers	O
the	O
second	O
best	O
score	O
for	O
a	O
class	O
.	O
We	O
also	O
indicate	O
the	O
subsampling	O
factor	O
used	O
on	O
the	O
input	O
images	O
,	O
whether	O
additional	O
coarsely	O
annotated	O
data	O
was	O
used	O
,	O
and	O
whether	O
the	O
model	O
was	O
initialized	O
with	O
pre	O
-	O
trained	O
weights	O
.	O
stream	O
.	O
section	O
:	O
Method	O
We	O
train	O
both	O
networks	O
on	O
the	O
quarter	O
-	O
resolution	O
Cityscapes	Material
dataset	O
for	O
45	O
,	O
000	O
iterations	O
at	O
a	O
batch	O
size	O
of	O
3	O
.	O
We	O
use	O
a	O
learning	Metric
rate	Metric
of	O
10	O
−3	O
for	O
the	O
first	O
35	O
,	O
000	O
iterations	O
and	O
then	O
reduce	O
it	O
to	O
10	O
−4	O
for	O
the	O
following	O
10	O
,	O
000	O
iterations	O
.	O
Both	O
networks	O
converged	O
within	O
these	O
iterations	O
.	O
The	O
FRRN	Method
A	Method
resulted	O
in	O
a	O
validation	O
set	O
mean	Metric
IoU	Metric
score	Metric
of	O
65.7	O
%	O
while	O
the	O
ResNet	Method
baseline	O
only	O
achieved	O
62.8	O
%	O
,	O
showing	O
a	O
significant	O
advantage	O
of	O
our	O
FRRNs	Method
.	O
Training	O
FRRN	Method
B	O
is	O
performed	O
in	O
a	O
similar	O
fashion	O
.	O
Detailed	O
training	O
curves	O
are	O
shown	O
in	O
Appendix	O
B.	O
section	O
:	O
Quantitative	O
Evaluation	O
Overview	O
In	O
Table	O
2	O
we	O
compare	O
our	O
method	O
to	O
the	O
best	O
(	O
published	O
)	O
performers	O
on	O
the	O
Cityscapes	Material
leader	O
board	O
,	O
namely	O
LRR	Method
[	O
reference	O
]	O
,	O
Adelaide	O
[	O
reference	O
]	O
,	O
and	O
Dilation	O
[	O
reference	O
]	O
.	O
Note	O
that	O
our	O
network	O
performs	O
on	O
par	O
with	O
the	O
very	O
complex	O
and	O
well	O
engineered	O
system	O
by	O
[	O
reference	O
]	O
.	O
Among	O
the	O
top	O
performers	O
on	O
Cityscapes	Material
,	O
only	O
ENet	Method
refrain	O
from	O
using	O
a	O
pre	Method
-	Method
trained	Method
network	Method
.	O
However	O
,	O
they	O
design	O
their	O
network	O
for	O
real	O
time	O
performance	O
and	O
thus	O
do	O
not	O
obtain	O
top	O
scores	O
.	O
To	O
the	O
best	O
of	O
our	O
knowledge	O
,	O
we	O
are	O
the	O
first	O
to	O
show	O
that	O
it	O
is	O
possible	O
to	O
obtain	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
results	O
even	O
without	O
pre	Method
-	Method
training	Method
.	O
This	O
gives	O
credibility	O
to	O
our	O
claim	O
that	O
network	Method
architectures	Method
can	O
have	O
a	O
crucial	O
effect	O
on	O
a	O
system	O
's	O
overall	O
performance	O
.	O
Subsampling	Method
Factor	Method
.	O
An	O
interesting	O
observation	O
that	O
we	O
made	O
on	O
the	O
Cityscapes	Material
test	O
set	O
is	O
a	O
correlation	O
between	O
the	O
subsampling	O
factor	O
and	O
the	O
test	O
performance	O
.	O
This	O
correlation	O
can	O
be	O
seen	O
in	O
Figure	O
5	O
where	O
we	O
show	O
the	O
scores	O
of	O
several	O
approaches	O
currently	O
listed	O
on	O
the	O
leader	O
board	O
against	O
their	O
respective	O
subsampling	O
factors	O
.	O
Unsurprisingly	O
,	O
most	O
of	O
the	O
best	O
performers	O
operate	O
on	O
the	O
fullresolution	O
input	O
images	O
.	O
Throughout	O
our	O
experiments	O
,	O
we	O
consistently	O
outperformed	O
other	O
approaches	O
who	O
trained	O
on	O
Mean	Metric
IoU	Metric
Score	Metric
(	O
%	O
)	O
section	O
:	O
Subsampling	O
factor	O
Published	O
Unpublished	O
LRR	O
[	O
reference	O
]	O
Adelaide	O
[	O
reference	O
]	O
Dilation	O
[	O
reference	O
]	O
ENet	Method
[	O
reference	O
]	O
SegNet	O
[	O
reference	O
]	O
DeepLab	Method
[	O
reference	O
]	O
FRRN	Method
A	O
/	O
B	O
Figure	O
5	O
.	O
Comparison	O
of	O
the	O
mean	Metric
IoU	Metric
scores	Metric
of	O
all	O
approaches	O
on	O
the	O
leader	O
board	O
of	O
the	O
Cityscapes	Material
segmentation	O
benchmark	O
based	O
on	O
the	O
subsampling	O
factor	O
of	O
the	O
images	O
that	O
they	O
were	O
trained	O
on	O
.	O
Dilation	Method
[	O
reference	O
]	O
LRR	Method
[	O
reference	O
]	O
FRRN	Method
B	O
Figure	O
6	O
.	O
The	O
trimap	Method
evaluation	Method
on	O
the	O
validation	O
set	O
.	O
The	O
solid	O
lines	O
show	O
the	O
mean	O
IoU	Metric
score	Metric
of	O
our	O
approach	O
and	O
two	O
top	O
performing	O
methods	O
that	O
released	O
their	O
code	O
.	O
The	O
dashed	O
lines	O
show	O
the	O
mean	O
IoU	Metric
score	Metric
when	O
using	O
the	O
7	O
Cityscapes	Material
category	O
labels	O
for	O
the	O
same	O
methods	O
.	O
the	O
same	O
image	O
resolutions	O
.	O
Even	O
though	O
we	O
only	O
train	O
on	O
half	O
-	O
resolution	O
images	O
,	O
Figure	O
5	O
clearly	O
shows	O
we	O
can	O
match	O
the	O
current	O
published	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
(	O
LRR	Method
[	O
reference	O
]	O
Figure	O
7	O
.	O
Qualitative	O
comparison	O
on	O
the	O
Cityscapes	Material
validation	O
set	O
.	O
Interesting	O
cases	O
are	O
the	O
fence	O
in	O
the	O
first	O
row	O
,	O
the	O
truck	O
in	O
the	O
second	O
row	O
,	O
or	O
the	O
street	O
light	O
poles	O
in	O
the	O
last	O
row	O
.	O
An	O
interesting	O
failure	O
case	O
is	O
shown	O
in	O
the	O
third	O
row	O
:	O
all	O
methods	O
struggle	O
to	O
find	O
the	O
correct	O
sidewalk	O
boundary	O
,	O
however	O
our	O
network	O
makes	O
a	O
clean	O
and	O
reasonable	O
prediction	O
.	O
section	O
:	O
Boundary	Task
Adherence	Task
Due	O
to	O
several	O
pooling	Method
operations	O
(	O
and	O
subsequent	O
upsampling	Method
)	O
in	O
many	O
of	O
today	O
's	O
FCN	Method
architectures	Method
,	O
boundaries	O
are	O
often	O
overly	O
smooth	O
,	O
resulting	O
in	O
lost	O
details	O
and	O
edge	O
-	O
bleeding	O
.	O
This	O
leads	O
to	O
suboptimal	O
scores	O
,	O
but	O
it	O
also	O
makes	O
the	O
output	O
of	O
a	O
semantic	Method
segmentation	Method
approach	Method
harder	O
to	O
use	O
without	O
further	O
post	Task
-	Task
processing	Task
.	O
Since	O
inaccurate	O
boundaries	O
are	O
often	O
not	O
apparent	O
from	O
the	O
standard	O
evaluation	Metric
metric	Metric
scores	Metric
,	O
a	O
typical	O
approach	O
is	O
a	O
trimap	Task
evaluation	Task
in	O
order	O
to	O
quantify	O
detailed	O
boundary	O
adherence	O
[	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
.	O
During	O
trimap	Task
evaluation	Task
,	O
all	O
predictions	O
are	O
ignored	O
if	O
they	O
do	O
not	O
fall	O
within	O
a	O
certain	O
radius	O
r	O
of	O
a	O
ground	O
truth	O
label	O
boundary	O
.	O
Figure	O
6	O
visualizes	O
our	O
trimap	Method
evaluation	Method
performed	O
on	O
the	O
validation	O
set	O
for	O
varying	O
trimap	O
widths	O
r	O
between	O
1	O
and	O
80	O
pixels	O
.	O
We	O
compare	O
to	O
LRR	Method
[	O
reference	O
]	O
and	O
Dilation	Method
[	O
reference	O
]	O
,	O
who	O
made	O
code	O
and	O
pre	O
-	O
trained	O
models	O
available	O
.	O
We	O
see	O
that	O
our	O
approach	O
outperforms	O
the	O
competition	O
consistently	O
for	O
all	O
radii	O
r.	O
Furthermore	O
,	O
it	O
shall	O
be	O
noted	O
that	O
the	O
method	O
of	O
[	O
reference	O
]	O
is	O
based	O
on	O
an	O
architecture	O
specifically	O
designed	O
for	O
clean	Task
boundaries	Task
.	O
Our	O
method	O
achieves	O
better	O
boundary	Metric
adherence	Metric
,	O
both	O
numerically	O
and	O
qualitatively	O
(	O
see	O
Figure	O
7	O
)	O
,	O
with	O
a	O
much	O
simpler	O
architecture	O
and	O
without	O
ImageNet	Method
pre	Method
-	Method
training	Method
.	O
Often	O
one	O
can	O
boost	O
both	O
the	O
numerical	Metric
score	Metric
and	O
the	O
boundary	O
adherence	O
by	O
using	O
a	O
fully	Method
connected	Method
CRF	Method
as	O
post	O
-	O
processing	O
step	O
.	O
We	O
tried	O
to	O
apply	O
a	O
fully	Method
connected	Method
CRF	Method
with	O
Gaussian	Method
kernel	Method
,	O
as	O
introduced	O
by	O
Krähenbühl	O
and	O
Kolton	O
[	O
reference	O
]	O
.	O
We	O
used	O
the	O
standard	O
appearance	Method
and	Method
smoothness	Method
kernels	Method
and	O
tuned	O
parameters	O
on	O
the	O
validation	O
set	O
by	O
running	O
several	O
thousand	O
Hyperopt	O
iterations	O
[	O
reference	O
]	O
.	O
Surprisingly	O
the	O
color	Metric
standard	Metric
deviation	Metric
for	O
the	O
appearance	O
kernel	O
tended	O
towards	O
very	O
small	O
values	O
,	O
while	O
the	O
weight	O
did	O
not	O
go	O
to	O
zero	O
.	O
This	O
indicates	O
that	O
the	O
appearance	Method
kernel	Method
would	O
only	O
smooth	O
labels	O
across	O
pixels	O
with	O
very	O
similar	O
colors	O
.	O
Nevertheless	O
,	O
with	O
the	O
best	O
parameters	O
we	O
only	O
obtained	O
an	O
IoU	Metric
boost	Metric
of	O
∼	O
0.5	O
%	O
on	O
the	O
validation	O
set	O
.	O
Given	O
the	O
high	O
computation	Metric
time	Metric
we	O
decided	O
against	O
any	O
post	Method
-	Method
processing	Method
steps	Method
.	O
section	O
:	O
Conclusion	O
In	O
this	O
paper	O
we	O
propose	O
a	O
novel	O
network	Method
architecture	Method
for	O
semantic	Task
segmentation	Task
in	O
street	O
scenes	O
.	O
Our	O
architecture	O
is	O
clean	O
,	O
does	O
not	O
require	O
additional	O
post	Method
-	Method
processing	Method
,	O
can	O
be	O
trained	O
from	O
scratch	O
,	O
shows	O
superior	O
boundary	Metric
adherence	Metric
,	O
and	O
reaches	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
results	O
on	O
the	O
Cityscapes	Material
benchmark	O
.	O
We	O
will	O
provide	O
code	O
and	O
all	O
trained	O
models	O
.	O
Since	O
we	O
do	O
not	O
incorporate	O
design	O
choices	O
specifically	O
tailored	O
towards	O
semantic	Task
segmentation	Task
,	O
we	O
believe	O
that	O
our	O
architecture	O
will	O
also	O
be	O
applicable	O
to	O
other	O
tasks	O
such	O
as	O
stereo	Task
or	O
optical	Task
flow	Task
where	O
predictions	Task
are	O
performed	O
per	O
pixel	O
.	O
Our	O
goal	O
is	O
to	O
find	O
γ	O
such	O
that	O
E	O
U	O
[	O
U	O
]	O
=	O
0.5	O
.	O
The	O
key	O
idea	O
to	O
solving	O
this	O
problem	O
is	O
to	O
look	O
at	O
the	O
deviation	O
of	O
U	O
from	O
0.5	O
.	O
Let	O
Z	O
be	O
this	O
deviation	O
.	O
Then	O
(	O
11	O
)	O
is	O
equivalent	O
to	O
Hence	O
,	O
without	O
solving	O
for	O
the	O
implicitly	O
defined	O
variable	O
U	O
explicitly	O
,	O
we	O
found	O
a	O
transformation	O
of	O
a	O
zero	O
-	O
mean	O
random	O
variable	O
Z	O
such	O
that	O
γ	O
has	O
the	O
desired	O
properties	O
.	O
Because	O
Z	O
was	O
defined	O
to	O
be	O
the	O
offset	O
from	O
0.5	O
and	O
U	O
∈	O
[	O
0	O
,	O
1	O
]	O
,	O
it	O
follows	O
Z	O
∈	O
[	O
−0.5	O
,	O
0.5	O
]	O
.	O
We	O
are	O
free	O
to	O
choose	O
any	O
distribution	O
such	O
that	O
Z	O
has	O
zero	O
mean	O
and	O
falls	O
into	O
the	O
range	O
[	O
−0.5	O
,	O
0.5	O
]	O
.	O
For	O
simplicity	O
reasons	O
,	O
we	O
choose	O
Z	O
to	O
be	O
uniformly	O
distributed	O
over	O
[	O
−a	O
,	O
a	O
]	O
where	O
a	O
∈	O
[	O
0	O
,	O
0.5	O
]	O
determines	O
the	O
strength	O
of	O
the	O
augmentation	O
.	O
Figure	O
8b	O
illustrates	O
the	O
obvious	O
bias	Task
reduction	Task
.	O
section	O
:	O
B.	O
Baseline	O
Evaluation	O
In	O
Section	O
5.2	O
of	O
the	O
main	O
paper	O
,	O
we	O
describe	O
the	O
setting	O
of	O
our	O
baseline	O
method	O
(	O
Residual	Method
Network	Method
Baseline	Method
)	O
and	O
compare	O
it	O
to	O
our	O
FRRN	Method
A	Method
network	Method
.	O
To	O
emphasize	O
on	O
a	O
proper	O
training	O
procedure	O
of	O
both	O
baselines	O
,	O
Figure	O
9	O
shows	O
the	O
mean	Metric
IoU	Metric
score	Metric
on	O
the	O
validation	O
set	O
over	O
time	O
.	O
We	O
can	O
see	O
that	O
our	O
model	O
outperforms	O
the	O
baseline	O
with	O
a	O
significant	O
margin	O
and	O
both	O
methods	O
are	O
trained	O
until	O
convergence	O
.	O
Figure	O
10	O
shows	O
and	O
compares	O
addtional	O
output	O
labelings	O
of	O
our	O
method	O
.	O
Please	O
also	O
consult	O
our	O
labeled	O
video	O
sequence	O
[	O
reference	O
]	O
to	O
gain	O
a	O
better	O
sense	O
of	O
the	O
quality	O
of	O
our	O
method	O
.	O
We	O
all	O
know	O
Latex	O
is	O
a	O
pain	O
.	O
section	O
:	O
C.	O
Qualitative	O
Results	O
section	O
:	O
Image	Task
Ground	Task
Truth	Task
Ours	O
LRR	Method
[	O
reference	O
]	O
Figure	O
10	O
.	O
Additional	O
qualitative	O
results	O
on	O
the	O
Cityscapes	Material
validation	O
set	O
.	O
We	O
omit	O
the	O
comparison	O
to	O
Dilation	O
[	O
reference	O
]	O
in	O
order	O
to	O
show	O
bigger	O
images	O
here	O
.	O
section	O
:	O
section	O
:	O
Appendix	O
section	O
:	O
A.	O
Gamma	Method
Augmentation	Method
Gamma	Method
augmentation	Method
is	O
an	O
augmentation	Method
method	Method
that	O
varies	O
the	O
image	O
contrast	O
and	O
brightness	O
.	O
Assume	O
the	O
intensity	O
values	O
of	O
an	O
image	O
are	O
scaled	O
to	O
the	O
unit	O
interval	O
[	O
0	O
,	O
1	O
]	O
.	O
Then	O
gamma	Method
augmentation	Method
applies	O
the	O
intensity	Method
transformation	Method
x	O
→	O
x	O
γ	O
for	O
a	O
randomly	O
sampled	O
augmentation	O
parameter	O
γ	O
>	O
0	O
.	O
However	O
,	O
sampling	O
the	O
augmentation	O
parameter	O
γ	O
is	O
not	O
trivial	O
.	O
Naively	O
drawing	O
samples	O
from	O
a	O
uniform	Method
or	O
truncated	Method
Gaussian	Method
distribution	Method
with	O
a	O
mean	O
of	O
1	O
results	O
in	O
a	O
noticeable	O
bias	O
(	O
Figure	O
8a	O
)	O
.	O
In	O
order	O
to	O
reduce	O
the	O
bias	O
,	O
we	O
deduce	O
a	O
novel	O
sampling	Method
schema	Method
for	O
γ	O
.	O
Let	O
U	O
be	O
a	O
random	O
variable	O
that	O
is	O
implicitly	O
defined	O
as	O
the	O
solution	O
to	O
the	O
fixed	Task
-	Task
point	Task
problem	Task
section	O
:	O
