document	O
:	O
Improved	O
Language	Task
Modeling	Task
by	O
Decoding	O
the	O
Past	O
Highly	O
regularized	O
LSTMs	Method
achieve	O
impressive	O
results	O
on	O
several	O
benchmark	O
datasets	O
in	O
language	Task
modeling	Task
.	O
We	O
propose	O
a	O
new	O
regularization	Method
method	Method
based	O
on	O
decoding	O
the	O
last	O
token	O
in	O
the	O
context	O
using	O
the	O
predicted	O
distribution	O
of	O
the	O
next	O
token	O
.	O
This	O
biases	O
the	O
model	O
towards	O
retaining	O
more	O
contextual	O
information	O
,	O
in	O
turn	O
improving	O
its	O
ability	O
to	O
predict	O
the	O
next	O
token	O
.	O
With	O
negligible	O
overhead	O
in	O
the	O
number	O
of	O
parameters	O
and	O
training	Material
time	O
,	O
our	O
Past	Method
Decode	Method
Regularization	Method
(	O
PDR	Method
)	O
method	O
achieves	O
a	O
word	Metric
level	Metric
perplexity	Metric
of	O
55.6	O
on	O
the	O
Penn	Material
Treebank	Material
and	O
63.5	O
on	O
the	O
WikiText	Material
-	Material
2	Material
datasets	Material
using	O
a	O
single	O
softmax	Method
.	O
We	O
also	O
show	O
gains	O
by	O
using	O
PDR	Method
in	O
combination	O
with	O
a	O
mixture	Method
-	Method
of	Method
-	Method
softmaxes	Method
,	O
achieving	O
a	O
word	Metric
level	Metric
perplexity	Metric
of	O
53.8	O
and	O
60.5	O
on	O
these	O
datasets	O
.	O
In	O
addition	O
,	O
our	O
method	O
achieves	O
1.169	O
bits	Metric
-	Metric
per	Metric
-	Metric
character	Metric
on	O
the	O
Penn	Material
Treebank	Material
Character	Material
dataset	Material
for	O
character	Task
level	Task
language	Task
modeling	Task
.	O
These	O
results	O
constitute	O
a	O
new	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
in	O
their	O
respective	O
settings	O
.	O
tickpos	O
=	O
left	O
colorbrewer	O
section	O
:	O
Introduction	O
Language	Task
modeling	Task
is	O
a	O
fundamental	O
task	O
in	O
natural	Task
language	Task
processing	Task
.	O
Given	O
a	O
sequence	O
of	O
tokens	O
,	O
its	O
joint	O
probability	O
distribution	O
can	O
be	O
modeled	O
using	O
the	O
auto	Method
-	Method
regressive	Method
conditional	Method
factorization	Method
.	O
This	O
leads	O
to	O
a	O
convenient	O
formulation	O
where	O
a	O
language	Method
model	Method
has	O
to	O
predict	O
the	O
next	O
token	O
given	O
a	O
sequence	O
of	O
tokens	O
as	O
context	O
.	O
Recurrent	Method
neural	Method
networks	Method
are	O
an	O
effective	O
way	O
to	O
compute	O
distributed	Task
representations	Task
of	Task
the	Task
context	Task
by	O
sequentially	O
operating	O
on	O
the	O
embeddings	O
of	O
the	O
tokens	O
.	O
These	O
representations	O
can	O
then	O
be	O
used	O
to	O
predict	O
the	O
next	O
token	O
as	O
a	O
probability	O
distribution	O
over	O
a	O
fixed	O
vocabulary	O
using	O
a	O
linear	O
decoder	Method
followed	O
by	O
Softmax	Method
.	O
Starting	O
from	O
the	O
work	O
of	O
,	O
there	O
has	O
been	O
a	O
long	O
list	O
of	O
works	O
that	O
seek	O
to	O
improve	O
language	Task
modeling	Task
performance	O
using	O
more	O
sophisticated	O
recurrent	Method
neural	Method
networks	Method
(	O
RNNs	Method
)	O
(	O
)	O
.	O
However	O
,	O
in	O
more	O
recent	O
work	O
vanilla	O
LSTMs	Method
(	O
)	O
with	O
relatively	O
large	O
number	O
of	O
parameters	O
have	O
been	O
shown	O
to	O
achieve	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
performance	O
on	O
several	O
standard	O
benchmark	O
datasets	O
both	O
in	O
word	Metric
-	Metric
level	Metric
and	O
character	Task
-	Task
level	Task
perplexity	Task
(	O
)	O
.	O
A	O
key	O
component	O
in	O
these	O
models	O
is	O
the	O
use	O
of	O
several	O
forms	O
of	O
regularization	Method
e.g.	O
variational	Method
dropout	Method
on	O
the	O
token	O
embeddings	O
(	O
)	O
,	O
dropout	Method
on	O
the	O
hidden	O
-	O
to	O
-	O
hidden	O
weights	O
in	O
the	O
LSTM	Method
(	O
)	O
,	O
norm	Method
regularization	Method
on	O
the	O
outputs	O
of	O
the	O
LSTM	Method
and	O
classical	Method
dropout	Method
(	O
)	O
.	O
By	O
carefully	O
tuning	O
the	O
hyperparameters	O
associated	O
with	O
these	O
regularizers	Method
combined	O
with	O
optimization	Method
algorithms	Method
like	O
NT	Method
-	Method
ASGD	Method
(	O
a	O
variant	O
of	O
the	O
Averaged	O
SGD	Method
)	O
,	O
it	O
is	O
possible	O
to	O
achieve	O
very	O
good	O
performance	O
.	O
Each	O
of	O
these	O
regularizations	O
address	O
different	O
parts	O
of	O
the	O
LSTM	Method
model	Method
and	O
are	O
general	O
techniques	O
that	O
could	O
be	O
applied	O
to	O
any	O
other	O
sequence	Task
modeling	Task
problem	Task
.	O
In	O
this	O
paper	O
,	O
we	O
propose	O
a	O
regularization	Method
technique	Method
that	O
is	O
specific	O
to	O
language	Task
modeling	Task
.	O
One	O
unique	O
aspect	O
of	O
language	Method
modeling	Method
using	O
LSTMs	Method
(	O
or	O
any	O
RNN	Method
)	O
is	O
that	O
at	O
each	O
time	O
step	O
,	O
the	O
model	O
takes	O
as	O
input	O
a	O
particular	O
token	O
from	O
a	O
vocabulary	O
and	O
using	O
the	O
hidden	O
state	O
of	O
the	O
LSTM	Method
(	O
which	O
encodes	O
the	O
context	O
till	O
)	O
predicts	O
a	O
probability	O
distribution	O
on	O
the	O
next	O
token	O
over	O
the	O
same	O
vocabulary	O
as	O
output	O
.	O
Since	O
can	O
be	O
mapped	O
to	O
a	O
trivial	O
probability	O
distribution	O
over	O
,	O
this	O
operation	O
can	O
be	O
interpreted	O
as	O
transforming	O
distributions	O
over	O
(	O
)	O
.	O
Clearly	O
,	O
the	O
output	O
distribution	O
is	O
dependent	O
on	O
and	O
is	O
a	O
function	O
of	O
and	O
the	O
context	O
further	O
in	O
the	O
past	O
and	O
encodes	O
information	O
about	O
it	O
.	O
We	O
ask	O
the	O
following	O
question	O
–	O
How	O
much	O
information	O
is	O
it	O
possible	O
to	O
decode	O
about	O
the	O
input	O
distribution	O
(	O
and	O
hence	O
)	O
from	O
the	O
output	O
distribution	O
?	O
In	O
general	O
,	O
it	O
is	O
impossible	O
to	O
decode	O
unambiguously	O
.	O
Even	O
if	O
the	O
language	Method
model	Method
is	O
perfect	O
and	O
correctly	O
predicts	O
with	O
probability	O
1	O
,	O
there	O
could	O
be	O
many	O
tokens	O
preceding	O
it	O
.	O
However	O
,	O
in	O
this	O
case	O
the	O
number	O
of	O
possibilities	O
for	O
will	O
be	O
limited	O
,	O
as	O
dictated	O
by	O
the	O
bigram	O
statistics	O
of	O
the	O
corpus	O
and	O
the	O
language	O
in	O
general	O
.	O
We	O
argue	O
that	O
biasing	O
the	O
language	Method
model	Method
such	O
that	O
it	O
is	O
possible	O
to	O
decode	O
more	O
information	O
about	O
the	O
past	O
tokens	O
from	O
the	O
predicted	O
next	O
token	O
distribution	O
is	O
beneficial	O
.	O
We	O
incorporate	O
this	O
intuition	O
into	O
a	O
regularization	Method
term	Method
in	O
the	O
loss	O
function	O
of	O
the	O
language	Method
model	Method
.	O
The	O
symmetry	O
in	O
the	O
inputs	O
and	O
outputs	O
of	O
the	O
language	Method
model	Method
at	O
each	O
step	O
lends	O
itself	O
to	O
a	O
simple	O
decoding	Method
operation	Method
.	O
It	O
can	O
be	O
cast	O
as	O
a	O
(	O
pseudo	Task
)	Task
language	Task
modeling	Task
problem	Task
in	O
“	O
reverse	Task
”	Task
,	O
where	O
the	O
future	Task
prediction	Task
acts	O
as	O
the	O
input	O
and	O
the	O
last	O
token	O
acts	O
as	O
the	O
target	O
of	O
prediction	Task
.	O
The	O
token	O
embedding	O
matrix	O
and	O
weights	O
of	O
the	O
linear	O
decoder	Method
of	O
the	O
main	Method
language	Method
model	Method
can	O
be	O
reused	O
in	O
the	O
past	O
decoding	Task
operation	Task
.	O
We	O
only	O
need	O
a	O
few	O
extra	O
parameters	O
to	O
model	O
the	O
nonlinear	O
transformation	O
performed	O
by	O
the	O
LSTM	Method
,	O
which	O
we	O
do	O
by	O
using	O
a	O
simple	O
stateless	Method
layer	Method
.	O
We	O
compute	O
the	O
cross	Metric
-	Metric
entropy	Metric
loss	Metric
between	O
the	O
decoded	O
distribution	O
for	O
the	O
past	O
token	O
and	O
and	O
add	O
it	O
to	O
the	O
main	O
loss	O
function	O
after	O
suitable	O
weighting	O
.	O
The	O
extra	O
parameters	O
used	O
in	O
the	O
past	O
decoding	O
are	O
discarded	O
during	O
inference	O
time	O
.	O
We	O
call	O
our	O
method	O
Past	Method
Decode	Method
Regularization	Method
or	O
PDR	Method
for	O
short	O
.	O
We	O
conduct	O
extensive	O
experiments	O
on	O
four	O
benchmark	O
datasets	O
for	O
word	Task
level	Task
and	Task
character	Task
level	Task
language	Task
modeling	Task
by	O
combining	O
PDR	Method
with	O
existing	O
LSTM	Method
based	O
language	O
models	O
and	O
achieve	O
new	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
performance	O
on	O
three	O
of	O
them	O
.	O
section	O
:	O
Past	Method
Decode	Method
Regularization	Method
(	O
PDR	Method
)	O
Let	O
be	O
a	O
sequence	O
of	O
tokens	O
.	O
In	O
this	O
paper	O
,	O
we	O
will	O
experiment	O
with	O
both	O
word	Method
level	Method
and	Method
character	Method
level	Method
language	Method
modeling	Method
.	O
Therefore	O
,	O
tokens	O
can	O
be	O
either	O
words	O
or	O
characters	O
.	O
The	O
joint	O
probability	O
factorizes	O
into	O
Let	O
denote	O
the	O
context	O
available	O
to	O
the	O
language	Method
model	Method
for	O
.	O
Let	O
denote	O
the	O
vocabulary	O
of	O
tokens	O
,	O
each	O
of	O
which	O
is	O
embedded	O
into	O
a	O
vector	O
of	O
dimension	O
.	O
Let	O
denote	O
the	O
token	O
embedding	O
matrix	O
of	O
dimension	O
and	O
denote	O
the	O
embedding	O
of	O
.	O
An	O
LSTM	Method
computes	O
a	O
distributed	Method
representation	Method
of	O
in	O
the	O
form	O
of	O
its	O
hidden	O
state	O
,	O
which	O
we	O
assume	O
has	O
dimension	O
as	O
well	O
.	O
The	O
probability	O
that	O
the	O
next	O
token	O
is	O
can	O
then	O
be	O
calculated	O
using	O
a	O
linear	O
decoder	Method
followed	O
by	O
a	O
Softmax	Method
layer	Method
as	O
where	O
is	O
the	O
entry	O
corresponding	O
to	O
in	O
a	O
bias	O
vector	O
of	O
dimension	O
and	O
represents	O
projection	O
onto	O
.	O
Here	O
we	O
assume	O
that	O
the	O
weights	O
of	O
the	O
decoder	Method
are	O
tied	O
with	O
the	O
token	Method
embedding	Method
matrix	Method
(	O
)	O
.	O
To	O
optimize	O
the	O
parameters	O
of	O
the	O
language	Method
model	Method
,	O
the	O
loss	O
function	O
to	O
be	O
minimized	O
during	O
training	Material
is	O
set	O
as	O
the	O
cross	O
-	O
entropy	O
between	O
the	O
predicted	O
distribution	O
and	O
the	O
actual	O
token	O
.	O
Note	O
that	O
Eq	O
.	O
(	O
[	O
reference	O
]	O
)	O
,	O
when	O
applied	O
to	O
all	O
produces	O
a	O
vector	O
,	O
encapsulating	O
the	O
prediction	O
the	O
language	Method
model	Method
has	O
about	O
the	O
next	O
token	O
.	O
Since	O
this	O
is	O
dependent	O
on	O
and	O
conditioned	O
on	O
,	O
clearly	O
encodes	O
information	O
about	O
it	O
;	O
in	O
particular	O
about	O
the	O
last	O
token	O
in	O
.	O
In	O
turn	O
,	O
it	O
should	O
be	O
possible	O
to	O
infer	O
or	O
decode	O
some	O
limited	O
information	O
about	O
from	O
.	O
We	O
argue	O
that	O
by	O
biasing	O
the	O
model	O
to	O
be	O
more	O
accurate	O
in	O
recalling	O
information	O
about	O
past	O
tokens	O
,	O
we	O
can	O
help	O
it	O
in	O
predicting	O
the	O
next	O
token	O
better	O
.	O
To	O
this	O
end	O
,	O
we	O
define	O
the	O
following	O
decoding	Method
operation	Method
to	O
compute	O
a	O
probability	O
distribution	O
over	O
as	O
the	O
last	O
token	O
in	O
the	O
context	O
.	O
Here	O
is	O
a	O
non	Method
-	Method
linear	Method
function	Method
that	O
maps	O
vectors	O
in	O
to	O
vectors	O
in	O
and	O
is	O
a	O
bias	O
vector	O
of	O
dimension	O
,	O
together	O
with	O
parameters	O
.	O
In	O
effect	O
,	O
we	O
are	O
decoding	O
the	O
past	O
–	O
the	O
last	O
token	O
in	O
the	O
context	O
.	O
This	O
produces	O
a	O
vector	O
of	O
dimension	O
.	O
The	O
cross	Metric
-	Metric
entropy	Metric
loss	Metric
with	O
respect	O
to	O
the	O
actual	O
last	O
token	O
can	O
then	O
be	O
computed	O
as	O
Here	O
stands	O
for	O
Past	Method
Decode	Method
Regularization	Method
.	O
captures	O
the	O
extent	O
to	O
which	O
the	O
decoded	O
distribution	O
of	O
tokens	O
differs	O
from	O
the	O
actual	O
tokens	O
in	O
the	O
context	O
.	O
Note	O
the	O
symmetry	O
between	O
Eqs	O
.	O
(	O
[	O
reference	O
]	O
)	O
and	O
(	O
[	O
reference	O
]	O
)	O
.	O
The	O
“	O
input	O
”	O
in	O
the	O
latter	O
case	O
is	O
and	O
the	O
“	O
context	O
”	O
is	O
provided	O
by	O
a	O
nonlinear	Method
transformation	Method
of	O
.	O
Different	O
from	O
the	O
former	O
,	O
the	O
context	O
in	O
Eq	O
.	O
(	O
[	O
reference	O
]	O
)	O
does	O
not	O
preserve	O
any	O
state	O
information	O
across	O
time	O
steps	O
as	O
we	O
want	O
to	O
decode	O
only	O
using	O
.	O
The	O
term	O
can	O
be	O
interpreted	O
as	O
a	O
“	O
soft	Method
”	Method
token	Method
embedding	Method
lookup	Method
,	O
where	O
the	O
token	O
vector	O
is	O
a	O
probability	O
distribution	O
instead	O
of	O
a	O
unit	O
vector	O
.	O
We	O
add	O
to	O
the	O
loss	O
function	O
in	O
Eq	O
.	O
(	O
[	O
reference	O
]	O
)	O
as	O
a	O
regularization	O
term	O
,	O
where	O
is	O
a	O
positive	O
weighting	O
coefficient	O
,	O
to	O
construct	O
the	O
following	O
new	O
loss	Method
function	Method
for	O
the	O
language	Method
model	Method
.	O
Thus	O
equivalently	O
PDR	Method
can	O
also	O
be	O
viewed	O
as	O
a	O
method	O
of	O
defining	O
an	O
augmented	Method
loss	Method
function	Method
for	O
language	Task
modeling	Task
.	O
The	O
choice	O
of	O
dictates	O
the	O
degree	O
to	O
which	O
we	O
want	O
the	O
language	Method
model	Method
to	O
incorporate	O
our	O
inductive	O
bias	O
i.e.	O
decodability	O
of	O
the	O
last	O
token	O
in	O
the	O
context	O
.	O
If	O
it	O
is	O
too	O
large	O
,	O
the	O
model	O
will	O
fail	O
to	O
predict	O
the	O
next	O
token	O
,	O
which	O
is	O
its	O
primary	O
task	O
.	O
If	O
it	O
is	O
zero	O
or	O
too	O
small	O
,	O
the	O
model	O
will	O
retain	O
less	O
information	O
about	O
the	O
last	O
token	O
which	O
hampers	O
its	O
predictive	O
performance	O
.	O
In	O
practice	O
,	O
we	O
choose	O
by	O
a	O
search	O
based	O
on	O
validation	Metric
set	Metric
performance	Metric
.	O
Note	O
that	O
the	O
trainable	O
parameters	O
associated	O
with	O
PDR	Method
are	O
used	O
only	O
during	O
training	Material
to	O
bias	O
the	O
language	Method
model	Method
and	O
are	O
not	O
used	O
at	O
inference	Task
time	Task
.	O
This	O
also	O
means	O
that	O
it	O
is	O
important	O
to	O
control	O
the	O
complexity	O
of	O
the	O
nonlinear	O
function	O
so	O
as	O
not	O
to	O
overly	O
bias	O
the	O
training	Material
.	O
As	O
a	O
simple	O
choice	O
,	O
we	O
use	O
a	O
single	O
fully	Method
connected	Method
layer	Method
of	Method
size	Method
followed	O
by	O
a	O
Tanh	O
nonlinearity	O
as	O
.	O
This	O
introduces	O
few	O
extra	O
parameters	O
and	O
a	O
small	O
increase	O
in	O
training	Material
time	O
as	O
compared	O
to	O
a	O
model	O
not	O
using	O
PDR	Method
.	O
section	O
:	O
Experiments	O
We	O
present	O
extensive	O
experimental	O
results	O
to	O
show	O
the	O
efficacy	O
of	O
using	O
PDR	Method
for	O
language	Task
modeling	Task
on	O
four	O
standard	O
benchmark	O
datasets	O
–	O
two	O
each	O
for	O
word	Task
level	Task
and	Task
character	Task
level	Task
language	Task
modeling	Task
.	O
For	O
the	O
former	O
,	O
we	O
evaluate	O
our	O
method	O
on	O
the	O
Penn	Material
Treebank	Material
(	O
PTB	Material
)	O
(	O
)	O
and	O
the	O
WikiText	Material
-	Material
2	Material
(	O
WT2	Material
)	O
(	O
)	O
datasets	O
.	O
For	O
the	O
latter	O
,	O
we	O
use	O
the	O
Penn	Material
Treebank	Material
Character	Material
(	O
PTBC	Material
)	O
(	O
)	O
and	O
the	O
Hutter	Material
Prize	Material
Wikipedia	Material
Prize	Material
(	O
)	O
(	O
also	O
known	O
as	O
Enwik8	Material
)	O
datasets	O
.	O
Key	O
statistics	O
for	O
these	O
datasets	O
is	O
presented	O
in	O
Table	O
[	O
reference	O
]	O
.	O
As	O
mentioned	O
in	O
the	O
introduction	O
,	O
some	O
of	O
the	O
best	O
existing	O
results	O
on	O
these	O
datasets	O
are	O
obtained	O
by	O
using	O
extensive	O
regularization	Method
techniques	Method
on	O
relatively	O
large	O
LSTMs	Method
(	O
)	O
.	O
We	O
apply	O
our	O
regularization	Method
technique	Method
to	O
these	O
models	O
,	O
the	O
so	O
called	O
AWD	Method
-	Method
LSTM	Method
.	O
We	O
consider	O
two	O
versions	O
of	O
the	O
model	O
–	O
one	O
with	O
a	O
single	O
softmax	Method
(	Method
AWD	Method
-	Method
LSTM	Method
)	O
and	O
one	O
with	O
a	O
mixture	Method
-	Method
of	Method
-	Method
softmaxes	Method
(	O
AWD	Method
-	Method
LSTM	Method
-	Method
MoS	Method
)	O
.	O
The	O
PDR	Method
regularization	O
term	O
is	O
computed	O
according	O
to	O
Eq	O
.	O
(	O
[	O
reference	O
]	O
)	O
and	O
Eq	O
.	O
(	O
[	O
reference	O
]	O
)	O
.	O
We	O
call	O
our	O
model	Method
AWD	Method
-	Method
LSTM	Method
+	Method
PDR	Method
when	O
using	O
a	O
single	O
softmax	Method
and	O
AWD	Method
-	Method
LSTM	Method
-	Method
MoS	Method
+	Method
PDR	Method
when	O
using	O
a	O
mixture	Method
-	Method
of	Method
-	Method
softmaxes	Method
.	O
We	O
largely	O
follow	O
the	O
experimental	O
procedure	O
of	O
the	O
original	O
models	O
and	O
incorporate	O
their	O
dropouts	Method
and	O
regularizations	Method
in	O
our	O
experiments	O
.	O
The	O
relative	O
contribution	O
of	O
these	O
existing	O
regularizations	Method
and	O
PDR	Method
will	O
be	O
analyzed	O
in	O
Section	O
[	O
reference	O
]	O
.	O
There	O
are	O
7	O
hyperparameters	O
associated	O
with	O
the	O
regularizations	Method
used	O
in	O
AWD	Method
-	Method
LSTM	Method
(	O
and	O
one	O
extra	O
with	O
MoS	Method
)	O
.	O
PDR	Method
also	O
has	O
an	O
associated	O
weighting	O
coefficient	O
.	O
For	O
our	O
experiments	O
,	O
we	O
set	O
which	O
was	O
determined	O
by	O
a	O
coarse	Method
search	Method
on	O
the	O
PTB	Material
and	O
WT2	Material
validation	O
sets	O
.	O
For	O
the	O
remaining	O
ones	O
,	O
we	O
perform	O
light	O
hyperparameter	Method
search	Method
in	O
the	O
vicinity	O
of	O
those	O
reported	O
for	O
AWD	Method
-	Method
LSTM	Method
in	Method
and	O
for	O
AWD	Method
-	Method
LSTM	Method
-	Method
MoS	Method
in	O
.	O
subsection	O
:	O
Model	O
and	O
training	Material
for	O
PTB	Material
and	O
WikiText	Material
-	Material
2	Material
For	O
the	O
single	Method
softmax	Method
model	Method
(	O
AWD	Method
-	Method
LSTM	Method
+	Method
PDR	Method
)	Method
,	O
for	O
both	O
PTB	Material
and	O
WT2	Material
,	O
we	O
use	O
a	O
3	O
-	O
layered	O
LSTM	Method
with	O
1150	O
,	O
1150	O
and	O
400	O
hidden	O
dimensions	O
.	O
The	O
word	O
embedding	O
dimension	O
is	O
set	O
to	O
.	O
For	O
the	O
mixture	Method
-	Method
of	Method
-	Method
softmax	Method
model	Method
,	O
we	O
use	O
a	O
3	O
-	O
layer	O
LSTM	Method
with	O
dimensions	O
960	O
,	O
960	O
and	O
620	O
,	O
embedding	O
dimension	O
of	O
280	O
and	O
15	O
experts	O
for	O
PTB	Material
and	O
a	O
3	O
-	O
layer	O
LSTM	Method
with	O
dimensions	O
1150	O
,	O
1150	O
and	O
650	O
,	O
embedding	O
dimension	O
of	O
and	O
15	O
experts	O
for	O
WT2	Material
.	O
Weight	Method
tying	Method
is	O
used	O
in	O
all	O
the	O
models	O
.	O
For	O
training	Material
the	O
models	O
,	O
we	O
follow	O
the	O
same	O
procedure	O
as	O
AWD	Method
-	Method
LSTM	Method
i.e.	Method
a	O
combination	O
of	O
SGD	Method
and	O
NT	Method
-	Method
ASGD	Method
,	O
followed	O
by	O
finetuning	Method
.	O
We	O
adopt	O
the	O
learning	O
rate	O
schedules	O
and	O
batch	O
sizes	O
of	O
and	O
in	O
our	O
experiments	O
.	O
subsection	O
:	O
Model	O
and	O
training	Material
for	O
PTBC	Material
and	O
Enwik8	Material
For	O
PTBC	Material
,	O
we	O
use	O
a	O
3	O
-	O
layer	O
LSTM	Method
with	O
1000	O
,	O
1000	O
and	O
200	O
hidden	O
dimensions	O
and	O
a	O
character	O
embedding	O
dimension	O
of	O
.	O
For	O
Enwik8	Material
,	O
we	O
use	O
a	O
LSTM	Method
with	O
1850	O
,	O
1850	O
and	O
400	O
hidden	O
dimensions	O
and	O
the	O
characters	O
are	O
embedded	O
in	O
dimensions	O
.	O
For	O
training	Material
,	O
we	O
largely	O
follow	O
the	O
procedure	O
laid	O
out	O
in	O
.	O
For	O
each	O
of	O
the	O
datasets	O
,	O
AWD	Method
-	Method
LSTM	Method
+	Method
PDR	Method
has	O
less	O
than	O
1	O
%	O
more	O
parameters	O
than	O
the	O
corresponding	O
AWD	Method
-	Method
LSTM	Method
model	Method
(	O
during	O
training	Material
only	O
)	O
.	O
The	O
maximum	O
observed	Metric
time	Metric
overhead	Metric
due	O
to	O
the	O
additional	O
computation	O
is	O
less	O
than	O
3	O
%	O
.	O
section	O
:	O
Results	O
on	O
Word	O
Level	O
Language	Task
Modeling	Task
The	O
results	O
for	O
PTB	Material
are	O
shown	O
in	O
Table	O
[	O
reference	O
]	O
.	O
With	O
a	O
single	O
softmax	Method
,	O
our	O
method	O
(	O
AWD	Method
-	Method
LSTM	Method
+	Method
PDR	Method
)	O
achieves	O
a	O
perplexity	Metric
of	O
55.6	O
on	O
the	O
PTB	Material
test	Material
set	Material
,	O
which	O
improves	O
on	O
the	O
current	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
with	O
a	O
single	O
softmax	O
by	O
an	O
absolute	O
1.7	O
points	O
.	O
The	O
advantages	O
of	O
better	O
information	Task
retention	Task
due	O
to	O
PDR	Method
are	O
maintained	O
when	O
combined	O
with	O
a	O
continuous	O
cache	O
pointer	O
(	O
)	O
,	O
where	O
our	O
method	O
yields	O
an	O
absolute	O
improvement	O
of	O
1.2	O
over	O
AWD	Method
-	Method
LSTM	Method
.	O
Notably	O
,	O
when	O
coupled	O
with	O
dynamic	Method
evaluation	Method
(	O
)	O
,	O
the	O
perplexity	Metric
is	O
decreased	O
further	O
to	O
49.3	O
.	O
To	O
the	O
best	O
of	O
our	O
knowledge	O
,	O
ours	O
is	O
the	O
first	O
method	O
to	O
achieve	O
a	O
sub	Task
50	Task
perplexity	Task
on	O
the	O
PTB	Material
test	Material
set	Material
with	O
a	O
single	O
softmax	Method
.	O
Note	O
that	O
,	O
for	O
both	O
cache	Task
pointer	Task
and	Task
dynamic	Task
evaluation	Task
,	O
we	O
coarsely	O
tune	O
the	O
associated	O
hyperparameters	O
on	O
the	O
validation	O
set	O
.	O
Using	O
a	O
mixture	Method
-	Method
of	Method
-	Method
softmaxes	Method
,	O
our	O
method	O
(	O
AWD	Method
-	Method
LSTM	Method
-	Method
MoS	Method
+	Method
PDR	Method
)	O
achieves	O
a	O
test	Metric
perplexity	Metric
of	O
53.8	O
,	O
an	O
improvement	O
of	O
0.6	O
points	O
over	O
the	O
current	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
.	O
The	O
use	O
of	O
dynamic	Method
evaluation	Method
pushes	O
the	O
perplexity	O
further	O
down	O
to	O
47.3	O
.	O
PTB	Material
is	O
a	O
restrictive	O
dataset	O
with	O
a	O
vocabulary	O
of	O
10	O
K	O
words	O
.	O
Achieving	O
good	O
perplexity	Task
requires	O
considerable	O
regularization	O
.	O
The	O
fact	O
that	O
PDR	Method
can	O
improve	O
upon	O
existing	O
heavily	Method
regularized	Method
models	Method
is	O
empirical	O
evidence	O
of	O
its	O
distinctive	O
nature	O
and	O
its	O
effectiveness	O
in	O
improving	O
language	Method
models	Method
.	O
Table	O
[	O
reference	O
]	O
shows	O
the	O
perplexities	O
achieved	O
by	O
our	O
model	O
on	O
WT2	Material
.	O
This	O
dataset	O
is	O
considerably	O
more	O
complex	O
than	O
PTB	Material
with	O
a	O
vocabulary	O
of	O
more	O
than	O
33	O
K	O
words	O
.	O
AWD	Method
-	Method
LSTM	Method
+	Method
PDR	Method
improves	O
over	O
the	O
current	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
with	O
a	O
single	O
softmax	Method
by	O
a	O
significant	O
2.3	O
points	O
,	O
achieving	O
a	O
perplexity	Metric
of	O
63.5	O
.	O
The	O
gains	O
are	O
maintained	O
with	O
the	O
use	O
of	O
cache	O
pointer	O
(	O
2.4	O
points	O
)	O
and	O
with	O
the	O
use	O
of	O
dynamic	O
evaluation	O
(	O
1.7	O
points	O
)	O
.	O
Using	O
a	O
mixture	Method
-	Method
of	Method
-	Method
softmaxes	Method
,	O
AWD	Method
-	Method
LSTM	Method
-	Method
MoS	Method
+	Method
PDR	Method
achieves	O
perplexities	Method
of	O
60.5	O
and	O
40.3	O
(	O
with	O
dynamic	Metric
evaluation	Metric
)	O
on	O
the	O
WT2	Material
test	Material
set	Material
,	O
improving	O
upon	O
the	O
current	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
by	O
1.0	O
and	O
0.4	O
points	O
respectively	O
.	O
subsection	O
:	O
Performance	O
on	O
Larger	O
Datasets	O
We	O
consider	O
the	O
Gigaword	O
dataset	O
with	O
a	O
truncated	O
vocabulary	O
of	O
about	O
100	O
K	O
tokens	O
with	O
the	O
highest	O
frequency	O
and	O
apply	O
PDR	Method
to	O
a	O
baseline	O
2	O
-	O
layer	O
LSTM	Method
language	O
model	O
with	O
embedding	O
and	O
hidden	O
dimensions	O
set	O
to	O
1024	O
.	O
We	O
use	O
all	O
the	O
shards	O
from	O
the	O
training	Material
set	O
for	O
training	Material
and	O
a	O
few	O
shards	O
from	O
the	O
heldout	O
set	O
for	O
validation	Task
(	O
heldout	O
-	O
0	O
,	O
10	O
)	O
and	O
test	O
(	O
heldout	O
-	O
20	O
,	O
30	O
,	O
40	O
)	O
.	O
We	O
tuned	O
the	O
PDR	Method
coefficient	O
coarsely	O
in	O
the	O
vicinity	O
of	O
0.001	O
.	O
While	O
the	O
baseline	O
model	O
achieved	O
a	O
validation	O
(	O
test	O
)	O
perplexity	Metric
of	O
44.3	O
(	O
43.1	O
)	O
,	O
on	O
applying	O
PDR	Method
,	O
the	O
model	O
achieved	O
a	O
perplexity	Metric
of	O
44.0	O
(	O
42.5	O
)	O
.	O
Thus	O
,	O
PDR	Method
is	O
relatively	O
less	O
effective	O
on	O
larger	O
datasets	O
,	O
a	O
fact	O
also	O
observed	O
for	O
other	O
regularization	Method
techniques	Method
on	O
such	O
datasets	O
(	O
)	O
.	O
section	O
:	O
Results	O
on	O
Character	O
Level	O
Language	Task
Modeling	Task
The	O
results	O
on	O
PTBC	Material
are	O
shown	O
in	O
Table	O
[	O
reference	O
]	O
.	O
Our	O
method	O
achieves	O
a	O
bits	Metric
-	Metric
per	Metric
-	Metric
character	Metric
(	O
BPC	Metric
)	O
performance	O
of	O
1.169	O
on	O
the	O
PTBC	Material
test	Material
set	Material
,	O
improving	O
on	O
the	O
current	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
by	O
0.006	O
or	O
0.5	O
%	O
.	O
It	O
is	O
notable	O
that	O
even	O
with	O
this	O
highly	O
processed	O
dataset	O
and	O
a	O
small	O
vocabulary	O
of	O
only	O
51	O
tokens	O
,	O
our	O
method	O
improves	O
on	O
already	O
highly	O
regularized	Method
models	Method
.	O
Finally	O
,	O
we	O
present	O
results	O
on	O
Enwik8	Material
in	O
Table	O
[	O
reference	O
]	O
.	O
AWD	Method
-	Method
LSTM	Method
+	Method
PDR	Method
achieves	O
1.245	O
BPC	Metric
.	O
This	O
is	O
0.012	O
or	O
about	O
1	O
%	O
less	O
than	O
the	O
1.257	O
BPC	Metric
achieved	O
by	O
AWD	Method
-	Method
LSTM	Method
in	O
our	O
experiments	O
(	O
with	O
hyperparameters	O
from	O
)	O
.	O
section	O
:	O
Analysis	O
of	O
PDR	Method
In	O
this	O
section	O
,	O
we	O
analyze	O
PDR	Method
by	O
probing	O
its	O
performance	O
in	O
several	O
ways	O
and	O
comparing	O
it	O
with	O
current	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
models	O
that	O
do	O
not	O
use	O
PDR	Method
.	O
subsection	O
:	O
A	O
Valid	O
Regularization	Method
To	O
verify	O
that	O
indeed	O
PDR	Method
can	O
act	O
as	O
a	O
form	O
of	O
regularization	Method
,	O
we	O
perform	O
the	O
following	O
experiment	O
.	O
We	O
take	O
the	O
models	O
for	O
PTB	Material
and	O
WT2	Material
and	O
turn	O
off	O
all	O
dropouts	Method
and	O
regularization	Method
and	O
compare	O
its	O
performance	O
with	O
only	O
PDR	Method
turned	O
on	O
.	O
The	O
results	O
,	O
as	O
shown	O
in	O
Table	O
[	O
reference	O
]	O
,	O
validate	O
the	O
premise	O
of	O
PDR	Method
.	O
The	O
model	O
with	O
only	O
PDR	Method
turned	O
on	O
achieves	O
2.4	O
and	O
5.1	O
better	O
validation	Metric
perplexity	Metric
on	O
PTB	Material
and	O
WT2	Material
as	O
compared	O
to	O
the	O
model	O
without	O
any	O
regularization	Method
.	O
Thus	O
,	O
biasing	O
the	O
LSTM	Method
by	O
decoding	O
the	O
distribution	O
of	O
past	O
tokens	O
from	O
the	O
predicted	O
next	O
-	O
token	O
distribution	O
can	O
indeed	O
act	O
as	O
a	O
regularizer	Method
leading	O
to	O
better	O
generalization	Task
performance	O
.	O
Next	O
,	O
we	O
plot	O
histograms	O
of	O
the	O
negative	O
log	O
-	O
likelihoods	O
of	O
the	O
correct	O
context	O
tokens	O
in	O
the	O
past	O
decoded	O
vector	O
computed	O
using	O
our	O
best	O
models	O
on	O
the	O
PTB	Material
and	O
WT2	Material
validation	O
sets	O
in	O
Fig	O
.	O
[	O
reference	O
]	O
(	O
a	O
)	O
.	O
The	O
NLL	O
values	O
are	O
significantly	O
peaked	O
near	O
0	O
,	O
which	O
means	O
that	O
the	O
past	Method
decoding	Method
operation	Method
is	O
able	O
to	O
decode	O
significant	O
amount	O
of	O
information	O
about	O
the	O
last	O
token	O
in	O
the	O
context	O
.	O
To	O
investigate	O
the	O
effect	O
of	O
hyperparameters	O
on	O
PDR	Method
,	O
we	O
pick	O
60	O
sets	O
of	O
random	O
hyperparameters	O
in	O
the	O
vicinity	O
of	O
those	O
reported	O
by	O
and	O
compute	O
the	O
validation	Metric
set	Metric
perplexity	Metric
after	O
training	Material
(	O
without	O
finetuning	Method
)	O
on	O
PTB	Material
,	O
for	O
both	O
AWD	Method
-	Method
LSTM	Method
+	O
PDR	Method
and	O
AWD	Method
-	Method
LSTM	Method
.	O
Their	O
histograms	O
are	O
plotted	O
in	O
Fig	O
.	O
[	O
reference	O
]	O
(	O
b	O
)	O
.	O
The	O
perplexities	O
for	O
models	O
with	O
PDR	Method
are	O
distributed	O
slightly	O
to	O
the	O
left	O
of	O
those	O
without	O
PDR	Method
.	O
There	O
appears	O
to	O
be	O
more	O
instances	O
of	O
perplexities	O
in	O
the	O
higher	O
range	O
for	O
models	O
without	O
PDR	Method
.	O
Note	O
that	O
there	O
are	O
certainly	O
hyperparameter	O
settings	O
where	O
adding	O
PDR	Method
leads	O
to	O
lower	O
validation	Metric
complexity	Metric
,	O
as	O
is	O
generally	O
the	O
case	O
for	O
any	O
regularization	Method
method	Method
.	O
[	O
scale=0.80	O
]	O
patterns	O
[	O
ybar	O
,	O
ymin=0	O
,	O
bar	O
width=2	O
,	O
x	O
tick	O
label	O
style	O
=	O
rotate=0	O
,	O
xlabel	O
=	O
Negative	O
log	O
-	O
likelihood	O
,	O
ylabel	O
=	O
Normalized	O
frequency	O
,	O
y	O
label	O
style	O
=	O
at=	O
(	O
0.05	O
,	O
0.5	O
)	O
,	O
every	O
axis	O
plot	O
/	O
.append	O
style	O
=	O
fill	O
,	O
legend	O
pos=	O
north	O
east	O
,	O
legend	O
entries	O
=	O
PTB	Material
-	O
Valid	O
,	O
WT2	Material
-	O
Valid	O
,	O
]	O
[	O
magenta	O
]	O
coordinates	O
(	O
0.33	O
,	O
0.316464626105	O
)(	O
1.0	O
,	O
0.0851737740793	O
)(	O
1.67	O
,	O
0.0652768579573	O
)(	O
2.33	O
,	O
0.057819113709	O
)(	O
3.0	O
,	O
0.0520170462726	O
)(	O
3.67	O
,	O
0.0518154856172	O
)(	O
4.33	O
,	O
0.050044631288	O
)(	O
5.0	O
,	O
0.0517866912379	O
)(	O
5.67	O
,	O
0.0515851305825	O
)(	O
6.33	O
,	O
0.0497854818739	O
)(	O
7.0	O
,	O
0.0443865357482	O
)(	O
7.67	O
,	O
0.0388580149155	O
)(	O
8.33	O
,	O
0.0341789282732	O
)(	O
9.0	O
,	O
0.0278297676294	O
)(	O
9.67	O
,	O
0.022977914711	O
)	O
;	O
[	O
black	O
]	O
coordinates	O
(	O
0.33	O
,	O
0.30860908651	O
)(	O
1.0	O
,	O
0.0787424358073	O
)(	O
1.67	O
,	O
0.0643498909958	O
)(	O
2.33	O
,	O
0.059959790672	O
)(	O
3.0	O
,	O
0.0559238916244	O
)(	O
3.67	O
,	O
0.0553451965817	O
)(	O
4.33	O
,	O
0.0522072726003	O
)(	O
5.0	O
,	O
0.0524417438676	O
)(	O
5.67	O
,	O
0.0500670986924	O
)(	O
6.33	O
,	O
0.0488797761049	O
)(	O
7.0	O
,	O
0.0446293607914	O
)(	O
7.67	O
,	O
0.0396455991739	O
)(	O
8.33	O
,	O
0.0349711400791	O
)(	O
9.0	O
,	O
0.0289646846361	O
)(	O
9.67	O
,	O
0.0252630318631	O
)	O
;	O
[	O
scale=0.80	O
]	O
patterns	O
[	O
ybar	O
,	O
ymin=0	O
,	O
bar	O
width=2	O
,	O
ymax=0.3	O
,	O
x	O
tick	O
label	O
style	O
=	O
rotate=0	O
,	O
xlabel	O
=	O
Perplexity	O
,	O
ylabel	O
=	O
Normalized	O
frequency	O
,	O
y	O
label	O
style	O
=	O
at=	O
(	O
0.02	O
,	O
0.5	O
)	O
,	O
legend	O
cell	O
align	O
=	O
left	O
,	O
every	O
axis	O
plot	O
/	O
.append	O
style	O
=	O
fill	O
,	O
y	O
tick	O
label	O
style=	O
/	O
pgf	O
/	O
number	O
format	O
/	O
.cd	O
,	O
fixed	O
,	O
fixed	O
zerofill	O
,	O
precision=2	O
,	O
legend	O
pos=	O
north	O
west	O
,	O
legend	O
entries	O
=	O
AWD	Method
-	Method
LSTM	Method
+	O
PDR	Method
,	O
AWD	Method
-	Method
LSTM	Method
,	O
]	O
[	O
red	O
]	O
coordinates	O
(	O
60.17	O
,	O
0.016393442623	O
)(	O
60.32	O
,	O
0.0	O
)(	O
60.47	O
,	O
0.016393442623	O
)(	O
60.61	O
,	O
0.0655737704918	O
)(	O
60.76	O
,	O
0.114754098361	O
)(	O
60.91	O
,	O
0.131147540984	O
)(	O
61.05	O
,	O
0.114754098361	O
)(	O
61.2	O
,	O
0.147540983607	O
)(	O
61.35	O
,	O
0.229508196721	O
)(	O
61.49	O
,	O
0.0655737704918	O
)(	O
61.64	O
,	O
0.0655737704918	O
)(	O
61.79	O
,	O
0.0	O
)(	O
61.93	O
,	O
0.016393442623	O
)(	O
62.08	O
,	O
0.0	O
)(	O
62.23	O
,	O
0.016393442623	O
)	O
;	O
[	O
black!60!green	O
]	O
coordinates	O
(	O
60.17	O
,	O
0.0	O
)(	O
60.32	O
,	O
0.0	O
)(	O
60.47	O
,	O
0.0	O
)(	O
60.61	O
,	O
0.0655737704918	O
)(	O
60.76	O
,	O
0.0819672131148	O
)(	O
60.91	O
,	O
0.16393442623	O
)(	O
61.05	O
,	O
0.180327868852	O
)(	O
61.2	O
,	O
0.131147540984	O
)(	O
61.35	O
,	O
0.0983606557377	O
)(	O
61.49	O
,	O
0.114754098361	O
)(	O
61.64	O
,	O
0.131147540984	O
)(	O
61.79	O
,	O
0.0327868852459	O
)(	O
61.93	O
,	O
0.0	O
)(	O
62.08	O
,	O
0.0	O
)(	O
62.23	O
,	O
0.0	O
)	O
;	O
subsection	O
:	O
Comparison	O
with	O
AWD	Method
-	Method
LSTM	Method
cycle	O
list	O
/	O
Set1	O
-	O
4	O
[	O
scale=0.80	O
]	O
patterns	O
[	O
ybar	O
,	O
ymin=0	O
,	O
bar	O
width=2	O
,	O
x	O
tick	O
label	O
style	O
=	O
rotate=0	O
,	O
xlabel	O
=	O
Predicted	O
token	O
entropy	O
,	O
ylabel	O
=	O
Normalized	O
frequency	O
,	O
y	O
label	O
style	O
=	O
at=	O
(	O
0.02	O
,	O
0.5	O
)	O
,	O
y	O
tick	O
label	O
style=	O
/	O
pgf	O
/	O
number	O
format	O
/	O
.cd	O
,	O
fixed	O
,	O
fixed	O
zerofill	O
,	O
precision=2	O
,	O
legend	O
cell	O
align	O
=	O
left	O
,	O
every	O
axis	O
plot	O
/	O
.append	O
style	O
=	O
fill	O
,	O
legend	O
pos=	O
north	O
west	O
,	O
legend	O
entries	O
=	O
AWD	O
-	O
LSTM	Method
+	O
PDR	Method
,	O
AWD	O
-	O
LSTM	Method
,	O
]	O
[	O
red	O
]	O
coordinates	O
(	O
0.33	O
,	O
0.0668799739693	O
)(	O
1.0	O
,	O
0.031575807698	O
)(	O
1.67	O
,	O
0.0282406214835	O
)(	O
2.33	O
,	O
0.0319960953917	O
)(	O
3.0	O
,	O
0.037310701067	O
)(	O
3.67	O
,	O
0.045865589284	O
)(	O
4.33	O
,	O
0.064331132472	O
)(	O
5.0	O
,	O
0.0876367629713	O
)(	O
5.67	O
,	O
0.108068167952	O
)(	O
6.33	O
,	O
0.133922639949	O
)(	O
7.0	O
,	O
0.145975406391	O
)(	O
7.67	O
,	O
0.117490746892	O
)(	O
8.33	O
,	O
0.0765737062596	O
)(	O
9.0	O
,	O
0.0230073618135	O
)(	O
9.67	O
,	O
0.00112528640573	O
)	O
;	O
[	O
black!60!green	O
]	O
coordinates	O
(	O
0.33	O
,	O
0.0684582220475	O
)(	O
1.0	O
,	O
0.0332840738079	O
)(	O
1.67	O
,	O
0.031372442685	O
)(	O
2.33	O
,	O
0.0344093602137	O
)(	O
3.0	O
,	O
0.0409305982999	O
)(	O
3.67	O
,	O
0.0500684662211	O
)(	O
4.33	O
,	O
0.0660529562494	O
)(	O
5.0	O
,	O
0.084057538741	O
)(	O
5.67	O
,	O
0.103553464662	O
)(	O
6.33	O
,	O
0.123117178921	O
)(	O
7.0	O
,	O
0.133583698261	O
)(	O
7.67	O
,	O
0.11149825784	O
)(	O
8.33	O
,	O
0.083824279071	O
)(	O
9.0	O
,	O
0.0334982171667	O
)(	O
9.67	O
,	O
0.00229124581407	O
)	O
;	O
[	O
scale=0.80	O
]	O
[	O
xmax=1200	O
,	O
xmin=50	O
,	O
ymax=85	O
,	O
x	O
tick	O
label	O
style	O
=	O
rotate=0	O
,	O
xlabel	O
=	O
No	O
.	O
of	O
epochs	O
,	O
ylabel	O
=	O
Perplexity	O
,	O
y	O
label	O
style	O
=	O
at=	O
(	O
0.05	O
,	O
0.5	O
)	O
,	O
legend	O
cell	O
align	O
=	O
left	O
,	O
legend	O
entries	O
=	O
AWD	Method
-	Method
LSTM	Method
+	O
PDR	Method
(	O
Train	O
),	O
AWD	Method
-	Method
LSTM	Method
(	O
Train	O
),	O
AWD	Method
-	Method
LSTM	Method
+	O
PDR	Method
(	O
Valid	O
),	O
AWD	Method
-	Method
LSTM	Method
(	O
Valid	O
)	O
]	O
[	O
red	O
,	O
thick	O
,	O
dashed	O
]	O
coordinates	O
(	O
10	O
,	O
155.13	O
)(	O
20	O
,	O
107.08	O
)(	O
30	O
,	O
88.67	O
)(	O
40	O
,	O
78.86	O
)(	O
50	O
,	O
72.14	O
)(	O
60	O
,	O
68.24	O
)(	O
70	O
,	O
66.26	O
)(	O
80	O
,	O
62.77	O
)(	O
90	O
,	O
61.43	O
)(	O
100	O
,	O
59.24	O
)(	O
110	O
,	O
57.73	O
)(	O
120	O
,	O
56.89	O
)(	O
130	O
,	O
55.47	O
)(	O
140	O
,	O
54.97	O
)(	O
150	O
,	O
53.56	O
)(	O
160	O
,	O
53.39	O
)(	O
170	O
,	O
51.40	O
)(	O
180	O
,	O
50.83	O
)(	O
190	O
,	O
51.02	O
)(	O
200	O
,	O
50.42	O
)(	O
210	O
,	O
49.81	O
)(	O
220	O
,	O
49.46	O
)(	O
230	O
,	O
49.05	O
)(	O
240	O
,	O
48.19	O
)(	O
250	O
,	O
48.29	O
)(	O
260	O
,	O
48.05	O
)(	O
270	O
,	O
47.82	O
)(	O
280	O
,	O
47.44	O
)(	O
290	O
,	O
47.52	O
)(	O
300	O
,	O
46.70	O
)(	O
310	O
,	O
46.44	O
)(	O
320	O
,	O
46.24	O
)(	O
330	O
,	O
46.49	O
)(	O
340	O
,	O
45.73	O
)(	O
350	O
,	O
45.62	O
)(	O
360	O
,	O
45.44	O
)(	O
370	O
,	O
44.94	O
)(	O
380	O
,	O
45.05	O
)(	O
390	O
,	O
44.54	O
)(	O
400	O
,	O
44.91	O
)(	O
410	O
,	O
44.52	O
)(	O
420	O
,	O
44.00	O
)(	O
430	O
,	O
43.94	O
)(	O
440	O
,	O
43.95	O
)(	O
450	O
,	O
44.13	O
)(	O
460	O
,	O
43.84	O
)(	O
470	O
,	O
43.88	O
)(	O
480	O
,	O
43.63	O
)(	O
490	O
,	O
43.73	O
)(	O
500	O
,	O
43.57	O
)(	O
510	O
,	O
42.99	O
)(	O
520	O
,	O
42.78	O
)(	O
530	O
,	O
42.89	O
)(	O
540	O
,	O
43.10	O
)(	O
550	O
,	O
43.06	O
)(	O
560	O
,	O
42.55	O
)(	O
570	O
,	O
42.55	O
)(	O
580	O
,	O
42.27	O
)(	O
590	O
,	O
41.90	O
)(	O
600	O
,	O
42.71	O
)(	O
610	O
,	O
42.08	O
)(	O
620	O
,	O
42.40	O
)(	O
630	O
,	O
42.15	O
)(	O
640	O
,	O
42.14	O
)(	O
650	O
,	O
42.57	O
)(	O
660	O
,	O
41.67	O
)(	O
670	O
,	O
41.60	O
)(	O
680	O
,	O
41.43	O
)(	O
690	O
,	O
41.55	O
)(	O
700	O
,	O
41.68	O
)(	O
710	O
,	O
41.68	O
)(	O
720	O
,	O
41.44	O
)(	O
730	O
,	O
41.21	O
)(	O
740	O
,	O
41.70	O
)(	O
750	O
,	O
41.69	O
)(	O
760	O
,	O
39.79	O
)(	O
770	O
,	O
41.44	O
)(	O
780	O
,	O
41.96	O
)(	O
790	O
,	O
42.13	O
)(	O
800	O
,	O
41.67	O
)(	O
810	O
,	O
41.85	O
)(	O
820	O
,	O
42.46	O
)(	O
830	O
,	O
41.82	O
)(	O
840	O
,	O
41.82	O
)(	O
850	O
,	O
41.76	O
)(	O
860	O
,	O
41.43	O
)(	O
870	O
,	O
41.65	O
)(	O
880	O
,	O
41.61	O
)(	O
890	O
,	O
41.94	O
)(	O
900	O
,	O
41.35	O
)(	O
910	O
,	O
41.76	O
)(	O
920	O
,	O
41.30	O
)(	O
930	O
,	O
41.34	O
)(	O
940	O
,	O
41.24	O
)(	O
950	O
,	O
41.09	O
)(	O
960	O
,	O
41.11	O
)(	O
970	O
,	O
40.72	O
)(	O
980	O
,	O
41.14	O
)(	O
990	O
,	O
40.53	O
)(	O
1000	O
,	O
41.03	O
)(	O
1010	O
,	O
41.11	O
)(	O
1020	O
,	O
41.06	O
)(	O
1030	O
,	O
40.65	O
)(	O
1040	O
,	O
41.14	O
)(	O
1050	O
,	O
40.73	O
)(	O
1060	O
,	O
40.62	O
)(	O
1070	O
,	O
40.48	O
)(	O
1080	O
,	O
40.83	O
)(	O
1090	O
,	O
41.12	O
)(	O
1100	O
,	O
40.41	O
)(	O
1110	O
,	O
40.65	O
)(	O
1120	O
,	O
40.17	O
)(	O
1130	O
,	O
40.44	O
)(	O
1140	O
,	O
40.28	O
)(	O
1150	O
,	O
40.05	O
)(	O
1160	O
,	O
40.44	O
)(	O
1170	O
,	O
39.93	O
)(	O
1180	O
,	O
39.90	O
)(	O
1190	O
,	O
39.59	O
)(	O
1200	O
,	O
40.16	O
)(	O
1210	O
,	O
40.28	O
)(	O
1220	O
,	O
39.82	O
)(	O
1230	O
,	O
40.00	O
)(	O
1240	O
,	O
40.08	O
)(	O
1250	O
,	O
39.93	O
)(	O
1260	O
,	O
39.62	O
)(	O
1270	O
,	O
39.45	O
)(	O
1280	O
,	O
39.85	O
)(	O
1290	O
,	O
39.82	O
)(	O
1300	O
,	O
40.09	O
)(	O
1310	O
,	O
39.63	O
)(	O
1320	O
,	O
39.64	O
)(	O
1330	O
,	O
39.34	O
)(	O
1340	O
,	O
39.05	O
)(	O
1350	O
,	O
39.43	O
)(	O
1360	O
,	O
39.12	O
)(	O
1370	O
,	O
39.32	O
)(	O
1380	O
,	O
39.37	O
)(	O
1390	O
,	O
39.63	O
)(	O
1400	O
,	O
39.71	O
)	O
;	O
[	O
black!60!green	O
,	O
thick	O
,	O
dashed	O
]	O
coordinates	O
(	O
10	O
,	O
140.66	O
)(	O
20	O
,	O
95.19	O
)(	O
30	O
,	O
79.04	O
)(	O
40	O
,	O
69.99	O
)(	O
50	O
,	O
64.20	O
)(	O
60	O
,	O
60.38	O
)(	O
70	O
,	O
58.07	O
)(	O
80	O
,	O
55.14	O
)(	O
90	O
,	O
53.71	O
)(	O
100	O
,	O
51.55	O
)(	O
110	O
,	O
50.41	O
)(	O
120	O
,	O
49.34	O
)(	O
130	O
,	O
48.23	O
)(	O
140	O
,	O
47.76	O
)(	O
150	O
,	O
46.76	O
)(	O
160	O
,	O
46.68	O
)(	O
170	O
,	O
44.84	O
)(	O
180	O
,	O
44.30	O
)(	O
190	O
,	O
44.08	O
)(	O
200	O
,	O
43.60	O
)(	O
210	O
,	O
43.48	O
)(	O
220	O
,	O
43.03	O
)(	O
230	O
,	O
42.56	O
)(	O
240	O
,	O
41.78	O
)(	O
250	O
,	O
41.93	O
)(	O
260	O
,	O
41.61	O
)(	O
270	O
,	O
41.81	O
)(	O
280	O
,	O
41.40	O
)(	O
290	O
,	O
41.20	O
)(	O
300	O
,	O
40.69	O
)(	O
310	O
,	O
40.43	O
)(	O
320	O
,	O
40.17	O
)(	O
330	O
,	O
40.40	O
)(	O
340	O
,	O
39.86	O
)(	O
350	O
,	O
39.66	O
)(	O
360	O
,	O
39.46	O
)(	O
370	O
,	O
39.03	O
)(	O
380	O
,	O
38.83	O
)(	O
390	O
,	O
38.53	O
)(	O
400	O
,	O
38.91	O
)(	O
410	O
,	O
38.74	O
)(	O
420	O
,	O
38.21	O
)(	O
430	O
,	O
37.93	O
)(	O
440	O
,	O
38.15	O
)(	O
450	O
,	O
38.09	O
)(	O
460	O
,	O
37.83	O
)(	O
470	O
,	O
37.85	O
)(	O
480	O
,	O
37.75	O
)(	O
490	O
,	O
37.72	O
)(	O
500	O
,	O
37.27	O
)(	O
510	O
,	O
37.09	O
)(	O
520	O
,	O
37.19	O
)(	O
530	O
,	O
36.76	O
)(	O
540	O
,	O
37.15	O
)(	O
550	O
,	O
37.02	O
)(	O
560	O
,	O
36.77	O
)(	O
570	O
,	O
36.77	O
)(	O
580	O
,	O
36.53	O
)(	O
590	O
,	O
36.16	O
)(	O
600	O
,	O
36.76	O
)(	O
610	O
,	O
36.43	O
)(	O
620	O
,	O
36.24	O
)(	O
630	O
,	O
36.26	O
)(	O
640	O
,	O
36.12	O
)(	O
650	O
,	O
36.44	O
)(	O
660	O
,	O
35.96	O
)(	O
670	O
,	O
35.79	O
)(	O
680	O
,	O
35.75	O
)(	O
690	O
,	O
35.62	O
)(	O
700	O
,	O
35.79	O
)(	O
710	O
,	O
35.62	O
)(	O
720	O
,	O
35.97	O
)(	O
730	O
,	O
35.30	O
)(	O
740	O
,	O
35.43	O
)(	O
750	O
,	O
35.72	O
)(	O
760	O
,	O
36.88	O
)(	O
770	O
,	O
36.87	O
)(	O
780	O
,	O
37.12	O
)(	O
790	O
,	O
36.91	O
)(	O
800	O
,	O
36.36	O
)(	O
810	O
,	O
36.07	O
)(	O
820	O
,	O
36.33	O
)(	O
830	O
,	O
35.65	O
)(	O
840	O
,	O
35.58	O
)(	O
850	O
,	O
35.48	O
)(	O
860	O
,	O
35.18	O
)(	O
870	O
,	O
35.29	O
)(	O
880	O
,	O
34.86	O
)(	O
890	O
,	O
35.3	O
)(	O
900	O
,	O
34.87	O
)(	O
910	O
,	O
35.37	O
)(	O
920	O
,	O
34.76	O
)(	O
930	O
,	O
34.68	O
)(	O
940	O
,	O
34.69	O
)(	O
950	O
,	O
34.31	O
)(	O
960	O
,	O
34.56	O
)(	O
970	O
,	O
34.15	O
)(	O
980	O
,	O
34.4	O
)(	O
990	O
,	O
33.95	O
)(	O
1000	O
,	O
34.02	O
)(	O
1010	O
,	O
34.12	O
)(	O
1020	O
,	O
34.24	O
)(	O
1030	O
,	O
33.9	O
)(	O
1040	O
,	O
34.11	O
)(	O
1050	O
,	O
33.79	O
)(	O
1060	O
,	O
33.91	O
)(	O
1070	O
,	O
33.84	O
)(	O
1080	O
,	O
34.06	O
)(	O
1090	O
,	O
34.3	O
)(	O
1100	O
,	O
33.75	O
)(	O
1110	O
,	O
33.54	O
)(	O
1120	O
,	O
33.57	O
)(	O
1130	O
,	O
33.55	O
)(	O
1140	O
,	O
33.42	O
)(	O
1150	O
,	O
33.17	O
)(	O
1160	O
,	O
33.78	O
)(	O
1170	O
,	O
33.1	O
)(	O
1180	O
,	O
33.01	O
)(	O
1190	O
,	O
32.9	O
)(	O
1200	O
,	O
33.38	O
)(	O
1210	O
,	O
33.12	O
)(	O
1220	O
,	O
32.83	O
)(	O
1230	O
,	O
32.94	O
)(	O
1240	O
,	O
32.95	O
)(	O
1250	O
,	O
33.04	O
)(	O
1260	O
,	O
32.57	O
)(	O
1270	O
,	O
32.57	O
)(	O
1280	O
,	O
32.63	O
)(	O
1290	O
,	O
32.93	O
)(	O
1300	O
,	O
32.83	O
)(	O
1310	O
,	O
32.68	O
)(	O
1320	O
,	O
32.54	O
)(	O
1330	O
,	O
32.72	O
)(	O
1340	O
,	O
32.24	O
)(	O
1350	O
,	O
32.65	O
)(	O
1360	O
,	O
32.42	O
)(	O
1370	O
,	O
32.24	O
)(	O
1380	O
,	O
32.53	O
)(	O
1390	O
,	O
32.42	O
)(	O
1400	O
,	O
32.45	O
)	O
;	O
[	O
red	O
,	O
thick	O
]	O
coordinates	O
(	O
10	O
,	O
121.40	O
)(	O
20	O
,	O
89.75	O
)(	O
30	O
,	O
81.34	O
)(	O
40	O
,	O
75.91	O
)(	O
50	O
,	O
73.53	O
)(	O
60	O
,	O
68.18	O
)(	O
70	O
,	O
66.82	O
)(	O
80	O
,	O
66.04	O
)(	O
90	O
,	O
65.49	O
)(	O
100	O
,	O
65.03	O
)(	O
110	O
,	O
64.64	O
)(	O
120	O
,	O
64.29	O
)(	O
130	O
,	O
63.97	O
)(	O
140	O
,	O
63.70	O
)(	O
150	O
,	O
63.46	O
)(	O
160	O
,	O
63.25	O
)(	O
170	O
,	O
63.04	O
)(	O
180	O
,	O
62.85	O
)(	O
190	O
,	O
62.69	O
)(	O
200	O
,	O
62.54	O
)(	O
210	O
,	O
62.40	O
)(	O
220	O
,	O
62.27	O
)(	O
230	O
,	O
62.15	O
)(	O
240	O
,	O
62.04	O
)(	O
250	O
,	O
61.93	O
)(	O
260	O
,	O
61.84	O
)(	O
270	O
,	O
61.76	O
)(	O
280	O
,	O
61.68	O
)(	O
290	O
,	O
61.60	O
)(	O
300	O
,	O
61.53	O
)(	O
310	O
,	O
61.46	O
)(	O
320	O
,	O
61.40	O
)(	O
330	O
,	O
61.35	O
)(	O
340	O
,	O
61.30	O
)(	O
350	O
,	O
61.25	O
)(	O
360	O
,	O
61.20	O
)(	O
370	O
,	O
61.15	O
)(	O
380	O
,	O
61.11	O
)(	O
390	O
,	O
61.06	O
)(	O
400	O
,	O
61.03	O
)(	O
410	O
,	O
60.99	O
)(	O
420	O
,	O
60.95	O
)(	O
430	O
,	O
60.92	O
)(	O
440	O
,	O
60.88	O
)(	O
450	O
,	O
60.85	O
)(	O
460	O
,	O
60.82	O
)(	O
470	O
,	O
60.80	O
)(	O
480	O
,	O
60.77	O
)(	O
490	O
,	O
60.75	O
)(	O
500	O
,	O
60.73	O
)(	O
510	O
,	O
60.71	O
)(	O
520	O
,	O
60.68	O
)(	O
530	O
,	O
60.66	O
)(	O
540	O
,	O
60.65	O
)(	O
550	O
,	O
60.63	O
)(	O
560	O
,	O
60.61	O
)(	O
570	O
,	O
60.59	O
)(	O
580	O
,	O
60.58	O
)(	O
590	O
,	O
60.56	O
)(	O
600	O
,	O
60.54	O
)(	O
610	O
,	O
60.53	O
)(	O
620	O
,	O
60.51	O
)(	O
630	O
,	O
60.50	O
)(	O
640	O
,	O
60.49	O
)(	O
650	O
,	O
60.48	O
)(	O
660	O
,	O
60.47	O
)(	O
670	O
,	O
60.46	O
)(	O
680	O
,	O
60.44	O
)(	O
690	O
,	O
60.43	O
)(	O
700	O
,	O
60.42	O
)(	O
710	O
,	O
60.41	O
)(	O
720	O
,	O
60.40	O
)(	O
730	O
,	O
60.40	O
)(	O
740	O
,	O
60.39	O
)(	O
750	O
,	O
60.39	O
)(	O
760	O
,	O
59.97	O
)(	O
770	O
,	O
59.78	O
)(	O
780	O
,	O
59.64	O
)(	O
790	O
,	O
59.51	O
)(	O
800	O
,	O
59.41	O
)(	O
810	O
,	O
59.32	O
)(	O
820	O
,	O
59.25	O
)(	O
830	O
,	O
59.18	O
)(	O
840	O
,	O
59.13	O
)(	O
850	O
,	O
59.08	O
)(	O
860	O
,	O
59.03	O
)(	O
870	O
,	O
59.00	O
)(	O
880	O
,	O
58.96	O
)(	O
890	O
,	O
58.93	O
)(	O
900	O
,	O
58.90	O
)(	O
910	O
,	O
58.88	O
)(	O
920	O
,	O
58.85	O
)(	O
930	O
,	O
58.83	O
)(	O
940	O
,	O
58.80	O
)(	O
950	O
,	O
58.78	O
)(	O
960	O
,	O
58.75	O
)(	O
970	O
,	O
58.73	O
)(	O
980	O
,	O
58.71	O
)(	O
990	O
,	O
58.69	O
)(	O
1000	O
,	O
58.67	O
)(	O
1010	O
,	O
58.65	O
)(	O
1020	O
,	O
58.63	O
)(	O
1030	O
,	O
58.61	O
)(	O
1040	O
,	O
58.59	O
)(	O
1050	O
,	O
58.57	O
)(	O
1060	O
,	O
58.56	O
)(	O
1070	O
,	O
58.54	O
)(	O
1080	O
,	O
58.52	O
)(	O
1090	O
,	O
58.50	O
)(	O
1100	O
,	O
58.48	O
)(	O
1110	O
,	O
58.47	O
)(	O
1120	O
,	O
58.45	O
)(	O
1130	O
,	O
58.44	O
)(	O
1140	O
,	O
58.42	O
)(	O
1150	O
,	O
58.41	O
)(	O
1160	O
,	O
58.39	O
)(	O
1170	O
,	O
58.38	O
)(	O
1180	O
,	O
58.37	O
)(	O
1190	O
,	O
58.35	O
)(	O
1200	O
,	O
58.34	O
)(	O
1210	O
,	O
58.33	O
)(	O
1220	O
,	O
58.31	O
)(	O
1230	O
,	O
58.30	O
)(	O
1240	O
,	O
58.29	O
)(	O
1250	O
,	O
58.28	O
)(	O
1260	O
,	O
58.27	O
)(	O
1270	O
,	O
58.26	O
)(	O
1280	O
,	O
58.25	O
)(	O
1290	O
,	O
58.24	O
)(	O
1300	O
,	O
58.23	O
)(	O
1310	O
,	O
58.22	O
)(	O
1320	O
,	O
58.21	O
)(	O
1330	O
,	O
58.21	O
)(	O
1340	O
,	O
58.20	O
)(	O
1350	O
,	O
58.19	O
)(	O
1360	O
,	O
58.18	O
)(	O
1370	O
,	O
58.18	O
)(	O
1380	O
,	O
58.17	O
)(	O
1390	O
,	O
58.16	O
)(	O
1400	O
,	O
58.15	O
)	O
;	O
[	O
black!60!green	O
,	O
thick	O
]	O
coordinates	O
(	O
10	O
,	O
115.36	O
)(	O
20	O
,	O
87.02	O
)(	O
30	O
,	O
79.04	O
)(	O
40	O
,	O
74.46	O
)(	O
50	O
,	O
72.82	O
)(	O
60	O
,	O
67.61	O
)(	O
70	O
,	O
66.66	O
)(	O
80	O
,	O
65.95	O
)(	O
90	O
,	O
65.42	O
)(	O
100	O
,	O
64.98	O
)(	O
110	O
,	O
64.60	O
)(	O
120	O
,	O
64.27	O
)(	O
130	O
,	O
63.96	O
)(	O
140	O
,	O
63.70	O
)(	O
150	O
,	O
63.48	O
)(	O
160	O
,	O
63.29	O
)(	O
170	O
,	O
63.12	O
)(	O
180	O
,	O
62.96	O
)(	O
190	O
,	O
62.81	O
)(	O
200	O
,	O
62.68	O
)(	O
210	O
,	O
62.56	O
)(	O
220	O
,	O
62.45	O
)(	O
230	O
,	O
62.35	O
)(	O
240	O
,	O
62.26	O
)(	O
250	O
,	O
62.17	O
)(	O
260	O
,	O
62.09	O
)(	O
270	O
,	O
62.02	O
)(	O
280	O
,	O
61.95	O
)(	O
290	O
,	O
61.89	O
)(	O
300	O
,	O
61.83	O
)(	O
310	O
,	O
61.77	O
)(	O
320	O
,	O
61.72	O
)(	O
330	O
,	O
61.66	O
)(	O
340	O
,	O
61.62	O
)(	O
350	O
,	O
61.57	O
)(	O
360	O
,	O
61.53	O
)(	O
370	O
,	O
61.48	O
)(	O
380	O
,	O
61.45	O
)(	O
390	O
,	O
61.41	O
)(	O
400	O
,	O
61.38	O
)(	O
410	O
,	O
61.35	O
)(	O
420	O
,	O
61.32	O
)(	O
430	O
,	O
61.29	O
)(	O
440	O
,	O
61.26	O
)(	O
450	O
,	O
61.23	O
)(	O
460	O
,	O
61.21	O
)(	O
470	O
,	O
61.18	O
)(	O
480	O
,	O
61.16	O
)(	O
490	O
,	O
61.14	O
)(	O
500	O
,	O
61.13	O
)(	O
510	O
,	O
61.11	O
)(	O
520	O
,	O
61.09	O
)(	O
530	O
,	O
61.07	O
)(	O
540	O
,	O
61.06	O
)(	O
550	O
,	O
61.04	O
)(	O
560	O
,	O
61.02	O
)(	O
570	O
,	O
61.01	O
)(	O
580	O
,	O
61.00	O
)(	O
590	O
,	O
60.98	O
)(	O
600	O
,	O
60.97	O
)(	O
610	O
,	O
60.96	O
)(	O
620	O
,	O
60.94	O
)(	O
630	O
,	O
60.93	O
)(	O
640	O
,	O
60.92	O
)(	O
650	O
,	O
60.91	O
)(	O
660	O
,	O
60.90	O
)(	O
670	O
,	O
60.89	O
)(	O
680	O
,	O
60.88	O
)(	O
690	O
,	O
60.87	O
)(	O
700	O
,	O
60.86	O
)(	O
710	O
,	O
60.85	O
)(	O
720	O
,	O
60.84	O
)(	O
730	O
,	O
60.83	O
)(	O
740	O
,	O
60.83	O
)(	O
750	O
,	O
60.82	O
)(	O
760	O
,	O
60.37	O
)(	O
770	O
,	O
60.30	O
)(	O
780	O
,	O
60.25	O
)(	O
790	O
,	O
60.18	O
)(	O
800	O
,	O
60.13	O
)(	O
810	O
,	O
60.07	O
)(	O
820	O
,	O
60.01	O
)(	O
830	O
,	O
59.97	O
)(	O
840	O
,	O
59.93	O
)(	O
850	O
,	O
59.91	O
)(	O
860	O
,	O
59.89	O
)(	O
870	O
,	O
59.86	O
)(	O
880	O
,	O
59.83	O
)(	O
890	O
,	O
59.81	O
)(	O
900	O
,	O
59.78	O
)(	O
910	O
,	O
59.76	O
)(	O
920	O
,	O
59.75	O
)(	O
930	O
,	O
59.73	O
)(	O
940	O
,	O
59.72	O
)(	O
950	O
,	O
59.70	O
)(	O
960	O
,	O
59.69	O
)(	O
970	O
,	O
59.68	O
)(	O
980	O
,	O
59.67	O
)(	O
990	O
,	O
59.66	O
)(	O
1000	O
,	O
59.65	O
)(	O
1010	O
,	O
59.63	O
)(	O
1020	O
,	O
59.62	O
)(	O
1030	O
,	O
59.61	O
)(	O
1040	O
,	O
59.60	O
)(	O
1050	O
,	O
59.58	O
)(	O
1060	O
,	O
59.57	O
)(	O
1070	O
,	O
59.56	O
)(	O
1080	O
,	O
59.55	O
)(	O
1090	O
,	O
59.54	O
)(	O
1100	O
,	O
59.52	O
)(	O
1110	O
,	O
59.51	O
)(	O
1120	O
,	O
59.49	O
)(	O
1130	O
,	O
59.48	O
)(	O
1140	O
,	O
59.47	O
)(	O
1150	O
,	O
59.46	O
)(	O
1160	O
,	O
59.45	O
)(	O
1170	O
,	O
59.44	O
)(	O
1180	O
,	O
59.43	O
)(	O
1190	O
,	O
59.43	O
)(	O
1200	O
,	O
59.42	O
)(	O
1210	O
,	O
59.41	O
)(	O
1220	O
,	O
59.40	O
)(	O
1230	O
,	O
59.39	O
)(	O
1240	O
,	O
59.39	O
)(	O
1250	O
,	O
59.38	O
)(	O
1260	O
,	O
59.37	O
)(	O
1270	O
,	O
59.37	O
)(	O
1280	O
,	O
59.36	O
)(	O
1290	O
,	O
59.36	O
)(	O
1300	O
,	O
59.35	O
)(	O
1310	O
,	O
59.35	O
)(	O
1320	O
,	O
59.34	O
)(	O
1330	O
,	O
59.34	O
)(	O
1340	O
,	O
59.34	O
)(	O
1350	O
,	O
59.33	O
)(	O
1360	O
,	O
59.33	O
)(	O
1370	O
,	O
59.33	O
)(	O
1380	O
,	O
59.32	O
)(	O
1390	O
,	O
59.32	O
)(	O
1400	O
,	O
59.31	O
)	O
;	O
To	O
show	O
the	O
qualitative	O
difference	O
between	O
AWD	Method
-	Method
LSTM	Method
+	O
PDR	Method
and	O
AWD	Method
-	Method
LSTM	Method
,	O
in	O
Fig	O
.	O
[	O
reference	O
]	O
(	O
a	O
)	O
,	O
we	O
plot	O
a	O
histogram	O
of	O
the	O
entropy	Metric
of	O
the	O
predicted	O
next	O
token	O
distribution	O
for	O
all	O
the	O
tokens	O
in	O
the	O
validation	O
set	O
of	O
PTB	Material
achieved	O
by	O
their	O
respective	O
best	O
models	O
.	O
The	O
distributions	O
for	O
the	O
two	O
models	O
is	O
slightly	O
different	O
,	O
with	O
some	O
identifiable	O
patterns	O
.	O
The	O
use	O
of	O
PDR	Method
has	O
the	O
effect	O
of	O
reducing	O
the	O
entropy	Metric
of	O
the	O
predicted	O
distribution	O
when	O
it	O
is	O
in	O
the	O
higher	O
range	O
of	O
8	O
and	O
above	O
,	O
pushing	O
it	O
into	O
the	O
range	O
of	O
5	O
-	O
8	O
.	O
This	O
shows	O
that	O
one	O
way	O
PDR	Method
biases	O
the	O
language	Method
model	Method
is	O
by	O
reducing	O
the	O
entropy	O
of	O
the	O
predicted	O
next	O
token	O
distribution	O
.	O
Indeed	O
,	O
one	O
way	O
to	O
reduce	O
the	O
cross	Metric
-	Metric
entropy	Metric
between	O
and	O
is	O
by	O
making	O
less	O
spread	O
out	O
in	O
Eq	O
.	O
(	O
[	O
reference	O
]	O
)	O
.	O
This	O
tends	O
to	O
benefits	O
the	O
language	Method
model	Method
when	O
the	O
predictions	O
are	O
correct	O
.	O
We	O
also	O
compare	O
the	O
training	Material
curves	O
for	O
the	O
two	O
models	O
in	O
Fig	O
.	O
[	O
reference	O
]	O
(	O
b	O
)	O
on	O
PTB	Material
.	O
Although	O
the	O
two	O
models	O
use	O
slightly	O
different	O
hyperparameters	O
,	O
the	O
regularization	O
effect	O
of	O
PDR	Method
is	O
apparent	O
with	O
a	O
lower	O
validation	Metric
perplexity	Metric
but	O
higher	O
training	Material
perplexity	O
.	O
The	O
corresponding	O
trends	O
shown	O
in	O
Fig	O
.	O
[	O
reference	O
]	O
(	O
a	O
,	O
b	O
)	O
for	O
WT2	Material
have	O
similar	O
characteristics	O
.	O
subsection	O
:	O
Ablation	Task
Studies	Task
We	O
perform	O
a	O
set	O
of	O
ablation	Task
experiments	O
on	O
the	O
best	O
AWD	Method
-	Method
LSTM	Method
+	O
PDR	Method
models	O
for	O
PTB	Material
and	O
WT2	Material
to	O
understand	O
the	O
relative	O
contribution	O
of	O
PDR	Method
and	O
the	O
other	O
regularizations	Method
used	O
in	O
the	O
model	O
.	O
The	O
results	O
are	O
shown	O
in	O
Table	O
[	O
reference	O
]	O
.	O
In	O
both	O
cases	O
,	O
PDR	Method
has	O
a	O
significant	O
effect	O
in	O
decreasing	O
the	O
validation	Metric
set	Metric
performance	Metric
,	O
albeit	O
lesser	O
than	O
the	O
other	O
forms	O
of	O
regularization	Method
.	O
This	O
is	O
not	O
surprising	O
as	O
PDR	Method
does	O
not	O
influence	O
the	O
LSTM	Method
directly	O
.	O
section	O
:	O
Related	O
Work	O
Our	O
method	O
builds	O
on	O
the	O
work	O
of	O
using	O
sophisticated	O
regularization	Method
techniques	Method
to	O
train	O
LSTMs	Method
for	O
language	Task
modeling	Task
.	O
In	O
particular	O
,	O
the	O
AWD	Method
-	Method
LSTM	Method
model	Method
achieves	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
performance	O
with	O
a	O
single	O
softmax	Method
on	O
the	O
four	O
datasets	O
considered	O
in	O
this	O
paper	O
(	O
)	O
.	O
also	O
achieve	O
similar	O
results	O
with	O
highly	O
regularized	O
LSTMs	Method
.	O
By	O
addressing	O
the	O
so	O
-	O
called	O
softmax	Method
bottleneck	Method
in	O
single	O
softmax	Method
models	Method
,	O
use	O
a	O
mixture	Method
-	Method
of	Method
-	Method
softmaxes	Method
to	O
achieve	O
significantly	O
lower	O
perplexities	Metric
.	O
PDR	Method
utilizes	O
the	O
symmetry	O
between	O
the	O
inputs	O
and	O
outputs	O
of	O
a	O
language	Method
model	Method
,	O
a	O
fact	O
that	O
is	O
also	O
exploited	O
in	O
weight	Method
tying	Method
(	O
)	O
.	O
Our	O
method	O
can	O
be	O
used	O
with	O
untied	O
weights	O
as	O
well	O
.	O
Although	O
motivated	O
by	O
language	Method
modeling	Method
,	O
PDR	Method
can	O
also	O
be	O
applied	O
to	O
seq2seq	Method
models	Method
with	O
shared	O
input	O
-	O
output	O
vocabularies	O
,	O
such	O
as	O
those	O
used	O
for	O
text	Task
summarization	Task
and	O
neural	Task
machine	Task
translation	Task
(	O
with	O
byte	O
pair	O
encoding	O
of	O
words	O
)	O
(	O
)	O
.	O
Regularizing	O
the	O
training	Material
of	O
an	O
LSTM	Method
by	O
combining	O
the	O
main	O
objective	O
function	O
with	O
auxiliary	Task
tasks	Task
has	O
been	O
successfully	O
applied	O
to	O
several	O
tasks	O
in	O
NLP	Task
(	Task
)	O
.	O
In	O
fact	O
,	O
a	O
popular	O
choice	O
for	O
the	O
auxiliary	Task
task	Task
is	O
language	Method
modeling	Method
itself	O
.	O
This	O
in	O
turn	O
is	O
related	O
to	O
multi	Task
-	Task
task	Task
learning	Task
(	O
)	O
.	O
Specialized	Method
architectures	Method
like	O
Recurrent	Method
Highway	Method
Networks	Method
(	O
)	O
and	O
NAS	Method
(	O
)	O
have	O
been	O
successfully	O
used	O
to	O
achieve	O
competitive	O
performance	O
in	O
language	Task
modeling	Task
.	O
The	O
former	O
one	O
makes	O
the	O
hidden	O
-	O
to	O
-	O
hidden	O
transition	O
function	O
more	O
complex	O
allowing	O
for	O
more	O
refined	O
information	O
flow	O
.	O
Such	O
architectures	O
are	O
especially	O
important	O
for	O
character	Task
level	Task
language	Task
modeling	Task
where	O
strong	O
results	O
have	O
been	O
shown	O
using	O
Fast	Method
-	Method
Slow	Method
RNNs	Method
(	O
)	O
,	O
a	O
two	Method
level	Method
architecture	Method
where	O
the	O
slowly	Method
changing	Method
recurrent	Method
network	Method
tries	O
to	O
capture	O
more	O
long	O
range	O
dependencies	O
.	O
The	O
use	O
of	O
historical	O
information	O
can	O
greatly	O
help	O
language	Method
models	Method
deal	O
with	O
long	O
range	O
dependencies	O
as	O
shown	O
by	O
.	O
Finally	O
,	O
in	O
a	O
recent	O
paper	O
,	O
achieve	O
improved	O
performance	O
for	O
language	Task
modeling	Task
by	O
using	O
frequency	Method
agnostic	Method
word	Method
embeddings	Method
,	O
a	O
technique	O
orthogonal	O
to	O
and	O
combinable	O
with	O
PDR	Method
.	O
bibliography	O
:	O
References	O
