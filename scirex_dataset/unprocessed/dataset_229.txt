document	O
:	O
Learning	O
Deep	Method
Context	Method
-	Method
aware	Method
Features	Method
over	O
Body	O
and	O
Latent	O
Parts	O
for	O
Person	Task
Re	Task
-	Task
identification	Task
Person	Task
Re	Task
-	Task
identification	Task
(	O
ReID	Task
)	O
is	O
to	O
identify	O
the	O
same	O
person	O
across	O
different	O
cameras	O
.	O
It	O
is	O
a	O
challenging	O
task	O
due	O
to	O
the	O
large	O
variations	O
in	O
person	O
pose	O
,	O
occlusion	O
,	O
background	O
clutter	O
,	O
How	O
to	O
extract	O
powerful	O
features	O
is	O
a	O
fundamental	O
problem	O
in	O
ReID	Task
and	O
is	O
still	O
an	O
open	O
problem	O
today	O
.	O
In	O
this	O
paper	O
,	O
we	O
design	O
a	O
Multi	Method
-	Method
Scale	Method
Context	Method
-	Method
Aware	Method
Network	Method
(	O
MSCAN	Method
)	O
to	O
learn	O
powerful	O
features	O
over	O
full	O
body	O
and	O
body	O
parts	O
,	O
which	O
can	O
well	O
capture	O
the	O
local	O
context	O
knowledge	O
by	O
stacking	O
multi	Method
-	Method
scale	Method
convolutions	Method
in	O
each	O
layer	O
.	O
Moreover	O
,	O
instead	O
of	O
using	O
predefined	O
rigid	O
parts	O
,	O
we	O
propose	O
to	O
learn	O
and	O
localize	O
deformable	O
pedestrian	O
parts	O
using	O
Spatial	Method
Transformer	Method
Networks	Method
(	O
STN	Method
)	O
with	O
novel	O
spatial	O
constraints	O
.	O
The	O
learned	O
body	O
parts	O
can	O
release	O
some	O
difficulties	O
,	O
pose	O
variations	O
and	O
background	O
clutters	O
,	O
in	O
part	Method
-	Method
based	Method
representation	Method
.	O
Finally	O
,	O
we	O
integrate	O
the	O
representation	Method
learning	Method
processes	Method
of	Method
full	Method
body	Method
and	Method
body	Method
parts	Method
into	O
a	O
unified	O
framework	O
for	O
person	O
ReID	Task
through	O
multi	Task
-	Task
class	Task
person	Task
identification	Task
tasks	Task
.	O
Extensive	O
evaluations	O
on	O
current	O
challenging	O
large	O
-	O
scale	O
person	O
ReID	Task
datasets	O
,	O
including	O
the	O
image	O
-	O
based	O
Market1501	Material
,	O
CUHK03	Material
and	O
sequence	O
-	O
based	O
MARS	Material
datasets	Material
,	O
show	O
that	O
the	O
proposed	O
method	O
achieves	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
results	O
.	O
table	O
section	O
:	O
Introduction	O
Person	Task
re	Task
-	Task
identification	Task
aims	O
to	O
search	O
for	O
the	O
same	O
person	O
across	O
different	O
cameras	O
with	O
a	O
given	O
probe	O
image	O
.	O
It	O
has	O
attracted	O
much	O
attention	O
in	O
recent	O
years	O
due	O
to	O
its	O
importance	O
in	O
many	O
practical	O
applications	O
,	O
such	O
as	O
video	Task
surveillance	Task
and	O
content	Task
-	Task
based	Task
image	Task
retrieval	Task
.	O
Despite	O
of	O
years	O
of	O
efforts	O
,	O
it	O
still	O
has	O
many	O
challenges	O
,	O
such	O
as	O
large	O
variations	O
in	O
person	O
pose	O
,	O
illumination	O
,	O
and	O
background	O
clutter	O
.	O
In	O
addition	O
,	O
similar	O
appearance	O
of	O
clothes	O
among	O
different	O
people	O
and	O
imperfect	O
pedestrian	Task
detection	Task
results	O
further	O
increase	O
its	O
difficulty	O
in	O
real	O
applications	O
.	O
Most	O
existing	O
methods	O
for	O
ReID	Task
focus	O
on	O
developing	O
a	O
powerful	O
representation	O
to	O
handle	O
the	O
variations	O
of	O
viewpoint	O
,	O
body	O
pose	O
,	O
background	O
clutter	O
,	O
,	O
or	O
learning	O
an	O
effective	O
distance	Metric
metric	Metric
.	O
Some	O
of	O
existing	O
methods	O
learn	O
both	O
of	O
them	O
jointly	O
.	O
Recently	O
,	O
deep	Method
feature	Method
learning	Method
based	Method
methods	Method
,	O
which	O
learn	O
a	O
global	O
pedestrian	O
feature	O
and	O
use	O
Euclidean	O
metric	O
to	O
measure	O
two	O
samples	O
,	O
have	O
obtained	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
results	O
.	O
With	O
the	O
increasing	O
sample	O
size	O
of	O
ReID	Task
dataset	O
,	O
the	O
learning	Task
of	Task
features	Task
from	O
multi	Task
-	Task
class	Task
person	Task
identification	Task
tasks	Task
,	O
denoted	O
as	O
ID	Method
-	Method
discriminative	Method
Embedding	Method
(	Method
IDE	Method
)	Method
,	O
has	O
shown	O
great	O
potentials	O
on	O
current	O
large	O
-	O
scale	O
person	O
ReID	Task
datasets	O
,	O
such	O
as	O
MARS	Material
and	O
PRW	Method
,	O
where	O
the	O
IDE	O
features	O
are	O
taken	O
from	O
the	O
last	O
hidden	Method
layer	Method
of	O
Deep	Method
Convolutional	Method
Neural	Method
Networks	Method
(	O
DCNN	Method
)	O
.	O
In	O
this	O
paper	O
,	O
we	O
aim	O
to	O
learn	O
the	O
IDE	O
feature	O
for	O
person	O
ReID	Task
using	O
DCNN	Method
.	O
Existing	O
DCNN	Method
models	Method
for	O
person	O
ReID	Task
typically	O
learn	O
a	O
global	Method
full	Method
-	Method
body	Method
representation	Method
for	O
input	O
person	O
image	O
(	O
Full	O
body	O
in	O
Figure	O
[	O
reference	O
]	O
)	O
,	O
or	O
learn	O
a	O
part	Method
-	Method
based	Method
representation	Method
for	O
predefined	O
rigid	O
parts	O
(	O
Rigid	O
body	O
parts	O
in	O
Figure	O
[	O
reference	O
]	O
)	O
or	O
learn	O
a	O
feature	Method
embedding	Method
for	O
both	O
of	O
them	O
.	O
Although	O
these	O
DCNN	Method
models	Method
have	O
obtained	O
impressive	O
results	O
on	O
existing	O
ReID	Material
datasets	Material
,	O
there	O
are	O
still	O
two	O
problems	O
.	O
First	O
,	O
for	O
feature	Task
learning	Task
,	O
current	O
popular	O
DCNN	Method
models	Method
typically	O
stack	O
single	Method
-	Method
scale	Method
convolution	Method
and	Method
max	Method
pooling	Method
layers	Method
to	O
generate	O
deep	Method
networks	Method
.	O
With	O
the	O
increase	O
of	O
the	O
number	O
of	O
layers	O
,	O
these	O
DCNN	Method
models	Method
could	O
easily	O
miss	O
some	O
small	O
scale	O
visual	O
cues	O
,	O
such	O
as	O
sunglasses	O
and	O
shoes	O
.	O
However	O
,	O
these	O
fine	O
-	O
grained	O
attributes	O
are	O
very	O
useful	O
to	O
distinguish	O
the	O
pedestrian	O
pairs	O
with	O
small	O
inter	O
-	O
class	O
variations	O
.	O
Thus	O
these	O
DCNN	Method
models	Method
are	O
not	O
the	O
best	O
choice	O
for	O
pedestrian	Task
feature	Task
learning	Task
.	O
Second	O
,	O
due	O
to	O
the	O
pose	O
variations	O
and	O
imperfect	O
pedestrian	Method
detectors	Method
,	O
the	O
pedestrian	O
image	O
samples	O
may	O
be	O
misaligned	O
.	O
Sometimes	O
they	O
may	O
have	O
some	O
backgrounds	O
or	O
lack	O
some	O
parts	O
,	O
legs	O
.	O
In	O
these	O
cases	O
,	O
for	O
part	Method
-	Method
based	Method
representation	Method
,	O
the	O
predefined	O
rigid	O
grids	O
may	O
fail	O
to	O
capture	O
correct	O
correspondence	O
between	O
two	O
pedestrian	O
images	O
.	O
Thus	O
the	O
rigid	O
predefined	O
grids	O
are	O
far	O
from	O
robust	O
for	O
effective	O
part	Task
-	Task
based	Task
feature	Task
learning	Task
.	O
In	O
this	O
paper	O
,	O
we	O
propose	O
to	O
learn	O
the	O
features	O
of	O
full	O
body	O
and	O
body	O
parts	O
jointly	O
.	O
To	O
solve	O
the	O
first	O
problem	O
,	O
we	O
propose	O
a	O
Multi	Method
-	Method
Scale	Method
Context	Method
-	Method
Aware	Method
Network	Method
(	O
MSCAN	Method
)	O
.	O
As	O
shown	O
in	O
Figure	O
[	O
reference	O
]	O
,	O
for	O
each	O
convolutional	Method
layer	Method
of	O
the	O
MSCAN	Method
,	O
we	O
adopt	O
multiple	O
convolution	Method
kernels	Method
with	O
different	O
receptive	O
fields	O
to	O
obtain	O
multiple	O
feature	O
maps	O
.	O
Feature	O
maps	O
from	O
different	O
convolution	Method
kernels	Method
are	O
concatenated	O
as	O
current	O
layer	O
’s	O
output	O
.	O
To	O
decrease	O
the	O
correlations	O
among	O
different	O
convolution	O
kernels	O
,	O
the	O
dilated	Method
convolution	Method
is	O
used	O
rather	O
than	O
general	Method
convolution	Method
kernels	Method
.	O
Through	O
this	O
way	O
,	O
multi	O
-	O
scale	O
context	O
knowledge	O
is	O
obtained	O
at	O
the	O
same	O
layer	O
.	O
Thus	O
the	O
local	O
visual	O
cues	O
for	O
fine	Task
-	Task
grained	Task
discrimination	Task
is	O
enhanced	O
.	O
In	O
addition	O
,	O
through	O
embedding	O
contextual	O
features	O
layer	O
-	O
by	O
-	O
layer	O
(	O
convolution	Method
operation	Method
across	O
layers	O
)	O
,	O
MSCAN	Method
can	O
obtain	O
more	O
context	Method
-	Method
aware	Method
representation	Method
for	O
input	O
image	O
.	O
To	O
solve	O
the	O
second	O
problem	O
,	O
instead	O
of	O
using	O
rigid	O
body	O
parts	O
,	O
we	O
propose	O
to	O
localize	O
latent	O
pedestrian	O
parts	O
through	O
Spatial	Method
Transform	Method
Networks	Method
(	O
STN	Method
)	Method
,	O
which	O
is	O
originally	O
proposed	O
to	O
learn	O
image	Task
transformation	Task
.	O
To	O
adapt	O
it	O
to	O
the	O
pedestrian	Task
part	Task
localization	Task
task	Task
,	O
we	O
propose	O
three	O
new	O
constraints	O
on	O
the	O
learned	O
transformation	O
parameters	O
.	O
With	O
these	O
constraints	O
,	O
more	O
flexible	O
parts	O
can	O
be	O
localized	O
at	O
the	O
informative	O
regions	O
,	O
so	O
as	O
to	O
reduce	O
the	O
distraction	O
of	O
background	O
contents	O
.	O
Generally	O
,	O
the	O
features	O
of	O
full	O
body	O
and	O
body	O
parts	O
are	O
complementary	O
to	O
each	O
other	O
.	O
The	O
full	O
-	O
body	O
features	O
pay	O
more	O
attention	O
to	O
the	O
global	O
information	O
while	O
the	O
body	O
-	O
part	O
features	O
care	O
more	O
about	O
the	O
local	O
regions	O
.	O
To	O
better	O
utilize	O
these	O
two	O
types	O
of	O
representations	O
,	O
in	O
this	O
paper	O
,	O
features	O
of	O
full	O
body	O
and	O
body	O
parts	O
are	O
concatenated	O
to	O
form	O
the	O
final	O
pedestrian	Method
representation	Method
.	O
In	O
test	O
stage	O
,	O
the	O
Euclidean	Metric
metric	Metric
is	O
adopted	O
to	O
compute	O
the	O
distance	O
between	O
two	O
L2	Method
normalized	Method
person	Method
representations	Method
for	O
person	O
ReID	Task
.	O
The	O
contributions	O
of	O
this	O
paper	O
are	O
summarized	O
as	O
follows	O
:	O
(	O
a	O
)	O
We	O
propose	O
a	O
multi	Method
-	Method
scale	Method
context	Method
-	Method
aware	Method
network	Method
to	O
enhance	O
the	O
visual	O
context	O
information	O
for	O
better	O
feature	Task
representation	Task
of	Task
fine	Task
-	Task
grained	Task
visual	Task
cues	Task
.	O
(	O
b	O
)	O
Instead	O
of	O
using	O
rigid	O
parts	O
,	O
we	O
propose	O
to	O
learn	O
and	O
localize	Task
pedestrian	Task
parts	Task
using	O
spatial	Method
transformer	Method
networks	Method
with	O
novel	O
prior	O
spatial	O
constraints	O
.	O
Experimental	O
results	O
show	O
that	O
fusing	O
the	O
global	Method
full	Method
-	Method
body	Method
and	Method
local	Method
body	Method
-	Method
part	Method
representations	Method
greatly	O
improves	O
the	O
performance	O
of	O
person	O
ReID	Task
.	O
section	O
:	O
Related	O
Work	O
Typical	O
person	O
ReID	Task
methods	O
focus	O
on	O
two	O
key	O
points	O
:	O
developing	O
a	O
powerful	O
feature	O
for	O
image	Task
representation	Task
and	O
learning	O
an	O
effective	O
metric	O
to	O
make	O
the	O
same	O
person	O
be	O
close	O
and	O
different	O
persons	O
far	O
away	O
.	O
Recently	O
,	O
deep	Method
learning	Method
approaches	Method
have	O
achieved	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
results	O
for	O
person	O
ReID	Task
.	O
Here	O
we	O
mainly	O
review	O
the	O
related	O
deep	Method
learning	Method
methods	Method
.	O
Deep	Method
learning	Method
approaches	Method
for	O
person	O
ReID	Task
tend	O
to	O
learn	O
person	O
representation	O
and	O
similarity	Metric
(	Metric
distance	Metric
)	Metric
metric	Metric
jointly	O
.	O
Given	O
a	O
pair	O
of	O
person	O
images	O
,	O
previous	O
deep	Method
learning	Method
approaches	Method
learn	O
each	O
person	O
’s	O
features	O
followed	O
by	O
a	O
deep	Method
matching	Method
function	Method
from	O
the	O
convolutional	O
features	O
or	O
the	O
Fully	Method
Connected	Method
(	Method
FC	Method
)	Method
features	Method
.	O
In	O
addition	O
to	O
the	O
deep	Method
metric	Method
learning	Method
,	O
some	O
work	O
directly	O
learns	O
image	Method
representation	Method
through	O
pair	Metric
-	Metric
wise	Metric
contrastive	Metric
loss	Metric
or	O
triplet	Metric
ranking	Metric
loss	Metric
,	O
and	O
use	O
Euclidean	Method
metric	Method
for	O
comparison	O
.	O
With	O
the	O
increasing	O
sample	O
size	O
of	O
ReID	Task
dataset	O
,	O
the	O
IDE	O
feature	O
which	O
is	O
learned	O
through	O
multi	Task
-	Task
class	Task
person	Task
identification	Task
tasks	Task
,	O
has	O
shown	O
great	O
potentials	O
on	O
current	O
large	O
-	O
scale	O
person	O
ReID	Material
datasets	Material
.	O
Xiao	O
propose	O
the	O
domain	Method
guided	Method
dropout	Method
to	O
learn	O
features	O
over	O
multiple	O
datasets	O
simultaneously	O
with	O
identity	Task
classification	Task
loss	Task
.	O
Zheng	O
learn	O
the	O
IDE	O
feature	O
for	O
the	O
video	Task
-	Task
based	Task
person	Task
re	Task
-	Task
identification	Task
.	O
Xiao	O
and	O
Zheng	O
learn	O
the	O
IDE	O
feature	O
to	O
jointly	O
solve	O
the	O
pedestrian	Task
detection	Task
and	O
person	Task
ReID	Task
tasks	Task
.	O
Schumann	O
learn	O
the	O
IDE	O
feature	O
for	O
domain	Task
adaptive	Task
person	Task
ReID	Task
.	O
The	O
similar	O
phenomenon	O
has	O
also	O
been	O
validated	O
on	O
face	Task
recognition	Task
.	O
As	O
we	O
know	O
,	O
previous	O
DCNN	Method
models	Method
usually	O
adopt	O
the	O
layer	Method
-	Method
by	Method
-	Method
layer	Method
single	Method
-	Method
scale	Method
convolution	Method
kernels	Method
to	O
learn	O
the	O
context	O
information	O
.	O
Some	O
DCNN	Method
models	Method
adopt	O
rigid	O
body	O
parts	O
to	O
learn	O
local	O
pedestrian	O
features	O
.	O
Different	O
from	O
them	O
,	O
we	O
improve	O
the	O
classical	O
models	O
in	O
two	O
ways	O
.	O
Firstly	O
,	O
we	O
propose	O
to	O
enhance	O
the	O
context	O
knowledge	O
through	O
multi	Method
-	Method
scale	Method
convolutions	Method
at	O
the	O
same	O
layer	O
.	O
The	O
relationship	O
among	O
different	O
context	O
knowledge	O
are	O
learned	O
by	O
embedding	Method
feature	Method
maps	Method
layer	Method
-	Method
by	Method
-	Method
layer	Method
(	O
convolution	Method
or	Method
FC	Method
operation	Method
)	O
.	O
Secondly	O
,	O
instead	O
of	O
using	O
rigid	O
parts	O
,	O
we	O
utilize	O
the	O
spatial	Method
transformer	Method
networks	Method
with	O
proposed	O
prior	O
constraints	O
to	O
learn	O
and	O
localize	O
latent	O
human	O
parts	O
.	O
section	O
:	O
Proposed	O
Method	O
The	O
focus	O
of	O
this	O
approach	O
is	O
to	O
learn	O
powerful	O
feature	Method
representations	Method
to	O
describe	O
pedestrians	O
.	O
The	O
overall	O
framework	O
of	O
the	O
proposed	O
method	O
is	O
shown	O
in	O
Figure	O
[	O
reference	O
]	O
.	O
In	O
this	O
section	O
,	O
we	O
introduce	O
our	O
model	O
from	O
four	O
aspects	O
:	O
a	O
multi	Method
-	Method
scale	Method
context	Method
-	Method
aware	Method
network	Method
for	O
efficient	O
feature	Task
learning	Task
(	O
Section	O
[	O
reference	O
]	O
)	O
,	O
the	O
latent	Method
parts	Method
learning	Method
and	Method
localization	Method
for	O
better	O
local	Method
part	Method
-	Method
based	Method
feature	Method
representation	Method
(	O
Section	O
[	O
reference	O
]	O
)	O
,	O
the	O
fusion	O
of	O
global	O
full	O
-	O
body	O
and	O
local	O
body	O
-	O
part	O
features	O
for	O
person	O
ReID	Task
(	O
Section	O
[	O
reference	O
]	O
)	O
,	O
and	O
our	O
final	O
objective	Metric
function	Metric
in	O
Section	O
[	O
reference	O
]	O
.	O
subsection	O
:	O
Multi	Task
-	Task
scale	Task
Context	Task
-	Task
aware	Task
Network	Task
Visual	Task
context	Task
is	O
an	O
important	O
component	O
to	O
assist	O
visual	Task
-	Task
related	Task
tasks	Task
,	O
such	O
as	O
object	Task
recognition	Task
and	O
object	Task
detection	Task
.	O
Typical	O
convolutional	Method
neural	Method
networks	Method
model	O
context	O
information	O
through	O
hierarchical	Method
convolution	Method
and	O
pooling	Method
.	O
For	O
person	Task
ReID	Task
task	Task
,	O
the	O
most	O
important	O
visual	O
cues	O
are	O
visual	O
attribute	O
knowledge	O
,	O
such	O
as	O
clothes	O
color	O
and	O
types	O
.	O
However	O
,	O
they	O
have	O
large	O
variations	O
in	O
scale	O
,	O
shape	O
and	O
position	O
,	O
such	O
as	O
the	O
hat	O
/	O
glasses	O
at	O
small	O
local	O
scale	O
and	O
the	O
cloth	O
color	O
at	O
the	O
larger	O
scale	O
.	O
Directly	O
using	O
bottom	Method
-	Method
to	Method
-	Method
up	Method
single	Method
-	Method
scale	Method
convolution	Method
and	Method
pooling	Method
may	O
not	O
be	O
effective	O
to	O
handle	O
these	O
complex	O
variations	O
.	O
Especially	O
,	O
with	O
the	O
increase	O
number	O
of	O
layers	O
,	O
the	O
small	O
visual	O
regions	O
,	O
such	O
as	O
hat	O
,	O
will	O
be	O
easily	O
missed	O
in	O
top	O
layers	O
.	O
To	O
better	O
learn	O
these	O
diverse	O
visual	O
cues	O
,	O
we	O
propose	O
the	O
Multi	Method
-	Method
scale	Method
Context	Method
-	Method
Aware	Method
Network	Method
.	O
The	O
architecture	O
of	O
the	O
proposed	O
MSCAN	Method
is	O
shown	O
in	O
Tabel	O
[	O
reference	O
]	O
.	O
It	O
has	O
an	O
initial	O
convolution	Method
layer	Method
with	O
kernel	O
size	O
to	O
capture	O
the	O
low	O
-	O
level	O
visual	O
features	O
.	O
Then	O
we	O
use	O
four	O
multi	Method
-	Method
scale	Method
convolution	Method
layers	Method
to	O
obtain	O
the	O
complex	O
image	O
context	O
information	O
.	O
In	O
each	O
multi	Method
-	Method
scale	Method
convolution	Method
layer	Method
,	O
we	O
use	O
a	O
convolution	Method
kernel	Method
with	O
size	O
.	O
To	O
obtain	O
multi	O
-	O
scale	O
receptive	O
fields	O
,	O
we	O
adopt	O
dilated	Method
convolution	Method
for	O
the	O
convolution	Method
filters	Method
.	O
We	O
use	O
three	O
different	O
dilation	O
ratios	O
,	O
i.e.	O
1	O
,	O
2	O
and	O
3	O
,	O
to	O
capture	O
different	O
scale	O
context	O
information	O
.	O
The	O
feature	O
maps	O
from	O
different	O
dilation	O
ratios	O
are	O
concatenated	O
along	O
the	O
channel	O
axis	O
to	O
form	O
the	O
final	O
output	O
of	O
the	O
current	O
convolution	Method
layer	Method
.	O
Thus	O
,	O
the	O
visual	O
context	O
information	O
are	O
enhanced	O
explicitly	O
.	O
To	O
integrate	O
different	O
context	O
information	O
together	O
,	O
the	O
feature	O
maps	O
of	O
current	O
convolution	Method
layer	Method
are	O
embedded	O
through	O
layer	Method
-	Method
by	Method
-	Method
layer	Method
convolution	Method
or	O
FC	Method
operation	Method
.	O
As	O
a	O
result	O
,	O
the	O
visual	O
cues	O
at	O
different	O
scales	O
are	O
fused	O
in	O
a	O
latent	O
way	O
.	O
Besides	O
,	O
we	O
adopt	O
Batch	Method
Normalization	Method
and	O
ReLU	Method
neural	Method
activation	Method
units	Method
after	O
each	O
convolution	Method
layer	Method
.	O
In	O
this	O
paper	O
,	O
we	O
use	O
the	O
dilated	Method
convolutions	Method
with	O
dilation	O
ratios	O
1	O
,	O
2	O
and	O
3	O
instead	O
of	O
the	O
classic	O
convolution	Method
filters	Method
with	O
kernel	O
size	O
,	O
and	O
.	O
The	O
main	O
reason	O
is	O
that	O
the	O
classic	O
convolution	Method
filters	Method
with	O
kernel	O
size	O
,	O
and	O
overlap	O
with	O
each	O
other	O
at	O
the	O
same	O
output	O
position	O
and	O
produce	O
redundant	O
information	O
.	O
To	O
make	O
it	O
clearer	O
,	O
we	O
show	O
the	O
dilated	Method
convolution	Method
kernel	Method
(	O
size	O
)	O
with	O
dilation	O
ratio	O
ranging	O
from	O
to	O
in	O
Figure	O
[	O
reference	O
]	O
.	O
For	O
the	O
same	O
output	O
position	O
which	O
is	O
shown	O
in	O
red	O
circle	O
,	O
the	O
convolution	Method
kernel	Method
with	O
larger	O
dilation	O
ratio	O
has	O
larger	O
receptive	O
field	O
,	O
while	O
only	O
the	O
center	O
position	O
is	O
overlapped	O
with	O
other	O
convolution	Method
kernels	Method
.	O
This	O
can	O
reduce	O
the	O
redundant	O
information	O
among	O
filters	O
with	O
different	O
receptive	O
fields	O
.	O
In	O
summary	O
,	O
as	O
shown	O
in	O
Figure	O
[	O
reference	O
]	O
,	O
we	O
use	O
MSCAN	Method
to	O
learn	O
the	O
multi	Method
-	Method
scale	Method
context	Method
representation	Method
for	O
full	O
body	O
and	O
body	O
parts	O
.	O
In	O
addition	O
,	O
it	O
is	O
also	O
used	O
for	O
feature	Task
learning	Task
in	O
spatial	Task
transformer	Task
networks	Task
mentioned	O
below	O
.	O
subsection	O
:	O
Latent	Task
Part	Task
Localization	Task
Pedestrian	Task
parts	Task
are	O
important	O
in	O
person	O
ReID	Task
.	O
Some	O
existing	O
work	O
has	O
explored	O
rigid	O
body	O
parts	O
to	O
develop	O
robust	O
features	O
.	O
However	O
,	O
due	O
to	O
the	O
unsatisfying	O
pedestrian	Task
detection	Task
algorithms	O
and	O
large	O
pose	O
variations	O
,	O
the	O
method	O
of	O
using	O
rigid	O
body	O
parts	O
for	O
local	Method
feature	Method
learning	Method
is	O
not	O
the	O
optimal	O
solution	O
.	O
As	O
shown	O
in	O
Figure	O
[	O
reference	O
]	O
,	O
when	O
using	O
rigid	O
body	O
parts	O
,	O
the	O
top	O
part	O
consists	O
of	O
large	O
amount	O
of	O
background	O
.	O
This	O
motivates	O
us	O
to	O
learn	O
and	O
localize	O
the	O
pedestrian	O
parts	O
automatically	O
.	O
We	O
integrate	O
STN	Method
as	O
the	O
part	Method
localization	Method
net	Method
in	O
our	O
proposed	O
model	O
.	O
The	O
original	O
STN	Method
is	O
proposed	O
to	O
explicitly	O
learn	O
the	O
image	O
transformation	O
parameters	O
,	O
such	O
as	O
translation	O
and	O
scale	O
.	O
It	O
has	O
two	O
main	O
advantages	O
:	O
(	O
1	O
)	O
it	O
is	O
fully	O
differentiable	O
and	O
can	O
be	O
easily	O
integrated	O
into	O
existing	O
deep	Method
learning	Method
frameworks	Method
,	O
(	O
2	O
)	O
it	O
can	O
learn	O
to	O
translate	O
,	O
scale	O
,	O
crop	O
or	O
warp	O
an	O
interesting	O
region	O
without	O
explicit	O
region	O
annotations	O
.	O
These	O
facts	O
make	O
it	O
very	O
suitable	O
for	O
pedestrian	Task
parts	Task
localization	Task
.	O
STN	Method
includes	O
two	O
components	O
,	O
the	O
spatial	Method
localization	Method
network	Method
to	O
learn	O
the	O
transformation	O
parameters	O
,	O
and	O
the	O
grid	Method
generator	Method
to	O
sample	O
the	O
input	O
image	O
using	O
an	O
image	Method
interpolation	Method
kernel	Method
.	O
More	O
details	O
about	O
STN	Method
can	O
be	O
seen	O
in	O
.	O
In	O
our	O
implementation	O
of	O
STN	Method
,	O
the	O
bilinear	Method
interpolation	Method
kernel	Method
is	O
adopted	O
to	O
sample	O
the	O
input	O
image	O
.	O
And	O
four	O
transformation	O
parameters	O
are	O
used	O
,	O
where	O
and	O
are	O
the	O
horizontal	O
and	O
vertical	O
scale	O
transformation	O
parameters	O
,	O
and	O
and	O
are	O
the	O
horizontal	O
and	O
vertical	O
translation	O
parameters	O
.	O
The	O
image	O
height	O
and	O
width	O
are	O
normalized	O
to	O
be	O
in	O
.	O
Only	O
scale	O
and	O
translation	O
parameters	O
are	O
learned	O
because	O
these	O
two	O
types	O
of	O
transformations	O
serve	O
enough	O
to	O
crop	O
the	O
pedestrian	O
parts	O
effectively	O
.	O
The	O
transformation	O
is	O
applied	O
as	O
an	O
inverse	Task
warping	Task
to	O
generate	O
the	O
output	O
body	O
part	O
regions	O
:	O
where	O
and	O
are	O
the	O
input	O
image	O
coordinates	O
,	O
and	O
are	O
the	O
output	O
part	O
image	O
coordinates	O
,	O
and	O
indexes	O
the	O
pixels	O
in	O
the	O
output	O
body	O
part	O
image	O
.	O
In	O
this	O
paper	O
,	O
we	O
expect	O
STN	Method
to	O
learn	O
three	O
parts	O
corresponding	O
to	O
the	O
head	O
-	O
shoulder	O
,	O
upper	O
body	O
and	O
lower	O
body	O
.	O
Each	O
part	O
is	O
learned	O
by	O
an	O
independent	O
STN	Method
from	O
the	O
original	O
pedestrian	O
image	O
.	O
For	O
the	O
spatial	Task
localization	Task
network	Task
,	O
firstly	O
we	O
use	O
MSCAN	Method
to	O
extract	O
the	O
global	O
image	O
feature	O
maps	O
.	O
Then	O
we	O
learn	O
the	O
high	O
-	O
level	O
abstract	Method
representation	Method
by	O
a	O
128	Method
-	Method
dimension	Method
FC	Method
layer	Method
(	O
FC_loc	Method
in	O
Figure	O
[	O
reference	O
]	O
)	O
.	O
At	O
last	O
,	O
we	O
learn	O
the	O
transformation	O
parameters	O
with	O
a	O
4	Method
-	Method
dimension	Method
FC	Method
layer	Method
based	O
on	O
the	O
FC_loc	Method
.	O
The	O
MSCAN	Method
and	O
FC_loc	Method
are	O
shared	O
among	O
three	O
spatial	Method
localization	Method
networks	Method
.	O
The	O
grid	Method
generator	Method
can	O
crop	O
the	O
learned	O
pedestrian	O
parts	O
based	O
on	O
the	O
learned	O
transformation	O
parameters	O
.	O
In	O
this	O
paper	O
,	O
the	O
resolution	O
of	O
the	O
cropped	O
part	O
image	O
is	O
.	O
For	O
the	O
part	Method
localization	Method
network	Method
,	O
it	O
is	O
hard	O
to	O
learn	O
three	O
groups	O
of	O
parameters	O
for	O
part	Task
localization	Task
.	O
There	O
are	O
three	O
problems	O
.	O
First	O
,	O
the	O
predicted	O
parts	O
from	O
STN	Method
can	O
easily	O
fall	O
into	O
the	O
same	O
region	O
,	O
,	O
the	O
center	O
region	O
of	O
a	O
person	O
,	O
and	O
result	O
in	O
redundance	O
.	O
Second	O
,	O
the	O
scale	O
parameters	O
can	O
easily	O
become	O
negative	O
and	O
the	O
pedestrian	O
part	O
will	O
be	O
mirrored	O
vertically	O
or	O
horizontally	O
or	O
both	O
.	O
This	O
is	O
not	O
consistent	O
with	O
general	O
human	O
cognition	O
.	O
Because	O
few	O
person	O
will	O
stand	O
upside	O
down	O
in	O
surveillance	O
scenes	O
.	O
At	O
last	O
,	O
the	O
cropped	O
parts	O
may	O
fall	O
out	O
of	O
the	O
person	O
image	O
,	O
thus	O
the	O
network	O
would	O
be	O
hard	O
to	O
converge	O
.	O
To	O
solve	O
the	O
above	O
problems	O
,	O
we	O
propose	O
three	O
prior	O
constraints	O
on	O
the	O
transformation	O
parameters	O
in	O
the	O
part	Method
localization	Method
network	Method
.	O
The	O
first	O
constraint	O
is	O
for	O
the	O
positions	O
of	O
predicted	O
parts	O
.	O
We	O
expect	O
the	O
predicted	O
parts	O
to	O
be	O
near	O
the	O
prior	O
center	O
points	O
,	O
so	O
that	O
the	O
learned	O
parts	O
would	O
be	O
complementary	O
to	O
each	O
other	O
.	O
This	O
is	O
termed	O
as	O
the	O
center	O
constraint	O
,	O
which	O
is	O
formalized	O
as	O
follows	O
:	O
where	O
and	O
are	O
prior	O
center	O
points	O
for	O
each	O
part	O
.	O
is	O
the	O
threshold	O
to	O
control	O
the	O
translation	O
between	O
estimated	O
and	O
prior	O
center	O
points	O
.	O
In	O
our	O
experiments	O
,	O
we	O
set	O
the	O
prior	O
center	O
point	O
(	O
)	O
to	O
,	O
,	O
and	O
for	O
each	O
part	O
.	O
The	O
threshold	O
is	O
set	O
to	O
.	O
The	O
second	O
one	O
is	O
the	O
value	O
range	O
constraint	O
on	O
the	O
predicted	O
scale	O
parameter	O
.	O
We	O
hope	O
the	O
scale	O
to	O
be	O
positive	O
,	O
so	O
that	O
the	O
predicted	O
parts	O
have	O
a	O
reasonable	O
extent	O
.	O
The	O
value	O
range	O
constraint	O
on	O
the	O
scale	O
parameter	O
is	O
formalized	O
as	O
follows	O
:	O
where	O
is	O
threshold	O
parameter	O
and	O
is	O
set	O
to	O
0.1	O
in	O
this	O
paper	O
.	O
The	O
last	O
one	O
is	O
to	O
make	O
the	O
localization	Method
network	Method
focus	O
on	O
the	O
inner	O
region	O
of	O
an	O
image	O
.	O
It	O
is	O
formalized	O
as	O
follows	O
:	O
where	O
is	O
the	O
boundary	O
parameter	O
.	O
is	O
set	O
to	O
1.0	O
in	O
our	O
paper	O
,	O
which	O
means	O
the	O
cropped	O
parts	O
should	O
be	O
inside	O
the	O
pedestrian	O
image	O
.	O
Finally	O
the	O
loss	O
for	O
the	O
transformation	O
parameters	O
in	O
the	O
part	Method
localization	Method
network	Method
is	O
described	O
as	O
follows	O
:	O
where	O
and	O
are	O
hyperparameters	O
.	O
The	O
hyperparameters	O
and	O
are	O
both	O
set	O
to	O
1.0	O
in	O
our	O
experiments	O
.	O
subsection	O
:	O
Feature	Task
Extraction	Task
and	O
Fusion	Task
The	O
features	O
of	O
full	O
body	O
and	O
body	O
parts	O
are	O
learned	O
by	O
separate	O
networks	O
and	O
then	O
are	O
fused	O
in	O
a	O
unified	O
framework	O
for	O
multi	Task
-	Task
class	Task
person	Task
identification	Task
tasks	Task
.	O
For	O
the	O
body	Method
-	Method
based	Method
representation	Method
,	O
we	O
use	O
MSCAN	Method
to	O
extract	O
the	O
global	O
feature	O
maps	O
and	O
then	O
learn	O
a	O
128	Method
-	Method
dimension	Method
feature	Method
embedding	Method
(	O
denoted	O
as	O
FC_body	O
in	O
Figure	O
[	O
reference	O
]	O
)	O
.	O
For	O
the	O
part	Method
-	Method
based	Method
representation	Method
,	O
first	O
,	O
for	O
each	O
body	O
part	O
,	O
we	O
use	O
the	O
MSCAN	Method
to	O
extract	O
its	O
feature	O
maps	O
and	O
learn	O
a	O
64	Method
-	Method
dimension	Method
feature	Method
embedding	Method
(	O
denoted	O
as	O
FC_part1	O
,	O
FC_part2	O
,	O
FC_part3	Method
)	O
.	O
Then	O
,	O
we	O
learn	O
a	O
128	O
-	O
dimension	O
feature	O
embedding	O
(	O
denoted	O
as	O
FC_part	Method
)	O
based	O
on	O
features	O
of	O
each	O
body	O
part	O
.	O
The	O
Dropout	Method
is	O
adopted	O
after	O
each	O
FC	Method
layer	Method
to	O
prevent	O
overfitting	O
.	O
At	O
last	O
,	O
the	O
features	O
of	O
global	O
full	O
body	O
and	O
local	O
body	O
parts	O
are	O
concatenated	O
to	O
be	O
a	O
256	O
-	O
dimension	O
feature	O
as	O
the	O
final	O
person	Method
representation	Method
.	O
subsection	O
:	O
Objective	Metric
Function	Metric
In	O
this	O
paper	O
,	O
we	O
adopt	O
the	O
softmax	O
loss	O
as	O
the	O
objective	O
function	O
for	O
multi	Task
-	Task
class	Task
person	Task
identification	Task
tasks	Task
.	O
where	O
is	O
the	O
index	O
of	O
person	O
images	O
,	O
is	O
the	O
feature	O
of	O
-	O
th	O
sample	O
,	O
is	O
the	O
identity	O
of	O
-	O
th	O
sample	O
,	O
is	O
the	O
number	O
of	O
person	O
images	O
,	O
is	O
the	O
number	O
of	O
person	O
identities	O
,	O
is	O
the	O
classifier	Method
for	O
-	O
th	O
identity	O
.	O
For	O
the	O
overall	O
network	Task
training	Task
,	O
we	O
use	O
the	O
classification	Task
and	Task
localization	Task
loss	Task
jointly	O
.	O
The	O
final	O
objective	Metric
function	Metric
is	O
as	O
follows	O
.	O
where	O
the	O
is	O
the	O
hyperparameter	O
,	O
which	O
is	O
set	O
to	O
0.1	O
in	O
our	O
experiments	O
.	O
section	O
:	O
Experiments	O
In	O
this	O
paragraph	O
,	O
the	O
datasets	O
and	O
evaluation	Metric
protocols	Metric
are	O
introduced	O
in	O
Section	O
[	O
reference	O
]	O
.	O
Implementation	O
details	O
are	O
described	O
in	O
Section	O
[	O
reference	O
]	O
.	O
Comparisons	O
with	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
methods	O
are	O
discussed	O
in	O
Section	O
[	O
reference	O
]	O
.	O
The	O
effectiveness	O
of	O
proposed	O
model	O
is	O
analyzed	O
in	O
Section	O
[	O
reference	O
]	O
and	O
Section	O
[	O
reference	O
]	O
.	O
Cross	Metric
-	Metric
dataset	Metric
evaluation	Metric
is	O
described	O
in	O
Section	O
[	O
reference	O
]	O
.	O
subsection	O
:	O
Datasets	O
and	O
Protocols	O
Datasets	O
.	O
In	O
this	O
paper	O
,	O
we	O
evaluate	O
our	O
proposed	O
method	O
on	O
current	O
largest	O
person	O
ReID	Task
datasets	O
,	O
including	O
Market1501	Material
,	O
CUHK03	Material
and	O
MARS	Material
.	O
We	O
do	O
not	O
directly	O
train	O
our	O
model	O
on	O
small	O
datasets	O
,	O
such	O
as	O
VIPeR	Material
.	O
It	O
would	O
be	O
easily	O
overfitting	O
and	O
insufficient	O
to	O
learn	O
such	O
a	O
large	Method
capacity	Method
network	Method
on	O
small	O
datasets	O
from	O
scratch	O
.	O
However	O
,	O
we	O
give	O
some	O
results	O
through	O
fine	O
-	O
tuneing	O
the	O
model	O
from	O
Market1501	Material
to	O
VIPeR	Material
and	O
make	O
cross	Material
-	Material
dataset	Material
ReID	Material
on	O
VIPeR	Material
for	O
generalization	Task
validation	Task
.	O
Related	O
experimental	O
results	O
are	O
discussed	O
in	O
Section	O
[	O
reference	O
]	O
.	O
Market1501	Material
:	O
It	O
contains	O
1	O
,	O
501	O
identities	O
which	O
are	O
captured	O
by	O
six	O
manually	O
set	O
cameras	O
.	O
There	O
are	O
32	O
,	O
368	O
pedestrian	O
images	O
in	O
total	O
.	O
Each	O
person	O
has	O
3.6	O
images	O
on	O
average	O
at	O
each	O
viewpoint	O
.	O
It	O
provides	O
two	O
types	O
of	O
images	O
,	O
including	O
cropped	O
and	O
automatically	O
detected	O
pedestrians	O
by	O
the	O
Deformable	Method
Part	Method
based	Method
Model	Method
(	O
DPM	Method
)	O
.	O
Following	O
,	O
751	O
identities	O
are	O
used	O
for	O
training	O
and	O
the	O
rest	O
750	O
identities	O
are	O
used	O
for	O
testing	O
.	O
CUHK03	Material
:	O
It	O
contains	O
1	O
,	O
360	O
identities	O
which	O
are	O
captured	O
by	O
six	O
surveillance	O
cameras	O
in	O
campus	O
.	O
Each	O
identity	O
is	O
captured	O
by	O
two	O
disjoint	O
cameras	O
.	O
Totally	O
it	O
consists	O
of	O
13	O
,	O
164	O
person	O
images	O
and	O
each	O
identity	O
has	O
about	O
4.8	O
images	O
at	O
each	O
viewpoint	O
.	O
This	O
dataset	O
provides	O
two	O
types	O
of	O
annotations	O
,	O
including	O
manually	O
annotated	O
bounding	O
boxes	O
,	O
and	O
bounding	O
boxes	O
detected	O
using	O
DPM	Method
.	O
We	O
validate	O
our	O
proposed	O
model	O
on	O
both	O
types	O
of	O
data	O
.	O
Following	O
,	O
we	O
use	O
1	O
,	O
260	O
person	O
identities	O
for	O
training	O
and	O
the	O
rest	O
100	O
identities	O
for	O
testing	O
.	O
Experiments	O
are	O
conducted	O
20	O
times	O
and	O
the	O
mean	O
result	O
is	O
reported	O
.	O
MARS	Material
:	O
It	O
is	O
the	O
largest	O
sequence	O
-	O
based	O
person	O
ReID	Task
dataset	O
.	O
It	O
contains	O
1	O
,	O
261	O
identities	O
with	O
each	O
identity	O
captured	O
by	O
at	O
least	O
two	O
cameras	O
.	O
It	O
consists	O
of	O
20	O
,	O
478	O
tracklets	O
and	O
1	O
,	O
191	O
,	O
003	O
bounding	O
boxes	O
.	O
Following	O
,	O
we	O
use	O
625	O
identities	O
for	O
training	O
and	O
the	O
rest	O
631	O
identities	O
for	O
testing	O
.	O
Protocols	O
.	O
Following	O
original	O
evaluation	O
protocols	O
in	O
each	O
dataset	O
,	O
we	O
adopt	O
three	O
evaluation	O
protocols	O
for	O
fair	O
comparison	O
with	O
existing	O
methods	O
.	O
The	O
first	O
one	O
is	O
Cumulated	Method
Matching	Method
Characteristics	Method
(	O
CMC	Method
)	O
which	O
is	O
adopted	O
on	O
the	O
CUHK03	Material
and	O
MARS	Material
datasets	Material
.	O
The	O
second	O
one	O
is	O
Rank	Metric
-	Metric
1	Metric
identification	Metric
rate	Metric
on	O
the	O
Market1501	Material
dataset	O
.	O
The	O
third	O
one	O
is	O
mean	Metric
Average	Metric
Precision	Metric
(	O
mAP	Metric
)	O
on	O
the	O
Market1501	Material
and	O
MARS	Material
datasets	Material
.	O
mAP	Metric
considers	O
both	O
precision	Metric
and	O
recall	Metric
rate	Metric
,	O
which	O
could	O
be	O
complementary	O
to	O
CMC	Method
.	O
subsection	O
:	O
Implementation	O
Details	O
Model	O
:	O
We	O
try	O
to	O
learn	O
the	O
pedestrian	Method
representation	Method
through	O
multi	Task
-	Task
class	Task
person	Task
identification	Task
tasks	Task
using	O
full	O
body	O
and	O
body	O
parts	O
.	O
To	O
evaluate	O
the	O
effectiveness	O
of	O
full	O
body	O
and	O
body	O
parts	O
independently	O
,	O
we	O
extract	O
two	O
sub	Method
-	Method
models	Method
from	O
the	O
whole	O
network	O
of	O
Figure	O
[	O
reference	O
]	O
.	O
The	O
first	O
one	O
only	O
uses	O
the	O
full	O
body	O
to	O
learn	O
the	O
person	Method
representation	Method
with	O
identity	Task
classification	Task
loss	Task
.	O
The	O
second	O
one	O
only	O
uses	O
the	O
parts	O
to	O
learn	O
the	O
person	Method
representation	Method
with	O
identity	Task
classification	Task
and	O
body	Task
parts	Task
localization	Task
loss	Task
.	O
For	O
person	Task
re	Task
-	Task
identification	Task
,	O
we	O
use	O
the	O
L2	Method
normalized	Method
person	Method
representation	Method
and	O
Euclidean	Method
metric	Method
to	O
measure	O
the	O
distance	O
between	O
two	O
pedestrian	O
samples	O
.	O
Optimization	Task
:	O
Our	O
model	O
is	O
implemented	O
based	O
on	O
Caffe	Method
.	O
We	O
use	O
all	O
the	O
available	O
training	O
identities	O
for	O
training	O
and	O
randomly	O
select	O
one	O
sample	O
for	O
each	O
identity	O
for	O
validation	Task
.	O
As	O
the	O
dataset	O
can	O
be	O
quite	O
large	O
,	O
in	O
practice	O
we	O
use	O
a	O
stochastic	Method
approximation	Method
of	Method
the	Method
objective	Method
function	Method
.	O
Training	O
data	O
is	O
randomly	O
divided	O
into	O
mini	O
-	O
batches	O
with	O
a	O
batch	O
size	O
of	O
64	O
.	O
The	O
model	O
performs	O
forward	Method
propagation	Method
on	O
each	O
mini	O
-	O
batch	O
and	O
computes	O
the	O
loss	O
.	O
Backpropagation	Method
is	O
then	O
used	O
to	O
compute	O
the	O
gradients	O
on	O
each	O
mini	O
-	O
batch	O
and	O
the	O
weights	O
are	O
updated	O
with	O
stochastic	Method
gradient	Method
descent	Method
.	O
We	O
start	O
with	O
a	O
base	O
learning	Metric
rate	Metric
of	O
and	O
gradually	O
decrease	O
it	O
after	O
each	O
iterations	O
.	O
It	O
should	O
be	O
noted	O
that	O
the	O
learning	Metric
rate	Metric
of	O
part	Method
localization	Method
network	Method
is	O
1	O
%	O
of	O
that	O
in	O
feature	Method
learning	Method
network	Method
.	O
We	O
use	O
a	O
momentum	O
of	O
and	O
weight	Method
decay	Method
.	O
For	O
overall	O
network	Task
training	Task
,	O
we	O
initialize	O
the	O
network	O
using	O
pretrained	Method
body	Method
-	Method
based	Method
and	Method
part	Method
-	Method
based	Method
model	Method
and	O
then	O
follow	O
the	O
same	O
training	Method
strategy	Method
as	O
described	O
above	O
.	O
We	O
use	O
the	O
model	O
at	O
iterations	O
for	O
testing	O
.	O
Data	Task
Preprocessing	Task
:	O
For	O
each	O
image	O
,	O
we	O
resize	O
it	O
to	O
,	O
subtract	O
the	O
mean	O
value	O
on	O
each	O
channel	O
(	O
B	O
,	O
G	O
and	O
R	O
)	O
,	O
and	O
then	O
normalize	O
it	O
with	O
scale	O
for	O
network	Task
training	Task
.	O
To	O
prevent	O
overfitting	O
,	O
we	O
randomly	O
reflect	O
each	O
image	O
horizontally	O
in	O
the	O
training	O
stage	O
.	O
subsection	O
:	O
Comparison	O
with	O
State	O
-	O
of	O
-	O
the	O
-	O
art	O
Methods	O
Market1501	Material
:	O
For	O
the	O
Market1501	Material
dataset	O
,	O
several	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
methods	O
are	O
compared	O
,	O
including	O
Bag	Method
of	Method
Words	Method
(	O
BOW	Method
)	O
,	O
Weighted	Method
Approximate	Method
Rank	Method
Component	Method
Analysis	Method
(	O
WARCA	Method
)	O
,	O
Discriminative	Method
Null	Method
Space	Method
(	Method
DNS	Method
)	O
,	O
Spatially	Method
Constrained	Method
Similarity	Method
function	Method
on	O
Polynomial	Method
feature	Method
map	Method
(	O
SCSP	Method
)	O
,	O
and	O
deep	Method
learning	Method
based	Method
approaches	Method
,	O
such	O
as	O
PersonNet	Method
,	O
Comparative	Method
Attention	Method
Network	Method
(	O
CAN	Method
)	O
,	O
Siamese	Method
Long	Method
Short	Method
-	Method
Term	Method
Memory	Method
(	Method
S	Method
-	Method
LSTM	Method
)	O
,	O
Gated	Method
Siamese	Method
Convolutional	Method
Neural	Method
Network	Method
(	O
Gate	Method
-	Method
SCNN	Method
)	Method
.	O
The	O
experimental	O
results	O
are	O
shown	O
in	O
Table	O
[	O
reference	O
]	O
.	O
Compared	O
with	O
existing	O
full	Method
body	Method
-	Method
based	Method
convolutional	Method
neural	Method
networks	Method
,	O
such	O
as	O
CAN	Method
and	O
Gate	O
-	O
SCNN	O
,	O
the	O
proposed	O
network	Method
structure	Method
can	O
better	O
capture	O
pedestrian	O
features	O
with	O
multi	Task
-	Task
class	Task
person	Task
identification	Task
tasks	Task
.	O
Our	O
full	Method
-	Method
body	Method
representation	Method
improves	O
Rank	Metric
-	Metric
1	Metric
identification	Metric
rate	Metric
by	O
9.57	O
%	O
on	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
results	O
produced	O
by	O
the	O
Gate	Method
-	Method
CNN	Method
in	O
single	O
query	O
.	O
Compared	O
with	O
the	O
full	O
body	O
,	O
our	O
body	Method
-	Method
part	Method
representation	Method
increase	O
0.80	O
%	O
.	O
The	O
main	O
reason	O
is	O
that	O
the	O
pedestrians	O
detected	O
by	O
DPM	Method
consists	O
much	O
more	O
background	O
information	O
and	O
the	O
part	Method
-	Method
based	Method
representation	Method
can	O
better	O
reduce	O
the	O
influences	O
of	O
background	O
clutter	O
.	O
The	O
full	Method
-	Method
body	Method
and	Method
body	Method
-	Method
part	Method
representations	Method
are	O
complementary	O
to	O
each	O
other	O
.	O
The	O
full	Method
-	Method
body	Method
representation	Method
cares	O
more	O
about	O
the	O
global	O
information	O
,	O
such	O
as	O
the	O
background	O
and	O
body	O
shape	O
.	O
The	O
body	Method
-	Method
part	Method
representation	Method
pays	O
more	O
attention	O
to	O
parts	O
,	O
such	O
as	O
head	O
,	O
upper	O
body	O
and	O
lower	O
body	O
.	O
As	O
shown	O
in	O
Table	O
[	O
reference	O
]	O
,	O
the	O
fusion	Method
model	Method
of	Method
full	Method
body	Method
and	Method
body	Method
parts	Method
improves	O
Rank	Metric
-	Metric
1	Metric
identification	Metric
rate	Metric
by	O
more	O
than	O
4.00	O
%	O
compared	O
with	O
the	O
body	Method
and	Method
parts	Method
-	Method
based	Method
models	Method
separately	O
in	O
single	O
query	O
.	O
The	O
mAP	Metric
improves	O
about	O
17.98	O
%	O
compared	O
with	O
the	O
best	O
result	O
produced	O
by	O
Gate	Method
-	Method
CNN	Method
.	O
CUHK03	Material
:	O
For	O
the	O
CUHK03	Material
dataset	O
,	O
we	O
compare	O
our	O
method	O
with	O
many	O
existing	O
approaches	O
,	O
including	O
Filter	Method
Pair	Method
Neural	Method
Networks	Method
(	O
FPNN	Method
)	O
,	O
Improved	O
Deep	Method
Learning	Method
Architecture	Method
(	O
IDLA	Method
)	O
,	O
Cross	Method
-	Method
view	Method
Quadratic	Method
Discriminant	Method
Analysis	Method
(	O
XQDA	Method
)	O
,	O
PSD	Method
constrained	Method
asymmetric	Method
metric	Method
learning	Method
(	O
denoted	O
as	O
MLAPG	Method
)	O
,	O
Sample	Method
-	Method
Specific	Method
SVM	Method
(	O
SS	Method
)	O
,	O
Single	Method
image	Method
and	Method
Cross	Method
image	Method
representation	Method
(	Method
SI	Method
-	Method
CI	Method
)	O
,	O
Embedding	Method
Deep	Method
Metric	Method
(	O
EDM	Method
)	O
,	O
Domain	Method
Guided	Method
Dropout	Method
(	O
DGD	Method
)	O
,	O
DNS	Method
,	O
S	Method
-	Method
LSTM	Method
and	O
Gate	Method
-	Method
SCNN	Method
.	O
On	O
this	O
dataset	O
,	O
we	O
conduct	O
experiments	O
on	O
both	O
the	O
detected	O
and	O
the	O
labeled	O
datasets	O
.	O
As	O
presented	O
in	O
previous	O
work	O
,	O
we	O
use	O
the	O
CMC	O
curve	O
in	O
the	O
single	Task
shot	Task
case	Task
to	O
evaluate	O
the	O
performance	O
.	O
The	O
overall	O
results	O
are	O
shown	O
in	O
the	O
Table	O
[	O
reference	O
]	O
and	O
Table	O
[	O
reference	O
]	O
.	O
The	O
full	O
CMC	O
curves	O
are	O
shown	O
in	O
supplementary	O
materials	O
.	O
Compared	O
with	O
metric	Method
learning	Method
methods	Method
,	O
such	O
as	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
approach	Method
DNS	Method
,	O
the	O
proposed	O
fusion	Method
model	Method
improves	O
the	O
Rank	Metric
-	Metric
1	Metric
identification	Metric
rate	Metric
by	O
11.66	O
%	O
and	O
13.29	O
%	O
on	O
the	O
labeled	O
and	O
detected	O
datasets	O
respectively	O
.	O
Compared	O
with	O
the	O
similar	O
multi	Method
-	Method
class	Method
person	Method
identification	Method
network	Method
DGD	Method
,	O
the	O
Rank	Metric
-	Metric
1	Metric
identification	Metric
rate	Metric
improves	O
by	O
1.63	O
%	O
using	O
our	O
fusion	Method
model	Method
on	O
the	O
labeled	O
dataset	O
.	O
It	O
should	O
be	O
noted	O
that	O
we	O
only	O
use	O
the	O
labeled	O
sets	O
for	O
training	O
,	O
while	O
the	O
DGD	Method
is	O
trained	O
on	O
both	O
the	O
labeled	O
and	O
detected	O
datasets	O
.	O
This	O
demonstrates	O
the	O
effectiveness	O
of	O
the	O
proposed	O
model	O
.	O
MARS	Material
:	O
This	O
dataset	O
is	O
the	O
largest	O
sequence	O
-	O
based	O
person	O
ReID	Task
dataset	O
.	O
On	O
this	O
dataset	O
,	O
we	O
compare	O
the	O
proposed	O
method	O
with	O
several	O
classical	O
methods	O
,	O
including	O
Keep	O
It	O
as	O
Simple	O
and	O
straightforward	Metric
Metric	Metric
(	O
KISSME	Method
)	Method
,	O
XQDA	Method
,	O
and	O
CaffeNet	Method
.	O
Similar	O
to	O
previous	O
work	O
,	O
both	O
single	O
query	O
and	O
multiple	O
query	O
are	O
evaluated	O
on	O
MARS	Material
.	O
The	O
overall	O
experimental	O
results	O
on	O
the	O
MARS	Material
are	O
shown	O
in	O
Table	O
[	O
reference	O
]	O
and	O
Table	O
[	O
reference	O
]	O
.	O
The	O
full	O
CMC	O
curves	O
are	O
shown	O
in	O
supplementary	O
materials	O
.	O
Compared	O
with	O
CaffeNet	Method
,	O
a	O
similar	O
multi	Method
-	Method
class	Method
person	Method
identification	Method
network	Method
,	O
our	O
body	Method
-	Method
based	Method
model	Method
improves	O
the	O
Rank	Metric
-	Metric
1	Metric
identification	Metric
rate	Metric
by	O
2.93	O
%	O
and	O
mAP	Metric
by	O
4.22	O
%	O
using	O
XQDA	Method
in	O
single	O
query	O
.	O
It	O
should	O
be	O
noticed	O
that	O
our	O
network	O
does	O
not	O
use	O
any	O
pre	Method
-	Method
training	Method
with	O
additional	O
data	O
.	O
Usually	O
deep	Method
learning	Method
network	Method
can	O
obtain	O
better	O
results	O
when	O
pretrained	O
with	O
on	O
ImageNet	Task
classification	Task
task	Task
.	O
Our	O
fusion	Method
model	Method
improves	O
Rank	Metric
-	Metric
1	Metric
identification	Metric
rate	Metric
and	O
mAP	Metric
by	O
6.47	O
%	O
and	O
by	O
8.45	O
%	O
in	O
single	O
query	O
.	O
This	O
illustrates	O
the	O
effectiveness	O
of	O
our	O
model	O
.	O
subsection	O
:	O
Effectiveness	O
of	O
MSCAN	Method
To	O
determine	O
the	O
effectiveness	O
of	O
MSCAN	Method
,	O
we	O
explore	O
four	O
variants	O
of	O
MSCANs	Method
to	O
learn	O
IDE	O
feature	O
based	O
on	O
the	O
whole	O
body	O
image	O
,	O
which	O
is	O
denoted	O
as	O
MSCAN	Method
-	O
,	O
.	O
is	O
the	O
number	O
of	O
dilation	O
ratios	O
.	O
For	O
example	O
,	O
MSCAN	Method
-	O
means	O
for	O
each	O
convolution	Method
layer	Method
in	O
Conv1	Method
-	Method
Conv4	Method
,	O
there	O
are	O
three	O
convolution	Method
kernels	Method
with	O
dilation	O
ratio	O
1	O
,	O
2	O
,	O
and	O
3	O
respectively	O
.	O
With	O
the	O
increase	O
of	O
,	O
the	O
MSCAN	Method
captures	O
larger	O
context	O
information	O
at	O
the	O
same	O
convolution	Method
layer	Method
.	O
The	O
experimental	O
results	O
based	O
on	O
these	O
four	O
types	O
of	O
MSCANs	Method
on	O
the	O
Market1501	Material
dataset	O
are	O
shown	O
in	O
Table	O
[	O
reference	O
]	O
.	O
As	O
we	O
can	O
see	O
,	O
with	O
the	O
increase	O
of	O
the	O
number	O
of	O
dilation	Metric
ratios	Metric
,	O
the	O
Rank	Metric
-	Metric
1	Metric
identification	Metric
rate	Metric
and	O
mAP	Metric
improve	O
stably	O
in	O
single	Task
query	Task
case	Task
.	O
For	O
multiple	Task
query	Task
case	Task
,	O
which	O
means	O
fusing	O
all	O
images	O
belonging	O
to	O
the	O
same	O
query	O
person	O
at	O
the	O
same	O
camera	O
through	O
average	O
pooling	O
in	O
feature	O
space	O
,	O
the	O
Rank	Metric
-	Metric
1	Metric
identification	Metric
rate	Metric
and	O
mAP	Metric
also	O
improves	O
step	O
by	O
step	O
.	O
However	O
,	O
the	O
Rank	Metric
-	Metric
1	Metric
identification	Metric
rate	Metric
and	O
mAP	Metric
increase	O
not	O
much	O
when	O
increase	O
from	O
3	O
to	O
4	O
.	O
We	O
think	O
there	O
is	O
a	O
suitable	O
number	O
of	O
dilation	O
ratios	O
for	O
feature	Task
learning	Task
.	O
Considering	O
the	O
model	Metric
complexity	Metric
and	O
accuracy	Metric
improvements	O
in	O
Rank	Metric
-	Metric
1	Metric
identification	Metric
rate	Metric
,	O
we	O
adopt	O
the	O
MSCAN	Method
-	O
3	O
as	O
our	O
final	O
MSCAN	Method
model	O
in	O
this	O
paper	O
.	O
subsection	O
:	O
Effectiveness	O
of	O
Latent	Method
Part	Method
Localization	Method
Learned	O
parts	O
parts	O
To	O
compare	O
with	O
popular	O
rigid	O
pedestrian	O
parts	O
,	O
we	O
divide	O
the	O
pedestrian	O
into	O
three	O
overlapped	O
regions	O
as	O
predefined	O
rigid	O
parts	O
.	O
We	O
use	O
the	O
rigid	O
body	O
parts	O
instead	O
of	O
the	O
learned	O
latent	O
body	O
parts	O
for	O
part	Task
-	Task
based	Task
feature	Task
learning	Task
.	O
Experimental	O
results	O
with	O
rigid	O
and	O
learned	O
body	O
parts	O
are	O
shown	O
in	O
Table	O
[	O
reference	O
]	O
.	O
Compared	O
with	O
rigid	O
body	O
parts	O
,	O
the	O
learned	O
body	O
parts	O
improve	O
Rank	Metric
-	Metric
1	Metric
identification	Metric
rate	Metric
and	O
mAP	Metric
by	O
3.27	O
%	O
and	O
3.73	O
%	O
in	O
single	O
query	O
,	O
and	O
by	O
1.70	O
%	O
and	O
by	O
2.67	O
%	O
in	O
multiple	O
query	O
.	O
This	O
validate	O
the	O
effectiveness	O
of	O
learned	O
person	Method
parts	Method
.	O
For	O
better	O
understanding	O
the	O
learned	O
pedestrian	O
parts	O
,	O
we	O
visualize	O
the	O
localized	O
latent	O
parts	O
in	O
Figure	O
[	O
reference	O
]	O
using	O
our	O
fusion	Method
model	Method
.	O
For	O
these	O
detected	O
person	O
with	O
large	O
background	O
(	O
the	O
first	O
row	O
in	O
Figure	O
[	O
reference	O
]	O
)	O
,	O
the	O
proposed	O
model	O
can	O
learn	O
foreground	O
information	O
with	O
complementary	O
latent	O
pedestrian	O
parts	O
.	O
As	O
we	O
can	O
see	O
,	O
the	O
learned	O
parts	O
consist	O
of	O
three	O
main	O
components	O
,	O
including	O
upper	O
body	O
,	O
middle	O
body	O
(	O
combination	O
of	O
upper	O
body	O
and	O
lower	O
body	O
)	O
,	O
and	O
lower	O
body	O
.	O
Similar	O
results	O
can	O
be	O
achieved	O
when	O
original	O
detection	O
pedestrians	O
contain	O
less	O
background	O
or	O
occlusion	O
(	O
the	O
second	O
row	O
in	O
Figure	O
[	O
reference	O
]	O
)	O
.	O
It	O
is	O
easy	O
to	O
see	O
that	O
,	O
the	O
automatically	O
learned	O
pedestrian	O
parts	O
are	O
not	O
strictly	O
head	O
-	O
shoulder	O
,	O
upper	O
body	O
and	O
lower	O
-	O
body	O
.	O
But	O
it	O
indeed	O
consists	O
of	O
these	O
three	O
parts	O
with	O
large	O
overlap	O
.	O
Compared	O
with	O
rigid	O
parts	O
,	O
the	O
proposed	O
model	O
can	O
automatically	O
localize	O
the	O
appropriate	O
latent	O
parts	O
for	O
feature	Task
learning	Task
.	O
Effectiveness	O
of	O
localization	Metric
loss	Metric
To	O
evaluate	O
the	O
effectiveness	O
of	O
the	O
proposed	O
constraints	O
on	O
the	O
latent	Method
part	Method
localization	Method
network	Method
,	O
we	O
conduct	O
additional	O
experiments	O
by	O
adding	O
or	O
deleting	O
proposed	O
in	O
the	O
training	O
stage	O
of	O
body	Method
parts	Method
network	Method
for	O
ReID	Task
.	O
Experimental	O
results	O
are	O
shown	O
in	O
Table	O
[	O
reference	O
]	O
.	O
As	O
we	O
can	O
see	O
,	O
with	O
the	O
additional	O
,	O
the	O
Rank	Metric
-	Metric
1	Metric
accuracy	Metric
increases	O
by	O
9.03	O
%	O
.	O
We	O
owe	O
the	O
improvements	O
to	O
the	O
effectiveness	O
of	O
the	O
proposed	O
constraints	O
on	O
the	O
part	Task
localization	Task
network	Task
.	O
subsection	O
:	O
Cross	Metric
-	Metric
dataset	Metric
Evaluation	Metric
Similar	O
with	O
typical	O
image	Task
classification	Task
task	Task
with	O
CNN	Method
,	O
our	O
approach	O
requires	O
large	O
scale	O
of	O
data	O
,	O
not	O
only	O
more	O
identities	O
,	O
but	O
also	O
more	O
instances	O
for	O
each	O
identity	O
.	O
So	O
we	O
do	O
not	O
train	O
the	O
proposed	O
model	O
on	O
each	O
single	O
small	O
person	O
ReID	Task
dataset	O
,	O
such	O
as	O
VIPeR.	Material
Instead	O
,	O
we	O
conduct	O
cross	Metric
-	Metric
dataset	Metric
evaluation	Metric
from	O
the	O
pretrained	Method
model	Method
on	O
the	O
Market1501	Material
,	O
CUHK03	Material
and	O
MARS	Material
datasets	O
to	O
the	O
VIPeR	Material
dataset	O
.	O
The	O
experimental	O
results	O
are	O
shown	O
in	O
Table	O
[	O
reference	O
]	O
.	O
Compared	O
with	O
other	O
methods	O
,	O
such	O
as	O
Domain	Method
Transfer	Method
Rank	Method
Support	Method
Vector	Method
Machines	Method
and	O
DML	Method
,	O
the	O
models	O
trained	O
on	O
large	O
-	O
scale	O
datasets	O
have	O
better	O
generalization	Metric
ability	Metric
and	O
have	O
better	O
Rank	Metric
-	Metric
1	Metric
identification	Metric
rate	Metric
.	O
To	O
take	O
further	O
analysis	O
of	O
the	O
proposed	O
method	O
,	O
we	O
also	O
fine	O
-	O
tune	O
the	O
model	O
from	O
large	O
dataset	O
Market1501	Material
to	O
small	O
dataset	O
VIPeR.	O
Experimental	O
results	O
are	O
shown	O
in	O
Table	O
[	O
reference	O
]	O
.	O
Our	O
fusion	Method
-	Method
based	Method
model	Method
obtains	O
better	O
Rank	Metric
-	Metric
1	Metric
identification	Metric
rate	Metric
than	O
existing	O
deep	Method
models	Method
,	O
IDLA	Method
(	O
34.8	O
%	O
)	O
,	O
Gate	Method
-	Method
SCNN	Method
(	O
37.8	O
%	O
)	O
,	O
SI	Method
-	Method
CI	Method
(	O
35.8	O
%	O
)	O
,	O
and	O
achieves	O
comparable	O
results	O
with	O
DGD	Method
(	O
38.6	O
%	O
)	O
.	O
section	O
:	O
Conclusion	O
In	O
this	O
work	O
,	O
we	O
have	O
studied	O
the	O
problem	O
of	O
person	O
ReID	Task
in	O
three	O
levels	O
:	O
1	O
)	O
a	O
multi	Method
-	Method
scale	Method
context	Method
-	Method
aware	Method
network	Method
to	O
capture	O
the	O
context	O
knowledge	O
for	O
pedestrian	Task
feature	Task
learning	Task
,	O
2	O
)	O
three	O
novel	O
constraints	O
on	O
STN	Method
for	O
effective	O
latent	Task
parts	Task
localization	Task
and	O
body	Task
-	Task
part	Task
feature	Task
representation	Task
,	O
3	O
)	O
the	O
fusion	Method
of	Method
full	Method
-	Method
body	Method
and	Method
body	Method
-	Method
part	Method
identity	Method
discriminative	Method
features	Method
for	O
powerful	O
pedestrian	Task
representation	Task
.	O
We	O
have	O
validated	O
the	O
effectiveness	O
of	O
the	O
proposed	O
method	O
on	O
current	O
large	O
-	O
scale	O
person	O
ReID	Task
datasets	O
.	O
Experimental	O
results	O
have	O
demonstrated	O
that	O
the	O
proposed	O
method	O
achieves	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
results	O
.	O
Acknowledgement	O
This	O
work	O
is	O
funded	O
by	O
the	O
National	O
Key	O
Research	O
and	O
Development	O
Program	O
of	O
China	O
(	O
2016YFB1001005	O
)	O
,	O
the	O
National	O
Natural	O
Science	O
Foundation	O
of	O
China	O
(	O
Grant	O
No	O
.	O
61673375	O
,	O
Grant	O
No	O
.	O
61403383	O
and	O
Grant	O
No	O
.	O
61473290	O
)	O
,	O
and	O
the	O
Projects	O
of	O
Chinese	O
Academy	O
of	O
Science	O
(	O
Grant	O
No	O
.	O
QYZDB	O
-	O
SSW	O
-	O
JSC006	O
,	O
Grant	O
No	O
.	O
173211KYSB20160008	O
)	O
.	O
bibliography	O
:	O
References	O
