document O
: O
CNN Task
Image Task
Retrieval Task
Learns O
from O
BoW Method
: O
Unsupervised Task
Fine Task
- Task
Tuning Task
with O
Hard O
Examples O
Convolutional Method
Neural Method
Networks Method
( O
CNNs Method
) O
achieve O
state O
- O
of O
- O
the O
- O
art O
performance O
in O
many O
computer Task
vision Task
tasks Task
. O
However O
, O
this O
achievement O
is O
preceded O
by O
extreme O
manual Task
annotation Task
in O
order O
to O
perform O
either O
training O
from O
scratch O
or O
fine Task
- Task
tuning Task
for O
the O
target O
task O
. O
In O
this O
work O
, O
we O
propose O
to O
fine O
- O
tune O
CNN Method
for O
image Task
retrieval Task
from O
a O
large O
collection O
of O
unordered O
images O
in O
a O
fully O
automated O
manner O
. O
We O
employ O
state O
- O
of O
- O
the O
- O
art O
retrieval Method
and O
Structure Method
- Method
from Method
- Method
Motion Method
( O
SfM Method
) O
methods O
to O
obtain O
3D Method
models Method
, O
which O
are O
used O
to O
guide O
the O
selection O
of O
the O
training O
data O
for O
CNN Task
fine Task
- Task
tuning Task
. O
We O
show O
that O
both O
hard O
positive O
and O
hard O
negative O
examples O
enhance O
the O
final O
performance O
in O
particular O
object Task
retrieval Task
with O
compact Method
codes Method
. O
+ O
section O
: O
Introduction O
Image Task
retrieval Task
has O
received O
a O
lot O
of O
attention O
since O
the O
advent O
of O
invariant O
local O
features O
, O
such O
as O
SIFT Method
, O
and O
since O
the O
seminal O
work O
of O
Sivic O
and O
Zisserman O
based O
on O
Bag Method
- Method
of Method
- Method
Words Method
( O
BoW Method
) O
. O
Retrieval Method
systems Method
have O
reached O
a O
higher O
level O
of O
maturity O
by O
incorporating O
large O
visual O
codebooks O
, O
spatial Task
verification Task
and O
query Method
expansion Method
. O
These O
ingredients O
constitute O
the O
state O
of O
the O
art O
on O
particular Task
object Task
retrieval Task
. O
Another O
line O
of O
research O
focuses O
on O
compact Task
image Task
representations Task
in O
order O
to O
decrease O
memory Metric
requirements Metric
and O
increase O
the O
search Metric
efficiency Metric
. O
Representative O
approaches O
are O
Fisher Method
vectors Method
, O
VLAD Method
and O
alternatives O
. O
Recent O
advances O
show O
that O
Convolutional Method
Neural Method
Networks Method
( O
CNN Method
) Method
offer O
an O
attractive O
alternative O
for O
image Task
search Task
representations Task
with O
small O
memory O
footprint O
. O
CNNs Method
attracted O
a O
lot O
of O
attention O
after O
the O
work O
of O
Krizhevsky O
et O
al O
. O
. O
Their O
success O
is O
mainly O
due O
to O
the O
computational O
power O
of O
GPUs Method
and O
the O
use O
of O
very O
large O
annotated O
datasets O
. O
Generation Task
of O
the O
latter O
comes O
at O
the O
expense O
of O
costly O
manual Task
annotation Task
. O
Using O
CNN Method
layer Method
activations Method
as O
off O
- O
the O
- O
shelf O
image Method
descriptors Method
appears O
very O
effective O
and O
is O
adopted O
in O
many O
tasks O
. O
In O
particular O
for O
image Task
retrieval Task
, O
Babenko O
et O
al O
. O
and O
Gong O
et O
al O
. O
concurrently O
propose O
the O
use O
of O
Fully Method
Connected Method
( O
FC Method
) O
layer O
activations O
as O
descriptors O
, O
while O
convolutional Method
layer Method
activations Method
are O
later O
shown O
to O
have O
superior O
performance O
. O
Generalization Task
to O
other O
tasks O
is O
attained O
by O
CNN Method
activations Method
, O
at O
least O
up O
to O
some O
extent O
. O
However O
, O
initialization O
by O
a O
pre Method
- Method
trained Method
network Method
and O
re O
- O
training O
for O
another O
task O
, O
a O
process O
called O
fine Task
- Task
tuning Task
, O
significantly O
improves O
the O
adaptation Metric
ability Metric
. O
Fine Task
- Task
tuning Task
by O
training O
with O
classes O
of O
particular O
objects O
, O
e.g. O
building O
classes O
in O
the O
work O
of O
Babenko O
et O
al O
. O
, O
is O
known O
to O
improve O
retrieval Metric
accuracy Metric
. O
This O
formulation O
is O
much O
closer O
to O
classification Task
than O
to O
the O
desired O
properties O
of O
instance Task
retrieval Task
. O
Typical O
architectures O
for O
metric Task
learning Task
, O
such O
as O
siamese Method
or Method
triplet Method
networks Method
employ O
matching O
and O
non O
- O
matching O
pairs O
to O
perform O
the O
training O
and O
better O
suit O
to O
this O
task O
. O
In O
this O
fashion O
, O
Arandjelovic O
et O
al O
. O
perform O
fine Task
- Task
tuning Task
based O
on O
geo O
- O
tagged O
databases O
and O
, O
similar O
to O
our O
work O
, O
they O
directly O
optimize O
the O
the O
similarity Metric
measure Metric
to O
be O
used O
in O
the O
final O
task O
. O
In O
contrast O
to O
them O
, O
we O
dispense O
with O
the O
need O
of O
annotated O
data O
or O
any O
assumptions O
on O
the O
training O
dataset O
. O
A O
concurrent O
work O
bears O
resemblance O
to O
ours O
but O
their O
focus O
is O
on O
boosting O
performance O
through O
end O
- O
to O
- O
end Task
learning Task
of O
a O
more O
sophisticated O
representation O
, O
while O
we O
target O
to O
reveal O
the O
importance O
of O
hard O
examples O
and O
of O
training O
data O
variation O
. O
A O
number O
of O
image Method
clustering Method
methods Method
based O
on O
local O
features O
have O
been O
introduced O
. O
Due O
to O
the O
spatial Task
verification Task
, O
the O
clusters O
discovered O
by O
these O
methods O
are O
reliable O
. O
In O
fact O
, O
the O
methods O
provide O
not O
only O
clusters O
, O
but O
also O
a O
matching O
graph O
or O
sub Method
- Method
graph Method
on O
the O
cluster O
images O
. O
These O
graphs O
are O
further O
used O
as O
an O
input O
to O
a O
Structure Method
- Method
from Method
- Method
Motion Method
( O
SfM Method
) O
pipeline O
to O
build O
a O
3D Method
model Method
. O
The O
SfM Method
filters O
out O
virtually O
all O
mismatched O
images O
, O
and O
also O
provides O
camera O
positions O
for O
all O
matched O
images O
in O
the O
cluster O
. O
The O
whole O
process O
from O
unordered O
collection O
of O
images O
to O
3D Task
reconstructions Task
is O
fully O
automatic O
. O
In O
this O
paper O
, O
we O
address O
an O
unsupervised Task
fine Task
- Task
tuning Task
of Task
CNN Task
for O
image Task
retrieval Task
. O
We O
propose O
to O
exploit O
3D Method
reconstructions Method
to O
select O
the O
training O
data O
for O
CNN Task
. O
We O
show O
that O
compared O
to O
previous O
supervised Method
approaches Method
, O
the O
variability O
in O
the O
training O
data O
from O
3D Method
reconstructions Method
delivers O
superior O
performance O
in O
the O
image Task
retrieval Task
task O
. O
During O
the O
training O
process O
the O
CNN Method
is O
trained O
to O
learn O
what O
a O
state O
- O
of O
- O
the O
- O
art O
retrieval Method
system Method
based O
on O
local O
features O
and O
spatial Task
verification Task
would O
match O
. O
Such O
a O
system O
has O
large O
memory Metric
requirements Metric
and O
high O
query Metric
times Metric
, O
while O
our O
goal O
is O
to O
mimic O
this O
via O
CNN Method
- Method
based Method
representation Method
. O
We O
derive O
a O
short Method
image Method
representation Method
and O
achieve O
similar O
performance O
to O
such O
state O
- O
of O
- O
the O
- O
art O
systems O
. O
In O
particular O
we O
make O
the O
following O
contributions O
. O
( O
1 O
) O
We O
exploit O
SfM Method
information O
and O
enforce O
not O
only O
hard O
non O
- O
matching O
( O
negative O
) O
but O
also O
hard O
matching O
( O
positive O
) O
examples O
to O
be O
learned O
by O
the O
CNN Method
. O
This O
is O
shown O
to O
enhance O
the O
derived O
image Method
representation Method
. O
( O
2 O
) O
We O
show O
that O
the O
whitening Method
traditionally Method
performed O
on O
short Task
representations Task
is O
, O
in O
some O
cases O
, O
unstable O
and O
we O
rather O
propose O
to O
learn O
the O
whitening Method
through O
the O
same O
training O
data O
. O
Its O
effect O
is O
complementary O
to O
fine Task
- Task
tuning Task
and O
it O
further O
boosts O
performance O
. O
( O
3 O
) O
Finally O
, O
we O
set O
a O
new O
state O
- O
of O
- O
the O
- O
art O
based O
on O
compact Method
representations Method
for O
Oxford Material
Buildings Material
and O
Paris Material
datasets Material
by O
re O
- O
training O
well O
known O
CNNs Method
, O
such O
as O
AlexNet Method
and O
VGG Method
. O
Remarkably O
, O
we O
are O
on O
par O
with O
existing O
256D Method
compact Method
representations Method
even O
by O
using O
32D O
image O
vectors O
. O
section O
: O
Related O
work O
A O
variety O
of O
previous O
methods O
apply O
CNN Method
activations Method
on O
the O
task O
of O
image Task
retrieval Task
. O
The O
achieved O
accuracy Metric
on O
retrieval Task
is O
evidence O
for O
the O
generalization Method
properties Method
of O
CNNs Method
. O
The O
employed O
networks O
were O
trained O
for O
image Task
classification Task
using O
ImageNet O
dataset O
, O
optimizing O
classification Metric
error Metric
. O
Babenko O
et O
al O
. O
go O
one O
step O
further O
and O
re O
- O
train O
such O
networks O
with O
a O
dataset O
that O
is O
closer O
to O
the O
target O
task O
. O
They O
perform O
training O
with O
object O
classes O
that O
correspond O
to O
particular O
landmarks O
/ O
buildings O
. O
Performance O
is O
improved O
on O
standard O
retrieval Metric
benchmarks Metric
. O
Despite O
the O
achievement O
, O
still O
, O
the O
final O
metric O
and O
utilized O
layers O
are O
different O
to O
the O
ones O
actually O
optimized O
during O
learning Task
. O
Constructing O
such O
training O
datasets O
requires O
manual O
effort O
. O
The O
same O
stands O
for O
attempts O
on O
different O
tasks O
that O
perform O
fine Task
- Task
tuning Task
and O
achieve O
increase O
of O
performance O
. O
In O
a O
recent O
work O
, O
geo O
- O
tagged O
datasets O
with O
timestamps O
offer O
the O
ground O
for O
weakly Task
supervised Task
fine Task
- Task
tuning Task
of Task
a Task
triplet Task
network Task
. O
Two O
images O
taken O
far O
from O
each O
other O
can O
be O
easily O
considered O
as O
non O
- O
matching Task
, O
while O
matching O
examples O
are O
picked O
by O
the O
most O
similar O
nearby O
images O
. O
In O
the O
latter O
case O
, O
similarity O
is O
defined O
by O
the O
current O
representation Method
of Method
the Method
CNN Method
. O
This O
is O
the O
first O
approach O
that O
performs O
end O
- O
to O
- O
end Task
fine Task
- Task
tuning Task
for O
image Task
retrieval Task
and O
in O
particular O
for O
the O
task O
of O
geo Task
- Task
localization Task
. O
The O
employed O
training O
data O
are O
now O
much O
closer O
to O
the O
final O
task O
. O
We O
differentiate O
by O
discovering Task
matching Task
and Task
non Task
- Task
matching Task
image Task
pairs Task
in O
an O
unsupervised O
way O
. O
Moreover O
, O
we O
derive O
matching O
examples O
based O
on O
3D Method
reconstruction Method
which O
allows O
for O
harder O
examples O
, O
compared O
to O
the O
ones O
that O
the O
current O
network O
identifies O
. O
Even O
though O
hard Task
negative Task
mining Task
is O
a O
standard O
process O
, O
this O
is O
not O
the O
case O
with O
hard O
positive O
examples O
. O
Large O
intra Task
- Task
class Task
variation Task
in O
classification Task
tasks Task
requires O
the O
positive O
pairs O
to O
be O
sampled O
carefully O
; O
forcing O
the O
model O
to O
learn O
extremely O
hard O
positives O
may O
result O
in O
over O
- O
fitting O
. O
Another O
exception O
is O
the O
work O
Simo O
- O
Serra O
et O
al O
. O
where O
they O
mine O
hard O
positive O
patches O
for O
descriptor Task
learning Task
. O
They O
are O
also O
guided O
by O
3D Method
reconstruction Method
but O
only O
at O
patch O
level O
. O
Despite O
the O
fact O
that O
one O
of O
the O
recent O
advances O
is O
the O
triplet Method
loss Method
, O
note O
that O
also O
Arandjelovic O
et O
al O
. O
use O
it O
, O
there O
are O
no O
extenstive O
and O
direct O
comparisons O
to O
siamese Method
networks Method
and O
the O
contrastive Method
loss Method
. O
One O
exception O
is O
the O
work O
of O
Hoffer O
and O
Ailon O
, O
where O
triplet Method
loss Method
is O
shown O
to O
be O
marginally O
better O
only O
on O
MNIST O
dataset O
. O
We O
rather O
employ O
a O
siamese Method
architecture Method
with O
the O
contrastive Method
loss Method
and O
find O
it O
to O
generalize O
better O
and O
to O
converge O
at O
higher O
performance O
than O
the O
triplet Metric
loss Metric
. O
section O
: O
Network Method
architecture Method
and O
image Task
representation Task
In O
this O
section O
we O
describe O
the O
derived O
image Method
representation Method
that O
is O
based O
on O
CNN Method
and O
we O
present O
the O
network Method
architecture Method
used O
to O
perform O
the O
end Task
- Task
to Task
- Task
end Task
learning Task
in O
a O
siamese Method
fashion Method
. O
Finally O
, O
we O
describe O
how O
, O
after O
fine Task
- Task
tuning Task
, O
we O
use O
the O
same O
training O
data O
to O
learn O
projections O
that O
appear O
to O
be O
an O
effective O
post Task
- Task
processing Task
step Task
. O
subsection O
: O
Image Method
representation Method
We O
adopt O
a O
compact Method
representation Method
that O
is O
derived O
from O
activations Method
of Method
convolutional Method
layers Method
and O
is O
shown O
to O
be O
effective O
for O
particular O
object Task
retrieval Task
. O
We O
assume O
that O
a O
network O
is O
fully O
convolutional O
or O
that O
all O
fully O
connected O
layers O
are O
discarded O
. O
Now O
, O
given O
an O
input O
image O
, O
the O
output O
is O
a O
3D O
tensor O
of O
dimensions O
, O
where O
is O
the O
number O
of O
feature O
maps O
in O
the O
last O
layer O
. O
Let O
be O
the O
set O
of O
all O
activations O
for O
feature O
map O
} O
. O
The O
network O
output O
consists O
of O
such O
sets O
of O
activations O
. O
The O
image Method
representation Method
, O
called O
Maximum Method
Activations Method
of Method
Convolutions Method
( O
MAC Method
) O
, O
is O
simply O
constructed O
by O
max Method
- Method
pooling Method
over O
all O
dimensions O
per O
feature O
map O
and O
is O
given O
by O
The O
indicator O
function O
takes O
care O
that O
the O
feature O
vector O
is O
non O
- O
negative O
, O
as O
if O
the O
last O
network Method
layer Method
was O
a O
Rectified Method
Linear Method
Unit Method
( O
ReLU Method
) O
. O
The O
feature O
vector O
finally O
consists O
of O
the O
maximum O
activation O
per O
feature O
map O
and O
its O
dimensionality O
is O
equal O
to O
. O
For O
many O
popular O
networks O
this O
is O
equal O
to O
256 O
or O
512 O
, O
which O
makes O
it O
a O
compact O
image Method
representation Method
. O
MAC Method
vectors O
are O
subsequently O
- O
normalized O
and O
similarity O
between O
two O
images O
is O
evaluated O
with O
inner Method
product Method
. O
The O
contribution O
of O
a O
feature O
map O
to O
the O
image Task
similarity Task
is O
measured O
by O
the O
product O
of O
the O
corresponding O
MAC Method
vector O
components O
. O
In O
Figure O
[ O
reference O
] O
we O
show O
the O
image O
patches O
in O
correspondence O
that O
contribute O
most O
to O
the O
similarity O
. O
Such O
implicit O
correspondences O
are O
improved O
after O
fine Method
- Method
tuning Method
. O
Moreover O
, O
the O
CNN Method
fires O
less O
to O
ImageNet O
classes O
, O
e.g. O
cars O
and O
bicycles O
. O
subsection O
: O
Network Method
and Method
siamese Method
learning Method
The O
proposed O
approach O
is O
applicable O
to O
any O
CNN Method
that O
consists O
of O
only O
convolutional Method
layers Method
. O
In O
this O
paper O
, O
we O
focus O
on O
re Task
- Task
training Task
( O
i.e. Task
fine Task
- Task
tuning Task
) O
state O
- O
of O
- O
the O
- O
art O
CNNs Method
for O
classification Task
, O
in O
particular O
AlexNet Method
and O
VGG Method
. O
Fully O
connected O
layers O
are O
discarded O
and O
the O
pre O
- O
trained Method
networks Method
constitute O
the O
initialization O
for O
our O
convolutional Method
layers Method
. O
Now O
, O
the O
last O
convolutional Method
layer Method
is O
followed O
by O
a O
MAC Method
layer O
that O
performs O
MAC Method
vector O
computation O
( O
[ O
reference O
] O
) O
. O
The O
input O
of O
a O
MAC Method
layer O
is O
a O
3D O
tensor O
of O
activation O
and O
the O
output O
is O
a O
non O
- O
negative O
vector O
. O
Then O
, O
an O
- Method
normalization Method
block Method
takes O
care O
that O
output O
vectors O
are O
normalized O
. O
In O
the O
rest O
of O
the O
paper O
, O
MAC Method
corresponds O
to O
the O
- O
normalized O
vector O
. O
We O
adopt O
a O
siamese Method
architecture Method
and O
train O
a O
two Method
branch Method
network Method
. O
Each O
branch O
is O
a O
clone O
of O
the O
other O
, O
meaning O
that O
they O
share O
the O
same O
parameters O
. O
Training O
input O
consists O
of O
image O
pairs O
and O
labels O
declaring O
whether O
a O
pair O
is O
non O
- O
matching O
( O
label O
0 O
) O
or O
matching O
( O
label O
1 O
) O
. O
We O
employ O
the O
contrastive Method
loss Method
that O
acts O
on O
the O
( O
non O
-) O
matching O
pairs O
and O
is O
defined O
as O
where O
is O
the O
- O
normalized O
MAC Method
vector O
of O
image O
, O
and O
is O
a O
parameter O
defining O
when O
non O
- O
matching O
pairs O
have O
large O
enough O
distance O
in O
order O
not O
to O
be O
taken O
into O
account O
in O
the O
loss O
. O
We O
train O
the O
network O
using O
Stochastic Method
Gradient Method
Descent Method
( O
SGD Method
) O
and O
a O
large O
training O
set O
created O
automatically O
( O
see O
Section O
[ O
reference O
] O
) O
. O
subsection O
: O
Whitening Task
and O
dimensionality Task
reduction Task
In O
this O
section O
, O
the O
post O
- O
processing O
of O
fine O
- O
tuned O
MAC Method
vectors O
is O
considered O
. O
Previous O
methods O
use O
PCA Method
of O
an O
independent O
set O
for O
whitening Task
and O
dimensionality Task
reduction Task
, O
that O
is O
the O
covariance O
matrix O
of O
all O
descriptors O
is O
analyzed O
. O
We O
propose O
to O
take O
advantage O
of O
the O
labeled O
data O
provided O
by O
the O
3D Method
models Method
and O
use O
linear Method
discriminant Method
projections Method
originally O
proposed O
by O
Mikolajczyk O
and O
Matas O
. O
The O
projection O
is O
decomposed O
into O
two O
parts O
, O
whitening O
and O
rotation O
. O
The O
whitening Method
part Method
is O
the O
inverse O
of O
the O
square O
- O
root O
of O
the O
intraclass O
( O
matching O
pairs O
) O
covariance O
matrix O
, O
where O
The O
rotation Method
part Method
is O
the O
PCA Method
of O
the O
interclass O
( O
non O
- O
matching O
pairs O
) O
covariance O
matrix O
in O
the O
whitened O
space O
, O
where O
The O
projection O
is O
then O
applied O
as O
, O
where O
is O
the O
mean O
MAC Method
vector O
to O
perform O
centering O
. O
To O
reduce O
the O
descriptor O
dimensionality O
to O
dimensions O
, O
only O
eigenvectors O
corresponding O
to O
largest O
eigenvalues O
are O
used O
. O
Projected O
vectors O
are O
subsequently O
- O
normalized O
. O
section O
: O
Training O
dataset O
In O
this O
section O
we O
briefly O
summarize O
the O
tightly O
- O
coupled O
BoW O
and O
SfM Method
reconstruction O
system O
that O
is O
employed O
to O
automatically O
select O
our O
training O
data O
. O
Then O
, O
we O
describe O
how O
we O
exploit O
the O
3D O
information O
to O
select O
harder O
matching O
pairs O
and O
hard O
non O
- O
matching O
pairs O
with O
larger O
variability O
. O
subsection O
: O
BoW Task
and O
3D Task
reconstruction Task
The O
retrieval Method
engine Method
used O
in O
the O
work O
of O
Schonberger O
et O
al O
. O
builds O
upon O
BoW Method
with O
fast Task
spatial Task
verification Task
. O
It O
uses O
Hessian O
affine O
local O
features O
, O
RootSIFT Method
descriptors Method
, O
and O
a O
fine O
vocabulary O
of O
16 O
M O
visual O
words O
. O
Then O
, O
query O
images O
are O
chosen O
via O
min Method
- Method
hash Method
and O
spatial Method
verification Method
, O
as O
in O
. O
Image Task
retrieval Task
based O
on O
BoW Method
is O
used O
to O
collect O
images O
of O
the O
objects O
/ O
landmarks O
. O
These O
images O
serve O
as O
the O
initial O
matching O
graph O
for O
the O
succeeding O
SfM Method
reconstruction O
, O
which O
is O
performed O
using O
state O
- O
of O
- O
the O
- O
art O
SfM Method
. O
Different O
mining Method
techniques Method
, O
e.g. O
zoom O
in O
, O
zoom O
out O
, O
sideways O
crawl O
, O
help O
to O
build O
larger O
and O
complete O
model O
. O
In O
this O
work O
, O
we O
exploit O
the O
outcome O
of O
such O
a O
system O
. O
Given O
a O
large O
unannotated O
image O
collection O
, O
images O
are O
clustered O
and O
a O
3D Method
model Method
is O
constructed O
per O
cluster O
. O
We O
use O
the O
terms O
3D Method
model Method
, O
model O
and O
cluster Method
interchangeably O
. O
For O
each O
image O
, O
the O
estimated O
camera O
position O
is O
known O
, O
as O
well O
as O
the O
local O
features O
registered O
on O
the O
3D Method
model Method
. O
We O
drop O
redundant O
( O
overlapping O
) O
3D O
models O
, O
that O
might O
have O
been O
constructed O
from O
different O
seeds O
. O
Models O
reconstructing O
the O
same O
landmark O
but O
from O
different O
and O
disjoint O
viewpoints O
are O
considered O
as O
non O
- O
overlapping O
. O
subsection O
: O
Selection O
of O
training Task
image Task
pairs Task
A O
3D Method
model Method
is O
described O
as O
a O
bipartite Method
visibility Method
graph Method
, O
where O
images O
and O
points O
are O
the O
vertices O
of O
the O
graph O
. O
Edges O
of O
this O
graph O
are O
defined O
by O
visibility O
relations O
between O
cameras O
and O
points O
, O
i.e. O
if O
a O
point O
is O
visible O
in O
an O
image O
, O
then O
there O
exists O
an O
edge O
. O
The O
set O
of O
points O
observed O
by O
an O
image O
is O
given O
by O
We O
create O
a O
dataset O
of O
tuples O
, O
where O
represents O
a O
query O
image O
, O
is O
a O
positive O
image O
that O
matches O
the O
query O
, O
and O
is O
a O
set O
of O
negative O
images O
that O
do O
not O
match O
the O
query O
. O
These O
tuples O
are O
used O
to O
form O
training O
image O
pairs O
, O
where O
each O
tuple O
corresponds O
to O
pairs O
. O
For O
a O
query O
image O
, O
a O
pool O
of O
candidate O
positive O
images O
is O
constructed O
based O
on O
the O
camera O
positions O
in O
the O
cluster O
of O
. O
It O
consists O
of O
the O
images O
with O
closest O
camera O
centers O
to O
the O
query O
. O
Due O
to O
the O
wide O
range O
of O
camera O
orientations O
, O
these O
do O
not O
necessarily O
depict O
the O
same O
object O
. O
We O
therefore O
propose O
three O
different O
ways O
to O
sample O
the O
positive O
image O
. O
The O
positives O
examples O
are O
fixed O
during O
the O
whole O
training O
process O
for O
all O
three O
strategies O
. O
paragraph O
: O
Positive O
images O
: O
MAC Method
distance O
. O
The O
image O
that O
has O
the O
lowest O
MAC Method
distance O
to O
the O
query O
is O
chosen O
as O
positive O
, O
formally O
This O
strategy O
is O
similar O
to O
the O
one O
followed O
by O
Arandjelovic O
et O
al O
. O
. O
They O
adopt O
this O
choice O
since O
only O
GPS O
coordinates O
are O
available O
and O
not O
camera O
orientations O
. O
Downside O
of O
this O
approach O
is O
that O
the O
chosen O
matching O
examples O
already O
have O
low O
distance O
, O
thus O
not O
forcing O
network Method
to O
learn O
much O
out O
of O
the O
positive O
samples O
. O
paragraph O
: O
Positive O
images O
: O
maximum O
inliers O
. O
In O
this O
approach O
, O
the O
3D O
information O
is O
exploited O
to O
choose O
the O
positive O
image O
, O
independently O
of O
the O
CNN Method
descriptor Method
. O
In O
particular O
, O
the O
image O
that O
has O
the O
highest O
number O
of O
co O
- O
observed O
3D O
points O
with O
the O
query O
is O
chosen O
. O
That O
is O
, O
This O
measure O
corresponds O
to O
the O
number O
of O
spatially O
verified O
features O
between O
two O
images O
, O
a O
measure O
commonly O
used O
for O
ranking Task
in O
BoW Task
- Task
based Task
retrieval Task
. O
As O
this O
choice O
is O
independent O
of O
the O
CNN Method
representation Method
, O
it O
delivers O
more O
challenging O
positive O
examples O
. O
paragraph O
: O
Positive O
images O
: O
relaxed O
inliers O
. O
Even O
though O
both O
previous O
methods O
choose O
positive O
images O
depicting O
the O
same O
object O
as O
the O
query O
, O
the O
variance O
of O
viewpoints O
is O
limited O
. O
Instead O
of O
using O
a O
pool O
of O
images O
with O
similar O
camera O
position O
, O
the O
positive O
example O
is O
selected O
at O
random O
from O
a O
set O
of O
images O
that O
co O
- O
observe O
enough O
points O
with O
the O
query O
, O
but O
do O
not O
exhibit O
too O
extreme O
scale O
change O
. O
The O
positive O
example O
in O
this O
case O
is O
where O
is O
the O
scale O
change O
between O
the O
two O
images O
. O
This O
method O
results O
in O
selecting O
harder O
matching O
examples O
which O
are O
still O
guaranteed O
to O
depict O
the O
same O
object O
. O
Method O
chooses O
different O
image O
than O
on O
86.5 O
% O
of O
the O
queries O
. O
In O
Figure O
[ O
reference O
] O
we O
present O
examples O
of O
query O
images O
and O
the O
corresponding O
positives O
selected O
with O
the O
three O
different O
methods O
. O
The O
relaxed Method
method Method
increases O
the O
variability O
of O
viewpoints O
. O
paragraph O
: O
Negative O
images O
. O
Negative O
examples O
are O
selected O
from O
clusters O
different O
than O
the O
cluster O
of O
the O
query O
image O
, O
as O
the O
clusters O
are O
non O
- O
overlaping O
. O
Following O
a O
well O
- O
known O
procedure O
, O
we O
choose O
hard O
negatives O
, O
that O
is O
, O
non O
- O
matching O
images O
with O
the O
most O
similar O
descriptor O
. O
Two O
different O
strategies O
are O
proposed O
. O
In O
the O
first O
, O
, O
k O
- O
nearest O
neighbors O
from O
all O
non O
- O
matching O
images O
are O
selected O
. O
In O
the O
other O
, O
, O
the O
same O
criterion O
is O
used O
, O
but O
at O
most O
one O
image O
per O
cluster O
is O
allowed O
. O
While O
often O
leads O
to O
multiple O
, O
and O
very O
similar O
, O
instances O
of O
the O
same O
object O
, O
provides O
higher O
variability O
of O
the O
negative O
examples O
, O
see O
Figure O
[ O
reference O
] O
. O
While O
positives O
examples O
are O
fixed O
during O
the O
whole O
training O
process O
, O
hard O
negatives O
depend O
on O
the O
current O
CNN O
parameters O
and O
are O
re O
- O
mined O
multiple O
times O
per O
epoch O
. O
section O
: O
Experiments O
In O
this O
section O
we O
discuss O
implementation O
details O
of O
our O
training O
, O
evaluate O
different O
components O
of O
our O
method O
, O
and O
compare O
to O
the O
state O
of O
the O
art O
. O
subsection O
: O
Training O
setup O
and O
implementation O
details O
Our O
training O
samples O
are O
derived O
from O
the O
dataset O
used O
in O
the O
work O
of O
Schonberger O
et O
al O
. O
, O
which O
consists O
of O
7.4 O
million O
images O
downloaded O
from O
Flickr O
using O
keywords O
of O
popular O
landmarks O
, O
cities O
and O
countries O
across O
the O
world O
. O
The O
clustering Method
procedure Method
gives O
images O
to O
serve O
as O
query O
seeds O
. O
The O
extensive O
retrieval O
- O
SfM Method
reconstruction O
of O
the O
whole O
dataset O
results O
in O
reconstructed Method
3D Method
models Method
. O
Removing O
overlapping Method
models Method
leaves O
us O
with O
3D Method
models Method
containing O
unique O
images O
from O
the O
initial O
dataset O
. O
The O
initial O
dataset O
contained O
on O
purpose O
all O
images O
of O
Oxford5k Material
and O
Paris6k Material
datasets O
. O
In O
this O
way O
, O
we O
are O
able O
to O
exclude O
98 O
clusters O
that O
contain O
any O
image O
( O
or O
their O
near O
duplicates O
) O
from O
these O
test O
datasets O
. O
The O
largest O
model O
has O
images O
, O
while O
the O
smallest O
has O
. O
We O
randomly O
select O
models O
( O
images O
) O
for O
training O
and O
( O
) O
for O
validation Task
. O
The O
number O
of O
training O
queries O
per O
cluster O
is O
10 O
% O
of O
the O
cluster O
size O
for O
clusters O
of O
300 O
or O
less O
images O
, O
or O
30 O
images O
for O
larger O
clusters O
. O
A O
total O
number O
of O
images O
is O
selected O
for O
training O
queries O
, O
and O
for O
validation Task
queries Task
. O
Each O
training O
and O
validation O
tuple O
contains O
query O
, O
positive O
and O
negative O
images O
. O
The O
pool O
of O
candidate O
positives O
consists O
of O
images O
with O
closest O
camera O
centers O
to O
the O
query O
. O
In O
particular O
, O
for O
method O
, O
the O
inliers Metric
overlap Metric
threshold Metric
is O
, O
and O
the O
scale O
change O
threshold O
. O
Hard O
negatives O
are O
re O
- O
mined O
times O
per O
epoch O
, O
i.e. O
roughly O
every O
training O
queries O
. O
Given O
the O
chosen O
queries O
and O
the O
chosen O
positives O
, O
we O
further O
add O
20 O
images O
per O
cluster O
to O
serve O
as O
candidate O
negatives O
during O
re Task
- Task
mining Task
. O
This O
constitutes O
a O
training O
set O
of O
images O
and O
it O
corresponds O
to O
the O
case O
that O
all O
3D Method
models Method
are O
included O
for O
training O
. O
To O
perform O
the O
fine Task
- Task
tuning Task
as O
described O
in O
Section O
[ O
reference O
] O
, O
we O
initialize O
by O
the O
convolutional Method
layers Method
of O
AlexNet Method
or O
VGG Method
. O
We O
use O
learning Metric
rate Metric
equal O
to O
, O
which O
is O
divided O
by O
every O
epochs O
, O
momentum O
, O
weight O
decay O
, O
parameter O
for O
contrastive O
loss O
, O
and O
batch O
size O
of O
training O
tuples O
. O
All O
training O
images O
are O
resized O
to O
a O
maximum O
dimensionality O
, O
while O
keeping O
the O
original O
aspect O
ratio O
. O
Training O
is O
done O
for O
at O
most O
epochs O
and O
the O
best O
network O
is O
selected O
based O
on O
performance O
, O
measured O
via O
mean Metric
Average Metric
Precision Metric
( O
mAP Metric
) O
, O
on O
validation Metric
tuples Metric
. O
subsection O
: O
Test O
datasets O
and O
evaluation Metric
protocol Metric
We O
evaluate O
our O
approach O
on O
Oxford Material
buildings Material
, O
Paris Material
and O
Holidays O
datasets O
. O
First O
two O
are O
closer O
to O
our O
training O
data O
, O
while O
the O
last O
differentiates O
by O
containing O
similar O
scenes O
and O
not O
only O
man O
made O
objects O
or O
buildings O
. O
These O
are O
also O
combined O
with O
100k O
distractors O
from O
Oxford100k O
to O
allow O
for O
evaluation O
at O
larger O
scale O
. O
The O
performance O
is O
measured O
via O
mAP Metric
. O
We O
follow O
the O
standard O
evaluation O
protocol O
for O
Oxford Material
and O
Paris Material
and O
crop O
the O
query O
images O
with O
the O
provided O
bounding O
box O
. O
The O
cropped O
image O
is O
fed O
as O
input O
to O
the O
CNN Method
. O
However O
, O
to O
deliver O
a O
direct O
comparison O
with O
other O
methods O
, O
we O
also O
evaluate O
queries O
generated O
by O
keeping O
all O
activations O
that O
fall O
into O
this O
bounding O
box O
when O
the O
full O
query O
image O
is O
used O
as O
input O
to O
the O
network O
. O
We O
refer O
to O
the O
cropped Method
images Method
approach Method
as O
and O
the O
cropped O
activations O
as O
. O
The O
dimensionality O
of O
the O
images O
fed O
into O
the O
CNN Method
is O
limited O
to O
pixels O
. O
In O
our O
experiments O
, O
no O
vector Method
post Method
- Method
processing Method
is O
applied O
if O
not O
otherwise O
stated O
. O
subsection O
: O
Results O
on O
image Task
retrieval Task
paragraph O
: O
Learning Task
. O
We O
evaluate O
the O
off Method
- Method
the Method
- Method
shelf Method
CNN Method
and O
our O
fine O
- O
tuned O
ones O
after O
different O
number O
of O
training O
epochs O
. O
Our O
different O
methods O
for O
positive Task
and Task
negative Task
selection Task
are O
evaluated O
independently O
in O
order O
to O
decompose O
the O
benefit O
of O
each O
ingredient O
. O
Finally O
, O
we O
also O
perform O
a O
comparison O
with O
the O
triplet Method
loss Method
, O
trained O
on O
exactly O
the O
same O
training O
data O
as O
the O
ones O
used O
for O
our O
architecture O
with O
the O
contrastive Method
loss Method
. O
Results O
are O
presented O
in O
Figure O
[ O
reference O
] O
. O
The O
results O
show O
that O
positive O
examples O
with O
larger O
view O
point O
variability O
, O
and O
negative O
examples O
with O
higher O
content O
variability O
, O
both O
acquire O
a O
consistent O
increase O
in O
the O
performance O
. O
The O
triplet Metric
loss Metric
appears O
to O
be O
inferior O
in O
our O
context O
; O
we O
observe O
oscillation O
of O
the O
error O
in O
the O
validation O
set O
from O
early O
epochs O
, O
which O
implies O
over O
- O
fitting O
. O
In O
the O
rest O
of O
the O
paper O
, O
we O
adopt O
the O
approach O
. O
paragraph O
: O
Dataset Metric
variability Metric
. O
We O
perform O
fine Task
- Task
tuning Task
by O
using O
a O
subset O
of O
the O
available O
3D Method
models Method
. O
Results O
are O
presented O
in O
Figure O
[ O
reference O
] O
with O
10 O
, O
100 O
and O
551 O
( O
all O
available O
) O
clusters O
, O
while O
keeping O
the O
amount O
of O
training O
data O
, O
i.e. O
training O
queries O
, O
fixed O
. O
In O
the O
case O
of O
10 O
and O
100 O
models O
we O
use O
the O
largest O
ones O
, O
i.e. O
ones O
with O
the O
highest O
number O
of O
images O
. O
It O
is O
better O
to O
train O
with O
all O
3D Method
models Method
due O
to O
the O
higher O
variability O
in O
the O
training O
set O
. O
Remarkably O
, O
significant O
increase O
in O
performance O
is O
achieved O
even O
with O
10 O
or O
100 O
models O
. O
However O
, O
the O
network O
is O
able O
to O
over O
- O
fit O
in O
the O
case O
of O
few O
clusters O
. O
All O
models O
are O
utilized O
in O
all O
other O
experiments O
. O
paragraph O
: O
Learned O
projections O
. O
The O
PCA Method
- Method
whitening Method
( O
PCA Method
) O
is O
shown O
to O
be O
essential O
in O
some O
cases O
of O
CNN Task
- Task
based Task
descriptors Task
. O
On O
the O
other O
hand O
, O
it O
is O
shown O
that O
on O
some O
of O
the O
datasets O
, O
the O
performance O
after O
PCA Method
substantially O
drops O
compared O
with O
the O
raw Method
descriptors Method
( O
max Method
pooling Method
on O
Oxford5k Material
) O
. O
We O
perform O
comparison O
of O
this O
traditional O
way O
of O
whitening Method
and O
our O
learned Method
whitening Method
( O
L O
) O
, O
described O
in O
Section O
[ O
reference O
] O
. O
Table O
[ O
reference O
] O
shows O
results O
without O
post Method
- Method
processing Method
and O
with O
the O
two O
different O
methods O
of O
whitening Method
. O
Our O
experiments O
confirm O
, O
that O
PCA Method
often O
reduces O
the O
performance O
. O
In O
contrast O
to O
that O
, O
the O
proposed O
L Method
achieves O
the O
best O
performance O
in O
most O
cases O
and O
is O
never O
the O
worst O
performing O
method O
. O
Compared O
to O
no O
post Method
- Method
processing Method
baseline Method
, O
L Method
reduces O
the O
performance O
twice O
for O
AlexNet Task
, O
but O
the O
drop O
is O
negligible O
compared O
to O
the O
drop O
observed O
for O
PCA Method
. O
For O
the O
VGG Method
, O
the O
proposed O
L Method
always O
outperforms O
the O
no Method
post Method
- Method
processing Method
baseline Method
. O
Our O
unsupervised Method
learning Method
directly O
optimizes O
MAC Method
when O
extracted O
from O
full O
images O
, O
however O
, O
we O
further O
apply O
the O
fine Method
- Method
tuned Method
networks Method
to O
construct O
R O
- O
MAC Method
representation O
with O
regions O
of O
three O
different O
scales O
. O
It O
consists O
of O
extracting O
MAC Method
from O
multiple O
sub O
- O
windows O
and O
then O
aggregating O
them O
. O
Directly O
optimizing O
R Method
- Method
MAC Method
during O
learning Task
is O
possible O
and O
could O
offer O
extra O
improvements O
, O
but O
this O
is O
left O
for O
future O
work O
. O
Despite O
the O
fact O
that O
R Method
- Method
MAC Method
offers O
improvements O
due O
to O
the O
regional Method
representation Method
, O
in O
our O
experiments O
it O
is O
not O
always O
better O
than O
MAC Method
, O
since O
the O
latter O
is O
optimized O
during O
the O
end Task
- Task
to Task
- Task
end Task
learning Task
. O
We O
apply O
PCA Method
on O
R Method
- Method
MAC Method
as O
in O
, O
that O
is O
, O
we O
whiten O
each O
region O
vector O
first O
and O
then O
aggregate O
. O
Performance O
is O
significantly O
higher O
in O
this O
way O
. O
In O
the O
case O
of O
our O
L O
, O
we O
directly O
whiten O
the O
final O
vector O
after O
aggregation Task
, O
which O
is O
also O
faster O
to O
compute O
. O
paragraph O
: O
Dimensionality Task
reduction Task
. O
We O
compare O
dimensionality Method
reduction Method
performed O
with O
PCA Method
and O
with O
our O
L O
. O
The O
performance O
for O
varying O
descriptor O
dimensionality O
is O
plotted O
in O
Figure O
[ O
reference O
] O
. O
The O
plots O
suggest O
that O
L O
works O
better O
in O
higher O
dimensionalities O
, O
while O
PCA Method
works O
slightly O
better O
for O
the O
lower O
ones O
. O
Remarkably O
, O
MAC Method
reduced O
down O
to O
16D O
outperforms O
state O
- O
of O
- O
the O
- O
art O
on O
BoW Method
- Method
based Method
128D Method
compact Method
codes Method
on O
Oxford105k Material
( O
vs O
) O
. O
Further O
results O
on O
very O
short O
codes O
can O
be O
found O
in O
Table O
[ O
reference O
] O
. O
paragraph O
: O
Over Method
- Method
fitting Method
and O
generalization Task
. O
In O
all O
experiments O
, O
all O
clusters O
including O
any O
image O
( O
not O
only O
query O
landmarks O
) O
from O
Oxford5k Material
or O
Paris6k Material
datasets O
are O
removed O
. O
To O
evaluate O
whether O
the O
network O
tends O
to O
over O
- O
fit O
to O
the O
training O
data O
or O
to O
generalize O
, O
we O
repeat O
the O
training O
, O
this O
time O
using O
all O
3D O
reconstructions O
, O
including O
those O
of O
Oxford Material
and O
Paris Material
landmarks O
. O
The O
same O
amount O
of O
training O
queries O
is O
used O
for O
a O
fair O
comparison O
. O
We O
observe O
negligible O
difference O
in O
the O
performance O
of O
the O
network O
on O
Oxford Material
and O
Paris Material
evaluation O
results O
, O
i.e. O
the O
difference O
in O
mAP Metric
was O
on O
average O
over O
all O
testing O
datasets O
. O
We O
conclude O
that O
the O
network O
generalizes O
well O
and O
is O
relatively O
insensitive O
to O
over O
- O
fitting O
. O
: O
Full O
images O
are O
used O
as O
queries O
making O
the O
results O
not O
directly O
comparable O
on O
Oxford Material
and O
Paris Material
. O
â€¡ O
: O
Our O
evaluation O
of O
MAC Method
with O
PCAw Method
as O
in O
[ O
] O
with O
the O
off O
- O
the O
- O
shelf O
network O
. O
paragraph O
: O
Comparison O
with O
the O
state O
of O
the O
art O
. O
We O
extensively O
compare O
our O
results O
with O
the O
state O
- O
of O
- O
the O
- O
art O
performance O
on O
compact Method
image Method
representations Method
and O
extremely O
short Method
codes Method
. O
The O
results O
for O
MAC Method
and O
R Method
- Method
MAC Method
with O
the O
fine Method
- Method
tuned Method
networks Method
are O
summarized O
together O
with O
previously O
published O
results O
in O
Table O
[ O
reference O
] O
. O
The O
proposed O
methods O
outperform O
the O
state O
of O
the O
art O
on O
Paris Material
and O
Oxford Material
datasets O
, O
with O
and O
without O
distractors O
with O
all O
16D O
, O
32D O
, O
128D O
, O
256D O
, O
and O
512D O
descriptors O
. O
On O
Holidays O
dataset O
, O
the O
Neural Method
codes Method
win O
the O
extreme O
short O
code O
category O
, O
while O
off O
- O
the O
- O
shelf O
NetVlad Method
performs O
the O
best O
on O
256D O
and O
higher O
. O
We O
additionally O
combine O
MAC Method
and O
R O
- O
MAC Method
with O
recent O
localization Method
method Method
for O
re Task
- Task
ranking Task
to O
further O
boost O
the O
performance O
. O
Our O
scores O
compete O
with O
state O
- O
of O
- O
the O
- O
art O
systems O
based O
on O
local O
features O
and O
query Method
expansion Method
. O
These O
have O
much O
higher O
memory O
needs O
and O
larger O
query Metric
times Metric
. O
Observations O
on O
the O
recently O
published O
NetVLAD Method
: O
( O
1 O
) O
After O
fine Method
- Method
tuning Method
, O
NetVLAD Method
performance O
drops O
on O
Holidays O
, O
while O
our O
training O
improves O
off O
- O
the O
- O
shelf O
results O
on O
all O
datasets O
. O
( O
2 O
) O
Our O
32D O
MAC Method
descriptor O
has O
comparable O
performance O
to O
256D Method
NetVLAD Method
on O
Oxford5k Material
( O
ours O
vs O
NetVLAD Method
) O
, O
and O
on O
Paris6k Material
( O
ours O
vs O
NetVLAD Method
) O
. O
section O
: O
Conclusions O
We O
addressed O
fine Task
- Task
tuning Task
of Task
CNN Task
for O
image Task
retrieval Task
. O
The O
training O
data O
are O
selected O
from O
an O
automated Method
3D Method
reconstruction Method
system Method
applied O
on O
a O
large O
unordered O
photo O
collection O
. O
The O
proposed O
method O
does O
not O
require O
any O
manual O
annotation O
and O
yet O
outperforms O
the O
state O
of O
the O
art O
on O
a O
number O
of O
standard O
benchmarks O
for O
wide O
range O
( O
16 O
to O
512 O
) O
of O
descriptor O
dimensionality O
. O
The O
achieved O
results O
are O
reaching O
the O
level O
of O
the O
best O
systems O
based O
on O
local O
features O
with O
spatial Method
matching Method
and O
query Method
expansion Method
, O
while O
being O
faster O
and O
requiring O
less O
memory O
. O
Training O
data O
, O
fine Method
- Method
tuned Method
networks Method
and O
evaluation O
code O
are O
publicly O
available O
. O
paragraph O
: O
Acknowledgment O
. O
Work O
was O
supported O
by O
the O
MSMT O
LL1303 O
ERC O
- O
CZ O
grant O
. O
bibliography O
: O
References O
