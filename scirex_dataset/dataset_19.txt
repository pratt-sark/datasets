document O
: O
Real Task
- Task
Time Task
Single Task
Image Task
and O
Video Task
Super Task
- Task
Resolution Task
Using O
an O
Efficient Method
Sub Method
- Method
Pixel Method
Convolutional Method
Neural Method
Network Method
Recently O
, O
several O
models O
based O
on O
deep Method
neural Method
networks Method
have O
achieved O
great O
success O
in O
terms O
of O
both O
reconstruction Metric
accuracy Metric
and O
computational Metric
performance O
for O
single O
image Task
super Task
- Task
resolution Task
. O
In O
these O
methods O
, O
the O
low Task
resolution Task
( O
LR Task
) O
input O
image Task
is O
upscaled O
to O
the O
high O
resolution O
( O
HR O
) O
space O
using O
a O
single O
filter Method
, O
commonly O
bicubic Method
interpolation Method
, O
before O
reconstruction Task
. O
This O
means O
that O
the O
super Task
- Task
resolution Task
( O
SR Task
) O
operation O
is O
performed O
in O
HR O
space O
. O
We O
demonstrate O
that O
this O
is O
sub O
- O
optimal O
and O
adds O
computational Metric
complexity O
. O
In O
this O
paper O
, O
we O
present O
the O
first O
convolutional Method
neural Method
network Method
( Method
CNN Method
) Method
capable O
of O
real Task
- Task
time Task
SR Task
of O
1080p O
videos O
on O
a O
single O
K2 O
GPU O
. O
To O
achieve O
this O
, O
we O
propose O
a O
novel O
CNN Method
architecture Method
where O
the O
feature O
maps O
are O
extracted O
in O
the O
LR Task
space O
. O
In O
addition O
, O
we O
introduce O
an O
efficient O
sub Method
- Method
pixel Method
convolution Method
layer Method
which O
learns O
an O
array Method
of Method
upscaling Method
filters Method
to O
upscale O
the O
final O
LR Task
feature O
maps O
into O
the O
HR O
output O
. O
By O
doing O
so O
, O
we O
effectively O
replace O
the O
handcrafted Method
bicubic Method
filter Method
in O
the O
SR Task
pipeline O
with O
more O
complex O
upscaling Method
filters Method
specifically O
trained O
for O
each O
feature O
map O
, O
whilst O
also O
reducing O
the O
computational Metric
complexity O
of O
the O
overall O
SR Task
operation O
. O
We O
evaluate O
the O
proposed O
approach O
using O
images O
and O
videos O
from O
publicly O
available O
datasets O
and O
show O
that O
it O
performs O
significantly O
better O
( O
+ O
0.15dB O
on O
Images O
and O
+ O
0.39dB O
on O
Videos O
) O
and O
is O
an O
order O
of O
magnitude O
faster O
than O
previous O
CNN Method
- Method
based Method
methods Method
. O
⌈⌉ O
⌊⌋ O
SISRSISRsingleimagesuper O
- O
resolution O
PSNRPSNRpeaksignaltonoiseratio O
MSEMSEmeansquarederror O
CNNCNNconvolutionalneuralnetwork O
ESPCNESPCNefficientsub O
- O
pixelconvolutionalneuralnetwork O
LRLRlowresolution O
HRHRhighresolution O
SRSRsuper O
- O
resolution O
HDHDhighdefinition O
FPSFPSframespersecond O
TNRDTNRDtrainablenonlinearreactiondiffusion O
section O
: O
Introduction O
The O
recovery O
of O
a O
HR O
image Task
or O
video O
from O
its O
LR Task
counter O
part O
is O
topic O
of O
great O
interest O
in O
digital O
image Task
processing O
. O
This O
task O
, O
referred O
to O
as O
SR Task
, O
finds O
direct O
applications O
in O
many O
areas O
such O
as O
HDTV Task
, O
medical Task
imaging Task
, O
satellite Task
imaging Task
, O
face Task
recognition Task
and O
surveillance Task
. O
The O
global O
SR Task
problem O
assumes O
LR Task
data O
to O
be O
a O
low O
- O
pass O
filtered O
( O
blurred O
) O
, O
downsampled O
and O
noisy O
version O
of O
HR O
data O
. O
It O
is O
a O
highly O
ill Task
- Task
posed Task
problem Task
, O
due O
to O
the O
loss O
of O
high O
- O
frequency O
information O
that O
occurs O
during O
the O
non Method
- Method
invertible Method
low Method
- Method
pass Method
filtering Method
and O
subsampling Method
operations Method
. O
Furthermore O
, O
the O
SR Task
operation O
is O
effectively O
a O
one Method
- Method
to Method
- Method
many Method
mapping Method
from O
LR Task
to O
HR O
space O
which O
can O
have O
multiple O
solutions O
, O
of O
which O
determining O
the O
correct O
solution O
is O
non O
- O
trivial O
. O
A O
key O
assumption O
that O
underlies O
many O
SR Task
techniques O
is O
that O
much O
of O
the O
high O
- O
frequency O
data O
is O
redundant O
and O
thus O
can O
be O
accurately O
reconstructed O
from O
low O
frequency O
components O
. O
SR Task
is O
therefore O
an O
inference Task
problem Task
, O
and O
thus O
relies O
on O
our O
model O
of O
the O
statistics Task
of Task
images Task
in Task
question Task
. O
Many O
methods O
assume O
multiple O
images O
are O
available O
as O
LR Task
instances O
of O
the O
same O
scene O
with O
different O
perspectives O
, O
i.e. O
with O
unique O
prior O
affine O
transformations O
. O
These O
can O
be O
categorised O
as O
multi O
- O
image Task
SR Task
methods O
and O
exploit O
explicit O
redundancy O
by O
constraining O
the O
ill Task
- Task
posed Task
problem Task
with O
additional O
information O
and O
attempting O
to O
invert O
the O
downsampling Method
process Method
. O
However O
, O
these O
methods O
usually O
require O
computationally O
complex O
image Task
registration O
and O
fusion O
stages O
, O
the O
accuracy Metric
of O
which O
directly O
impacts O
the O
quality O
of O
the O
result O
. O
An O
alternative O
family O
of O
methods O
are O
SISR Method
techniques Method
. O
These O
techniques O
seek O
to O
learn O
implicit O
redundancy O
that O
is O
present O
in O
natural O
data O
to O
recover O
missing O
HR O
information O
from O
a O
single O
LR Task
instance O
. O
This O
usually O
arises O
in O
the O
form O
of O
local O
spatial O
correlations O
for O
images O
and O
additional O
temporal O
correlations O
in O
videos O
. O
In O
this O
case O
, O
prior O
information O
in O
the O
form O
of O
reconstruction O
constraints O
is O
needed O
to O
restrict O
the O
solution O
space O
of O
the O
reconstruction O
. O
subsection O
: O
Related O
Work O
The O
goal O
of O
SISR Method
methods Method
is O
to O
recover O
a O
HR O
image Task
from O
a O
single O
LR Task
input O
image Task
. O
Recent O
popular O
SISR Method
methods Method
can O
be O
classified O
into O
edge Method
- Method
based Method
, O
image Task
statistics O
- O
based O
and O
patch O
- O
based O
methods O
. O
A O
detailed O
review O
of O
more O
generic O
SISR Method
methods Method
can O
be O
found O
in O
. O
One O
family O
of O
approaches O
that O
has O
recently O
thrived O
in O
tackling O
the O
SISR Task
problem Task
is O
sparsity Method
- Method
based Method
techniques Method
. O
Sparse Method
coding Method
is O
an O
effective O
mechanism O
that O
assumes O
any O
natural O
image Task
can O
be O
sparsely O
represented O
in O
a O
transform O
domain O
. O
This O
transform O
domain O
is O
usually O
a O
dictionary O
of O
image Task
atoms O
, O
which O
can O
be O
learnt O
through O
a O
training Method
process Method
that O
tries O
to O
discover O
the O
correspondence O
between O
LR Task
and O
HR O
patches O
. O
This O
dictionary O
is O
able O
to O
embed O
the O
prior O
knowledge O
necessary O
to O
constrain O
the O
ill Task
- Task
posed Task
problem Task
of Task
super Task
- Task
resolving Task
unseen Task
data Task
. O
This O
approach O
is O
proposed O
in O
the O
methods O
of O
. O
A O
drawback O
of O
sparsity Method
- Method
based Method
techniques Method
is O
that O
introducing O
the O
sparsity O
constraint O
through O
a O
nonlinear Method
reconstruction Method
is O
generally O
computationally O
expensive O
. O
Image Method
representations Method
derived O
via O
neural Method
networks Method
have O
recently O
also O
shown O
promise O
for O
SISR Method
. O
These O
methods O
, O
employ O
the O
back Method
- Method
propagation Method
algorithm Method
to O
train O
on O
large O
image Task
databases O
such O
as O
ImageNet Method
in O
order O
to O
learn O
nonlinear O
mappings O
of O
LR Task
and O
HR O
image Task
patches O
. O
Stacked Method
collaborative Method
local Method
auto Method
- Method
encoders Method
are O
used O
in O
to O
super O
- O
resolve O
the O
LR Task
image Task
layer O
by O
layer O
. O
Osendorfer O
et O
al O
. O
suggested O
a O
method O
for O
SISR Method
based O
on O
an O
extension O
of O
the O
predictive Method
convolutional Method
sparse Method
coding Method
framework Method
. O
A O
multiple Method
layer Method
CNN Method
inspired O
by O
sparse Method
- Method
coding Method
methods Method
is O
proposed O
in O
. O
Chen O
et O
. O
al O
. O
proposed O
to O
use O
multi Method
- Method
stage Method
TNRD Method
as O
an O
alternative O
to O
CNN Method
where O
the O
weights O
and O
the O
nonlinearity O
is O
trainable O
. O
Wang O
et O
. O
al O
trained O
a O
cascaded Method
sparse Method
coding Method
network Method
from O
end O
to O
end O
inspired O
by O
LISTA Method
( O
Learning Method
iterative Method
shrinkage Method
and Method
thresholding Method
algorithm Method
) O
to O
fully O
exploit O
the O
natural O
sparsity O
of O
images O
. O
The O
network Method
structure Method
is O
not O
limited O
to O
neural Method
networks Method
, O
for O
example O
, O
a O
random Method
forest Method
has O
also O
been O
successfully O
used O
for O
SISR Method
. O
subsection O
: O
Motivations O
and O
contributions O
With O
the O
development O
of O
CNN Method
, O
the O
efficiency O
of O
the O
algorithms O
, O
especially O
their O
computational Metric
and O
memory Metric
cost Metric
, O
gains O
importance O
. O
The O
flexibility O
of O
deep Method
network Method
models Method
to O
learn O
nonlinear O
relationships O
has O
been O
shown O
to O
attain O
superior O
reconstruction Metric
accuracy Metric
compared O
to O
previously O
hand Method
- Method
crafted Method
models Method
. O
To O
super O
- O
resolve O
a O
LR Task
image Task
into O
HR O
space O
, O
it O
is O
necessary O
to O
increase O
the O
resolution O
of O
the O
LR Task
image Task
to O
match O
that O
of O
the O
HR O
image Task
at O
some O
point O
. O
In O
Osendorfer O
et O
al O
. O
, O
the O
image Task
resolution O
is O
increased O
in O
the O
middle O
of O
the O
network O
gradually O
. O
Another O
popular O
approach O
is O
to O
increase O
the O
resolution O
before O
or O
at O
the O
first O
layer O
of O
the O
network O
. O
However O
, O
this O
approach O
has O
a O
number O
of O
drawbacks O
. O
Firstly O
, O
increasing O
the O
resolution O
of O
the O
LR Task
images O
before O
the O
image Task
enhancement O
step O
increases O
the O
computational Metric
complexity O
. O
This O
is O
especially O
problematic O
for O
convolutional Method
networks Method
, O
where O
the O
processing Metric
speed Metric
directly O
depends O
on O
the O
input O
image Task
resolution O
. O
Secondly O
, O
interpolation Method
methods Method
typically O
used O
to O
accomplish O
the O
task O
, O
such O
as O
bicubic Method
interpolation Method
, O
do O
not O
bring O
additional O
information O
to O
solve O
the O
ill Task
- Task
posed Task
reconstruction Task
problem Task
. O
Learning Method
upscaling Method
filters Method
was O
briefly O
suggested O
in O
the O
footnote O
of O
Dong O
et.al O
. O
. O
However O
, O
the O
importance O
of O
integrating O
it O
into O
the O
CNN Method
as O
part O
of O
the O
SR Task
operation O
was O
not O
fully O
recognised O
and O
the O
option O
not O
explored O
. O
Additionally O
, O
as O
noted O
by O
Dong O
et O
al O
. O
, O
there O
are O
no O
efficient O
implementations O
of O
a O
convolution Method
layer Method
whose O
output O
size O
is O
larger O
than O
the O
input O
size O
and O
well O
- O
optimized Method
implementations Method
such O
as O
convnet Method
do O
not O
trivially O
allow O
such O
behaviour O
. O
In O
this O
paper O
, O
contrary O
to O
previous O
works O
, O
we O
propose O
to O
increase O
the O
resolution Metric
from O
LR Task
to O
HR O
only O
at O
the O
very O
end O
of O
the O
network O
and O
super O
- O
resolve O
HR O
data O
from O
LR Task
feature O
maps O
. O
This O
eliminates O
the O
need O
to O
perform O
most O
of O
the O
SR Task
operation O
in O
the O
far O
larger O
HR O
resolution O
. O
For O
this O
purpose O
, O
we O
propose O
an O
efficient O
sub Method
- Method
pixel Method
convolution Method
layer Method
to O
learn O
the O
upscaling Method
operation Method
for O
image Task
and O
video Task
super Task
- Task
resolution Task
. O
The O
advantages O
of O
these O
contributions O
are O
two O
fold O
: O
In O
our O
network O
, O
upscaling Task
is O
handled O
by O
the O
last Method
layer Method
of O
the O
network O
. O
This O
means O
each O
LR Task
image Task
is O
directly O
fed O
to O
the O
network O
and O
feature Task
extraction Task
occurs O
through O
nonlinear Method
convolutions Method
in O
LR Task
space O
. O
Due O
to O
the O
reduced O
input O
resolution O
, O
we O
can O
effectively O
use O
a O
smaller O
filter O
size O
to O
integrate O
the O
same O
information O
while O
maintaining O
a O
given O
contextual O
area O
. O
The O
resolution Method
and O
filter Method
size Method
reduction Method
lower O
the O
computational Metric
and O
memory O
complexity O
substantially O
enough O
to O
allow O
super Task
- Task
resolution Task
of O
HD O
videos O
in O
real O
- O
time O
as O
shown O
in O
Sec O
. O
[ O
reference O
] O
. O
For O
a O
network O
with O
layers O
, O
we O
learn O
upscaling Method
filters Method
for O
the O
feature O
maps O
as O
opposed O
to O
one O
upscaling Method
filter Method
for O
the O
input O
image Task
. O
In O
addition O
, O
not O
using O
an O
explicit O
interpolation Method
filter Method
means O
that O
the O
network O
implicitly O
learns O
the O
processing O
necessary O
for O
SR Task
. O
Thus O
, O
the O
network O
is O
capable O
of O
learning O
a O
better O
and O
more O
complex O
LR Task
to O
HR O
mapping O
compared O
to O
a O
single O
fixed Method
filter Method
upscaling Method
at O
the O
first O
layer O
. O
This O
results O
in O
additional O
gains O
in O
the O
reconstruction Metric
accuracy Metric
of O
the O
model O
as O
shown O
in O
Sec O
. O
[ O
reference O
] O
and O
Sec O
. O
[ O
reference O
] O
. O
We O
validate O
the O
proposed O
approach O
using O
images O
and O
videos O
from O
publicly O
available O
benchmarks O
datasets O
and O
compared O
our O
performance O
against O
previous O
works O
including O
. O
We O
show O
that O
the O
proposed O
model O
achieves O
state O
- O
of O
- O
art O
performance O
and O
is O
nearly O
an O
order O
of O
magnitude O
faster O
than O
previously O
published O
methods O
on O
images O
and O
videos O
. O
section O
: O
Method O
The O
task O
of O
SISR Task
is O
to O
estimate O
a O
HR O
image Task
given O
a O
LR Task
image Task
downscaled O
from O
the O
corresponding O
original O
HR O
image Task
. O
The O
downsampling Method
operation Method
is O
deterministic O
and O
known O
: O
to O
produce O
from O
, O
we O
first O
convolve O
using O
a O
Gaussian Method
filter Method
- O
thus O
simulating O
the O
camera Method
’s Method
point Method
spread Method
function Method
- O
then O
downsample O
the O
image Task
by O
a O
factor O
of O
. O
We O
will O
refer O
to O
as O
the O
upscaling O
ratio O
. O
In O
general O
, O
both O
and O
can O
have O
colour O
channels O
, O
thus O
they O
are O
represented O
as O
real O
- O
valued O
tensors O
of O
size O
and O
, O
respectively O
. O
To O
solve O
the O
SISR Task
problem Task
, O
the O
SRCNN Method
proposed O
in O
recovers O
from O
an O
upscaled O
and O
interpolated O
version O
of O
instead O
of O
. O
To O
recover O
, O
a O
3 Method
layer Method
convolutional Method
network Method
is O
used O
. O
In O
this O
section O
we O
propose O
a O
novel O
network Method
architecture Method
, O
as O
illustrated O
in O
Fig O
. O
[ O
reference O
] O
, O
to O
avoid O
upscaling O
before O
feeding O
it O
into O
the O
network O
. O
In O
our O
architecture O
, O
we O
first O
apply O
a O
layer Method
convolutional Method
neural Method
network Method
directly O
to O
the O
LR Task
image Task
, O
and O
then O
apply O
a O
sub Method
- Method
pixel Method
convolution Method
layer Method
that O
upscales O
the O
LR Task
feature O
maps O
to O
produce O
. O
For O
a O
network O
composed O
of O
layers O
, O
the O
first O
layers O
can O
be O
described O
as O
follows O
: O
Where O
are O
learnable O
network O
weights O
and O
biases O
respectively O
. O
is O
a O
2D Method
convolution Method
tensor Method
of O
size O
, O
where O
is O
the O
number O
of O
features O
at O
layer O
, O
, O
and O
is O
the O
filter O
size O
at O
layer O
. O
The O
biases O
are O
vectors O
of O
length O
. O
The O
nonlinearity O
function O
( O
or O
activation O
function O
) O
is O
applied O
element O
- O
wise O
and O
is O
fixed O
. O
The O
last O
layer O
has O
to O
convert O
the O
LR Task
feature O
maps O
to O
a O
HR O
image Task
. O
subsection O
: O
Deconvolution Method
layer Method
The O
addition O
of O
a O
deconvolution Method
layer Method
is O
a O
popular O
choice O
for O
recovering Task
resolution Task
from O
max Method
- Method
pooling Method
and O
other O
image Task
down O
- O
sampling O
layers O
. O
This O
approach O
has O
been O
successfully O
used O
in O
visualizing Task
layer Task
activations Task
and O
for O
generating O
semantic Task
segmentations Task
using O
high O
level O
features O
from O
the O
network O
. O
It O
is O
trivial O
to O
show O
that O
the O
bicubic Method
interpolation Method
used O
in O
SRCNN Method
is O
a O
special O
case O
of O
the O
deconvolution Method
layer Method
, O
as O
suggested O
already O
in O
. O
The O
deconvolution Method
layer Method
proposed O
in O
can O
be O
seen O
as O
multiplication O
of O
each O
input O
pixel O
by O
a O
filter O
element O
- O
wise O
with O
stride O
, O
and O
sums O
over O
the O
resulting O
output O
windows O
also O
known O
as O
backwards Method
convolution Method
. O
subsection O
: O
Efficient O
sub Method
- Method
pixel Method
convolution Method
layer Method
The O
other O
way O
to O
upscale O
a O
LR Task
image Task
is O
convolution Method
with O
fractional O
stride O
of O
in O
the O
LR Task
space O
as O
mentioned O
by O
, O
which O
can O
be O
naively O
implemented O
by O
interpolation Method
, O
perforate O
or O
un Method
- Method
pooling Method
from O
LR Task
space O
to O
HR O
space O
followed O
by O
a O
convolution Method
with O
a O
stride O
of O
in O
HR O
space O
. O
These O
implementations O
increase O
the O
computational Metric
cost Metric
by O
a O
factor O
of O
, O
since O
convolution Method
happens O
in O
HR O
space O
. O
Alternatively O
, O
a O
convolution Method
with O
stride O
of O
in O
the O
LR Task
space O
with O
a O
filter O
of O
size O
with O
weight O
spacing O
would O
activate O
different O
parts O
of O
for O
the O
convolution O
. O
The O
weights O
that O
fall O
between O
the O
pixels O
are O
simply O
not O
activated O
and O
do O
not O
need O
to O
be O
calculated O
. O
The O
number O
of O
activation O
patterns O
is O
exactly O
. O
Each O
activation O
pattern O
, O
according O
to O
its O
location O
, O
has O
at O
most O
weights O
activated O
. O
These O
patterns O
are O
periodically O
activated O
during O
the O
convolution O
of O
the O
filter Method
across O
the O
image Task
depending O
on O
different O
sub O
- O
pixel O
location O
: O
where O
are O
the O
output O
pixel O
coordinates O
in O
HR O
space O
. O
In O
this O
paper O
, O
we O
propose O
an O
effective O
way O
to O
implement O
the O
above O
operation O
when O
: O
where O
is O
an O
periodic Method
shuffling Method
operator Method
that O
rearranges O
the O
elements O
of O
a O
tensor O
to O
a O
tensor O
of O
shape O
. O
The O
effects O
of O
this O
operation O
are O
illustrated O
in O
Fig O
. O
[ O
reference O
] O
. O
Mathematically O
, O
this O
operation O
can O
be O
described O
in O
the O
following O
way O
The O
convolution Method
operator Method
thus O
has O
shape O
. O
Note O
that O
we O
do O
not O
apply O
nonlinearity O
to O
the O
outputs O
of O
the O
convolution Method
at O
the O
last O
layer O
. O
It O
is O
easy O
to O
see O
that O
when O
and O
it O
is O
equivalent O
to O
sub O
- O
pixel O
convolution O
in O
the O
LR Task
space O
with O
the O
filter Method
. O
We O
will O
refer O
to O
our O
new O
layer O
as O
the O
sub Method
- Method
pixel Method
convolution Method
layer Method
and O
our O
network O
as O
ESPCN Method
. O
This O
last O
layer O
produces O
a O
HR O
image Task
from O
LR Task
feature O
maps O
directly O
with O
one O
upscaling Method
filter Method
for O
each O
feature O
map O
as O
shown O
in O
Fig O
. O
[ O
reference O
] O
. O
Given O
a O
training O
set O
consisting O
of O
HR O
image Task
examples O
, O
we O
generate O
the O
corresponding O
LR Task
images O
, O
and O
calculate O
the O
pixel Metric
- Metric
wise Metric
MSE Metric
of Metric
the Metric
reconstruction Metric
as O
an O
objective Metric
function Metric
to O
train O
the O
network O
: O
It O
is O
noticeable O
that O
the O
implementation O
of O
the O
above O
periodic Method
shuffling Method
can O
be O
avoided O
in O
training O
time O
. O
Instead O
of O
shuffling O
the O
output O
as O
part O
of O
the O
layer O
, O
we O
can O
pre O
- O
shuffle O
the O
training O
data O
to O
match O
the O
output O
of O
the O
layer O
before O
. O
Thus O
our O
proposed O
layer O
is O
times O
faster O
compared O
to O
deconvolution Method
layer Method
in O
training Task
and O
times O
faster O
compared O
to O
implementations O
using O
various O
forms O
of O
upscaling Method
before Method
convolution Method
. O
section O
: O
Experiments O
[ O
Baboon O
Original O
] O
[ O
Bicubic Method
/ O
23.21db O
] O
[ O
SRCNN Method
/ O
23.67db O
] O
[ O
TNRD Method
/ O
23.62db O
] O
[ O
ESPCN Method
/ O
23.72db O
] O
[ O
Comic O
Original O
] O
[ O
Bicubic Method
/ O
23.12db O
] O
[ O
SRCNN Method
/ O
24.56db O
] O
[ O
TNRD Method
/ O
24.68db O
] O
[ O
ESPCN Method
/ O
24.82db O
] O
[ O
Monarch O
Original O
] O
[ O
Bicubic Method
/ O
29.43db O
] O
[ O
SRCNN Method
/ O
32.81db O
] O
[ O
TNRD Method
/ O
33.62db O
] O
[ O
ESPCN Method
/ O
33.66db O
] O
The O
detailed O
report O
of O
quantitative O
evaluation O
including O
the O
original O
data O
including O
images O
and O
videos O
, O
down O
- O
sampled O
data O
, O
super O
- O
resolved O
data O
, O
overall O
and O
individual O
scores O
and O
run Metric
- Metric
times Metric
on O
a O
K2 Method
GPU Method
are O
provided O
in O
the O
supplemental O
material O
. O
subsection O
: O
Datasets O
During O
the O
evaluation O
, O
we O
used O
publicly O
available O
benchmark O
datasets O
including O
the O
Timofte O
dataset O
widely O
used O
by O
SISR O
papers O
which O
provides O
source O
code O
for O
multiple O
methods O
, O
91 O
training O
images O
and O
two O
test O
datasets O
Set5 Material
and O
Set14 Material
which O
provides O
5 O
and O
14 O
images O
; O
The O
Berkeley O
segmentation O
dataset O
BSD300 O
and O
BSD500 O
which O
provides O
100 O
and O
200 O
images O
for O
testing O
and O
the O
super O
texture O
dataset O
which O
provides O
136 O
texture O
images O
. O
For O
our O
final O
models O
, O
we O
use O
50 O
, O
000 O
randomly O
selected O
images O
from O
ImageNet Method
for O
the O
training O
. O
Following O
previous O
works O
, O
we O
only O
consider O
the O
luminance O
channel O
in O
YCbCr O
colour O
space O
in O
this O
section O
because O
humans O
are O
more O
sensitive O
to O
luminance O
changes O
. O
For O
each O
upscaling O
factor O
, O
we O
train O
a O
specific O
network O
. O
For O
video O
experiments O
we O
use O
1080p O
HD O
videos O
from O
the O
publicly O
available O
Xiph Material
database Material
, O
which O
has O
been O
used O
to O
report O
video O
SR Task
results O
in O
previous O
methods O
. O
The O
database O
contains O
a O
collection O
of O
HD O
videos O
approximately O
seconds O
in O
length O
and O
with O
width O
and O
height O
. O
In O
addition O
, O
we O
also O
use O
the O
Ultra Material
Video Material
Group Material
database Material
, O
containing O
videos O
of O
in O
size O
and O
seconds O
in O
length O
. O
subsection O
: O
Implementation O
details O
[ O
14092 O
Original O
] O
[ O
Bicubic Method
/ O
29.06db O
] O
[ O
SRCNN Method
/ O
29.74db O
] O
[ O
TNRD Method
/ O
29.74db O
] O
[ O
ESPCN Method
/ O
29.78db O
] O
[ O
335094 O
Original O
] O
[ O
Bicubic Method
/ O
22.24db O
] O
[ O
SRCNN Method
/ O
23.96db O
] O
[ O
TNRD Method
/ O
24.15db O
] O
[ O
ESPCN Method
/ O
24.14db O
] O
[ O
384022 O
Original O
] O
[ O
Bicubic Method
/ O
25.42db O
] O
[ O
SRCNN Method
/ O
26.72db O
] O
[ O
TNRD Method
/ O
26.74db O
] O
[ O
ESPCN Method
/ O
26.86db O
] O
For O
the O
ESPCN Method
, O
we O
set O
, O
, O
and O
in O
our O
evaluations O
. O
The O
choice O
of O
the O
parameter O
is O
inspired O
by O
SRCNN Method
’s Method
3 Method
layer Method
9 O
- O
5 O
- O
5 O
model O
and O
the O
equations O
in O
Sec O
. O
[ O
reference O
] O
. O
In O
the O
training O
phase O
, O
pixel O
sub O
- O
images O
are O
extracted O
from O
the O
training O
ground O
truth O
images O
, O
where O
is O
the O
upscaling O
factor O
. O
To O
synthesize O
the O
low O
- O
resolution O
samples O
, O
we O
blur O
using O
a O
Gaussian Method
filter Method
and O
sub O
- O
sample O
it O
by O
the O
upscaling O
factor O
. O
The O
sub O
- O
images O
are O
extracted O
from O
original O
images O
with O
a O
stride O
of O
from O
and O
a O
stride O
of O
from O
. O
This O
ensures O
that O
all O
pixels O
in O
the O
original O
image Task
appear O
once O
and O
only O
once O
as O
the O
ground O
truth O
of O
the O
training O
data O
. O
We O
choose O
instead O
of O
as O
the O
activation O
function O
for O
the O
final O
model O
motivated O
by O
our O
experimental O
results O
. O
The O
training O
stops O
after O
no O
improvement O
of O
the O
cost O
function O
is O
observed O
after O
100 O
epochs O
. O
Initial Metric
learning Metric
rate Metric
is O
set O
to O
0.01 O
and O
final O
learning Metric
rate Metric
is O
set O
to O
0.0001 O
and O
updated O
gradually O
when O
the O
improvement O
of O
the O
cost O
function O
is O
smaller O
than O
a O
threshold O
. O
The O
final O
layer O
learns O
10 O
times O
slower O
as O
in O
. O
The O
training O
takes O
roughly O
three O
hours O
on O
a O
K2 Method
GPU Method
on O
91 O
images O
, O
and O
seven O
days O
on O
images O
from O
ImageNet Method
for O
upscaling O
factor O
of O
3 O
. O
We O
use O
the O
PSNR Metric
as O
the O
performance Metric
metric Metric
to O
evaluate O
our O
models O
. O
PSNR Metric
of O
SRCNN Method
and O
Chen Method
’s Method
models Method
on O
our O
extended O
benchmark O
set O
are O
calculated O
based O
on O
the O
Matlab Method
code Method
and O
models O
provided O
by O
. O
subsection O
: O
Image O
super Task
- Task
resolution Task
results O
subsubsection O
: O
Benefits O
of O
the O
sub Method
- Method
pixel Method
convolution Method
layer Method
In O
this O
section O
, O
we O
demonstrate O
the O
positive O
effect O
of O
the O
sub Method
- Method
pixel Method
convolution Method
layer Method
as O
well O
as O
activation O
function O
. O
We O
first O
evaluate O
the O
power O
of O
the O
sub Method
- Method
pixel Method
convolution Method
layer Method
by O
comparing O
against O
SRCNN Method
’s O
standard O
9 Method
- Method
1 Method
- Method
5 Method
model Method
. O
Here O
, O
we O
follow O
the O
approach O
in O
, O
using O
as O
the O
activation O
function O
for O
our O
models O
in O
this O
experiment O
, O
and O
training O
a O
set O
of O
models O
with O
91 O
images O
and O
another O
set O
with O
images O
from O
ImageNet Method
. O
The O
results O
are O
shown O
in O
Tab O
. O
[ O
reference O
] O
. O
ESPCN Method
with O
trained O
on O
ImageNet Method
images O
achieved O
statistically O
significantly O
better O
performance O
compared O
to O
SRCNN Method
models Method
. O
It O
is O
noticeable O
that O
ESPCN Method
( O
91 O
) O
performs O
very O
similar O
to O
SRCNN Method
( O
91 O
) O
. O
Training O
with O
more O
images O
using O
ESPCN Method
has O
a O
far O
more O
significant O
impact O
on O
PSNR Metric
compared O
to O
SRCNN Method
with O
similar O
number O
of O
parameters O
( O
+ O
0.33 O
vs O
+ O
0.07 O
) O
. O
To O
make O
a O
visual O
comparison O
between O
our O
model O
with O
the O
sub Method
- Method
pixel Method
convolution Method
layer Method
and O
SRCNN Method
, O
we O
visualized O
weights O
of O
our O
ESPCN Method
( O
ImageNet Method
) O
model O
against O
SRCNN Method
9 O
- O
5 O
- O
5 O
ImageNet Method
model O
from O
in O
Fig O
. O
[ O
reference O
] O
and O
Fig O
. O
[ O
reference O
] O
. O
The O
weights O
of O
our O
first O
and O
last Method
layer Method
filters Method
have O
a O
strong O
similarity O
to O
designed O
features O
including O
the O
log Method
- Method
Gabor Method
filters Method
, O
wavelets Method
and O
Haar O
features O
. O
It O
is O
noticeable O
that O
despite O
each O
filter O
is O
independent O
in O
LR Task
space O
, O
our O
independent Method
filters Method
is O
actually O
smooth O
in O
the O
HR O
space O
after O
. O
Compared O
to O
SRCNN Method
’s Method
last Method
layer Method
filters Method
, O
our O
final Method
layer Method
filters Method
has O
complex O
patterns O
for O
different O
feature O
maps O
, O
it O
also O
has O
much O
richer O
and O
more O
meaningful O
representations O
. O
We O
also O
evaluated O
the O
effect O
of O
activation O
function O
based O
on O
the O
above O
model O
trained O
on O
91 O
images O
and O
ImageNet Method
images O
. O
Results O
in O
Tab O
. O
[ O
reference O
] O
suggests O
that O
function O
performs O
better O
for O
SISR Method
compared O
to O
. O
The O
results O
for O
ImageNet Method
images O
with O
activation O
is O
shown O
in O
Tab O
. O
[ O
reference O
] O
. O
subsubsection O
: O
Comparison O
to O
the O
state O
- O
of O
- O
the O
- O
art O
In O
this O
section O
, O
we O
show O
ESPCN Method
trained O
on O
ImageNet Method
compared O
to O
results O
from O
SRCNN Method
and O
the O
TNRD Method
which O
is O
currently O
the O
best O
performing O
approach O
published O
. O
For O
simplicity O
, O
we O
do O
not O
show O
results O
which O
are O
known O
to O
be O
worse O
than O
. O
For O
the O
interested O
reader O
, O
the O
results O
of O
other O
previous O
methods O
can O
be O
found O
in O
. O
We O
choose O
to O
compare O
against O
the O
best O
SRCNN O
9 O
- O
5 O
- O
5 O
ImageNet Method
model O
in O
this O
section O
. O
And O
for O
, O
results O
are O
calculated O
based O
on O
the O
stages Method
model Method
. O
Our O
results O
shown O
in O
Tab O
. O
[ O
reference O
] O
are O
significantly O
better O
than O
the O
SRCNN O
9 O
- O
5 O
- O
5 O
ImageNet Method
model O
, O
whilst O
being O
close O
to O
, O
and O
in O
some O
cases O
out O
- O
performing O
, O
the O
TNRD Method
. O
Although O
TNRD Method
uses O
a O
single O
bicubic Method
interpolation Method
to O
upscale O
the O
input O
image Task
to O
HR O
space O
, O
it O
possibly O
benefits O
from O
a O
trainable Method
nonlinearity Method
function Method
. O
This O
trainable Method
nonlinearity Method
function Method
is O
not O
exclusive O
from O
our O
network O
and O
will O
be O
interesting O
to O
explore O
in O
the O
future O
. O
Visual O
comparison O
of O
the O
super O
- O
resolved O
images O
is O
given O
in O
Fig O
. O
[ O
reference O
] O
and O
Fig O
. O
[ O
reference O
] O
, O
the O
CNN Method
methods Method
create O
a O
much O
sharper O
and O
higher O
contrast O
images O
, O
ESPCN Method
provides O
noticeably O
improvement O
over O
SRCNN Method
. O
subsection O
: O
Video O
super Task
- Task
resolution Task
results O
In O
this O
section O
, O
we O
compare O
the O
ESPCN Method
trained O
models O
against O
single O
frame O
bicubic Method
interpolation Method
and O
SRCNN Method
on O
two O
popular O
video O
benchmarks O
. O
One O
big O
advantage O
of O
our O
network O
is O
its O
speed O
. O
This O
makes O
it O
an O
ideal O
candidate O
for O
video O
SR Task
which O
allows O
us O
to O
super O
- O
resolve O
the O
videos O
frame O
by O
frame O
. O
Our O
results O
shown O
in O
Tab O
. O
[ O
reference O
] O
and O
Tab O
. O
[ O
reference O
] O
are O
better O
than O
the O
SRCNN O
9 O
- O
5 O
- O
5 O
ImageNet Method
model O
. O
The O
improvement O
is O
more O
significant O
than O
the O
results O
on O
the O
image Task
data O
, O
this O
maybe O
due O
to O
differences O
between O
datasets O
. O
Similar O
disparity O
can O
be O
observed O
in O
different O
categories O
of O
the O
image Task
benchmark O
as O
Set5 Material
vs O
SuperTexture O
. O
subsection O
: O
Run Metric
time Metric
evaluations Metric
In O
this O
section O
, O
we O
evaluated O
our O
best O
model O
’s O
run Metric
time Metric
on O
Set14It O
should O
be O
noted O
our O
results O
outperform O
all O
other O
algorithms O
in O
accuracy Metric
on O
the O
larger O
BSD Material
datasets Material
. O
However O
, O
the O
use O
of O
Set14 Material
on O
a O
single O
CPU O
core O
is O
selected O
here O
in O
order O
to O
allow O
a O
straight O
- O
forward O
comparison O
with O
results O
from O
previous O
published O
results O
[ O
] O
. O
with O
an O
upscale O
factor O
of O
3 O
. O
We O
evaluate O
the O
run Metric
time Metric
of O
other O
methods O
from O
the O
Matlab Method
codes Method
provided O
by O
and O
. O
For O
methods O
which O
use O
convolutions Method
including O
our O
own O
, O
a O
python Method
/ Method
theano Method
implementation Method
is O
used O
to O
improve O
the O
efficiency O
based O
on O
the O
Matlab Method
codes Method
provided O
in O
. O
The O
results O
are O
presented O
in O
Fig O
. O
[ O
reference O
] O
. O
Our O
model O
runs O
a O
magnitude O
faster O
than O
the O
fastest O
methods O
published O
so O
far O
. O
Compared O
to O
SRCNN O
9 O
- O
5 O
- O
5 O
ImageNet Method
model O
, O
the O
number O
of O
convolution O
required O
to O
super O
- O
resolve O
one O
image Task
is O
times O
smaller O
and O
the O
number O
of O
total O
parameters O
of O
the O
model O
is O
times O
smaller O
. O
The O
total O
complexity Metric
of O
the O
super Task
- Task
resolution Task
operation O
is O
thus O
times O
lower O
. O
We O
have O
achieved O
a O
stunning O
average O
speed O
of O
for O
super O
- O
resolving O
one O
single O
image Task
from O
Set14 Material
on O
a O
K2 O
GPU O
. O
Utilising O
the O
amazing O
speed O
of O
the O
network O
, O
it O
will O
be O
interesting O
to O
explore O
ensemble Method
prediction Method
using O
independently O
trained O
models O
as O
discussed O
in O
to O
achieve O
better O
SR Task
performance O
in O
the O
future O
. O
We O
also O
evaluated O
run Metric
time Metric
of O
1080 O
HD O
video O
super Task
- Task
resolution Task
using O
videos O
from O
the O
Xiph Material
and O
the O
Ultra Material
Video Material
Group Material
database Material
. O
With O
upscale O
factor O
of O
3 O
, O
SRCNN O
9 O
- O
5 O
- O
5 O
ImageNet Method
model O
takes O
0.435s O
per O
frame O
whilst O
our O
ESPCN Method
model O
takes O
only O
0.038s O
per O
frame O
. O
With O
upscale O
factor O
of O
4 O
, O
SRCNN O
9 O
- O
5 O
- O
5 O
ImageNet Method
model O
takes O
0.434s O
per O
frame O
whilst O
our O
ESPCN Method
model O
takes O
only O
0.029s O
per O
frame O
. O
section O
: O
Conclusion O
In O
this O
paper O
, O
we O
demonstrate O
that O
a O
non Method
- Method
adaptive Method
upscaling Method
at O
the O
first O
layer O
provides O
worse O
results O
than O
an O
adaptive Method
upscaling Method
for O
SISR Method
and O
requires O
more O
computational Metric
complexity O
. O
To O
address O
the O
problem O
, O
we O
propose O
to O
perform O
the O
feature Method
extraction Method
stages Method
in O
the O
LR Task
space O
instead O
of O
HR O
space O
. O
To O
do O
that O
we O
propose O
a O
novel O
sub Method
- Method
pixel Method
convolution Method
layer Method
which O
is O
capable O
of O
super O
- O
resolving O
LR Task
data O
into O
HR O
space O
with O
very O
little O
additional O
computational Metric
cost Metric
compared O
to O
a O
deconvolution Method
layer Method
at O
training O
time O
. O
Evaluation O
performed O
on O
an O
extended O
bench O
mark O
data O
set O
with O
upscaling O
factor O
of O
4 O
shows O
that O
we O
have O
a O
significant O
speed O
( O
) O
and O
performance O
( O
+ O
0.15dB O
on O
Images O
and O
+ O
0.39dB O
on O
videos O
) O
boost O
compared O
to O
the O
previous O
CNN Method
approach Method
with O
more O
parameters O
( O
5 O
- O
3 O
- O
3 O
vs O
9 O
- O
5 O
- O
5 O
) O
. O
This O
makes O
our O
model O
the O
first O
CNN Method
model Method
that O
is O
capable O
of O
SR Task
HD Task
videos Task
in O
real O
time O
on O
a O
single O
GPU O
. O
section O
: O
Future O
work O
A O
reasonable O
assumption O
when O
processing O
video Task
information Task
is O
that O
most O
of O
a O
scene O
’s O
content O
is O
shared O
by O
neighbouring O
video O
frames O
. O
Exceptions O
to O
this O
assumption O
are O
scene O
changes O
and O
objects O
sporadically O
appearing O
or O
disappearing O
from O
the O
scene O
. O
This O
creates O
additional O
data O
- O
implicit O
redundancy O
that O
can O
be O
exploited O
for O
video Task
super Task
- Task
resolution Task
as O
has O
been O
shown O
in O
. O
Spatio Method
- Method
temporal Method
networks Method
are O
popular O
as O
they O
fully O
utilise O
the O
temporal O
information O
from O
videos O
for O
human Task
action Task
recognition Task
. O
In O
the O
future O
, O
we O
will O
investigate O
extending O
our O
ESPCN Method
network O
into O
a O
spatio Method
- Method
temporal Method
network Method
to O
super O
- O
resolve O
one O
frame O
from O
multiple O
neighbouring O
frames O
using O
3D Method
convolutions Method
. O
bibliography O
: O
References O
