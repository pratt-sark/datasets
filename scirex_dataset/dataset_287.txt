document O
: O
Instance Task
- Task
aware Task
Semantic Task
Segmentation Task
via O
Multi Method
- Method
task Method
Network Method
Cascades Method
Semantic Task
segmentation Task
research O
has O
recently O
witnessed O
rapid O
progress O
, O
but O
many O
leading O
methods O
are O
unable O
to O
identify O
object O
instances O
. O
In O
this O
paper O
, O
we O
present O
Multi Method
- Method
task Method
Network Method
Cascades Method
for O
instance Task
- Task
aware Task
semantic Task
segmentation Task
. O
Our O
model O
consists O
of O
three O
networks O
, O
respectively O
differentiating O
instances O
, O
estimating O
masks O
, O
and O
categorizing O
objects O
. O
These O
networks O
form O
a O
cascaded Method
structure Method
, O
and O
are O
designed O
to O
share O
their O
convolutional O
features O
. O
We O
develop O
an O
algorithm O
for O
the O
nontrivial O
end Task
- Task
to Task
- Task
end Task
training Task
of O
this O
causal Method
, Method
cascaded Method
structure Method
. O
Our O
solution O
is O
a O
clean O
, O
single Method
- Method
step Method
training Method
framework Method
and O
can O
be O
generalized O
to O
cascades O
that O
have O
more O
stages O
. O
We O
demonstrate O
state O
- O
of O
- O
the O
- O
art O
instance Metric
- Metric
aware Metric
semantic Metric
segmentation Metric
accuracy Metric
on O
PASCAL Material
VOC Material
. O
Meanwhile O
, O
our O
method O
takes O
only O
360ms O
testing O
an O
image O
using O
VGG Method
- Method
16 Method
, O
which O
is O
two O
orders O
of O
magnitude O
faster O
than O
previous O
systems O
for O
this O
challenging O
problem O
. O
As O
a O
by O
product O
, O
our O
method O
also O
achieves O
compelling O
object Task
detection Task
results O
which O
surpass O
the O
competitive O
Fast Method
/ Method
Faster Method
R Method
- Method
CNN Method
systems Method
. O
The O
method O
described O
in O
this O
paper O
is O
the O
foundation O
of O
our O
submissions O
to O
the O
MS O
COCO Task
2015 Task
segmentation O
competition O
, O
where O
we O
won O
the O
1st O
place O
. O
section O
: O
Introduction O
Since O
the O
development O
of O
fully Method
convolutional Method
networks Method
( O
FCNs Method
) O
, O
the O
accuracy Metric
of O
semantic Task
segmentation Task
has O
been O
improved O
rapidly O
thanks O
to O
deeply O
learned O
features O
, O
large O
- O
scale O
annotations O
, O
and O
advanced O
reasoning Method
over O
graphical Method
models Method
. O
Nevertheless O
, O
FCNs Method
and O
improvements O
are O
designed O
to O
predict O
a O
category O
label O
for O
each O
pixel O
, O
but O
are O
unaware O
of O
individual O
object O
instances O
. O
Accurate O
and O
fast O
instance Task
- Task
aware Task
semantic Task
segmentation Task
is O
still O
a O
challenging O
problem O
. O
To O
encourage O
the O
research O
on O
this O
problem O
, O
the O
recently O
established O
COCO Material
dataset Material
and O
competition O
only O
accept O
instance Task
- Task
aware Task
semantic Task
segmentation Task
results O
. O
There O
have O
been O
a O
few O
methods O
addressing O
instance Task
- Task
aware Task
semantic Task
segmentation Task
using O
convolutional Method
neural Method
networks Method
( O
CNNs Method
) O
. O
These O
methods O
all O
require O
mask Method
proposal Method
methods Method
that O
are O
slow O
at O
inference O
time O
. O
In O
addition O
, O
these O
mask Method
proposal Method
methods Method
take O
no O
advantage O
of O
deeply O
learned O
features O
or O
large O
- O
scale O
training O
data O
, O
and O
may O
become O
a O
bottleneck O
for O
segmentation Metric
accuracy Metric
. O
In O
this O
work O
, O
we O
address O
instance Task
- Task
aware Task
semantic Task
segmentation Task
solely O
based O
on O
CNNs Method
, O
without O
using O
external Method
modules Method
( O
, O
) O
. O
We O
observe O
that O
the O
instance Task
- Task
aware Task
semantic Task
segmentation Task
task Task
can O
be O
decomposed O
into O
three O
different O
and O
related O
sub O
- O
tasks O
. O
1 O
) O
Differentiating Task
instances Task
. O
In O
this O
sub Task
- Task
task Task
, O
the O
instances O
can O
be O
represented O
by O
bounding O
boxes O
that O
are O
class Method
- Method
agnostic Method
. O
2 O
) O
Estimating O
masks O
. O
In O
this O
sub Task
- Task
task Task
, O
a O
pixel O
- O
level O
mask O
is O
predicted O
for O
each O
instance O
. O
3 O
) O
Categorizing Task
objects Task
. O
In O
this O
sub Task
- Task
task Task
, O
the O
category O
- O
wise O
label O
is O
predicted O
for O
each O
mask Method
- Method
level Method
instance Method
. O
We O
expect O
that O
each O
sub Task
- Task
task Task
is O
simpler O
than O
the O
original O
instance Task
segmentation Task
task Task
, O
and O
is O
more O
easily O
addressed O
by O
convolutional Method
networks Method
. O
Driven O
by O
this O
decomposition O
, O
we O
propose O
Multi Method
- Method
task Method
Network Method
Cascades Method
( O
MNCs Method
) O
for O
accurate Task
and Task
fast Task
instance Task
- Task
aware Task
semantic Task
segmentation Task
. O
Our O
network Method
cascades Method
have O
three O
stages O
, O
each O
of O
which O
addresses O
one O
sub O
- O
task O
. O
The O
three O
stages O
share O
their O
features O
, O
as O
in O
traditional O
multi Task
- Task
task Task
learning Task
. O
Feature Method
sharing Method
greatly O
reduces O
the O
test Task
- Task
time Task
computation Task
, O
and O
may O
also O
improve O
feature Method
learning Method
thanks O
to O
the O
underlying O
commonality O
among O
the O
tasks O
. O
But O
unlike O
many O
multi Task
- Task
task Task
learning Task
applications Task
, O
in O
our O
method O
a O
later O
stage O
depends O
on O
the O
outputs O
of O
an O
earlier O
stage O
, O
forming O
a O
causal O
cascade O
( O
see O
Fig O
. O
[ O
reference O
] O
) O
. O
So O
we O
call O
our O
structures O
“ O
multi Task
- Task
task Task
cascades Task
” O
. O
Training O
a O
multi Task
- Task
task Task
cascade Task
is O
nontrivial O
because O
of O
the O
causal O
relations O
among O
the O
multiple O
outputs O
. O
For O
example O
, O
our O
mask Method
estimating Method
layer Method
takes O
convolutional O
features O
and O
predicted O
box O
instances O
as O
inputs O
, O
both O
of O
which O
are O
outputs O
of O
other O
layers O
. O
According O
to O
the O
chain Method
rule Method
of Method
backpropagation Method
, O
the O
gradients O
involve O
those O
with O
respect O
to O
the O
convolution O
responses O
and O
also O
those O
with O
respect O
to O
the O
spatial O
coordinates O
of O
predicted O
boxes O
. O
To O
achieve O
theoretically O
valid O
backpropagation O
, O
we O
develop O
a O
layer Method
that O
is O
differentiable O
with O
respect O
to O
the O
spatial O
coordinates O
, O
so O
the O
gradient O
terms O
can O
be O
computed O
. O
Our O
cascade Method
model Method
can O
thus O
be O
trained O
end O
- O
to O
- O
end O
via O
a O
clean Method
, Method
single Method
- Method
step Method
framework Method
. O
This O
single O
- O
step O
training Method
algorithm Method
naturally O
produces O
convolutional O
features O
that O
are O
shared O
among O
the O
three O
sub O
- O
tasks O
, O
which O
are O
beneficial O
to O
both O
accuracy Metric
and O
speed Metric
. O
Meanwhile O
, O
under O
this O
training Method
framework Method
, O
our O
cascade Method
model Method
can O
be O
extended O
to O
more O
stages O
, O
leading O
to O
improvements O
on O
accuracy Metric
. O
We O
comprehensively O
evaluate O
our O
method O
on O
the O
PASCAL Material
VOC Material
dataset Material
. O
Our O
method O
results O
in O
63.5 O
% O
mean O
Average O
Precision O
( O
mAP Metric
) O
, O
about O
3.0 O
% O
higher O
than O
the O
previous O
best O
results O
using O
the O
same O
VGG Method
network Method
. O
Remarkably O
, O
this O
result O
is O
obtained O
at O
a O
test Metric
- Metric
time Metric
speed Metric
of O
360ms O
per O
image O
, O
which O
is O
two O
orders O
of O
magnitudes O
faster O
than O
previous O
systems O
. O
Thanks O
to O
the O
end O
- O
to O
- O
end O
training O
and O
the O
independence O
of O
external Method
modules Method
, O
the O
three O
sub O
- O
tasks O
and O
the O
entire O
system O
easily O
benefit O
from O
stronger O
features O
learned O
by O
deeper Method
models Method
. O
We O
demonstrate O
excellent O
accuracy Metric
on O
the O
challenging O
MS Material
COCO Material
segmentation Material
dataset Material
using O
an O
extremely O
deep O
101 Method
- Method
layer Method
residual Method
net Method
( O
ResNet Method
- Method
101 Method
) O
, O
and O
also O
report O
our O
1st O
- O
place O
result O
in O
the O
COCO Task
segmentation Task
track O
in O
ILSVRC Task
& O
COCO Task
2015 Task
competitions O
. O
section O
: O
Related O
Work O
Object Method
detection Method
methods Method
involve O
predicting Task
object Task
bounding Task
boxes Task
and O
categories O
. O
The O
work O
of O
R Method
- Method
CNN Method
adopts O
region Method
proposal Method
methods Method
( O
, O
) O
for O
producing O
multiple Task
instance Task
proposals Task
, O
which O
are O
used O
for O
CNN Task
- Task
based Task
classification Task
. O
In O
SPPnet Method
and O
Fast Method
R Method
- Method
CNN Method
, O
the O
convolutional Method
layers Method
of Method
CNNs Method
are O
shared O
on O
the O
entire O
image O
for O
fast Task
computation Task
. O
Faster O
R Method
- Method
CNN Method
exploits O
the O
shared O
convolutional O
features O
to O
extract O
region O
proposals O
used O
by O
the O
detector O
. O
Sharing Method
convolutional Method
features Method
leads O
to O
substantially O
faster O
speed Metric
for O
object Task
detection Task
systems Task
. O
Using O
mask Method
- Method
level Method
region Method
proposals Method
, O
instance Task
- Task
aware Task
semantic Task
segmentation Task
can O
be O
addressed O
based O
on O
the O
R Method
- Method
CNN Method
philosophy Method
, O
as O
in O
R Method
- Method
CNN Method
, O
SDS Method
, O
and O
Hypercolumn Method
. O
Sharing O
convolutional O
features O
among O
mask O
- O
level O
proposals O
is O
enabled O
by O
using O
masking Method
layers Method
. O
All O
these O
methods O
rely O
on O
computationally O
expensive O
mask Method
proposal Method
methods Method
. O
For O
example O
, O
the O
widely O
used O
MCG Method
takes O
30 O
seconds O
processing O
an O
image O
, O
which O
becomes O
a O
bottleneck O
at O
inference O
time O
. O
DeepMask Method
is O
recently O
developed O
for O
learning Task
segmentation Task
candidates Task
using O
convolutional Method
networks Method
, O
taking O
over O
1 O
second O
per O
image O
. O
Its O
accuracy Metric
for O
instance Task
- Task
aware Task
semantic Task
segmentation Task
is O
yet O
to O
be O
evaluated O
. O
Category Task
- Task
wise Task
semantic Task
segmentation Task
is O
elegantly O
tackled O
by O
end O
- O
to O
- O
end Method
training Method
FCNs Method
. O
The O
output O
of O
an O
FCN Method
consists O
of O
multiple O
score Method
maps Method
, O
each O
of O
which O
is O
for O
one O
category O
. O
This O
formulation O
enables O
per Task
- Task
pixel Task
regression Task
in O
a O
fully Method
- Method
convolutional Method
form Method
, O
but O
is O
not O
able O
to O
distinguish O
instances O
of O
the O
same O
category O
. O
The O
FCN Method
framework Method
has O
been O
further O
improved O
in O
many O
papers O
( O
, O
) O
, O
but O
these O
methods O
also O
have O
the O
limitations O
of O
not O
being O
able O
to O
predict O
instances O
. O
section O
: O
Multi Method
- Method
task Method
Network Method
Cascades Method
In O
our O
MNC Method
model Method
, O
the O
network O
takes O
an O
image O
of O
arbitrary O
size O
as O
the O
input O
, O
and O
outputs O
instance Task
- Task
aware Task
semantic Task
segmentation Task
results O
. O
The O
cascade O
has O
three O
stages O
: O
proposing O
box O
- O
level O
instances O
, O
regressing O
mask O
- O
level O
instances O
, O
and O
categorizing O
each O
instance O
. O
These O
three O
stages O
are O
designed O
to O
share O
convolutional O
features O
( O
, O
the O
13 O
convolutional Method
layers Method
in O
VGG Method
- Method
16 Method
) O
. O
Each O
stage O
involves O
a O
loss O
term O
, O
but O
a O
later O
stage O
’s O
loss O
relies O
on O
the O
output O
of O
an O
earlier O
stage O
, O
so O
the O
three O
loss O
terms O
are O
not O
independent O
. O
We O
train O
the O
entire O
network O
cascade O
end O
- O
to O
- O
end O
with O
a O
unified Method
loss Method
function Method
. O
Fig O
. O
[ O
reference O
] O
illustrates O
our O
cascade Method
model Method
. O
In O
this O
section O
we O
describe O
the O
definition O
for O
each O
stage O
. O
In O
the O
next O
section O
we O
introduce O
an O
end Method
- Method
to Method
- Method
end Method
training Method
algorithm Method
to O
address O
the O
causal O
dependency O
. O
subsection O
: O
Regressing O
Box O
- O
level O
Instances O
In O
the O
first O
stage O
, O
the O
network O
proposes O
object O
instances O
in O
the O
form O
of O
bounding O
boxes O
. O
These O
bounding O
boxes O
are O
class O
- O
agnostic O
, O
and O
are O
predicted O
with O
an O
objectness Metric
score Metric
. O
The O
network O
structure O
and O
loss O
function O
of O
this O
stage O
follow O
the O
work O
of O
Region Method
Proposal Method
Networks Method
( O
RPNs Method
) O
, O
which O
we O
briefly O
describe O
as O
follows O
for O
completeness O
. O
An O
RPN Method
predicts O
bounding O
box O
locations O
and O
objectness O
scores O
in O
a O
fully Method
- Method
convolutional Method
form Method
. O
On O
top O
of O
the O
shared O
features O
, O
a O
3 Method
3 Method
convolutional Method
layer Method
is O
used O
for O
reducing O
dimensions O
, O
followed O
by O
two O
sibling Method
1 Method
1 Method
convolutional Method
layers Method
for O
regressing Task
box Task
locations Task
and O
classifying Task
object Task
/ Task
non Task
- Task
object Task
. O
The O
box Method
regression Method
is O
with O
reference O
to O
a O
series O
of O
pre O
- O
defined O
boxes O
( O
called O
“ O
anchors O
” O
) O
at O
each O
location O
. O
We O
use O
the O
RPN Method
loss Method
function Method
given O
in O
. O
This O
loss Method
function Method
serves O
as O
the O
loss O
term O
of O
our O
stage O
1 O
. O
It O
has O
a O
form O
of O
: O
Here O
represents O
all O
network O
parameters O
to O
be O
optimized O
. O
is O
the O
network O
output O
of O
this O
stage O
, O
representing O
a O
list O
of O
boxes O
: O
and O
, O
where O
is O
a O
box O
indexed O
by O
. O
The O
box O
is O
centered O
at O
with O
width O
and O
height O
, O
and O
is O
the O
objectness O
probability O
. O
The O
notations O
in O
Eqn O
. O
( O
[ O
reference O
] O
) O
indicate O
that O
the O
box O
predictions O
are O
functions O
of O
the O
network O
parameters O
. O
subsection O
: O
Regressing O
Mask O
- O
level O
Instances O
The O
second O
stage O
takes O
the O
shared O
convolutional O
features O
and O
stage O
- O
1 O
boxes O
as O
input O
. O
It O
outputs O
a O
pixel Method
- Method
level Method
segmentation Method
mask Method
for O
each O
box O
proposal O
. O
In O
this O
stage O
, O
a O
mask Method
- Method
level Method
instance Method
is O
still O
class O
- O
agnostic O
. O
Given O
a O
box O
predicted O
by O
stage O
1 O
, O
we O
extract O
a O
feature O
of O
this O
box O
by O
Region Method
- Method
of Method
- Method
Interest Method
( O
RoI Method
) O
pooling O
. O
The O
purpose O
of O
RoI Method
pooling O
is O
for O
producing O
a O
fixed O
- O
size O
feature O
from O
an O
arbitrary O
box O
, O
which O
is O
set O
as O
14 O
14 O
at O
this O
stage O
. O
We O
append O
two O
extra O
fully Method
- Method
connected Method
( O
fc Method
) O
layers O
to O
this O
feature O
for O
each O
box O
. O
The O
first O
fc Method
layer O
( O
with O
ReLU Method
) O
reduces O
the O
dimension O
to O
256 O
, O
followed O
by O
the O
second O
fc Method
layer O
that O
regresses O
a O
pixel O
- O
wise O
mask O
. O
This O
mask O
, O
of O
a O
pre O
- O
defined O
spatial O
resolution O
of O
( O
we O
use O
) O
, O
is O
parameterized O
by O
an O
- O
dimensional O
vector O
. O
The O
second O
fc Method
layer O
has O
outputs O
, O
each O
performing O
binary Method
logistic Method
regression Method
to O
the O
ground O
truth O
mask O
. O
With O
these O
definitions O
, O
the O
loss O
term O
of O
stage O
2 O
for O
regressing Task
masks Task
exhibits O
the O
following O
form O
: O
Here O
is O
the O
network O
outputs O
of O
this O
stage O
, O
representing O
a O
list O
of O
masks O
: O
and O
is O
an O
- O
dimensional O
logistic Method
regression Method
output Method
( O
via O
sigmoid Method
) O
taking O
continuous O
values O
in O
. O
Eqn O
. O
( O
[ O
reference O
] O
) O
indicates O
that O
the O
mask Task
regression Task
loss Task
is O
dependent O
on O
but O
also O
on O
. O
As O
a O
related O
method O
, O
DeepMask Method
also O
regresses O
discretized O
masks O
. O
DeepMask Method
applies O
the O
regression Method
layers Method
to O
dense O
sliding O
windows O
( O
fully O
- O
convolutionally O
) O
, O
but O
our O
method O
only O
regresses O
masks O
from O
a O
few O
proposed O
boxes O
and O
so O
reduces O
computational Metric
cost Metric
. O
Moreover O
, O
mask Method
regression Method
is O
only O
one O
stage O
in O
our O
network Method
cascade Method
that O
shares O
features O
among O
multiple O
stages O
, O
so O
the O
marginal Metric
cost Metric
of O
the O
mask Method
regression Method
layers Method
is O
very O
small O
. O
subsection O
: O
Categorizing Task
Instances Task
The O
third O
stage O
takes O
the O
shared O
convolutional O
features O
, O
stage O
- O
1 O
boxes O
, O
and O
stage O
- O
2 O
masks O
as O
input O
. O
It O
outputs O
category O
scores O
for O
each O
instance O
. O
Given O
a O
box O
predicted O
by O
stage O
1 O
, O
we O
also O
extract O
a O
feature O
by O
RoI Method
pooling O
. O
This O
feature O
map O
is O
then O
“ O
masked O
” O
by O
the O
stage Method
- Method
2 Method
mask Method
prediction Method
, O
inspired O
by O
the O
feature Method
masking Method
strategy Method
in O
. O
This O
leads O
to O
a O
feature O
focused O
on O
the O
foreground O
of O
the O
prediction O
mask O
. O
The O
masked O
feature O
is O
given O
by O
element Method
- Method
wise Method
product Method
: O
Here O
is O
the O
feature O
after O
RoI Method
pooling O
, O
is O
a O
mask Method
prediction Method
from O
stage O
2 O
( O
resized O
to O
the O
RoI Method
resolution O
) O
, O
and O
represents O
element Method
- Method
wise Method
product Method
. O
The O
masked O
feature O
is O
dependent O
on O
. O
Two O
4096 O
- O
d O
fc Method
layers O
are O
applied O
on O
the O
masked O
feature O
. O
This O
is O
a O
mask Method
- Method
based Method
pathway Method
. O
Following O
, O
we O
also O
use O
another O
box Method
- Method
based Method
pathway Method
, O
where O
the O
RoI Method
pooled O
features O
directly O
fed O
into O
two O
4096 O
- O
d O
fc Method
layers O
( O
this O
pathway O
is O
not O
illustrated O
in O
Fig O
. O
[ O
reference O
] O
) O
. O
The O
mask Method
- Method
based Method
and Method
box Method
- Method
based Method
pathways Method
are O
concatenated O
. O
On O
top O
of O
the O
concatenation Method
, O
a O
softmax Method
classifier Method
of O
+ O
1 O
ways O
is O
used O
for O
predicting O
categories O
plus O
one O
background O
category O
. O
The O
box Method
- Method
level Method
pathway Method
may O
address O
the O
cases O
when O
the O
feature O
is O
mostly O
masked O
out O
by O
the O
mask Method
- Method
level Method
pathway Method
( O
, O
on O
background O
) O
. O
The O
loss O
term O
of O
stage O
3 O
exhibits O
the O
following O
form O
: O
Here O
is O
the O
network O
outputs O
of O
this O
stage O
, O
representing O
a O
list O
of O
category O
predictions O
for O
all O
instances O
: O
. O
This O
loss Method
term Method
is O
dependent O
on O
and O
( O
where O
is O
used O
for O
generating O
the O
RoI Method
feature O
) O
. O
section O
: O
End Task
- Task
to Task
- Task
End Task
Training Task
We O
define O
the O
loss O
function O
of O
the O
entire O
cascade O
as O
: O
where O
balance O
weights O
of O
1 O
are O
implicitly O
used O
among O
the O
three O
terms O
. O
is O
minimized O
the O
network O
parameters O
. O
This O
loss Method
function Method
is O
unlike O
traditional O
multi Method
- Method
task Method
learning Method
, O
because O
the O
loss O
term O
of O
a O
later O
stage O
depends O
on O
the O
output O
of O
the O
earlier O
ones O
. O
For O
example O
, O
based O
on O
the O
chain Method
rule Method
of Method
backpropagation Method
, O
the O
gradient O
of O
involves O
the O
gradients O
. O
The O
main O
technical O
challenge O
of O
applying O
the O
chain Method
rule Method
to O
Eqn O
. O
( O
[ O
reference O
] O
) O
lies O
on O
the O
spatial O
transform O
of O
a O
predicted O
box O
that O
determines O
RoI Method
pooling O
. O
For O
the O
RoI Method
pooling O
layer O
, O
its O
inputs O
are O
a O
predicted O
box O
and O
the O
convolutional Method
feature Method
map Method
, O
both O
being O
functions O
of O
. O
In O
Fast Method
R Method
- Method
CNN Method
, O
the O
box O
proposals O
are O
pre O
- O
computed O
and O
fixed O
, O
and O
the O
backpropagation O
of O
RoI Method
pooling O
layer O
in O
only O
involves O
. O
However O
, O
this O
is O
not O
the O
case O
in O
the O
presence O
of O
. O
Gradients O
of O
both O
terms O
need O
to O
be O
considered O
in O
a O
theoretically O
sound O
end O
- O
to O
- O
end Task
training Task
solution Task
. O
In O
this O
section O
, O
we O
develop O
a O
differentiable O
RoI Method
warping O
layer O
to O
account O
for O
the O
gradient O
predicted O
box O
positions O
and O
address O
the O
dependency O
on O
. O
The O
dependency O
on O
is O
also O
tackled O
accordingly O
. O
Differentiable O
RoI Method
Warping O
Layers O
. O
The O
RoI Method
pooling O
layer O
performs O
max Method
pooling Method
on O
a O
discrete O
grid O
based O
on O
a O
box O
. O
To O
derive O
a O
form O
that O
is O
differentiable O
the O
box O
position O
, O
we O
perform O
RoI Method
pooling O
by O
a O
differentiable O
RoI Method
warping O
layer O
followed O
by O
standard O
max Method
pooling Method
. O
The O
RoI Method
warping O
layer O
crops O
a O
feature O
map O
region O
and O
warps O
it O
into O
a O
target O
size O
by O
interpolation O
. O
We O
use O
to O
denote O
the O
full Task
- Task
image Task
convolutional Task
feature Task
map Task
. O
Given O
a O
predicted O
box O
centered O
at O
with O
width O
and O
height O
, O
an O
RoI Method
warping O
layer O
interpolates O
the O
features O
inside O
the O
box O
and O
outputs O
a O
feature O
of O
a O
fixed O
spatial O
resolution O
. O
This O
operation O
can O
be O
written O
as O
linear Method
transform Method
on O
the O
feature O
map O
: O
Here O
is O
reshaped O
as O
an O
- O
dimensional O
vector O
, O
with O
for O
a O
full O
- O
image O
feature O
map O
of O
a O
spatial O
size O
. O
represents O
the O
cropping Task
and Task
warping Task
operations Task
, O
and O
is O
an O
- O
by O
- O
matrix O
where O
corresponds O
to O
the O
pre O
- O
defined O
RoI Method
warping O
output O
resolution O
. O
is O
an O
- O
dimensional O
vector O
representing O
the O
RoI Method
warping O
output O
. O
We O
note O
that O
these O
operations O
are O
performed O
for O
each O
channel O
independently O
. O
The O
computation O
in O
Eqn O
. O
( O
[ O
reference O
] O
) O
has O
this O
form O
: O
where O
the O
notations O
in O
Eqn O
. O
( O
[ O
reference O
] O
) O
are O
omitted O
for O
simplifying O
presentation O
. O
Here O
represent O
a O
spatial O
position O
in O
the O
target O
feature O
map O
, O
and O
run O
over O
the O
full O
- O
image O
feature O
map O
. O
The O
function O
represents O
transforming O
a O
proposed O
box O
from O
a O
size O
of O
into O
another O
size O
of O
. O
Using O
bilinear Method
interpolation Method
, O
is O
separable O
: O
where O
: O
where O
is O
the O
bilinear O
interpolation O
function O
, O
and O
maps O
the O
position O
of O
to O
the O
full O
- O
image O
feature O
map O
domain O
. O
is O
defined O
similarly O
. O
We O
note O
that O
because O
is O
non O
- O
zero O
in O
a O
small O
interval O
, O
the O
actual O
computation O
of O
Eqn O
. O
( O
[ O
reference O
] O
) O
involves O
a O
very O
few O
terms O
. O
According O
to O
the O
chain Method
rule Method
, O
for O
backpropagation Task
involving Task
Eqn Task
. O
( O
[ O
reference O
] O
) O
we O
need O
to O
compute O
: O
where O
we O
use O
to O
denote O
, O
, O
, O
and O
for O
simplicity O
. O
The O
term O
in O
Eqn O
. O
( O
[ O
reference O
] O
) O
can O
be O
derived O
from O
Eqn O
. O
( O
[ O
reference O
] O
) O
. O
As O
such O
, O
the O
RoI Method
warping O
layer O
can O
be O
trained O
with O
any O
preceding Method
/ Method
succeding Method
layers Method
. O
If O
the O
boxes O
are O
constant O
( O
, O
given O
by O
Selective O
Search O
) O
, O
Eqn O
. O
( O
[ O
reference O
] O
) O
is O
not O
needed O
, O
which O
becomes O
the O
case O
of O
the O
existing O
RoI Method
pooling O
in O
. O
After O
the O
differentiable O
RoI Method
warping O
layer O
, O
we O
append O
a O
max Method
pooling Method
layer Method
to O
perform O
the O
RoI Method
max O
pooling O
behavior O
. O
We O
expect O
the O
RoI Method
warping O
layer O
to O
produce O
a O
sufficiently O
fine Metric
resolution Metric
, O
which O
is O
set O
as O
in O
this O
paper O
. O
A O
max Method
pooling Method
layer Method
is O
then O
applied O
to O
produce O
a O
lower O
- O
resolution O
output O
, O
, O
7 O
7 O
for O
VGG Method
- Method
16 Method
. O
The O
RoI Method
warping O
layer O
shares O
similar O
motivations O
with O
the O
recent O
work O
of O
Spatial Method
Transformer Method
Networks Method
. O
In O
, O
a O
spatial Method
transformation Method
of O
the O
entire O
image O
is O
learned O
, O
which O
is O
done O
by O
feature Method
interpolation Method
that O
is O
differentiable O
the O
transformation O
parameters O
. O
The O
networks O
in O
are O
used O
for O
image Task
classification Task
. O
Our O
RoI Method
warping O
layer O
is O
also O
driven O
by O
the O
differentiable O
property O
of O
interpolating O
features O
. O
But O
the O
RoI Method
warping O
layer O
is O
applied O
to O
multiple O
proposed O
boxes O
that O
are O
of O
interest O
, O
instead O
of O
the O
entire O
image O
. O
The O
RoI Method
warping O
layer O
has O
a O
pre O
- O
defined O
output O
size O
and O
arbitrary O
input O
sizes O
, O
in O
contrast O
to O
. O
Masking O
Layers O
. O
We O
also O
compute O
the O
gradients O
involved O
in O
, O
where O
the O
dependency O
on O
and O
is O
determined O
by O
Eqn O
. O
( O
[ O
reference O
] O
) O
. O
With O
the O
differentiable O
RoI Method
warping O
module O
( O
) O
, O
the O
operations O
in O
Eqn O
. O
( O
[ O
reference O
] O
) O
can O
be O
simply O
implemented O
by O
an O
element Method
- Method
wise Method
product Method
module Method
. O
In O
summary O
, O
given O
the O
differentiable O
RoI Method
warping O
module O
, O
we O
have O
all O
the O
necessary O
components O
for O
backpropagation Method
( O
other O
components O
are O
either O
standard O
, O
or O
trivial O
to O
implement O
) O
. O
We O
train O
the O
model O
by O
stochastic Method
gradient Method
descent Method
( Method
SGD Method
) Method
, O
implemented O
in O
the O
Caffe Method
library Method
. O
section O
: O
Cascades O
with O
More O
Stages O
Next O
we O
extend O
the O
cascade Method
model Method
to O
more O
stages O
within O
the O
above O
MNC Method
framework Method
. O
In O
Fast Method
R Method
- Method
CNN Method
, O
the O
( Method
+ Method
1 Method
)- Method
way Method
classifier Method
is O
trained O
jointly O
with O
class Method
- Method
wise Method
bounding Method
box Method
regression Method
. O
Inspired O
by O
this O
practice O
, O
on O
stage O
3 O
, O
we O
add O
a O
4 O
( O
+ O
1 O
)- O
d O
fc Method
layer O
for O
regression Task
class Task
- Task
wise Task
bounding Task
boxes Task
, O
which O
is O
a O
sibling Method
layer Method
with O
the O
classifier Method
layer Method
. O
The O
entire O
3 Method
- Method
stage Method
network Method
cascade Method
is O
trained O
as O
in O
Sec O
. O
[ O
reference O
] O
. O
The O
inference Method
step Method
with O
box Method
regression Method
, O
however O
, O
is O
not O
as O
straightforward O
as O
in O
object Task
detection Task
, O
because O
our O
ultimate O
outputs O
are O
masks O
instead O
of O
boxes O
. O
So O
during O
inference Task
, O
we O
first O
run O
the O
entire O
3 Method
- Method
stage Method
network Method
and O
obtain O
the O
regressed O
boxes O
on O
stage O
3 O
. O
These O
boxes O
are O
then O
considered O
as O
new O
proposals O
. O
Stages O
2 O
and O
3 O
are O
performed O
for O
the O
second O
time O
on O
these O
proposals O
. O
This O
is O
in O
fact O
5 Task
- Task
stage Task
inference Task
. O
Its O
inference O
- O
time O
structure O
is O
illustrated O
in O
Fig O
. O
[ O
reference O
] O
. O
The O
new O
stages O
4 O
and O
5 O
share O
the O
same O
structures O
as O
stages O
2 O
and O
3 O
, O
except O
that O
they O
use O
the O
regressed O
boxes O
from O
stage O
3 O
as O
the O
new O
proposals O
. O
This O
inference Method
process Method
can O
be O
iterated O
, O
but O
we O
have O
observed O
negligible O
gains O
. O
Given O
the O
above O
5 Method
- Method
stage Method
cascade Method
structure Method
( O
Fig O
. O
[ O
reference O
] O
) O
, O
it O
is O
easy O
to O
adopt O
our O
algorithm O
in O
Sec O
. O
[ O
reference O
] O
to O
train O
this O
cascade O
end O
- O
to O
- O
end O
by O
backpropagation Method
. O
Training O
the O
model O
in O
this O
way O
makes O
the O
training O
- O
time O
structure O
consistent O
with O
the O
inference O
- O
time O
structure O
, O
which O
improves O
accuracy Metric
as O
will O
be O
shown O
by O
experiments O
. O
It O
is O
possible O
to O
train O
a O
cascade Method
with O
even O
more O
stages O
in O
this O
way O
. O
But O
due O
to O
concerns O
on O
fast Task
inference Task
, O
we O
only O
present O
MNCs Method
with O
up O
to O
5 O
stages O
. O
section O
: O
Implementation O
Details O
Non Method
- Method
maximum Method
suppression Method
. O
On O
stage O
1 O
, O
the O
network O
produces O
regressed O
boxes O
. O
For O
generating O
the O
proposals O
for O
stage O
2 O
, O
we O
use O
non Method
- Method
maximum Method
suppression Method
( O
NMS Method
) O
to O
reduce O
redundant O
candidates O
. O
The O
threshold O
of O
the O
Intersection O
- O
over O
- O
Union O
( O
IoU Metric
) O
ratio O
for O
this O
NMS Method
is O
0.7 O
as O
in O
. O
After O
that O
, O
the O
top O
- O
ranked O
300 O
boxes O
will O
be O
used O
for O
stage O
2 O
. O
During O
training O
, O
the O
forward O
/ O
backward O
propagated O
signals O
of O
stages O
2 O
and O
3 O
only O
go O
through O
the O
“ O
pathways O
” O
determined O
by O
these O
300 O
boxes O
. O
NMS Method
is O
similar O
to O
max Method
pooling Method
, O
maxout Method
, O
or O
other O
local Method
competing Method
layers Method
, O
which O
are O
implemented O
as O
routers Method
of Method
forward Method
/ Method
backward Method
pathways Method
. O
During O
inference Task
, O
we O
use O
the O
same O
NMS Method
strategy O
to O
produce O
300 O
proposals O
for O
stage O
2 O
. O
Positive O
/ O
negative O
samples O
. O
( O
i O
) O
On O
stage O
1 O
, O
their O
definitions O
follow O
. O
( O
ii O
) O
On O
stage O
2 O
, O
for O
each O
proposed O
box O
we O
find O
its O
highest O
overlapping O
ground O
truth O
mask O
. O
If O
the O
overlapping Metric
ratio Metric
( O
IoU Metric
) O
is O
greater O
than O
0.5 O
, O
this O
proposed O
box O
is O
considered O
as O
positive O
and O
contributes O
to O
the O
mask O
regression O
loss O
; O
otherwise O
is O
ignored O
in O
the O
regression Task
loss Task
. O
The O
mask O
regression O
target O
is O
the O
intersection O
between O
the O
proposed O
box O
and O
the O
ground O
truth O
mask O
, O
resized O
to O
pixels O
. O
( O
iii O
) O
On O
stage O
3 O
, O
we O
consider O
two O
sets O
of O
positive O
/ O
negative O
samples O
. O
In O
the O
first O
set O
, O
the O
positive O
samples O
are O
the O
instances O
that O
overlap O
with O
ground O
truth O
boxes O
by O
box O
- O
level O
IoU Metric
( O
the O
negative O
samples O
are O
the O
rest O
) O
. O
In O
the O
second O
set O
, O
the O
positive O
samples O
are O
the O
instances O
that O
overlap O
with O
ground O
truth O
instances O
by O
box O
- O
level O
IoU Metric
and O
mask Metric
- Metric
level Metric
IoU Metric
. O
The O
loss Method
function Method
of O
stage O
3 O
involves O
two O
( O
+ Method
1 Method
)- Method
way Method
classifiers Method
, O
one O
for O
classifying Task
mask Task
- Task
level Task
instances Task
and O
the O
other O
for O
classifying Task
box Task
- Task
level Task
instances Task
( O
whose O
scores O
are O
not O
used O
for O
inference Task
) O
. O
The O
reason O
for O
considering O
both O
box O
- O
level O
and O
mask O
- O
level O
IoU Metric
is O
that O
when O
the O
proposed O
box O
is O
not O
a O
real O
instance O
( O
, O
on O
the O
background O
or O
poorly O
overlapping O
with O
ground O
truth O
) O
, O
the O
regressed O
mask O
might O
be O
less O
reliable O
and O
thus O
the O
box Metric
- Metric
level Metric
IoU Metric
is O
more O
confident O
. O
Hyper O
- O
parameters O
for O
training O
. O
We O
use O
the O
ImageNet Method
pre Method
- Method
trained Method
models Method
( O
, O
VGG Method
- Method
16 Method
) O
to O
initialize O
the O
shared Method
convolutional Method
layers Method
and O
the O
corresponding O
4096 O
- O
d O
fc Method
layers O
. O
The O
extra O
layers O
are O
initialized O
randomly O
as O
in O
. O
We O
adopt O
an O
image Method
- Method
centric Method
training Method
framework Method
: O
the O
shared Method
convolutional Method
layers Method
are O
computed O
on O
the O
entire O
image O
, O
while O
the O
RoIs O
are O
randomly O
sampled O
for O
computing O
loss O
functions O
. O
In O
our O
system O
, O
each O
mini O
- O
batch O
involves O
1 O
image O
, O
256 O
sampled O
anchors O
for O
stage O
1 O
as O
in O
, O
and O
64 O
sampled O
RoIs O
for O
stages O
2 O
and O
3 O
. O
We O
train O
the O
model O
using O
a O
learning Metric
rate Metric
of O
0.001 O
for O
32k O
iterations O
, O
and O
0.0001 O
for O
the O
next O
8k O
. O
We O
train O
the O
model O
in O
8 O
GPUs Method
, O
each O
GPU O
holding O
1 O
mini O
- O
batch O
( O
so O
the O
effective O
mini O
- O
batch O
size O
is O
8 O
) O
. O
The O
images O
are O
resized O
such O
that O
the O
shorter O
side O
has O
600 O
pixels O
. O
We O
do O
not O
adopt O
multi Method
- Method
scale Method
training Method
/ Method
testing Method
, O
as O
it O
provides O
no O
good O
trade O
- O
off O
on O
speed Metric
accuracy Metric
. O
Inference Task
. O
We O
use O
5 Method
- Method
stage Method
inference Method
for O
both O
3 Task
- Task
stage Task
and O
5 O
- O
stage O
trained O
structures O
. O
The O
inference Method
process Method
gives O
us O
a O
list O
of O
600 O
instances O
with O
masks O
and O
category O
scores O
( O
300 O
from O
the O
stage O
3 O
outputs O
, O
and O
300 O
from O
the O
stage O
5 O
outputs O
) O
. O
We O
post O
- O
process O
this O
list O
to O
reduce O
similar O
predictions O
. O
We O
first O
apply O
NMS Method
( O
using O
box O
- O
level O
IoU Metric
0.3 O
) O
on O
the O
list O
of O
600 O
instances O
based O
on O
their O
category O
scores O
. O
After O
that O
, O
for O
each O
not O
- O
suppressed O
instance O
, O
we O
find O
its O
“ O
similar O
” O
instances O
which O
are O
defined O
as O
the O
suppressed O
instances O
that O
overlap O
with O
it O
by O
IoU Metric
0.5 O
. O
The O
prediction O
masks O
of O
the O
not O
- O
suppressed O
instance O
and O
its O
similar O
instances O
are O
merged O
together O
by O
weighted Method
averaging Method
, O
pixel O
- O
by O
- O
pixel O
, O
using O
the O
classification O
scores O
as O
their O
averaging O
weights O
. O
This O
“ O
mask Method
voting Method
” Method
scheme Method
is O
inspired O
by O
the O
box Method
voting Method
in O
. O
The O
averaged O
masks O
, O
taking O
continuous O
values O
in O
, O
are O
binarized O
to O
form O
the O
final O
output O
masks O
. O
The O
averaging Method
step Method
improves O
accuracy Metric
by O
1 O
% O
over O
the O
NMS Method
outcome O
. O
This O
post O
- O
processing O
is O
performed O
for O
each O
category O
independently O
. O
section O
: O
Experiments O
subsection O
: O
Experiments O
on O
PASCAL Material
VOC Material
2012 Material
We O
follow O
the O
protocols O
used O
in O
recent O
papers O
for O
evaluating O
instance Task
- Task
aware Task
semantic Task
segmentation Task
. O
The O
models O
are O
trained O
on O
the O
PASCAL Material
VOC Material
2012 Material
training Material
set Material
, O
and O
evaluated O
on O
the O
validation O
set O
. O
We O
use O
the O
segmentation O
annotations O
in O
for O
training O
and O
evaluation Task
, O
following O
. O
We O
evaluate O
the O
mean Metric
Average Metric
Precision Metric
, O
which O
is O
referred O
to O
as O
mean Metric
AP Metric
or O
simply O
mAP Metric
. O
We O
evaluate O
mAP Metric
using O
IoU Metric
thresholds O
at O
0.5 O
and O
0.7 O
. O
Ablation O
Experiments O
on O
Training Method
Strategies Method
. O
Table O
[ O
reference O
] O
compares O
the O
results O
of O
different O
training Method
strategies Method
for O
MNCs Method
. O
We O
remark O
that O
in O
this O
table O
all O
results O
are O
obtained O
via O
5 Method
- Method
stage Method
inference Method
, O
so O
the O
differences O
are O
contributed O
by O
the O
training Method
strategies Method
. O
We O
show O
results O
using O
ZF Method
net Method
that O
has O
5 O
convolutional O
layers O
and O
3 O
fc Method
layers O
, O
and O
VGG Method
- Method
16 Method
net Method
that O
has O
13 O
convolutional Method
layers Method
and O
3 O
fc Method
layers O
. O
As O
a O
simple O
baseline O
( O
Table O
[ O
reference O
] O
, O
a O
) O
, O
we O
train O
the O
three O
stages O
step O
- O
by O
- O
step O
without O
sharing O
their O
features O
. O
Three O
separate O
networks O
are O
trained O
, O
and O
a O
network O
of O
a O
later O
stage O
takes O
the O
outputs O
from O
the O
trained O
networks O
of O
the O
earlier O
stages O
. O
The O
three O
separate O
networks O
are O
all O
initialized O
by O
the O
ImageNet Method
- Method
pre Method
- Method
trained Method
model Method
. O
This O
baseline O
has O
an O
mAP Metric
of O
60.2 O
% O
using O
VGG Method
- Method
16 Method
. O
We O
note O
that O
this O
baseline O
result O
is O
competitive O
( O
see O
also O
Table O
[ O
reference O
] O
) O
, O
suggesting O
that O
decomposing O
the O
task O
into O
three O
sub O
- O
tasks O
is O
an O
effective O
solution O
. O
To O
achieve O
feature Task
sharing Task
, O
one O
may O
follow O
the O
step O
- O
by O
- O
step Method
training Method
in O
. O
Given O
the O
above O
model O
( O
a O
) O
, O
the O
shared O
convolutional O
layers O
are O
kept O
unchanged O
by O
using O
the O
last O
stage O
’s O
weights O
, O
and O
the O
three O
separate O
networks O
are O
trained O
step O
- O
by O
- O
step O
again O
with O
the O
shared O
layers O
not O
tuned O
, O
following O
. O
Doing O
so O
leads O
to O
an O
mAP Metric
of O
60.5 O
% O
, O
just O
on O
par O
with O
the O
baseline O
that O
does O
not O
share O
features O
. O
This O
suggests O
that O
sharing O
features O
does O
not O
directly O
improve O
accuracy Metric
. O
Next O
we O
experiment O
with O
the O
single O
- O
step O
, O
end Method
- Method
to Method
- Method
end Method
training Method
algorithm Method
developed O
in O
Sec O
. O
[ O
reference O
] O
. O
Table O
[ O
reference O
] O
( O
c O
) O
shows O
the O
result O
of O
end Task
- Task
to Task
- Task
end Task
training Task
a O
3 Method
- Method
stage Method
cascade Method
. O
The O
mAP Metric
is O
increased O
to O
62.6 O
% O
. O
We O
note O
that O
in O
Table O
[ O
reference O
] O
( O
a O
) O
, O
( O
b O
) O
, O
and O
( O
c O
) O
, O
the O
models O
have O
the O
same O
structure O
for O
training O
. O
So O
the O
improvement O
of O
( O
c O
) O
is O
contributed O
by O
end O
- O
to O
- O
end O
training O
this O
cascade Method
structure Method
. O
This O
improvement O
is O
similar O
to O
other O
gains O
observed O
in O
many O
practices O
of O
multi Task
- Task
task Task
learning Task
. O
By O
developing O
training Method
algorithm Method
as O
in O
Sec O
. O
[ O
reference O
] O
, O
we O
are O
able O
to O
train O
the O
network O
by O
backpropagation Method
in O
a O
theoretically O
sound O
way O
. O
The O
features O
are O
naturally O
shared O
by O
optimizing O
a O
unified Method
loss Method
function Method
, O
and O
the O
benefits O
of O
multi Task
- Task
task Task
learning Task
are O
witnessed O
. O
Table O
[ O
reference O
] O
( O
d O
) O
shows O
the O
result O
of O
end O
- O
to O
- O
end Task
training Task
a O
5 Method
- Method
stage Method
cascade Method
. O
The O
mAP Metric
is O
further O
improved O
to O
63.5 O
% O
. O
We O
note O
that O
all O
results O
in O
Table O
[ O
reference O
] O
are O
based O
on O
the O
same O
5 Method
- Method
stage Method
inference Method
strategy Method
. O
So O
the O
accuracy Metric
gap Metric
between O
( O
d O
) O
and O
( O
c O
) O
is O
contributed O
by O
training O
a O
5 Method
- Method
stage Method
structure Method
that O
is O
consistent O
with O
its O
inference O
- O
time O
usage O
. O
The O
series O
of O
comparisons O
are O
also O
observed O
when O
using O
the O
ZF Method
net Method
as O
the O
pre O
- O
trained Method
model Method
( O
Table O
[ O
reference O
] O
, O
left O
) O
, O
showing O
the O
generality O
of O
our O
findings O
. O
Comparisons O
with O
State O
- O
of O
- O
the O
- O
art O
Methods O
. O
In O
Table O
[ O
reference O
] O
we O
compare O
with O
SDS Method
, O
Hypercolumn Method
, O
and O
CFM Method
, O
which O
are O
existing O
CNN Method
- Method
based Method
semantic Method
segmentation Method
methods Method
that O
are O
able O
to O
identify O
instances O
. O
These O
papers O
reported O
their O
mAP Metric
under O
the O
same O
protocol O
used O
by O
our O
experiments O
. O
Our O
MNC Method
has O
3 O
% O
higher O
mAP Metric
@0.5 O
than O
previous O
best O
results O
. O
Our O
method O
also O
has O
higher O
mAP Metric
@0.7 O
than O
previous O
methods O
. O
Fig O
[ O
reference O
] O
shows O
some O
examples O
of O
our O
results O
on O
the O
validation O
set O
. O
Our O
method O
can O
handle O
challenging O
cases O
where O
multiple O
instances O
of O
the O
same O
category O
are O
spatially O
connected O
to O
each O
other O
( O
, O
Fig O
[ O
reference O
] O
, O
first O
row O
) O
. O
Running Metric
Time Metric
. O
Our O
method O
has O
an O
inference Metric
- Metric
time Metric
speed Metric
of O
360ms O
per O
image O
( O
Table O
[ O
reference O
] O
) O
, O
evaluated O
on O
an O
Nvidia O
K40 O
GPU O
. O
Table O
[ O
reference O
] O
shows O
the O
details O
. O
Our O
method O
does O
not O
require O
any O
external Method
region Method
proposal Method
method Method
, O
whereas O
the O
region Method
proposal Method
step Method
in O
SDS Method
, O
Hypercolumn Method
, O
and O
CFM Method
costs O
30s O
using O
MCG Method
. O
Furthermore O
, O
our O
method O
uses O
the O
shared O
convolutional O
features O
for O
the O
three O
sub Task
- Task
tasks Task
and O
avoids O
redundant O
computation O
. O
Our O
system O
is O
about O
two O
orders O
of O
magnitude O
faster O
than O
previous O
systems O
. O
Object Task
Detection Task
Evaluations Task
. O
We O
are O
also O
interested O
in O
the O
box Metric
- Metric
level Metric
object Metric
detection Metric
performance Metric
( O
mAP Metric
) O
, O
so O
that O
we O
can O
compare O
with O
more O
systems O
that O
are O
designed O
for O
object Task
detection Task
. O
We O
train O
our O
model O
on O
the O
PASCAL Material
VOC Material
2012 Material
trainval Material
set Material
, O
and O
evaluate O
on O
the O
PASCAL Material
VOC Material
2012 Material
test Material
set Material
for O
object Task
detection Task
. O
Given O
mask O
- O
level O
instances O
generated O
by O
our O
model O
, O
we O
simply O
assign O
a O
tight O
bounding O
box O
to O
each O
instance O
. O
Table O
[ O
reference O
] O
shows O
that O
our O
result O
( O
70.9 O
% O
) O
compares O
favorably O
to O
the O
recent O
Fast O
/ O
Faster O
R Method
- Method
CNN Method
systems Method
. O
We O
note O
that O
our O
result O
is O
obtained O
with O
fewer O
training O
images O
( O
without O
the O
2007 Material
set Material
) O
, O
but O
with O
mask O
- O
level O
annotations O
. O
This O
experiment O
shows O
the O
effectiveness O
of O
our O
algorithm O
for O
detecting O
both O
box Task
- Task
and Task
mask Task
- Task
level Task
instances Task
. O
The O
above O
detection Task
result O
is O
solely O
based O
on O
the O
mask O
- O
level O
outputs O
. O
But O
our O
method O
also O
has O
box O
- O
level O
outputs O
from O
the O
box Method
regression Method
layers Method
in O
stage O
3 O
/ O
5 O
. O
Using O
these O
box O
layers O
’ O
outputs O
( O
box O
coordinates O
and O
scores O
) O
in O
place O
of O
the O
mask O
- O
level O
outputs O
, O
we O
obtain O
an O
mAP Metric
of O
73.5 O
% O
( O
Table O
[ O
reference O
] O
) O
. O
Finally O
, O
we O
train O
the O
MNC Method
model Method
on O
the O
union O
set O
of O
2007 Material
trainval Material
+ Material
test Material
and O
2012 Material
trainval Material
. O
As O
the O
2007 O
set O
has O
no O
mask O
- O
level O
annotation O
, O
when O
a O
sample O
image O
from O
the O
2007 O
set O
is O
used O
, O
its O
mask O
regression O
loss O
is O
ignored O
( O
but O
the O
mask O
is O
generated O
for O
the O
later O
stages O
) O
and O
its O
mask O
- O
level O
IoU Metric
measure O
for O
determining Task
positive Task
/ Task
negative Task
samples Task
is O
ignored O
. O
These O
samples O
can O
still O
impact O
the O
box Task
proposal Task
stage Task
and O
the O
categorizing Method
stage Method
. O
Under O
this O
setting O
, O
we O
obtain O
an O
mAP Metric
of O
75.9 O
% O
( O
Table O
[ O
reference O
] O
) O
, O
substantially O
better O
than O
Fast Method
/ Method
Faster Method
R Method
- Method
CNN Method
. O
subsection O
: O
Experiments O
on O
MS Task
COCO Task
Segmentation Task
We O
further O
evaluate O
on O
the O
MS Material
COCO Material
dataset Material
. O
This O
dataset O
consists O
of O
80 O
object O
categories O
for O
instance Task
- Task
aware Task
semantic Task
segmentation Task
. O
Following O
the O
COCO O
guidelines O
, O
we O
use O
the O
80k Material
+ Material
40k Material
trainval Material
images Material
to O
train O
, O
and O
report O
the O
results O
on O
the O
test O
- O
dev O
set O
. O
We O
evaluate O
the O
standard O
COCO Metric
metric Metric
( O
mAP Metric
@IoU= O
[ O
0.5:0.95 O
] O
) O
and O
also O
the O
PASCAL Metric
metrics Metric
( O
mAP Metric
@IoU=0.5 O
) O
. O
Table O
[ O
reference O
] O
shows O
our O
method O
using O
VGG Method
- Method
16 Method
has O
a O
result O
of O
19.5% O
/ O
39.7 O
% O
. O
The O
end O
- O
to O
- O
end O
training O
behavior O
and O
the O
independence O
of O
external Method
models Method
make O
our O
method O
easily O
enjoy O
gains O
from O
deeper Method
representations Method
. O
By O
replacing O
VGG Method
- Method
16 Method
with O
an O
extremely O
deep Method
101 Method
- Method
layer Method
network Method
( O
ResNet Method
- Method
101 Method
) O
, O
we O
achieve O
24.6% O
/ O
44.3 O
% O
on O
the O
MS Material
COCO Material
test Material
- Material
dev Material
set Material
( O
Table O
[ O
reference O
] O
) O
. O
It O
is O
noteworthy O
that O
ResNet Method
- Method
101 Method
leads O
to O
a O
relative O
improvement O
of O
26 O
% O
( O
on O
mAP Metric
@ O
[ O
.5:.95 O
] O
) O
over O
VGG Method
- Method
16 Method
, O
which O
is O
consistent O
to O
the O
relative O
improvement O
of O
COCO Task
object Task
detection Task
in O
. O
This O
baseline O
result O
is O
close O
to O
the O
2nd O
- O
place O
winner O
’s O
ensemble O
result O
( O
25.1% O
/ O
45.8 O
% O
by O
FAIRCNN Method
) O
. O
On O
our O
baseline O
result O
, O
we O
further O
adopt O
global Method
context Method
modeling Method
and O
multi Task
- Task
scale Task
testing Task
as O
in O
, O
and O
ensembling Method
. O
Our O
final O
result O
on O
the O
test O
- O
challenge O
set O
is O
28.2% O
/ O
51.5 O
% O
, O
which O
won O
the O
1st O
place O
in O
the O
COCO Material
segmentation Material
track Material
of O
ILSVRC Task
& O
COCO Task
2015 Task
competitions O
. O
Fig O
. O
[ O
reference O
] O
shows O
some O
examples O
. O
section O
: O
Conclusion O
We O
have O
presented O
Multi Method
- Method
task Method
Network Method
Cascades Method
for O
fast Task
and Task
accurate Task
instance Task
segmentation Task
. O
We O
believe O
that O
the O
idea O
of O
exploiting O
network Method
cascades Method
in O
a O
multi Task
- Task
task Task
learning Task
framework Task
is O
general O
. O
This O
idea O
, O
if O
further O
developed O
, O
may O
be O
useful O
for O
other O
recognition Task
tasks Task
. O
Our O
method O
is O
designed O
with O
fast Task
inference Task
in O
mind O
, O
and O
is O
orthogonal O
to O
some O
other O
successful O
strategies O
developed O
previously O
for O
semantic Task
segmentation Task
. O
For O
example O
, O
one O
may O
consider O
exploiting O
a O
CRF Method
to O
refine O
the O
boundaries O
of O
the O
instance O
masks O
. O
This O
is O
beyond O
the O
scope O
of O
this O
paper O
and O
will O
be O
investigated O
in O
the O
future O
. O
bibliography O
: O
References O
