document	O
:	O
FPNN	Method
:	O
Field	Method
Probing	Method
Neural	Method
Networks	Method
for	O
3D	Task
Data	Task
Building	O
discriminative	Method
representations	Method
for	O
3D	O
data	O
has	O
been	O
an	O
important	O
task	O
in	O
computer	Task
graphics	Task
and	O
computer	Task
vision	Task
research	Task
.	O
Convolutional	Method
Neural	Method
Networks	Method
(	O
CNNs	Method
)	O
have	O
shown	O
to	O
operate	O
on	O
2D	O
images	O
with	O
great	O
success	O
for	O
a	O
variety	O
of	O
tasks	O
.	O
Lifting	Method
convolution	Method
operators	Method
to	O
3D	O
(	O
3DCNNs	Method
)	O
seems	O
like	O
a	O
plausible	O
and	O
promising	O
next	O
step	O
.	O
Unfortunately	O
,	O
the	O
computational	Metric
complexity	Metric
of	O
3D	Method
CNNs	Method
grows	O
cubically	O
with	O
respect	O
to	O
voxel	O
resolution	O
.	O
Moreover	O
,	O
since	O
most	O
3D	Method
geometry	Method
representations	Method
are	O
boundary	Method
based	Method
,	O
occupied	O
regions	O
do	O
not	O
increase	O
proportionately	O
with	O
the	O
size	O
of	O
the	O
discretization	O
,	O
resulting	O
in	O
wasted	O
computation	O
.	O
In	O
this	O
work	O
,	O
we	O
represent	O
3D	O
spaces	O
as	O
volumetric	O
fields	O
,	O
and	O
propose	O
a	O
novel	O
design	O
that	O
employs	O
field	Method
probing	Method
filters	Method
to	O
efficiently	O
extract	O
features	O
from	O
them	O
.	O
Each	O
field	Method
probing	Method
filter	Method
is	O
a	O
set	O
of	O
probing	O
points	O
—	O
sensors	O
that	O
perceive	O
the	O
space	O
.	O
Our	O
learning	Method
algorithm	Method
optimizes	O
not	O
only	O
the	O
weights	O
associated	O
with	O
the	O
probing	O
points	O
,	O
but	O
also	O
their	O
locations	O
,	O
which	O
deforms	O
the	O
shape	O
of	O
the	O
probing	Method
filters	Method
and	O
adaptively	O
distributes	O
them	O
in	O
3D	O
space	O
.	O
The	O
optimized	O
probing	O
points	O
sense	O
the	O
3D	O
space	O
‘	O
‘	O
intelligently	O
’	O
’	O
,	O
rather	O
than	O
operating	O
blindly	O
over	O
the	O
entire	O
domain	O
.	O
We	O
show	O
that	O
field	Method
probing	Method
is	O
significantly	O
more	O
efficient	O
than	O
3DCNNs	Method
,	O
while	O
providing	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
performance	O
,	O
on	O
classification	Task
tasks	Task
for	O
3D	Task
object	Task
recognition	Task
benchmark	O
datasets	O
.	O
section	O
:	O
Introduction	O
Rapid	O
advances	O
in	O
3D	Method
sensing	Method
technology	Method
have	O
made	O
3D	O
data	O
ubiquitous	O
and	O
easily	O
accessible	O
,	O
rendering	O
them	O
an	O
important	O
data	O
source	O
for	O
high	Task
level	Task
semantic	Task
understanding	Task
in	O
a	O
variety	O
of	O
environments	O
.	O
The	O
semantic	Task
understanding	Task
problem	Task
,	O
however	O
,	O
remains	O
very	O
challenging	O
for	O
3D	O
data	O
as	O
it	O
is	O
hard	O
to	O
find	O
an	O
effective	O
scheme	O
for	O
converting	O
input	O
data	O
into	O
informative	O
features	O
for	O
further	O
processing	O
by	O
machine	Method
learning	Method
algorithms	Method
.	O
For	O
semantic	Task
understanding	Task
problems	Task
in	O
2D	O
images	O
,	O
deep	Method
CNNs	Method
have	O
been	O
widely	O
used	O
and	O
have	O
achieved	O
great	O
success	O
,	O
where	O
the	O
convolutional	Method
layers	Method
play	O
an	O
essential	O
role	O
.	O
They	O
provide	O
a	O
set	O
of	O
2D	Method
filters	Method
,	O
which	O
when	O
convolved	O
with	O
input	O
data	O
,	O
transform	O
the	O
data	O
to	O
informative	O
features	O
for	O
higher	O
level	Task
inference	Task
.	O
In	O
this	O
paper	O
,	O
we	O
focus	O
on	O
the	O
problem	O
of	O
learning	O
a	O
3D	Task
shape	Task
representation	Task
by	O
a	O
deep	Method
neural	Method
network	Method
.	O
We	O
keep	O
two	O
goals	O
in	O
mind	O
when	O
designing	O
the	O
network	O
:	O
the	O
shape	O
features	O
should	O
be	O
discriminative	O
for	O
shape	Task
recognition	Task
and	O
efficient	O
for	O
extraction	Task
at	O
runtime	O
.	O
However	O
,	O
existing	O
3D	Task
CNN	Task
pipelines	O
that	O
simply	O
replace	O
the	O
conventional	O
2D	Method
filters	Method
by	O
3D	Method
ones	Method
,	O
have	O
difficulty	O
in	O
capturing	O
geometric	O
structures	O
with	O
sufficient	O
efficiency	O
.	O
The	O
input	O
to	O
these	O
3D	Method
CNNs	Method
are	O
voxelized	O
shapes	O
represented	O
by	O
occupancy	Method
grids	Method
,	O
in	O
direct	O
analogy	O
to	O
pixel	Method
array	Method
representation	Method
for	O
images	O
.	O
We	O
observe	O
that	O
the	O
computational	Metric
cost	Metric
of	O
3D	Method
convolution	Method
is	O
quite	O
high	O
,	O
since	O
convolving	O
3D	O
voxels	O
has	O
cubical	O
complexity	O
with	O
respect	O
to	O
spatial	O
resolution	O
,	O
one	O
order	O
higher	O
than	O
the	O
2D	O
case	O
.	O
Due	O
to	O
this	O
high	O
computational	Metric
cost	Metric
,	O
researchers	O
typically	O
choose	O
resolution	O
to	O
voxelize	O
shapes	O
,	O
which	O
is	O
significantly	O
lower	O
than	O
the	O
widely	O
adopted	O
resolution	O
for	O
processing	Task
images	Task
.	O
We	O
suspect	O
that	O
the	O
strong	O
artifacts	O
introduced	O
at	O
this	O
level	O
of	O
quantization	O
(	O
see	O
Figure	O
[	O
reference	O
]	O
)	O
hinder	O
the	O
process	O
of	O
learning	O
effective	O
3D	Method
convolutional	Method
filters	Method
.	O
Two	O
significant	O
differences	O
between	O
2D	O
images	O
and	O
3D	O
shapes	O
interfere	O
with	O
the	O
success	O
of	O
directly	O
applying	O
2D	Method
CNNs	Method
on	O
3D	O
data	O
.	O
First	O
,	O
as	O
the	O
voxel	O
resolution	O
grows	O
,	O
the	O
grids	O
occupied	O
by	O
shape	O
surfaces	O
get	O
sparser	O
and	O
sparser	O
(	O
see	O
Figure	O
[	O
reference	O
]	O
)	O
.	O
The	O
convolutional	Method
layers	Method
that	O
are	O
designed	O
for	O
2D	O
images	O
thereby	O
waste	O
much	O
computation	O
resource	O
in	O
such	O
a	O
setting	O
,	O
since	O
they	O
convolve	O
with	O
3D	O
blocks	O
that	O
are	O
largely	O
empty	O
and	O
a	O
large	O
portion	O
of	O
multiplications	O
are	O
with	O
zeros	O
.	O
Moreover	O
,	O
as	O
the	O
voxel	O
resolution	O
grows	O
,	O
the	O
local	O
3D	O
blocks	O
become	O
less	O
and	O
less	O
discriminative	O
.	O
To	O
capture	O
informative	O
features	O
,	O
long	O
range	O
connections	O
have	O
to	O
be	O
established	O
for	O
taking	O
distant	O
voxels	O
into	O
consideration	O
.	O
This	O
long	O
range	O
effect	O
demands	O
larger	O
3D	Method
filters	Method
,	O
which	O
yields	O
an	O
even	O
higher	O
computation	Metric
overhead	Metric
.	O
To	O
address	O
these	O
issues	O
,	O
we	O
represent	O
3D	O
data	O
as	O
3D	O
fields	O
,	O
and	O
propose	O
a	O
field	Method
probing	Method
scheme	Method
,	O
which	O
samples	O
the	O
input	O
field	O
by	O
a	O
set	O
of	O
probing	Method
filters	Method
(	O
see	O
Figure	O
[	O
reference	O
]	O
)	O
.	O
Each	O
probing	Method
filter	Method
is	O
composed	O
of	O
a	O
set	O
of	O
probing	O
points	O
which	O
determine	O
the	O
shape	O
and	O
location	O
of	O
the	O
filter	O
,	O
and	O
filter	O
weights	O
associated	O
with	O
probing	O
points	O
.	O
In	O
typical	O
CNNs	Method
,	O
only	O
the	O
filter	O
weights	O
are	O
trained	O
,	O
while	O
the	O
filter	O
shape	O
themselves	O
are	O
fixed	O
.	O
In	O
our	O
framework	O
,	O
due	O
to	O
the	O
usage	O
of	O
3D	Method
field	Method
representation	Method
,	O
both	O
the	O
weights	O
and	O
probing	O
point	O
locations	O
are	O
trainable	O
,	O
making	O
the	O
filters	O
highly	O
flexible	O
in	O
coupling	O
long	O
range	O
effects	O
and	O
adapting	O
to	O
the	O
sparsity	O
of	O
3D	O
data	O
when	O
it	O
comes	O
to	O
feature	Task
extraction	Task
.	O
The	O
computation	Metric
amount	Metric
of	O
our	O
field	Method
probing	Method
scheme	Method
is	O
determined	O
by	O
how	O
many	O
probing	Method
filters	Method
we	O
place	O
in	O
the	O
3D	O
space	O
,	O
and	O
how	O
many	O
probing	O
points	O
are	O
sampled	O
per	O
filter	O
.	O
Thus	O
,	O
the	O
computational	Metric
complexity	Metric
does	O
not	O
grow	O
as	O
a	O
function	O
of	O
the	O
input	O
resolution	O
.	O
We	O
found	O
that	O
a	O
small	O
set	O
of	O
field	Method
probing	Method
filters	Method
is	O
enough	O
for	O
sampling	O
sufficient	O
information	O
,	O
probably	O
due	O
to	O
the	O
sparsity	O
characteristic	O
of	O
3D	O
data	O
.	O
Intuitively	O
,	O
we	O
can	O
think	O
our	O
field	Method
probing	Method
scheme	Method
as	O
a	O
set	O
of	O
sensors	O
placed	O
in	O
the	O
space	O
to	O
collect	O
informative	O
signals	O
for	O
high	Task
level	Task
semantic	Task
tasks	Task
.	O
With	O
the	O
long	O
range	O
connections	O
between	O
the	O
sensors	O
,	O
global	O
overview	O
of	O
the	O
underlying	O
object	O
can	O
be	O
easily	O
established	O
for	O
effective	O
inference	Task
.	O
Moreover	O
,	O
the	O
sensors	O
are	O
‘	O
‘	O
smart	O
’	O
’	O
in	O
the	O
sense	O
that	O
they	O
learn	O
how	O
to	O
sense	O
the	O
space	O
(	O
by	O
optimizing	O
the	O
filter	O
weights	O
)	O
,	O
as	O
well	O
as	O
where	O
to	O
sense	O
(	O
by	O
optimizing	O
the	O
probing	O
point	O
locations	O
)	O
.	O
Note	O
that	O
the	O
intelligence	O
of	O
the	O
sensors	O
is	O
not	O
hand	O
-	O
crafted	O
,	O
but	O
solely	O
derived	O
from	O
data	O
.	O
We	O
evaluate	O
our	O
field	Method
probing	Method
based	Method
neural	Method
networks	Method
(	O
FPNN	Method
)	O
on	O
a	O
classification	Task
task	Task
on	O
ModelNet	Material
dataset	Material
,	O
and	O
show	O
that	O
they	O
match	O
the	O
performance	O
of	O
3DCNNs	Method
while	O
requiring	O
much	O
less	O
computation	O
,	O
as	O
they	O
are	O
designed	O
and	O
trained	O
to	O
respect	O
the	O
sparsity	O
of	O
3D	O
data	O
.	O
section	O
:	O
Related	O
Work	O
paragraph	O
:	O
3D	Method
Shape	Method
Descriptors	Method
.	O
3D	Method
shape	Method
descriptors	Method
lie	O
at	O
the	O
core	O
of	O
shape	Task
analysis	Task
and	O
a	O
large	O
variety	O
of	O
shape	Method
descriptors	Method
have	O
been	O
designed	O
in	O
the	O
past	O
few	O
decades	O
.	O
3D	O
shapes	O
can	O
be	O
converted	O
into	O
2D	O
images	O
and	O
represented	O
by	O
descriptors	Method
of	O
the	O
converted	O
images	O
.	O
3D	O
shapes	O
can	O
also	O
be	O
represented	O
by	O
their	O
inherent	O
statistical	O
properties	O
,	O
such	O
as	O
distance	Method
distribution	Method
and	O
spherical	Method
harmonic	Method
decomposition	Method
.	O
Heat	Method
kernel	Method
signatures	Method
extract	O
shape	O
descriptions	O
by	O
simulating	O
an	O
heat	Method
diffusion	Method
process	Method
on	O
3D	O
shapes	O
.	O
In	O
contrast	O
,	O
we	O
propose	O
an	O
approach	O
for	O
learning	O
the	O
shape	Method
descriptor	Method
extraction	Method
scheme	Method
,	O
rather	O
than	O
hand	O
-	O
crafting	O
it	O
.	O
paragraph	O
:	O
Convolutional	Method
Neural	Method
Networks	Method
.	O
The	O
architecture	O
of	O
CNN	Method
is	O
designed	O
to	O
take	O
advantage	O
of	O
the	O
2D	O
structure	O
of	O
an	O
input	O
image	O
(	O
or	O
other	O
2D	O
input	O
such	O
as	O
a	O
speech	O
signal	O
)	O
,	O
and	O
CNNs	Method
have	O
advanced	O
the	O
performance	O
records	O
in	O
most	O
image	Task
understanding	Task
tasks	Task
in	O
computer	Task
vision	Task
.	O
An	O
important	O
reason	O
for	O
this	O
success	O
is	O
that	O
by	O
leveraging	O
large	O
image	O
datasets	O
(	O
e.g.	O
,	O
ImageNet	O
)	O
,	O
general	Method
purpose	Method
image	Method
descriptors	Method
can	O
be	O
directly	O
learned	O
from	O
data	O
,	O
which	O
adapt	O
to	O
the	O
data	O
better	O
and	O
outperform	O
hand	O
-	O
crafted	O
features	O
.	O
Our	O
approach	O
follows	O
this	O
paradigm	O
of	O
feature	Method
learning	Method
,	O
but	O
is	O
specifically	O
designed	O
for	O
3D	O
data	O
coming	O
from	O
object	Method
surface	Method
representations	Method
.	O
paragraph	O
:	O
CNNs	Method
on	O
Depth	O
and	O
3D	O
Data	O
.	O
With	O
rapid	O
advances	O
in	O
3D	Task
sensing	Task
technology	Task
,	O
depth	O
has	O
became	O
available	O
as	O
an	O
additional	O
information	O
channel	O
beyond	O
color	O
.	O
Such	O
2.5D	O
data	O
can	O
be	O
represented	O
as	O
multiple	O
channel	O
images	O
,	O
and	O
processed	O
by	O
2D	Method
CNNs	Method
.	O
Wu	O
et	O
al	O
.	O
in	O
a	O
pioneering	O
paper	O
proposed	O
to	O
extend	O
2D	Method
CNNs	Method
to	O
process	O
3D	O
data	O
directly	O
(	O
3D	O
ShapeNets	O
)	O
.	O
A	O
similar	O
approach	O
(	O
VoxNet	Method
)	O
was	O
proposed	O
in	O
.	O
However	O
,	O
such	O
approaches	O
can	O
not	O
work	O
on	O
high	O
resolution	O
3D	O
data	O
,	O
as	O
the	O
computational	Metric
complexity	Metric
is	O
a	O
cubic	O
function	O
of	O
the	O
voxel	O
grid	O
resolution	O
.	O
Since	O
CNNs	Method
for	O
images	O
have	O
been	O
extensively	O
studied	O
,	O
3D	O
shapes	O
can	O
be	O
rendered	O
into	O
2D	O
images	O
,	O
and	O
be	O
represented	O
by	O
the	O
CNN	O
features	O
of	O
the	O
images	O
,	O
which	O
,	O
surprisingly	O
,	O
outperforms	O
any	O
3D	Task
CNN	Task
approaches	O
,	O
in	O
a	O
3D	Task
shape	Task
classification	Task
task	Task
.	O
Recently	O
,	O
Qi	O
et	O
al	O
.	O
presented	O
an	O
extensive	O
study	O
of	O
these	O
volumetric	Method
and	Method
multi	Method
-	Method
view	Method
CNNs	Method
and	O
refreshed	O
the	O
performance	O
records	O
.	O
In	O
this	O
work	O
,	O
we	O
propose	O
a	O
feature	Method
learning	Method
approach	Method
that	O
is	O
specifically	O
designed	O
to	O
take	O
advantage	O
of	O
the	O
sparsity	O
of	O
3D	O
data	O
,	O
and	O
compare	O
against	O
results	O
reported	O
in	O
.	O
Note	O
that	O
our	O
method	O
was	O
designed	O
without	O
explicit	O
consideration	O
of	O
deformable	O
objects	O
,	O
which	O
is	O
a	O
purely	O
extrinsic	Method
construction	Method
.	O
While	O
3D	O
data	O
is	O
represented	O
as	O
meshes	O
,	O
neural	Method
networks	Method
can	O
benefit	O
from	O
intrinsic	O
constructions	O
to	O
learn	O
object	O
invariance	O
to	O
isometries	O
,	O
thus	O
require	O
less	O
training	O
data	O
for	O
handling	O
deformable	O
objects	O
.	O
Our	O
method	O
can	O
be	O
viewed	O
as	O
an	O
efficient	O
scheme	Method
of	Method
sparse	Method
coding	Method
.	O
The	O
learned	O
weights	O
of	O
each	O
probing	O
curve	O
can	O
be	O
interpreted	O
as	O
the	O
entries	O
of	O
the	O
coding	O
matrix	O
in	O
the	O
sparse	Method
coding	Method
framework	Method
.	O
Compared	O
with	O
conventional	O
sparse	Method
coding	Method
,	O
our	O
framework	O
is	O
not	O
only	O
computationally	O
more	O
tractable	O
,	O
but	O
also	O
enables	O
an	O
end	Task
-	Task
to	Task
-	Task
end	Task
learning	Task
system	Task
.	O
section	O
:	O
Field	Method
Probing	Method
Neural	Method
Network	Method
subsection	O
:	O
Input	O
3D	O
Fields	O
We	O
study	O
the	O
3D	Task
shape	Task
classification	Task
problem	Task
by	O
employing	O
a	O
deep	Method
neural	Method
network	Method
.	O
The	O
input	O
of	O
our	O
network	O
is	O
a	O
3D	O
vector	O
field	O
built	O
from	O
the	O
input	O
shape	O
and	O
the	O
output	O
is	O
an	O
object	O
category	O
label	O
.	O
3D	O
shapes	O
represented	O
as	O
meshes	O
or	O
point	O
clouds	O
can	O
be	O
converted	O
into	O
3D	O
distance	O
fields	O
.	O
Given	O
a	O
mesh	O
(	O
or	O
point	O
cloud	O
)	O
,	O
we	O
first	O
convert	O
it	O
into	O
a	O
binary	Method
occupancy	Method
grid	Method
representation	Method
,	O
where	O
the	O
binary	O
occupancy	O
value	O
in	O
each	O
grid	O
is	O
determined	O
by	O
whether	O
it	O
intersects	O
with	O
any	O
mesh	O
surface	O
(	O
or	O
contains	O
any	O
sample	O
point	O
)	O
.	O
Then	O
we	O
treat	O
the	O
occupied	O
cells	O
as	O
the	O
zero	O
level	O
set	O
of	O
a	O
surface	O
,	O
and	O
apply	O
a	O
distance	Method
transform	Method
to	O
build	O
a	O
3D	O
distance	O
field	O
,	O
which	O
is	O
stored	O
in	O
a	O
3D	O
array	O
indexed	O
by	O
,	O
where	O
,	O
and	O
is	O
the	O
resolution	O
of	O
the	O
distance	O
field	O
.	O
We	O
denote	O
the	O
distance	O
value	O
at	O
by	O
.	O
Note	O
that	O
represents	O
distance	O
values	O
at	O
discrete	O
grid	O
locations	O
.	O
The	O
distance	O
value	O
at	O
an	O
arbitrary	O
location	O
can	O
be	O
computed	O
by	O
standard	O
trilinear	Method
interpolation	Method
over	O
.	O
See	O
Figure	O
[	O
reference	O
]	O
for	O
an	O
illustration	O
of	O
the	O
3D	Method
data	Method
representations	Method
.	O
Similar	O
to	O
3D	O
distance	O
fields	O
,	O
other	O
3D	O
fields	O
,	O
such	O
as	O
normal	O
fields	O
,	O
,	O
and	O
,	O
can	O
also	O
be	O
used	O
for	O
representing	Task
shapes	Task
.	O
Note	O
that	O
the	O
normal	O
fields	O
can	O
be	O
derived	O
from	O
the	O
gradient	O
of	O
the	O
distance	O
field	O
:	O
where	O
.	O
Our	O
framework	O
can	O
employ	O
any	O
set	O
of	O
fields	O
as	O
input	O
,	O
as	O
long	O
as	O
the	O
gradients	O
can	O
be	O
computed	O
.	O
subsection	O
:	O
Field	Task
Probing	Task
Layers	Task
The	O
basic	O
modules	O
of	O
deep	Method
neural	Method
networks	Method
are	O
layers	O
,	O
which	O
gradually	O
convert	O
input	O
to	O
output	O
in	O
a	O
forward	O
pass	O
,	O
and	O
get	O
updated	O
during	O
a	O
backward	O
pass	O
through	O
the	O
Back	Method
-	Method
propagation	Method
mechanism	Method
.	O
The	O
key	O
contribution	O
of	O
our	O
approach	O
is	O
that	O
we	O
replace	O
the	O
convolutional	Method
layers	Method
in	O
CNNs	Method
by	O
field	Method
probing	Method
layers	Method
,	O
a	O
novel	O
component	O
that	O
uses	O
field	Method
probing	Method
filters	Method
to	O
efficiently	O
extract	O
features	O
from	O
the	O
3D	O
vector	O
field	O
.	O
They	O
are	O
composed	O
of	O
three	O
layers	O
:	O
Sensor	Method
layer	Method
,	O
DotProduct	Method
layer	Method
and	O
Gaussian	Method
layer	Method
.	O
The	O
Sensor	Method
layer	Method
is	O
responsible	O
for	O
collecting	O
the	O
signals	O
(	O
the	O
values	O
in	O
the	O
input	O
fields	O
)	O
at	O
the	O
probing	O
points	O
in	O
the	O
forward	O
pass	O
,	O
and	O
updating	O
the	O
probing	O
point	O
locations	O
in	O
the	O
backward	O
pass	O
.	O
The	O
DotProduct	Method
layer	Method
computes	O
the	O
dot	O
product	O
between	O
the	O
probing	Method
filter	Method
weights	O
and	O
the	O
signals	O
from	O
the	O
Sensor	Method
layer	Method
.	O
The	O
Gaussian	Method
layer	Method
is	O
an	O
utility	Method
layer	Method
that	O
transforms	O
distance	O
field	O
into	O
a	O
representation	O
that	O
is	O
more	O
friendly	O
for	O
numerical	Task
computation	Task
.	O
We	O
introduce	O
them	O
in	O
the	O
following	O
paragraphs	O
,	O
and	O
show	O
that	O
they	O
fit	O
well	O
for	O
training	O
a	O
deep	Method
network	Method
.	O
paragraph	O
:	O
Sensor	Method
Layer	Method
.	O
The	O
input	O
to	O
this	O
layer	O
is	O
a	O
3D	O
field	O
,	O
where	O
yields	O
a	O
channel	O
(	O
for	O
distance	O
field	O
and	O
for	O
normal	O
fields	O
)	O
vector	O
at	O
location	O
.	O
This	O
layer	O
contains	O
probing	Method
filters	Method
scattered	O
in	O
space	O
,	O
each	O
with	O
probing	O
points	O
.	O
The	O
parameters	O
of	O
this	O
layer	O
are	O
the	O
locations	O
of	O
all	O
probing	O
points	O
,	O
where	O
indexes	O
the	O
filter	O
and	O
indexes	O
the	O
probing	O
point	O
within	O
each	O
filter	O
.	O
This	O
layer	O
simply	O
outputs	O
the	O
vector	O
at	O
the	O
probing	O
points	O
.	O
The	O
output	O
of	O
this	O
layer	O
forms	O
a	O
data	O
chunk	O
of	O
size	O
.	O
The	O
gradient	O
of	O
this	O
function	O
can	O
be	O
evaluated	O
by	O
numerical	Task
computation	Task
,	O
which	O
will	O
be	O
used	O
for	O
updating	O
the	O
locations	O
of	O
probing	O
points	O
in	O
the	O
back	Task
-	Task
propagation	Task
process	Task
.	O
This	O
formal	O
definition	O
emphasizes	O
why	O
we	O
need	O
the	O
input	O
being	O
represented	O
as	O
3D	O
fields	O
:	O
the	O
gradients	O
computed	O
from	O
the	O
input	O
fields	O
are	O
the	O
forces	O
to	O
push	O
the	O
probing	O
points	O
towards	O
more	O
informative	O
locations	O
until	O
they	O
converge	O
to	O
a	O
local	O
optimum	O
.	O
paragraph	O
:	O
DotProduct	Method
Layer	Method
.	O
The	O
input	O
to	O
this	O
layer	O
is	O
the	O
output	O
of	O
the	O
Sensor	Method
layer	Method
—	O
a	O
data	O
chunk	O
of	O
size	O
,	O
denoted	O
as	O
.	O
The	O
parameters	O
of	O
DotProduct	Method
layer	Method
are	O
the	O
filter	O
weights	O
associated	O
with	O
probing	O
points	O
,	O
i.e.	O
,	O
there	O
are	O
filters	O
,	O
each	O
of	O
length	O
,	O
in	O
channels	O
.	O
We	O
denote	O
the	O
set	O
of	O
parameters	O
as	O
.	O
The	O
function	O
at	O
this	O
layer	O
computes	O
a	O
dot	O
product	O
between	O
and	O
,	O
and	O
outputs	O
—	O
a	O
-	O
dimensional	O
vector	O
,	O
and	O
the	O
gradient	O
for	O
the	O
backward	O
pass	O
is	O
:	O
Typical	O
convolution	Method
encourages	O
weight	O
sharing	O
within	O
an	O
image	O
patch	O
by	O
‘	O
‘	O
zipping	O
’	O
’	O
the	O
patch	O
into	O
a	O
single	O
value	O
for	O
upper	O
layers	O
by	O
a	O
dot	Method
production	Method
between	O
the	O
patch	O
and	O
a	O
2D	Method
filter	Method
.	O
Our	O
DotProduct	Method
layer	Method
shares	O
the	O
same	O
‘	O
‘	O
zipping	O
’	O
’	O
idea	O
,	O
which	O
facilitates	O
to	O
fully	O
connect	O
it	O
:	O
probing	O
points	O
are	O
grouped	O
into	O
probing	Method
filters	Method
to	O
generate	O
output	O
with	O
lower	O
dimensionality	O
.	O
Another	O
option	O
in	O
designing	O
convolutional	Method
layers	Method
is	O
to	O
decide	O
whether	O
their	O
weights	O
should	O
be	O
shared	O
across	O
different	O
spatial	O
locations	O
.	O
In	O
2D	Method
CNNs	Method
,	O
these	O
parameters	O
are	O
usually	O
shared	O
when	O
processing	O
general	O
images	O
.	O
In	O
our	O
case	O
,	O
we	O
opt	O
not	O
to	O
share	O
the	O
weights	O
,	O
as	O
information	O
is	O
not	O
evenly	O
distributed	O
in	O
3D	O
space	O
,	O
and	O
we	O
encourage	O
our	O
probing	Method
filters	Method
to	O
individually	O
deviate	O
for	O
adapting	O
to	O
the	O
data	O
.	O
paragraph	O
:	O
Gaussian	Method
Layer	Method
.	O
Samples	O
in	O
locations	O
distant	O
to	O
the	O
object	O
surface	O
are	O
associated	O
with	O
large	O
distance	O
values	O
from	O
the	O
distance	O
field	O
.	O
Directly	O
feeding	O
them	O
into	O
the	O
DotProduct	Method
layer	Method
does	O
not	O
converge	O
and	O
thus	O
does	O
not	O
yield	O
reasonable	O
performance	O
.	O
To	O
emphasize	O
the	O
importance	O
of	O
samples	O
in	O
the	O
vicinity	O
of	O
the	O
object	O
surface	O
,	O
we	O
apply	O
a	O
Gaussian	Method
transform	Method
(	O
inverse	Method
exponential	Method
)	O
on	O
the	O
distances	O
so	O
that	O
regions	O
approaching	O
the	O
zero	O
surface	O
have	O
larger	O
weights	O
while	O
distant	O
regions	O
matter	O
less	O
.	O
.	O
We	O
implement	O
this	O
transform	O
with	O
a	O
Gaussian	Method
layer	Method
.	O
The	O
input	O
is	O
the	O
output	O
values	O
of	O
the	O
Sensor	Method
layer	Method
.	O
Let	O
us	O
assume	O
the	O
values	O
are	O
,	O
then	O
this	O
layer	O
applies	O
an	O
element	Method
-	Method
wise	Method
Gaussian	Method
transform	Method
,	O
and	O
the	O
gradient	O
is	O
for	O
the	O
backward	O
pass	O
.	O
paragraph	O
:	O
Complexity	Metric
of	O
Field	O
Probing	O
Layers	O
.	O
The	O
complexity	Metric
of	O
field	Method
probing	Method
layers	Method
is	O
,	O
where	O
is	O
the	O
number	O
of	O
probing	Method
filters	Method
,	O
is	O
the	O
number	O
of	O
probing	O
points	O
on	O
each	O
filter	O
,	O
and	O
is	O
the	O
number	O
of	O
input	O
fields	O
.	O
The	O
complexity	Metric
of	O
the	O
convolutional	Method
layer	Method
is	O
,	O
where	O
is	O
the	O
3D	O
kernel	O
size	O
,	O
is	O
the	O
output	O
channel	O
number	O
,	O
and	O
is	O
the	O
number	O
of	O
the	O
sliding	O
locations	O
for	O
each	O
dimension	O
.	O
In	O
field	Task
probing	Task
layers	Task
,	O
we	O
typically	O
use	O
,	O
,	O
and	O
(	O
distance	O
and	O
normal	O
fields	O
)	O
,	O
while	O
in	O
3D	Task
CNN	Task
,	O
and	O
.	O
Compared	O
with	O
convolutional	Method
layers	Method
,	O
field	Method
probing	Method
layers	Method
save	O
a	O
majority	O
of	O
computation	O
(	O
)	O
,	O
as	O
the	O
probing	Method
filters	Method
in	O
field	Method
probing	Method
layers	Method
are	O
capable	O
of	O
learning	O
where	O
to	O
‘	O
‘	O
sense	O
’	O
’	O
,	O
whereas	O
convolutional	Method
layers	Method
exhaustively	O
examine	O
everywhere	O
by	O
sliding	O
the	O
3D	O
kernels	O
.	O
paragraph	O
:	O
Initialization	Task
of	Task
Field	Task
Probing	Task
Layers	Task
.	O
There	O
are	O
two	O
sets	O
of	O
parameters	O
:	O
the	O
probing	O
point	O
locations	O
and	O
the	O
weights	O
associated	O
with	O
them	O
.	O
To	O
encourage	O
the	O
probing	O
points	O
to	O
explore	O
as	O
many	O
potential	O
locations	O
as	O
possible	O
,	O
we	O
initialize	O
them	O
to	O
be	O
widely	O
distributed	O
in	O
the	O
input	O
fields	O
.	O
We	O
first	O
divide	O
the	O
space	O
into	O
grids	O
and	O
then	O
generate	O
filters	Method
in	O
each	O
grid	O
.	O
Each	O
filter	O
is	O
initialized	O
as	O
a	O
line	O
segment	O
with	O
a	O
random	O
orientation	O
,	O
a	O
random	O
length	O
in	O
(	O
we	O
use	O
by	O
default	O
)	O
,	O
and	O
a	O
random	O
center	O
point	O
within	O
the	O
grid	O
it	O
belongs	O
to	O
(	O
Figure	O
[	O
reference	O
]	O
left	O
)	O
.	O
Note	O
that	O
a	O
probing	Method
filter	Method
spans	O
distantly	O
in	O
the	O
3D	O
space	O
,	O
so	O
they	O
capture	O
long	O
range	O
effects	O
well	O
.	O
This	O
is	O
a	O
property	O
that	O
distinguishes	O
our	O
design	O
from	O
those	O
convolutional	Method
layers	Method
,	O
as	O
they	O
have	O
to	O
increase	O
the	O
kernel	O
size	O
to	O
capture	O
long	O
range	O
effects	O
,	O
at	O
the	O
cost	O
of	O
increased	O
complexity	Metric
.	O
The	O
weights	O
of	O
field	Method
probing	Method
filters	Method
are	O
initialized	O
by	O
the	O
Xavier	Method
scheme	Method
.	O
In	O
Figure	O
[	O
reference	O
]	O
right	O
,	O
weights	O
for	O
distance	O
field	O
are	O
visualized	O
by	O
probing	O
point	O
colors	O
and	O
weights	O
for	O
normal	O
fields	O
by	O
arrows	O
attached	O
to	O
each	O
probing	O
point	O
.	O
paragraph	O
:	O
FPNN	Method
Architecture	O
and	O
Usage	O
.	O
Field	Method
probing	Method
layers	Method
transform	O
input	O
3D	O
fields	O
into	O
an	O
intermediate	Method
representation	Method
,	O
which	O
can	O
further	O
be	O
processed	O
and	O
eventually	O
linked	O
to	O
task	O
specific	O
loss	O
layers	O
(	O
Figure	O
[	O
reference	O
]	O
)	O
.	O
To	O
further	O
encourage	O
long	O
range	O
connections	O
,	O
we	O
feed	O
the	O
output	O
of	O
our	O
field	Method
probing	Method
layers	Method
into	O
fully	Method
connected	Method
layers	Method
.	O
The	O
advantage	O
of	O
long	O
range	O
connections	O
makes	O
it	O
possible	O
to	O
stick	O
with	O
a	O
small	O
number	O
of	O
probing	Method
filters	Method
,	O
while	O
the	O
small	O
number	O
of	O
probing	Method
filters	Method
makes	O
it	O
possible	O
to	O
directly	O
use	O
fully	O
connected	O
layers	O
.	O
Object	Task
classification	Task
is	O
widely	O
used	O
in	O
computer	Task
vision	Task
as	O
a	O
testbed	O
for	O
evaluating	O
neural	Method
network	Method
designs	Method
,	O
and	O
the	O
neural	Method
network	Method
parameters	Method
learned	O
from	O
this	O
task	O
may	O
be	O
transferred	O
to	O
other	O
high	Task
-	Task
level	Task
understanding	Task
tasks	Task
such	O
as	O
object	Task
retrieval	Task
and	O
scene	Task
parsing	Task
.	O
Thus	O
we	O
choose	O
3D	Task
object	Task
classification	Task
as	O
the	O
task	O
for	O
evaluating	O
our	O
FPNN	Method
.	O
section	O
:	O
Results	O
and	O
Discussions	O
subsection	O
:	O
Timing	O
We	O
implemented	O
our	O
field	Method
probing	Method
layers	Method
in	O
Caffe	Method
.	O
The	O
Sensor	Method
layer	Method
is	O
parallelized	O
by	O
assigning	O
computation	O
on	O
each	O
probing	O
point	O
to	O
one	O
GPU	O
thread	O
,	O
and	O
DotProduct	Method
layer	Method
by	O
assigning	O
computation	O
on	O
each	O
probing	Method
filter	Method
to	O
one	O
GPU	O
thread	O
.	O
Figure	O
[	O
reference	O
]	O
shows	O
a	O
run	Metric
time	Metric
comparison	Metric
between	O
convonlutional	Method
layers	Method
and	O
field	Method
probing	Method
layers	Method
on	O
different	O
input	O
resolutions	O
.	O
The	O
computation	Metric
cost	Metric
of	O
our	O
field	Method
probing	Method
layers	Method
is	O
agnostic	O
to	O
input	O
resolutions	O
,	O
the	O
slight	O
increase	O
of	O
the	O
run	Metric
time	Metric
on	O
higher	O
resolution	O
is	O
due	O
to	O
GPU	O
memory	O
latency	O
introduced	O
by	O
the	O
larger	O
3D	O
fields	O
.	O
Note	O
that	O
the	O
convolutional	Method
layers	Method
in	O
are	O
based	O
on	O
highly	O
optimized	O
cuBlas	Method
library	Method
from	O
NVIDIA	Method
,	O
while	O
our	O
field	Method
probing	Method
layers	Method
are	O
implemented	O
with	O
our	O
naive	O
parallelism	O
,	O
which	O
is	O
likely	O
to	O
be	O
further	O
improved	O
.	O
subsection	O
:	O
Datasets	O
and	O
Evaluation	Metric
Protocols	Metric
We	O
use	O
ModelNet40	Method
(	O
12	O
,	O
311	O
models	O
from	O
40	O
categories	O
,	O
training	O
/	O
testing	O
split	O
with	O
9	O
,	O
843	O
/	O
2	O
,	O
468	O
models	O
)	O
—	O
the	O
standard	O
benchmark	O
for	O
3D	Task
object	Task
classification	Task
task	Task
,	O
in	O
our	O
experiments	O
.	O
Models	O
in	O
this	O
dataset	O
are	O
already	O
aligned	O
with	O
a	O
canonical	O
orientation	O
.	O
For	O
3D	Task
object	Task
recognition	Task
scenarios	Task
in	O
real	O
world	O
,	O
the	O
gravity	O
direction	O
can	O
often	O
be	O
captured	O
by	O
the	O
sensor	O
,	O
but	O
the	O
horizontal	O
‘	O
‘	O
facing	O
’	O
’	O
direction	O
of	O
the	O
objects	O
are	O
unknown	O
.	O
We	O
augment	O
ModelNet40	Material
data	Material
by	O
randomly	O
rotating	O
the	O
shapes	O
horizontally	O
.	O
Note	O
that	O
this	O
is	O
done	O
for	O
both	O
training	O
and	O
testing	O
samples	O
,	O
thus	O
in	O
the	O
testing	O
phase	O
,	O
the	O
orientation	O
of	O
the	O
inputs	O
are	O
unknown	O
.	O
This	O
allows	O
us	O
to	O
assess	O
how	O
well	O
the	O
trained	O
network	O
perform	O
on	O
real	O
world	O
data	O
.	O
subsection	O
:	O
Performance	O
of	O
Field	Method
Probing	Method
Layers	Method
We	O
train	O
our	O
FPNN	Method
iterations	O
on	O
distance	O
field	O
with	O
batch	O
size	O
.	O
,	O
with	O
SGD	Method
solver	Method
,	O
learning	Metric
rate	Metric
,	O
momentum	O
,	O
and	O
weight	Method
decay	Method
.	O
Trying	O
to	O
study	O
the	O
performance	O
of	O
our	O
field	Method
probing	Method
layers	Method
separately	O
,	O
we	O
build	O
up	O
an	O
FPNN	Method
with	O
only	O
one	O
fully	Method
connected	Method
layer	Method
that	O
converts	O
the	O
output	O
of	O
field	Method
probing	Method
layers	Method
into	O
the	O
representation	O
for	O
softmax	Task
classification	Task
loss	Task
(	O
1	O
-	O
FC	O
setting	O
)	O
.	O
Batch	Method
normalization	Method
and	O
rectified	Method
-	Method
linear	Method
unit	Method
are	O
used	O
in	O
-	O
between	O
our	O
field	Method
probing	Method
layers	Method
and	O
the	O
fully	Method
connected	Method
layer	Method
for	O
reducing	O
internal	O
covariate	O
shift	O
and	O
introducing	O
non	O
-	O
linearity	O
.	O
We	O
train	O
the	O
network	O
without	O
/	O
with	O
updating	O
the	O
field	O
probing	O
layer	O
parameters	O
.	O
We	O
show	O
their	O
top	O
-	O
1	O
accuracy	Metric
on	O
3D	Task
object	Task
classification	Task
task	Task
on	O
dataset	O
with	O
single	O
testing	O
view	O
in	O
Table	O
[	O
reference	O
]	O
.	O
It	O
is	O
clear	O
that	O
our	O
field	Method
probing	Method
layers	Method
learned	O
to	O
sense	O
the	O
input	O
field	O
more	O
intelligently	O
,	O
with	O
a	O
performance	O
gain	O
from	O
to	O
.	O
Note	O
that	O
,	O
what	O
achieved	O
by	O
this	O
simple	O
network	O
,	O
,	O
is	O
already	O
better	O
than	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
3DCNN	Method
before	O
(	O
in	O
and	O
in	O
)	O
.	O
We	O
also	O
evaluate	O
the	O
performance	O
of	O
our	O
field	Method
probing	Method
layers	Method
in	O
the	O
context	O
of	O
a	O
deeper	O
FPNN	Method
,	O
where	O
four	O
fully	Method
connected	Method
layers	Method
,	O
with	O
in	O
-	O
between	O
batch	O
normalization	O
,	O
rectified	O
-	O
linear	O
unit	O
and	O
Dropout	O
layers	O
,	O
are	O
used	O
(	O
4	Method
-	Method
FCs	Method
setting	O
)	O
.	O
As	O
shown	O
in	O
Table	O
[	O
reference	O
]	O
,	O
the	O
deeper	O
FPNN	Method
performs	O
better	O
,	O
while	O
the	O
gap	O
between	O
with	O
and	O
without	O
field	O
probing	O
layers	O
,	O
,	O
is	O
smaller	O
than	O
that	O
in	O
one	O
fully	O
connected	O
FPNN	Method
setting	O
.	O
This	O
is	O
not	O
surprising	O
,	O
as	O
the	O
additional	O
fully	O
connected	O
layers	O
,	O
with	O
many	O
parameters	O
introduced	O
,	O
have	O
strong	O
learning	O
capability	O
.	O
The	O
performance	O
gap	O
introduced	O
by	O
our	O
field	Method
probing	Method
layers	Method
is	O
a	O
precious	O
extra	O
over	O
a	O
strong	O
baseline	O
.	O
It	O
is	O
important	O
to	O
note	O
that	O
in	O
both	O
settings	O
(	O
1	O
-	O
FC	O
and	O
4	Method
-	Method
FCs	Method
)	O
,	O
our	O
FPNNs	Method
provides	O
reasonable	O
performance	O
even	O
without	O
optimizing	O
the	O
field	O
probing	O
layers	O
.	O
This	O
confirms	O
that	O
long	O
range	O
connections	O
among	O
the	O
sensors	O
are	O
beneficial	O
.	O
Furthermore	O
,	O
we	O
evaluate	O
our	O
FPNNs	Method
with	O
multiple	O
input	O
fields	O
(	O
+	O
NF	Method
setting	O
)	O
.	O
We	O
did	O
not	O
only	O
employ	O
distance	O
fields	O
,	O
but	O
also	O
normal	O
fields	O
for	O
our	O
probing	O
layers	O
and	O
found	O
a	O
consistent	O
performance	O
gain	O
for	O
both	O
of	O
the	O
aforementioned	O
FPNNs	Method
(	O
see	O
Table	O
[	O
reference	O
]	O
)	O
.	O
Since	O
normal	O
fields	O
are	O
derived	O
from	O
distance	O
fields	O
,	O
the	O
same	O
group	O
of	O
probing	Method
filters	Method
are	O
used	O
for	O
both	O
fields	O
.	O
Employing	O
multiple	O
fields	O
in	O
the	O
field	O
probing	O
layers	O
with	O
different	O
groups	O
of	O
filters	O
potentially	O
enables	O
even	O
higher	O
performance	O
.	O
paragraph	O
:	O
Robustness	Metric
Against	O
Spatial	O
Perturbations	O
.	O
We	O
evaluate	O
our	O
FPNNs	Method
on	O
different	O
levels	O
of	O
spatial	O
perturbations	O
,	O
and	O
summarize	O
the	O
results	O
in	O
Table	O
[	O
reference	O
]	O
,	O
where	O
indicates	O
random	O
horizontal	O
rotation	O
,	O
indicates	O
plus	O
a	O
small	O
random	O
rotation	O
(	O
,	O
)	O
in	O
the	O
other	O
two	O
directions	O
,	O
indicates	O
random	O
translations	O
within	O
range	O
(	O
,	O
)	O
of	O
the	O
object	O
size	O
in	O
all	O
directions	O
,	O
indicates	O
random	O
scaling	O
within	O
range	O
(	O
,	O
)	O
in	O
all	O
directions	O
.	O
and	O
shares	O
the	O
same	O
notations	O
,	O
but	O
with	O
even	O
stronger	O
rotation	O
and	O
translation	O
,	O
and	O
are	O
used	O
in	O
for	O
evaluating	O
the	O
performance	O
of	O
.	O
Note	O
that	O
such	O
perturbations	O
are	O
done	O
on	O
both	O
training	O
and	O
testing	O
samples	O
.	O
It	O
is	O
clear	O
that	O
our	O
FPNNs	Method
are	O
robust	O
against	O
spatial	O
perturbations	O
.	O
paragraph	O
:	O
Advantage	O
of	O
Long	O
Range	O
Connections	O
.	O
We	O
evaluate	O
our	O
FPNNs	Method
with	O
different	O
range	O
parameters	O
used	O
in	O
initializing	O
the	O
probing	Method
filters	Method
,	O
and	O
summarize	O
the	O
results	O
in	O
Table	O
[	O
reference	O
]	O
.	O
Note	O
that	O
since	O
the	O
output	O
dimensionality	O
of	O
our	O
field	Method
probing	Method
layers	Method
is	O
low	O
enough	O
to	O
be	O
directly	O
feed	O
into	O
fully	O
connected	O
layers	O
,	O
distant	O
sensor	O
information	O
is	O
directly	O
coupled	O
by	O
them	O
.	O
This	O
is	O
a	O
desirable	O
property	O
,	O
however	O
,	O
it	O
poses	O
the	O
difficulty	O
to	O
study	O
the	O
advantage	O
of	O
field	O
probing	O
layers	O
in	O
coupling	Task
long	Task
range	Task
information	Task
separately	O
.	O
Table	O
[	O
reference	O
]	O
shows	O
that	O
even	O
if	O
the	O
following	O
fully	Method
connected	Method
layer	Method
has	O
the	O
capability	O
to	O
couple	O
distance	O
information	O
,	O
the	O
long	O
range	O
connections	O
introduced	O
in	O
our	O
field	O
probing	O
layers	O
are	O
beneficial	O
.	O
paragraph	O
:	O
Performance	O
on	O
Different	O
Field	O
Resolutions	O
.	O
We	O
evaluate	O
our	O
FPNNs	Method
on	O
different	O
input	O
field	O
resolutions	O
,	O
and	O
summarize	O
the	O
results	O
in	O
Table	O
[	O
reference	O
]	O
.	O
Higher	O
resolution	O
input	O
fields	O
can	O
represent	O
input	O
data	O
more	O
accurately	O
,	O
and	O
Table	O
[	O
reference	O
]	O
shows	O
that	O
our	O
FPNN	Method
can	O
take	O
advantage	O
of	O
the	O
more	O
accurate	O
representations	O
.	O
Since	O
the	O
computation	Metric
cost	Metric
of	O
our	O
field	Method
probing	Method
layers	Method
is	O
agnostic	O
to	O
the	O
resolution	O
of	O
the	O
data	Method
representation	Method
,	O
higher	O
resolution	O
input	O
fields	O
are	O
preferred	O
for	O
better	O
performance	O
,	O
while	O
coupling	O
with	O
efficient	O
data	Method
structures	Method
reduces	O
the	O
I	Metric
/	Metric
O	Metric
footprint	Metric
.	O
paragraph	O
:	O
‘	O
‘	O
Sharpness	O
’	O
’	O
of	O
Gaussian	O
Layer	O
.	O
The	O
hyper	O
-	O
parameter	O
in	O
Gaussian	Method
layer	Method
controls	O
how	O
‘	O
‘	O
sharp	O
’	O
’	O
is	O
the	O
transform	O
.	O
We	O
select	O
its	O
value	O
empirically	O
in	O
our	O
experiments	O
,	O
and	O
the	O
best	O
performance	O
is	O
given	O
when	O
we	O
use	O
of	O
the	O
object	O
size	O
.	O
Smaller	O
slightly	O
hurts	O
the	O
performance	O
(	O
)	O
,	O
but	O
has	O
the	O
potential	O
of	O
reducing	O
I	Metric
/	Metric
O	Metric
footprint	Metric
.	O
paragraph	O
:	O
FPNN	Method
Features	O
and	O
Visual	O
Similarity	O
.	O
Figure	O
[	O
reference	O
]	O
shows	O
a	O
visualization	O
of	O
the	O
features	O
extracted	O
by	O
the	O
FPNN	Method
trained	O
for	O
a	O
classification	Task
task	Task
.	O
Our	O
FPNN	Method
is	O
capable	O
of	O
capturing	O
3D	O
geometric	O
structures	O
such	O
that	O
it	O
allows	O
to	O
map	O
3D	Method
models	Method
that	O
belong	O
to	O
the	O
same	O
categories	O
(	O
indicated	O
by	O
colors	O
)	O
to	O
similar	O
regions	O
in	O
the	O
feature	O
space	O
.	O
More	O
specifically	O
,	O
our	O
FPNN	Method
maps	O
3D	Method
models	Method
into	O
points	O
in	O
a	O
high	O
dimensional	O
feature	O
space	O
,	O
where	O
the	O
distances	O
between	O
the	O
points	O
measure	O
the	O
similarity	O
between	O
their	O
corresponding	O
3D	Method
models	Method
.	O
As	O
can	O
be	O
seen	O
from	O
Figure	O
[	O
reference	O
]	O
(	O
better	O
viewed	O
in	O
zoomin	O
mode	O
)	O
,	O
the	O
FPNN	Method
feature	O
distances	O
between	O
3D	Method
models	Method
represent	O
their	O
shape	O
similarities	O
,	O
thus	O
FPNN	Method
features	O
can	O
support	O
shape	Task
exploration	Task
and	O
retrieval	Task
tasks	Task
.	O
subsection	O
:	O
Generalizability	O
of	O
FPNN	Method
Features	O
One	O
superior	O
characteristic	O
of	O
CNN	O
features	O
is	O
that	O
features	O
from	O
one	O
task	O
or	O
dataset	O
can	O
be	O
transferred	O
to	O
another	O
task	O
or	O
dataset	O
.	O
We	O
evaluate	O
the	O
generalizability	O
of	O
FPNN	Method
features	O
by	O
cross	Method
validation	Method
—	O
we	O
train	O
on	O
one	O
dataset	O
and	O
test	O
on	O
another	O
.	O
We	O
first	O
split	O
(	O
lexicographically	O
by	O
the	O
category	O
names	O
)	O
into	O
two	O
parts	O
and	O
,	O
where	O
each	O
of	O
them	O
contains	O
non	O
-	O
overlapping	O
categories	O
.	O
Then	O
we	O
train	O
two	O
FPNNs	Method
in	O
a	O
1	Method
-	Method
FC	Method
setting	Method
(	O
updating	O
both	O
field	Method
probing	Method
layers	Method
and	O
the	O
only	O
one	O
fully	Method
connected	Method
layer	Method
)	O
on	O
these	O
two	O
datasets	O
,	O
achieving	O
and	O
accuracy	Metric
,	O
respectively	O
(	O
the	O
second	O
column	O
in	O
Table	O
[	O
reference	O
]	O
)	O
.	O
Finally	O
,	O
we	O
fine	O
tune	O
only	O
the	O
fully	Method
connected	Method
layer	Method
of	O
these	O
two	O
FPNNs	Method
on	O
the	O
dataset	O
that	O
they	O
were	O
not	O
trained	O
from	O
,	O
and	O
achieved	O
and	O
on	O
and	O
,	O
respectively	O
(	O
the	O
fourth	O
column	O
in	O
Table	O
[	O
reference	O
]	O
)	O
,	O
which	O
is	O
comparable	O
to	O
that	O
directly	O
trained	O
from	O
the	O
testing	O
categories	O
.	O
We	O
also	O
trained	O
two	O
FPNNs	Method
in	O
1	Method
-	Method
FC	Method
setting	Method
with	O
updating	O
only	O
the	O
fully	O
connected	O
layer	O
,	O
which	O
achieves	O
and	O
accuracy	Metric
on	O
and	O
,	O
respectively	O
(	O
the	O
third	O
column	O
in	O
Table	O
[	O
reference	O
]	O
)	O
.	O
These	O
two	O
FPNNs	Method
do	O
not	O
perform	O
as	O
well	O
as	O
the	O
fine	Method
-	Method
tuned	Method
FPNNs	Method
(	O
on	O
and	O
on	O
)	O
,	O
although	O
all	O
of	O
them	O
only	O
update	O
the	O
fully	Method
connected	Method
layer	Method
.	O
These	O
experiments	O
show	O
that	O
the	O
field	Method
probing	Method
filters	Method
learned	O
from	O
one	O
dataset	O
can	O
be	O
applied	O
to	O
another	O
one	O
.	O
subsection	O
:	O
Comparison	O
with	O
State	O
-	O
of	O
-	O
the	O
-	O
art	O
We	O
compare	O
the	O
performance	O
of	O
our	O
FPNNs	Method
against	O
two	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
approaches	O
—	O
SubvolSup	Method
+	O
BN	Method
and	O
MVCNN	Method
-	O
MultiRes	Method
,	O
both	O
from	O
,	O
in	O
Table	O
[	O
reference	O
]	O
.	O
SubvolSup	Method
+	O
BN	Method
is	O
a	O
subvolume	O
supervised	O
volumetric	O
3D	Task
CNN	Task
,	O
with	O
batch	Method
normalization	Method
applied	O
during	O
the	O
training	O
,	O
and	O
MVCNN	Method
-	O
MultiRes	Method
is	O
a	O
multi	Method
-	Method
view	Method
multi	Method
-	Method
resolution	Method
image	Method
based	Method
2D	Method
CNN	Method
.	O
Note	O
that	O
our	O
FPNN	Method
achieves	O
comparable	O
performance	O
to	O
SubvolSup	Method
+	O
BN	Method
with	O
less	O
computational	Metric
complexity	Metric
.	O
However	O
,	O
both	O
our	O
FPNN	Method
and	O
SubvolSup	Method
+	O
BN	Method
do	O
not	O
perform	O
as	O
well	O
as	O
MVCNN	Method
-	O
MultiRes	Method
.	O
It	O
is	O
intriguing	O
to	O
answer	O
the	O
question	O
why	O
methods	O
directly	O
operating	O
on	O
3D	O
data	O
can	O
not	O
match	O
or	O
outperform	O
multi	Method
-	Method
view	Method
2D	Method
CNNs	Method
.	O
The	O
research	O
on	O
closing	O
the	O
gap	O
between	O
these	O
modalities	O
can	O
lead	O
to	O
a	O
deeper	O
understanding	O
of	O
both	O
2D	O
images	O
and	O
3D	O
shapes	O
or	O
even	O
higher	O
dimensional	O
data	O
.	O
subsection	O
:	O
Limitations	O
and	O
Future	O
Work	O
paragraph	O
:	O
FPNN	Method
on	O
Generic	O
Fields	O
.	O
Our	O
framework	O
provides	O
a	O
general	O
means	O
for	O
optimizing	Task
probing	Task
locations	Task
in	Task
3D	Task
fields	Task
where	O
the	O
gradients	O
can	O
be	O
computed	O
.	O
We	O
suspect	O
this	O
capability	O
might	O
be	O
particularly	O
important	O
for	O
analyzing	Task
3D	Task
data	Task
with	O
invisible	O
internal	O
structures	O
.	O
Moreover	O
,	O
our	O
approach	O
can	O
easily	O
be	O
extended	O
into	O
higher	O
dimensional	O
fields	O
,	O
where	O
a	O
careful	O
storage	O
design	O
of	O
the	O
input	O
fields	O
is	O
important	O
for	O
making	O
the	O
I	Metric
/	Metric
O	Metric
footprint	Metric
tractable	O
though	O
.	O
paragraph	O
:	O
From	O
Probing	Method
Filters	Method
to	O
Probing	Task
Network	Task
.	O
In	O
our	O
current	O
framework	O
,	O
the	O
probing	Method
filters	Method
are	O
independent	O
to	O
each	O
other	O
,	O
which	O
means	O
,	O
they	O
do	O
not	O
share	O
locations	O
and	O
weights	O
,	O
which	O
may	O
result	O
in	O
too	O
many	O
parameters	O
for	O
small	O
training	O
sets	O
.	O
On	O
the	O
other	O
hand	O
,	O
fully	O
shared	O
weights	O
greatly	O
limit	O
the	O
representation	O
power	O
of	O
the	O
probing	Method
filters	Method
.	O
A	O
trade	O
-	O
off	O
might	O
be	O
learning	O
a	O
probing	Method
network	Method
,	O
where	O
each	O
probing	O
point	O
belongs	O
to	O
multiple	O
‘	O
‘	O
pathes	O
’	O
’	O
in	O
the	O
network	O
for	O
partially	O
sharing	O
parameters	O
.	O
paragraph	O
:	O
FPNN	Method
for	O
Finer	Task
Shape	Task
Understanding	Task
.	O
Our	O
current	O
approach	O
is	O
superior	O
for	O
extracting	O
robust	Task
global	Task
descriptions	Task
of	Task
the	Task
input	Task
data	Task
,	O
but	O
lacks	O
the	O
capability	O
of	O
understanding	O
finer	O
structures	O
inside	O
the	O
input	O
data	O
.	O
This	O
capability	O
might	O
be	O
realized	O
by	O
strategically	O
initializing	O
the	O
probing	Method
filters	Method
hierarchically	Method
,	O
and	O
jointly	O
optimizing	Method
filters	Method
at	O
different	O
hierarchies	O
.	O
section	O
:	O
Conclusions	O
We	O
proposed	O
a	O
novel	O
design	O
for	O
feature	Task
extraction	Task
from	O
3D	O
data	O
,	O
whose	O
computation	Metric
cost	Metric
is	O
agnostic	O
to	O
the	O
resolution	Method
of	Method
data	Method
representation	Method
.	O
A	O
significant	O
advantage	O
of	O
our	O
design	O
is	O
that	O
long	O
range	O
interaction	O
can	O
be	O
easily	O
coupled	O
.	O
As	O
3D	O
data	O
is	O
becoming	O
more	O
accessible	O
,	O
we	O
believe	O
that	O
our	O
method	O
will	O
stimulate	O
more	O
work	O
on	O
feature	Task
learning	Task
from	O
3D	O
data	O
.	O
We	O
open	O
-	O
source	O
our	O
code	O
at	O
for	O
encouraging	O
future	O
developments	O
.	O
subsubsection	O
:	O
Acknowledgments	O
We	O
would	O
first	O
like	O
to	O
thank	O
all	O
the	O
reviewers	O
for	O
their	O
valuable	O
comments	O
and	O
suggestions	O
.	O
Yangyan	O
thanks	O
Daniel	O
Cohen	O
-	O
Or	O
and	O
Zhenhua	O
Wang	O
for	O
their	O
insightful	O
proofreading	O
.	O
The	O
work	O
was	O
supported	O
in	O
part	O
by	O
NSF	O
grants	O
DMS	O
-	O
1546206	O
and	O
IIS	O
-	O
1528025	O
,	O
UCB	O
MURI	O
grant	O
N00014	O
-	O
13	O
-	O
1	O
-	O
0341	O
,	O
Chinese	O
National	O
973	O
Program	O
(	O
2015CB352501	O
)	O
,	O
the	O
Stanford	O
AI	O
Lab	O
-	O
Toyota	O
Center	O
for	O
Artificial	O
Intelligence	O
Research	O
,	O
the	O
Max	O
Planck	O
Center	O
for	O
Visual	O
Computing	O
and	O
Communication	O
,	O
and	O
a	O
Google	O
Focused	O
Research	O
award	O
.	O
bibliography	O
:	O
References	O
