ï€  O
section O
: O
section O
: O
I. O
INTRODUCTION O
OWADAYS Method
DL Method
provides O
state O
- O
of O
- O
the O
- O
art O
performance O
for O
image O
classification Task
[ O
reference O
] O
, O
segmentation Task
[ O
reference O
] O
, O
detection Task
and Task
tracking Task
[ O
reference O
] O
, O
and O
captioning Task
[ O
reference O
] O
. O
Since O
2012 O
, O
several O
Deep Method
Convolutional Method
Neural Method
Network Method
( O
DCNN Method
) O
models O
have O
been O
proposed O
such O
as O
AlexNet Method
[ O
reference O
] O
, O
VGG Method
[ O
reference O
] O
, O
GoogleNet Method
[ O
reference O
] O
, O
Residual Method
Net Method
[ O
reference O
] O
, O
DenseNet Method
[ O
reference O
] O
, O
and O
CapsuleNet Method
[ O
reference O
] O
[ O
reference O
] O
. O
A O
DL Method
based Method
approach Method
( O
CNN Method
in O
particular O
) O
provides O
state O
- O
of O
- O
the O
- O
art O
performance O
for O
classification Task
and O
segmentation Task
tasks O
for O
several O
reasons O
: O
first O
, O
activation Method
functions Method
resolve O
training Metric
problems O
in O
DL Method
approaches Method
. O
Second O
, O
dropout Method
helps O
regularize O
the O
networks O
. O
Third O
, O
several O
efficient O
optimization Method
techniques Method
are O
available O
for O
training Metric
CNN Method
models Method
[ O
reference O
] O
. O
However O
, O
in O
most O
cases O
, O
models O
are O
explored O
and O
evaluated O
using O
classification Task
tasks O
on O
very O
large O
- O
scale O
datasets O
like O
ImageNet Material
[ O
reference O
] O
, O
where O
the O
outputs O
of O
the O
classification Task
tasks O
are O
single O
label O
or O
probability O
values O
. O
Alternatively O
, O
small Method
architecturally Method
variant Method
models Method
are O
used O
for O
semantic O
image O
segmentation Task
tasks O
. O
For O
example O
, O
a O
fully Method
- Method
connected Method
convolutional Method
neural Method
network Method
( O
FCN Method
) O
also O
provides O
state O
- O
of O
- O
the O
- O
art O
results O
for O
image O
segmentation Task
tasks O
in O
computer Task
vision Task
[ O
reference O
] O
. O
Another O
variant O
of O
FCN Method
was O
also O
proposed O
which O
is O
called O
SegNet Method
[ O
reference O
] O
. O
Due O
to O
the O
great O
success O
of O
DCNNs Method
in O
the O
field O
of O
computer Task
vision Task
, O
different O
variants O
of O
this O
approach O
are O
applied O
in O
different O
modalities O
of O
medical Method
imaging Method
including O
segmentation Task
, O
classification Task
, O
detection Task
, O
registration Task
, O
and O
medical Task
information Task
processing Task
. O
The O
medical Method
imaging Method
comes O
from O
different O
imaging Method
techniques Method
such O
as O
Computer Method
Tomography Method
( O
CT Method
) O
, O
ultrasound Method
, O
X Method
- Method
ray Method
, O
and O
Magnetic Method
Resonance Method
Imaging Method
( O
MRI Method
) O
. O
The O
goal O
of O
Computer Task
- Task
Aided Task
Diagnosis Task
( O
CAD Task
) O
is O
to O
obtain O
a O
faster O
and O
better O
diagnosis Task
to O
ensure O
better O
treatment O
of O
a O
large O
number O
of O
people O
at O
the O
same O
time O
. O
Additionally O
, O
efficient O
automatic Task
processing Task
without O
human O
involvement O
to O
reduce O
human Metric
error Metric
and O
also O
reduces O
overall O
time O
and O
cost Metric
. O
Due O
to O
the O
slow O
process O
and O
tedious O
nature O
of O
Mahmudul O
Hasan O
[ O
reference O
] O
, O
is O
with O
Comcast O
Labs O
, O
Washington O
, O
DC O
, O
USA O
. O
( O
e O
- O
mail O
: O
mahmud.ucr@gmail.com O
) O
. O
manual O
segmentation Task
approaches O
, O
there O
is O
a O
significant O
demand O
for O
computer Method
algorithms Method
that O
can O
do O
segmentation Task
quickly O
and O
accurately O
without O
human O
interaction O
. O
However O
, O
there O
are O
some O
limitations O
of O
medical O
image O
segmentation Task
including O
data O
scarcity O
and O
class O
imbalance O
. O
Most O
of O
the O
time O
the O
large O
number O
of O
labels O
( O
often O
in O
the O
thousands O
) O
for O
training Metric
is O
not O
available O
for O
several O
reasons O
[ O
reference O
] O
. O
Labeling O
the O
dataset O
requires O
an O
expert O
in O
this O
field O
which O
is O
expensive O
, O
and O
it O
requires O
a O
lot O
of O
effort O
and O
time O
. O
Sometimes O
, O
different O
data Method
transformation Method
or Method
augmentation Method
techniques Method
( O
data Method
whitening Method
, O
rotation O
, O
translation O
, O
and O
scaling O
) O
are O
applied O
for O
increasing O
the O
number O
of O
labeled O
samples O
available O
[ O
reference O
] O
. O
In O
addition O
, O
patch Method
based Method
approaches Method
are O
used O
for O
solving O
class Task
imbalance Task
problems Task
. O
In O
this O
work O
, O
we O
have O
evaluated O
the O
proposed O
approaches O
on O
both O
patch Method
- Method
based Method
and Method
entire Method
image Method
- Method
based Method
approaches Method
. O
However O
, O
to O
switch O
from O
the O
patch Method
- Method
based Method
approach Method
to O
the O
pixel Method
- Method
based Method
approach Method
that O
works O
with O
the O
entire O
image O
, O
we O
must O
be O
aware O
of O
the O
class Task
imbalance Task
problem Task
. O
In O
the O
case O
of O
semantic O
segmentation Task
, O
the O
image O
backgrounds O
are O
assigned O
a O
label O
and O
the O
foreground O
regions O
are O
assigned O
a O
target O
class O
. O
Therefore O
, O
the O
class Task
imbalance Task
problem Task
is O
resolved O
without O
any O
trouble O
. O
Two O
advanced O
techniques O
including O
cross Metric
- Metric
entropy Metric
loss Metric
and O
dice Metric
similarity Metric
are O
introduced O
for O
efficient O
training Task
of Task
classification Task
and O
segmentation Task
tasks Task
in O
[ O
reference O
][ O
reference O
] O
. O
Furthermore O
, O
in O
medical Task
image Task
processing Task
, O
global Task
localization Task
and O
context Task
modulation Task
is O
very O
often O
applied O
for O
localization Task
tasks Task
. O
Each O
pixel O
is O
assigned O
a O
class O
label O
with O
a O
desired O
boundary O
that O
is O
related O
to O
the O
contour O
of O
the O
target O
lesion O
in O
identification Task
tasks Task
. O
To O
define O
these O
target O
lesion O
boundaries O
, O
we O
must O
emphasize O
the O
related O
pixels O
. O
Landmark Task
detection Task
in O
medical Method
imaging Method
[ O
reference O
][ O
reference O
] O
is O
one O
example O
of O
this O
. O
There O
were O
several O
traditional O
machine Method
learning Method
and Method
image Method
processing Method
techniques Method
available O
for O
medical O
image O
segmentation Task
tasks O
before O
the O
DL Task
revolution Task
, O
including O
amplitude O
segmentation Task
based O
on O
histogram O
features O
[ O
reference O
] O
, O
the O
region O
based O
segmentation Task
method O
[ O
reference O
] O
, O
and O
the O
graph Method
- Method
cut Method
approach Method
[ O
reference O
] O
. O
However O
, O
semantic O
segmentation Task
approaches O
that O
utilize O
DL Method
have O
become O
very O
popular O
in O
recent O
years O
in O
the O
field O
of O
medical O
image O
segmentation Task
, O
lesion Task
detection Task
, O
and O
localization Task
[ O
reference O
] O
. O
In O
addition O
, O
DL Method
based Method
approaches Method
are O
known O
as O
universal Method
learning Method
approaches Method
, O
where O
a O
single O
model O
can O
be O
utilized O
efficiently O
in O
different O
modalities O
of O
medical Method
imaging Method
such O
as O
MRI Method
, O
CT Method
, O
and O
X Method
- Method
ray Method
. O
According O
to O
a O
recent O
survey O
, O
DL Method
approaches Method
are O
applied O
to O
almost O
all O
modalities O
of O
medical Method
imagining Method
[ O
reference O
][ O
reference O
] O
. O
Furthermore O
, O
the O
highest O
number O
of O
papers O
have O
been O
published O
on O
segmentation Task
tasks Task
in O
different O
modalities O
of O
medical Method
imaging Method
[ O
reference O
][ O
reference O
] O
. O
A O
DCNN Method
based O
brain O
tumor O
segmentation Task
and O
detection O
method O
was O
proposed O
in O
[ O
reference O
] O
. O
From O
an O
architectural O
point O
of O
view O
, O
the O
CNN Method
model Method
for O
classification Task
tasks O
requires O
an O
encoding Method
unit Method
and O
provides O
class O
probability O
as O
an O
output O
. O
In O
classification Task
tasks O
, O
we O
have O
performed O
convolution Method
operations Method
with O
activation O
functions O
followed O
by O
sub Method
- Method
sampling Method
layers Method
which O
reduces O
the O
dimensionality O
of O
the O
feature O
maps O
. O
As O
the O
input O
samples O
traverse O
through O
the O
layers O
of O
the O
network O
, O
the O
number O
of O
feature O
maps O
increases O
but O
the O
dimensionality O
of O
the O
feature O
maps O
decreases O
. O
This O
is O
shown O
in O
the O
first O
part O
of O
the O
model O
( O
in O
green O
) O
in O
Fig O
. O
2 O
. O
Since O
, O
the O
number O
of O
feature O
maps O
increase O
in O
the O
deeper O
layers O
, O
the O
number O
of O
network O
parameters O
increases O
respectively O
. O
Eventually O
, O
the O
Softmax Method
operations Method
are O
applied O
at O
the O
end O
of O
the O
network O
to O
compute O
the O
probability O
of O
the O
target O
classes O
. O
As O
opposed O
to O
classification Task
tasks O
, O
the O
architecture O
of O
segmentation Task
tasks Task
requires O
both O
convolutional Method
encoding Method
and Method
decoding Method
units Method
. O
The O
encoding Method
unit Method
is O
used O
to O
encode O
input O
images O
into O
a O
larger O
number O
of O
maps O
with O
lower O
dimensionality O
. O
The O
decoding Method
unit Method
is O
used O
to O
perform O
up Method
- Method
convolution Method
( Method
deconvolution Method
) Method
operations Method
to O
produce O
segmentation Task
maps O
with O
the O
same O
dimensionality O
as O
the O
original O
input O
image O
. O
Therefore O
, O
the O
architecture O
for O
segmentation Task
tasks Task
generally O
requires O
almost O
double O
the O
number O
of O
network O
parameters O
when O
compared O
to O
the O
architecture O
of O
the O
classification Task
tasks O
. O
Thus O
, O
it O
is O
important O
to O
design O
efficient O
DCNN Method
architectures O
for O
segmentation Task
tasks Task
which O
can O
ensure O
better O
performance O
with O
less O
number O
of O
network O
parameters O
. O
This O
research O
demonstrates O
two O
modified O
and O
improved O
segmentation Task
models O
, O
one O
using O
recurrent Method
convolution Method
networks Method
, O
and O
another O
using O
recurrent Method
residual Method
convolutional Method
networks Method
. O
To O
accomplish O
our O
goals O
, O
the O
proposed O
models O
are O
evaluated O
on O
different O
modalities O
of O
medical Method
imagining Method
as O
shown O
in O
Fig O
. O
1 O
The O
paper O
is O
organized O
as O
follows O
: O
Section O
II O
discusses O
related O
work O
. O
The O
architectures O
of O
the O
proposed O
RU Method
- Method
Net Method
and O
R2U Method
- Method
Net Method
models O
are O
presented O
in O
Section O
III O
. O
Section O
IV O
, O
explains O
the O
datasets O
, O
experiments O
, O
and O
results O
. O
The O
conclusion O
and O
future O
direction O
are O
discussed O
in O
Section O
V. O
section O
: O
II O
. O
RELATED O
WORK O
Semantic O
segmentation Task
is O
an O
active O
research O
area O
where O
DCNNs Method
are O
used O
to O
classify O
each O
pixel O
in O
the O
image O
individually O
, O
which O
is O
fueled O
by O
different O
challenging O
datasets O
in O
the O
fields O
of O
computer Task
vision Task
and O
medical Method
imaging Method
[ O
reference O
] O
. O
Before O
the O
deep Method
learning Method
revolution Method
, O
the O
traditional O
machine Method
learning Method
approach Method
mostly O
relied O
on O
hand O
engineered O
features O
that O
were O
used O
for O
classifying O
pixels O
independently O
. O
In O
the O
last O
few O
years O
, O
a O
lot O
of O
models O
have O
been O
proposed O
that O
have O
proved O
that O
deeper Method
networks Method
are O
better O
for O
recognition O
and O
segmentation Task
tasks O
[ O
reference O
] O
. O
However O
, O
training Metric
very O
deep Method
models Method
is O
difficult O
due O
to O
the O
vanishing Task
gradient Task
problem Task
, O
which O
is O
resolved O
by O
implementing O
modern O
activation Method
functions Method
such O
as O
Rectified Method
Linear Method
Units Method
( O
ReLU Method
) O
or O
Exponential Method
Linear Method
Units Method
( O
ELU Method
) O
[ O
reference O
][ O
reference O
] O
. O
Another O
solution O
to O
this O
problem O
is O
proposed O
by O
He O
et O
al O
. O
, O
a O
deep Method
residual Method
model Method
that O
overcomes O
the O
problem O
utilizing O
an O
identity Method
mapping Method
to O
facilitate O
the O
training Metric
process O
[ O
reference O
] O
. O
In O
addition O
, O
CNNs O
based O
segmentation Task
methods O
based O
on O
FCN Method
provide O
superior O
performance O
for O
natural O
image O
segmentation Task
[ O
reference O
] O
. O
One O
of O
the O
image Method
patch Method
- Method
based Method
architectures Method
is O
called O
Random Method
architecture Method
, O
which O
is O
very O
computationally O
intensive O
and O
contains O
around O
134.5 O
M O
network O
parameters O
. O
The O
main O
drawback O
of O
this O
approach O
is O
that O
a O
large O
number O
of O
pixel O
overlap O
and O
the O
same O
convolutions O
are O
performed O
many O
times O
. O
The O
performance O
of O
FCN Method
has O
improved O
with O
recurrent Method
neural Method
networks Method
( O
RNN Method
) Method
, O
which O
are O
fine O
- O
tuned O
on O
very O
large O
datasets O
[ O
reference O
] O
. O
Semantic O
image O
segmentation Task
with O
DeepLab Method
is O
one O
of O
the O
state O
- O
of O
- O
the O
- O
art O
performing O
methods O
[ O
reference O
] O
. O
SegNet Method
consists O
of O
two O
parts O
, O
one O
is O
the O
encoding Method
network Method
which O
is O
a O
13 Method
- Method
layer Method
VGG16 Method
network Method
[ O
reference O
] O
, O
and O
the O
corresponding O
decoding Method
network Method
uses O
pixel O
- O
wise O
classification Task
layers O
. O
The O
main O
contribution O
of O
this O
paper O
is O
the O
way O
in O
which O
the O
decoder O
upsamples O
its O
lower O
resolution O
input O
feature O
maps O
[ O
reference O
] O
. O
Later O
, O
an O
improved O
version O
of O
SegNet Method
, O
which O
is O
called O
Bayesian Method
SegNet Method
was O
proposed O
in O
2015 O
[ O
reference O
] O
. O
Most O
of O
these O
architectures O
are O
explored O
using O
computer Task
vision Task
applications Task
. O
However O
, O
there O
are O
some O
deep Method
learning Method
models Method
that O
have O
been O
proposed O
specifically O
for O
the O
medical O
image O
segmentation Task
, O
as O
they O
consider O
data Task
insufficiency Task
and O
class Task
imbalance Task
problems Task
. O
One O
of O
the O
very O
first O
and O
most O
popular O
approaches O
for O
semantic O
medical O
image O
segmentation Task
is O
called O
" O
U Method
- Method
Net Method
" O
[ O
reference O
] O
. O
A O
diagram O
of O
the O
basic O
U Method
- Method
Net Method
model O
is O
shown O
in O
Fig O
. O
2 O
. O
According O
to O
the O
structure O
, O
the O
network O
consists O
of O
two O
main O
parts O
: O
the O
convolutional Method
encoding Method
and Method
decoding Method
units Method
. O
The O
basic O
convolution Method
operations Method
are O
performed O
followed O
by O
ReLU Method
activation Method
in O
both O
parts O
of O
the O
network O
. O
For O
down Task
sampling Task
in O
the O
encoding Method
unit Method
, O
2Ã—2 Method
max Method
- Method
pooling Method
operations Method
are O
performed O
. O
In O
the O
decoding Task
phase Task
, O
the O
convolution Method
transpose Method
( O
representing O
up Method
- Method
convolution Method
, O
or O
de Method
- Method
convolution Method
) Method
operations Method
are O
performed O
to O
up O
- O
sample O
the O
feature O
maps O
. O
The O
very O
first O
version O
of O
U Method
- Method
Net Method
was O
used O
to O
crop O
and O
copy O
feature O
maps O
from O
the O
encoding Method
unit Method
to O
the O
decoding Method
unit Method
. O
The O
U Method
- Method
Net Method
model O
provides O
several O
advantages O
for O
segmentation Task
tasks Task
: O
first O
, O
this O
model O
allows O
for O
the O
use O
of O
global O
location O
and O
context O
at O
the O
same O
time O
. O
Second O
, O
it O
works O
with O
very O
few O
training Metric
samples O
and O
provides O
better O
performance O
for O
segmentation Task
tasks Task
[ O
reference O
] O
. O
Third O
, O
an O
end O
- O
to O
- O
end Method
pipeline Method
process O
the O
entire O
image O
in O
the O
forward O
pass O
and O
directly O
produces O
segmentation Task
maps O
. O
This O
ensures O
that O
U Method
- Method
Net Method
preserves O
the O
full O
context O
of O
the O
input O
images O
, O
which O
is O
a O
major O
advantage O
when O
compared O
to O
patch O
- O
based O
segmentation Task
approaches O
[ O
reference O
][ O
reference O
] O
. O
However O
, O
U Method
- Method
Net Method
is O
not O
only O
limited O
to O
the O
applications O
in O
the O
domain O
of O
medical Method
imaging Method
, O
nowadays O
this O
model O
is O
massively O
applied O
for O
computer Task
vision Task
tasks Task
as O
well O
[ O
reference O
][ O
reference O
] O
. O
Meanwhile O
, O
different O
variants O
of O
U Method
- Method
Net Method
models O
have O
been O
proposed O
, O
including O
a O
very O
simple O
variant O
of O
U Method
- Method
Net Method
for O
CNN O
- O
based O
segmentation Task
of O
Medical Material
Imaging Material
data Material
[ O
reference O
] O
. O
In O
this O
model O
, O
two O
modifications O
are O
made O
to O
the O
original O
design O
of O
U Method
- Method
Net Method
: O
first O
, O
a O
combination O
of O
multiple O
segmentation Task
maps O
and O
forward Method
feature Method
maps Method
are O
summed O
( O
element O
- O
wise O
) O
from O
one O
part O
of O
the O
network O
to O
the O
other O
. O
The O
feature O
maps O
are O
taken O
from O
different O
layers O
of O
encoding Method
and Method
decoding Method
units Method
and O
finally O
summation O
( O
element O
- O
wise O
) O
is O
performed O
outside O
of O
the O
encoding Method
and Method
decoding Method
units Method
. O
The O
authors O
report O
promising O
performance O
improvement O
during O
training Metric
with O
better O
convergence Metric
compared O
to O
U Method
- Method
Net Method
, O
but O
no O
benefit O
was O
observed O
when O
using O
a O
summation O
of O
features O
during O
the O
testing O
phase O
[ O
reference O
] O
. O
However O
, O
this O
concept O
proved O
that O
feature Method
summation Method
impacts O
the O
performance O
of O
a O
network O
. O
The O
importance O
of O
skipped O
connections O
for O
biomedical O
image O
segmentation Task
tasks O
have O
been O
empirically O
evaluated O
with O
U Method
- Method
Net Method
and O
residual O
networks O
[ O
reference O
] O
. O
A O
deep Method
contour Method
- Method
aware Method
network Method
called O
Deep Method
ContourAware Method
Networks Method
( O
DCAN Method
) O
was O
proposed O
in O
2016 O
, O
which O
can O
extract O
multi O
- O
level O
contextual O
features O
using O
a O
hierarchical Method
architecture Method
for O
accurate O
gland O
segmentation Task
of O
histology O
images O
and O
shows O
very O
good O
performance O
for O
segmentation Task
[ O
reference O
] O
. O
Furthermore O
, O
Nabla Method
- Method
Net Method
: O
a O
deep Method
dig Method
- Method
like Method
convolutional Method
architecture Method
was O
proposed O
for O
segmentation Task
in O
2017 O
[ O
reference O
] O
. O
Other O
deep Method
learning Method
approaches Method
have O
been O
proposed O
based O
on O
U Method
- Method
Net Method
for O
3D O
medical O
image O
segmentation Task
tasks O
as O
well O
. O
The O
3D Method
- Method
Unet Method
architecture Method
for O
volumetric O
segmentation Task
learns O
from O
sparsely O
annotated O
volumetric O
images O
[ O
reference O
] O
. O
A O
powerful O
end O
- O
toend O
3D O
medical O
image O
segmentation Task
system O
based O
on O
volumetric O
images O
called O
V Method
- Method
net Method
has O
been O
proposed O
, O
which O
consists O
of O
a O
FCN Method
with Method
residual Method
connections Method
[ O
reference O
] O
. O
This O
paper O
also O
introduces O
a O
dice O
loss O
layer O
[ O
reference O
] O
. O
Furthermore O
, O
a O
3D Method
deeply Method
supervised Method
approach Method
for O
automated O
segmentation Task
of O
volumetric O
medical O
images O
was O
presented O
in O
[ O
reference O
] O
. O
High Method
- Method
Res3DNet Method
was O
proposed O
using O
residual Method
networks Method
for O
3D O
segmentation Task
tasks O
in O
2016 O
[ O
reference O
] O
. O
In O
2017 O
, O
a O
CNN O
based O
brain O
tumor O
segmentation Task
approach O
was O
proposed O
using O
a O
3D Method
- Method
CNN Method
model Method
with O
a O
fully Method
connected Method
CRF Method
[ O
reference O
] O
. O
Pancreas O
segmentation Task
was O
proposed O
in O
[ O
reference O
] O
, O
and O
Voxresnet Method
was O
proposed O
in O
2016 O
where O
a O
deep Method
voxel Method
wise Method
residual Method
network Method
is O
used O
for O
brain O
segmentation Task
. O
This O
architecture O
utilizes O
residual Method
networks Method
and O
summation Method
of Method
feature Method
maps Method
from O
different O
layers O
[ O
reference O
] O
. O
Alternatively O
, O
we O
have O
proposed O
two O
models O
for O
semantic O
segmentation Task
based O
on O
the O
architecture O
of O
U Method
- Method
Net Method
in O
this O
paper O
. O
The O
proposed O
Recurrent Method
Convolutional Method
Neural Method
Networks Method
( O
RCNN Method
) O
model O
based O
on O
U Method
- Method
Net Method
is O
named O
RU Method
- Method
Net Method
, O
which O
is O
shown O
in O
Fig O
. O
3 O
. O
Additionally O
, O
we O
have O
proposed O
a O
residual O
RCNN Method
based O
U Method
- Method
Net Method
model O
which O
is O
called O
R2U Method
- Method
Net Method
. O
The O
following O
section O
provides O
the O
architectural O
details O
of O
both O
models O
. O
section O
: O
III O
. O
RU Method
- Method
NET Method
AND O
R2U Method
- Method
NET Method
ARCHITECTURES O
Inspired O
by O
the O
deep Method
residual Method
model Method
[ O
reference O
] O
, O
RCNN Method
[ O
reference O
] O
, O
and O
UNet Method
[ O
reference O
] O
, O
we O
propose O
two O
models O
for O
segmentation Task
tasks Task
which O
are O
named O
RU Method
- Method
Net Method
and O
R2U Method
- Method
Net Method
. O
These O
two O
approaches O
utilize O
the O
strengths O
of O
all O
three O
recently O
developed O
deep Method
learning Method
models Method
. O
RCNN Method
and O
its O
variants O
have O
already O
shown O
superior O
performance O
on O
object Task
recognition Task
tasks Task
using O
different O
benchmarks O
[ O
reference O
][ O
reference O
] O
. O
The O
recurrent Method
residual Method
convolutional Method
operations Method
can O
be O
demonstrated O
mathematically O
according O
to O
the O
improved Method
- Method
residual Method
networks Method
in O
[ O
reference O
] O
. O
The O
operations O
of O
the O
Recurrent Method
Convolutional Method
Layers Method
( O
RCL Method
) O
are O
performed O
with O
respect O
to O
the O
discrete O
time O
steps O
that O
are O
expressed O
according O
to O
the O
RCNN Method
[ O
reference O
] O
. O
Let O
's O
consider O
the O
input O
sample O
in O
the O
â„Ž O
layer O
of O
the O
residual Method
RCNN Method
( O
RRCNN Method
) O
block O
and O
a O
pixel O
located O
at O
( O
, O
) O
in O
an O
input O
sample O
on O
the O
k O
th O
feature O
map O
in O
the O
RCL Method
. O
Additionally O
, O
let O
's O
assume O
the O
output O
of O
the O
network O
( O
) O
is O
at O
the O
time O
step O
t. O
The O
output O
can O
be O
expressed O
as O
follows O
as O
: O
Here O
( O
, O
) O
( O
) O
and O
( O
, O
) O
( O
âˆ’ O
1 O
) O
are O
the O
inputs O
to O
the O
standard O
convolution Method
layers Method
and O
for O
the O
â„Ž Method
RCL Method
respectively O
. O
The O
and O
values O
are O
the O
weights O
of O
the O
standard O
convolutional Method
layer Method
and O
the O
RCL Method
of O
the O
k O
th O
feature O
map O
respectively O
, O
and O
is O
the O
bias O
. O
The O
outputs O
of O
RCL Method
are O
fed O
to O
the O
standard O
ReLU Method
activation Method
function Method
and O
are O
expressed O
: O
â„± O
( O
, O
) O
represents O
the O
outputs O
from O
of O
l O
th O
layer O
of O
the O
RCNN Method
unit O
. O
The O
output O
of O
â„± O
( O
, O
) O
is O
used O
for O
down Method
- Method
sampling Method
and Method
up Method
- Method
sampling Method
layers Method
in O
the O
convolutional Method
encoding Method
and Method
decoding Method
units Method
of O
the O
RU Method
- Method
Net Method
model O
respectively O
. O
In O
the O
case O
of O
R2U Method
- Method
Net Method
, O
the O
final O
outputs O
of O
the O
RCNN Method
unit O
are O
passed O
through O
the O
residual Method
unit Method
that O
is O
shown O
Fig O
. O
4 O
( O
d O
) O
. O
Let O
's O
consider O
that O
the O
output O
of O
the O
RRCNN Method
- O
block O
is O
+ O
1 O
and O
can O
be O
calculated O
as O
follows O
: O
Here O
, O
represents O
the O
input O
samples O
of O
the O
RRCNN Method
- O
block O
. O
The O
+ O
1 O
sample O
is O
used O
the O
input O
for O
the O
immediate O
succeeding O
sub Method
- Method
sampling Method
or Method
up Method
- Method
sampling Method
layers Method
in O
the O
encoding Method
and Method
decoding Method
convolutional Method
units Method
of O
R2U Method
- Method
Net Method
. O
However O
, O
the O
number O
of O
feature O
maps O
and O
the O
dimensions O
of O
the O
feature O
maps O
for O
the O
residual O
units O
are O
the O
same O
as O
in O
the O
RRCNN Method
- O
block O
shown O
in O
Fig O
. O
4 O
( O
d O
) O
. O
The O
proposed O
deep Method
learning Method
models Method
are O
the O
building O
blocks O
of O
the O
stacked Method
convolutional Method
units Method
shown O
in O
Fig O
. O
4 O
( O
b O
) O
and O
( O
d O
) O
. O
There O
are O
four O
different O
architectures O
evaluated O
in O
this O
work O
. O
First O
, O
U Method
- Method
Net Method
with O
forward Method
convolution Method
layers Method
and O
feature Method
concatenation Method
is O
applied O
as O
an O
alternative O
to O
the O
crop Method
and Method
copy Method
method Method
found O
in O
the O
primary O
version O
of O
U Method
- Method
Net Method
[ O
reference O
] O
. O
The O
basic O
convolutional Method
unit Method
of O
this O
model O
is O
shown O
in O
Fig O
. O
4 O
( O
a O
) O
. O
Second O
, O
U Method
- Method
Net Method
with O
forward Method
convolutional Method
layers Method
with O
residual O
connectivity O
is O
used O
, O
which O
is O
often O
called O
residual Method
U Method
- Method
net Method
( O
ResU Method
- Method
Net Method
) O
and O
is O
shown O
in O
Fig O
. O
4 O
( O
c O
) O
[ O
reference O
] O
. O
The O
third O
architecture O
is O
U Method
- Method
Net Method
with O
forward Method
recurrent Method
convolutional Method
layers Method
as O
shown O
in O
Fig O
. O
4 O
( O
b O
) O
, O
which O
is O
named O
RU Method
- Method
Net Method
. O
Finally O
, O
the O
last O
architecture O
is O
U Method
- Method
Net Method
with O
recurrent Method
convolution Method
layers Method
with O
residual O
connectivity O
as O
shown O
in O
Fig O
. O
4 O
( O
d O
) O
, O
which O
is O
named O
R2U Method
- Method
Net Method
. O
The O
pictorial Method
representation Method
of O
the O
unfolded Method
RCL Method
layers Method
with O
respect O
to O
time O
- O
step O
is O
shown O
in O
Fig O
5 O
. O
Here O
t=2 O
( O
0 O
~ O
2 O
) O
, O
refers O
to O
the O
recurrent Method
convolutional Method
operation Method
that O
includes O
one O
single O
convolution Method
layer Method
followed O
by O
two O
subsequential O
recurrent Method
convolutional Method
layers Method
. O
In O
this O
implementation O
, O
we O
have O
applied O
concatenation Method
to O
the O
feature O
maps O
from O
the O
encoding Method
unit Method
to O
the O
decoding Method
unit Method
for O
both O
RUNet Method
and O
R2U Method
- Method
Net Method
models Method
. O
The O
differences O
between O
the O
proposed O
models O
with O
respect O
to O
the O
U Method
- Method
Net Method
model O
are O
three O
- O
fold O
. O
This O
architecture O
consists O
of O
convolutional Method
encoding Method
and Method
decoding Method
units Method
same O
as O
U Method
- Method
Net Method
. O
However O
, O
the O
RCLs Method
and O
RCLs Method
with O
residual O
units O
are O
used O
instead O
of O
regular Method
forward Method
convolutional Method
layers Method
in O
both O
the O
encoding Method
and Method
decoding Method
units Method
. O
The O
residual Method
unit Method
with O
RCLs Method
helps O
to O
develop O
a O
more O
efficient O
deeper Method
model Method
. O
Second O
, O
the O
efficient O
feature Method
accumulation Method
method Method
is O
included O
in O
the O
RCL Method
units Method
of O
both O
proposed O
models O
. O
The O
effectiveness O
of O
feature Task
accumulation Task
from O
one O
part O
of O
the O
network O
to O
the O
other O
is O
shown O
in O
the O
CNN O
- O
based O
segmentation Task
approach O
for O
medical Method
imaging Method
. O
In O
this O
model O
, O
the O
element Method
- Method
wise Method
feature Method
summation Method
is O
performed O
outside O
of O
the O
U Method
- Method
Net Method
model O
[ O
reference O
] O
. O
This O
model O
only O
shows O
the O
benefit O
during O
the O
training Metric
process O
in O
the O
form O
of O
better O
convergence Metric
. O
However O
, O
our O
proposed O
models O
show O
benefits O
for O
both O
training Metric
and O
testing O
phases O
due O
to O
the O
feature O
accumulation O
inside O
the O
model O
. O
The O
feature Method
accumulation Method
with O
respect O
to O
different O
time O
- O
steps O
ensures O
better O
and O
stronger O
feature Method
representation Method
. O
Thus O
, O
it O
helps O
extract O
very O
low O
- O
level O
features O
which O
are O
essential O
for O
segmentation Task
tasks Task
for O
different O
modalities O
of O
medical Method
imaging Method
( O
such O
as O
blood O
vessel O
segmentation Task
) O
. O
Third O
, O
we O
have O
removed O
the O
cropping Method
and Method
copying Method
unit Method
from O
the O
basic O
U Method
- Method
Net Method
model O
and O
use O
only O
concatenation Method
operations Method
, O
resulting O
a O
much O
- O
sophisticated O
architecture O
that O
results O
in O
better O
performance O
. O
There O
are O
several O
advantages O
of O
using O
the O
proposed O
architectures O
when O
compared O
with O
U Method
- Method
Net Method
. O
The O
first O
is O
the O
efficiency O
in O
terms O
of O
the O
number O
of O
network O
parameters O
. O
The O
proposed O
RU Method
- Method
Net Method
, O
and O
R2U Method
- Method
Net Method
architectures O
are O
designed O
to O
have O
the O
same O
number O
of O
network O
parameters O
when O
compared O
to O
U Method
- Method
Net Method
and O
ResU Method
- Method
Net Method
, O
and O
RU Method
- Method
Net Method
and O
R2U Method
- Method
Net Method
show O
better O
performance O
on O
segmentation Task
tasks Task
. O
The O
recurrent Method
and Method
residual Method
operations Method
do O
not O
increase O
the O
number O
of O
network O
parameters O
. O
However O
, O
they O
do O
have O
a O
significant O
impact O
on O
training Metric
and O
testing Task
performance O
. O
This O
is O
shown O
through O
empirical O
evidence O
with O
a O
set O
of O
experiments O
in O
the O
following O
sections O
[ O
reference O
] O
. O
This O
approach O
is O
also O
generalizable O
, O
as O
it O
easily O
be O
applied O
deep Method
learning Method
models Method
based O
on O
SegNet Method
[ O
reference O
] O
, O
3D Method
- Method
UNet Method
[ O
reference O
] O
, O
and O
VNet Method
[ O
reference O
] O
with O
improved O
performance O
for O
segmentation Task
tasks Task
. O
section O
: O
IV O
. O
EXPERIMENTAL O
SETUP O
AND O
RESULTS O
To O
demonstrate O
the O
performance O
of O
the O
RU Method
- Method
Net Method
and O
R2U Method
- Method
Net Method
models Method
, O
we O
have O
tested O
them O
on O
three O
different O
medical Method
imaging Method
datasets O
. O
These O
include O
blood Method
vessel Method
segmentations Method
from O
retina O
images O
( O
DRIVE Material
, O
STARE Material
, O
and O
CHASE_DB1 Material
shown O
in O
Fig O
. O
6 O
) O
, O
skin Task
cancer Task
lesion Task
segmentation Task
, O
and O
lung Task
segmentation Task
from O
2D O
images O
. O
For O
this O
implementation O
, O
the O
Keras Method
, Method
and Method
TensorFlow Method
frameworks Method
are O
used O
on O
a O
single O
GPU Method
machine Method
with O
56 O
G O
of O
RAM O
and O
an O
NIVIDIA O
GEFORCE O
GTX O
- O
980 O
Ti O
. O
section O
: O
A. O
Database O
Summary O
1 O
) O
Blood Task
Vessel Task
Segmentation Task
We O
have O
experimented O
on O
three O
different O
popular O
datasets O
for O
retina Task
blood Task
vessel Task
segmentation Task
including O
DRIVE Material
, O
STARE Material
, O
and O
CHASH_DB1 Material
. O
The O
DRIVE Material
dataset O
is O
consisted O
of O
40 O
color O
retinal O
images O
in O
total O
, O
in O
which O
20 O
samples O
are O
used O
for O
training Metric
and O
remaining O
20 O
samples O
are O
used O
for O
testing O
. O
The O
size O
of O
each O
original O
image O
is O
565Ã—584 O
pixels O
[ O
reference O
] O
. O
To O
develop O
a O
square Material
dataset Material
, O
the O
images O
are O
cropped O
to O
only O
contain O
the O
data O
from O
columns O
9 O
through O
574 O
, O
which O
then O
makes O
each O
image O
565Ã—565 O
pixels O
. O
In O
this O
implementation O
, O
we O
considered O
190 O
, O
000 O
randomly O
selected O
patches O
from O
20 O
of O
the O
images O
in O
the O
DRIVE Material
dataset O
, O
where O
171 O
, O
000 O
patches O
are O
used O
for O
training Metric
, O
and O
the O
remaining O
19 O
, O
000 O
patches O
used O
for O
validation Task
. O
The O
size O
of O
each O
patch O
is O
48Ã—48 O
for O
all O
three O
datasets O
shown O
in O
Fig O
. O
7 O
. O
The O
second O
dataset O
, O
STARE Material
, O
contains O
20 O
color Material
images Material
, O
and O
each O
image O
has O
a O
size O
of O
700Ã—605 O
pixels O
[ O
reference O
][ O
reference O
] O
. O
Due O
to O
the O
smaller O
number O
of O
samples O
, O
two O
approaches O
are O
applied O
very O
often O
for O
training Metric
and O
testing Task
on O
this O
dataset O
. O
First O
, O
training Metric
sometimes O
performed O
with O
randomly O
selected O
samples O
from O
all O
20 O
images O
[ O
reference O
] O
. O
Another O
approach O
is O
the O
" O
leave Method
- Method
one Method
- Method
out Method
" Method
method Method
, O
in O
which O
each O
image O
is O
tested O
, O
and O
training Metric
is O
conducted O
on O
the O
remaining O
19 O
samples O
[ O
reference O
] O
. O
Therefore O
, O
there O
is O
no O
overlap O
between O
training Metric
and O
testing O
samples O
. O
In O
this O
implementation O
, O
we O
used O
the O
" O
leaveone Method
- Method
out Method
" Method
approach Method
for O
STARE Material
dataset O
. O
The O
CHASH_DB1 Material
dataset Material
contains O
28 O
color O
retina O
images O
and O
the O
size O
of O
each O
image O
is O
999Ã—960 O
pixels O
[ O
reference O
] O
. O
The O
images O
in O
this O
dataset O
were O
collected O
from O
both O
left O
and O
right O
eyes O
of O
14 O
school O
children O
. O
The O
dataset O
is O
divided O
into O
two O
sets O
where O
samples O
are O
selected O
randomly O
. O
A O
20 O
- O
sample O
set O
is O
used O
for O
training Metric
and O
the O
remaining O
8 O
samples O
are O
used O
for O
testing O
. O
As O
the O
dimensionality O
of O
the O
input O
data O
larger O
than O
the O
entire O
DRIVE Material
dataset O
, O
we O
have O
considered O
250 O
, O
000 O
patches O
in O
total O
from O
20 O
images O
for O
both O
STARE Material
and O
CHASE_DB1 Material
. O
In O
this O
case O
225 O
, O
000 O
patches O
are O
used O
for O
training Metric
and O
the O
remaining O
25 O
, O
000 O
patches O
are O
used O
for O
validation Task
. O
Since O
the O
binary O
FOV O
( O
which O
is O
shown O
in O
second O
row O
in O
Fig O
. O
6 O
) O
is O
not O
available O
for O
the O
STARE Material
and O
CHASE_DB1 Material
datasets O
, O
we O
generated O
FOV O
masks O
using O
a O
similar O
technique O
to O
the O
one O
described O
in O
[ O
reference O
] O
. O
One O
advantage O
of O
the O
patch Method
- Method
based Method
approach Method
is O
that O
the O
patches O
give O
the O
network O
access O
to O
local O
information O
about O
the O
pixels O
, O
which O
has O
impact O
on O
overall O
prediction Task
. O
Furthermore O
, O
it O
ensures O
that O
the O
classes O
of O
the O
input O
data O
are O
balanced O
. O
The O
input O
patches O
are O
randomly O
sampled O
over O
an O
entire O
image O
, O
which O
also O
includes O
the O
outside O
region O
of O
the O
FOV O
. O
section O
: O
2 O
) O
Skin Task
Cancer Task
Segmentation Task
This O
dataset O
is O
taken O
from O
the O
Kaggle Task
competition Task
on O
skin O
lesion O
segmentation Task
that O
occurred O
in O
2017 O
[ O
reference O
] O
. O
This O
dataset O
contains O
2000 O
samples O
in O
total O
. O
It O
consists O
of O
1250 O
training Metric
samples O
, O
150 O
validation O
samples O
, O
and O
600 O
testing O
samples O
. O
The O
original O
size O
of O
each O
sample O
was O
700Ã—900 O
, O
which O
was O
rescaled O
to O
256Ã—256 O
for O
this O
implementation O
. O
The O
training Metric
samples O
include O
the O
original O
images O
, O
as O
well O
as O
corresponding O
target O
binary O
images O
containing O
cancer O
or O
non O
- O
cancer O
lesions O
. O
The O
target O
pixels O
are O
represented O
with O
a O
value O
of O
either O
255 O
or O
0 O
for O
the O
pixels O
outside O
of O
the O
target O
lesion O
. O
section O
: O
3 O
) O
Lung Task
Segmentation Task
The O
Lung Task
Nodule Task
Analysis Task
( O
LUNA Task
) O
competition O
at O
the O
Kaggle Task
Data Task
Science Task
Bowl Task
in O
2017 O
was O
held O
to O
find O
lung O
lesions O
in O
2D O
and O
3D O
CT Method
images O
. O
The O
provided O
dataset O
consisted O
of O
534 O
2D O
samples O
with O
respective O
label O
images O
for O
lung Task
segmentation Task
[ O
reference O
] O
. O
For O
this O
study O
, O
70 O
% O
of O
the O
images O
are O
used O
for O
training Metric
and O
the O
remaining O
30 O
% O
are O
used O
for O
testing O
. O
The O
original O
image O
size O
was O
512Ã—512 O
, O
however O
, O
we O
resized O
the O
images O
to O
256Ã—256 O
pixels O
in O
this O
implementation O
. O
section O
: O
B. O
Quantitative Method
Analysis Method
Approaches Method
For O
quantitative Task
analysis Task
of O
the O
experimental O
results O
, O
several O
performance Metric
metrics Metric
are O
considered O
, O
including O
accuracy Metric
( O
AC Metric
) O
, O
sensitivity Metric
( O
SE Metric
) O
, O
specificity Metric
( O
SP Metric
) O
, O
F1 Metric
- Metric
score Metric
, O
Dice Metric
coefficient Metric
( O
DC Method
) O
, O
and O
Jaccard Metric
similarity Metric
( O
JS Method
) O
. O
To O
do O
this O
we O
also O
use O
the O
variables O
True O
Positive O
( O
TP Metric
) O
, O
True O
Negative O
( O
TN Metric
) O
, O
False Metric
Positive Metric
( O
FP Metric
) O
, O
and O
False Metric
Negative Metric
( Metric
FN Metric
) O
. O
The O
overall O
accuracy Metric
is O
calculated O
using O
Eq O
. O
( O
4 O
) O
, O
and O
sensitivity Metric
is O
calculated O
using O
Eq O
. O
Furthermore O
, O
specificity Metric
is O
calculated O
using O
the O
following O
Eq O
. O
( O
6 O
) O
. O
The O
DC O
is O
expressed O
as O
in O
Eq O
. O
( O
7 O
) O
according O
to O
[ O
reference O
] O
. O
Here O
GT O
refers O
to O
the O
ground O
truth O
and O
SR Method
refers O
the O
segmentation Task
result O
. O
The O
JS Method
is O
represented O
using O
Eq O
. O
( O
8 O
) O
as O
in O
[ O
reference O
] O
. O
However O
, O
the O
area Metric
under Metric
curve Metric
( O
AUC Metric
) O
and O
the O
receiver Metric
operating Metric
characteristics Metric
( O
ROC Metric
) Metric
curve Metric
are O
common O
evaluation Metric
measures Metric
for O
medical O
image O
segmentation Task
tasks O
. O
In O
this O
experiment O
, O
we O
utilized O
both O
analytical O
methods O
to O
evaluate O
the O
performance O
of O
the O
proposed O
approaches O
considering O
the O
mentioned O
criterions O
against O
existing O
state O
- O
of O
- O
the O
- O
art O
techniques O
. O
Fig O
. O
9 O
. O
Training Metric
accuracy Metric
of O
the O
proposed O
models O
of O
RU Method
- Method
Net Method
, O
and O
R2U Method
- Method
Net Method
against O
ResU Method
- Method
Net Method
and O
U Method
- Method
Net Method
. O
section O
: O
C. O
Results O
1 O
) O
Retina Task
Blood Task
Vessel Task
Segmentation Task
Using O
the O
DRIVE Material
Dataset O
The O
precise O
segmentation Task
results O
achieved O
with O
the O
proposed O
R2U Method
- Method
Net Method
model O
are O
shown O
in O
Fig O
. O
8 O
. O
Figs O
. O
9 O
and O
10 O
show O
the O
training Metric
and O
validation Metric
accuracy Metric
when O
using O
the O
DRIVE Material
dataset O
. O
These O
figures O
show O
that O
the O
proposed O
R2U Method
- Method
Net Method
and O
RU Method
- Method
Net Method
models Method
provide O
better O
performance O
during O
both O
the O
training Metric
and O
validation O
phase O
when O
compared O
to O
U Method
- Method
Net Method
and O
ResU Method
- Method
Net Method
. O
section O
: O
2 O
) O
Retina O
blood O
vessel O
segmentation Task
on O
the O
STARE Material
dataset O
The O
experimental O
outputs O
of O
R2U Method
- Method
Net Method
when O
using O
the O
STARE Material
dataset O
are O
shown O
in O
Fig O
. O
11 O
. O
The O
training Metric
and O
validation Metric
accuracy Metric
for O
the O
STARE Material
dataset O
is O
shown O
in O
Figs O
. O
12 O
and O
13 O
respectively O
. O
R2U Method
- Method
Net Method
shows O
a O
better O
performance O
than O
all O
other O
models O
during O
training Metric
. O
In O
addition O
, O
the O
validation Metric
accuracy Metric
in O
Fig O
. O
13 O
demonstrates O
that O
the O
RU Method
- Method
Net Method
and O
R2U Method
- Method
Net Method
models Method
provide O
better O
validation Metric
accuracy Metric
when O
compared O
to O
the O
equivalent O
UNet Method
and O
ResU Method
- Method
Net Method
models Method
. O
Thus O
, O
the O
performance O
demonstrates O
the O
effectiveness O
of O
the O
proposed O
approaches O
for O
segmentation Task
tasks Task
. O
Fig O
. O
11 O
. O
Experimental O
outputs O
of O
STARE Material
dataset O
using O
R2UNet Method
: O
first O
row O
shows O
input O
image O
after O
performing O
normalization Method
, O
second O
row O
show O
ground O
truth O
, O
and O
third O
row O
shows O
the O
experimental O
outputs O
. O
section O
: O
3 O
) O
CHASE_DB1 Material
For O
qualitative Task
analysis Task
, O
the O
example O
outputs O
of O
R2U Method
- Method
Net Method
are O
shown O
in O
Fig O
. O
14 O
. O
For O
quantitative Task
analysis Task
, O
the O
results O
are O
given O
in O
Table O
I. O
From O
the O
table O
, O
it O
can O
be O
concluded O
that O
in O
all O
cases O
, O
the O
proposed O
RU Method
- Method
Net Method
and O
R2U Method
- Method
Net Method
models O
show O
better O
performance O
in O
terms O
of O
AUC Metric
and O
accuracy Metric
. O
The O
ROC Metric
for O
the O
highest O
AUCs Metric
for O
the O
R2U Method
- Method
Net Method
model O
on O
each O
of O
the O
three O
retina O
blood O
vessel O
segmentation Task
datasets O
is O
shown O
in O
Fig O
. O
15 O
. O
Fig O
. O
14 O
. O
Qualitative Method
analysis Method
for O
CHASE_DB1 Material
dataset O
. O
The O
segmentation Task
outputs O
of O
8 O
testing O
samples O
using O
R2U Method
- Method
Net Method
. O
First O
row O
shows O
the O
input O
images O
, O
second O
row O
is O
ground O
truth O
, O
and O
third O
row O
shows O
the O
segmentation Task
outputs O
using O
R2U Method
- Method
Net Method
. O
section O
: O
4 O
) O
Skin Task
Cancer Task
Lesion Task
Segmentation Task
In O
this O
implementation O
, O
this O
dataset O
is O
preprocessed O
with O
mean Method
subtraction Method
and O
normalized O
according O
to O
the O
standard Metric
deviation Metric
. O
We O
used O
the O
ADAM Method
optimization Method
technique Method
with O
a O
learning Metric
rate Metric
of Metric
2Ã—10 Metric
- Metric
4 Metric
and O
binary Metric
cross Metric
entropy Metric
loss Metric
. O
In O
addition O
, O
we O
also O
calculated O
MSE Metric
error Metric
during O
the O
training Metric
and O
validation O
phase O
. O
In O
this O
case O
10 O
% O
of O
the O
samples O
are O
used O
for O
validation Task
during O
training Metric
with O
a O
batch O
size O
of O
32 O
and O
150 O
epochs O
. O
The O
training Metric
accuracy Metric
of O
the O
proposed O
models O
R2U Method
- Method
Net Method
and O
RU Method
- Method
Net Method
was O
compared O
with O
that O
of O
ResU Method
- Method
Net Method
and O
U Method
- Method
Net Method
for O
an O
end O
- O
to O
- O
end O
image O
based O
segmentation Task
approach O
. O
The O
result O
is O
shown O
in O
Fig O
. O
16 O
. O
The O
validation Metric
accuracy Metric
is O
shown O
in O
Fig O
. O
17 O
. O
In O
both O
cases O
, O
the O
proposed O
models O
show O
better O
performance O
when O
compared O
with O
the O
equivalent O
U Method
- Method
Net Method
and O
ResU Method
- Method
Net Method
models O
. O
This O
clearly O
demonstrates O
the O
robustness O
of O
the O
proposed O
models O
in O
end O
- O
to O
- O
end O
image O
- O
based O
segmentation Task
tasks O
. O
The O
quantitative O
results O
of O
this O
experiment O
were O
compared O
against O
existing O
methods O
as O
shown O
in O
Table O
II O
. O
Some O
of O
the O
example O
outputs O
from O
the O
testing O
phase O
are O
shown O
in O
Fig O
. O
18 O
. O
The O
first O
column O
shows O
the O
input O
images O
, O
the O
second O
column O
shows O
the O
ground O
truth O
, O
the O
network O
outputs O
are O
shown O
in O
the O
third O
column O
, O
and O
the O
fourth O
column O
demonstrates O
the O
final O
outputs O
after O
performing O
post Method
processing Method
with O
a O
threshold O
of O
0.5 O
. O
Figure O
18 O
shows O
promising O
segmentation Task
results O
. O
In O
most O
cases O
, O
the O
target O
lesions O
are O
segmented O
accurately O
with O
almost O
the O
same O
shape O
of O
ground O
truth O
. O
However O
, O
if O
we O
observe O
the O
second O
and O
third O
rows O
in O
Fig O
. O
18 O
, O
it O
can O
be O
clearly O
seen O
that O
the O
input O
images O
contain O
two O
spots O
, O
one O
is O
a O
target O
lesion O
and O
the O
other O
bright O
spot O
which O
is O
not O
a O
target O
. O
This O
result O
is O
obtained O
even O
though O
the O
non O
- O
target O
lesion O
is O
brighter O
than O
the O
target O
lesion O
shown O
in O
the O
third O
row O
in O
Fig O
. O
18 O
. O
The O
R2U Method
- Method
Net Method
model O
still O
segments O
the O
desired O
part O
accurately O
, O
which O
clearly O
shows O
the O
robustness O
of O
the O
proposed O
segmentation Task
method O
. O
We O
have O
compared O
the O
performance O
of O
the O
proposed O
approaches O
against O
recently O
published O
results O
with O
respect O
to O
sensitivity Metric
, O
specificity Metric
, O
accuracy Metric
, O
AUC Metric
, O
and O
DC Metric
. O
The O
proposed O
R2U Method
- Method
Net Method
model O
provides O
a O
testing Metric
accuracy Metric
0.9424 O
with O
a O
higher O
AUC Metric
, O
which O
is O
0.9419 O
. O
The O
average O
AUC Metric
for O
skin O
lesion O
segmentation Task
is O
shown O
in O
Fig O
. O
19 O
. O
In O
addition O
, O
we O
calculated O
the O
average Metric
DC Metric
in O
the O
testing O
phase O
and O
achieved O
0.8616 O
, O
which O
is O
around O
1.26 O
% O
better O
than O
recently O
proposed O
alternatives O
[ O
reference O
] O
. O
Furthermore O
, O
the O
JSC Metric
and O
F1 Metric
scores Metric
are O
calculated O
and O
the O
R2U Method
- Method
Net Method
model O
obtains O
0.9421 O
for O
JSC Metric
and O
0.8920 O
for O
F1 Metric
score Metric
for O
skin O
lesion O
segmentation Task
with O
t=3 O
. O
These O
results O
are O
achieved O
with O
a O
R2U Method
- Method
Net Method
model O
that O
only O
contains O
about O
1.037 O
million O
( O
M O
) O
network O
parameters O
. O
Contrarily O
, O
the O
work O
presented O
in O
[ O
reference O
] O
evaluated O
VGG Method
- Method
16 Method
and O
Incpetion Method
- Method
V3 Method
models Method
for O
skin O
lesion O
segmentation Task
, O
but O
those O
networks O
contained O
around O
138 O
M O
and O
23 O
M O
network O
parameters O
respectively O
. O
Fig O
. O
18 O
. O
This O
results O
demonstrates O
qualitative O
assessment O
of O
the O
proposed O
R2U Method
- Method
Net Method
for O
skin O
cancer O
segmentation Task
task O
with O
t=3 O
. O
First O
column O
is O
the O
input O
sample O
, O
second O
column O
is O
ground O
truth O
, O
third O
column O
shows O
the O
outputs O
from O
network O
, O
and O
fourth O
column O
show O
the O
final O
resulting O
after O
performing O
thresholding Method
with O
0.5 O
. O
section O
: O
5 O
) O
Lung Task
Segmentation Task
Lung O
segmentation Task
is O
very O
important O
for O
analyzing Task
lung Task
related Task
diseases Task
, O
and O
can O
be O
applied O
to O
lung O
cancer O
segmentation Task
and O
lung O
pattern O
classification Task
for O
identifying O
other O
problems O
. O
In O
this O
experiment O
, O
the O
ADAM Method
optimizer Method
is O
used O
with O
a O
learning Metric
rate Metric
of O
2Ã—10 O
- O
4 O
. O
We O
used O
binary Metric
cross Metric
entropy Metric
loss Metric
, O
and O
also O
calculated O
MSE Metric
during O
training Metric
and O
validation Task
. O
In O
this O
case O
10 O
% O
of O
the O
samples O
were O
used O
for O
validation Task
with O
a O
batch O
size O
of O
16 O
and O
150 O
epochs O
150 O
. O
Table O
III O
shows O
the O
summary O
of O
how O
well O
the O
proposed O
models O
performed O
against O
equivalent O
U Method
- Method
Net Method
and O
ResU Method
- Method
Net Method
models Method
. O
The O
experimental O
results O
show O
that O
the O
proposed O
models O
outperform O
the O
U Method
- Method
Net Method
and O
ResU Method
- Method
Net Method
models Method
with O
same O
number O
of O
network O
parameters O
. O
Furthermore O
, O
many O
models O
struggle O
to O
define O
the O
class O
boundary O
properly O
during O
segmentation Task
tasks Task
[ O
reference O
] O
. O
However O
, O
if O
we O
observe O
the O
experimental O
outputs O
shown O
in O
Fig O
. O
20 O
, O
the O
outputs O
in O
the O
third O
column O
show O
different O
hit O
maps O
on O
the O
border O
, O
which O
can O
be O
used O
to O
define O
the O
boundary O
of O
the O
lung O
region O
, O
while O
the O
ground O
truth O
tends O
to O
have O
a O
smooth O
boundary O
. O
In O
addition O
, O
if O
we O
observe O
the O
input O
, O
ground O
truth O
, O
and O
output O
of O
this O
proposed O
approaches O
in O
the O
second O
row O
, O
it O
can O
be O
observed O
that O
the O
output O
of O
the O
proposed O
approaches O
shows O
better O
segmentation Task
with O
appropriate O
contour O
. O
The O
ROC Metric
with O
AUCs Metric
are O
shown O
Fig O
. O
21 O
. O
The O
highest O
AUC Metric
is O
achieved O
with O
the O
proposed O
approach O
of O
R2U Method
- Method
Net Method
with O
t=3 Method
. O
section O
: O
D. O
Evaluation O
Most O
of O
the O
cases O
, O
the O
networks O
are O
evaluated O
for O
different O
segmentation Task
tasks Task
with O
following O
architectures O
: O
1ïƒ 64ïƒ 128ïƒ 256ïƒ 512ïƒ 256 O
ïƒ  O
128ïƒ 64ïƒ 1 O
that O
require O
4.2 O
M O
network O
parameters O
and O
1ïƒ 64ïƒ 128ïƒ 256ïƒ 512ïƒ 256 O
ïƒ  O
128ïƒ 64ïƒ 1 O
, O
which O
require O
about O
8.5 O
M O
network O
parameters O
respectively O
. O
However O
, O
we O
also O
experimented O
with O
U Method
- Method
Net Method
, O
ResU Method
- Method
Net Method
, O
RU Method
- Method
Net Method
, O
and O
R2U Method
- Method
Net Method
models Method
with O
following O
structure O
: O
1ïƒ 16ïƒ 32ïƒ 64ïƒ 128ïƒ 64 O
ïƒ  O
32ïƒ 16ïƒ 1 O
. O
In O
this O
case O
we O
used O
a O
time O
- O
step O
of O
t=3 O
, O
which O
refers O
to O
one O
forward Method
convolution Method
layer Method
followed O
by O
three O
subsequent O
recurrent Method
convolutional Method
layers Method
. O
This O
network O
was O
tested O
on O
skin O
and O
lung O
lesion O
segmentation Task
. O
Though O
the O
number O
of O
network O
parameters O
increase O
little O
bit O
with O
respect O
to O
the O
time O
- O
step O
in O
the O
recurrent Method
convolution Method
layer Method
, O
further O
improved O
performance O
can O
be O
clearly O
seen O
in O
the O
last O
rows O
of O
Table O
II O
and O
III O
. O
Furthermore O
, O
we O
have O
evaluated O
both O
of O
the O
proposed O
models O
for O
patch Method
- Method
based Method
modeling Method
on O
retina Task
blood Task
vessel Task
segmentation Task
and O
end Method
- Method
to Method
- Method
end Method
image Method
- Method
based Method
methods Method
for O
skin O
and O
lung O
lesion O
segmentation Task
. O
In O
both O
cases O
, O
the O
proposed O
models O
outperform O
existing O
stateof O
- O
the O
- O
art O
methods O
including O
ResU Method
- Method
Net Method
and O
U Method
- Method
Net Method
in O
terms O
of O
AUC Metric
and O
accuracy Metric
on O
all O
three O
datasets O
. O
The O
network Method
architectures Method
with O
different O
numbers O
of O
network O
parameters O
with O
respect O
to O
the O
different O
time O
- O
step O
are O
shown O
in O
Table O
IV O
. O
The O
processing Metric
times Metric
during O
the O
testing O
phase O
for O
the O
STARE Material
, O
CHASE_DB Material
, O
and O
DRIVE Material
datasets Material
were O
6.42 O
, O
8.66 O
, O
and O
2.84 O
seconds O
per O
sample O
respectively O
. O
In O
addition O
, O
skin O
cancer O
segmentation Task
and O
lung Task
segmentation Task
take O
0.22 O
and O
1.145 O
seconds O
per O
sample O
respectively O
. O
section O
: O
E. O
Computational Metric
time Metric
The O
computational Metric
time Metric
for O
testing O
per O
sample O
is O
shown O
in O
Table O
V O
for O
blood O
vessel O
segmentation Task
for O
retina O
images O
, O
skin Task
cancer Task
, O
and O
lung Task
segmentation Task
respectively O
. O
In O
this O
paper O
, O
we O
proposed O
an O
extension O
of O
the O
U Method
- Method
Net Method
architecture O
using O
Recurrent Method
Convolutional Method
Neural Method
Networks Method
and O
Recurrent Method
Residual Method
Convolutional Method
Neural Method
Networks Method
. O
The O
proposed O
models O
are O
called O
" O
RU Method
- Method
Net Method
" Method
and O
" O
R2U Method
- Method
Net Method
" O
respectively O
. O
These O
models O
were O
evaluated O
using O
three O
different O
applications O
in O
the O
field O
of O
medical Method
imaging Method
including O
retina Task
blood Task
vessel Task
segmentation Task
, O
skin Task
cancer Task
lesion Task
segmentation Task
, O
and O
lung Task
segmentation Task
. O
The O
experimental O
results O
demonstrate O
that O
the O
proposed O
RU Method
- Method
Net Method
, O
and O
R2U Method
- Method
Net Method
models Method
show O
better O
performance O
in O
segmentation Task
tasks Task
with O
the O
same O
number O
of O
network O
parameters O
when O
compared O
to O
existing O
methods O
including O
the O
U Method
- Method
Net Method
and O
residual O
U Method
- Method
Net Method
( O
or O
ResU Method
- Method
Net Method
) O
models O
on O
all O
three O
datasets O
. O
In O
addition O
, O
results O
show O
that O
these O
proposed O
models O
not O
only O
ensure O
better O
performance O
during O
the O
training Metric
but O
also O
in O
testing O
phase O
. O
In O
future O
, O
we O
would O
like O
to O
explore O
the O
same O
architecture O
with O
a O
novel O
feature Method
fusion Method
strategy Method
from O
encoding O
to O
the O
decoding Method
units Method
. O
Fig O
. O
21 O
. O
ROC Metric
curve Metric
for O
lung Task
segmentation Task
four O
models O
with O
t=2 O
and O
t=3 O
. O
section O
: O
