document	O
:	O
Nonlinear	Method
3D	Method
Face	Method
Morphable	Method
Model	Method
As	O
a	O
classic	O
statistical	Method
model	Method
of	Method
3D	Method
facial	Method
shape	Method
and	Method
texture	Method
,	O
3D	Method
Morphable	Method
Model	Method
(	O
3DMM	Method
)	Method
is	O
widely	O
used	O
in	O
facial	Task
analysis	Task
,	O
e.g.	O
,	O
model	Task
fitting	Task
,	O
image	Task
synthesis	Task
.	O
Conventional	O
3DMM	Method
is	O
learned	O
from	O
a	O
set	O
of	O
well	O
-	O
controlled	O
2D	O
face	O
images	O
with	O
associated	O
3D	O
face	O
scans	O
,	O
and	O
represented	O
by	O
two	O
sets	O
of	O
PCA	Method
basis	Method
functions	Method
.	O
Due	O
to	O
the	O
type	O
and	O
amount	O
of	O
training	O
data	O
,	O
as	O
well	O
as	O
the	O
linear	O
bases	O
,	O
the	O
representation	O
power	O
of	O
3DMM	Method
can	O
be	O
limited	O
.	O
To	O
address	O
these	O
problems	O
,	O
this	O
paper	O
proposes	O
an	O
innovative	O
framework	O
to	O
learn	O
a	O
nonlinear	Method
3DMM	Method
model	O
from	O
a	O
large	O
set	O
of	O
unconstrained	O
face	O
images	O
,	O
without	O
collecting	O
3D	O
face	O
scans	O
.	O
Specifically	O
,	O
given	O
a	O
face	O
image	O
as	O
input	O
,	O
a	O
network	Method
encoder	Method
estimates	O
the	O
projection	O
,	O
shape	O
and	O
texture	O
parameters	O
.	O
Two	O
decoders	Method
serve	O
as	O
the	O
nonlinear	Method
3DMM	Method
to	O
map	O
from	O
the	O
shape	O
and	O
texture	O
parameters	O
to	O
the	O
3D	O
shape	O
and	O
texture	O
,	O
respectively	O
.	O
With	O
the	O
projection	O
parameter	O
,	O
3D	O
shape	O
,	O
and	O
texture	O
,	O
a	O
novel	O
analytically	Method
-	Method
differentiable	Method
rendering	Method
layer	Method
is	O
designed	O
to	O
reconstruct	O
the	O
original	O
input	O
face	O
.	O
The	O
entire	O
network	O
is	O
end	O
-	O
to	O
-	O
end	O
trainable	O
with	O
only	O
weak	O
supervision	O
.	O
We	O
demonstrate	O
the	O
superior	O
representation	Metric
power	Metric
of	O
our	O
nonlinear	Method
3DMM	Method
over	O
its	O
linear	Method
counterpart	Method
,	O
and	O
its	O
contribution	O
to	O
face	Task
alignment	Task
and	O
3D	Task
reconstruction	Task
.	O
⌊⌋	O
⌈⌉	O
section	O
:	O
Introduction	O
3D	Method
Morphable	Method
Model	Method
(	O
3DMM	Method
)	O
is	O
a	O
statistical	Method
model	Method
of	O
3D	O
facial	O
shape	O
and	O
texture	O
in	O
a	O
space	O
where	O
there	O
are	O
explicit	O
correspondences	O
.	O
The	O
morphable	Method
model	Method
framework	Method
provides	O
two	O
key	O
benefits	O
:	O
first	O
,	O
a	O
point	O
-	O
to	O
-	O
point	O
correspondence	O
between	O
the	O
reconstruction	Method
and	O
all	O
other	O
models	O
,	O
enabling	O
âmorphingâ	O
,	O
and	O
second	O
,	O
modeling	O
underlying	O
transformations	O
between	O
types	O
of	O
faces	O
(	O
male	O
to	O
female	O
,	O
neutral	O
to	O
smile	O
,	O
etc	O
.	O
)	O
.	O
3DMM	Method
has	O
been	O
widely	O
applied	O
in	O
numerous	O
areas	O
,	O
such	O
as	O
computer	Task
vision	Task
,	O
graphics	Task
,	O
human	Task
behavioral	Task
analysis	Task
and	O
craniofacial	Task
surgery	Task
.	O
3DMM	Method
is	O
learnt	O
through	O
supervision	Method
by	O
performing	O
dimension	Method
reduction	Method
,	O
normally	O
Principal	Method
Component	Method
Analysis	Method
(	O
PCA	Method
)	O
,	O
on	O
a	O
training	O
set	O
of	O
face	O
images	O
/	O
scans	O
.	O
To	O
model	O
highly	O
variable	O
3D	O
face	O
shapes	O
,	O
a	O
large	O
amount	O
of	O
high	O
-	O
quality	O
3D	O
face	O
scans	O
is	O
required	O
.	O
However	O
,	O
this	O
requirement	O
is	O
expensive	O
to	O
fulfill	O
.	O
The	O
first	O
3DMM	Method
was	O
built	O
from	O
scans	O
of	O
subjects	O
with	O
a	O
similar	O
ethnicity	O
/	O
age	O
group	O
.	O
They	O
were	O
also	O
captured	O
in	O
well	O
-	O
controlled	O
conditions	O
,	O
with	O
only	O
neutral	O
expressions	O
.	O
Hence	O
,	O
it	O
is	O
fragile	O
to	O
large	O
variances	O
in	O
the	O
face	O
identity	O
.	O
The	O
widely	O
used	O
Basel	Method
Face	Method
Model	Method
(	O
BFM	Method
)	Method
is	O
also	O
built	O
with	O
only	O
subjects	O
in	O
neutral	O
expressions	O
.	O
Lack	O
of	O
expression	O
can	O
be	O
compensated	O
using	O
expression	O
bases	O
from	O
FaceWarehouse	Method
or	O
BD	Method
-	Method
3FE	Method
.	O
After	O
more	O
than	O
a	O
decade	O
,	O
almost	O
all	O
models	O
use	O
less	O
than	O
training	O
scans	O
.	O
Such	O
a	O
small	O
training	O
set	O
is	O
far	O
from	O
adequate	O
to	O
describe	O
the	O
full	O
variability	O
of	O
human	O
faces	O
.	O
Only	O
recently	O
,	O
Booth	O
et	O
al	O
.	O
spent	O
a	O
significant	O
effort	O
to	O
build	O
3DMM	Method
from	O
scans	O
of	O
subjects	O
.	O
Second	O
,	O
the	O
texture	Method
model	Method
of	O
3DMM	Method
is	O
normally	O
built	O
with	O
a	O
small	O
number	O
of	O
2D	O
face	O
images	O
co	O
-	O
captured	O
with	O
3D	O
scans	O
,	O
under	O
well	O
-	O
controlled	O
conditions	O
.	O
Therefore	O
,	O
such	O
a	O
model	O
is	O
only	O
learnt	O
to	O
represent	O
the	O
facial	O
texture	O
in	O
similar	O
conditions	O
,	O
rather	O
than	O
in	O
-	O
the	O
-	O
wild	O
environments	O
.	O
This	O
substantially	O
limits	O
the	O
application	O
scenarios	O
of	O
3DMM	Method
.	O
Finally	O
,	O
the	O
representation	O
power	O
of	O
3DMM	Method
is	O
limited	O
by	O
not	O
only	O
the	O
size	O
of	O
training	O
set	O
but	O
also	O
its	O
formulation	O
.	O
The	O
facial	O
variations	O
are	O
nonlinear	Method
in	O
nature	O
.	O
E.g.	O
,	O
the	O
variations	O
in	O
different	O
facial	O
expressions	O
or	O
poses	O
are	O
nonlinear	Method
,	O
which	O
violates	O
the	O
linear	Method
assumption	Method
of	Method
PCA	Method
-	Method
based	Method
models	Method
.	O
Thus	O
,	O
a	O
PCA	Method
model	Method
is	O
unable	O
to	O
interpret	O
facial	O
variations	O
well	O
.	O
Given	O
the	O
barrier	O
of	O
3DMM	Method
in	O
its	O
data	O
,	O
supervision	Task
and	Task
linear	Task
bases	Task
,	O
this	O
paper	O
aims	O
to	O
revolutionize	O
the	O
paradigm	O
of	O
learning	O
3DMM	Method
by	O
answering	O
a	O
fundamental	O
question	O
:	O
Whether	O
and	O
how	O
can	O
we	O
learn	O
a	O
nonlinear	Method
3D	Method
Morphable	Method
Model	Method
of	O
face	O
shape	O
and	O
texture	O
from	O
a	O
set	O
of	O
unconstrained	O
2D	O
face	O
images	O
,	O
without	O
collecting	O
3D	O
face	O
scans	O
?	O
If	O
the	O
answer	O
were	O
yes	O
,	O
this	O
would	O
be	O
in	O
sharp	O
contrast	O
to	O
the	O
conventional	O
3DMM	Method
approach	O
,	O
and	O
remedy	O
all	O
aforementioned	O
limitations	O
.	O
Fortunately	O
,	O
we	O
have	O
developed	O
approaches	O
that	O
offer	O
positive	O
answers	O
to	O
this	O
question	O
.	O
Therefore	O
,	O
the	O
core	O
of	O
this	O
paper	O
is	O
regarding	O
how	O
to	O
learn	O
this	O
new	O
3DMM	Method
,	O
what	O
is	O
the	O
representation	O
power	O
of	O
the	O
model	O
,	O
and	O
what	O
is	O
the	O
benefit	O
of	O
the	O
model	O
to	O
facial	Task
analysis	Task
.	O
As	O
shown	O
in	O
Fig	O
.	O
[	O
reference	O
]	O
,	O
starting	O
with	O
an	O
observation	O
that	O
the	O
linear	O
3DMM	Method
formulation	O
is	O
equivalent	O
to	O
a	O
single	Method
layer	Method
network	Method
,	O
using	O
a	O
deep	Method
network	Method
architecture	Method
naturally	O
increases	O
the	O
model	O
capacity	O
.	O
Hence	O
,	O
we	O
utilize	O
two	O
network	Method
decoders	Method
,	O
instead	O
of	O
two	O
PCA	O
spaces	O
,	O
as	O
the	O
shape	Method
and	Method
texture	Method
model	Method
components	Method
,	O
respectively	O
.	O
With	O
careful	O
consideration	O
of	O
each	O
component	O
,	O
we	O
design	O
different	O
networks	O
for	O
shape	O
and	O
texture	O
:	O
the	O
multi	Method
-	Method
layer	Method
perceptron	Method
(	Method
MLP	Method
)	Method
for	O
shape	Method
and	O
convolutional	Method
neural	Method
network	Method
(	O
CNN	Method
)	O
for	O
texture	O
.	O
Each	O
decoder	O
will	O
take	O
a	O
shape	O
or	O
texture	O
representation	O
as	O
input	O
and	O
output	O
the	O
dense	O
3D	O
face	O
or	O
a	O
face	O
texture	O
.	O
These	O
two	O
decoders	O
are	O
essentially	O
the	O
nonlinear	Method
3DMM	Method
.	O
Further	O
,	O
we	O
learn	O
the	O
fitting	Method
algorithm	Method
to	O
our	O
nonlinear	Method
3DMM	Method
,	O
which	O
is	O
formulated	O
as	O
a	O
CNN	Method
encoder	Method
.	O
The	O
encoder	O
takes	O
a	O
2D	O
face	O
image	O
as	O
input	O
and	O
generates	O
the	O
shape	O
and	O
texture	O
parameters	O
,	O
from	O
which	O
two	O
decoders	Method
estimate	O
the	O
3D	O
face	O
and	O
texture	O
.	O
The	O
3D	O
face	O
and	O
texture	O
would	O
perfectly	O
reconstruct	O
the	O
input	O
face	O
,	O
if	O
the	O
fitting	Method
algorithm	Method
and	O
3DMM	Method
are	O
well	O
learnt	O
.	O
Therefore	O
,	O
we	O
design	O
a	O
differentiable	Method
rendering	Method
layer	Method
to	O
generate	O
a	O
reconstructed	O
face	O
by	O
fusing	O
the	O
3D	O
face	O
,	O
texture	O
,	O
and	O
the	O
camera	O
projection	O
parameters	O
estimated	O
by	O
the	O
encoder	Method
.	O
Finally	O
,	O
the	O
end	Method
-	Method
to	Method
-	Method
end	Method
learning	Method
scheme	Method
is	O
constructed	O
where	O
the	O
encoder	Method
and	O
two	O
decoders	Method
are	O
learnt	O
jointly	O
to	O
minimize	O
the	O
difference	O
between	O
the	O
reconstructed	O
face	O
and	O
the	O
input	O
face	O
.	O
Jointly	O
learning	O
the	O
3DMM	Method
and	O
the	O
model	Method
fitting	Method
encoder	Method
allows	O
us	O
to	O
leverage	O
the	O
large	O
collection	O
of	O
unconstrained	O
2D	O
images	O
without	O
relying	O
on	O
3D	O
scans	O
.	O
We	O
show	O
significantly	O
improved	O
shape	O
and	O
texture	O
representation	O
power	O
over	O
the	O
linear	Method
3DMM	Method
.	O
Consequently	O
,	O
this	O
also	O
benefits	O
other	O
tasks	O
such	O
as	O
2D	O
face	Task
alignment	Task
and	O
3D	Task
reconstruction	Task
.	O
In	O
this	O
paper	O
,	O
we	O
make	O
the	O
following	O
contributions	O
:	O
1	O
)	O
We	O
learn	O
a	O
nonlinear	Method
3DMM	Method
model	O
that	O
has	O
greater	O
representation	O
power	O
than	O
its	O
traditional	O
linear	Method
counterpart	Method
.	O
2	O
)	O
We	O
jointly	O
learn	O
the	O
model	O
and	O
the	O
model	Method
fitting	Method
algorithm	Method
via	O
weak	Method
supervision	Method
,	O
by	O
leveraging	O
a	O
large	O
collection	O
of	O
2D	O
images	O
without	O
3D	O
scans	O
.	O
The	O
novel	O
rendering	Method
layer	Method
enables	O
the	O
end	Task
-	Task
to	Task
-	Task
end	Task
training	Task
.	O
3	O
)	O
The	O
new	O
3DMM	Method
further	O
improves	O
performance	O
in	O
related	O
tasks	O
:	O
face	Task
alignment	Task
and	O
face	Task
reconstruction	Task
.	O
section	O
:	O
Prior	O
Work	O
Linear	Method
3DMM	Method
.	O
Since	O
the	O
original	O
work	O
by	O
Blanz	O
and	O
Vetter	O
,	O
there	O
has	O
been	O
a	O
large	O
amount	O
of	O
effort	O
trying	O
to	O
improve	O
3DMM	Method
modeling	O
mechanism	O
.	O
Paysan	O
et	O
al	O
.	O
use	O
a	O
Nonrigid	Method
Iterative	Method
Closest	Method
Point	Method
to	O
directly	O
align	O
3D	O
scans	O
as	O
an	O
alternative	O
to	O
the	O
UV	Method
space	Method
alignment	Method
method	Method
in	O
.	O
Vlasic	O
et	O
al	O
.	O
use	O
a	O
multilinear	Method
model	Method
to	O
model	O
the	O
combined	O
effect	O
of	O
identity	O
and	O
expression	O
variation	O
on	O
the	O
facial	O
shape	O
.	O
Later	O
,	O
Bolkart	O
and	O
Wuhrer	O
show	O
how	O
such	O
a	O
multilinear	Method
model	Method
can	O
be	O
estimated	O
directly	O
from	O
the	O
3D	O
scans	O
using	O
a	O
joint	Method
optimization	Method
over	O
the	O
model	O
parameters	O
and	O
groupwise	Method
registration	Method
of	O
3D	O
scans	O
.	O
Improving	O
Linear	Method
3DMM	Method
.	O
With	O
PCA	Method
bases	Method
,	O
the	O
statistical	Method
distribution	Method
underlying	O
3DMM	Method
is	O
Gaussian	Method
.	O
Koppen	O
et	O
al	O
.	O
argue	O
that	O
single	Method
-	Method
mode	Method
Gaussian	Method
ca	Method
n’t	Method
represent	O
real	O
-	O
world	O
distribution	O
.	O
They	O
introduce	O
the	O
Gaussian	O
Mixture	O
3DMM	Method
that	O
models	O
the	O
global	O
population	O
as	O
a	O
mixture	Method
of	Method
Gaussian	Method
subpopulations	Method
,	O
each	O
with	O
its	O
own	O
mean	O
,	O
but	O
shared	O
covariance	O
.	O
Booth	O
el	O
al	O
.	O
aim	O
to	O
improve	O
texture	O
of	O
3DMM	Method
to	O
go	O
beyond	O
controlled	O
settings	O
by	O
learning	O
âin	Method
-	Method
the	Method
-	Method
wildâ	Method
feature	Method
-	Method
based	Method
texture	Method
model	Method
.	O
However	O
,	O
both	O
works	O
are	O
still	O
based	O
on	O
statistical	Method
PCA	Method
bases	Method
.	O
Duong	O
et	O
al	O
.	O
address	O
the	O
problem	O
of	O
linearity	Task
in	Task
face	Task
modeling	Task
by	O
using	O
Deep	Method
Boltzmann	Method
Machines	Method
.	O
However	O
,	O
they	O
only	O
work	O
with	O
2D	O
face	O
and	O
sparse	O
landmarks	O
;	O
and	O
hence	O
can	O
not	O
handle	O
faces	O
with	O
large	O
-	O
pose	O
variations	O
or	O
occlusion	O
well	O
.	O
2D	Task
Face	Task
Alignment	Task
.	O
2D	Task
Face	Task
Alignment	Task
can	O
be	O
cast	O
as	O
a	O
regression	Task
problem	Task
where	O
2D	O
landmark	O
locations	O
are	O
regressed	O
directly	O
.	O
For	O
large	Task
-	Task
pose	Task
or	Task
occluded	Task
faces	Task
,	O
strong	O
priors	O
of	O
3DMM	Method
face	O
shape	O
have	O
been	O
shown	O
to	O
be	O
beneficial	O
.	O
Hence	O
,	O
there	O
is	O
increasing	O
attention	O
in	O
conducting	O
face	Task
alignment	Task
by	O
fitting	O
a	O
3D	Method
face	Method
model	Method
to	O
a	O
single	O
2D	O
image	O
.	O
Among	O
the	O
prior	O
works	O
,	O
iterative	Method
approaches	Method
with	O
cascades	O
of	O
regressors	O
tend	O
to	O
be	O
preferred	O
.	O
At	O
each	O
cascade	O
,	O
it	O
can	O
be	O
a	O
single	O
or	O
even	O
two	O
regressors	O
.	O
In	O
contrast	O
to	O
aforementioned	O
works	O
that	O
use	O
a	O
fixed	O
3DMM	Method
model	O
,	O
our	O
model	O
and	O
model	Method
fitting	Method
are	O
learned	O
jointly	O
.	O
This	O
results	O
in	O
a	O
more	O
powerful	O
model	O
:	O
a	O
single	Method
-	Method
pass	Method
encoder	Method
,	O
which	O
is	O
learnt	O
jointly	O
with	O
the	O
model	O
,	O
achieves	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
face	Task
alignment	Task
performance	Task
on	O
AFLW2000	Material
benchmark	Material
dataset	Material
.	O
3D	Task
Face	Task
Reconstruction	Task
.	O
3DMM	Method
also	O
demonstrates	O
its	O
strength	O
in	O
face	Task
reconstruction	Task
.	O
Since	O
with	O
a	O
single	O
image	O
,	O
present	O
information	O
about	O
the	O
surface	O
is	O
limited	O
;	O
3D	Task
face	Task
reconstruction	Task
must	O
rely	O
on	O
prior	O
knowledge	O
like	O
3DMM	Method
.	O
Besides	O
3DMM	Method
fitting	O
methods	O
,	O
recently	O
,	O
Richardson	O
et	O
al	O
.	O
design	O
a	O
refinement	Method
network	Method
that	O
adds	O
facial	O
details	O
on	O
top	O
of	O
the	O
3DMM	Method
-	O
based	O
geometry	O
.	O
However	O
,	O
this	O
approach	O
can	O
only	O
learn	O
2.5D	O
depth	O
map	O
,	O
which	O
loses	O
the	O
correspondence	O
property	O
of	O
3DMM	Method
.	O
The	O
recent	O
work	O
of	O
Tewari	O
et	O
al	O
.	O
reconstruct	O
a	O
3D	O
face	O
by	O
an	O
elegant	O
encoder	Method
-	Method
decoder	Method
network	Method
.	O
While	O
their	O
ability	O
to	O
decompose	O
lighting	O
with	O
reflectance	O
is	O
satisfactory	O
,	O
our	O
work	O
has	O
a	O
different	O
objective	O
of	O
learning	O
a	O
nonlinear	Method
3DMM	Method
.	O
section	O
:	O
Proposed	O
Method	O
subsection	O
:	O
Conventional	O
Linear	Method
3DMM	Method
The	O
3D	Method
Morphable	Method
Model	Method
(	O
3DMM	Method
)	O
and	O
its	O
2D	Method
counterpart	Method
,	O
Active	Method
Appearance	Method
Model	Method
,	O
provide	O
parametric	Method
models	Method
for	O
synthesizing	Task
faces	Task
,	O
where	O
faces	O
are	O
modeled	O
using	O
two	O
components	O
:	O
shape	O
and	O
texture	O
.	O
In	O
,	O
Blanz	O
et	O
al	O
.	O
propose	O
to	O
describe	O
the	O
3D	O
face	O
space	O
with	O
PCA	Method
:	O
where	O
is	O
a	O
3D	O
face	O
with	O
vertices	O
,	O
is	O
the	O
mean	O
shape	O
,	O
is	O
the	O
shape	O
parameter	O
corresponding	O
to	O
a	O
3D	O
shape	O
bases	O
.	O
The	O
shape	O
bases	O
can	O
be	O
further	O
split	O
into	O
,	O
where	O
is	O
trained	O
from	O
3D	O
scans	O
with	O
neutral	O
expression	O
,	O
and	O
is	O
from	O
the	O
offsets	O
between	O
expression	O
and	O
neutral	O
scans	O
.	O
The	O
texture	O
of	O
the	O
face	O
is	O
defined	O
within	O
the	O
mean	O
shape	O
,	O
which	O
describes	O
the	O
R	O
,	O
G	O
,	O
B	O
colors	O
of	O
corresponding	O
vertices	O
.	O
is	O
also	O
formulated	O
as	O
a	O
linear	Method
combination	Method
of	Method
texture	Method
basis	Method
functions	Method
:	O
where	O
is	O
the	O
mean	O
texture	O
,	O
is	O
the	O
texture	O
bases	O
,	O
and	O
is	O
the	O
texture	O
parameter	O
.	O
The	O
3DMM	Method
can	O
be	O
used	O
to	O
synthesize	O
novel	O
views	O
of	O
the	O
face	O
.	O
Firstly	O
,	O
a	O
3D	O
face	O
is	O
projected	O
onto	O
the	O
image	O
plane	O
with	O
the	O
weak	Method
perspective	Method
projection	Method
model	Method
:	O
where	O
is	O
the	O
model	Method
construction	Method
and	O
projection	O
function	O
leading	O
to	O
the	O
2D	O
positions	O
of	O
3D	O
vertices	O
,	O
is	O
the	O
scale	O
factor	O
,	O
is	O
the	O
orthographic	O
projection	O
matrix	O
,	O
is	O
the	O
rotation	O
matrix	O
constructed	O
from	O
three	O
rotation	O
angles	O
pitch	O
,	O
yaw	O
,	O
roll	O
,	O
and	O
is	O
the	O
translation	O
vector	O
.	O
While	O
the	O
projection	O
matrix	O
has	O
dimensions	O
,	O
it	O
has	O
six	O
degrees	O
of	O
freedom	O
,	O
which	O
is	O
parameterized	O
by	O
a	O
-	O
dim	O
vector	O
.	O
Then	O
,	O
the	O
2D	O
image	O
is	O
rendered	O
using	O
texture	Method
and	O
an	O
illumination	Method
model	Method
as	O
described	O
in	O
.	O
subsection	O
:	O
Nonlinear	O
3DMM	Method
As	O
mentioned	O
in	O
Sec	O
.	O
[	O
reference	O
]	O
,	O
the	O
linear	Method
3DMM	Method
has	O
the	O
problems	O
such	O
as	O
requiring	O
3D	O
face	O
scans	O
for	O
supervised	Task
learning	Task
,	O
unable	O
to	O
leverage	O
massive	O
unconstrained	O
face	O
images	O
for	O
learning	Task
,	O
and	O
the	O
limited	O
representation	O
power	O
due	O
to	O
the	O
linear	Method
bases	Method
.	O
We	O
propose	O
to	O
learn	O
a	O
nonlinear	Method
3DMM	Method
model	O
using	O
only	O
large	O
-	O
scale	O
in	O
-	O
the	O
-	O
wild	O
2D	O
face	O
images	O
.	O
subsubsection	O
:	O
Problem	Task
Formulation	Task
In	O
linear	Method
3DMM	Method
,	O
the	O
factorization	O
of	O
each	O
components	O
(	O
texture	O
,	O
shape	O
)	O
can	O
be	O
seen	O
as	O
a	O
matrix	Method
multiplication	Method
between	O
coefficients	O
and	O
bases	O
.	O
From	O
a	O
neural	Method
network	Method
’s	O
perspective	O
,	O
this	O
can	O
be	O
viewed	O
as	O
a	O
shallow	Method
network	Method
with	O
only	O
one	O
fully	O
connected	O
layer	O
and	O
no	O
activation	O
function	O
.	O
Naturally	O
,	O
to	O
increase	O
the	O
model	O
’s	O
representative	O
power	O
,	O
the	O
shallow	Method
network	Method
can	O
be	O
extended	O
to	O
a	O
deep	Method
architecture	Method
.	O
In	O
this	O
work	O
,	O
we	O
design	O
a	O
novel	O
learning	Method
scheme	Method
to	O
learn	O
a	O
deep	O
3DMM	Method
and	O
its	O
inference	Method
(	Method
or	Method
fitting	Method
)	Method
algorithm	Method
.	O
Specifically	O
,	O
as	O
shown	O
in	O
Fig	O
.	O
[	O
reference	O
]	O
,	O
we	O
use	O
two	O
deep	Method
networks	Method
to	O
decode	O
the	O
shape	O
,	O
texture	O
parameters	O
into	O
the	O
3D	O
facial	O
shape	O
and	O
texture	O
respectively	O
.	O
To	O
make	O
the	O
framework	O
end	O
-	O
to	O
-	O
end	O
trainable	O
,	O
these	O
parameters	O
are	O
estimated	O
by	O
an	O
encoder	Method
network	Method
,	O
which	O
is	O
essentially	O
the	O
fitting	Method
algorithm	Method
of	O
our	O
3DMM	Method
.	O
Three	O
deep	Method
networks	Method
join	O
forces	O
for	O
the	O
ultimate	O
goal	O
of	O
reconstructing	O
the	O
input	O
face	O
image	O
,	O
with	O
the	O
assistance	O
of	O
a	O
geometry	Method
-	Method
based	Method
rendering	Method
layer	Method
.	O
Formally	O
,	O
given	O
a	O
set	O
of	O
2D	O
face	O
images	O
,	O
we	O
aim	O
to	O
learn	O
an	O
encoder	Method
:	O
that	O
estimates	O
the	O
projection	O
parameter	O
,	O
and	O
shape	O
and	O
texture	O
parameters	O
,	O
a	O
3D	Method
shape	Method
decoder	Method
:	O
that	O
decodes	O
the	O
shape	O
parameter	O
to	O
a	O
3D	O
shape	O
,	O
and	O
a	O
texture	Method
decoder	Method
:	O
that	O
decodes	O
the	O
texture	O
parameter	O
to	O
a	O
realistic	O
texture	O
,	O
with	O
the	O
objective	O
that	O
the	O
rendered	O
image	O
with	O
,	O
,	O
and	O
can	O
approximate	O
the	O
original	O
image	O
well	O
.	O
Mathematically	O
,	O
the	O
objective	Metric
function	Metric
is	O
:	O
where	O
is	O
the	O
rendering	O
layer	O
(	O
Sec	O
.	O
[	O
reference	O
]	O
)	O
.	O
subsubsection	O
:	O
Shape	Method
&	Method
Texture	Method
Representation	Method
Our	O
shape	Method
representation	Method
is	O
the	O
same	O
as	O
that	O
of	O
the	O
linear	O
3DMM	Method
,	O
i.e.	O
,	O
is	O
a	O
set	O
of	O
vertices	O
on	O
the	O
face	O
surface	O
.	O
The	O
shape	Method
decoder	Method
is	O
a	O
MLP	Method
whose	O
input	O
is	O
the	O
shape	O
parameter	O
from	O
.	O
Fig	O
.	O
[	O
reference	O
]	O
illustrates	O
three	O
possible	O
texture	Method
representations	Method
.	O
Texture	O
is	O
defined	O
per	O
vertex	O
in	O
the	O
linear	Method
3DMM	Method
and	O
recent	O
work	O
such	O
as	O
(	O
Fig	O
.	O
[	O
reference	O
]	O
(	O
a	O
)	O
)	O
.	O
There	O
is	O
a	O
texture	O
intensity	O
value	O
corresponding	O
to	O
each	O
vertex	O
in	O
the	O
face	O
mesh	O
.	O
Since	O
3D	O
vertices	O
are	O
not	O
defined	O
on	O
a	O
2D	O
grid	O
,	O
this	O
representation	O
will	O
be	O
parameterized	O
as	O
a	O
vector	O
,	O
which	O
not	O
only	O
loses	O
the	O
spatial	O
relation	O
of	O
vertices	O
,	O
but	O
also	O
prevents	O
it	O
from	O
leveraging	O
the	O
convenience	O
of	O
deploying	O
CNN	Method
on	O
2D	O
imagery	O
.	O
In	O
contrast	O
,	O
given	O
the	O
rapid	O
progress	O
in	O
image	Task
synthesis	Task
,	O
it	O
is	O
desirable	O
to	O
choose	O
a	O
2D	O
image	O
,	O
e.g.	O
,	O
a	O
frontal	O
-	O
view	O
face	O
image	O
in	O
Fig	O
.	O
[	O
reference	O
]	O
(	O
b	O
)	O
,	O
as	O
a	O
texture	Method
representation	Method
.	O
However	O
,	O
frontal	O
faces	O
contain	O
little	O
information	O
of	O
two	O
sides	O
,	O
which	O
would	O
lose	O
much	O
texture	O
information	O
for	O
side	O
-	O
view	O
faces	O
.	O
In	O
light	O
of	O
these	O
considerations	O
,	O
we	O
use	O
an	O
unwrapped	O
2D	O
texture	O
as	O
our	O
texture	Method
representation	Method
(	O
Fig	O
.	O
[	O
reference	O
]	O
(	O
c	O
)	O
)	O
.	O
Specifically	O
,	O
each	O
3D	O
vertex	O
is	O
projected	O
onto	O
the	O
UV	O
space	O
using	O
cylindrical	O
unwarp	O
.	O
Assuming	O
that	O
the	O
face	O
mesh	O
has	O
the	O
top	O
pointing	O
up	O
the	O
axis	O
,	O
the	O
projection	O
of	O
onto	O
the	O
UV	O
space	O
is	O
computed	O
as	O
:	O
where	O
are	O
constant	O
scale	O
and	O
translation	O
scalars	O
to	O
place	O
the	O
unwrapped	O
face	O
into	O
the	O
image	O
boundaries	O
.	O
Also	O
,	O
the	O
texture	Method
decoder	Method
is	O
a	O
CNN	Method
constructed	O
by	O
fractionally	Method
-	Method
strided	Method
convolution	Method
layers	Method
.	O
subsubsection	O
:	O
In	Task
-	Task
Network	Task
Face	Task
Rendering	Task
To	O
reconstruct	O
a	O
face	O
image	O
from	O
the	O
texture	O
,	O
shape	O
,	O
and	O
projection	O
parameter	O
,	O
we	O
define	O
a	O
rendering	Method
layer	Method
.	O
This	O
is	O
accomplished	O
in	O
three	O
steps	O
.	O
Firstly	O
,	O
the	O
texture	O
value	O
of	O
each	O
vertex	O
in	O
is	O
determined	O
by	O
its	O
predefined	O
location	O
in	O
the	O
2D	O
texture	O
.	O
Usually	O
,	O
it	O
involves	O
sub	Method
-	Method
pixel	Method
sampling	Method
via	O
a	O
bilinear	Method
sampling	Method
kernel	Method
:	O
where	O
is	O
the	O
UV	O
space	O
projection	O
of	O
via	O
Eqn	O
.	O
[	O
reference	O
]	O
.	O
Secondly	O
,	O
the	O
3D	O
shape	O
/	O
mesh	O
is	O
projected	O
to	O
the	O
image	O
plane	O
via	O
Eqn	O
.	O
[	O
reference	O
]	O
.	O
Finally	O
,	O
the	O
3D	O
mesh	O
is	O
then	O
rendered	O
using	O
a	O
Z	Method
-	Method
buffer	Method
renderer	Method
,	O
where	O
each	O
pixel	O
is	O
associated	O
with	O
a	O
single	O
triangle	O
of	O
the	O
mesh	O
,	O
where	O
is	O
an	O
operation	O
returning	O
three	O
vertices	O
of	O
the	O
triangle	O
that	O
encloses	O
the	O
pixel	O
after	O
projection	O
.	O
In	O
order	O
to	O
handle	O
occlusions	O
,	O
when	O
a	O
single	O
pixel	O
resides	O
in	O
more	O
than	O
one	O
triangle	O
,	O
the	O
triangle	O
that	O
is	O
closest	O
to	O
the	O
image	O
plane	O
is	O
selected	O
.	O
The	O
value	O
of	O
each	O
pixel	O
is	O
determined	O
by	O
interpolating	O
the	O
intensity	O
of	O
the	O
mesh	O
vertices	O
via	O
barycentric	O
coordinates	O
.	O
There	O
are	O
alternative	O
designs	O
to	O
our	O
rendering	Method
layer	Method
.	O
If	O
the	O
texture	Method
representation	Method
is	O
defined	O
per	O
vertex	O
,	O
as	O
in	O
Fig	O
.	O
[	O
reference	O
]	O
(	O
a	O
)	O
,	O
one	O
may	O
warp	O
the	O
input	O
image	O
onto	O
the	O
vertex	O
space	O
of	O
the	O
3D	O
shape	O
,	O
whose	O
distance	O
to	O
the	O
per	Method
-	Method
vertex	Method
texture	Method
representation	Method
can	O
form	O
a	O
reconstruction	O
loss	O
.	O
This	O
design	O
is	O
adopted	O
by	O
the	O
recent	O
work	O
of	O
.	O
In	O
comparison	O
,	O
our	O
rendered	O
image	O
is	O
defined	O
on	O
a	O
2D	O
grid	O
while	O
the	O
alternative	O
is	O
on	O
top	O
of	O
the	O
3D	O
mesh	O
.	O
As	O
a	O
result	O
,	O
our	O
rendered	O
image	O
can	O
enjoy	O
the	O
convenience	O
of	O
applying	O
the	O
adversarial	Method
loss	Method
,	O
which	O
is	O
shown	O
to	O
be	O
critical	O
in	O
improving	O
the	O
quality	Metric
of	Metric
synthetic	Metric
texture	Metric
.	O
Another	O
design	O
for	O
rendering	Task
layer	Task
is	O
image	Task
warping	Task
based	O
on	O
the	O
spline	Method
interpolation	Method
,	O
as	O
in	O
.	O
However	O
,	O
this	O
warping	O
is	O
continuous	O
:	O
every	O
pixel	O
in	O
the	O
input	O
will	O
map	O
to	O
the	O
output	O
.	O
Hence	O
this	O
warping	Method
operation	Method
fails	O
in	O
the	O
occlusion	O
part	O
.	O
As	O
a	O
result	O
,	O
Cole	O
et	O
al	O
.	O
limit	O
their	O
scope	O
to	O
only	O
synthesizing	O
frontal	O
faces	O
by	O
warping	O
from	O
normalized	O
faces	O
.	O
subsubsection	O
:	O
Network	Method
Architecture	Method
We	O
design	O
our	O
network	Method
architecture	Method
as	O
in	O
Tab	O
.	O
[	O
reference	O
]	O
.	O
Also	O
,	O
includes	O
two	O
fully	Method
connected	Method
layers	Method
with	O
-	Method
dim	Method
intermediate	Method
representation	Method
with	O
eLU	Method
activation	Method
.	O
The	O
entire	O
network	O
is	O
end	O
-	O
to	O
-	O
end	O
trained	O
to	O
reconstruct	O
the	O
input	O
images	O
,	O
with	O
the	O
loss	O
function	O
:	O
where	O
the	O
reconstruction	O
loss	O
enforces	O
the	O
rendered	O
image	O
to	O
be	O
similar	O
to	O
the	O
input	O
,	O
the	O
adversarial	Method
loss	Method
favors	O
realistic	Task
rendering	Task
,	O
and	O
the	O
landmark	O
loss	O
enforces	O
geometry	O
constraint	O
.	O
Adversarial	O
Loss	O
.	O
Based	O
on	O
the	O
principal	O
of	O
Generative	Method
Adversarial	Method
Network	Method
(	O
GAN	Method
)	O
,	O
the	O
adversarial	Method
loss	Method
is	O
widely	O
used	O
to	O
synthesize	O
photo	O
-	O
realistic	O
images	O
,	O
where	O
the	O
generator	Method
and	Method
discriminator	Method
are	O
trained	O
alternatively	O
.	O
In	O
our	O
case	O
,	O
networks	O
that	O
generate	O
the	O
rendered	O
image	O
is	O
the	O
generator	O
.	O
The	O
discriminator	O
includes	O
a	O
dedicated	Method
network	Method
,	O
which	O
aims	O
to	O
distinguish	O
between	O
the	O
real	O
face	O
image	O
and	O
rendered	O
image	O
.	O
During	O
the	O
training	O
of	O
the	O
generator	Method
,	O
the	O
texture	Method
model	Method
will	O
be	O
updated	O
with	O
the	O
objective	O
that	O
is	O
being	O
classified	O
as	O
real	O
faces	O
by	O
.	O
Since	O
our	O
face	Method
rendering	Method
already	O
creates	O
correct	O
global	O
structure	O
of	O
the	O
face	O
image	O
,	O
the	O
global	Method
image	Method
-	Method
based	Method
adversarial	Method
loss	Method
may	O
not	O
be	O
effective	O
in	O
producing	O
high	O
-	O
quality	O
textures	O
on	O
local	O
facial	O
regions	O
.	O
Therefore	O
,	O
we	O
employ	O
patchGAN	Method
in	O
our	O
discriminator	Method
.	O
Here	O
,	O
is	O
a	O
CNN	Method
consisting	O
of	O
four	O
conv	Method
layers	Method
with	O
stride	O
of	O
,	O
and	O
number	O
of	O
filters	O
are	O
,	O
,	O
and	O
,	O
respectively	O
.	O
Finally	O
,	O
one	O
of	O
key	O
reasons	O
we	O
are	O
able	O
to	O
employ	O
adversarial	Method
loss	Method
is	O
that	O
we	O
are	O
rendering	O
in	O
the	O
2D	O
image	O
space	O
,	O
rather	O
than	O
the	O
3D	O
vertices	O
space	O
or	O
unwrapped	O
texture	O
space	O
.	O
This	O
shows	O
the	O
necessity	O
and	O
importance	O
of	O
our	O
rendering	Method
layer	Method
.	O
Semi	Task
-	Task
Supervised	Task
Pre	Task
-	Task
Training	Task
.	O
Fully	O
unsupervised	Method
training	Method
using	O
only	O
the	O
mentioned	O
reconstruction	Method
and	Method
adversarial	Method
loss	Method
on	O
the	O
rendered	O
image	O
could	O
lead	O
to	O
a	O
degenerate	O
solution	O
,	O
since	O
the	O
initial	Method
estimation	Method
is	O
far	O
from	O
ideal	O
to	O
render	O
meaningful	O
images	O
.	O
Hence	O
,	O
we	O
introduce	O
pre	Method
-	Method
training	Method
loss	Method
functions	Method
to	O
guide	O
the	O
training	Task
in	O
the	O
early	O
iterations	O
.	O
With	O
face	Method
profiling	Method
technique	Method
,	O
Zhu	O
et	O
al	O
.	O
expands	O
the	O
300W	O
dataset	O
into	O
images	O
with	O
the	O
fitted	O
3DMM	Method
shape	O
and	O
projection	O
parameters	O
.	O
Given	O
and	O
,	O
we	O
create	O
the	O
pseudo	O
groundtruth	O
texture	O
by	O
referring	O
every	O
pixel	O
in	O
the	O
UV	O
space	O
back	O
to	O
the	O
input	O
image	O
,	O
i.e.	O
,	O
backward	O
of	O
our	O
rendering	Method
layer	Method
.	O
With	O
,	O
,	O
,	O
we	O
define	O
our	O
pre	Metric
-	Metric
training	Metric
loss	Metric
by	O
:	O
where	O
Due	O
to	O
the	O
pseudo	O
groundtruth	O
,	O
using	O
may	O
run	O
into	O
the	O
risk	O
that	O
our	O
solution	O
learns	O
to	O
mimic	O
the	O
linear	Method
model	Method
.	O
Thus	O
,	O
we	O
switch	O
to	O
the	O
loss	O
of	O
Eqn	O
.	O
[	O
reference	O
]	O
after	O
converges	O
.	O
Sparse	Task
Landmark	Task
Alignment	Task
.	O
To	O
help	O
to	O
better	O
learn	O
the	O
facial	O
shape	O
,	O
the	O
landmark	Task
loss	Task
can	O
be	O
an	O
auxiliary	Task
task	Task
.	O
where	O
is	O
the	O
manually	O
labeled	O
2D	O
landmark	O
locations	O
,	O
is	O
a	O
constant	O
-	O
dim	O
vector	O
storing	O
the	O
indexes	O
of	O
3D	O
vertices	O
corresponding	O
to	O
the	O
labeled	O
2D	O
landmarks	O
.	O
Unlike	O
the	O
three	O
losses	O
above	O
,	O
these	O
landmark	O
annotations	O
are	O
“	O
golden	O
”	O
groundtruth	O
,	O
and	O
hence	O
can	O
be	O
used	O
during	O
the	O
entire	O
training	Task
process	Task
.	O
Different	O
from	O
traditional	O
face	Task
alignment	Task
work	O
where	O
the	O
shape	O
bases	O
are	O
fixed	O
,	O
our	O
work	O
jointly	O
learns	O
the	O
bases	O
functions	O
(	O
i.e.	O
,	O
the	O
shape	Method
decoder	Method
)	O
as	O
well	O
.	O
Minimizing	Task
the	Task
landmark	Task
loss	Task
when	O
updating	O
only	O
moves	O
a	O
tiny	O
subset	O
of	O
vertices	O
,	O
since	O
our	O
is	O
a	O
MLP	Method
consisting	O
of	O
fully	Method
connected	Method
layers	Method
.	O
This	O
could	O
lead	O
to	O
unrealistic	O
shapes	O
.	O
Hence	O
,	O
when	O
optimizing	O
the	O
landmark	Task
loss	Task
,	O
we	O
fix	O
the	O
decoder	Method
and	O
only	O
update	O
the	O
encoder	Method
.	O
Note	O
that	O
the	O
estimated	O
groundtruth	O
in	O
and	O
the	O
landmarks	O
are	O
the	O
only	O
supervision	O
used	O
in	O
our	O
training	O
,	O
due	O
to	O
this	O
our	O
learning	O
is	O
considered	O
as	O
weakly	Task
supervised	Task
.	O
section	O
:	O
Experimental	O
Results	O
The	O
experiments	O
study	O
three	O
aspects	O
of	O
the	O
proposed	O
nonlinear	Method
3DMM	Method
,	O
in	O
terms	O
of	O
its	O
expressiveness	Metric
,	O
representation	Metric
power	Metric
,	O
and	O
applications	O
to	O
facial	Task
analysis	Task
.	O
Using	O
facial	O
mesh	O
triangle	O
definition	O
by	O
Basel	Method
Face	Method
Model	Method
(	O
BFM	Method
)	O
,	O
we	O
train	O
our	O
3DMM	Method
using	O
300W	O
-	O
LP	O
dataset	O
.	O
The	O
model	O
is	O
optimized	O
using	O
Adam	Method
optimizer	Method
with	O
an	O
initial	O
learning	Metric
rate	Metric
of	O
when	O
minimizing	O
,	O
and	O
when	O
minimizing	O
.	O
We	O
set	O
the	O
following	O
parameters	O
:	O
,	O
,	O
.	O
values	O
are	O
set	O
to	O
make	O
losses	O
to	O
have	O
similar	O
magnitudes	O
.	O
subsection	O
:	O
Expressiveness	O
Exploring	Task
feature	Task
space	Task
.	O
We	O
use	O
the	O
entire	O
CelebA	O
dataset	O
with	O
k	O
images	O
to	O
feed	O
to	O
our	O
network	O
to	O
obtain	O
the	O
empirical	O
distribution	O
of	O
our	O
shape	O
and	O
texture	O
parameters	O
.	O
By	O
varying	O
the	O
mean	O
parameter	O
along	O
each	O
dimension	O
proportional	O
to	O
their	O
standard	O
deviations	O
,	O
we	O
can	O
get	O
a	O
sense	O
how	O
each	O
element	O
contributes	O
to	O
the	O
final	O
shape	O
and	O
texture	O
.	O
We	O
sort	O
elements	O
in	O
the	O
shape	O
parameter	O
based	O
on	O
their	O
differences	O
to	O
the	O
mean	O
3D	O
shape	O
.	O
Fig	O
.	O
[	O
reference	O
]	O
shows	O
four	O
examples	O
of	O
shape	O
changes	O
,	O
whose	O
differences	O
rank	O
No	O
.	O
,	O
,	O
,	O
and	O
among	O
elements	O
.	O
Most	O
of	O
top	O
changes	O
are	O
expression	O
related	O
.	O
Similarly	O
,	O
in	O
Fig	O
.	O
[	O
reference	O
]	O
,	O
we	O
visualize	O
different	O
texture	O
changes	O
by	O
adjusting	O
only	O
one	O
element	O
of	O
off	O
the	O
mean	O
parameter	O
.	O
The	O
elements	O
with	O
the	O
same	O
ranks	O
as	O
the	O
shape	O
counterpart	O
are	O
selected	O
.	O
Attribute	Method
Embedding	Method
.	O
To	O
better	O
understand	O
different	O
shape	O
and	O
texture	O
instances	O
embedded	O
in	O
our	O
two	O
decoders	O
,	O
we	O
dig	O
into	O
their	O
attribute	O
meaning	O
.	O
For	O
a	O
given	O
attribute	O
,	O
e.g.	O
,	O
male	O
,	O
we	O
feed	O
images	O
with	O
that	O
attribute	O
into	O
our	O
encoder	O
to	O
obtain	O
two	O
sets	O
of	O
parameters	O
and	O
.	O
These	O
sets	O
represent	O
corresponding	O
empirical	O
distributions	O
of	O
the	O
data	O
in	O
the	O
low	O
dimensional	O
spaces	O
.	O
By	O
computing	O
the	O
mean	O
parameters	O
,	O
and	O
feed	O
into	O
their	O
respective	O
decoders	Method
,	O
we	O
can	O
reconstruct	O
the	O
mean	O
shape	O
and	O
texture	O
with	O
that	O
attribute	O
.	O
Fig	O
.	O
[	O
reference	O
]	O
visualizes	O
the	O
reconstructed	O
shape	O
and	O
texture	O
related	O
to	O
some	O
attributes	O
.	O
Differences	O
among	O
attributes	O
present	O
in	O
both	O
shape	O
and	O
texture	O
.	O
subsection	O
:	O
Representation	Method
Power	Method
Texture	O
.	O
Given	O
a	O
face	O
image	O
,	O
assuming	O
we	O
know	O
the	O
groundtruth	O
shape	O
and	O
projection	O
parameters	O
,	O
we	O
can	O
unwarp	O
the	O
texture	O
into	O
the	O
UV	O
space	O
,	O
as	O
we	O
generate	O
“	O
pseudo	O
groundtruth	O
”	O
texture	O
in	O
the	O
weakly	Task
supervised	Task
step	Task
.	O
With	O
the	O
groundtruth	O
texture	O
,	O
by	O
using	O
gradient	Method
descent	Method
,	O
we	O
can	O
estimate	O
a	O
texture	O
parameter	O
whose	O
decoded	O
texture	O
matches	O
with	O
the	O
groundtruth	O
.	O
Alternatively	O
,	O
we	O
can	O
minimize	O
the	O
reconstruction	Metric
error	Metric
in	O
the	O
image	O
space	O
,	O
through	O
the	O
rendering	Method
layer	Method
with	O
the	O
groundtruth	O
and	O
.	O
Empirically	O
,	O
the	O
two	O
methods	O
give	O
similar	O
performances	O
but	O
we	O
choose	O
the	O
first	O
option	O
as	O
it	O
involves	O
only	O
one	O
warping	O
step	O
,	O
instead	O
of	O
rendering	O
in	O
every	O
optimization	Task
iteration	Task
.	O
For	O
the	O
linear	Method
model	Method
,	O
we	O
use	O
the	O
fitting	O
results	O
of	O
Basel	Method
texture	Method
and	O
Phong	Method
illumination	Method
model	Method
given	O
by	O
.	O
As	O
in	O
Fig	O
.	O
[	O
reference	O
]	O
,	O
our	O
nonlinear	Method
texture	Method
is	O
closer	O
to	O
the	O
groundtruth	O
than	O
the	O
linear	Method
model	Method
,	O
especially	O
for	O
in	O
-	O
the	O
-	O
wild	O
images	O
(	O
the	O
first	O
two	O
rows	O
)	O
.	O
This	O
is	O
expected	O
since	O
the	O
linear	Method
model	Method
is	O
trained	O
with	O
controlled	O
images	O
.	O
Quantitatively	O
,	O
our	O
nonlinear	Method
model	O
has	O
significantly	O
lower	O
reconstruction	Metric
error	Metric
than	O
the	O
linear	Method
model	Method
(	O
vs.	O
,	O
as	O
in	O
Tab	O
.	O
[	O
reference	O
]	O
)	O
.	O
3D	O
Shape	O
.	O
We	O
also	O
compare	O
the	O
power	O
of	O
nonlinear	Method
and	O
linear	Method
3DMM	Method
in	O
representing	O
real	Task
-	Task
world	Task
3D	Task
scans	Task
.	O
We	O
compare	O
with	O
BFM	Method
,	O
the	O
most	O
commonly	O
used	O
3DMM	Method
at	O
present	O
.	O
We	O
use	O
ten	O
3D	O
face	O
scans	O
provided	O
by	O
,	O
which	O
are	O
not	O
included	O
in	O
the	O
training	O
set	O
of	O
BFM	Method
.	O
As	O
these	O
face	O
meshes	O
are	O
already	O
registered	O
using	O
the	O
same	O
triangle	O
definition	O
with	O
BFM	Method
,	O
no	O
registration	Task
is	O
necessary	O
.	O
Given	O
the	O
groundtruth	O
shape	O
,	O
by	O
using	O
gradient	Method
descent	Method
,	O
we	O
can	O
estimate	O
a	O
shape	O
parameter	O
whose	O
decoded	O
shape	O
matches	O
the	O
groundtruth	O
.	O
We	O
define	O
matching	Metric
criteria	Metric
on	O
both	O
vertex	O
distances	O
and	O
surface	O
normal	O
direction	O
.	O
This	O
empirically	O
improves	O
fidelity	O
of	O
final	O
results	O
compared	O
to	O
only	O
optimizing	O
vertex	O
distances	O
.	O
Also	O
,	O
to	O
emphasize	O
the	O
compactness	O
of	O
nonlinear	Method
models	O
,	O
we	O
train	O
different	O
models	O
with	O
different	O
latent	O
space	O
sizes	O
.	O
Fig	O
.	O
[	O
reference	O
]	O
shows	O
the	O
visual	Metric
quality	Metric
of	O
two	O
models	O
’	O
reconstructions	O
.	O
As	O
we	O
can	O
see	O
,	O
our	O
reconstructions	O
closely	O
match	O
the	O
face	O
shapes	O
.	O
Meanwhile	O
the	O
linear	Method
model	Method
struggles	O
with	O
face	O
shapes	O
outside	O
its	O
PCA	O
span	O
.	O
To	O
quantify	O
the	O
difference	O
,	O
we	O
use	O
NME	Method
,	O
averaged	Metric
per	Metric
-	Metric
vertex	Metric
errors	Metric
between	O
the	O
recovered	O
and	O
groundtruth	O
shapes	O
,	O
normalized	O
by	O
inter	O
-	O
ocular	O
distances	O
.	O
Our	O
nonlinear	Method
model	O
has	O
a	O
significantly	O
smaller	O
reconstruction	Metric
error	Metric
than	O
the	O
linear	Method
model	Method
,	O
vs.	O
(	O
Tab	O
.	O
[	O
reference	O
]	O
)	O
.	O
Also	O
,	O
the	O
non	O
-	O
linear	Method
models	Method
are	O
more	O
compact	O
.	O
They	O
can	O
achieve	O
similar	O
performances	O
as	O
linear	Method
models	Method
whose	O
latent	O
spaceâs	O
sizes	O
doubled	O
.	O
subsection	O
:	O
Applications	O
Having	O
shown	O
the	O
capability	O
of	O
our	O
nonlinear	Method
3DMM	Method
(	O
i.e.	O
,	O
two	O
decoders	Method
)	O
,	O
now	O
we	O
demonstrate	O
the	O
applications	O
of	O
our	O
entire	O
network	O
,	O
which	O
has	O
the	O
additional	O
encoder	O
.	O
Many	O
applications	O
of	O
3DMM	Method
are	O
centered	O
on	O
its	O
ability	O
to	O
fit	O
to	O
2D	O
face	O
images	O
.	O
Fig	O
.	O
[	O
reference	O
]	O
visualizes	O
our	O
3DMM	Method
fitting	O
results	O
on	O
CelebA	O
dataset	O
.	O
Our	O
encoder	Method
estimates	O
the	O
shape	O
,	O
texture	O
as	O
well	O
as	O
projection	O
parameter	O
.	O
We	O
can	O
recover	O
personal	O
facial	O
characteristic	O
in	O
both	O
shape	O
and	O
texture	O
.	O
Our	O
texture	O
can	O
have	O
variety	O
skin	O
color	O
or	O
facial	O
hair	O
,	O
which	O
is	O
normally	O
hard	O
to	O
be	O
recovered	O
by	O
linear	Method
3DMM	Method
.	O
2D	Task
Face	Task
Alignment	Task
.	O
Face	Task
alignment	Task
is	O
a	O
critical	O
step	O
for	O
any	O
facial	Task
analysis	Task
task	Task
such	O
as	O
face	Task
recognition	Task
.	O
With	O
enhancement	O
in	O
the	O
modeling	Task
,	O
we	O
hope	O
to	O
improve	O
this	O
task	O
(	O
Fig	O
.	O
[	O
reference	O
]	O
)	O
.	O
We	O
compare	O
face	Task
alignment	Task
performance	O
with	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
methods	O
,	O
SDM	Method
and	O
3DDFA	Method
,	O
on	O
the	O
AFLW2000	Material
dataset	Material
.	O
The	O
alignment	Metric
accuracy	Metric
is	O
evaluated	O
by	O
the	O
Normalized	Metric
Mean	Metric
Error	Metric
(	O
NME	Method
)	O
,	O
the	O
average	Metric
of	Metric
visible	Metric
landmark	Metric
error	Metric
normalized	O
by	O
the	O
bounding	O
box	O
size	O
.	O
Here	O
,	O
current	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
3DDFA	Method
is	O
a	O
cascade	Method
of	Method
CNNs	Method
that	O
iteratively	O
refines	O
its	O
estimation	O
in	O
multiple	O
steps	O
,	O
meanwhile	O
ours	O
is	O
a	O
single	O
-	O
pass	O
of	O
and	O
.	O
However	O
,	O
by	O
jointly	O
learning	O
model	Method
fitting	Method
with	O
3DMM	Method
,	O
our	O
network	O
can	O
surpass	O
’s	O
performance	O
,	O
as	O
in	O
Tab	O
.	O
[	O
reference	O
]	O
.	O
Another	O
perspective	O
is	O
that	O
in	O
conventional	O
3DMM	Method
fitting	O
,	O
the	O
texture	O
is	O
used	O
as	O
the	O
input	O
to	O
regress	O
the	O
shape	O
parameter	O
,	O
while	O
ours	O
adopts	O
an	O
analysis	Method
-	Method
by	Method
-	Method
synthesis	Method
scheme	Method
and	O
texture	O
is	O
the	O
output	O
of	O
the	O
synthesis	O
.	O
Further	O
,	O
for	O
a	O
more	O
fair	O
comparison	O
of	O
nonlinear	Method
vs.	O
linear	Method
models	Method
,	O
we	O
train	O
an	O
encoder	Method
with	O
the	O
same	O
architecture	O
as	O
our	O
,	O
whose	O
output	O
parameter	O
will	O
multiple	O
with	O
the	O
linear	O
shape	O
bases	O
,	O
and	O
train	O
with	O
the	O
landmark	O
loss	O
function	O
(	O
Eqn	O
.	O
[	O
reference	O
]	O
)	O
.	O
Again	O
we	O
observe	O
the	O
higher	O
error	O
from	O
the	O
linear	Method
model	Method
-	O
based	O
fitting	O
.	O
3D	Task
Face	Task
Reconstruction	Task
.	O
We	O
compare	O
our	O
approach	O
to	O
recent	O
works	O
:	O
the	O
CNN	Method
-	Method
based	Method
iterative	Method
supervised	Method
regressor	Method
of	O
Richardson	O
et	O
al	O
.	O
and	O
unsupervised	Method
regressor	Method
method	Method
of	O
Tewari	O
et	O
al	O
.	O
.	O
The	O
work	O
by	O
Tewari	O
et	O
al	O
.	O
is	O
relevant	O
to	O
us	O
as	O
they	O
also	O
learn	O
to	O
fit	O
3DMM	Method
in	O
an	O
unsupervised	Method
fashion	Method
.	O
However	O
,	O
they	O
are	O
limited	O
to	O
linear	O
3DMM	Method
bases	O
,	O
which	O
of	O
course	O
are	O
not	O
jointly	O
trained	O
with	O
the	O
model	O
.	O
Also	O
,	O
we	O
only	O
compare	O
with	O
the	O
coarse	Method
network	Method
in	O
as	O
their	O
refinement	Method
network	Method
use	O
SfS	Method
,	O
which	O
leads	O
to	O
a	O
2.5D	Method
representation	Method
and	O
loses	O
correspondence	O
between	O
different	O
3D	O
shapes	O
.	O
This	O
is	O
orthogonal	O
to	O
our	O
approach	O
.	O
Fig	O
.	O
[	O
reference	O
]	O
shows	O
visual	O
comparison	O
.	O
Following	O
the	O
same	O
setting	O
in	O
,	O
we	O
also	O
quantitatively	O
compare	O
our	O
method	O
with	O
prior	O
works	O
on	O
subjects	O
of	O
FaceWarehouse	O
database	O
(	O
Fig	O
.	O
[	O
reference	O
]	O
)	O
.	O
We	O
achieve	O
on	O
-	O
par	O
results	O
with	O
Garrido	O
et	O
al	O
.	O
,	O
an	O
offline	Method
optimization	Method
method	Method
,	O
while	O
surpassing	O
all	O
other	O
regression	Method
methods	Method
.	O
subsection	O
:	O
Ablation	O
on	O
Texture	Task
Learning	Task
With	O
great	O
representation	O
power	O
,	O
we	O
would	O
like	O
to	O
learn	O
a	O
realistic	O
texture	Method
model	Method
from	O
in	O
-	O
the	O
-	O
wild	O
images	O
.	O
The	O
rendering	Method
layer	Method
opens	O
a	O
possibility	O
to	O
apply	O
adversarial	O
loss	O
in	O
addition	O
to	O
global	O
loss	O
.	O
Using	O
a	O
global	Method
image	Method
-	Method
based	Method
discriminator	Method
is	O
redundant	O
as	O
the	O
global	O
structure	O
is	O
guaranteed	O
by	O
the	O
rendering	Method
layer	Method
.	O
Also	O
,	O
we	O
empirically	O
find	O
that	O
using	O
global	Method
image	Method
-	Method
based	Method
discriminator	Method
can	O
cause	O
severe	O
artifacts	O
in	O
the	O
resultant	O
texture	O
.	O
Fig	O
.	O
[	O
reference	O
]	O
visualizes	O
outputs	O
of	O
our	O
network	O
with	O
different	O
options	O
of	O
adversarial	O
loss	O
.	O
Clearly	O
,	O
patchGAN	Method
offers	O
higher	O
realism	O
and	O
fewer	O
artifacts	O
.	O
section	O
:	O
Conclusions	O
Since	O
its	O
debut	O
in	O
1999	O
,	O
3DMM	Method
has	O
became	O
a	O
cornerstone	O
of	O
facial	Task
analysis	Task
research	Task
with	O
applications	O
to	O
many	O
problems	O
.	O
Despite	O
its	O
impact	O
,	O
it	O
has	O
drawbacks	O
in	O
requiring	O
training	O
data	O
of	O
3D	O
scans	O
,	O
learning	O
from	O
controlled	O
2D	O
images	O
,	O
and	O
limited	O
representation	O
power	O
due	O
to	O
linear	Method
bases	Method
.	O
These	O
drawbacks	O
could	O
be	O
formidable	O
when	O
fitting	O
3DMM	Method
to	O
unconstrained	Task
faces	Task
,	O
or	O
learning	O
3DMM	Method
for	O
generic	Task
objects	Task
such	O
as	O
shoes	O
.	O
This	O
paper	O
demonstrates	O
that	O
there	O
exists	O
an	O
alternative	O
approach	O
to	O
3DMM	Method
learning	O
,	O
where	O
a	O
nonlinear	Method
3DMM	Method
can	O
be	O
learned	O
from	O
a	O
large	O
set	O
of	O
unconstrained	O
face	O
images	O
without	O
collecting	O
3D	O
face	O
scans	O
.	O
Further	O
,	O
the	O
model	Method
fitting	Method
algorithm	Method
can	O
be	O
learnt	O
jointly	O
with	O
3DMM	Method
,	O
in	O
an	O
end	O
-	O
to	O
-	O
end	O
fashion	O
.	O
Our	O
experiments	O
cover	O
a	O
diverse	O
aspects	O
of	O
our	O
learnt	Method
model	Method
,	O
some	O
of	O
which	O
might	O
need	O
the	O
subjective	O
judgment	O
of	O
the	O
readers	O
.	O
We	O
hope	O
that	O
both	O
the	O
judgment	O
and	O
quantitative	O
results	O
could	O
be	O
viewed	O
under	O
the	O
context	O
that	O
,	O
unlike	O
linear	Method
3DMM	Method
,	O
no	O
genuine	O
3D	O
scans	O
are	O
used	O
in	O
our	O
learning	O
.	O
Finally	O
,	O
we	O
believe	O
that	O
unsupervisedly	Method
learning	Method
3D	Method
models	Method
from	O
large	Task
-	Task
scale	Task
in	Task
-	Task
the	Task
-	Task
wild	Task
2D	Task
images	Task
is	O
one	O
promising	O
research	O
direction	O
.	O
This	O
work	O
is	O
one	O
step	O
along	O
this	O
direction	O
.	O
bibliography	O
:	O
References	O
