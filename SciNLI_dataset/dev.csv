,id,sentence1,sentence2,label
0,dev_0,Robustness to noise was only achieved by training with the same distribution-at the expense of performance degradation on other types of noise.,our method performed well on natural noise at test time by using a simplified synthetic noise model during training.,contrasting
1,dev_1,The field has largely moved toward probabilistic decoding strategies that randomly sample from the output distribution token-by-token.,"when many low-likelihood words cumulatively contain quite a bit of probability mass, choosing one of these words can lead to odd or contradictory phrases and semantic errors.",contrasting
2,dev_2,"The verb catch also has a number of possible senses, which can depend on the nature of the object, e.g., a body part object (caught his foot) ""selects"" the meaning of ""becoming entangled"".","there is still a difference between this and the more idiomatic lost his footing; caught would have the same interpretation whichever body part is chosen, and this interpretation is probably the default one in a construction context.",contrasting
3,dev_3,"We found that ""core"" construction activities, like drilling, dismantling, lifting or offloading generally achieve high levels of agreement.","other ""supporting"" ac- Unexpected/unintentional and (potentially) harmful accident or incident occurring during construction activities.",contrasting
4,dev_4,"Third, in terms of the AUC metric, the performance of news recommendation methods on unseen users is slightly lower than that on overlap users which are included in training data.",the performance on both kinds of users in terms of MRR and nDCG metrics has no significant difference.,contrasting
5,dev_5,"As the results in Table 1 show, the current implementation that uses DBpedia Spotlight instead of KanDis for entity linking step, on average achieves a 5% lower accuracy on the unsupervised binary task than the original implementation (Hulpus , et al., 2019).",it achieves a 4% better accuracy on the binary classification between original articles and their first level of simplification (0-1).,contrasting
6,dev_6,"Smooth continuation or just passing the time by chatting is the ""goal"" of this type of dialogue.",the task-oriented dialogue has a specific goal for dialogue participants to achieve together through dialogue.,contrasting
7,dev_7,"In many tasks that are submitted to the crowdsourcing system, each worker works alone; therefore, they can do the task at any time at any place they want.","when we collect human-human dialogues, a pair of workers must be online at the same time.",contrasting
8,dev_8,The aspect of dialogue collection was gamified in these games.,they cannot use their games for other tasks.,contrasting
9,dev_9,is no significant difference in dialogue time and utterance numbers between the gamified and plain versions.,the utterance contents are different between them.,contrasting
10,dev_10,"If the interpretation is faithful, then the curve will drop rapidly, resulting in a small area under a curve (AUC).",replacing the token with zero or removing it from a sentence can cause the OOD problem again.,contrasting
11,dev_11,"For predicting a class entailment, the token with a similar meaning were assigned high attribution score, such as ""swim"" (b3).","tokens that makes two sentences contradicting were highlighted for predicting contradiction, such as ""cafe"" vs. ""bar"" (b4).",contrasting
12,dev_12,"Stance detection has been studied on various types of formal texts such as congressional debates (Thomas et al., 2006) and company-internal discussions (Murakami and Raymond, 2010).","like most recent related work on the topic, we are particularly interested in informal texts from online social media.",contrasting
13,dev_13,"Word sense disambiguation is required for these cases, which is known to be very challenging for verbs.","a potential solution could be to annotate VerbNet frames with effects, but this is outside the scope of this work.",contrasting
14,dev_14,"The assumption might be true in human educational settings where prescriptivism is preferred over descriptivism because the goal is to test humans with well-defined knowledge or norms (Trask, 1999).",it is not true for many NLP tasks due to their pragmatic nature where the meaning of the same sentence might differ depending on the context or background knowledge.,contrasting
15,dev_15,"To be specific, the estimated collective human performance gives JSD and KL scores far below 0.1 on all three sets.",the best JSD achieved by the models is larger than 0.2 and the best KL achieved by the models barely goes below 0.5 across the table.,contrasting
16,dev_16,"A shortcoming of these methods is that they consider all occurrences of a term in the corpus when calculating its representation, including many contexts that are irrelevant to the concept at hand due to polysemy, noise in the corpus or noninformative contexts.","the pattern-based approach consid-ers specific indicative patterns that signal the desired concept, looking for them in a large corpus, and extracting the terms that appear in them.",contrasting
17,dev_17,"If the input contains two sets of information in quotes, the program will assume it is receiving both Ham-NoSys symbols and their glosses.","if the input only contains one set of information in quotes, it will assume it is just receiving HamNoSys symbols",contrasting
18,dev_18,"The previous challenge involved literal language, amenable to symbolic execution.","non-literal language is pervasive in everyday speech (Lakoff and Johnson, 1980).",contrasting
19,dev_19,"The performance is impressive, with some tasks yielding lower perplexity than BERT pre-training + single task finetuning.",it still lags significantly behind fine-tuning applied after pushshift.io Reddit pretraining.,contrasting
20,dev_20,This means that multi-tasking across many tasks helps transfer learning.,the gap between zeroshot performance and multi-task or fine-tuning performance means there is still a significant challenge in improving these results.,contrasting
21,dev_21,"DFGN (Xiao et al., 2019) and SAE (Tu et al., 2019) construct entity graph through named entity recognition (NER).","to the above mentioned models, our SRLGRN builds a heterogeneous graph that contains a document-level graph of various sentences and replaces the entity-based graphs with argumentpredicate based sub-graphs using SRL.",contrasting
22,dev_22,"Several deep SRL models achieve highly accurate results in finding argument spans (Zhou and Xu, 2015;Tan et al., 2018;Marcheggiani et al., 2017;He et al., 2017).",those models are evaluated based on given gold predicates.,contrasting
23,dev_23,SOCC was recollected to study different aspects of on-line comments such as the connections between articles and comments; the connections of comments to each other; the types of topics discussed in comments; the nice (constructive) or mean (toxic) ways in which commenters respond to each other; and how language is used to convey very specific types of evaluation.,the main focus of the annotation is oriented toward the study of the constructiveness and evaluation in the comments.,contrasting
24,dev_24,"In the anamnesis reports, 1,079 sentences (35.20%) were found to contain negations out of 3,065 sentences.","1,219 sentences (22.80%) out of 5,347 sentences were annotated with negations in the radiology reports.",contrasting
25,dev_25,Negation cue detection and scope identification are the tasks for which there are more corpora.,"it is noteworthy that in some of the corpora (BioInfer, Genia Event, Product Review, EMC Dutch, IxaMed-GS, and German negation and speculation corpus) negation cues have not been annotated, despite the fact that the cue is the element that denotes the presence of negation in a sentence and the one to which the rest of the elements (scope, event, and focus) are connected.",contrasting
26,dev_26,UHU-HUVR and IULA Spanish Clinical Record corpora could also be merged for the identification of lexical cues.,"we cannot merge corpora in their actual form because, as we have analyzed before, the annotation formats and guidelines are different.",contrasting
27,dev_27,"As shown in Table 1, a significant fraction of the questions posted in the two forums have answers that were accepted by the person who asked the question (accepted answers).",the majority of these Accepted Answers rely on the question or on fuller forum discourse history and are not good stand-alone candidates for a MRC dataset.,contrasting
28,dev_28,"Especially, identifying when public drifts occur is of great importance to different stakeholders, such as government agencies, companies and news agencies, where they can take proactive actions to avoid damages and pay close attentions to new topics/sentiments etc (Hu et al., 2017).","the dynamic nature of drifts/changes makes it a challenging problem, although concept drift analysis can be applied to focus on detecting variation of data distributions over time.",contrasting
29,dev_29,This indicates that the entity specific model architecture is more efficient in capturing the sort of information required for this knowledge probing task than the general encoderdecoder architecture used by T5.,when T5 is enhanced with an extra pre-training steps focusing on likely answer spans from Wikipedia (T5-11B + SSM) its performance leapfrogs that of EAE.,contrasting
30,dev_30,"In addition to BERT's pre-training objective, ERNIE also masks entities and trains the model to predict them.","with both KNOWBERT and EAE, ERNIE takes entity linking as an input rather than learning to do it inside the model.",contrasting
31,dev_31,"Back Translation: With the same monolingual corpus, MTL achieves better performance on some language pairs (e.g. Fr→En, Gu→En), while getting outperformed on some others, especially on the En→X direction.",back translation is computationally expensive as it involves the additional procedure of training 10 bilingual models (20 for the X→X system) and generating translations for each monolingual sentence.,contrasting
32,dev_32,"Existing question answering datasets focus on dealing with homogeneous information, based either only on text or KB/Table information alone.","as human knowledge is distributed over heterogeneous forms, using homogeneous information alone might lead to severe coverage problems.",contrasting
33,dev_33,This gap suggests the necessity to aggregate heterogeneous information in HybridQA.,the hybrid model's score is still far behind human performance.,contrasting
34,dev_34,"From Table 5, we can clearly observe that using either Table-Only or Passage-Only model achieves a poor accuracy below 20%.",the proposed HYBRIDER can achieve up to 50% EM increase by leveraging both structured and unstructured data during reasoning.,contrasting
35,dev_35,These models simulate a 'fake' KB-incomplete scenario by masking out triples from KB.,"the questions in HYBRIDQA are inherently hybrid in the sense that it requires both information forms to reason, which makes our testbed more realistic.",contrasting
36,dev_36,"For this, human interpreters usually start translation before the source sentence ends.","this makes the translation process much more challenging than the full-sentence translation, because to balance the translation quality and latency, interpreters need to make decisions on when to continue translation and when to stop temporarily to wait for more source side information, which are difficult, especially for syntactically divergent language pairs, such as German and English.",contrasting
37,dev_37,"At each step, there is a wait-k policy synchronizing the adaptive policy, meaning that they have the same lag at that step.","specifically, at any step t, if the lag of the adaptive policy is k , then we apply the NMT model with the wait-k policy and force it to predict existing target tokens until step t, when the model will make a new prediction as the output of step t. the above method only shows how to simulate the adaptive policy to make a prediction at one step if we would like to write at that step, but it does not tell us at which steps we should write.",contrasting
38,dev_38,"If we have a set of models trained independently with different wait-k policies, then we can apply ensemble of those models (Dietterich, 2000; Hansen and Salamon, 1990) to improve the translation quality, which is also used to improve the translation quality of full-sentence translation (Stahlberg and Byrne, 2017).","there may be two issues to apply ensemble of all models: (1) the runtime for each prediction could be longer, resulting in higher latency; and (2) the translation accuracy may be worse, for the best model for one policy may give bad performance when doing inference with another policy.",contrasting
39,dev_39,"Ranzato et al. (2016) propose MIXER algorithm, which is the first application of REINFORCE algorithm (Williams, 1992) in training sequence to sequence model.","an additional model, which is used to predict expected reward, is required in MIXER.",contrasting
40,dev_40,"Knowledge inference on knowledge graph has attracted extensive attention, which aims to find out connotative valid facts in knowledge graph and is very helpful for improving the performance of many downstream applications.",researchers have mainly poured attention to knowledge inference on binary facts.,contrasting
41,dev_41,"Natural language interfaces (NLIs) have been the ""holy grail"" of natural language understating and human-computer interaction for decades (Woods et al., 1972;Codd, 1974;Hendrix et al., 1978;Zettlemoyer and Collins, 2005).","early attempts in building NLIs to databases did not achieve the expected success due to limitations in language understanding capability, among other reasons (Androutsopoulos et al., 1995;Jones and Galliers, 1995).",contrasting
42,dev_42,"Concurrent work on model CHECKLIST evaluation (Ribeiro et al., 2020) includes an invariance test which also examines model undersensitivity.","to CHECKLIST, our work focuses with more detail on the analysis of the invariance phenomenon, the automatic generation of probing samples, an investigation of concrete methods to overcome undesirably invariant model behaviour, and shows that adherence to invariance tests leads to more robust model generalisation.",contrasting
43,dev_43,"On the one hand, this exercise provided a good opportunity to assess the added value of the ontology extraction method adopted and to give it an objective evaluation.","as the final Portuguese ontology evolved from a projection supported by a pre-existing ontology for English, this extraction exercise provided also a ground to gain insight on the similarity of two lexical semantics-based ontologies, for the same semantic domains, but with terms from two different languages, Portuguese and English.",contrasting
44,dev_44,"The prediction accuracy (microaveraged recall) on seen intents may be reduced compared to ReCapsNet and other baselines, since some utterances of seen intents are classified to unseen intents.","the F1 score on seen intents increases significantly, indicating that it has much higher precision than that of the baselines.",contrasting
45,dev_45,Mutual strengthening of opinions: a major cause of disagreement seems to be the piling up of opinions that make each other stronger and therefore better to recognize.,each single expression of such a concatenation can be easily treated differently by the annotators.,contrasting
46,dev_46,Meng et al. (2017) applied a Seq2seq model with a copy mechanism to a keyword extraction task.,models without explicit modeling the sentence planning have a great limitation in generating complex argument structures depending on hierarchy.,contrasting
47,dev_47,Our method is parallel to SLKS because we also utilize the previously selected knowledge.,"we explicitly compute the difference between knowledge selected at different turns, while SLKS only encodes the already selected knowledge in an implicit way.",contrasting
48,dev_48,"As a result, PostKS++ generates a response which is not coherent to the previous context at the 3 rd turn.","our two models select both diverse and appropriate knowledge sentences at all the turns, thereby generating informative responses and making the dialog coherent and natural.",contrasting
49,dev_49,This makes it difficult to scalable for a new domain with limited labeled data.,there has been relatively little research on how to effectively use data from all domains to improve the performance of each domain and also unseen domains.,contrasting
50,dev_50,"As shown in Figure 2(b), The second strand of work (Wen et al., 2018; Qin et al., 2019b) trains model separately for each domain, which can better capture domain-specific features",those methods ignore shared knowledge between different domains (e.g. the location word exists in both schedule domain and navigation domain),contrasting
51,dev_51,The method explicitly differentiates shared and private knowledge.,"this framework still has two issues: (1) given a new domain with extremely little data, the private module can fail to effectively extract the corresponding domain knowledge.",contrasting
52,dev_52,Their works consider only domain-specific features.,our framework explicitly leverages domain-shared features across domains.,contrasting
53,dev_53,"On the one hand, we train the domain classifier to minimize the domain classification loss.","we update the parameters of the network underlying the domain classifier to maximize the domain classification loss, which works adversarially towards the domain classifier.",contrasting
54,dev_54,"As shown in the table, the accuracy of attention methods decreases significantly when we remove attention weights other than those deemed active by the threshold λ.",our model retains high accuracy even with just the active alignments since sparsity is naturally modeled in our contrained optimal transport framework.,contrasting
55,dev_55,"For instance, the compositional meaning of the verb-object pair break the ice could be paraphrased as ""clearing the ice from the sea so that ships could pass"".","the same expression also has an established sense, ""to overcome initial stiffness or reserve in a social setting"" (Ammer, 2013).",contrasting
56,dev_56,"Unlike measuring embedding bias, measuring classification bias is difficult: most NLP datasets are not annotated with protected attributes, precluding the use of standard fairness measures such as equal opportunity (Hardt et al., 2016).",manually annotating a large dataset with a protected attribute is slow and expensive.,contrasting
57,dev_57,"Graph representations of documents such as similarity graph based on lexical similarities (Erkan and Radev, 2004) and discourse graph based on discourse relations (Christensen et al., 2013), have been widely used in traditional graph-based extractive MDS models.","they are not well studied by most abstractive approaches, especially the end-to-end neural approaches.",contrasting
58,dev_58,It can be observed that the proposed learning approach provides positive impacts across most of the target languages.,including Swahili (sw) as an auxiliary language in X-MAML is not beneficial for the performance on the other target languages.,contrasting
59,dev_59,"Recently, deep neural networks have been used to tackle the problem (Bamman et al., 2019), and related problems such as generating coherent and cohesive text (Cho et al., 2019) and identifying relations in generated stories (Roemmele, 2019) have also been addressed.","these studies only focused on how to understand a narrative itself (e.g., how to extract information from a narrative).",contrasting
60,dev_60,This is a step towards guided response generation and bears some similarities with our study.,"a narrative is more general than keywords, and it provides a description of the dialogue session rather than imposing keywords to the next response.",contrasting
61,dev_61,"3) When we remove context-narrative matching, the performance drops too, indicating that context-narrative matching may provide implicit and complementary information for controlling the alignment of response and narrative.","4) when we remove the contextresponse matching, the performance also drops, however, at a much smaller scale, especially on P weak , than when narrative-response matching is removed.",contrasting
62,dev_62,"For a similar purpose, Huang and Carley (2019) used graph attention networks (GAT) to explicitly establish the dependency relationships between words.",these approaches generally ignore the dependency relations which might identify the connections between aspects and opinion words.,contrasting
63,dev_63,"Finally,  Fries et al. (2017) presented a weak supervision approach to NER in the biomedical domain.","unlike the model proposed in this paper, their approach relies on an ad-hoc mechanism for generating candidate spans to classify.",contrasting
64,dev_64,These methods rely on multiple classifiers run simultaneously and whose outputs are combined at prediction time.,"our approach (as in other weak supervision frameworks) only requires labelling functions to be aggregated once, as an intermediary step to create training data for the final model.",contrasting
65,dev_65,Such approaches are useful in case the KG is incomplete.,"this leads to another level of complexity in the QA system, and text corpora might not always be available.",contrasting
66,dev_66,"Hence models that require question-specific sub-graph construction (GraftNet, PullNet) are unable to recall the answer entity in their generated sub-graph and therefore performs poorly.",their performance improves only after including additional text corpora.,contrasting
67,dev_67,"Along with conversational intents, dialogue acts are also used for natural language understanding (NLU) in task-oriented systems (Li et al., 2019; Peskov et al., 2019).","to these prior approaches, our work uses more in-depth meaning representations for open-domain dialogue systems based on lexical conceptual structures (explained in Section 3.1).",contrasting
68,dev_68,"In this work, we limit the types to GIVE, GAIN, LOSE, and PERFORM.",we do not restrict the ask action and target at all.,contrasting
69,dev_69,We can see similar trends of performance for RW based sequences in case of sentiment polarized node expansion also.,sentiment polarized node expansion strategically mitigates the problem of under-specified tweets by extending the tweet-network view to include less-noisy informative nodes so that the generated walks are more diverse and discriminating.,contrasting
70,dev_70,This combination (T+Filtered) outperforms the tweet only prediction by 3.9% -depicting nodes selected for expansion are important for inference.,"as T+Biased without node expansion, T+Unbiased and T+Biased with sentiment polarized node expansion beat this T+Filtered by a margin of 1.8%, 2.7% & 6.4% accuracy respectively.",contrasting
71,dev_71,"For SemEval-2016, a fascinating thing to observe is -Unbiased and Biased RW-based sequences almost give a comparable performance in terms of accuracy.",the Biased RW view consistently outperformed the Unbiased view in F-macro measure in both datasets for each of the cases of node expansion.,contrasting
72,dev_72,"The most related work to Refer360° is Touchdown (Chen et al., 2018) which introduces two tasks: a vision and language navigation task and a spatial description resolution (SDR) task (i.e. a referring expression recognition task for a simulated outdoor environment).","with Touchdown, in our setup instructors, followers, and learning systems observe a partial FoV of the scene, but they can change the FoV continuously to explore the scene.",contrasting
73,dev_73,"Following the Efficient Annotation of Scalar Labels framework (EASL; Sakaguchi and Durme, 2018), we present annotators 5 sentence-pairs, each with a slider bar enabling direct assessment for each pair and ask annotators to calibrate their score for a sentence-pair based on the scores they provided to the other four pairs.","to the uniform scale employed in the original EASL protocol, we modify the interface to allow finer-grained values near 0.0 and 1.0, following psychological findings that humans are especially sensitive to values near the ends of the probability spectrum (Tversky and Kahneman, 1981).",contrasting
74,dev_74,"One method would be to train a categorical NLI model on SNLI and when fine-tuning on u-SNLI, replace the last layer of the network from a categorical prediction with a sigmoid function.",a typical categorical loss function would not take into account the ordering between the different categorical labels.,contrasting
75,dev_75,Distributed representations of words have been an indispensable component for natural language processing (NLP) tasks.,"the large memory footprint of word embeddings makes it challenging to deploy NLP models to memory-constrained devices (e.g., selfdriving cars, mobile devices).",contrasting
76,dev_76,"This break-through performance facilitates the demand to deploy such models to embedded systems (e.g., self-driving cars, mobile devices).","the neural models typically require a large storage or memory footprint, which is a significant concern when deploying neural models to memory-constrained devices (Hinton et al., 2015).",contrasting
77,dev_77,"When we only pretrain the compressing model, the large portion of words, around 80%, is assigned to the largest code-book (i.e., 128).","when we fine-tune the pre-trained models to the task, the ratio of the large one is significantly decreased.",contrasting
78,dev_78,Other studies for ontology embeddings  consider relative positions between spheres as the hierarchical relationships of corresponding concepts.,"they are still limited to linear embeddings, hence may easily fall short of preserving the deep hierarchical structures of KGs.",contrasting
79,dev_79,This observation is generally in line with our expectations because a small dimension limits the expressiveness of KG embeddings.,"hyperKA still exhibits satisfying performance at very small dimensions in comparison to other methods, such as under the dimensions of 10 and 25.",contrasting
80,dev_80,These elements contain potentially crucial information for problem resolution.,they cannot be correctly parsed by tools designed for natural language.,contrasting
81,dev_81,The author uses code tags in HTML sources of posts for supervised training of a character level sequence labelling model.,"the code tags in the posts usually include all forms of non-natural language text like code snippets, command outputs, error messages or stack traces, and file paths (See Fig 2).",contrasting
82,dev_82,They also propose a dependency parser-based approach for extracting these attributes.,"while this approach pays attention to the semantics of the problem, the syntactical idiosyncrasies are ignored.",contrasting
83,dev_83,"To the best of our knowledge, no previous system for learning word embeddings has explicitly focused on the acquisition of this sort of knowledge; by contrast, ConceptNet is at the base of other projects concerned with the development of lexical resources (Mensa, Radicioni, and Lieto 2018) and their usage along with formal ontologies Rho 2015, 2017).","conceptNet is principally a lexical resource, and as such it disregards the conceptual anchoring issue: If we consider the term bat, the bat node in conceptNet mixes all possible senses for the given term, such as the nocturnal mammal, the implement used for hitting the ball, the acronym for ""brown adipose tissue,"" an entity such as the radar-guided glide bomb used by the US Navy in World War II, and so forth.",contrasting
84,dev_84,"For instance, starting from the term sunset eng we encounter the sense bn:08410678n (representing the city of Sunset, Texas).","this sense is provided with the following lexicalizations: out of these three terms only sunset eng actually appears in CNN, giving us a final singleton t + = {sunset eng }.",contrasting
85,dev_85,"In spite of the simplicity of the system using LESSLEX embeddings, our results overcome those reported in literature, where by far more complex architectures were used.","such scores are higher than the agreement among human raters, which can be thought of as an upper bound to systems' performance.",contrasting
86,dev_86,"A popular way to tackle NLP problems with overlap between input and output is to equip seq2seq models with a copying mechanism (Jia and Liang, 2016;Zhao et al., 2019;Chen and Bansal, 2018;Gulcehre et al., 2016;See et al., 2017;Gu et al., 2016), usually borrowing ideas from pointer networks  to point to single tokens in the source sequence.",we use pointer networks to identify entire spans that are to be copied which results in a much more compact representation and faster decoding.,contrasting
87,dev_87,"Fact-checking -a task in which the veracity of an input claim is verified against a corpus of documents that support or refute the claim -has been studied to combat the proliferation of misinformation in political news, social media, and on the web (Thorne et al., 2018;Hanselowski et al., 2019).",verifying scientific claims poses new challenges to both dataset construction and effective modeling.,contrasting
88,dev_88,"The conventional approach to CQA is to train one model to fit the entire training set, and then use it for answering all complex questions at the test time.","such a one-size-fits-all strategy is sub-optimal as the test questions may have diversity due to their inherently different characteristics (Huang et al., 2018).",contrasting
89,dev_89,"There are different ways of explaining how machines make the decision (Ribeiro et al., 2016; Alvarez-Melis and Jaakkola, 2017;  Lee et al., 2019; Liu et al., 2019a), and one of these methods is to extract rationales  (Lei et al., 2016; DeYoung et al., 2019).","most prior work focused on extracting rationales in a supervised manner , but not all datasets contain such annotated rationales for model learning, making the rationalization task difficult and impractical.",contrasting
90,dev_90,"The larger variance of baselines is due to rationalizing-specific training (Lei et al., 2016), which may cause instability when extracting rationales.","our model utilizes the generality from multi-task learning, which is expected to extract rationales in a more stable manner (lower variance), indicating that the proposed method generalizes to different aspects better than baselines.",contrasting
91,dev_91,"Naturally, they provide critical clues to select the candidate news C 2 and C 3 which reveal relevant information.","they are less informative to identify the candidate news C 1 , which is about the competition of National Football League (NFL).",contrasting
92,dev_92,"At the lexical level, it includes semantic tag annotations, which we rely on in our work.","due to the novelty of this task, the available annotations are limited in quantity and consist of a mix of gold and silver standard data.",contrasting
93,dev_93,A simple method is to concatenate multiple documents into a long flat text and treat it as a long sequence to sequence task.,it blurs the boundaries between documents and loses the hierarchy within the document cluster.,contrasting
94,dev_94,"On the one hand there are works for cognate detection harnessing computational methods that propose the first step in a (semi-) automatic analysis of cognates using the vast amount of digitally available data, when manual annotation requires a lot of man-hours (Jager et al., 2017; List et al., 2018).","there are semantic analyses of cognates, that manually investigate cognates to look for links between two different languages (List et al., 2018;Aske, 2015).",contrasting
95,dev_95,"A wealth of work has shown that toxicity and social biases in training data are acquired by large pretrained sentence encoders (e.g., gender bias in BERT; May et al., 2019;Zhao et al., 2019;Basta et al., 2019;Kurita et al., 2019).","fewer studies have investigated toxicity in autoregressive language models, whose generations also suffer from incoherence, blandness, and repetitiveness (Holtzman et al., 2020;Welleck et al., 2019).",contrasting
96,dev_96,"Many researchers have studied previous (non-Transformer) models to understand their actual behavior under different scenarios, showing that these models are taking advantage of clues or failures of datasets and that slight perturbations on the input data can severely reduce their performance.",recent models have not been systematically tested with adversarial-examples in order to show their robustness under severe stress conditions.,contrasting
97,dev_97,"On the one hand, Natural Language Inference (NLI), also known as recognizing textual entailment (RTE) which consists of finding semantic relations between a premise sentence and an associated hypothesis, by classifying if they are entailed, in contradiction or in neutral relationship.","we apply stress tests on a questionanswering (QA) task, also known as machine reading comprehension (MRC) which consists of predicting the answer to a question given a paragraph.",contrasting
98,dev_98,"In the NLI task, we verified that the distraction test significantly reduces the performance of all models, especially in the negation test.","tests on noise examples show that models are somewhat robust, possibly because they were pre-trained in a huge corpus that may have had natural noise.",contrasting
99,dev_99,Most language-based methods for human attribute prediction assume all documents generated by a person are equally informative.,this is not necessarily true.,contrasting
100,dev_100,"Several recent works (Liu et al., 2020; Soleimani et al., 2020; Zhao et al., 2020) leverage representations from large pre-trained language models (LMs) like BERT (Devlin et al., 2019), and RoBERTa  to achieve state-of-the-art results on FEVER.",it is unclear how factual knowledge encompassed in these LMs influences the verification process.,contrasting
101,dev_101,Data-driven approaches using neural networks have achieved promising performances in natural language generation (NLG).,"neural generators are prone to make mistakes, e.g., neglecting an input slot value and generating a redundant slot value.",contrasting
102,dev_102,"Recently, end-to-end neural network-based approaches have shown significant improvements over traditional pipeline-based models in English coreference resolution.",such advancements came at a cost of computational complexity and recent works have not focused on tackling this problem.,contrasting
103,dev_103,This makes it hard to locate the heads in the mentions because the head location is not deterministic.,having deterministic head locations is a very desirable linguistic trait for solving the aforementioned computational complexity issue.,contrasting
104,dev_104,"In both these examples, the embedded clause (that global warming is serious) is presented as an opinion belonging to a source entity (scientists).",differences in the choice of predicate (agree vs. claim) and in how the source is described lead to very different interpretations.,contrasting
105,dev_105,"Intuitively, it would be incompatible with real world events to describe Exxon as vocally denouncing fossil fuels or Al Gore as vocally criticizing climate science, but it is possible to describe such entities as silently holding contradictory beliefs (and in doing so, highlight their hypocrisy).","we also see exceptions (demonstrate in LL, reveal in RL), suggesting that more complex interactions are involved.",contrasting
106,dev_106,"Finally, we experiment with using tweets from known GW activists/skeptics as well as GW article headlines taken from extreme liberal/conservative news sources as additional training data, inferring labels based on the stance of the Twitter user or news source.",we find that adding these examples yields a lower performance compared to using only the human-annotated data.,contrasting
107,dev_107,A wide range of computational models has been applied for extracting different forms of discourse structures.,"across several tasks, neural network methods (Ji and Eisenstein, 2015; Becker et al., 2017) are found the most effective, with relatively superior performance obtained by modeling discourse-level context (Dai and Huang, 2018a,b).",contrasting
108,dev_108,"On the one hand, loneliness—a negative and unwanted state of being alone—has been shown to be correlated with increased cognitive decline, dementia, depression, suicide ideation, self harm, and even death (GerstEmerson and Jayawardhana, 2015; Hawkley and Capitanio, 2015; Luo et al., 2012; Endo et al., 2017)","solitude-a positive and self-driven state of being alone-has been shown to improve autonomy, creativity, and well-being (Long et al., 2003;Knafo, 2012;Coplan and Bowker, 2017;Coplan et al., 2019a).",contrasting
109,dev_109,"Proponents of self-determination theory (Deci and Ryan, 2010) postulate that time alone that is intrinsically motivated (i.e., choosing to spend time alone) is better for one's well-being than time alone that arises for external reasons (e.g., one who is alone due to the nature of their work) (Chua and Koestner, 2008;Nguyen et al., 2018).",the experience of being alone may also differ as a result of when this state arises.,contrasting
110,dev_110,"These are words referring to peaceful and spiritual activities of being with oneself, recharging, and enjoying the present moment.","the words more strongly associated with loneliness than with solitude refer to negative personal experiences of being sad, scared, bored, hurt, and broken-hearted.",contrasting
111,dev_111,Similar percentage of male users is inferred in the solitude sub-corpora (52%).,"in the lonely and loneliness sub-corpora the majority of the inferred users are female (56% and 52%, respectively).",contrasting
112,dev_112,"There were 12% more tweets with the word lonely written by female users than tweets written by males, even though in the General Tweet Corpus (used as control) there were 10% more tweets written by male users.",the emotional content in the SOLO tweets written by male and female users was strikingly similar.,contrasting
113,dev_113,Table 8 shows an inference that relies on inferring the gender of an entity based on a possessive adjectives.,"in French, gender inflection of possessive adjectives depends on the gender of the possessee instead of the gender of the possessor.",contrasting
114,dev_114,"The dataset covers already more than 22 years of publications, including mode than 15 million entries, and it will be available for academics researches.","despite the full range of customization of neural networks, it is possible to achieve even better results.",contrasting
115,dev_115,Their elements are always pairs of conjunctions of atomic predications.,"the TBox includes the semantic relations codified in PrOnto, e.g., the is-a relations between the ontological classes associated with the predicates, as well as definitions of other needed predicates, such as (3) and (4) above for handling negation and disjunction.",contrasting
116,dev_116,"For the pre-training task of machine translation, we have chosen English-to-German (EN-DE) with 3.9M sentence pairs.",it is still unclear whether it is critical to choose the right language pair.,contrasting
117,dev_117,"Since standard BPE produces single segmentation, to realize this regularization the author had to propose a new subword segmentation, different from BPE.","the introduced approach is rather complicated: it requires training a separate segmentation unigram language model, using EM and Viterbi algorithms, and forbids using conventional BPE.",contrasting
118,dev_118,Subword regularization was shown to achieve significant improvements over the method using a single subword sequence.,the proposed method is rather complicated and forbids using conventional BPE.,contrasting
119,dev_119,Thus there is a potential danger that models trained with BPEdropout may tend to use more fine-grained segmentation in inference and hence to slow inference down.,in practice this is not the case: distributions of lengths of generated translations for models trained with BPE and with BPEdropout are close (Figure 4 (b)).,contrasting
120,dev_120,"So far, the only way to overcome this BPE imperfection, its deterministic nature, was to create another subword segmentation algorithm (Kudo, 2018).",we show that BPE itself incorporates the ability to produce multiple segmentations of the same word.,contrasting
121,dev_121,"Many solutions for calculating semantic similarity, both topological and statistical, have already been developed for English.","few are designed that they can be adapted to under-resourced languages like Arabic language, because they often use advanced natural language processing techniques which are specific to a language.",contrasting
122,dev_122,"In 54.14%(1155 answers), the difference is at most one point.","in 11.01%(235 answers), the difference is more than one point.",contrasting
123,dev_123,"Ideally, using word embedding as the learning target via minimizing CD can effectively train the decoder to model the semantic relation existing in the embedding space.","such an approach suffers from the hubness problem (Faruqui et al., 2016) of word embedding in practice (as we later discuss in Sec. 4.5).",contrasting
124,dev_124,"Recently, neural sequential models (Lample et al., 2016; Akbik et al., 2018; Vaswani et al., 2017) have shown strong performance for various sequence labeling task.",these deep neural models are label hungrythey require large amounts of annotated sequences to achieve strong performance.,contrasting
125,dev_125,"We aim to generate augmented labeled sequences for the queried samples in each iteration, thereby introducing more data diversity and improve model generalization.","data augmentation for active sequence labeling is challenging, because we need to generate sentences and token-level labels jointly.",contrasting
126,dev_126,"Several other studies have independently proposed different setups for probing varied aspects of explainability techniques (DeYoung et al., 2020; Sundararajan et al., 2017).",existing studies evaluating explainability methods are discordant and do not compare to properties from previous studies.,contrasting
127,dev_127,"Thus, when a model recognizes a highly indicative pattern of the predicted class k, the tokens involved in the pattern would have highly positive saliency scores for this class and highly negative saliency scores for the remaining classes.","when the model is not highly confident, we can assume that it is unable to recognize a strong indication of any class, and the tokens accordingly do not have high saliency scores for any class.",contrasting
128,dev_128,In Figure 8 (a) our approach finds that the word many is salient and perturbing it slightly can make the NN change the class of the review to negative.,lIME does not identify many as significant.,contrasting
129,dev_129,Our SeNsER can effectively learn the common features of different buildings such as temperature and equipment operating status.,"the building names vary a lot in different buildings and share no similar features; for example, recall the examples in Table 1, the building name phrases are EBU3b, ap&m, and SDH.",contrasting
130,dev_130,The new Audio Span Features alone demonstrate really poor performance and are missing almost all the disfluency events (Detection Recall and F1 lower than 0.001).,"the Audio Span Features along the acoustic and prosodic representation show the best performance on the frame-based system, especially in the identification task (Identification F1 0.118 and Error Rate below 1).",contrasting
131,dev_131,"Clearly, explicit incitement, of the type expressed by an utterance of ""kill all [members of a minority group]"" or ""let's make sure that all [members of a minority group] do not feel welcome,"" is not very difficult to discern.","since ""most contemporary societies do disapprove of"" such invocations, ""overt prejudicial bias has been transformed into subtle and increasingly covert expressions"" (Leets, 2003, p.146).",contrasting
132,dev_132,"The recent years have seen advances in deep learning methods for text matching (Mueller and Thyagarajan, 2016;Gong et al., 2017;Chen et al., 2017;Lan and Xu, 2018).",almost all of these models are initially proposed for English text matching.,contrasting
133,dev_133,"Although character-based models can overcome the problem of data sparsity to some degree (Li et al., 2019), the main drawback of these models is that explicit word information is not fully exploited, which can be potentially useful for semantic matching.",word-based models often suffer some potential issues caused by word segmentation.,contrasting
134,dev_134,This allows the interactive relations among different subtasks to be modeled explicitly for the joint training methods.,none of existing studies along this line has fully exploited the power of such relations.,contrasting
135,dev_135,Most results in Table 2 are within a reasonable range of the results reported in the original article.,some large discrepancies occur in some of the experiments.,contrasting
136,dev_136,"Regardless of the source of the problem, a mismatch between the results from the software and the publications is not desirable, but there is little we can solve with exact replications.",code and data availability is also crucial for reproduction.,contrasting
137,dev_137,Previous research has investigated such persuasive effects for argumentative content.,this paper studies how important the style of news editorials is to achieve persuasion.,contrasting
138,dev_138,We find that the model trained on backtranslated data is often conservative choosing to leave many input sentences almost unchanged.,"as shown by examples in Table 6, the model learned useful transformations by compressing long sentences and utilizing vocabulary adapted to the language of press releases (e.g. �the researchers� in the last example).",contrasting
139,dev_139,"Considering that the structures of the monolingual embedding spaces are closely related to the choice of the context window, it is natural to expect that the context window has a considerable impact on the performance of mapping-based bilingual word embeddings.","most existing work has not provided empirical results on the effect of the context window on cross-lingual embeddings, as their focus is on how to learn a mapping between the two embedding spaces.",contrasting
140,dev_140,"Neural network models have achieved remarkable performance on text classification due to their capacity of representation learning on natural language texts (Zhang et al., 2015;Yang et al., 2016;Joulin et al., 2017;Devlin et al., 2018).","the lack of understanding of their prediction behaviors has become a critical issue for reliability and trustworthiness and hindered their applications in the real world (Lipton, 2016;Ribeiro et al., 2016;Jacovi and Goldberg, 2020).",contrasting
141,dev_141,"Particularly in each iteration, the first term in Equation 9 is approximated with a single sample from q(R|x (i) ) (Kingma and Welling, 2014).",sampling from a Bernoulli distribution (like from any other discrete distributions) causes difficulty in backpropagation.,contrasting
142,dev_142,"Moreover, structured data can also test a model's ability for reasoning and numerical inference (Wiseman et al., 2017) and for building representations of structured objects (Liu et al., 2018), providing an interesting complement to tasks that test these aspects in the NLU setting (Pasupat and Liang, 2015;Chen et al., 2019;Dua et al., 2019).",constructing a data-to-text dataset can be challenging on two axes: task design and annotation process.,contrasting
143,dev_143,"The simplest approach is simply to use the entire table as the source, adding special tokens to mark which cells have been highlighted",many tables can be very large and this strategy performs poorly.,contrasting
144,dev_144,"This hallucination phenomenon has been widely observed in other existing data-to-text datasets (Lebret et al., 2016;Wiseman et al., 2017).",the noisy references in these datasets make it difficult to disentangle model incapability from data noise.,contrasting
145,dev_145,The hidden Markov model (HMM) is a fundamental tool for sequence modeling that cleanly separates the hidden state from the emission structure.,"this separation makes it difficult to fit HMMs to large datasets in modern NLP, and they have fallen out of use due to very poor performance compared to fully observed models.",contrasting
146,dev_146,Previous works usually apply beamsearch-based methods or stochastic searching methods to lexically-constrained generation.,"when the search space is too large, beam-search-based methods always fail to find the constrained optimal solution.",contrasting
147,dev_147,"In cases where the datasets have been a part of shared tasks, we report the highest scores obtained in each task as the State Of The Art (SOTA) for the dataset.","note that we report this to situate our results in context of the same, and these cannot be directly compared, since each task's SOTA is obtained by varied training architecture, suited to perform well in one particular task alone.",contrasting
148,dev_148,The difference between these two tasks is that zero pronoun resolution focuses on resolving anaphoric pronouns to their antecedents assuming the position of the dropped pronoun is already known.,"in dropped pronoun recovery, we consider both anaphoric and non-anaphoric pronouns, and attempt to recover the type of dropped pronoun but not its referent.",contrasting
149,dev_149,"Existing work has focused on modeling referent semantics of the dropped pronoun from context, and globally optimizing the prediction sequences by exploring label dependencies.",there is also something need to do about how to recover the referent as a proper pronoun based on the referent semantics.,contrasting
150,dev_150,"Similarity defined as association, i.e., the mental activation of a term when another is presented (Chiarello et al., 1990; Lemaire and Denhiere, 2006), e.g., knife-murder, has been estimated in terms of frequency of co-occurrence of words in language (and the physical world) (Turney, 2001; Turney and Pantel, 2010; McRae et al., 2012; Bruni et al., 2012).","to associative relatedness, a concept of semantic similarity defined in terms of shared superordinate category (Lupker, 1984; Resnik, 1995) (taxonomical similarity (Turney and Pantel, 2010)) or shared semantic features (Tversky, 1977; Frenck-Mestre and Bueno, 1999; Turney, 2006) has been proposed.",contrasting
151,dev_151,"We observe that our Phase 1 set-up tends to encourage placing antonymous words in the same broad groups, based on their relatedness (e.g., antonymous pairs stay and leave, and lose and gain end up clustered together).","in Phase 2 antonyms are predominantly kept apart: out of 67 antonymy pairs shared with SimVerb (i.e., pairs labeled ANTONYMS in SimVerb), only 2 are placed closer in the arena (inhale - exhale and sink - swim).",contrasting
152,dev_152,"Note that these are not bigram, trigram, and quadgram patterns in ""true"" sense as one of the two activations is dropped during max-pooling process with a pool size of 2 after every CNN layer.","on forwarded high activations, the notion of bigram, trigram, and quadgram holds true.",contrasting
153,dev_153,"These results substantiate the findings on coarse-grained classification task which suggest that instead of training embeddings, using existing pre-trained embeddings by fine-tuning them on the task in hand is a more perceptive choice.",a carefully tailored model on top of these embeddings is advantageous.,contrasting
154,dev_154,Pre-trained language models have achieved huge improvement on many NLP tasks.,"these methods are usually designed for written text, so they do not consider the properties of spoken language.",contrasting
155,dev_155,Our annotators collectively assigned it a low score of 24%.,hTER would miss-classify it as a good translation since there is only one token that requires post-editing.,contrasting
156,dev_156,"Unsurprisingly, supervised models are more accurate than weakly supervised ones.","training supervised models is still challenging: both x and y are structured, so models typically generate y in multiple steps, but the training data cannot reveal which parts of x generate which parts of y and how they are combined.",contrasting
157,dev_157,"In other words, use direct references to the presented row order id as little as possible.","use id if the question explicitly asks about the presentation order, e.g., ""the first on the list"" or ""the first listed"".",contrasting
158,dev_158,The outcomes of the study show that higher-dimensional sentence representations improve translation quality and also the performance in classification tasks.,shorter sentence representations increase the accuracy in non-trainable similarity tasks.,contrasting
159,dev_159,"The proposed QG method added to the BERT-large QA model enjoys a performance boost of about 10 to 20 points, depending on the datasets, with an addition of only about 100 pre-labeled instances.","it is sufficient to add only 1K pre-labeled instances to reach the performance level of the supervised models, where its performance begins to level off.",contrasting
160,dev_160,Knowledge-driven conversation approaches have achieved remarkable research attention recently.,generating an informative response with multiple relevant knowledge without losing fluency and coherence is still one of the main challenges.,contrasting
161,dev_161,We assume an alignment between the anchor words and the story sentencesthe i th anchor word corresponds to the i th sentence in the story.,stories do not naturally occur with a tagged set of such anchor words or keywords.,contrasting
162,dev_162,The training data for this T2is identical to T1.1with both entity mentions and relations manually annotated (D1.1).,the test data only contains entity mentions without relations between them.,contrasting
163,dev_163,"There were a few places in the RHZ that were indicating 19 as ""maximum sentences length"", which can be interpreted as the count includes tokens from entities.",we decided to count excluding the entity tokens as described in the section 2.3 of the RHZ paper.,contrasting
164,dev_164,"Due to scarcer annotated data, the pure data-driven baseline method (TACOLM) falls behind the statistical learning one (i.e. StructLR) with comprehensively designed features.","our model successfully complements the insufficient supervision signals, partly by incorporating linguistic and commonsense knowledge.",contrasting
165,dev_165,"It is shown that negative training effectively reduce probability mass assigned to malicious targets, while keeping the behavior on the test-set unchanged.","almost every word in the malicious target sentences gets lower probability, especially when FWA is not used.",contrasting
166,dev_166,"Collecting a set of explanations E requires additional effort-it took the authors about 1 minute or less to construct each explanation, though we note that it only needs to be done once per dataset (not per example).",collecting a small number of explanations can significantly and disproportionately reduce the number of labeled examples required.,contrasting
167,dev_167,The results are dataset-specific: random explanations help on Spouse but not on Disease.,"in both cases, random explanations do significantly worse than the original explanations (Table 4).",contrasting
168,dev_168,"The ability to incorporate prior knowledge of the ""right"" inductive biases into model representations dangles the prospect of building models that are more robust.",more work will need to be done to make this approach more broadly applicable.,contrasting
169,dev_169,Numbers of data augmentation methods have been proposed to alleviate the dependence on labeled data.,current augmentation approaches such as random insertion or repetition fail to resemble training corpus well and usually resulted in unnatural and limited types of disfluencies.,contrasting
170,dev_170,Other neural baselines were able to achieve reasonable BLEU and Sent Acc.,"their results could not serve as augmented data to pretrain sequence tagging models, since there was no indication where were the disfluent segments in output sentences.",contrasting
171,dev_171,Previous studies for joint CWS and POS tagging mainly follow the character-based tagging paradigm with introducing contextual information such as n-gram features or sentential representations from recurrent neural models.,"for many cases, the joint tagging needs not only modeling from context features but also knowledge attached to them (e.g., syntactic relations among words); limited efforts have been made by existing research to meet such needs.",contrasting
172,dev_172,"Some previous studies (Huang et al., 2007;Jiang et al., 2009;Wang et al., 2011; verified the idea for this task by learning from autoprocessed corpora.",their studies treat auto-processed corpora as gold reference and thus are unable to distinguishingly use it according to its quality (the resulted knowledge is not accurate in most cases).,contrasting
173,dev_173,"If a model is syntactically uninformed, we would expect ""media"" and ""on"" to have comparable impacts on the prediction of ""transitions"", and vice versa.","we observe a far greater impact (darker color) between ""media"" and ""transitions"" than that between ""on"" and ""transitions"".",contrasting
174,dev_174,"The above findings prove that BERT has learned its own syntax as a by-product of self-supervised training, not by directly copying any human design.","giving the superior performance of BERT on downstream tasks, it is natural to ask if BERT is learning an empirically useful structure of language.",contrasting
175,dev_175,"To ensure a fair comparison with them, we also introduced this right-branching bias.","our results show that our method is also robust without this bias (e.g., only 0.9 F1 drops on PTB23).",contrasting
176,dev_176,"In particular, we observe a decent accuracy in identifying discourse relations between adjacent EDUs, perhaps due to the ""next sentence prediction"" task in pre-training, as pointed out in (Shi and Demberg, 2019).","our probes fall behind the left-chain baseline, which benefits from its strong structural prior 4 (principal clause mostly in front of its subordinate clause).",contrasting
177,dev_177,Their results show that the BERT model captures syntax-sensitive agreement patterns well in general.,"subject-verb agreement cannot provide more nuanced tests of other complex structures (e.g., dependency structure, constituency structure), which are the interest of our work.",contrasting
178,dev_178,"Recent efforts (Lu et al., 2018;Schwartz et al., 2019) propose to leverage the semantics of class name to enhance class representation.","different from us, these methods focus on image classification where effects of name semantic are implicit and label dependency is not required.",contrasting
179,dev_179,"Few-shot learning in natural language processing has been explored for classification tasks, including text classification Geng et al., 2019;Yu et al., 2018), entity relation classification Gao et al., 2019;Ye and Ling, 2019), and dialog act prediction (Vlasov et al., 2018).",fewshot learning for slot tagging is less investigated.,contrasting
180,dev_180,The GitHub README describes the code as being based on the study we aim to reproduce.,it implements a different training scheme.,contrasting
181,dev_181,Adding the CamemBERT embeddings always increases the performance of the model LSTM based models.,"as opposed to adding ELMo, the difference with/without CamemBERT is equally considerable for both the LSTM-seq2seq and LSTM-CRF.",contrasting
182,dev_182,"These methods use a graph state long short-term memory (LSTM) network, gated graph neural network (GGNN), or graph convolution network (GCN) to encode AMR graphs directly, and they can explicitly utilize the information provided by the graph structure.",these graph encoders still cannot significantly outperform sequence encoders.,contrasting
183,dev_183,"They first use a generative model to generate the question with the paragraph and answer as model input, and then use a pre-trained MRC model to filter the synthetic question data.",they are unable to generate context-relevant unanswerable questions.,contrasting
184,dev_184,This can cause the augmented question to miss the original key information and not to able to infer the original answer.,it can be observed that the generated answerable questions of CRQDA still maintain the key information for the original answer inference.,contrasting
185,dev_185,"Normally, the pre-training procedures are designed to learn on tokens corresponding to small units of texts (e.g., word pieces for English, characters for Chinese) for efficiency and simplicity.","some important information carried by larger text units may be lost for certain languages when we use a standard encoder, such as BERT.",contrasting
186,dev_186,Sun et al. (2019a) proposed to perform both entity-level and phraselevel masking to learn knowledge and information from the pre-training corpus.,their approaches are limited in the following senses.,contrasting
187,dev_187,"Clearly, encoding premise targets into Seq2Seq boosts its effectiveness, indicating the importance of modeling premise targets.",both Seq2Seq variants perform poorly compared to our approaches.,contrasting
188,dev_188,"Generally, over-performing triplets had little effect on the success rates due to reduced strategy attention.",under-performing triplets were relatively highly attended to.,contrasting
189,dev_189,"These methods include bi-directional language modeling (Peters et al., 2018), masked language models (Devlin et al., 2019), word order permutation (Yang et al., 2019), more robust training (Liu et al., 2019) and more efficient architectures (Lan et al., 2019).",little focus has been put on learning discourse coherence as part of the pretraining objective.,contrasting
190,dev_190,The success of multilingual NMT on low-resource languages relies heavily on transfer learning from high-resource languages for which copious amounts of parallel data is easily accessible.,"existing multilingual NMT approaches often do not effectively utilize the abundance of monolingual data, especially in lowresource languages.",contrasting
191,dev_191,"While massively multilingual models have obtained impressive quality improvements for low-resource languages as well as zero-shot scenarios (Aharoni et al., 2019;Arivazhagan et al., 2019a), it has not yet been shown how these massively multilingual models could be extended to unseen languages, beyond the pipelined approaches (Currey and Heafield, 2019;Lakew et al., 2019).","self-supervised learning approaches have excelled at down-stream cross-lingual transfer (Devlin et al., 2019;Raffel et al., 2019;, but their success for unsupervised NMT (Conneau and Lample, 2019;Song et al., 2019) currently lacks robustness when languages are distant or monolingual data domains are mismatched (Neubig and Hu, 2018;VuliÃ„â€¡ et al., 2019).",contrasting
192,dev_192,"For instance, TAC will assign the same merit score when gold interval [10,20] is compared with predicted interval [5,15], versus when gold [100,200] is compared with prediction [95,195].","a human would judge the latter more favorably, because a 5minute delay in a 10-minute trip would usually be considered more serious than in a 100-minute journey.",contrasting
193,dev_193,TIMEPLEX predicts 1967 for this query (earning an aeIOU credit of 33.33).,tNtComplex predicts 2013 (earning almost no credit) -this also highlights that it does not capture commonsense that a 4 the list of such relation pairs is given in the Appendix C person can marry only after they are born.,contrasting
194,dev_194,These benchmarks help to provide a uniform evaluation of new modeling developments.,"recent work shows a problem with this standard evaluation paradigm based on i.i.d. test sets: datasets often have systematic gaps (such as those due to various kinds of annotator bias) that (unintentionally) allow simple decision rules to perform well on test data (Chen et al., 2016; Gururangan et al., 2018; Geva et al., 2019). ",contrasting
195,dev_195,"Adversarial examples are almost the methodological opposite of contrast sets: they change the input such that a model's decision changes but the gold label does not (Jia and Liang, 2017; Wallace et al., 2019a).","contrast sets are model-agnostic, constructed by experts to characterize whether a model's decision boundary locally aligns to the true decision boundary around some point.",contrasting
196,dev_196,"For most datasets, the average time to perturb each example was 1-3 minutes, which translates to approximately 17-50 hours of work to create 1,000 examples.","some datasets, particularly those with complex output structures, took substantially longer: each example for dependency parsing took an average of 15 minutes (see Appendix B for more details).",contrasting
197,dev_197,"In addition, we use knowledge graphs to obtain distractors for the masked entities, and propose a novel distractor-suppressed ranking objective that is optimized jointly with masked language model.","to existing paradigms, our approach uses knowledge graphs implicitly, only during pre-training, to inject language models with structured knowledge via learning from raw text.",contrasting
198,dev_198,"Recently, Ye et al. (2019) propose to mask one entity mention in a sentence, and then formulate a multiple-choice QA task (Talmor et al., 2019) for representation learning, by treating the masked sentence as the question, and the masked entity plus its negative samples as answer candidates.",this model does not quite match the MLM since the model is pre-trained by multiple-choice QA and only one entity can be masked in a sentence.,contrasting
199,dev_199,"Note, methods using IR (e.g., RoBERTa+KE) must retrieve from Wikipedia during finetuning and inference, which increases the computational overhead significantly.","methods based on additional self-supervised pre-training are more efficient, but often achieve sub-optimal performance since they lack explicitly retrieved contexts.",contrasting
200,dev_200,This helps filter human-generated distractor answers since they unlikely appear in Concept-Net.,our method never uses Concept-Net during finetuning and only observes a small subgraph of ConceptNet (about 30% Ã¢Ë†Â¼ 40% linked concepts without relations) during pre-training.,contrasting
201,dev_201,Both KG-guided and random entity masking can mask informative chunks and long-term dependency needs to be modeled in order to infer the masked tokens.,random span or word masking is likely to mask tokens that can be easily inferred from local context a much simpler task.,contrasting
202,dev_202,"For example, Peters et al. (2019) retrieve entities' embeddings according to the similarity between Transformer's hidden states and pre-trained graph embeddings, then treat the retrieved embeddings as extra inputs to the next layer.","Bosselut et al. (2019) directly finetune a pre-trained LM on partially-masked triples from a KG, aiming at commonsense KBC tasks.",contrasting
203,dev_203,"As for entity linking, there are many mature entity linking systems for ontological or factoid KGs, such as S-MART (Yang and Chang, 2015), DBpeida Lookup, and DeepType (Raiman and Raiman, 2018).","for a commonsense KG whose content consists of non-canonicalized or free-form texts, there is no such a system to complete its entity linking.",contrasting
204,dev_204,"Recently, novel neural architectures have been explored for modeling action items in emails (Lin et al., 2018) and identifying intents in email conversations .","there has been less focus on task-specific email summarization (Corston-Oliver et al., 2004).",contrasting
205,dev_205,"This is namely the case of the Reading Comprehension task (Richardson et al., 2013).",reading Comprehension datasets are costly and difficult to collect and are essentially native English datasets.,contrasting
206,dev_206,The results show us that a relatively low number of samples are needed to reach acceptable results on the reading comprehension task.,"to outperform the Human Score, i.e. 91.2% and 75.9 %, a larger number of samples is required.",contrasting
207,dev_207,"More (2016) combines CRF and structured perceptron with a curated normalization scheme to predict values, and Xu et al. (2019) regard attributes as queries and adopt BIO tags for any attributes, making it applicable for the large-scaled attribute system.",our experimental results show that the model of Xu et al. (2019) may be insufficient to identify which attribute a value corresponds to.,contrasting
208,dev_208,"With respect to harnessing cheap supervision, Williams (2012); Gusev et al. (2011) propose to mine web data using a collection of hand-designed query patterns","to our approach, they are based on counting instead of machine learning and cannot handle the contextualization of events.",contrasting
209,dev_209,We use the original baseline system and interchange transformer weights to compare between BERT and ours.,"because our model replaces temporal expressions with special tokens, it is at disadvantage to be directly evaluated on the original dataset with temporal expressions in natural language.",contrasting
210,dev_210,"As expected, we find that our model achieves better  performance on the three dimensions that are focused in this work (i.e., duration, frequency, and typical time) as well as stationarity.","the improvements are not very substantial, indicating the difficulty of this task and motivates future works.",contrasting
211,dev_211,Policy gradients-based reinforcement learning has proven to be a promising approach for directly optimizing non-differentiable evaluation metrics for language generation tasks.,"optimizing for a specific metric reward leads to improvements in mostly that metric only, suggesting that the model is gaming the formulation of that metric in a particular way without often achieving real qualitative improvements.",contrasting
212,dev_212,"This line of work relies mainly on distributional semantic models, which produce one abstract representation for every word form.","aggregating all senses of a word into a single representation is particularly problematic for semantic change as word meaning hardly ever shifts directly from one sense to another, but rather typically goes through polysemous stages (Hopper et al., 1991).",contrasting
213,dev_213,"Essentially, that work examines how a word gains new senses, and how some senses of a word may become deprecated.","here we examine how different words compete to represent the same meaning, and how the degree of success of words in that competition changes over time.",contrasting
214,dev_214,"Furthermore, many languages with complex morphology are spoken by a limited number of people or are listed as endangered languages  (Mager et al., 2018), which reduces the possible annotator pool even more.","However, morphological segmentation is important for downstream tasks like machine translation (Conforti et al., 2018; Vania and Lopez, 2017), dependency parsing (Seeker and C¸ etinoglu ˘ , 2015; Vania et al., 2018), or semantic role labeling (Sahin and Steedman, 2018). ",contrasting
215,dev_215,The scores of all systems vary across languages.,iL consistently is among the two best systems in terms of accuracy in all settings.,contrasting
216,dev_216,"Looking on the learning curves for each model for increasing training set sizes, we can see that both proposed systems show monotonically increasing performance: they take advantage of more data well, but still achieve decent performance in the low-resource setting, even outperforming all non-neural systems in some settings.","the non-neural models joint and semiCRF have in many cases a good start, but only benefit to a limited extends from additional data.",contrasting
217,dev_217,"If we only consider the exact segmentation point prediction, s2s performs better for all languages.",the differences between the observed error rates are relatively small between s2s and PGNet models.,contrasting
218,dev_218,The translation quality only slightly decreases when drastically decreasing the vocabulary.,there is a gap between the character- Determ   level and subword-level model of 1-2 BLEU points.,contrasting
219,dev_219,BLI accuracy is easy to compute and captures the desired property of CLWE that translation pairs should be close.,"bLI accuracy does not always correlate with accuracy on downstream tasks such as cross-lingual document classification and dependency parsing (Ammar et al., 2016; Fujinuma et al., 2019; Glavas et al., 2019).",contrasting
220,dev_220,"These Process entities can be further selected by combining another query, for example, a compound name.","without annotated documents, we cannot focus on a specific category of terms as shown in Table 8, where we find few terms categorized in Process.",contrasting
221,dev_221,"The matscholar has annotations of seven entities, such as material names, synthesis methods, and applications.",it targets the general material science domain while we focus on superconducting domain.,contrasting
222,dev_222,"They annotated material names and transition temperatures on five full papers, and obtained pair sets of these entities.","our experimental results showed that we need the amount of around 1,000 annotated abstracts to obtain mostly stable results.",contrasting
223,dev_223,Product key memory (PKM) proposed by Lample et al. (2019) enables to improve prediction accuracy by increasing model capacity efficiently with insignificant computational overhead.,their empirical application is only limited to causal language modeling.,contrasting
224,dev_224,Larger model capacity has brought improvement in accuracy by enabling better modeling of data.,increasing model capacity causes a significant increase in computational cost at both training and inference time despite better accuracy.,contrasting
225,dev_225,"Due to the remarkable prediction accuracy, a transformer becomes standard architecture in natural language processing.",memory architecture can also be used to design a function that maps a continuous representation to another representation as a layer in neural networks.,contrasting
226,dev_226,"On the assumption that updating memory parameters sparsely using a limited number of data and training steps might be vulnerable to the catastrophic drift, we try to fix memory parameters during fine-tuning as in Table 5.",it degrades the downstream performance.,contrasting
227,dev_227,"They either have focused on scenarios where the policy is able to explore and collect more data (Degris et al., 2012; Riedmiller, 2005) such as learning online from an outdated replay buffer (e.g. (Munos et al., 2016)), or have performed off-policy policy evaluation (Farajtabar et al., 2018; Jiang and Li, 2016;Precup, 2000; Thomas and Brunskill, 2016).","we learn a policy entirely offline, from a fixed batch of data, with no ability to explore.",contrasting
228,dev_228,We empirically verify the consistency between the predicted answer and the generated proof by showing that the full accuracy matches the proof accuracy.,"in scenarios where questions have open-ended answers, generating answer from a 'proof' in a consistent manner needs more exploration.",contrasting
229,dev_229,Research publications describe both academic and industrial research results.,"it could be that industrial research is not entirely disclosed, since not all industrial research results are made public.",contrasting
230,dev_230,"While in general the number of publications is higher for Asia than for Europe, this proportion changes, when publications of top conferences are compared, putting Europe in first place followed by North America.",it should be noted that the trend in the last two years is an increasing number of research from Asia in comparison to Europe and North America.,contrasting
231,dev_231,Our analysis of publications related to information retrieval for 2000-2017 also demonstrates more interest in this topic before year 2010.,the number of publications after 2010 is rather stable (about 6K a year).,contrasting
232,dev_232,"In most of the rolesets, two to four numbered roles exist.","in some verb groups, such as verbs of motion, there can be six numbered roles in the roleset.",contrasting
233,dev_233,"As discussed previously, derived forms that can be produced through a rule have not been included, as long as they share the same meaning with their bases.","forms that have taken on different meanings, i.e. diverging from the bases from which they were derived, have been included",contrasting
234,dev_234,"General time and place information can be specified for any verb, therefore we chose not to include these as arguments.","more specific occurrences of these have been included, such as ""interval of time"", or ""place that relates to the structure of the event"".",contrasting
235,dev_235,"For instance, in a sentence such as “I ate at a restaurant.”, the place information is simply an additional detail and it is unrelated to the internal structure of the event.","in “I went to the library.”, the place information is an important component of the event, since “to go” is a verb of motion that entails a change in location.",contrasting
236,dev_236,"Comparing the two corpora, one can observe that Turkish is very fond of phrasal structures and makes extensive use of idioms instead of simple verbs, as mentioned above.",what is truly remarkable is the embedding of arguments inside the phrasal verb.,contrasting
237,dev_237,The AVG model performs slightly better than the BiLSTM on both generation tasks.,these metrics are a very crude measure of physical reasoning performance and are not intuitive.,contrasting
238,dev_238,Online social media platforms are popular outlets for individuals to exchange viewpoints and discuss topics they are interested in.,the huge volume of online conversations produced daily hinders people's capability of finding the information they are interested in.,contrasting
239,dev_239,"For recommendation, there are extensive efforts on post-level recommendation (Chen et al., 2012; Yan et al., 2012) and conversation-level (Chen et al., 2011; Zeng et al., 2018, 2019b).","with them which assume static user interests, we capture how user interests change over time and take advantage of the recent advancement of dynamic product recommendation (Wu et al., 2017;Beutel et al., 2018).",contrasting
240,dev_240,This is probably because earlier history enables learning of long-term dynamics and technology change usually happens in a time span that is longer than 1-2 months.,"topics on Fun and Learn may change more rapidly, making the earlier history more noisy and less helpful for modeling users' current interests.",contrasting
241,dev_241,"In this light, more and more governments have realized the importance of public diplomacy, making great efforts to promote their countries' values and perspectives to foreign publics (Entman, 2008; Golan and Himelboim, 2016).",these efforts are not always successful.,contrasting
242,dev_242,"""Economic Consequences"" as the first and ""Public Opinion"" as the second.","in a multiclass setup in which the model is configured to produce a single label, it learns to disregard the second frame ""Public Opinion"" while strongly attending the words ""fargo"" and ""credit"" related to for the theme of ""Economic Consequences"".",contrasting
243,dev_243,"However, in a multiclass setup in which the model is configured to produce a single label, it learns to disregard the second frame ""Public Opinion"" while strongly attending the words ""fargo"" and ""credit"" related to for the theme of ""Economic Consequences"".","a multi-label model correctly attends all words that are related to both frames i.e. ""fargo"", ""credit"", ""nuns"" and ""opposition"" and predicts “Economic Consequences"" and “Public Opinion"" correctly.",contrasting
244,dev_244,These general purpose language identification models work well for longer texts which have similar editing style.,"their performance drops significantly on shorter texts such as search queries and shorter tweets (Cavnar and Trenkle, 1994;Sibun and Reynar, 1996;Baldwin and Lui, 2010), as do many NLP components (Baldwin et al., 2013).",contrasting
245,dev_245,"Since without word boundaries information, it is intuitive to model characters in Chinese tasks directly.","in most cases, the semantic of a single Chinese character is ambiguous.",contrasting
246,dev_246,"Clearly, the automatically labeled datasets in distant supervision contain amounts of sentences with wrong relation labels.",previous works only focus on wrongly labeled instances in training sets but neglect those in test sets.,contrasting
247,dev_247,The model is trained using gold alignments.,our approach is fully unsupervised; it does not require gold alignments generated by human annotators during training.,contrasting
248,dev_248,"For each model, one can extract separate word alignments and symmetrize these using heuristics like grow-diagonal (Och and Ney, 2000b;Koehn et al., 2005).","this approach uses the hard word alignments of both directions as an input, and does not consider any other information of the forward and backward model.",contrasting
249,dev_249,obtained among models selected via SSD (GAZE-SEQ: 56.16) is even higher than that obtained by the best CIDEr-selected one (GAZE-AGG: 55.74).,"this is likely due to CIDEr being sensitive to lexical differences between the test set and the validation set used for model selection, which could lead to slightly different patterns.",contrasting
250,dev_250,"We thus conjecture that this ability is due to the presence of the gaze-dedicated LSTM, which allows for a more abstract processing of the visual input.","the presence of gaze data does not fully solve the issue of words being repeated within the same caption, as illustrated by the rightmost example in Fig.",contrasting
251,dev_251,"A model that can provide such detailed interpretations facilitates answering inferential questions, such as ""Will the player get angry later?"".",existing visual understanding systems are unable to perform such tasks that require speculative reasoning.,contrasting
252,dev_252,"Video Question Answering: Since caption generation can only describe observable events, recent work seeks to move closer to comprehension, by learning to answer complex questions about videos.","the datasets used for Video QA (Yang et al., 2003;Xu et al., 2016;Zhu et al., 2017) focus only on directly evident visual concepts and construct the questions mostly about ""where"" and ""what"" aspects.",contrasting
253,dev_253,Splitting the stigma definition into simpler concepts was adopted in the current research as well.,"the above mentioned approaches do not distinguish between different degrees of the concept, whereas the present work introduced several layers of the concept that were reduced to two in the process: blame and out-of-group generalization.",contrasting
254,dev_254,"It is important that NLP applications such as named entity recognition and question answering produce calibrated confidence scores for their predictions, especially if the applications are to be deployed in a safetycritical domain such as healthcare.",the output space of such structured prediction models is often too large to adapt binary or multi-class calibration methods directly.,contrasting
255,dev_255,"Their biggest limitation is that they rely heavily on cross-domain mapping of information such as functional similarities, e.g., (Vandevenne et al., 2012; Vandevenne et al., 2016; Shu and Cheong, 2010; Cheong and Shu, 2014;Rugaber et al., 2016; Zhao et al., 2018).","automatically identifying crossdomain relational similarities, requires substantial reasoning beyond what is currently computationally feasible.",contrasting
256,dev_256,"The training set contains 30% more images with ""woman cooking"" than ""man cooking"".","when evaluating the top predictions of a trained model, the disparity between males and females is amplified to around 70%.",contrasting
257,dev_257,"If the bias is not amplified, the dots should be scattered around the reference line.","most dots are on the top-right or bottom-left, showing the bias is amplified.",contrasting
258,dev_258,"Recent studies have noticed the problem and focused on generating appropriate seller responses by integrating external information, e.g., product attributes and titles, into single-turn dialogue generation (Zhao et al., 2019; Chen et al., 2019; Gao et al., 2019).",they are difficult to generalize in reality because of limited materials on hand and different scenarios.,contrasting
259,dev_259,"Meng et al. (2019) proposed RefNet, which used background descriptions about the target dialogue and used a copy mechanism to copy tokens or semantic units.","all these models are difficult to generalize in reality because of using different materials, which are not always accessible.",contrasting
260,dev_260,Wu et al. (2016) proposed a hierarchical encoderdecoder framework to model all the context utterances which can better grasp the overall information of the dialogues.,"these models are difficult to generalize, and their results are unsatisfied since responses maybe vary a lot for the same question towards different occasions and speakers.",contrasting
261,dev_261,"Concurrently with this work, Chen et al. (2020) also developed a method of studying the interaction between words using Shapley-based techniques like CD.",their method was based on an assumption of underlying hierarchical structure and therefore unsuitable for the experiments we are about to conduct.,contrasting
262,dev_262,"For example, in the sentence, ""Socrates asked the student trick questions"", ""trick questions"" has a clear definition and strong connotations that are less evident in each word individually.","knowing that ""trick"" and ""student"" co-occur is not sufficient to clarify the meaning and connotations of either word or compose a shared meaning.",contrasting
263,dev_263,The application of a curriculum is based on the often unspoken assumption that the representation of a complex pattern can be reached more easily from a simpler pattern.,"we find that effectively representing shorter scaffolds actually makes a language model less effective at generalizing a long-range rule, as found by Zhang et al. (2018).",contrasting
264,dev_264,"Open-ended generation -the task of generating text that forms a natural continuation from the input text -requires the model to hallucinate text; hence the focus has been to ensure that the model learns to generate text that is more human-like (i.e., less repetitive or dull with more content-related words) (Holtzman et al., 2020;Welleck et al., 2020;See et al., 2019).","tasks such as document summarization (Nenkova and McKeown, 2011;See et al., 2017;Paulus et al., 2018) and data-to-text generation (Lebret et al., 2016;Wiseman et al., 2017) which are not open-ended, require models to be factual and/or faithful to the source text.",contrasting
265,dev_265,"Finally, others have used reinforcement learning to improve informativeness and reduce contradictory information in abstractive summaries, e.g., Pasunuru and Bansal (2018) used a textual entailment-based reward and Arumae and Liu (2019), a question-answering based reward.",these approaches don't evaluate if these rewards improve faithfulness of summaries.,contrasting
266,dev_266,"At first glance, these models are quite similar to ours.",we should make it clear that they are totally different.,contrasting
267,dev_267,"It is acceptable that when using more complicated language models, the effect of visual knowledge will be weakened.","there are indeed some methods to improve the current results, which will be investigated in our future work.",contrasting
268,dev_268,"In some cases, the word jili-da 'be frightened' was annotated with the original frame Experiencer focus when used in a sentence without objects or emotion.","if there were objects and emotion in a sentence, the crowd workers generally selected the frame Emotion directed.",contrasting
269,dev_269,"The frame Intentionally act is a comprehensive high-level frame that covers a wide range of acts, and there are many LUs and derived frames associated with it.","during our testing, the crowd workers tended to choose more specific frames that better represented the meaning of the words in sentences.",contrasting
270,dev_270,"Also, the word bodo-ha-'(a press) report' was annotated with the frame Reporting to emphasize the role of the speaker.","the crowd workers chose the frame Statement for the verbs yeonsul-hada 'speech', jujanghada 'claim', and suneon-hada 'declare' because those verbs are not influenced by the role of the speaker.",contrasting
271,dev_271,The annotators suggested the frame Emotions of mental activity or the frame Emotion active for a sentence describing the emotion of an experience.,"if a sentence was focused on an event or a situation that provoked emotions in an experience, the crowd workers tend to choose the frame Stimulus focus.",contrasting
272,dev_272,"Generally, these works are based on the assumption that the translated target-language words have the same frames as the original-language words.","because of the differences in culture and linguistics (Baker et al., 2018), frames are shown in different manners in bilingual corpora (Torrent et al., 2018)",contrasting
273,dev_273,"Leveraging large amounts of unlabeled data using Transformer-like architectures, like BERT, has gained popularity in recent times owing to their effectiveness in learning general representations that can then be further fine-tuned for downstream tasks to much success.",training these models can be costly both from an economic and environmental standpoint.,contrasting
274,dev_274,"These pre-trained models, particularly the ones based on the Transformer architecture (Vaswani et al., 2017) 1 have achieved state-of-the-art results in a variety of NLP tasks, but come at a great cost financially and environmentally (Strubell et al., 2019;Schwartz et al., 2019).","cross-View Training (cVT) ) is a semi-supervised approach that uses unlabeled data in a task-specific manner, rather than trying to learn general representations that can be used for many downstream tasks.",contrasting
275,dev_275,"For computer vision, the information compressed/reduced in image features can be partially retrieved from neighboring pixels since they share similar and uniform characteristics spatially.","for NLP, the syntax and semantics information of Transformer in language/text domain are more sensitive than that of computer vision.",contrasting
276,dev_276,"A different model was proposed by Frermann and Lapata (2016), focusing instead on capturing the subtle meaning changes within a sense over time.","evaluating such models is difficult, as the lack of large scale time-stamped data prevents direct quantitative evaluation.",contrasting
277,dev_277,"For NEO, the error is below 0.1 (near perfect predictions) for more than 30% of the instances while it is above 0.9 (totally incorrect predictions) for slightly less than 20% of the instances.",sCAN scores correctly more than 40% of the instances while the incorrect predictions are more than 30%.,contrasting
278,dev_278,"On one hand, the MAE is calculated as the average error across the instances which are labeled only with this particular true sense.","in the classification setting, all the instances of a target are taken into account for a specific sense.",contrasting
279,dev_279,Such domains might also require the use of more sophisticated aspect term extraction methods.,it is not the case that our model necessarily overlooks implicit aspects.,contrasting
280,dev_280,"Kirov and Cotterell (2018) argue that the answer is yes: modern Encoder-Decoder (ED) architectures learn human-like behavior when inflecting English verbs, such as extending the regular past tense form /-(e)d/ to novel words.","their work does not address the criticism raised by Marcus et al. (1995): that neural models may learn to extend not the regular, but the most frequent class — and thus fail on tasks like German number inflection, where infrequent suffixes like /-s/ can still be productively generalized.",contrasting
281,dev_281,"Recently, several evaluation test sets have been proposed to measure the word sense disambiguation (WSD) capability of machine translation systems.","to date, these evaluation test sets do not include any training data that would provide a fair setup measuring the sense distributions present within the training data itself.",contrasting
282,dev_282,"Furthermore, English as source language produces higher numbers of ambiguous words compared to English as target language.",the extended training sets tend to be larger in the language pairs with English as source language.,contrasting
283,dev_283,"Unlike in the fully unsupervised setting, the HSMM model with ordering (HSMM+Ord, row U4) learns to distinguish steps from background when constrained to predict each step region once in a video, with predicted background timesteps (70.6%) close to the ground-truth (72%).",performance of this model is still very low on the task metrics -comparable to or underperforming the ordered uniform baseline with background (row B3) on all metrics.,contrasting
284,dev_284,Narration constraints substantially improve all label accuracy (comparing U1 and U5).,"the model overpredicts background, likely because it doesn't enforce each step type to occur in a given video.",contrasting
285,dev_285,"The language has over 30 million extant manuscripts potent for digitisation, one hundred times those in Greek and Latin combined (Goyal et al., 2012).",a major source of concern for the processing of texts in a low-resource language like Sanskrit is the lack of availability of labelled data.,contrasting
286,dev_286,"Based on the predictions from these systems 5 , the relevant candidate words are highlighted so as to assist the annotator by inviting her attention to those words.","the final decision still remains with the annotator, who may or may not choose the suggestion.",contrasting
287,dev_287,"By the end of the experiment, each annotator ends up annotating all the 30 sentences.","an annotator annotates a particular sentence for only one of the 3 annotations tasks, i.e. segmentation annotation without suggestion, segmentation annotation with suggestions and morphosyntactic annotation",contrasting
288,dev_288,"The stock-specific information in Hu et al. (2018) was encoded in the neural network, however, making it focused on the price prediction task","we represent such stock-specific information by the stock embedding, i.e., a vector, which is easy to interpret geometrically and extract for other applications.",contrasting
289,dev_289,"The upper figure (a) shows the conventional setting without sharing, in which J classifiers are generated, one for each stock.",the lower figure (b) shows one classifier generated for all stocks.,contrasting
290,dev_290,Xie and Sun (2019) proposed a sequence-to-tree (Seq2Tree) method for generating an expression tree in pre-order based on the parent node and the left sibling tree of each node.,global information is still not being considered in the generated expression tree.,contrasting
291,dev_291,"The corpus contains 106 texts, only one of which is marked as Evenki in the literary language.","in addition, we will take texts from the Newspaper corpus to be Evenki in the literary language.",contrasting
292,dev_292,"In constrast, Analyser Free can produce analysis for wordforms with different ordering of affixes.","the mean ambiguity also increases, as wordforms receive more possible analyses.",contrasting
293,dev_293,Previous works on cross-lingual NER are mostly based on label projection with pairwise texts or direct model transfer.,"such methods either are not applicable if the labeled data in the source languages is unavailable, or do not leverage information contained in unlabeled data in the target language.",contrasting
294,dev_294,"Differently, model-transfer based methods (Wu and Dredzea, 2019; Wu et al., 2020) focus on training a shared NER model on the labeled data in the source language with languageindependent features, such as cross-lingual word representations (Devlin et al., 2019), and then directly testing the model on the target language.",there are limitations in both labelprojection based methods and model-transfer based methods.,contrasting
295,dev_295,"Past work in natural language processing has studied calibration in the nonneural (Nguyen and O'Connor, 2015) and neural (Kumar and Sarawagi, 2019) settings across several tasks.","past work has not analyzed large-scale pre-trained models, and we additionally analyze out-of-domain settings, whereas past work largely focuses on in-domain calibration (Nguyen and O'Connor, 2015;Guo et al., 2017).",contrasting
296,dev_296,"For example, the KORE 50 (Hoffart et al., 2012) and DBpedia Spotlight (Mendes et al., 2011) data sets are publicly available, converted into NIF and contain news topics from different domains.","they both rely on DBpedia -""the central point of the Linked Open Data movement,"" according to  (Roder et al., 2014) and thus are not capable of delivering results on other KGs.",contrasting
297,dev_297,"To this end, product-related community question answering (PQA) platforms have emerged in many E-commerce sites such as Amazon and Taobao, allowing users to pose their concerns as questions and receive answers from fellow users to obtain useful product information.","similar to other community question answering (CQA) platforms, the user-provided answers on PQA platforms vary significantly on their qualities (Zhang et al., 2020b), and more seriously, their veracity due to the lack of systematic quality control (Mihaylova et al., 2018).",contrasting
298,dev_298,"As pointed out in Mihaylova et al. (2019), verifying the verdict of answers in CQA requires using rich world knowledge.",gathering relevant information as evidence can be difficult due to the open-domain nature of those questions.,contrasting
299,dev_299,"The claim and evidence representations can be learned with neural networks such as recurrent neural networks (RNNs) (Rashkin et al., 2017) or convolutional neural networks (CNNs) (Wang, 2017).",none of these work conducts fact checking problem in QA settings with associated well-formatted evidence sentences.,contrasting
300,dev_300,"There are 27 confounders in the test set, and my vector addition model places all of them in the top 4 ranks for the confounding term.","the Pixie Autoencoder and BERT do not fall for the confounders, with a mean rank of 171 and 266, respectively.",contrasting
301,dev_301,"(Kim, 2014;Li et al., 2015;Zhou et al., 2016;Yang et al., 2016;Chen et al., 2017;Li et al., 2015) focused on classifying the given text as positive, negative, neutral at document level and sentence level.",the accuracy of sentiment classification on multiple opinion aspects/targets level is unsatisfactory.,contrasting
302,dev_302,Existing belief trackers mainly depend on supervised learning with human annotations of belief states for every user utterance.,"collecting these turn-level annotations is labor-intensive and time-consuming, and often requires domain knowledge to identify slots correctly.",contrasting
303,dev_303,"On the whole, GTS-CNN and GTS-BiLSTM achieve the best results respectively with 2 and 3 inference times on two datasets, and GTS-CNN performs better than GTS-BiLSTM in different inference times.",gTS-BERT reaches a crest only with 1 time of inference because BERT has contained rich context semantics.,contrasting
304,dev_304,"To avoid the error propagation of pipeline methods, some studies use joint learning based on traditional machine learning algorithms and hand-crafted features, including Imperatively Defined Factor graph (IDF) (Klinger and Cimiano, 2013a), joint inference based on IDF (Klinger and Cimiano, 2013b), and Integer Linear Programming (ILP) (Yang and Cardie, 2013).","these methods heavily depend on the quality of handcrafted features and sometimes perform worse than pipeline methods (Klinger and Cimiano, 2013b).",contrasting
305,dev_305,"Definition generation, which aims to automatically generate dictionary definitions for words, has recently been proposed to assist the construction of dictionaries and help people understand unfamiliar texts.","previous works hardly consider explicitly modeling the ""components"" of definitions, leading to under-specific generation results.",contrasting
306,dev_306,"It is a common practice for human to consult a dictionary when encountering unfamiliar words (Fraser, 1999).",it is often the case that we cannot find satisfying definitions for words that are rarely used or newly created.,contrasting
307,dev_307,"Inspired by this, Yang et al. (2019) incorporate sememes (Bloomfield, 1949; Dong and Dong, 2003), i.e. minimum units of semantic meanings of human languages, in the task of generating definition in Chinese.","it is just as, if not more, time-consuming and expensive to label the components of words than to write definitions manually.",contrasting
308,dev_308,This in itself is uncontroversial -we do not mind if the model is able to predict a person's gender.,"as gender information is now encoded in the embedding of person1, the model is also able to use this information when scoring other triples, such as (person1, profession, banker).",contrasting
309,dev_309,"Overall, the random forest model gave the highest prediction, in classifying news articles as either reporting an epidemic event or not.","for French documents, the model could predict only one class using the default classification threshold of 0.5.",contrasting
310,dev_310,This is particularly promising since speech pauses can be automatically extracted in tools such as PRAAT.,the results imply that gestures can be employed to predict audience response to some extent as well.,contrasting
311,dev_311,"Since CDM completely blocks the signals of the contexts being identified unimportant, it may falsely disregard useful signals.",cDW emphasizes flexibility and allows further signals to contribute small weights corresponding to its relatedness with the aspect terms in the dependency-based tree.,contrasting
312,dev_312,"Since LCF-BERT uses Semantic Relative Distance, the sentiment term ""without a doubt"" has been paid the most focus due to its close distance to the aspect term ""cuisine"" based on word counts metrics.","the signal of a key sentiment word ""delicious"" is mistakenly down-weighted because it is far away from the aspect term ""cuisine"".",contrasting
313,dev_313,"On QQP, the best model gets 80.2% F1 on heuristically balanced test examples.","on all-pairs test data, the best model can only reach 3.5% precision at a modest 20% recall.",contrasting
314,dev_314,"On WikiQA, our best c-MAP of 84.6% is higher than the best previously reported c-MAP without using additional question-answering data, 83.6% (Garg et al., 2020).","on all-pairs test data, the best model gets 6.5% precision at 20% recall.",contrasting
315,dev_315,"True positives and false negatives are computationally easy to compute, as they only require evaluating S(x) on all the positive inputs x in D test all .","without any structural assumptions on S, it is computationally infeasible to exactly compute the number of false positives, as that would require evaluating S on every negative example in D test all , which is too large to enumerate.",contrasting
316,dev_316,"Static retrieval collects fewer positives over time, as it exhausts the set of positives that are easy to identify.","uncertainty sampling collects many more positives, especially after the first round of training, because it improves its embeddings over time.",contrasting
317,dev_317,The recent emergence of multilingual pretraining language model (mPLM) has enabled breakthroughs on various downstream crosslingual transfer (CLT) tasks.,mPLMbased methods usually involve two problems: (1) simply fine-tuning may not adapt generalpurpose multilingual representations to be task-aware on low-resource languages; (2) ignore how cross-lingual adaptation happens for downstream tasks.,contrasting
318,dev_318,"Specifically, MGL models each CLT process as heterogeneous information propagation over a dynamic graph, which captures latent language correlations and makes the downstream CLT adaptation more interpretable.",solely learning the dynamic graph structures may be insufficient since the graph-based metric space usually favors highresource languages over low-resource ones.,contrasting
319,dev_319,"Recently, some efforts have been initiated on meta learning for low-resource NLP tasks that straightforwardly views each dataset with its objective as a task (Dou et al., 2019).",this strategy can only make meta-leaner learn knowledge from each language separately.,contrasting
320,dev_320,"As we can see, increasing the number of GCN layers from 1 to 2 (default) shows significant improvements.","when further increasing the number of layers to 3 and 4, the performances will be degraded.",contrasting
321,dev_321,"Besides, we propose methods to breakdown the whole (graph, sentence) pair into smaller pieces of (edge, word) pairs with alignments, before training our model to reconstruct each edge given the corresponding word.",neither of the previous efforts tried to leverage this valuable information.,contrasting
322,dev_322,One may argue that we could directly predict the original graph so that no structural information would be lost.,"each type of graphs can have their own parsing algorithm due to their unique properties (such as directed vs undirected, rooted vs unrooted, etc).",contrasting
323,dev_323,Existing dialogue state tracking (DST) models require plenty of labeled data.,"collecting high-quality labels is costly, especially when the number of domains increases.",contrasting
324,dev_324,"JamSpell and Pyenchant spelling checkers are inadequate for correcting text errors at character-level, these performed equally poorly, introducing significantly more errors than they fixed.","the seq2seq-based neural model was our best performing WEC system, it proved to be very effective, correcting significantly more errors than it introduced.",contrasting
325,dev_325,"Our measure is designed to be broadly applicable, requiring no domain-specific annotations; we provide exploratory output on justice utterances from the Supreme Court's oral arguments in the appendix and release code implementing our approach at http://convokit.cornell.edu to encourage experiments in other domains.",the method's efficacy in the present setting is likely boosted by the relative uniformity of crisis counseling conversations; and future work could aim to better accomodate settings with less structure and more linguistic variability.,contrasting
326,dev_326,"Most of the successful and predominant methods for Bilingual Lexicon Induction (BLI) are mapping-based, where a linear mapping function is learned with the assumption that the word embedding spaces of different languages exhibit similar geometric structures (i.e., approximately isomorphic).",several recent studies have criticized this simplified assumption showing that it does not hold in general even for closely related languages.,contrasting
327,dev_327,"Almost all CLWE methods inherently assume that embedding spaces of different languages are approximately isomorphic (i.e., similar in geometric structure).","recently researchers have questioned this simplified assumption and attributed the performance degradation of existing CLWE methods to the strong mismatches in embedding spaces caused by the linguistic and domain divergences Ormazabal et al., 2019).",contrasting
328,dev_328,Both of the individual models have the same encoderdecoder structure as JUG.,the main difference is that there is no shared latent variable between the two individual NLU and NLG models.,contrasting
329,dev_329,"This is supported with the loss of ROBERTA that is adapted to NEWS, calculated on a sample of REVIEWS.",rOBErTA that is adapted to rEVIEWS results in the highest loss for a NEWS sample.,contrasting
330,dev_330,"This class bundles families or groups of genes/proteins, e.g. [transcription factors] protein family or group or [aquaporins] protein family or group .","it does not incorporate very general terms (lipoprotein), locations (mitochondrial genes), functions (RNA-binding proteins) or similarity-descriptions (Caspase-like proteins).",contrasting
331,dev_331,"Such a fast pace of research would not be possible without general NLU benchmarks, which allow for a fair comparison of the proposed methods.",such benchmarks are available only for a handful of languages.,contrasting
332,dev_332,The authors released a toolkit 2 for model evaluation.,they do not provide a public leaderboard to compare the results of different models.,contrasting
333,dev_333,The Slavic-BERT has higher scores than Multi-BERT on seven out of nine tasks.,"without a detailed ablation study, it is difficult to infer the main reason resulting in better performance.",contrasting
334,dev_334,"While these results are not strictly comparable as they are based on different subsets of the data, use different cross-validation strategies and report different performance metrics, they collectively show that supervised models can learn to identify patients with AD using data from elicited speech samples.","as is generally the case with supervised learning on small data sets, overfitting is a concern.",contrasting
335,dev_335,"This model was then used to estimate perplexity of elicited speech samples in cases and controls, with significant differences between mean perplexity scores obtained from subjects with the semantic dementia variant of FTLD and controls.",the authors did not attempt to use perplexity score as a variable in a diagnostic classification of FTLD or its subtypes.,contrasting
336,dev_336,"Fritsch et al. (2019) further improved performance of this approach by substituting a neural LM (a LSTM model) for the n-gram LM, and report an improved AUC of 0.92.","it is currently unclear as to whether this level of accuracy is due to dementia-specific linguistic markers, or a result of markers of other significant differences between the case and control group such as age (x = 71.4 vs. 63) and years of education (x= 12.1 vs. 14.3) (Becker et al., 1994).",contrasting
337,dev_337,"While all models tend to find the increasingly perturbed transcripts more perplexing than their minimally perturbed counterparts, this perplexity decreases with increasing contributions of the dementia LM.","when only this model is used, relative perplexity of the perturbed transcripts increases.",contrasting
338,dev_338,"As such, these benchmarks do not provide reliable estimations of the actual ASR accuracy.","on the truly challenging benchmarks, such as the dinner party conversations CHiME5 (Manohar et al., 2019) benchmark, modern ASRs report WERs in the ranges of 46%-73%.",contrasting
339,dev_339,An alternative to deterministic text generation is to sample directly from the softmax distribution.,"since the probability mass tends to accumulate in a long tail, this procedure generates unlikely words too often, leading to degenerate text (Fan et al., 2018;Holtzman et al., 2020).",contrasting
340,dev_340,"Usually, authors report the values for perplexity computed on the original probability distribution, before truncation.",this metric does not allow different sparse decoding strategies to be compared.,contrasting
341,dev_341,"After learning the joint topic vectors, embedding-based predictions can be derived for any unlabeled review.",these predictions are sub-optimal for sentiment analysis where word order plays an important role.,contrasting
342,dev_342,"Recent advances in self-supervised pretraining (Radford et al., 2018; Devlin et al., 2018a; Liu et al., 2019) have resulted in impressive downstream performance on several NLP tasks (Wang et al., 2018, 2019).","this has led to the development of enormous models, which often require days of training on non-commodity hardware (e.g. TPUs)",contrasting
343,dev_343,We might expect an end-to-end ASR model (without an explicit disfluency detection component) not to effectively detect disfluencies.,"we show that end-to-end ASR models do learn to directly generate fluent transcripts and their performance is comparable to a baseline pipeline system (i.e. an ASR
model followed by a specialized disfluency
detection model).",contrasting
344,dev_344,"While WER with respect to the full reference transcript (containing both fluent and disfluent words) is not meaningful for integrated systems intended to produce fluent output, WER with respect to the fluent subsequence is a meaningful measure of overall system, since this is the intended output of an integrated system.","since disfluencies only comprise around 6% of the total words, the WER score largely reflects how well fluent words are recognized, rather than how well the system handles disfluencies.",contrasting
345,dev_345,"As k is usually small (averaging around 2 per example in our experiments), sequence lengths remain similar to those encountered for the same x during language modeling.",using LMs to directly predict x from x˜ as in Fedus et al. (2018) effectively doubles the sequence length of x,contrasting
346,dev_346," Zhu et al. (2019); Shen et al. (2020) infill multiple variable-length sequences, but these approaches require the masked context to be iteratively updated and reprocessed to fill in blanks one a time.",our approach appends infilled text to the context and does not require reprocessing the entire input sequence for each blank.,contrasting
347,dev_347,Vega-Redondo et al. (2019) annotate business relevance and sentiment on online chat interactions among aspiring entrepreneurs.,"we annotate the communicative styles cooperativeness, motivational, advice and equality on chat interactions between young aspiring entrepreneurs, and develop machine learning systems to automatically predict these styles and indicators of business success for the participants.",contrasting
348,dev_348,"The impact of SpanBERT over BERT is clear, showing 2.4% improvement on average.",none of the HOI models shows a clear advantage over SpanBERT which adapts no HOI.,contrasting
349,dev_349,"Table 3 shows that EE and CM reduce FL errors by 4+%, suggesting that the aggregation of non-local features indeed leads to more conservative linking decisions.","adapting an advanced encoder shows higher impact on WL errors, as SpanBERT reduces almost 10% compared to BERT, implying that representation learning is still more important for semantic matching.",contrasting
350,dev_350,"Contextualized word embeddings have been employed effectively across several tasks in Natural Language Processing, as they have proved to carry useful semantic information.",it is still hard to link them to structured sources of knowledge.,contrasting
351,dev_351,"On the other hand, supervised models (Huang et al., 2019;) have proved to achieve state-of-the-art results on the English benchmarks by taking advantage of manually-annotated data for the task and machine learning algorithms.","supervised approaches are mostly focused on English (Navigli, 2018;Pasini, 2020) and have only recently been applied to lower-resourced languages thanks to automatically-produced datasets (Scarlini et al., 2019;Barba et al., 2020;.",contrasting
352,dev_352,"As expected, conditioning on longer histories increases the predictability of a sentence.","this effect is significantly larger for imagined stories, which suggests that imagined stories flow more linearly than recalled stories.",contrasting
353,dev_353,"We crawled all the weblogs tagged as lung cancer, which resulted in 472 weblogs with 117k articles.","with clinical records written by medical practitioners, patient weblogs contain a wide variety of topics; not only records of progress of their treatment and physical conditions, but also memories of their daily lives.",contrasting
354,dev_354,Patients report nearly four times more adverse effects than therapeutic effects.,they report the nonoccurrence of expected effects with similar frequency for therapeutic and adverse effects.,contrasting
355,dev_355,"This has largely been successful, with over 30 wordnets uploaded to the new interface.","there were some issues along the way, which we detail below.",contrasting
356,dev_356,Figure 2 shows some examples of failed checks on the quality of the semantic hierarchy.,"if the validation process did not encounter any problems, then the projects will have the option to upload it onto the OMW system, which will make it immediately available on its online interface.",contrasting
357,dev_357,"On WMT En-De, with K = 10, beam search gives a mBLEU score of 66.3 but a pairwise score of 74.","the sampling baseline generates very diverse but inaccurate hypotheses, with a pairwise score of 11.8, but a mBLEU of 28.2.",contrasting
358,dev_358,"We propose a new transformer pattern that adheres to this property, the sandwich transformer, and show that it improves perplexity on multiple word-level and character-level language modeling benchmarks, at no cost in parameters, memory, or training time.","the sandwich reordering pattern does not guarantee performance gains across every task, as we demonstrate on machine translation models.",contrasting
359,dev_359,"If the span is incorrect, we expect workers would make a best effort to interpret the span (for example, if the span is one word too long or short they will probably still understand it correctly, especially since they see it in the context of the entire sentence).","for evaluation, we label these cases with a special category, 'none', indicating that the span is incorrect or attached to the incorrect predicate.",contrasting
360,dev_360,"There has been much interest in the problem of systematic generalization in recent years (Bahdanau et al., 2019;Bentivogli et al., 2016;Lake et al., 2017a,b;Gershman and Tenenbaum, 2015;McCoy et al., 2019a;Veldhoen and Zuidema, 2017;Soulos et al., 2019;Prasad et al., 2019;Richardson et al., 2019;Johnson et al., 2017, inter alia).","to our approach (testing novel words in familiar combinations), many of these studies probe systematicity by testing familiar words in novel combinations.",contrasting
361,dev_361,"Depending on the characteristics of the dataset, answers can be selected either from entities in the constructed entity graph (Song et al., 2018;Dhingra et al., 2018; De Cao et al., 2019; Tu et al., 2019; Ding et al., 2019), or from spans in documents by fusing entity representations back into token-level document representation (Xiao et al., 2019).","the constructed graph is mostly used for answer prediction only, while insufficient for finding supporting facts.",contrasting
362,dev_362,"In the Distractor setting, there are 2 gold paragraphs and 8 distractors.",2 gold paragraphs may not be available in the Fullwiki Setting.,contrasting
363,dev_363,"In the task of sentiment analysis, we observe that training examples containing the most positively salient token in the test example generally have a higher influence to the test prediction.","we do not see this trend (in fact, it is the opposite) in the task of natural language inference.",contrasting
364,dev_364,"Since the appearance and rise of attentionbased models, many work naturally inspect attention scores and interpret with them.","we are aware of the recent discussion over whether attention is a kind of faithful explanation (Jain and Wallace, 2019;Wiegreffe and Pinter, 2019).",contrasting
365,dev_365,"Regarding reproducibility in NLP, a cross-cutting analysis of papers presented at the EMNLP 4 2018 conference (Dodge et al., 2019) showed a widespread, positive practice of reporting the best hyperparameter settings (74%) and the data splits used (92%).","only 8% of the papers describe the hyperparameter search bounds, 14% the search strategy, and only 30% provide the source code.",contrasting
366,dev_366,"Even though most semantic-role formalisms are built upon constituent syntax, and only syntactic constituents can be labeled as arguments (e.g., FrameNet and PropBank), all the recent work on syntaxaware SRL relies on dependency representations of syntax.",we show how graph convolutional networks (GCNs) can be used to encode constituent structures and inform an SRL system.,contrasting
367,dev_367,"An interesting difference is that for ELMo, syntax is more helpful for arguments very far from the predicate.","for RoBERTa, syntax is helpful on arguments 4-7 tokens away from the predicate, but hurts performance on arguments farther away from the predicate.",contrasting
368,dev_368,Tweets quoting another tweet are considered like responses and are annotated in the same way.,"to let the annotator know, the quoting tweets contain an extract of the quoted text, as shown in the second tweet in Figure 2.",contrasting
369,dev_369,We could argue that the addition of the ignore class is thus not very useful since increasing the number of classes is likely to decrease the inter-rater agreement.,certain annotators reported less frustration when having the possibility to use the ignore class.,contrasting
370,dev_370,"We observe that for Captions, where we transfer a factual (neutral) to romantic/humorous sentence, the add- tagger provides the best accuracy with a relatively negligible drop in BLEU scores.","for Yelp, where both polarities are clearly defined, the replace-tagger gives the best performance.",contrasting
371,dev_371,"For example, Lakshmi Narayan et al. (2019) applied noise injection and word dropout and obtained a performance boost, Bodapati et al. (2019) varied the capitalization of words to increase the robustness to capitalization errors, Liu et al. (2019) augmented traditional models with pretraining on external knowledge bases.",our work can be viewed as data augmentation in the continuous hidden space without external resources.,contrasting
372,dev_372,"To fight against miscalibration, a natural option is to apply a calibration method such as temperature scaling (Guo et al., 2017) in a post-processing step.","temperature scaling only learns a single parameter to rescale all the logits, which is not flexible and insufficient.",contrasting
373,dev_373,"A third option is to use Bayesian neural networks (Blundell et al., 2015;Louizos and Welling, 2017), which treat model parameters as probability distributions to represent model uncertainty explicitly.","these Bayesian approaches are often prohibitive, as the priors of the model parameters are difficult to specify, and exact inference is intractable, which can also lead to unreliable uncertainty estimates.",contrasting
374,dev_374,They first train multiple models with different initializations and then average their predictions.,fine-tuning multiple language models requires extremely intensive computing resources.,contrasting
375,dev_375,"Kumar et al. (2018) propose a differentiable surrogate for the expected calibration error, called maximum mean calibration error (MMCE), using kernel embedding.",such a kernel embedding method is computationally expensive and not scalable to the large pre-trained language models.,contrasting
376,dev_376,"In an attempt to set the ground for more comparable research in the area, a standard for dialog act annotation was developed (Bunt et al., 2012;Bunt et al., 2017).","annotating dialogs according to this standard is an exhaustive process, especially since the annotation does not consist of a single label, which in the standard nomenclature is called a communicative function, but rather of a complex structure which includes information regarding the semantic dimension of the dialog act and relations with other segments, among others.",contrasting
377,dev_377,Such methods/metrics solely optimize/reward similarity with human-generated reference questions treated as the ground truth (GT).,"in many openended generation tasks where only one or a few of many possible GTs are available through human annotation, this approach directly penalizes diversity by discouraging deviation from the GT(s).",contrasting
378,dev_378,"A common practice, as seen in Vaswani et al. (2017)’s setup, is to jointly learn BPE for both source and target languages, which facilitates three-way weight sharing between the encoder’s input, the decoder’s input, and the output (i.e. classifier’s class) embeddings (Press and Wolf, 2017).","to facilitate fine-grained analysis of vocabulary sizes and their effect on class imbalance, our models separately learn source and target vocabularies; weight sharing between the encoder's  combined in Figure 4.",contrasting
379,dev_379,"While Sperber et al. (2019) use a beam of size 1 for the ASR component of their cascade to compare with their two-stage end-to end models, we find that using equal beam sizes of 15 for both ASR and MT improves cascaded performance with the same model by 4-8 BLEU; combining these two parameter changes makes the same cascaded model a much more competitive baseline (compare lines 3 in both Table 2 and Table 3).",widening beam size to yield an equivalent search space for end-to-end models has diminishing returns after a certain point; we did not see further benefits with a larger beam (> 15).,contrasting
380,dev_380,"Their model provides considerable training and decoding time improvements due to the reduced source sequence length, and shows consistent improvements over the baseline end-to-end model using the original filterbank feature sequences which increase with the amount of training data.",their model has lower overall performance and with much smaller performance improvements over our baselines in lower-resource conditions than the phone featured models we propose here.,contrasting
381,dev_381,"Many impressive progresses have been made in neural machine translation (NMT) in the past few years (Luong et al., 2015; Gehring et al., 2017; Vaswani et al., 2017; Wu et al., 2019).",the general training procedure requires tremendous amounts of high-quality parallel corpus to achieve a deep model's full potential.,contrasting
382,dev_382,We use our proposed method to evaluate 21 models submitted to the Spider leader board and manually verify that our method is always correct on 100 examples.,"the current Spider metric leads to a 2.5% false negative rate on average and 8.1% in the worst case, indicating that test suite accuracy is needed.",contrasting
383,dev_383,It improves over exact string matching by preventing false negatives due to semantically equivalent clause reordering.,it is still considered a strict metric and creates false negatives.,contrasting
384,dev_384,"By SQL style conventions, ""LIKE"" usually precedes a value of the form ""%[name]%"" and corresponds to natural language query ""contains [name]"" rather than ""matches [name]""; it seems plausible that the model does not understand the natural language query.","if we replace the wrong value ""%[name]%"" with the gold value ""[name]"" after the ""LIKE"" operator, the predicate becomes semantically equivalent to ""= [value]"" and hence makes the query semantically correct.",contrasting
385,dev_385,"Compared with the previous two approaches, a language model, trained on an enormous amount of text, can naturally capture coherence among both words and utterances.","a good evaluation metric should not only measure the quality of gen-eration, but also the diversity of generation, which is especially important for open-ended tasks like dialogue or story generation (Hashimoto et al., 2019).",contrasting
386,dev_386,This paper provides a holistic and automatic evaluation method for open-domain dialogue models.,"to prior art, our means of evaluation captures not only the quality of generation, but also the diversity and logical consistency of responses.",contrasting
387,dev_387,"Thus, we need articles written about entities for which we can identify the gender information.",to obtain gender information for existing annotated datasets could be costly or impossible.,contrasting
388,dev_388,"Since we obtain the distantly supervised sentences for a relation from the head entity's article, this guarantees the model will not reuse sentences from an article.",it is possible that the head entity will appear as a tail entity in other relations because an entity could appear in multiple articles.,contrasting
389,dev_389,They learn a vocabulary of edit operations from training data and thus can work for any language.,their performance is inferior to their seq2seq counterpart.,contrasting
390,dev_390,"Each tweet was labelled by 3 human annotators using five classes: positive, negative, neutral, mixed, and unknown.","the authors published not the full-text of the tweets, but the IDs of the annotated tweets.",contrasting
391,dev_391,"Improvements have been obtained by exploiting either more sophisticated spaces (e.g., going from Euclidean to complex or hyperbolic space) or more sophisticated operations (e.g., from translations to isometries, or to learning graph neural networks).",our approach takes a step forward in both directions.,contrasting
392,dev_392,"The recent QuatE model (Zhang et al., 2019) learns KG embeddings using quaternions.","a downside is that these embeddings require very highdimensional spaces, leading to high memory costs.",contrasting
393,dev_393,"Therefore, topic models explore the word co-occurrence patterns, i.e., semantics.",no Transformer-based model considers these explicit semantics.,contrasting
394,dev_394,"Next, the results in rows 20-23 show that the YouTube metadata features improve the performance when combined with the Twitter followers' features.","the Facebook audience features' performance is deficient and hurts the overall performance, i.e., these estimates seem not to correlate well with the political leanings of news media.",contrasting
395,dev_395,"Intelligent assistants have gained great popularity in recent years since they provide a new way for people to interact with the Internet conversationally (Hoy, 2018).",it is still challenging to answer people's diverse questions effectively.,contrasting
396,dev_396,"In our test set, 87.45% news is satire and the rest of them are misleading news and clickbait.",the dataset we used for the human baseline contains 23% satire news.,contrasting
397,dev_397,"In addition to that, it is also found that the use of punctuations in fake news is more frequent than authentic news, and most of the time fake news is found on the least popular sites.","since character level features have shown better results so we will incorporate the character level features in neural network models such as (Kim et al., 2016;Hwang and Sung, 2017).",contrasting
398,dev_398,We ran experiments including question length and word overlap between the passage and question as calibrator features.,these features did not improve the validation performance of the calibrator.,contrasting
399,dev_399,"In particular, the WebAnno we are using, makes it possible to calculate Kohen's Kappa, Fleiss' Kappa and Krippendorff's Alpha.","in order to do it properly, a tool needs to know all interdependencies among categories of tags.",contrasting
400,dev_400,"In principle, this approach is similar to knowledge-based approaches for word sense disambiguation, especially the classic algorithm Lesk and its extensions (Lesk, 1986;Agirre et al., 2014;Basile et al., 2014), that apply a common strategy to disambiguate any word by referring to sense representations and measuring overlaps between a word context and sense representations.","different from the previous knowledge-based approaches that  directly use sense representations provided by lexicalsemantic resources, we leverage sense-annotated corpus as well in a data-driven manner to learn to build sense representations and learn to measure the overlap between a word context and a sense representation.",contrasting
401,dev_401,We observe that the word-specific classifier model obtains comparable performance when trained with either in-class or outof-the-class verb instances.,"the single-classifier models are able to effectively transfer common syntactic (and semantic) alternation patterns across verbs in the same VerbNet class and, thus, significantly improve the performance when trained on in-class verb instance.",contrasting
402,dev_402,"The main impetus lies in the pre-trained neural language models that capture long-range dependencies among words, owing to multi-head attention that is unique in the architecture.","little is known for how linguistic properties are processed, represented, and utilized for downstream tasks among hundreds of attention heads inside the pre-trained transformerbased model.",contrasting
403,dev_403,"Throughout the entire experiments, we mainly used huggingface’s seven pre-trained transformers2 , implemented with Pytorch.","since the original implemented models do not return the output vectors of the internal attention heads, we developed the wrapper class that enables extracting the output vectors from the created pre-trained model objects.",contrasting
404,dev_404,"In particular, we can see the exact distribution of the predictions of our algorithm for experiment 8 with a confusion matrix (figure 3).","some measures seem to differ, such as those in experiment 2, which are lower than 0.5, or those in experiment 5, which are lower than 0.6, with both experiments taking into account features related to the context of the question (vectorization in the first case and the presence of words belonging to lexicons in the second one).",contrasting
405,dev_405,"This difference in the variation can be observed in the average edit distance between the prompts of each class, which is 3.27 and 2.73 for mined and paraphrased prompts respectively.","the improvement led by ensembling paraphrases is still significant over just using one prompt (Top1 vs. Opti.), raising microaveraged accuracy from 32.7% to 36.2% on BERT-base, and from 37.8% to 40.1% on BERTlarge. ",contrasting
406,dev_406,Theoretical quantities like mutual information might seem appealing in this context given their strong grounding in information theory.,"applying them would potentially require us to fully specify the state space the world can be in for an open-domain conversation, as well as estimating the probability distribution over potential configurations, neither of which is trivial, if feasible.",contrasting
407,dev_407,"During this same year, Spandau Ballet achieved platinum status with the compilation The Singles Collection, which kept the focus on the band between studio albums and celebrated its five years of success.",the album was released by Chrysalis Records without the band's approval and the band instigated legal action against the label.,contrasting
408,dev_408,"In the area of dialogue systems, a number of contributions are concerned with the generation of variety in the utterances of the dialogue system (e.g (Wen et al., 2015; Kozlowski et al., 2003; Langkilde and Knight, 1998)).",those efforts are mainly focused on word-level paraphrases and little work has been dedicated to the generation of contextual paraphrases.,contrasting
409,dev_409,BERT is intended to be pre-trained in the described manner and then fine-tuned to a specific task.,"as our goal is not to solve a specific task, but rather to determine the informational content of a model, we employ the featurebased approach without fine-tuning presented in the original work.",contrasting
410,dev_410,"While neither SNCS nor the machine learning based approaches need time for training if pre-trained encoders are used, the aforementioned flexibility to train a new encoder comes at the cost of additional time needed to perform this training.","during deployment the machine learning based approaches can embed sentences much faster than SNCS, as they merely perform a number of mathematical operations while SNCS needs to search for words in a Semantic Net repeatedly for each sentence pair individually.",contrasting
411,dev_411,"Therefore, we exclude this model from our study of the dialogue act clustering task.","to get an idea of the performance of this model, we add a dialogue act classification task.",contrasting
412,dev_412,"Therefore, existing models provide a solid foundation for research involving contextual paraphrases.",additional work needs to be done to improve the current results and further advance the handling of contextual paraphrases.,contrasting
413,dev_413,"Only very recently, recommending conferences based on authors, abstracts, and keywords became a new research area (Iana et al., 2019).",the authors approach a more general setting that includes conferences from a wide variety of fields.,contrasting
414,dev_414,"In order to make the event and argument classifier shared across modalities, the image and text graph should be encoded to the same space.",it is extremely costly to obtain the parallel text and image event annotation.,contrasting
415,dev_415,"On Robust04, the use of smaller BERT variants always leads to decreasing effectiveness.","when using BERT-Small and BERT-Base for the final re-ranking, the corresponding BERT-QE variants always outperform BERT-Large significantly at the 0.1 level.",contrasting
416,dev_416,Fine Tuning Results so far evaluate the ability of NMT models to integrate similar sentences.,"we have run our comparisons over a ""generic"" model built from a heterogeneous training data set while it is well known that these models do not achieve best performance on homogeneous test sets.",contrasting
417,dev_417,"According to the annotation guidelines of Prop-Bank (Bonial et al., 2010), Experiencer is typically Arg0 in numbered roles.","the numbered role Arg1 is usually assigned to the Patient argument, i.e. “the argument which undergoes the change of state or is being affected by the action”. ",contrasting
418,dev_418,"Due to the alleviation of error propagation and lower latency, the end-to-end ST model has been a hot topic in recent years.","large paired data of source audios and target sentences are required to train such a model, which is not easy to satisfy for most language pairs.",contrasting
419,dev_419," Recently, Wang et al. (2019b) propose to stack an ASR encoder and an MT encoder as a new ST encoder, which incorporates acoustic and linguistic knowledge respectively.",the gap between these two encoders is hard to bridge by simply concatenating the encoders.,contrasting
420,dev_420,They formalize learning strategies from easier networks to more difficult network structures.,we focus on curriculum learning in pre-training and increase the difficulty of pre-training tasks.,contrasting
421,dev_421,This is because the target word prediction task is dictionary-supervised in expanded setting rather than reference-supervised as in base setting.,our method still outperforms the simple pre-training method by a large margin.,contrasting
422,dev_422,This indicates our method can make a good use of ASR corpus and learn valuable linguistic knowledge other than simple acoustic information.,"when additional MT data is used, there is still a gap between the end-to-end method and the cascaded method.",contrasting
423,dev_423,"We also found some examples where both the retrieve-only y 1 and the pre-ranked y were the same, and they were copied verbatim to generate the candidate output.","several of these copied retrieved outputs were too general summaries, and since the source was ignored during generation, the generated candidate output was missing some article specific information present in the target summary.",contrasting
424,dev_424,Transformers have supplanted recurrent models in a large number of NLP tasks.,the differences in their abilities to model different syntactic properties remain largely unknown.,contrasting
425,dev_425,"For models with positional encoding, the lack of the ability to generalize to higher lengths could be attributed to the fact that the model has never been trained on some of the positional encodings that it receives at test time.",the model without any explicit form of positional encoding is less susceptible to such issues if it is capable of performing the task and was found to generalize well across various hyperparameter settings.,contrasting
426,dev_426,"At the same time, it is easy to show that if cos(nπ), which has a period of two is used as positional encoding, the self-attention mechanism can easily achieve the task which we also observe when we empirically evaluated with such an encoding.","the same encoding would not work for a language such as (aaaa) * , which has a periodicity of four.",contrasting
427,dev_427,"Prior work studied learning from human provided rationales (Lei et al., 2016; Ross et al., 2017; Bao et al., 2018; Ghaeini et al., 2019) in order to improve model explainability.",human rationales are expensive to acquire.,contrasting
428,dev_428,"Comparing correlation values for H and L in Tab3, we observe that when the models are making correct and confident predictions (H), the values of correlation tend to be higher.","when the model fails to detect the correct relation (L), we see substantially lower correlation scores.",contrasting
429,dev_429,"In practice, this method produces significant speedups at both training and inference time (by selecting a small subset of columns and performing matrix multiplications given much smaller matrices).","it is reported to achieve lower performance compared to unstructured pruning (Yao et al., 2019) due to more restrictive sparse patterns",contrasting
430,dev_430,Previous sections illustrate the potential external supervision by assuming the existence of vokens.,we are currently lacking the dense annotations from tokens to images.,contrasting
431,dev_431,The vision-language module represents the interactions between the image and the question.,"this module alone is not able to answer questions that require insights that are neither in the image, nor in the question.",contrasting
432,dev_432,Document-level relation extraction requires integrating information within and across multiple sentences of a document and capturing complex interactions between inter-sentence entities.,effective aggregation of relevant information in the document remains a challenging research question.,contrasting
433,dev_433,"There are also feature-based approaches achieving good results by optimizing sentence selection under a summary length constraint (Feigenblat et al., 2017).","to previous work, our proposal does not simultaneously perform segment selection and query matching.",contrasting
434,dev_434,"It is known that for the language modeling validation perplexity measures using teacher forcing is not the best evaluation of generative capabilities, even if there is correlation between the two.","it is a commonly used metric for language modeling, and can be parallelized and computed inexpensively without the need for autoregressive sampling of output text.",contrasting
435,dev_435,"Alternatively, GCC-DEC (355M) adheres more closely to the references instead of the prior conversation context, thus resulting in higher style match for longer conversations.",this over-adherance to the conversation style does seem to impact conversation quality for longer conversations.,contrasting
436,dev_436,"Concurrent work has shown the value of leveraging large amounts of Reddit data to harvest naturally occurring conversations for the purposes of downstream conversational tasks (Zhang et al., 2019).","this work does not address the issue of stylistic control or the effects of scaling models to large sizes, which are central themes of our work.",contrasting
437,dev_437,"Previous work has cast a few traditional NLP tasks as question answering, such as textual entailment (McCann et al., 2018), entity-relation extraction (Li et al., 2019), and coreference resolution (Wu et al., 2020).","unlike these tasks, we do not have large scale training datasets for bridging.",contrasting
438,dev_438,"Looking at the results on ISNotes, we find that BARQA trained on a small number of in-domain dataset (BASHI) achieves an accuracy of 38.16% on ISNotes, which is better than the model trained on the other two large-scale datasets (SQuAD 1.1 and QuasiBridging).","when using these two datasets to pre-train the model then fine-tuning it with the small in-domain dataset (BASHI), both settings (i.e., SQuAD 1.1 + BASHI and QuasiBridging + BASHI) achieve better results compared to using BASHI as the only training dataset.",contrasting
439,dev_439,"Particularly, we notice that the performance of using QuasiBridging alone is worse than the one using SQuAD 1.1 only.","combining Qua-siBridging and BASHI achieves the best result on ISNotes, with an accuracy of 47.21%.",contrasting
440,dev_440,"To this end, (Satyapanich et al., 2020) recently presents the first dataset for cybersecurity ED (called CASIE) that annotates event instances with rich annotation.",this dataset involves at least three limitations that hinder future research in this area.,contrasting
441,dev_441,"Prior work has applied NLP to perform several tasks for the cybersecurity domain, including privacy policy analysis (Peng et al., 2012; Pandita et al., 2013; Zhu and Dumitras, 2016), text analysis for cybersecurity with social media text (i.e., DDos attack detection, alert generation for threads and vulnerabilities using Twitter) (Mittal et al., 2016; Wang and Zhang, 2017; Sceller et al., 2017; Chambers et al., 2018; Perera et al., 2018; Alguliyev et al., 2019; Hasan et al., 2019), and report and timeline creation of cybersecurity events (Hackmageddon, 2019; PrivacyRight, 2019).",none of these work considers the detection of event trigger words from cybersecurity articles as we do.,contrasting
442,dev_442,"(Hu et al., 2019) adopts a heuristic algorithm a length penalty to avoid overlong targets.",the length penalty make the model be incline to ignore target phrases.,contrasting
443,dev_443,"Compared to (Zhou et al., 2019), the extraction method proposed by (Hu et al., 2019) has solved the problem of huge search space better and achieve better results.",there are still some issues with it.,contrasting
444,dev_444,"Take the example 4 in the table as an example, the correct extracted target should be ""chili signed food items"", but SPANpipeline split the gold target entity to two separate targets because of its length penalty.","our algorithm can extract the target ""chili signed food items"" correctly since we get the original candidates with the closest indexes and then extract the targets by the extending strategy.",contrasting
445,dev_445,"Modeling temporal user context, either as a bagof-tweets (Gaur et al., 2019), or sequentially (Cao et al., 2019;Matero et al., 2019) helps in identifying suicidal intent.","in Figure 1, we show that the impact of varying time intervals between tweets is crucial for an accurate assessment.",contrasting
446,dev_446,The parsing speed of the A* parser differs dramatically for the different graphbanks.,the parsing speed with the transition systems is less sensitive to the graphbank and faster overall.,contrasting
447,dev_447,"To allow the Transformer to utilize the order information of source code tokens, we train an embedding matrix W Pe that learns to encode tokens' absolute positions into vectors of dimension dmodel .",we show that capturing the order of code tokens is not helpful to learn source code representations and leads to poor summarization performance (§ 3.2).,contrasting
448,dev_448,"Similar to our approach, they use tables extracted from LATEX sources.",they do not extract absolute metric values but rank papers and do not appear to utilise the text content of publications.,contrasting
449,dev_449,"Evert (2004) uses the dataset of 21,796 German PP-verb combinations (German_PNV_Krenn) in his experiments, manually annotated as lexical collocations or non-collocations by Brigitte Krenn (Krenn, 2000).","evert (2004) emphasizes that it is not possible to generalize the results of experiments on verbal collocations to other types of collocations, i.e. with different syntactic relations.",contrasting
450,dev_450,Consider the adjective tief 'deep': its prototypical sense is 'reaching from top to bottom'.,in the phrase tiefe Liebe 'deep love' the adjective is not used in its basic meaning and means 'intense'.,contrasting
451,dev_451,"For example, the adjective holzern has only two senses: the prototypical one 'wooden' which belongs to the domain of concrete concepts and the non-prototypical abstract one 'awkward', and both annotators correctly identified one case of the non-prototypical usage in holzerner Dialog 'awkward dialog'.",all the senses of the adjective historisch 'historical' are very abstract and the interpretation of each adjective-noun pair is highly subjective which reflects in the agreement of only 66%.,contrasting
452,dev_452,"In contrast, we generate a single unbiased reference translation generated by humans instead of trying to cover a wider space of possible translations.","to human paraphrasing (our instructions asked for most diverse paraphrases), automatic paraphrasing are still far from perfect (Roy and Grangier, 2019) and mostly generate local changes that do not steer away from biases as e.g. introducing different sentence structures",contrasting
453,dev_453,We acquire 3 ratings per sentence and take the average as the final sentence score.,"to WMT, we do not normalize the scores, and report the average absolute ratings.",contrasting
454,dev_454,"All references generated with human translations (WMT, HQ(R) and HQ(all 4)) show negative correlation with human ratings for these extreme cases and produce the wrong order.",all references that rely purely on paraphrased references do produce the correct ranking of these three systems.,contrasting
455,dev_455,"Big Data research enables computer-assisted, broadbased generalizations over rich datasets, which cannot be obtained through traditional methods of observation.","these generalizations often come with partially or completely untested assumptions about the irrelevance of potential noise in the data, the nature of which may influence results in ways which remain elusive to the researcher.",contrasting
456,dev_456,"Supervised approaches have made great achievements in the slot filling task (Goo et al., 2018; Zhang et al., 2019), where substantial labeled training samples are needed.",collecting large numbers of training samples is not only expensive but also time-consuming.,contrasting
457,dev_457,"Because it did not outperform BERT-base in our cross-validation based development setting, we did not further experiment with BERT-large.",we found that it resulted in the best F1-score achieved on our test set.,contrasting
458,dev_458,Table 5 shows that our unsupervised model achieves consistent performance in both Switchboard and the three cross-domain datas.,"to the performance on the Switchboard dev set as shown in Table 3, our unsupervised model achieves performance similar to the ELECTRA-Base fine-tuning model.",contrasting
459,dev_459,The joint models can capture long-range dependency of disfluencies as well as chunk-level information.,training a parsing-based model requires large annotated tree-banks that contain both disfluencies and syntactic structures.,contrasting
460,dev_460,"In most previous works, human annotators are asked to compose new sentences for the given sentences to make examples in some previous works.","such artificial sentences lead hidden biases, because annotators unconsciously use particular words.",contrasting
461,dev_461,"In reasoning annotation, we focused only on nonentailment examples to exclude false entailment.",false entailment examples may exist.,contrasting
462,dev_462,Many studies have used the DS approach to expand target relations and reduce the cost of constructing handcrafted training data.,a statistical analysis of the DS data from Wikipedia-DBpedia collected in this study was found to contain 49% noise.,contrasting
463,dev_463,"As far as we know, Amazon Mechanical Turk and Crowdflower are widely used in English.","there is not a Korean related work there, and it is not easy to gather Korean worker.",contrasting
464,dev_464,"The results obtained, with an F score of 73.35, suggest that the methods that have been previously proposed for English are transferable to Spanish.",a question that remains open is whether the methodology used is optimal for Spanish.,contrasting
465,dev_465,Everything indicates that the system seems to be extending the scope to the final punctuation mark.,"there are also some errors due to the system shortening the scope, as in Ex. (21), where the second element of the coordinated adjectival phrase is not included, or Ex. (22) where the complement of the noun cable is not included.",contrasting
466,dev_466,The results of the system indicate that the methods used for English are transferable to Spanish.,a qualitative error analysis has shown that the methods applied are not optimal.,contrasting
467,dev_467,"Candidates in MOCHA come from existing models, so that a metric learned on this data will be most applicable to current research.","as research in generative reading comprehension models is presently limited, the strength of these models can be low.",contrasting
468,dev_468,"The second cateogry of metrics eschew some of the aforementioned issues by calculating a softer similarity score using embeddings of tokens (Clark et al., 2019b; Zhang et al., 2019).","it is unclear how to tailor them to question answering, where the passage and question should be assimilated.",contrasting
469,dev_469,Machine learning models such as deep neural networks have achieved remarkable performance in many NLP tasks.,"as noticed by recent studies, these models often inherit and amplify the biases in the datasets used to train the models (Zhao et al., 2017;Bolukbasi et al., 2016;Caliskan et al., 2017;Zhou et al., 2019;Manzini et al., 2019;Blodgett et al., 2020).",contrasting
470,dev_470,This gap is only marginally larger than the performance gap of 2.4% when evaluating the model on two randomly split groups.,"if we evaluate the performance gap on the sentences containing the token ""racist"", the performance gap between these two groups is as large as 19%.",contrasting
471,dev_471,Incorporating sentence functions into conversations has shown improvements in the quality of generated responses.,the number of utterances for different types of fine-grained sentence functions is extremely imbalanced.,contrasting
472,dev_472,"Considering all query and response sentence functions, we could have 20 × 20 = 400 meta tasks.",some tasks are extremely low-resource with less than 100 samples.,contrasting
473,dev_473,"With fine-tuning on responses of the target sentence function, MTL+FT can capture the correct response pattern in some cases.","it is inferior to our proposed models MAML and SML, which can not only generate words related to the target sentence function but also keep the coherence and informativeness of responses.",contrasting
474,dev_474,"Seq2Seq models have been used to generate agent responses without the need for intermediate dialog components such as the DST or the Natural Language Generator (Gangadharaiah et al., 2018).",there has not been much work that uses deeper knowledge of semantic representations in task-oriented dialog.,contrasting
475,dev_475,"Thus, low human performances in this task would support the validity of our corpus.",this validation procedure will provide a precise baseline against which the automated classification model performances may be compared.,contrasting
476,dev_476,"Prior work has combined these three scores into a single number using geometric averaging (Xu et al., 2018) or learned weights (Pang and Gimpel, 2019).","the aggregation is computed after averaging each metric independently across the test set (corpus-level aggregation), which is problematic since systems might generate sentences that optimize only a subset of metrics.",contrasting
477,dev_477,"In the proposed method, the model learned with only images achieved the highest precision, but that learned with texts using BERT in addition to the images achieved the highest recall and F1.",the result of the model using LSTM was even worse than that trained with only images.,contrasting
478,dev_478,"At the beginning, when the segmentation prediction network performs poorly, the model pools over only ground truth segment bounds, allowing it to learn the cleanest topic representations.","as training progresses and the segmentation accuracy begins to converge, we switch from pooling over ground truth segments to aligning predicted and ground truth segment.",contrasting
479,dev_479,"Indeed, several works (Zheng et al., 2017; Luan et al., 2019; Wadden et al., 2019) use the Boundaries setting to compare to previous Strict results.","because the Strict setting is more restrictive, this leads to overestimating the benefit of the proposed model over previous SOTA.",contrasting
480,dev_480,"In terms of modeling, their approaches used regular BERT as their encoders, where the argument representations are not explicitly conditioned on triggers.","our encoder is enhanced by providing more trigger-oriented information and BERT is only used as one part of it, which results in a trigger-aware sequence encoder.",contrasting
481,dev_481,"Moreover, Gharouit and Nfaoui (2017) suggest to use BabelNet as knowledge base in the detection of verbose queries and then present a comparative study between different algorithms to classify queries into two classes, verbose or succinct.",both papers deal with the classification of queries submitted to search engines.,contrasting
482,dev_482,"There, it has been quite hard for the annotators to distinguish between different levels of directness so that the class distribution of the directness is sub-optimal for the classification task.",comparing the results to a majority-class classifier clearly shows that there is still a lot of information encoded in the DA feature set achieving higher UAR.,contrasting
483,dev_483,"For the classification of the 3-class elaborateness and the 3-class directness, the RNN classifier yields worse results than the ANN classifier.","for the estimation of the binary directness, the RNN classifier outperforms the ANN classifier, reaching an UAR of 78 % when using linguistic features encoded as word embeddings in combination with grammatical and dialogue act features (WE+DA+G).",contrasting
484,dev_484,"A very few works try structured weight pruning, e.g., Wang et al. (2019) proposes a structured pruning approach based on low-rank factorization and augmented Lagrangian L0 norm regularization.",there also exist works that prune a coherent set of sub-modules in the Transformer model.,contrasting
485,dev_485,"Analogously, intimacy in language can also be constructed with intentional pragmatic choices to signal the perceived intimacy between speakers.","while psychologists have deeply explored people's behavior of self-disclosure (Cozby, 1973) as one of the major components of verbal intimacy (Fitzpatrick, 1987), intimacy in language is not just conveyed by the degree of self-disclosure.",contrasting
486,dev_486,"Societal views of gender roles significantly constrain the use of intimate communication, with specific expectations not only of the individual on the basis of their gender (Caltabiano and Smithson, 1983) but dyadic effects depending on the gender identities present .","individuals are less adherent to these norms as they perceive themselves to be anonymous or when interacting with an individual whom they perceive they will not interact with again (Rubin, 1983; Wynne and Wynne, 1986; Dindia et al., 1997); without the potential loss of face or social capital in such circumstances, individuals are more likely to engage in more intimate communication.",contrasting
487,dev_487,"Individuals in these encounters have little likelihood of future interactions, removing the consequences for violating intimacy norms around increased disclosure (Thibaut, 2017; Wynne and Wynne, 1986).","to both friends and strangers, individuals are least intimate with casual acquaintances for which there are some expectations of potential future interaction and, therefore, longer-term consequences for norm violations.",contrasting
488,dev_488,"The topic model baseline is still able to attain moderate performance, matching the intuition that some topics are more intimate (e.g., romance) while others are less (e.g., mobile phones).","as shown in Appendix J, Figure 8, many topics span the range of intimacies, demonstrating that estimating intimacy from topic alone is insufficient.",contrasting
489,dev_489,"Bohm et al. (2019) train a BERT-based evaluation function with 2,500 human ratings for 500 machinegenerated summaries from the CNN/DailyMail dataset; their method correlates better with human ratings than ROUGE and BLEU.","as their method is designed for evaluating single-document summaries, it correlates poorly with the Pyramid scores for multi-document summaries (see Â§3).",contrasting
490,dev_490,Lugosch et al. (2019) propose a pretraining method for end-to-end spoken command recognition that relies on the availability of transcribed data.,"while this pretraining strategy brings improvement over a system trained without transcripts, the absence of any other text-based baseline (such as a pipeline system) prevents any conclusion on the advantage of the end-to-end training when textual supervision is available.",contrasting
491,dev_491,"Harwath et al. (2018) focus on speech, exploring how spoken captions in two languages can be used simultaneously to improve performance in an English-Hindi parallel subset of the Places-205 dataset (Zhou et al., 2014).",our experiments concern the setting where speech data from a low-resource language is used in conjunction with corresponding translated written captions.,contrasting
492,dev_492,"For example, in the second bag {cat, on, the}, if looking only locally, we may pick ""the"" as the left neighbor of ""cat"".","if we notice that there is another determiner ""a"" in the first bag, then ""the"" will not be the only choice.",contrasting
493,dev_493,"For example, BlockBERT with sequence length N = 512 and 2 blocks is trained with ten heads using permutation (1, 2) and the other two using permutation (2, 1).","there are other ways to assign twelve attention heads, e.g., seven heads for permutation (1, 2) and the other five for permutation (2, 1).",contrasting
494,dev_494,"Automatic recognition of humor has become an important task in the area of figurative language processing, which can benefit various downstream NLP applications such as dialogue systems, sentiment analysis, and machine translation (Melby and Warner, 1995; Augello et al., 2008; Ghosh et al., 2015; Bertero and Fung, 2016; Blinov et al., 2019).",humor is one of the most complicated behaviors in natural language semantics and sometimes it is even difficult for humans to interpret.,contrasting
495,dev_495,"The two meanings of the same expression are consistent with its context, which creates a humorous pun in both sentences when there is a clear contrast between two meanings.",heterographic puns take advantage of phonologically same or similar words.,contrasting
496,dev_496,"Especially in the pun detection task, we observe that our model requires longer contexts (more than 20 words) to detect the homographic puns.","shorter contexts (less than 10 words) are adequate for heterographic pun detection, which indicates the contribution from phonological features.",contrasting
497,dev_497,"Due to daily usage, participants stated they were strongly biased regarding mouse and keyboard, where ""the muscle memory"" helps.","many actually considered MK as very unintuitive if they imagined never having used it before, especially compared to pen and touch, or as one participant stated for reordering: ""why do I have to do all of this, why is it not as simple as the pen"".",contrasting
498,dev_498,"We note that by combining sentence, paragraph and token index in the corpus, whole sentences can be reconstructed.","from 5,000 tokens roughly 300 sentences could be reconstructed, which are far too few to be used for training a neural model.",contrasting
499,dev_499,Different plot types have different slots.,some slots are shared across plot types.,contrasting
500,dev_500,None of the models above does consider the scores from the base parser when ranking trees.,"it seems plausible to try combining the advantages from both models, base parser and reranker, to produce a better final model.",reasoning
501,dev_501,NER systems are often trained on the clean text.,"they exhibit degraded performance in real-world scenarios where the transcriptions are produced by the previous upstream component, such as OCR or ASR ( §2.2), which results in a detrimental mismatch between the training and the test conditions.",reasoning
502,dev_502,Top-k in particular creates text that is easy for machines to detect but very hard for humans.,"we observe the general trend: as the number of unlikely words available to be chosen is increased, humans get better at detecting fakes while automatic systems get worse.",reasoning
503,dev_503,"Third, there is no explicit rating of news articles posted by users on news platforms.","in news recommendation users' interest in news is usually inferred from their click behaviors in an implicit way (Ilievski and Roy, 2013).",reasoning
504,dev_504,"Third, news recommendation can be formulated as a special text matching problem, i.e., the matching between a candidate news article and a set of previously clicked news articles in some news reading interest space.","news recommendation has attracted increasing attentions from the NLP community (An et al., 2019; Wu et al., 2019c).",reasoning
505,dev_505,Other entities are found related to the surface forms of pay (Pay television) and ride (List of amusement rides).,"it is expected that the activation values related to amusement rides and the company are lower than the activation values related to payments and Amazon, making the second text more conceptually complex than the first one.",reasoning
506,dev_506,"Since the goal of the dialogue is given in advance for the task-oriented dialogue, we hardly find the chit-chat logs that are compatible with the goal on the Internet nor in the existing texts.",individual environments were set up according to the goal for collecting dialogue data in the past.,reasoning
507,dev_507,Minecraft provides a framework for chatting in a virtual world.,"as a by-product, we obtain an environment for the situated dialogue where dialogue participants need to consider more diverse contextual information than the text-based dialogue, e.g. spatial relations, deictic reference and gesture.",reasoning
508,dev_508,"Measuring the dynamics of gestures (Byrd, 1994;Mooshammer et.al., 2012) it became evident, that articulatory gestures are related to the positions (onset, vowel, coda) within a syllable.",it is concluded that the activity of the neuronal network steering the articulators is related to the structure of a syllable.,reasoning
509,dev_509,The advent of deep learning has greatly improved the performances of natural language processing (NLP) models.,"the models are becoming more complex (Yang et al., 2019; Liu et al., 2019), rendering it difficult to understand the rationale behind their predictions.",reasoning
510,dev_510,"As MLM is trained by masking only a part of the input sentence, replacing too many tokens can degrade its modeling performance.","we calculate the AUC until 20% of the tokens are replaced, and refer to it as AUC rep .",reasoning
511,dev_511,We selected 200 direct objects as W c from the most frequent 250 direct objects and the other 50 direct objects as w t for each verb.,"the number of tasks N was 50,000, i.e., 50 tasks for each of the 1,000 verbs.",reasoning
512,dev_512,"Target Identification To detect the targets of the claim (T c ) and topic (T t ), we assume that T c is semantically related to the topic, or more specifically, to T t .",we identify T c and T t simultaneously by following three strategies.,reasoning
513,dev_513,"In the provided example in the table, one can see that the modifier terrorist dominates the sentiment of the positive word haven.",both terrorist haven and terrorist attack are considered generally bad.,reasoning
514,dev_514,"Mainly, its good performance on the claims that refer to consequences reinforces our intuition that designing systems tailored for particular argumentation schemes might be a good alternative to topic-specific models.",we plan to complement this work with approaches for other frequently applied schemes such as arguments by expert opinion and arguments by example.,reasoning
515,dev_515,"Intuitively, such disagreements among humans should be allowed because different annotators might have different subjective views of the world and might think differently when they encounter the same reasoning task.","from a descriptive perspective, evaluating the capacity of NLP models in predicting not only individual human opinions or the majority human opinion, but also the overall distribution over human judgments provides a more representative comparison between model capabilities and 'collective' human intelligence.",reasoning
516,dev_516,"Thus, from a descriptive perspective, evaluating the capacity of NLP models in predicting not only individual human opinions or the majority human opinion, but also the overall distribution over human judgments provides a more representative comparison between model capabilities and 'collective' human intelligence.","we collect ChaosNLI, a large set of Collective HumAn OpinionS for examples in several existing (English) NLI datasets, and comprehensively examine the factor of human agreement (measured by the entropy of the distribution over human annotations) on the state-of-the-art model performances.",reasoning
517,dev_517,"We identify several weaknesses: beam search can only find local optima, and a genuine parallel sentence cannot be recovered once it is pruned.",the method is vulnerable when parallel sentences have different word ordering.,reasoning
518,dev_518,"By constraining on a target side trie during decoding, beam search can approximate pairwise comparison between source and target sentences.",overall we present an interesting way of finding parallel sentences through trie-constrained decoding.,reasoning
519,dev_519,"This is because the document encoder, SpanBERT, dominates the memory usage during inference (as also observed by Xia et al., 2020).",the peak memory usage during inference is determined by the mention proposal stage rather than the mention clustering stage.,reasoning
520,dev_520,"However, there is no chain between the first supporting fact and the second supporting fact due to the lack of the external knowledge that can connect ""Coker"", ""coach"" and ""Miami Hurricanes football team"".",the isolated reasoning chain leads to a wrong answer.,reasoning
521,dev_521,There are cases in which not all types of negation have been considered or they have only partially been taken into account.,"when merging the corpora it is very important to take into consideration the types of negations (syntactic, morphological, lexical) and merge only those corpora completely annotated with the same types to avoid the system being trained with false negatives.",reasoning
522,dev_522,"The overall size of the released data (600 training questions) is in line with real-world scenarios, where the high cost of domain expert time limits the amount of quality data that can reasonably be collected.","the dataset is meant to stimulate research in domain adaptation, in addition to developing algorithms for longer questions and answers than the current leaderboards.",reasoning
523,dev_523,This means that all SOTA Sup and UnSup approaches can be considered as a module that operates on the feed-in parameter Q.,"we propose two different strategies for semi-supervision that emphasize the two-way interaction between the supervised signal and unsupervised alignment based on the message passing mechanisms, see Figure 1.",reasoning
524,dev_524,"Several pre-trained visually grounded models have been proposed recently, and they are conceptually similar yet vary in design details, making evaluating them complicated and difficult.","for simplicity, we propose a simple and performant baseline, VisualBERT (see Figure 2), and base our analysis on this model.",reasoning
525,dev_525,We would like to adopt a similar training procedure as BERT but VisualBERT must learn to accommodate both language and visual input.,"we reach to a resource of paired data: COCO (Chen et al., 2015) that contains images each paired with 5 independent captions.",reasoning
526,dev_526,"As such, drift detection is treated as sequence segmentation task, and the better segmentations, the higher the overall accuracy.","experiment results of our model and all baselines are compared with the same metric, i.e., overall accuracy.",reasoning
527,dev_527,There is no guarantee that these questions need to aggregate heterogeneous information to find the answer.,"designing hybrid question answering systems would probably yield marginal benefits over the non-hybrid ones, which greatly hinders the research development in building hybrid question answering systems.",reasoning
528,dev_528,"However, directly maximizing the marginal likelihood is unnecessarily complicated as the marginalization leads to huge computation cost.",we propose to train the three models independently and then combine them to do inference.,reasoning
529,dev_529,Note that both common functional words and rare specific concepts in Chinese are commonly composed of multiple characters.,"the contrast between common and rare characters is not so obvious, which leads to small α (no overwhelmingly functional words in syntax) and huge  β + γnorm (extremely analytic in morphology).",reasoning
530,dev_530,"As described in section 2, GTM is an extension to W-LDA with the main difference that GTM models topics in a larger context and incorporates more global information with the graph encoder.",the improvements of GTM over W-LDA indicate the effectiveness of such information for topic modeling.,reasoning
531,dev_531,"Wilkes-Gibbs and Clark (1992) indicated that when people collaborate on referring expressions, they issue full noun phrases initially, after which they begin to shorten the phrases.","in the process of repair, one could say ""Give me the T8 Torx screwdriver"", and then ""Give me the screwdriver"", or just ""next one"".",reasoning
532,dev_532,"Here, however, we are interested in knowing the tools that are needed for each step of the task.",we utilize the toolbox provided by the instructors as a gazetteer 3 and search for the complete and/or partial mention of tools in the text.,reasoning
533,dev_533,Information extraction from instructional text is often performed by driving a dense representation of meanings from every sentence of the instructions.,it is assumed that the steps are described with single actions in imperative sentences.,reasoning
534,dev_534,"However, the predicted Y is not guaranteed to meet this requirement, indicating the need for a standardization step.",the overall procedure of generation is divided into two stages: first the algorithm delimits standard edit regions via searching minimal covering rectangles for each connected region; then it manipulates the incomplete utterance based on these standard edit regions to produce the rewritten utterance.,reasoning
535,dev_535,"As mentioned in Section 3, the expected supervision for our model is the word-level edit matrix, but existing datasets only contain rewritten utterances.",we use a procedure to automatically derive (noisy) word-level edit matrices (i.e.,reasoning
536,dev_536,"However, none of automatic metrics reflects the utterance fluency or the improvement on downstream tasks.",human evaluations are included to evaluate the fluency of rewritten utterances and their boost on the downstream task.,reasoning
537,dev_537,"The studies on n-ary facts are relatively scarcer, although they are also ubiquitous in the real world.",this paper addresses knowledge inference on n-ary facts.,reasoning
538,dev_538,"Then, the values of their interaction vector, measuring the compatibility in many different views, are all encouraged to be large.","for each dimension, the minimum over it of all the interaction vectors is not allowed to be too small.",reasoning
539,dev_539,"By differentiating the primary triple from other auxiliary description(s), NeuInfer considers the validity of the primary triple and the compatibility between the primary triple and its auxiliary description(s) to model each n-ary fact more appropriately and reasonably.",it is not surprising that NeuInfer beats the baselines.,reasoning
540,dev_540,It suggests that the validity evaluation component plays a pivotal role in our method.,each component of our method is necessary.,reasoning
541,dev_541,"For each n-ary fact, NeuInfer distinguishes the primary triple from other auxiliary description(s) and models them properly.",neuInfer well handles various types of entity and relation inference concerning the primary triple coupled with any number of its auxiliary description(s).,reasoning
542,dev_542,"Generally, the main consideration of job seekers is the skills they need to master, such as Python, English, and Go Language.","although S2SA generates some right words, like ""preferred"", it does not increase the quality of the generated text because it generates inaccurate skills.",reasoning
543,dev_543,"Moreover, PostKS++ selects a quite different knowledge sen-tence at the 3 rd turn from those at previous turns, which is about the topic History of Australia but not Georgia (U.S. state).",postKS++ generates a response which is not coherent to the previous context at the 3 rd turn.,reasoning
544,dev_544,"We think ""answer-span"" supervision allows the model to track the supporting sentences from simple word matching.",our investigations are focused on evaluating and analyzing the effectiveness of the proposed graph neural network-based model for classifying supporting sentences compared to the well-known answer-selection QA models.,reasoning
545,dev_545,"In many real-world applications, there are multiple dialog types in human-bot conversations (called multi-type dialogs), such as chit-chat, task oriented dialogs, recommendation dialogs, and even question answering (Ram et al., 2018;Wang et al., 2014;Zhou et al., 2018b).",it is crucial to study how to proactively and naturally make conversational recommendation by the bots in the context of multi-type human-bot communication.,reasoning
546,dev_546,"Finally we use some rules to generate a description for each goal (e.g., which side, the seeker or the recommender, to start the dialog, how to complete the goal).",we have task templates for guidance of data annotation.,reasoning
547,dev_547,"Additionally, it is not trivial to train a model for a task in a particular language (e.g., English) and apply it directly to another language where only limited training data is available (i.e., low-resource languages).",it is essential to investigate strategies that allow one to use the large amount of training data available for English for the benefit of other languages.,reasoning
548,dev_548,"For example, some uploaded paragraphs express one's subjective opinions about the movie, the actors, or simply copy the script.",we manually review the data and remove such non-narrative data.,reasoning
549,dev_549,The information that has been expressed is decayed.,the updated narrative focuses more on the remaining information.,reasoning
550,dev_550,This second approach turns out to perform better.,we only report the results with this latter method5 .,reasoning
551,dev_551,"Here, instructions are given from the perspective of a partial field of view (FoV) of the scene, and these FoVs can dynamically be changed.","the correct interpretation of the sequence of instructions will require reasoning about what is currently visible in the FoV (e.g., grounding of objects) but also what is not visible yet.",reasoning
552,dev_552,"Second, unlike other datasets, the target locations in Refer360° are randomly distributed and thus may occur anywhere – not just on predetermined objects.","target locations are less prone to bias (Devlin et al., 2015; Agrawal et al., 2016; Jabri et al., 2016; Goyal et al., 2016; Cirik et al., 2018b).",reasoning
553,dev_553,"Further, real scenes are 3D, but the FoV is represented in 2D in our task.",interpreting some instructions will require inferences about depth.,reasoning
554,dev_554,"To be more specific, when annotators give instructions, they use supporting objects as anchor points to help guide the attention of the follower.",the availability of a rich set of objects is essential for describing the target location.,reasoning
555,dev_555,"First, previous datasets use the entire scene as a single field of view.",there is reduced need to describe how to find the target location sequentially,reasoning
556,dev_556,"Instead of letting annotators decide where to place targets in the scene, we randomly picked a target location in the scene and asked them to describe how to find that loca-tion.",our instruction sequences are complex as we show next.,reasoning
557,dev_557,"For each instruction sequence that was accurately found by another annotator, we paid a bonus of $0.10 to both the annotator who found the location and the annotator who wrote the instruction sequence.",for both the finding and describing task annotators have an interest in performing the task accurately.,reasoning
558,dev_558,Romanization is not necessarily reversible with simple rules due to information loss.,"previous work on romanized machine translation has focused on source-side romanization only (Du and Way, 2017;Wang et al., 2018;Aqlan et al., 2019;Briakou and Carpuat, 2019;Gheini and May, 2019).",reasoning
559,dev_559,"In practice, for a neural translation model in OpenNMT (Klein et al., 2017), the word embedding parameters accout for 80% of the total parameters.",it is significant to reduce the parameters of the embedding layer for deploying NLP models to memory-constrained devices.,reasoning
560,dev_560,Different KGs are usually extracted from separate data sources or contributed by people with different expertise.,"it is natural for these KGs to constitute complementary knowledge of the world that can be expressed in different languages, structures and levels of specificity (Lehmann et al., 2015;Speer et al., 2017).",reasoning
561,dev_561,"However, the characters in these tokens are probably very informative (for example ""http"" in a token would signal that the token is a URL).","fastText, which uses n-grams from a token to compute embeddings, would emit more meaningful representations.",reasoning
562,dev_562,"In this setting, multilingual access is governed by the mapping of terms onto their underlying sense descriptions, such that all vectors co-exist in the same semantic space.","for each term we have thus the ""blended"" terminological vector along with those describing all senses associated to that term.",reasoning
563,dev_563,"For example, word embeddings tend to be consistent across language variations (Aldarmaki, Mohan, and Diab 2018), whereas multilingual vector spaces have more difficulty in representing individual words (such as, e.g., homographs with unrelated senses and phrasal verbs) because of their different usage distributions.",using such words in the alignment dictionary may undermine the mapping (Aldarmaki and Diab 2019).,reasoning
564,dev_564,"As mentioned by Amsili and Seminck (2017), association with arbitrary proper names (e.g., Jane) is irrelevant.","to make our baseline stronger, we sometimes represented a given answer by a word that is not part of this answer but that is syntactically or semantically associated with it in the text.",reasoning
565,dev_565,"Our data collection process also reveals that even in a domain as critically important as medical news, only a small fraction of news articles (24.6%) include a complete citation and a link to the original research.","the presented task has utility in medical factchecking, identifying health-related misinformation, and assessing some empirically verifiable aspects of health news reporting.",reasoning
566,dev_566,"In spite of recent advances, the transformerbased models are large, and using them to compare each query with each document is computationally expensive even for a small corpus.",the two-stage approach remains a prudent choice.,reasoning
567,dev_567,"This challenge is especially acute during public health crises like the current COVID-19 pandemic, due to the extremely fast rate at which new findings are reported and the risks associated with making decisions based on outdated or incomplete information.",there is a need for automated tools to assist researchers and the public in evaluating the veracity of scientific claims.,reasoning
568,dev_568,"We examined the rationales that the SCIFACT-trained model identified but the FEVER-trained model missed, and found that they generally contain sciencespecific vocabulary.",training on additional out-of-domain data provides little benefit.,reasoning
569,dev_569,"Vote-based ideal points, which only model binary values, cannot capture this nuance in his opinion.",sanders' vote-based ideal point is pulled to the right.,reasoning
570,dev_570,"It is known that traditional frequency measures, such as the mean (an estimator of location) and standard deviation (an estimator of scale) are not robust to outliers: a single frequency burst can move them out of bounds.","the field of robust statistic has introduced several robust estimators (Rousseeuw and Croux, 1993).",reasoning
571,dev_571,"Unlike the topical variation, which can be observed from the keywords using an unsupervised approach, non-topical variation in genres is expressed via stylistic features, which are harder to interpret (Biber, 1995).",this requires a supervised approach to determine the genre categories.,reasoning
572,dev_572,"On the contrary, we consider the different task where the questions are single-turn and have no context.",a novel challenge arises in retrieving accurate support sets without conversationbased context information.,reasoning
573,dev_573,The accumulated general knowledge acquired during meta-learning enables the model to generalize over varied tasks instead of fitting the distribution of data points from a single task.,the tasks generated from tiny (less than 1%) portion of the training data are sufficient for meta learner to acquire the general knowledge.,reasoning
574,dev_574,We thus learn a model that can subsequently adapt the initial parameters to each new given question and specialize the adapted parameters to the particular domain of the new questions.,"with the help of the adapted parameters, MRL-CQA can answer each new question more precisely than PG.",reasoning
575,dev_575,"For example, only providing the prediction to medical tasks may not be enough, and providing the associated reasons is more crucial for the practical applications.",there has been increasing attempts that focus on interpretability or explainability of the machine-learned models.,reasoning
576,dev_576,This paper focuses on zero-shot rationalization by transferring knowledge from question answering.,"three datasets are used in the experiments, where a QA dataset, SQuAD 2.0, is utilized for the transfer purpose and two benchmark rationalization datasets, BeerReview and MovieReview, are used for evaluating the performance of zero-shot rationalization for the proposed method.",reasoning
577,dev_577,"Even if LMs satisfy the criteria described in 3.3, there is no exact guarantee that LM scores will reflect the effectiveness of human processing of specific constructions in general.",there seems to be a danger of confusing LM artifacts with language facts.,reasoning
578,dev_578,"However, the overwhelming number of newly-sprung news makes it difficult for users to find their interested content (Wu et al., 2019c).","personalized news recommendation becomes an important technology to online reading experience (IJntema et al., 2010).",reasoning
579,dev_579,"In this way, we directly derive scores of long answers from its paragraph-level representations and obtain scores of short answers from the start and end positions on the token-level representations.",the long and short answer selection tasks can be trained jointly to promote each other.,reasoning
580,dev_580,"Generally speaking, a document can be decomposed to a list of paragraphs, which can be further decomposed to lists of sentences and lists of tokens.","it is straightforward to treat the document structure as a tree, which has four types of nodes, namely token nodes, sentence nodes, paragraph nodes, and a document node.",reasoning
581,dev_581,"The reason is that, for instances with no answer or no apparent answers, fine-grained information is more crucial.","using the score of short answer spans might be more accurate than the long answer score from paragraph nodes, which are coarse-grained.",reasoning
582,dev_582,"To create a large semantic tagging resource for English words, we apply POS-aware Prediction with k = 3 for all words in the vocabulary of the Sketch Engine POS-specific word embeddings.","we obtain semantic tag vectors for 6,143,073 word forms from their English vocabulary.",reasoning
583,dev_583,"It is natural to think that in real scenarios, misspelled words will appear at a much lower rate than in this test.",this result can be seen as a kind of lower-bound estimator for performance on Natural Noise in real scenarios.,reasoning
584,dev_584,"In all the experiments, each model was trained/fine-tuned on the original SQuAD v1.1 training set, and tested on each one of the generated adversarial datasets.","we see that all models are affected by these adversarial samples, but also found that some adversaries are model-specific because they do not affect all models as much as they affect the model they are targeting.",reasoning
585,dev_585,"However, while the sentence-level biLSTM augments sentence representations with the local context, they may be still unaware of the main topic.","we compute element-wise products and differences between the document encoding and a sentence encoding to measure their correlations, and further concatenate the products and differences with the sentence encoding to obtain the final sentence representation that is used for predicting its sentence type.",reasoning
586,dev_586,"In addition, news articles are known to follow inverted pyramid (Bell, 1998) or other commonly used styles where the output labels are not independent.","we also use a linear chain CRF (Lafferty et al., 2001) layer on the output scores of the local classifier to model dependence among discourse labels.",reasoning
587,dev_587,"Loneliness and solitude have also been shown to play a role in the adaptive fitness of our species (Hawkley and Capitanio, 2015;Larson, 1990).",loneliness and solitude are starting to receive substantial amounts of attention from the medical and psychological research.,reasoning
588,dev_588,"A tweet may include the term loneliness, lonely, or solitude and yet may not be relevant to the state of being alone.",we manually examined a small sample of SOLO to determine the percentage of relevant tweets.,reasoning
589,dev_589,"We have shown that by using the search terms loneliness, lonely, and solitude we can collect voluminous corpora of tweets highly related to the state of being alone.","this search strategy over the Twitter stream can be used to monitor the positive and negative aspects of being alone and their relation to well-being over the entire population across time, geographical regions, and demographic groups.",reasoning
590,dev_590,A register sample of the dataset available for public download is shown in Figure 2.,"to form the database, the third section was downloaded from January 1998 to January 2018 into a PDF format and converted to a text format.",reasoning
591,dev_591,Words extracted by the methods described above can contain undesired words whose meanings are far from the target OOV word.,we calculate more accurate similarity scores for the extracted words through a neural network surface encoder.,reasoning
592,dev_592,"A FLEECE merger refers to a process in which what used to be different vowels in words such as meat, meet, piece, peace converged over time, putting all of them in one lexical set, FLEECE, in most varieties of English.","meet and meat will be homophones in the accents that have gone through the FLEECE merger, and a minimal pair in the ac cents that have not.",reasoning
593,dev_593,"PrOnto has been built via standard minimization principles from the ontology engineering literature (Brank et al., 2005;Bandeira et al., 2016).","PrOnto does not truly fit for legal reasoning: PrOnto only defines the main concepts involved in the GDPR and their inter-relations, but it lacks another component necessary for legal reasoning: defeasibility (cf. (Casini et al., 2015))",reasoning
594,dev_594,"For the most part, legal interpretations will be figured out later; in such cases, it is generally the role of jurisprudence to rule out the correct application of the provisions (case law), but in some cases legislation will be amended in order to account for new exceptions.",it seems there is no need to introduce more complex defeasible schema for modeling legislation.,reasoning
595,dev_595,Variables in AMR graphs are only necessary to indicate co-referring nodes and they do not carry any semantic information by themselves.,aMR graphs are first converted into aMR trees by removing variables and duplicating the co-referring nodes.,reasoning
596,dev_596,"There is, however, a drawback of BPE in its deterministic nature: it splits words into unique subword sequences, which means that for each word a model observes only one segmentation.","a model is likely not to reach its full potential in exploiting morphology, learning the compositionality of words and being robust to segmentation errors.",reasoning
597,dev_597,"Since BPE-dropout produces more fine-grained segmentation, sentences segmented with BPEdropout are longer; distribution of sentence lengths are shown in Figure 4 (a) (with p = 0.1, on average about 1.25 times longer).",there is a potential danger that models trained with BPEdropout may tend to use more fine-grained segmentation in inference and hence to slow inference down.,reasoning
598,dev_598,"Taking advantage of the availability of Zahran-WE (Zahran et al., 2015), we evaluated word distribution in the semantic space vs. WE distribution.","in our basic system, we replaced the semantic space vector words by Zahran-WE (from the CBOW and SkipGram models) and calculated the correlation on the AR-ASAG Dataset.",reasoning
599,dev_599,"The comparison between 3 different score thresholds demonstrates the lower the perplexity, the better the generation quality.",the final F1 score becomes higher with the better generated tokens.,reasoning
600,dev_600,"For models with diverse architectures, we expect rationales to be diverse as well and to cause low consistency.","we focus on a set of models with the same architecture, trained from different random seeds as well as the same architecture, but with randomly initialized weights.",reasoning
601,dev_601,"Our method has the advantage of being able to account for non-linearities in the decision boundary that a local approach such as LIME cannot handle, albeit at a cost of higher computational complexity (a similar point was made in (Blaas et al., 2020) for Gaussian processes).","we are able to discover words that our framework views as important, but LIME does not, and vice versa.",reasoning
602,dev_602,"Unfortunately, sensor metadata in different buildings often follows distinct naming conventions.",learning a tagger currently requires extensive annotations on a per building basis.,reasoning
603,dev_603,"As there usually exist buildings that are already tagged, leveraging this information could potentially expedite the tagging process in a new building.","in this paper, we seek to answer the following question: Can we learn a sensor metadata tagger for a new building based on its raw metadata and some existing fully annotated building(s)?",reasoning
604,dev_604,"We observe that some k-mers (i.e., substrings of length-k) (Compeau et al., 2011) express the same meaning regardless of buildings, e.g., ""T"", ""tmp"", or ""temp"" almost always appear in sensor names related to temperature.","we propose to leverage such meaningful k-mers to complement the representation produced by the language model (i.e., z i defined in Eqq. (1)) as “word”-level information.",reasoning
605,dev_605,"There are only 4 classes in building C that appear in either building A or B, so there is not much difference between chunking and tagging.","we only evaluate chunking when training models based on building A and B and testing them on building C. We evaluate the performance of SeNsER with regard to chunking and tagging using the precision, recall, and F 1 scores, similar to NER tasks.",reasoning
606,dev_606,"Moreover, regex for tagging patterns cannot transfer across buildings, which is our goal in this work.",regex is neither an economical nor scalable solution.,reasoning
607,dev_607,The higher the value of uit−1 the more likely there was a recent mention of the entity being tracked by the cell.,"uit−1 provides an alternative to distance-based features commonly used in pairwise scores for spans (Lee et al., 2017).",reasoning
608,dev_608,"Second, the discourse element of a specific sentence depends on context.",considering individual sentences only would have difficulties in identifying discourse elements.,reasoning
609,dev_609,Self-attention ignores word order in a sentence.,position representations are developed to cooperate with self-attention.,reasoning
610,dev_610,This is consistent with the experimental results on the Chinese dataset.,the effectiveness of the SPE and ISA can be verified on both the Chinese and the English datasets.,reasoning
611,dev_611,"From a natural language processing (NLP) perspective, treatments of hate speech focus mainly on the problem of identification (Fortuna and Nunes, 2018).","given a span of text, the task is to identify whether it is an instance of hate speech or not.",reasoning
612,dev_612,A word sequence can be regarded as a thin graph.,it can be used to replace the word lattice as the input of GMN.,reasoning
613,dev_613,"Compared with the tiny graph, the overall lattice has more noisy nodes (i.e. invalid words in the corresponding sentence).",we think it is reasonable that the performance of tiny lattice (PKU+JIEBA) is comparable to the performance of the overall lattice (Lattice).,reasoning
614,dev_614,"For subtasks AE and OE, the key features for determining the existence of aspect and opinion terms are the representations of the original and adjacent words.","we construct two encoders to extract local AE-oriented features X A and OE-oriented features X O : For subtask SC, the process of feature generation is different from that in AE/OE.",reasoning
615,dev_615,"Although SC needs to assign a polarity to every word, we know the ground truth aspect terms in AE during the training process.",we directly use the ground truth tag sequence Ya of AE to refine the labeling process in SC.,reasoning
616,dev_616,"Although fixing the random seed may help replicating the exact same values, it hides an important aspect of most machine learning systems: the variation due to random initialization and different training-test splits.","we repeat each of their experiments 10 times, and allow the random seed to differ in each run.",reasoning
617,dev_617,"An explanation that was given by the authors of why the classifier predictions were worse for the German texts than for the Italian and Czech was that for German it was a five-class problem, whereas for Italian and Czech only a three-class problem.","in our experiment, three experiment settings are carried out.",reasoning
618,dev_618,"Since all texts are written by students taking the Cambridge First exam, the proficiency levels of the authors are less heterogeneous than in the MERLIN corpus, where texts of all CEFR levels are included.",the models and features may not be able to predict the fine-grained scores of a more homogeneous dataset with regard to the levels of the writers.,reasoning
619,dev_619,"However, the performance of the dependency context turned out to be always in the middle between smaller and larger linear windows, and we found nothing notable.",the following analysis only focuses on the results of the linear context window.,reasoning
620,dev_620,"Specifically, we first empirically study the functionalities of the encoder and the decoder in NAT models, and find that the encoder takes a more important role than the decoder regarding the translation quality.",we propose to train the encoder more rigorously by masking the encoder input while training.,reasoning
621,dev_621,The graph learning mechanism will be performed separately for claim-based and evidencebased graph.,"we denote H c and H e as the representations of all nodes in claim-based graph and evidence-based graphs, respectively.",reasoning
622,dev_622,"Prior to the advent of neural approaches, generation systems typically separated content selection (what to say) from surface realization (how to say it) (Reiter and Dale, 1997)","many generation datasets only focused on the latter stage (Wen et al., 2015;Gardent et al., 2017b).",reasoning
623,dev_623,"Due to the complexity of the task, s decontext may still have grammatical errors, even if annotators were instructed to fix grammar.",a second set of annotators were asked to further correct the sentence and were shown the table with highlighted cells as additional context.,reasoning
624,dev_624,"This task is different from what the annotators perform, since they are provided a starting sentence requiring revision.","the task is more challenging, as the model must generate a new sentence instead of revising an existing one.",reasoning
625,dev_625,"The original BERT model is pre-trained with both Wikipedia and the Books corpus (Zhu et al., 2015), the former of which contains our (unrevised) test targets.","we also pre-train a version of BERT on the Books corpus only, which we consider a more correct baseline.",reasoning
626,dev_626,All speeches in an assembly were transcribed into a local assembly minutes based on the local autonomy law.,the local assembly minutes form an extremely large amount of text data.,reasoning
627,dev_627,All speeches in an assembly are transcribed into a local assembly minutes based on the local autonomy law.,the local assembly minutes result in an extremely large amount of text data.,reasoning
628,dev_628,"Generally speaking we mark locations that are named, nominal, or pronominal.","there are six principal types and the implicit ""O"" type, which indicates unmarked (or Other).",reasoning
629,dev_629,"Our proposed optimization methods introduce a trust-region-type regularization (Conn et al., 2000) at each iteration, and then update the model only within a small neighborhood of the previous iterate.",they can effectively prevent aggressive updating and stabilize the finetuning process.,reasoning
630,dev_630,"Compared to CGMH, our method can not only use the gradient norm to locate the editing position more accurately but also our method can use the gradient to fine-tune the inserted or replaced words.",our gradientguided method can achieve a better result than CGMH.,reasoning
631,dev_631,"We recover the dropped pronoun as one of 17 types pronouns pre-defined in (Yang et al., 2015), which include five types of abstract pronouns corresponding to the non-anaphoric pronouns.",traditional rulebased pronoun resolution methods are not suitable for recovering dropped pronouns.,reasoning
632,dev_632,"These results also indicate that decreasing the number of words to be arranged does not guarantee higher agreement, and being presented with a semantically clusterable bigger set of words (like the ones produced in Phase 1) may be preferable to imposing an arbitrary size limit on the classes.","of the difficulty of some verb sets, the inter-annotator agreement scores for some classes show low positive correlation.",reasoning
633,dev_633,"As a consequence of the difficulty of some verb sets, the inter-annotator agreement scores for some classes show low positive correlation.",evaluation of representation models would best be focused on classes with higher inter-annotator agreement and consequently clearer semantics.,reasoning
634,dev_634,"Moreover, the manual process also poses problems related to the subjective notions of what constitutes hate-speech and offensive language, which might result in misuse of this process to silence minorities and to suppress criticism of official policies, political opposition, or religious beliefs.",an automated system to detect hate speech and offensive language is inevitable.,reasoning
635,dev_635,"They also highlighted the fact that different features are important for each hate-speech label, all of which cannot be captured by a single model.","ensemble methods have been used by studies such as Park and Fung (2017), who have used a hybrid-Convolutional Neural Network (CNN) which combines word and character level CNN, Pitsilis et al. (2018), who have used an ensemble of Long Short-term Memory (LSTM) classifiers with majority voting and confidence based aggregation, and Mahata et al. (2019), who used an ensemble of CNN and LSTM based classifiers to capture both salient local information and long term contexts",reasoning
636,dev_636,"However, ensembles are carefully selected task-specific combinations which might not generalize well and are computationally expensive.",a single model with a greater robustness and generalization is desirable.,reasoning
637,dev_637,"The highest performance of RomUrEm can be attributed to the fact that it is trained on tweets having both random and hateful content, while the other embeddings are trained on common texts.","to make a fair comparison, we perform fine-tuning for all embeddings on RUHSOLD dataset in order to perform transfer learning from one domain to the other.",reasoning
638,dev_638,"However, it is relatively an easier task as compared to fine-grained classification.",more concrete conclusions can be drawn by analyzing the results on fine-grained classification task.,reasoning
639,dev_639,"Previous work has shown that non-AAVE speakers often fail to demonstrate comprehension of AAVE speech, and we acknowledge that such misunderstandings may influence the intent-equivalence of our dataset (Jones et al., 2019).","to determine the semantic validity of the translations, we asked annotators who selfidentified as native AAVE speakers and/or codeswitchers to verify whether translated SAE phrases preserved the meaning of original AAVE phrases.",reasoning
640,dev_640,"Pretrained sentence encoders have become particularly popular due to the success of training models for downstream tasks on top of their learned representations, greatly improving the results compared to training from scratch, especially in low-data regimes (see Table 1).","we also probe the usefulness of ConveRT encodings for transfer learning in the intent classification task: the model must classify the user's utterance into one of several predefined classes, that is, intents (e.g., within e-banking intents can be card lost or replace card).",reasoning
641,dev_641,"Only 5.9% of the words in the Switchboard are disfluent, and BERT is only trained on fluent texts such as books and Wikipedia, so the baseline parser may be starved of disfluent training examples.",self-training on a corpus of conversational speech may compensate for the scarcity of disfluent gold data.,reasoning
642,dev_642,"However, these methods are usually designed for written text, so they do not consider the properties of spoken language.",this paper aims at generalizing the idea of language model pre-training to lattices generated by recognition systems.,reasoning
643,dev_643,This task also demands BERT to distinguish the characteristic of source and target domain for better knowledge transfer.,we propose BERT posttraining which takes BERT's pre-trained weights as the initialization for basic language understanding and adapts BERT by novel self-supervised pretrained tasks: domain-distinguish task and target domain masked language model.,reasoning
644,dev_644,"This ability will enhance the domain discriminator, which will help to find more complicated domain specific features and get abandoned by adversarial training.","we further decrease the divergence between the domains, which is quantitatively measured by A-distance in Sec 4.6.",reasoning
645,dev_645,"With the advent of NMT models, we have seen an increase in the quality of translation systems.",a random sample of translations might have few examples with lowquality scores.,reasoning
646,dev_646,"An Unsupervised Alternative A heuristic-based, albeit lower-coverage, alternative to manual alignment is to use questions' mentions of column names.",we use automatically-generated exact-match features in our baseline models for comparison in our experiments.,reasoning
647,dev_647,Our oracle studies also show that there is large unrealized further potential for our annotations.,it remains an exciting challenge for future research to use our lexical alignment annotations more effectively.,reasoning
648,dev_648,"One problem with this is that the reference text often contains extra information that is not presented in the table because human beings have external knowledge beyond the input table when writing the text, or it even misses some important information in the table (Dhingra et al., 2019) due to the noise from the dataset collection process.","unconstrained training with such mis-matching information usually leads to hallucinated words or phrases in generated texts, making them unfaithful to the table and thus harmful in practical uses.",reasoning
649,dev_649,The focus of our work is to build a powerful encoder to incorporate the information from other modality.,we will first begin with an introduction to the incorpo-ration method.,reasoning
650,dev_650,"Paragraphlevel models select multiple answer spans, one for each paragraph, to form a possible outcome.","multiple A-consistent answer spans can occur in a single outcome, as long as they are in different paragraphs.",reasoning
651,dev_651,"We attribute this to the fact that correct answers often have multiple relevant mentions for TriviaQA (also see §5.6), whereas for Narra-tiveQA this is rarely the case.",inference with Sum in NarrativeQA could potentially boost the probability of irrelevant frequent strings.,reasoning
652,dev_652,"Very few researches on copyable generative models pay attention to handle external knowledge, while in knowledge-driven conversation, the description words from knowledge are usually an important component of dialog response.","we leverage a knowledge-aware pointer network upon recurrent knowledge interactive decoder, which integrates the Seq2seq model and pointer networks containing two pointers that refer to utterance attention distribution and knowledge attention distribution.",reasoning
653,dev_653,"Using the constrained inference net with the unconstrained decoder will bias the decoder to use the anchor words in the aligned sentences – the model is not required to do this, but variational learning will pull the inference network and true model posterior towards each other (i.e. the ELBO objective pressures them to agree).","if the inference net is constrained, but the decoder is not, learning will try to find a weakly constrained decoder to match the approximate posterior.",reasoning
654,dev_654,"On analyzing the argmax outputs from the inference network of the trained LAP-CINF-UDEC model, we find that 42% of the predicted anchor words are nouns, 39% of them are verbs, and 11% are adjectives, compared to 58%, 33% and 6% respectively for the RAKE extracted keywords for the ROC data.",the inference network learned along-with the LAP-CINF-UDEC model has higher preference for verbs and adjectives compared to the RAKE algorithm.,reasoning
655,dev_655,"The intuition is based on the observation that RNN classifier tends to outperform CNN classifier on longer sequences, while CNN classifier has the ability to capture local context information within a shorter sequence.",for longer sequences we will assign higher weight to the predictions from RNN.,reasoning
656,dev_656,Human languages evolve to communicate about real-world events.,understanding events plays a critical role in natural language understanding (NLU).,reasoning
657,dev_657,"Notice that most emotions are relatively independent, which means the way we express certain emotion is pretty different from other emotions.",for an unseen class we can hardly find a similar class in the seen class set.,reasoning
658,dev_658,The design conditions of Marvin and Linzen (2018) and our cross-linguistic replications rule out the possibility of memorizing the training data or relying on statistical correlations/token collocations.,"our findings indicate that LSTM language models can distinguish grammatical from ungrammatical subject-verb agreement dependencies with considerable overall accuracy across languages, but their accuracy declines on some constructions (in particular, center-embedded clauses).",reasoning
659,dev_659,Reason (2) is that many of the nouns and verbs in the direct translation of the evaluation sets do not appear in the language models' vocabularies.,"some nouns or focus verbs would effectively be <unk>s if left in, rendering that particular example unusable.",reasoning
660,dev_660,"In our model, legislator embeddings interact with embedding representations of Donald Trump himself, constructed from a neural network using the text (and timing) of his tweets during the same time frame.",our model leverages the text feature extraction capabilities of neural networks and incorporates the legislator sentiment in tweets about Trump as well as the strategic decision about whether and when to tweet about him.,reasoning
661,dev_661,A key limitation of initial methods for estimating ideal points was the inability to perform out-ofsample predictions.,they could not be used to predict votes on new legislation.,reasoning
662,dev_662,"In order to use our model to generate diverse disfluent sentences, we experimented with different variants of PG and found PG-NC-AD-ID produced better performances.","we finally chose PG-NC-AD-ID and the heuristic Planner applying the position choosing heuristic described in Section 3.2.1, since the model-based Planner always chose certain most probable positions, and generated less diverse disfluent sentences, which did not work well as augmented data GPT2 was used to replace the LSTM decoder and trained on a partial pretraining dataset to alleviate the domain gap.",reasoning
663,dev_663,"To effectively perform CWS and POS tagging, combining them into a joint task is proved to have better performance than separately conducting the two tasks in a sequence (Ng and Low, 2004).","many studies were proposed in the past decade for joint CWS and POS tagging (Jiang et al., 2008, 2009; Sun, 2011; Zeng et al., 2013; Zheng et al., 2013; Kurita et al., 2017; Shao et al., 2017; Zhang et al., 2018).",reasoning
664,dev_664,The reason could be straightforward: the output of kvMN is built upon value (knowledge) embeddings and therefore information from key (context feature) embeddings does not directly contribute to it other than providing weights for the value.,kvMN acts in a similar yet inferior 12 way of setting (3) where only knowledge is used.,reasoning
665,dev_665,Note that the original PTB does not contain dependency annotations.,we convert them into Universal Dependencies using Stanford CoreNLP.,reasoning
666,dev_666,"Since LIGHT-LS cannot rank high-frequency words at the top, it often outputs the target words as is.",17 LIGHT-LS has a low changed proportion.,reasoning
667,dev_667,"As discussed in section 4.2, SOC eliminates the compositional effects of a given word or phrase.",regularizing SOC explanations does not prohibit the model from utilizing contextual information related to group identifiers.,reasoning
668,dev_668,In line with Dacrema et al. (2019) we only consider experimental results reproducible if the available source code requires only minimal modifications to work correctly.,we do not replicate the ablation study that is reported on in Tables 5 to 8.,reasoning
669,dev_669,"An important feature of our method is that while the model explicitly takes advantage of n-gram information, the model only outputs character-level encodings that is consistent with BERT.",downstream tasks are not affected.,reasoning
670,dev_670,"Note that ZEN employs a different method to incorporate word (n-gram) information, which could be complementary to some other previous approaches.",it is potentially beneficial to combine it with other character-encoding approaches.,reasoning
671,dev_671,"We observe that the gold justification contains some sentences that are not relevant to the fact check, and the extractive summary is fooled to select explanation sentences that are close to the gold summary.",the explanation does not provide enough information about the chosen veracity label.,reasoning
672,dev_672,"We use the LIAR dataset to train such models, which contains fact checked single-sentence claims that already contain professional justifications.",we make an initial step towards automating the generation of professional fact checking justifications.,reasoning
673,dev_673,"Additionally, rather than creating new data from scratch, contrast sets augment existing test examples to fill in systematic gaps.","contrast sets often require less effort to create, and they remain grounded in the original data distribution of some training set.",reasoning
674,dev_674,"Intuitively, fine-tuning RoBERTa on an intermediate task can cause the model to forget some of its ability to perform the MLM task.","a future direction for potential improvement for intermediate-task training may be integrating the MLM objective into intermediate-task training or bounding network parameter changes to reduce catastrophic forgetting (Kirkpatrick et al., 2016; Chen et al., 2019).",reasoning
675,dev_675,Retrieving at-least one helpful sentence is crucial to obtain contextual information for the To-Do item.,we evaluate our approaches based on the proportion of emails where at-least one helpful sentence is present in the top K retrieved sentences.,reasoning
676,dev_676,"In this work, we demonstrate that it is possible to achieve SoTA results by cluster ranking alone, i.e. by linking mentions directly to the entities.","our model is less complex than the existing entitylevel models (Lee et al., 2018;Kantor and Globerson, 2019) using similar mention representations.",reasoning
677,dev_677,"First of all, the current SoTA mention-ranking systems tend to be hybrids, using entity-level features alongside mention-pair features.","such models are usually more complex than pure mention ranking models, and substantially increase the number of trainable parameters.",reasoning
678,dev_678,CEFR levels are also used in classroom language teaching to differentiate between different learner groups.,"one can have a Swedish class for B1 learners, which presupposes that learners taking the class have mastered all or most of the skills of the lower levels A1 and A2 and should have mastered all or most skills introduced at B1 after having finished the class.",reasoning
679,dev_679,"To this aim, we start from one language pair, for example French/Swedish, and for each entry we look up possible translations in the third language, English in this case, from the other two resources.","if we start with the French/Swedish list, we retrieve English translations from the aligned English/Swedish and English/French lists.",reasoning
680,dev_680,"This is due to the fact that we only perform a single-step translation look-up, and that some translations might only be reachable under certain circumstances.","in a second step, we remove partial entries which are covered by more complete entries.",reasoning
681,dev_681,"Since each hypothesis starts with a different assumption and makes a (mathematically) different claim, it can only be tested with a certain set of statistical methods.",nLP practitioners ought to define their target hypothesis before choosing an assessment method.,reasoning
682,dev_682,A large p-value implies that the data could easily have been observed under the null-hypothesis.,a lower p-value is used as evidence towards rejecting the null-hypothesis.,reasoning
683,dev_683,"The more answers to a question there are, the more likely it is that any other answer is equal to one of the expected answers.",the higher number of answers in SQuAD1.1 contributes to the higher human performance compared to FQuAD1.1 regarding the exact match metric.,reasoning
684,dev_684,"We argue that product attributes and values are highly correlated, e.g., it will be easier to extract the values on condition that the product attributes are given.",we jointly model the attribute prediction and value extraction tasks from multiple aspects towards the interactions between attributes and values.,reasoning
685,dev_685,"The model proposed along with the MAE dataset takes textual product descriptions, visual information, and product attributes as input and treats the attribute value extraction task  as predicting the value for a given product attribute.",we compare our M-JAVE model with the MAE-model only on the value extraction task.,reasoning
686,dev_686,"A pre-trained language model may not handle this issue well, as it cannot identify the TCS dimensions in temporal mentions and effectively learn from them.",it cannot generalize well to similar events without explicit temporal mentions.,reasoning
687,dev_687,"Such temporal arguments are usually composed of a duration phrase and a numerical head (e.g., ""four times per"") indicating the frequency within the duration (e.g., ""week"").","we check for multiple keywords that indicate the start of a frequency expression, including ""every,"" ""per,"" ""once,"" .",reasoning
688,dev_688,"Moreover, all these reward approaches are fixed and do not change over training, and all the metrics may not be important over every stage of the training.","it might be useful to consider using a dynamic combination of metrics, which rewards to use early vs. later, or which rewards might be useful to come back later in training, and consider the context of the full history of rewards, as well as the models current state and the nature of the metric.",reasoning
689,dev_689,"Past work has reported great variation in how human evaluations are done (van der Lee et al., 2019).","we begin with a meta-analysis of a subset of human evaluation experiments from EMNLP 2019, which we then use as the basis for claims about the power of human evaluations in NLP more generally.",reasoning
690,dev_690,"For real speech inter speaker comparison (last row), we calculated DTW for sentences uttered by all speakers (4 common sentences, common).","for each speaker we compared the time series with all time series of the other speakers uttering the same sentence once, or more than once, and calculated DTW for each pair of time series.",reasoning
691,dev_691,"This variety is driven by many factors such as topics, individuals, settings, and even differences between spoken and written text.","it is difficult to scale traditional word-level debiasing approaches (which involve bias-attribute words such as man, woman) (Bolukbasi et al., 2016) to sentences.",reasoning
692,dev_692,"On the other hand, the potential number of sentences are unbounded which makes it harder to precisely characterize the sentences in which bias is present or absent.",it is not trivial to directly convert these words to sentences to obtain a representation from pretrained sentence encoders.,reasoning
693,dev_693,"Note that even if the magnitudes of sentence representations are not normalized, the debiased representations are still pointing in directions orthogonal to the bias subspace.",skipping the equalize step still results in debiased sentence representations as measured by our definition of bias.,reasoning
694,dev_694,"For BERT fine-tuned on QNLI, using a larger number of domains reduces the variance in effect size and improves stability of the algorithm.",it is important to use a large variety of templates across different domains.,reasoning
695,dev_695,"Occasionally new words emerge, and every now and then some words fall out of favour so much that they may be considered extinct.","it is not surprising that prominent thinkers of the past, including Charles Darwin, have argued that just as there is a natural selection in the plant and animal species over time, there is a natural selection of words over time (Darwin, 1968;Darwin, 2003).",reasoning
696,dev_696,"In this analogy, word type maps to a species, and word frequency maps to the species population.","the creation and use of a new word is akin to the birth of a new species, the wide-spread use of a word is akin to the thriving of a species, and the complete lack of use of a word is akin to the extinction of a species.",reasoning
697,dev_697,"To smooth frequencies, we aggregate frequencies across ten-year spans.","the entry for a word w and 1809, includes the total number of times w occurred in books from 1800 up to and including 1809; the entry for 1810, includes the total number of times w occurred in books from 1801 up to and including 1810; and so on.",reasoning
698,dev_698,"However, while accuracy in emulated low-resource scenarios is over 50% for all languages, for the truly lowresource languages Popoluca and Tepehua, our best model only obtains 37.4% and 28.4% accuracy, respectively.",we conclude that canonical segmentation is still a challenging task for low-resource languages.,reasoning
699,dev_699,"We use BPE (Sennrich et al., 2016) for subword segmentation because it generates the merge operations in a deterministic order.",a vocabulary based on a smaller number of merges is a subset of a vocabulary based on more merges estimated from the same training data.,reasoning
700,dev_700,"BLI accuracy assumes that all test words are equally important, but the importance of a word depends on the downstream task; e.g., ""the"" is irrelevant in document classification but important in dependency parsing.",future work should focus on downstream tasks instead of BLI.,reasoning
701,dev_701,"In hybrid clustering, we use Exchange for the clustering part and Brown for building the hierarchical structure.","for a hybrid clustering, one defines a set number of classes c, runs Exchange over the corpus to compute the c classes, and then runs Brown over the flat clustering.",reasoning
702,dev_702,The vast majority of the final AMI is achieved within three or four iterations.,"stopping Exchange after three iterations results in a three-fold speedup compared to suggestions in the literature (Uszkoreit and Brants, 2008;Martin et al., 1998).",reasoning
703,dev_703,R-MeN considers each triple as a sequence of 3 input vectors that recurrently interact with a memory using a transformer self-attention mechanism.,r-MeN encodes new information from interactions between the memory and each input vector to return a corresponding vector.,reasoning
704,dev_704,Thus R-MeN encodes new information from interactions between the memory and each input vector to return a corresponding vector.,r-MeN feeds these 3 returned vectors to a convolutional neural network-based decoder to produce a scalar score for the triple.,reasoning
705,dev_705,"Knowledge graphs (KGs) -representing the genuine relationships among entities in the form of triples (subject, relation, object) denoted as (s, r, o) -are often insufficient for knowledge presentation due to the lack of many valid triples (West et al., 2014).","research work has been focusing on inferring whether a new triple missed in KGs is likely valid or not (Bordes et al., 2011(Bordes et al., , 2013Socher et al., 2013).",reasoning
706,dev_706,"Such a growing prevalence of cyberbullying on social media has detrimental societal effects, such as victims may experience lower self-esteem, increased suicidal ideation, and a variety of negative emotional responses (Hinduja and Patchin, 2014).","it has become critically important to be able to detect and prevent cyberbullying text, image, video on social media.",reasoning
707,dev_707,It is also crucial to understand why a media session is detected as cyberbullying.,we study the novel problem of explainable cyberbullying detection that aims at improving detection performance and highlighting explainable comments.,reasoning
708,dev_708,"However, these projects are usually not based on open source software and do not comply with a standardized workflow.","their frameworks are neither reusable, nor are their data interoperable.",reasoning
709,dev_709,"Laughter has been shown to be very important to human affiliation (Provine, 1996) and solidarity (Hay, 2000).","we detect the number of occurrences of strings indicating laughter (e.g. ‘ha’, ‘lol’) in the user’s response, and use this as a reward.",reasoning
710,dev_710,"While it would be ideal if our chatbots could intelligently adapt their conversation style to a new user, in reality most baseline dialog models struggle to maintain topic coherence, even over a few utterances (for an analysis of this effect, see ).","we reward semantic similarity between the user's input and the bot's response, to encourage the bot to stay on topic and produce reasonable answers.",reasoning
711,dev_711,"At the same time, it must be noted that out of respect for competition not all companies are disclosing the details of deals or exact amounts.",the true investment amounts (especially in Asia) might be noticeably larger.,reasoning
712,dev_712,There are a greater number of European search companies offering enterprise services and specific languages.,their market presence is more fragmented resulting in a weak position.,reasoning
713,dev_713,"Although Chinese is the second largest language in terms of number of users, the total number of European Internet users exceeds it.","""top ten language"" as criteria used to identify advantages for data must be carefully evaluated.",reasoning
714,dev_714,"With PropBank, our aim is to provide this indispensable contextual information through annotating the argument structure of each verb.",it is evident that PropBank's function is indispensable for processing and properly interpreting Turkish.,reasoning
715,dev_715,"To sum up, TRropBank provides unprecedented data on the overall tendencies of Turkish verbs within the framework of transitivity and the portion of idiomatic expressions.",we can infer that TRropBank helps us unveil the properties of argument structure of Turkish verbs in regards to theoretical linguistics in addition to being a valuable asset for NLP solutions.,reasoning
716,dev_716,"Many verbs seem to be ambiguous when it comes to this categorization, and they seem to change category depending on context.","once again, intuition had to be relied upon for the classification of these verbs.",reasoning
717,dev_717,"The three physical concepts at play in the simulations -friction, collision, and gravity are either a cause or an effect of some collision.",collisions were the most common physical event in the simulations (average = 54 per task) and so we decided to only record collisions.,reasoning
718,dev_718,"Although most tasks in NLP require reasoning, the LegalAI tasks are somehow different, as legal reasoning must strictly follow the rules well-defined in law.",combining predefined rules and AI technology is essential to legal reasoning.,reasoning
719,dev_719,The task LJP mainly concerns how to predict the judgment results from both the fact description of a case and the contents of the statutory articles in the Civil Law system.,"lJP is an essential and representative task in countries with Civil law system like France, Germany, Japan, and China.",reasoning
720,dev_720,"In those countries with the Common Law system like the United States, Canada, and India, judicial decisions are made according to similar and representative cases in the past.",how to identify the most similar case is the primary concern in the judgment of the Common Law system.,reasoning
721,dev_721,This task is slightly different from previous Machine Reading Comprehension (MRC) since the document which contains the correct answer is not directly provided.,how to collect the domain knowledge from massive QA data becomes extremely important.,reasoning
722,dev_722,"However, as depicted in Figure 2(b), in MAT-INF, our jointly labeled fashion can guarantee that X remains the same as in a single task and only Y is added.","mATINF provides a fair and ideal stage for exploring multi-task learning, especially auxiliary and multi-task supervision under a single dataset.",reasoning
723,dev_723,"We have worked with a limited number of eight journalists, as it is cumbersome and expensive to obtain domain expert annotations, but the crowd-sourcing platforms are generally low-cost and employ a very high number of annotators for their tasks (in our case eighty).",the non-experts have annotated generally more articles and also more articles in common with each other -the latter could make their agreement scores more robust.,reasoning
724,dev_724,"Surprisingly, the expert community and the crowd-workers appear to agree on what is biased and what is not at approximately 70% of the time.",in the majority of the articles the individuals in E and NE recognize the evidence in the text to mark it as biased or unbiased.,reasoning
725,dev_725,"Interestingly, the STDEV in E vs. All is much lower than in NE vs. All, which can be an indicator of the consistency and reliability of the journalists.","given the lower variance, one might not need as many expert annotators as crowd workers to obtain a high quality media bias detection dataset.",reasoning
726,dev_726,"Since the annotator agreement results for the Figure Eight dataset were not satisfactory, we use only the MTurk dataset for the rest of our experiments.","when we refer to the non-expert annotations, only the dataset from MTurk is considered.",reasoning
727,dev_727,"However, the huge volume of online conversations produced daily hinders people's capability of finding the information they are interested in.",there is pressing demand for developing a conversation recommendation engine that tracks ongoing conversations and recommends suitable ones to users.,reasoning
728,dev_728,"Even if we filter to only keep people who have watched a movie, it is hard to guarantee they can recall all the scenes in the movie.",the factuality check is only done by the person who performed this dialogue.,reasoning
729,dev_729,"Intuitively, Chinese NER is correlated with word segmentation, and named entity boundaries are also word boundaries.","the potential boundary information presented by the additional segmentation input can provide better guidance to label each character, which is consistent with the conclusion in (Zhang and Yang, 2018).",reasoning
730,dev_730,"With this vetting strategy, the most valuable data is always selected first.",vetting budget is the only factor controlling the vetting procedure.,reasoning
731,dev_731,"For the purpose of word alignment, this translation Transformer is used as-is to extract representations of the source and the target sequences, and our alignment technique does not change the parameters of the Transformer.","improvements to the translation system can be expected to directly carry over to alignment quality, and the alignment component does not affect translation output in any way.",reasoning
732,dev_732,"Using BPE units instead of words also improved results for GIZA++ (e.g., 20.9% vs. 18.9% for Germanâ†’English in a single direction).",we use the exact same input data for GIZA++ and all our neural approaches.,reasoning
733,dev_733,Most of the language pairs do not contain an adequately sized development set for word alignment experiments.,"rather than early stopping, we used a fixed number of updates for each training stage across all languages pairs: 90k for training the translation model, 10k for the alignment layer and 10k for guided alignment training (batch-size: 36k words).",reasoning
734,dev_734,This performance improvement finding resultant of high-order features or structure learning suggests that the same benefits might be observed in SRL.,this paper intends to explore the integration and effect of high-order structures learning in the neural SRL model.,reasoning
735,dev_735,"In the current GPU memory conditions, second-order J = 2 is the upper limit that can be explored in practice if without pruning.","we enumerate all three second-order structures as objects of study in SRL, as shown in the left part of Figure 1, namely sibling (sib), co-parents (cop), and grandparent (gp).",reasoning
736,dev_736,Mean field variational inference approximates a true posterior distribution with a factorized variational distribution and tries to iteratively minimize its KL divergence.,we use mean field variational inference approximates to obtain the final arc distribution.,reasoning
737,dev_737,"The number of human descriptions per image varies in DIDEC and as we also removed some captions during preprocessing, images do not have an equal number of captions.","we report the average number of captions per image for each split, as well as their range, in Table 5.",reasoning
738,dev_738,"Unlike images, actions in videos are also inherently linked to social aspects such as intentions (why the action is taking place), effects (what changes due to the action), and attributes that describe the agent.","for video understanding, such as when captioning videos or when answering questions about videos, one must have an understanding of these commonsense aspects.",reasoning
739,dev_739,"However, we want to make sure that these descriptions are also relevant to the video.",we utilize human workers from Amazon Mechanical Turk (AMT) for selecting the most relevant commonsense descriptions.,reasoning
740,dev_740,"Moreover, since the video is not used for retrieving these, the commonsense annotations may be out-of-context.","we bring in human annotators to watch the video, read the caption, and then use the set of descriptions from ATOMIC to select the relevant once and to discard the irrelevant or out of context descriptions.",reasoning
741,dev_741,We have 21 types of templates with each template having numerous possibilities for combinations of the slots in the template.,"we get 21 types of questions (7 each for intention, effect, and attribute) as shown in Table 6.",reasoning
742,dev_742,"A non-biologist may expect 'bleaching' to refer to cleaning, sterilizing, or whitening (Nagel, 2014).","terminology from the engineering domain does not always provide a good starting point for the identification of relevant biological information (Fayemi et al., 2015;Kruiper et al., 2017).",reasoning
743,dev_743,A major issue is that engineers know little biology or few details of plants or animals.,"engineers have trouble identifying, selecting and understanding relevant biological information (Vattam and Goel, 2011; Vattam and Goel, 2013b).",reasoning
744,dev_744,"However, when analyzing the top predictions, the models are forced to make one decision.","even if the model assigns high scores to both labels of ""woman cooking"" and ""man cooking"", it has to pick one as the prediction.",reasoning
745,dev_745,"Moreover, the vast majority of these papers do not engage with the relevant literature outside of NLP to ground normative concerns when proposing quantitative techniques for measuring or mitigating ""bias.""","we fnd that many of these techniques are poorly matched to their motivations, and are not comparable to one another.",reasoning
746,dev_746,"Similarly, ""controlling images,"" such as stereotypes of Black women, which are linguistically and visually transmitted through literature, news media, television, and so forth, provide ""ideological justifcation"" for their continued oppression (Collins, 2000, Chapter 4).","many groups have sought to bring about social changes through changes in language, disrupting patterns of oppression and marginalization via so-called ""gender-fair"" language (Sczesny et al., 2016;Menegatti and Rubini, 2017), language that is more inclusive to people with disabilities (ADA, 2018), and language that is less dehumanizing (e.g., abandoning the use of the term ""illegal"" in everyday discourse on immigration in the U.S. (Rosa, 2019)).",reasoning
747,dev_747,"In an ideal world, shared task papers would engage with ""bias"" more critically, but given the nature of shared tasks it is understandable that they do not.",we excluded them from our counts for techniques as well.,reasoning
748,dev_748,Different model configurations may influence model performance greatly.,we conduct an ablation study to validate the effectiveness of each model component used in this work.,reasoning
749,dev_749,"In Figure 3, we see that in general, the closer two words occur in sequence, the more they influence each other, leading to correspondingly high DI.",we stratify by the sequential distance of words when we investigate syntactic distance.,reasoning
750,dev_750,"In the familiar-scaffold setting, we randomly distribute 1000 occurrences of each scaffold throughout the corpus outside of the rule patterns.",each scaffold is seen often enough to be memorized (see Appendix B).,reasoning
751,dev_751,"Empirically, LSTMs encode the most recent noun as the subject of a verb by default, but they are still capable of learning to encode grammatical inflection from the first word in a sequence rather than the most recent (Ravfogel et al., 2019).","while inductive biases inherent to the model play a critical role in the ability of an LSTM to learn effectively, they are neither necessary nor sufficient in determining what the model can learn.",reasoning
752,dev_752,The speed of acquisition of the dependency rule in a familiar-scaffold training environment therefore has an explanation other than hierarchical composition.,"in order to confirm our proposed compositional bias, we observe the interactions between scaffold and superstructure (long distance dependency) using DI.",reasoning
753,dev_753,"After model training, learned G and E will build a two-way projection between document-topic distribution and document-word distribution.",g and E could be used for topic generation and cluster inference.,reasoning
754,dev_754,"They used Word2Vec vectors (Mikolov et al., 2013) of positive words and random negative words as input to the learning objective.",their entity embeddings are aligned with the Word2Vec word embeddings.,reasoning
755,dev_755,"The contained data should be as natural as possible, but we gave priority to collecting clear audio-visual dialog data.",we separated the participants into different sound-proof chambers connected by audio-visual communication to record the video clips from the second-person perspective and speech in individual channels.,reasoning
756,dev_756,The purpose of this project is to construct a multimodal dialog corpus that is useful for developing the dialog systems.,we collected clear audio signals and video clips that capture speakers' behavior from the second-person perspective.,reasoning
757,dev_757,"While EHRs contain medical billing codes that aim to represent the conditions and treatments patients may have, much of the information is only present in the patient notes.",it is critical to develop robust algorithms to infer patients' conditions and treatments from their written notes.,reasoning
758,dev_758,"Their perception is based on extensive conversational experience with real people, rather than using an explicit reference that helps to determine what is correct or wrong.",the main contribution of this effort is to investigate whether dialogue modeling approaches used for dialogue systems can detect anomalous conversations in contrast to normal ones.,reasoning
759,dev_759,"The sequence-to-sequence approach is also on par with the others, which is noteworthy because unlike the others, it cannot capture long-term dependencies in dialogues.",long-term context appears to be not necessary for the scoring of these dialogues by the annotators.,reasoning
760,dev_760,This can be very costly in terms of resources.,the research and development of these systems could benefit significantly from an automated approach that can evaluate conversations.,reasoning
761,dev_761,"Intuitively, initial scenes of an episode tend to have high similarity with all other scenes in the screenplay, and on their own are not very informative (e.g., the crime, victim, and suspects are introduced but the perpetrator is not yet known).",the undirected version of TEXTRANK tends to favor the first part of the story and the resulting summary consists mainly of initial scenes.,reasoning
762,dev_762,"Moreover, models are usually agnostic to the noises or artifacts of the training data, such as reference divergence, making them vulnerable to hallucinations (Kryscinski et al., 2019a;Wiseman et al., 2017;Dhingra et al., 2019).","models can generate texts that are not consistent with the input, yet would likely have reasonable model log-likelihood.",reasoning
763,dev_763,The pretraining prepares BertS2S to be more aware of the domain of the document and less prone to language model vulnerabilities.,"bertS2S is more confident in predicting tokens from the document than TranS2S, hence, improving faithfulness.",reasoning
764,dev_764,"In fact, for extrinsic hallucinations, even though PTGEN hallucinates less than BERTS2S (63.3% vs. 64.1%), 6.6% of BERTS2S hallucinations were factual, compared to 2.2% of PTGEN.","if we consider factual hallucinations to be valid, this means that even for extrinsic cases, BERTS2S hallucinates the least.",reasoning
765,dev_765,"In the first stage, a text representation model ViBERT is trained in the bi-modal sequence-tosequence approach for scene layout generation on COCO.",visual commonsense knowledge like spatial relations will be encoded in ViBERT by the supervision of caption and image layout.,reasoning
766,dev_766,"However, the background knowledge required in the commonsense reasoning task, such as spatial relations, causes and effects, scientific facts and social conventions, are usually not explicitly provided by the text.",it is difficult to capture such knowledge solely from the raw texts.,reasoning
767,dev_767,"In contrast, the crowd workers tended to select more specific frames instead of comprehensive frames, such as the frame Intentionally act.",the crowdsourcing approach better captured the meaning of the ICSI English frames both cross-culturally and cross-linguistically than those obtained via the transferring approach.,reasoning
768,dev_768,"However, in the framing task, the frame candidates for a given target word should be given for crowd workers, with exemplar sentences for each frame.",the crowdsourcing approach is more of a method of extending the existing FrameNet resources than a method of building the initial data.,reasoning
769,dev_769,For many lowresource languages -in particular those ones which are on the brink of extinction -this means they will effectively disappear from research when existing data is of low quality and new data can no longer be obtained.,"making existing data ready for re-use -""lifting"" it into current research environments -is vital for any cross-linguistic research.",reasoning
770,dev_770,We demonstrate the training strategy in Figure 2.,the model is trained to produce consistent results despite seeing partial views of the input -thereby improving underlying representations.,reasoning
771,dev_771,"As in real life, to succeed a betrayal must be a surprise to the victim.",players pride themselves on being able to lie and detect lies.,reasoning
772,dev_772,Diplomacy games are different in that they can last a month. . . and people already play the game for free,we do not want compensation to interfere with what these players already do well: lying.,reasoning
773,dev_773,"Even the obituary of the game's inventor explains Diplomacy rewards all manner of mendacity: spying, lying, bribery, rumor mongering, psychological manipulation, outright intimidation, betrayal, vengeance and backstabbing (the use of actual cutlery is discouraged)"" (Fox, 2013).","our goal is to have compensation mechanisms that get people to play this game as they normally would, finish their games, and put up with our (slightly) cumbersome interface.",reasoning
774,dev_774,A high compression rate for large-scale language models is difficult to achieve on downstream NLP tasks.,"there are few works in exploring and optimizing hardware-friendly model compression techniques for state-of-the-art Transformer-based pre-trained language models, to reduce the weight storage and computation on computer system while maintaining prediction accuracy.",reasoning
775,dev_775,"There are two reasons: i) Information compressed in image features can be partially retrieved from neighboring pixels since spatially they share similar and uniform characteristics, whereas syntax and semantics information in deep Transformer in language/text domain are not uniformly characterized; ii) Intuitively, the high-level semantic, syntax, and language understanding capability might be broken when we prune zero or near-zero weights in the latent space.",a high compression rate for large-scale language models is difficult to achieve on downstream NLP tasks.,reasoning
776,dev_776,The results show that the embedding layers and linear weights in transformer layers are sensitive on CoLA and MRPC datasets.,we set the compression ratios of corresponding weights zero to ensure the final accuracy.,reasoning
777,dev_777,"(2) Lexical entrainment: Speakers tend to reuse words that were effective in previous mentions (Garrod and Anderson, 1987; Brennan and Clark, 1996) possibly due to priming effects (Pickering and Garrod, 2004).","besides being a challenging problem intriguing from a linguistic and psycholinguistic point of view, computationally modelling the generation of subsequent references can contribute to better user adaptation in dialogue systems and to more natural humancomputer interaction.",reasoning
778,dev_778,The top-scoring utterance in the game round is selected as a referring utterance for i and used as an additional caption for extracting subsequent references in the following game rounds.,"of this procedure, for a given dialogue and an image i, we obtain a reference chain made up of the referring utterances-maximum one per round-that refer to i in the dialogue.",reasoning
779,dev_779,"In particular, we consider three measures based on n-gram matching: BLEU-2 (Papineni et al., 2002), 8 ROUGE (Lin, 2004), and observed.","some of the candidate images have multimodal representations (if they were already mentioned in the dialogue), while others do not.",reasoning
780,dev_780,"Instead, the target values of the subtasks are based on ""change scores"" which represent only the existence or degree of LSC.","of this simplification, the evaluation methods used in the Unsupervised LSC are incompatible with the WSI and DWSI tasks.",reasoning
781,dev_781,The intuition behind this measure is that a perfect system should predict probability one for the gold sense and zero for any other sense.,"the further the predicted probability deviates from one, the higher the error.",reasoning
782,dev_782,"In theory the true answer is the emergence year, but in a classification setting it is reasonable to allow some margin of error.",the predictions of an emergence is counted as correct if it falls within the bounds of a 5 year window centered on the true emergence year.,reasoning
783,dev_783,"While our proposed model is able to reason very effectively achieving state-of-the-art on the recent datasets, it is able to do so with an assumption of perfect OCR.",it will be pertinent to have better OCR models for chart images.,reasoning
784,dev_784,"With the help of those techniques, it is observed that NAR models can match the accuracy of AR models for some tasks (Ren et al., 2019), but the gap still exists for some other tasks (Gu et al., 2017; Chen et al., 2019).",several questions come out naturally: (1) Why the gap still exists for some tasks?,reasoning
785,dev_785,"It is non-trivial to directly measure and compare the target token dependency in different modalities (i.e., speech or text) and different conditional source modalities (i.e., speech or text).","we have several considerations in the design of CoMMA: 1) We use masked language modeling in BERT (Devlin et al., 2018) with source condition to train CoMMA, which can help measure the dependency on target context when predicting the current masked token.",reasoning
786,dev_786,Such annotation is difficult to obtain at scale.,"recent work has focused on training such models with less supervision: one line of work assumes that only the order of actions happening in the video is given and use this weak supervision to perform action segmentation (Bojanowski et al., 2014;Huang et al., 2016;Ding and Xu, 2018;Chang et al., 2019).",reasoning
787,dev_787,"When using EPA to identify the polarity of sentiment, the E, P, and A weights need to be projected to one value before integrating it into a deep learning model.",the EPA values are transformed into one single weight WEPA which is regarded as an affective influence value.,reasoning
788,dev_788,"All the results congruently suggest that affective terms with informative sentiment representation can effectively and consistently contribute to model enhancement across different datasets, including both short sentences and long paragraphs, of which the later is more significant.",highlighting the affective terms relevant to sentiment could further improve the attention mechanism.,reasoning
789,dev_789,One significant observation is EPA together serves as the best representation which indicates the orthogonality of each component could be supplementary to each other.,we use EPA with equal weights for our model comparison in Section 4.2..,reasoning
790,dev_790,"In these approaches, the overall mutual effect between texts and prices is distributed over the neural network, which makes it difficult to extract this effect and apply it to tasks other than price prediction.",we take a new approach by explicitly describing this mutual effect in terms of a vector.,reasoning
791,dev_791,"Precisely, our stock embedding is trained through a binary classification problem, namely, whether a stock price goes up or down in comparison with the previous day's price.",an acquired stock embedding captures the relation between a stock name and a news article even when the article has no direct mention of the stock.,reasoning
792,dev_792,"Furthermore, to examine the effect of the data size, we tested different dataset portions: 1 year, 3 years, and the whole dataset.","the experimental variants involved five methods (four comparison + our proposal) and three data sizes, or a total of 15 experiments.",reasoning
793,dev_793,"Overall, our model successfully achieved 68.8% accuracy for the R&B dataset, which was significantly better than any of the other four variants.","far, the evaluation on classification has shown the capability of our framework in understanding news articles.",reasoning
794,dev_794,"In our set of interventions, we only modify the flow of information within the network, versus the number of trainable parameters.",we do not have confounding factors of varying network capacity.,reasoning
795,dev_795,KonText also supports automatic text selection based on custom proportions of individual attributes (typically text registers).,the created subcorpus can keep the user-specified proportion of the main registers without the need to specify individual texts.,reasoning
796,dev_796,"Data sets often contain data from specific domains such as sports-, celebrities-or music-related topics.",annotation methods can only be evaluated on a small part of the KG concerning a specific domain.,reasoning
797,dev_797,"Furthermore, annotation of texts based on the abovementioned KGs shows whether KORE 50 adequately evaluates entity linking systems on varying KGs or just covers specific domains.","kORE 50 DYWC is not limited to evaluating NERD systems, but can also be used to analyse kGs in terms of advantages and disadvantages with regard to varying tasks -potentially limited to (or enhanced by) domain-specific knowledge.",reasoning
798,dev_798,"In NERD, empty data sets will lead to an increased false positive rate and thus a lower precision of the entity linking-system (Waitelonis et al., 2016).","documents that cannot be annotated, as is often the case with Crunchbase, should be excluded for a more realistic evaluation.",reasoning
799,dev_799,"Those untruthful answers may attribute to multiple factors such as misunderstandings of the question, improper expressions during writing, and even intentionally malicious attacks from the competitors (Carmel et al., 2018).","automatically verifying the answer veracity is becoming a demanding need, which can offer a more reliable online shopping environment, for example, by triggering a double-check on the detected doubtful answers.",reasoning
800,dev_800,"To predict the veracity of an answer in the QA settings, one can notice that it is insufficient to consider the answer alone since the question text also carries important semantic information for the prediction.",we need to appropriately leverage the question text into the verification process.,reasoning
801,dev_801,The sof tmax() function on the other hand will normalize the score for each evidence sentence.,more important evidence can have larger weight and attach more importance in the subsequent prediction process.,reasoning
802,dev_802,We conjecture that DeClarE treats each claim-evidence pair as one training instance without considering the relations between evidence sentences.,the model can be misled by conflicting evidence sentences and makes random predictions.,reasoning
803,dev_803,Enterprises are the subject in economic activities.,the entities corresponding to enterprises are candidates of the sentiment targets.,reasoning
804,dev_804,"Furthermore, the conjunctions always play an important role in distinguishing sentiment polarity conflict situations because people normally emphasizes the part behind the adversative conjunction.",we determinate the sentiment polarity according to the emphasized part.,reasoning
805,dev_805,Note that the probability p(d t |b t ) is omitted as database result d t is deterministically obtained given b t .,"the system response can be generated as a three-step process: first predict the belief state b t , then use b t to query the database and obtain d t , finally generate the system response r t based on all the conditions.",reasoning
806,dev_806,"Task Subjectivity In some tasks, aggregated annotations always correspond to the correct answer (Brew et al., 2010).","to fully utilize the crowd's knowledge, different approaches have been proposed to aggregate labels, from simply applying majority voting to more sophisticated strategies to assess annotators' reliability (Yang et al., 2018;Srinivasan and Chander, 2019;Rodrigues et al., 2014).",reasoning
807,dev_807,"We decided to treat the first, second, and third choices differently as they represent the workers' priorities.","we give the highest weight to the first choices (1.0) and lower weights (0.6) and (0.3) to the second and third choices, respectively.",reasoning
808,dev_808,Font Recall (FR) Less popular fonts could be underrepresented by the models.,we need an evaluation metric that measures the performance of models in learning individual labels.,reasoning
809,dev_809,"That is, we wish to make it impossible to predict, for example, a person's gender, from their embedding.",predictions made using these embeddings (such as about profession) will also be independent of these attributes.,reasoning
810,dev_810,"Although these times are benchmarked on FB15K only, the relative differences in spe stays constant for the larger datasets, as time to read from/write to memory is negligible.",we are able to train our full model on the Wikidata knowledge graph for 10 epochs in a time of around 10 hours on a system with 64 cpus.,reasoning
811,dev_811,"For FB3M and Wikidata, we found these values to be too small.",we increased the values for FB3M to 100.0 for gender and 500.0 for the other three attributes.,reasoning
812,dev_812,"In the worst case scenario, outliers introduce a high correlation when there is no association between metric and human scores for the rest of the systems.",future evaluations should also measure correlations after removing outlier systems.,reasoning
813,dev_813,"Our system produces de-tokenized cased output after BPE decoding, whereas previous systems produce traditional tokenized lower-cased output.",we lowercase and tokenize our system outputs to have fair comparisons with previous systems.,reasoning
814,dev_814,"One possible reason could be the intrinsic difference of linguistic patterns between human conversations and writing text, resulting in a large gap of data distributions (Bao et al., 2019).","pre-training dialogue language models using chit-chat corpora from social media, such as Twitter or Reddit, has been recently investigated, especially for dialogue response generation (Zhang et al., 2019) and retrieval (Henderson et al., 2019b).",reasoning
815,dev_815,"We care the most in this paper whether TOD-BERT, a pre-trained language model using aggregated taskoriented corpora, can show any advantage over BERT.",we avoid adding too many additional components on top of its architecture when fine-tuning on each downstream task.,reasoning
816,dev_816,"The source URLs, together with the other meta-data were formatted and stored in JSON format making corpus 1 easily reusable and reproducible.",this makes it easy for any interested researcher to process the dataset and use it in modeling epidemiological event extraction or any other related NLP tasks.,reasoning
817,dev_817,"Conscious or subconscious gesturing is part of non-verbal communication (Argyle, 2010).","gestures, such as hand gestures, head movements, facial expressions or body posture, which are connected to speech (Kendon, 2004;McNeill, 2015), are called co-speech gestures.",reasoning
818,dev_818,"Since the stated data artificially overrepresents positive examples, the model trained on stated data is initially miscalibrated-the points it is uncertain about are actually almost all negative points.",uncertainty sampling initially collects very few additional positive examples.,reasoning
819,dev_819,"Existing models are optimized by maximizing the conditional word probabilities of a reference sentence, a common signal for training language models.","these models can learn to produce fluent sentences, but some crucial input concepts and relations may be messed up or even dropped.",reasoning
820,dev_820,"For more detail, we remove any abbreviations from a KG node (such as ""New York (NY)"" is changed to ""New York""), before finding the first phrase in the sentence that matches the longest prefix of the node.",we find a match for 91% KG nodes.,reasoning
821,dev_821,"This is quite intuitive, because edge labels carry important relational knowledge between the two connected nodes.",discarding these labels will cause loss of significant semantic information.,reasoning
822,dev_822,"Also, context vectors are used to predict slot gates, which is essential to be able to trigger the state generator.",using self-supervision to align contextual slot vectors may help get better attention distributions and better slot gate prediction.,reasoning
823,dev_823,"Also, each perturbed sample may generate slot values that have different number of words, and maintaining consistency of sequential distributions could be challenging.","we use slot gate distribution and attention distribution as intermediate targets since the former is the first stage for the whole prediction process, and the latter directly influences the copy mechanism.",reasoning
824,dev_824,"Since code completion is an important scenario, we would like to test model's ability in predicting the correct token merely based on preceding PL contexts.","we add an additional setting for PL side, where the input includes the complete NL documentation and preceding PL codes.",reasoning
825,dev_825,"TC is predominantly used in Taiwan, Hong Kong, and Macau, whereas SC is mainly adopted in mainland China and SC characters are simplified versions of TC characters in terms of strokes and parts.",chinese NLP practitioners apply script converters 1   dataset into their desired language.,reasoning
826,dev_826,"Although Hong Kong and Taiwan both use Traditional Chinese, they are stylistically different as the dominant spoken language in HK is Cantonese and in TW is Taiwanese Mandarin.",it is quite essential to test the performance of our algorithms on these two styles.,reasoning
827,dev_827,Orientation compares the extent to which an utterance aims to advance the conversation forwards with the extent to which it looks backwards.,we must somehow quantify how the utterance relates to the subsequent and preceding interaction.,reasoning
828,dev_828,"In all previous work, the summary length is weakly controlled by length embeddings or a soft length penalty (Zhou and Rush, 2019;Wang and Lee, 2018;Fevry and Phang, 2018;Baziotis et al., 2019).","the generated summaries by different systems vary considerably in average length, for example, ranging from 9 to 15 on a headline corpus (Section 4.1).",reasoning
829,dev_829,"We show that ROUGE F1 is unfortunately sensitive to summary output length, in general favoring models that produce longer summaries.",we argue that controlling the output length should be an integral part of the summarization task and that a fair system comparison can only be conducted between summaries in the same length bracket.,reasoning
830,dev_830,"Our model generates a candidate summary in a non-autoregressive fashion, in contrast to the beam search in Zhou and Rush (2019).","we are able to simultaneously consider forward and backward language models, using the geometric average of their perplexities.",reasoning
831,dev_831,"Second, our personal observation is that the Wikipedia conventions have gained some popularity among the online community since their first publication.",by opting for the Wikipedia conventions we remain close to other online content.,reasoning
832,dev_832,"Yet, existing corpora differ greatly in size, thematic focus, annotation quality, granularity of the underlying conceptual entity representation and the way individual entity classes are defined-even when different corpora cover the same entity classes.","merging all available annotations into one large corpus and regard it as a coherent source of gene/protein annotations (Wang et al., 2009;Wang et al., 2010;Galea et al., 2018) might not be advisable.",reasoning
833,dev_833,Since the original test sets for those domains are scarce (50 reviews each) we decided to use the original out-of-domain training set of 900 reviews for testing purposes and create the new split of development and test sets.,"the task consists of 1000 reviews, which is comparable in size to the in-domain test dataset of 1400 reviews.",reasoning
834,dev_834,"To increase the difficulty and diversity of the task, we filter out multiple abstracts from the same article.",there is at most one negative pair created from each pair of articles.,reasoning
835,dev_835,"Unlike most written languages in the world, the Chinese writing system does not use explicit delimiters (e.g., white space) to separate words in written text.","chinese word segmentation (cWS) conventionally serves as the first step in chinese language processing, especially for many downstream tasks such as text classification (Zeng et al., 2018), question answering (Liu et al., 2018), machine translation (Yang et al., 2018), etc.",reasoning
836,dev_836,"Although some studies sidestepped the idea by incorporating contextual n-grams (Pei et al., 2014;Zhou et al., 2017) or word attention (Higashiyama et al., 2019) into the sequence labeling process, they are limited in either concatenating word and character embeddings or requiring a well-defined word lexicon.",it has not been fully explored what would be the best way of representing contextual information such as wordhood features in neural CWS models.,reasoning
837,dev_837,"WMSEG provides a general way of integrating wordhood information for CWS, we expect other wordhood measures to play the same role in it.",we test PMI and DLG in our model and compare them with the previous results from AV (see Table 6).,reasoning
838,dev_838,"However, while existing abstractive summarization models are optimized to generate summaries that highly overlap with human references (Paulus et al., 2018), this does not guarantee factually correct summaries, as shown in Figure 1.",maintaining factual correctness of the generated summaries remains a critical yet unsolved problem.,reasoning
839,dev_839,"Despite these efforts, none of the existing work has focused explicitly on optimizing an abstractive summarization system with a correctness objective.","even state-of-the-art systems trained with ample data still produce summaries with a substantial number of factual errors (Goodrich et al., 2019; Kryscinski et al., 2019a).",reasoning
840,dev_840,"Due to the absence of ground truth summaries, the model is not trained to reconstruct the aggregate encoding of reviews, but rather it only learns to reconstruct the encoding of individual reviews.",it may not be able to generate meaningful text when the number of reviews is large.,reasoning
841,dev_841,"Different from the existing work that enhances the representation capability of models through neural architecture engineering, we turn to an orthogonal direction that we keep the generation model simple, and optimize the simple structure by learning with auxiliary tasks that encode context understanding.",our model can provide high-quality responses at a low cost.,reasoning
842,dev_842,The challenge requires a model to connect semantically related words and utterances.,we design masked content recovery tasks on both a word level and an utterance level to enhance the self-attention module in terms of awareness of the semantic connections.,reasoning
843,dev_843,The generation model of SNN is just a simple RNN sequence-to-sequence with one layer encoder and one layer decoder.,our model is comparable with SSN in terms of complexity and speed.,reasoning
844,dev_844,"In many cases, utterances are just formed by copying a proportion of words from the profiles.",recognizing the semantic connections and the relationship among words in contexts is more critical for the data.,reasoning
845,dev_845,"The problem that arises 
here is that since many disfluent words are copies 
of fluent words, if the same cost is used to align 
fluent and disfluent words, the alignment will be 
ambiguous (i.e. there will be multiple alignments with the same cost).","to force the aligner to 
prefer aligning null (i.e. deletions) for disfluent 
words and copy for fluent words, we modify the 
alignment weights so the intuitively correct alignment scores better, and so will be chosen by the 
alignment algorithm",reasoning
846,dev_846,"For each approach we compute a score, which we define as the percentage of examples where the annotator did not correctly identify the machinegenerated sentence.","a higher score implies a better (more natural, human-like) model.",reasoning
847,dev_847,"However, we observe that the lower left corner formed by the classes Family, Characteristics and Biographical Sketch is almost symmetric in its confusions, which led us to inspect and classify the types of errors.","we investigated all errors manually and classified them in three main types of errors: errors due to Ambiguity (39%), errors due to wrong Annotation (18%) and errors tagged as Other (42%) where the errors are more difficult to explain (see last column in Table 6).",reasoning
848,dev_848,This work addresses the question of how to automatically structure obituaries.,we acquire a new corpus consisting of 20058 obituaries of which 1008 are annotated.,reasoning
849,dev_849,"To avoid overlapping between f a and f c , we set f c as 0 if the cluster is the initial cluster (L6).","f c becomes the consultation such that when f c > 0, the span g x is likely to match the cluster C y , and vice versa.",reasoning
850,dev_850,"We note that the sentences comprised within the same cluster define similar contexts for the target word, hence implying that l is very likely to be used with the same meaning across sentences.",we associate each cluster with one of l's meanings and a disambiguation score.,reasoning
851,dev_851,"Furthermore, adverse effects may occur due to a combination of drugs.","our guideline instructs to label a span describing effects with all possible drugs, so that correspondences between drugs and effects are many-to-many.",reasoning
852,dev_852,"For these agreed sets of labels, we took the longest span attached to the exactly matching sets in order to complement the ambiguity in span identification.",we obtained 677 labelled spans of drug reactions on 169 weblog articles as summarised in Table 5.,reasoning
853,dev_853,"As discussed in Sec. 4.2., our annotation dataset consists of challenging examples that (a) have many-to-many correspondences between drugs and drug reactions, (b) require to distinguish drugs related to a specific reaction from other drugs prescribed together, and (c) require to label not only phrases but also sentences or even longer spans.",our dataset is also useful as an advanced dataset for existing aspect-based sentiment analysis and sequential labelling problems.,reasoning
854,dev_854,"They are particularly painful for patients who need long-term treatment, such as cancer patients.",information on adverse drug reactions is essential for medical practitioners to prescribe drugs that maximise the therapeutic effects while minimising the adverse drug reactions as much as possible.,reasoning
855,dev_855,"However, this did not scale well, as sometimes we received notice of a new wordnet, and it took us months to find time to write a converter.","we decided to try to shift this burden, as far as possible, to the individual wordnet projects.",reasoning
856,dev_856,"Some examples were: wordnets with no synsets, senses and synsets having different parts of speech, synsets with no part of speech, examples or definitions consisting of empty strings, different projects interpreting the directions of relations differently, definitions in unknown languages, projects including the PWN definitions, among others.","the new OMW system keeps adding an increasing number of extra checks on the content of uploaded wordnets, which warn the uploader of any problems before any upload is possible.",reasoning
857,dev_857,An example is that traditional Chinese includes about 17k distinct tokens.,it could be expected to suffer from underfitting not only word embedding but also character embedding.,reasoning
858,dev_858,"A three-layer transformer network, for example, would be denoted s fs f s f, with the flow of computation moving from input on the left to output on the right.",any string in the regular language (s|f) * defines a valid network that uses the same building blocks as the original transformer.,reasoning
859,dev_859,"For two attention mechanisms to be similar, they must put attention on the same parts of the text.",we first define a metric for quantifying the overlap in the words selected by human annotators and by deep learning models.,reasoning
860,dev_860,"However, 2 gold paragraphs may not be available in the Fullwiki Setting.",the Fullwiki setting is more challenge which requires to search the entire Wikipedia to find relevant documents.,reasoning
861,dev_861,"While Koh and Liang (2017) show that influence functions can be a good approximation even when the convexity assumption is not satisfied (in their case, a CNN for image classification), it is still not obvious that the influence function would work for BERT.","we conduct a sanity check: for each instance in our test set, we by turns remove the most positively influential 10%, the most negatively influential 10%, the least influential (where influence scores are near zero) 10%, and a random 10% of training examples.",reasoning
862,dev_862,"When removing a token with the most positive saliency score, we expect the model to be less confident about its current prediction; it could possibly make a different prediction.",we expect to see a most different influence distribution from the original influence result compared to removing the token with median or the most negative saliency score.,reasoning
863,dev_863,"We observe that targets and aspects interrelate in subtle ways, often yielding conflicting sentiments.","a naive aggregation of sentiments from aspects and targets treated separately, as in existing sentiment analysis models, impairs performance.",reasoning
864,dev_864,A context word can be associated with one or more targets.,capturing Target-Context relationships is pivotal.,reasoning
865,dev_865,"However, the publicly available datasets of MOOC are limited in size with few types of data, which hinders advanced models and novel attempts in related topics.","we present MOOCCube, a large-scale data repository of over 700 MOOC courses, 100k concepts, 8 million student behaviors with an external resource.",reasoning
866,dev_866,"Moreover, these datasets only contain a small size of specific entities or relation instances, e.g., prerequisite relation of TutorialBank (Fabbri et al., 2018) only has 794 cases, making it insufficient for advanced models (such as graph neural networks).","we present MOOCCube, a data repository that integrates courses, concepts, student behaviors, relationships, and external resources.",reasoning
867,dev_867,"However, existing taxonomies like ConceptNet (Liu and Singh, 2004) or Wiki Taxonomy (Ponzetto and Strube, 2007) cannot be directly applied to course concepts because course concepts are mostly academic terms and the non-academic categories greatly interfere with the quality of taxonomy.",we select a crosslingual term taxonomy from CNCTST 4 as a basis and lead manual annotation to build a serviceable course concept taxonomy for MOOCCube.,reasoning
868,dev_868,"However, labeling all possible pairs is infeasible, for 100K concepts may generate over 500 billion candidate pairs.",we lead a distantly supervised annotation in three stages.,reasoning
869,dev_869,"Second, we base our experiments on a dataset derived from the Enron corpus (Klimt and Yang, 2004) which consists of email exchanges in an American corporation.",we restrict our attention to the notion of politeness as widely accepted by the speakers of North American English in a formal setting.,reasoning
870,dev_870,"In each round, 1.67% of the entire parallel corpus is selected and added into the training corpus.",we ensure the token budget is 20% of the entire parallel corpus in the final round.,reasoning
871,dev_871,"For instance, humans have been found to use their knowledge about typical colours of an object when perceiving an instance of that object, in order to compensate for, e.g., perceptually challenging illumination conditions and achieve colour constancy (Mitterer and de Ruiter, 2008;Witzel and Gegenfurtner, 2018).","the visual perception of object colours can be thought of as leveraging top-down knowledge for bottom-up processing of sensory input, in accordance with traditional approaches in psychology (e.g.",reasoning
872,dev_872,"We also tried visual features extracted with a neural object recognizer (Simonyan and Zisserman, 2014) which only give a small improvement over colour histograms.","in Section 4, we report results only for RGB histograms, as they are more transparent as representations and do not include any conceptual information on objects.",reasoning
873,dev_873,This component relies only on conceptual information about the object which consists of assignments of objects to object types and colour distributions for object types reflected in the data.,"this classifier predicts colour terms given only the object type, which is supposed to mimic the memory colour effect discussed in Section 2.",reasoning
874,dev_874,"For CBOs, there is still a clear improvement over BOTTOM-UP, whereas for CNOs the model mostly relies on BOTTOM-UP.","even though the fusion is hard-coded, it achieves the desired flexible pattern for combining the components.",reasoning
875,dev_875,"Both context coherence and response fluency (quality metrics) can naturally be captured by metrics based on strong language models like GPT-2 (Radford et al., 2019).",we propose to recruit and fine-tune GPT-2 as a basis of our quality metrics.,reasoning
876,dev_876,We define gender bias in NRE as a difference in model performance when predicting on sentences from male versus female articles.,we need articles written about entities for which we can identify the gender information.,reasoning
877,dev_877,"However, to obtain gender information for existing annotated datasets could be costly or impossible.",we elected to create WikiGenderBias with this gender information to be able to detect scenarios like that in Figure  1.,reasoning
878,dev_878,Many of these entities have gender information and their corresponding articles are readily available.,we create our dataset based on sentences extracted from Wikipedia.,reasoning
879,dev_879,"Besides, Wikipedia includes more articles written about males than about females.",there are more male instances than female instances in WikiGenderBias as well.,reasoning
880,dev_880,"Equality of Opportunity (EoO) was originally proposed to measure and address allocative biases (Hardt et al., 2016).",we examine this metric in the context of relation extraction to better understand how allocative biases can begin to emerge at this stage.,reasoning
881,dev_881,A solution to reduce the computational burden of these networks is to lower numerical precision.,"numerical values can be represented using fewer bits (Tang and Kwan, 1993;Marchesi et al., 1993).",reasoning
882,dev_882,A major advantage to delaying quantization is to perform more training steps in the same given amount of time.,"when training time is a constraint, a possible strategy is to train a model without quantization, perform more training steps and finally post-quantize the model.",reasoning
883,dev_883,"Figures 1b and 1d show, that the accuracy of the negative class drops from 0.95 to 0.88 and that the number of negative samples classified as positive raises from 5% to 12%.",we recommend training BERT models on the balanced data set.,reasoning
884,dev_884,The resulting models achieved both lower accuracy on the negative class.,we recommend training these models on the balanced data set.,reasoning
885,dev_885,"Further, due to the limited position index during pre-training, most Transformer-based models have a maximum capacity of input tokens.","they often truncate the length of a document to satisfy the length limitation of the encoder, which may lose some important semantics, especially for long documents.",reasoning
886,dev_886,"Topic embedding with masked attention (TEMA): Since a topic is a distribution over tokens in the vocabulary, we use the mixture of token embeddings to represent the corresponding topic embedding.",topics with large proportions for a document can be considered as extra input tokens of the decoder.,reasoning
887,dev_887,"Secondly, the Transformer models are getting bigger and bigger (Sanh et al., 2019), resulting in a fact that it is almost impossible to pre-train such a big model on a personal computer.","models with plug-andplay property are attractive to Transformer-based models (Dathathri et al., 2019).",reasoning
888,dev_888,"Compared with BertSUM that ignores the subsequent document-tokens, BertSUM+TA is able to reserve these information in some degree, since the topic model extracts global semantics from all tokens in the document.","with the increase of the document length, the improvement produced by TA gets more evident.",reasoning
889,dev_889,"Clearly, TA introduces a few parameters, less than 10%.",tA has a friendly memory footprint to the transformer models.,reasoning
890,dev_890,"It can be seen that a small number of topics are inadequate to express all the semantics, while too many topics are redundant and introduce more learnable parameters.",we set 256 topics in all experiments.,reasoning
891,dev_891,"Ideally, if we can learn the expressions representing for a certain action or domain and how they compose an utterance for existing intents, then we can learn how to compose utterances for few-shot intents naturally.",we define an intent as a combination of a domain and an action.,reasoning
892,dev_892,"We find that MaxProb gives good confidence estimates on in-domain data, but is overconfident on OOD data.","maxProb performs poorly in mixed settings: it does not abstain enough on OOD examples, relative to in-domain examples.",reasoning
893,dev_893,"In this paper we want to show, analysing a particular procedure applied for lexico-semantic annotation of BCPM, that in practice such a single choice may consist of a chain of interdependent decisions, and annotators can agree or disagree at every step.",we have to value each such decision separately and then combine the result.,reasoning
894,dev_894,"The PCC (Ogrodniczuk et al., 2015), in turn, is randomly selected from the whole NKJP corpus.",bCPM as a whole is part of NKJP.,reasoning
895,dev_895,"Typical MWEs may be compositional (e.g. dawka śmiertelna ‘deadly dose’ is a ‘dose’) or not (e.g. there is not a meaning for centrum ‘centre’ for centrum handlowe ‘shopping centre’, ‘mall’",we decided to allow linguists to optionally annotate elements of MWEs.,reasoning
896,dev_896,"Most existing data-driven approaches for Word sense disambiguation (WSD) build word-specific classifiers to predict the right sense of a word instance, which lack the capability to generalize across words and therefore require sufficient sense-annotated data for every word (de Lacalle and Agirre, 2015) in order to disambiguate them well.",the model's performance decreases significantly when there is a lack of training data for a word or some of its senses.,reasoning
897,dev_897,"In addition, the sense inventory WordNet (Miller et al., 1990) contains an example for many word senses and the well-composed example (Table 2) can precisely illustrate essential semantic or syntactic constraints in adopting a word sense.","we use the example of a word sense, if available, as a prototype in a regularization component of the shared model for guiding the WSD system to concentrate on most relevant segments of a word context.",reasoning
898,dev_898,"The example provided by the sense inventory WordNet (Miller et al., 1990) for each word sense, if available, clearly illustrates essential semantic or syntactic constraints for adopting a word sense in a real sentence.","the shared model measures correspondence between a sense prototype and a word context as well, with both the prototype and context encodings attended by the gloss encoding.",reasoning
899,dev_899,Note that the metric for the STS-B task is Pearson and Spearman scores.,we measured the validation Pearson score instead of validation accuracy for choosing influential attention heads for the STS-B task.,reasoning
900,dev_900,They are what the sender suggests to the receiver of the message and that must be decoded and understood : it is a non-literal or implicit message.,"of the several steps that led to our reference corpus, we were able to identify three categories reflecting the intention expressed by the speaker by producing a statement and more precisely a question : opinion, will and doubt.",reasoning
901,dev_901,"However, we found that directly optimizing prompts guided by gradients was unstable and often yielded prompts in unnatural English in our preliminary experiments.","we instead resorted to a more straightforward hillclimbing method that starts with an initial prompt, then masks out one token at a time and replaces it with the most probable token conditioned on the other tokens, inspired by the mask-predict decoding algorithm used in non-autoregressive machine translation (Ghazvininejad et al., 2019): 9 where w i is the i-th token in the prompt and t r \ i is the prompt with the i-th token masked out.",reasoning
902,dev_902,"Further analysis reveals that about 12.6% of dev questions and 15.7% test ones are considered unanswerable by crowd workers, which is a byproduct of the information-asymmetric setting adopted when the data was collected.","many reference questions could be considered uninformative by our definition, since they might cause the QA model to abstain from answering.",reasoning
903,dev_903,"As each sentence pair generates a unique encoding, common optimisations that allow for faster computations cannot be employed.",we exclude this model from our study of the dialogue act clustering task.,reasoning
904,dev_904,"As can be seen, BERT-Large significantly outperforms all non-BERT baselines by a big margin, regardless of whether query expansion is used.",only significance tests relative to BERT-Large are shown.,reasoning
905,dev_905,"The importance of these knowledge has been verified by tasks at different level, for instance, sentence-level sentiment classification (Taboada et al., 2011;Shin et al., 2017;Lei et al., 2018), aspect-level sentiment classification (Vo and Zhang, 2015;Zeng et al., 2019), opinion extraction (Li and Lam, 2017;Gui et al., 2017;Fan et al., 2019) and so on.","we assume that, by integrating these knowledge into the pre-training process, the learned representation would be more sentimentspecific and appropriate for sentiment analysis.",reasoning
906,dev_906,An aspectsentiment pair refers to the mention of an aspect and its corresponding sentiment word.,a sentiment word with its nearest noun will be considered as an aspect-sentiment pair.,reasoning
907,dev_907,Aspect sentiment pairs reveal more information than sentiment words do.,"in order to capture the dependency between aspect and sentiment, an aspectsentiment pair objective is proposed.",reasoning
908,dev_908,The reason why we employ the conventional named semantic roles is that the named semantic roles are intuitively more understandable for humans compared to the numbered roles.,"the named roles are expected to be used in queries when language learners or linguists want to extract example sentences that, e.g., contain ""Experiencer"" arguments in the emotional sense, or ""Source"" arguments in the moving sense.",reasoning
909,dev_909,"However, the composed meaning of the light verb construction, i.e., the chat frame and the verb 'oshaberi-sur-u' (chat-do-PRS) are assigned to the light verb 'shi-ma-su'.",the role sets of the chat frame are applied to the arguments and adjuncts except for 'oshaberi o' (ArgM PRX).,reasoning
910,dev_910,"The recipient 'imooto-ni' (sister DAT) must be part of a construction (Goldberg, 1995).",the recipient can be considered as an argument because the recipient appears depending on the create frame.,reasoning
911,dev_911,"In the Contacting frame, the recipient role is defined as the Addressee role that indicates a core role (i.e., an essential argument).",both English language resources offer an analysis that is the same as our analysis for the Japanese data.,reasoning
912,dev_912,"The results show that the accuracies of semantic role annotation systems are almost the same as the current quality of named semantic roles, for results near to the achievements of previous work.",we can estimate that the quality of the annotated semantic roles are highly promising.,reasoning
913,dev_913,"Although these explorations have achieved promising results, they are still limited to those specific KGs whose entities have additional text information.","reasoning over sparse KGs is still an important but not fully resolved problem, and requires a more generalized approach to this problem.",reasoning
914,dev_914,"In this task, we give the model more explicit and strong cross-lingual training signals.","the encoder has the ability to perform simple word translation, and the burden on the ST decoder is largely reduced.",reasoning
915,dev_915,The model achieves the best performance when we choose N = 8.,we use this strategy in our main experiments.,reasoning
916,dev_916,The original datasets do not have all mention boundary labels annotated.,"in order to evaluate both mention detection and entity disambiguation, we extend previous labels and create new end-to-end question entity-linking datasets, WebQSP EL and GraphQ EL .",reasoning
917,dev_917,"Moreover, these results concern the expressive power of Transformers and do not apply to learning and generalization abilities.",transformers' ability to model formal languages requires further investigation.,reasoning
918,dev_918,"Instead of binding our vokenizer to a specific pre-training framework (e.g., BERT), we want to enable its extensibility to other frameworks (e.g., RoBERTa).","we introduce a ""revokenization"" technique to address this limitation.",reasoning
919,dev_919,The vokenization runs at a speed of 100K tokens / second with 4 Titan V100 GPU.,the vokenization of the full Wikipedia is finished in 8 hours.,reasoning
920,dev_920,It also provides information on how the answer can be derived from the question.,the complexity of the questions can be increased based on the supporting knowledge base.,reasoning
921,dev_921,Our model is different from the previous methods since we use pre-trained image and language features and fuse them with KG embeddings to incorporate the external knowledge into the VQA task.,our model does not need additional knowledge annotations or search queries and reduces computational costs.,reasoning
922,dev_922,The answers to these type of questions often are entities out of the main entities in the question and the visual features in the image.,the information extracted from the knowledge graph plays an important role in determining the answer.,reasoning
923,dev_923,"The translation workload was divided into 10 batches for each language, which were submitted separately to Gengo.",different parts of the dataset might have been translated by different translators.,reasoning
924,dev_924,"The idea of face acts appears quite attractive from a computational standpoint for their potential role in understanding what is ""meant"" from what is ""said"" (Grice et al., 1975; Brown et al., 1987; Leech, 2016).","politeness has been widely researched in various domains of language technologies (Walker et al., 1997; Gupta et al., 2007; Wang et al., 2012; Abdul-Mageed and Diab, 2012; Danescu-Niculescu-Mizil et al., 2013) in addition to foundational work in pragmatics and sociolinguistics (Brown et al., 1987; Grice et al., 1975; Leech, 2016).",reasoning
925,dev_925,"However, much prior work modeling politeness reduces the problem to a rating task or binary prediction task, separating polite and impolite behavior.","what the models end up learning is mainly overt markers of politeness or rudeness, rather than the underlying indirect strategies for achieving politeness or rudeness through raising or attacking face, even in the indirect case where no overt markers of rudeness or politeness might be explicitly displayed.",reasoning
926,dev_926,"Different from the SQuAD-style question answering where there is no specific requirement for the position of the predicted span, in bridging anaphora resolution, an anaphor must appear after its antecedent.","in the inference stage, for each bridging anaphor a, we first identify the position of a in its context c a , then we only predict text spans which appear before a.",reasoning
927,dev_927,"This gives us a quasi-bridging example with two adjacent sentences (i.e., s y and s x ) and a bridging link (i.e., justicethe obstruction).","we obtain a large amount of ""quasibridging"" training data (i.e., around 2.8 million bridging pairs) by applying the method described above to the NYT19 section of the automatically parsed Gigaword corpus.",reasoning
928,dev_928,"Last but not least, CASIE has not been comprehensively evaluated with the state-of-the-art ED systems, making it challenging to accurately estimate the difficulty/complexity of the dataset.","in this work, we introduce a novel dataset for cybersecurity ED (called CySecED) that is manually annotated for 30 event types to better characterize the important cyber attacks and vulnerabilities reported in texts.",reasoning
929,dev_929,"For target sentiment analysis, both shared information of both sub-tasks and private information of each sub-tasks should be considered.","a shared network is designed to encode shared information between the two sub-tasks, such as semantic and syntactic information of the input sentence.",reasoning
930,dev_930,"In addition, shared features generally portray common information between the two sub-tasks, like semantic and syntactic information, which also exist in other NLP tasks.","the prevalent model of Bidirectional Encoder Representations from Transformers (BERT) (Devlin et al., 2018), which is a pre-trained bidirectional Transformer encoder that achieves state-of-the-art performances across a variety of NLP tasks, is chosen as the shared network.",reasoning
931,dev_931,"Secondly, SPRM achieves 0.66%, 4.25%, and 1.76% absolute gains on three datasets compared to the best SPAN method SPAN-pipeline, indicating the efficacy of the Shared BERT.","sPRM can get better performance with fewer parameters compared to sPAN-pipeline, which employs two separate BERT encoding network for target extraction and target classification, respectively.",reasoning
932,dev_932,"Besides, SPRM with BERT-Base outperforms SPAN-pipeline with BERT-Large, which uses almost 5 times the trainable parameters of SPRM with BERT-Base.",the introduction of Shared BERT can not only connect the task of target extraction and target classification to some extent but also reduce the parameter number.,reasoning
933,dev_933,"Collocations are numerous in every language, and due to their idiosyncratic nature, they pose considerable problems for non-native speakers.","there is a strong need to include them in dictionaries, and they have received considerable attention in lexicography.",reasoning
934,dev_934,"In other words, they simplified both tasks by avoiding the challenging task of identifying the locations of argument components.",their approach cannot be applied in a realistic setting where the input is an unannotated text.,reasoning
935,dev_935,This is largely because argumentative relationships can occur between ACs in non-adjacent sentences.,a deeper semantic understanding of ACs is necessary in order to develop features or heuristics for detecting argumentative relationships between them.,reasoning
936,dev_936,The paraphrased references had only minor changes and consequently only minor impact on the automatic metrics.,we changed the instructions and asked linguists to paraphrase the sentence as much as possible while also suggesting using synonyms and different sentence structures.,reasoning
937,dev_937,We generated our paraphrased reference translation with the instructions to modify the translations as much as possible.,"the non-translationese, perhaps more natural, nature of the paraphrased translations make it more demanding to assign an accurate rating.",reasoning
938,dev_938,"As mentioned above, relevant entity mentions and their types are only annotated for sentences containing experiment information and neighboring sentences.",we here compute agreement on the detection of entity mention and type assignment on the subset of 90 sentences that both annotators considered as containing experimental information.,reasoning
939,dev_939,"Spatial domain queries have several unique properties making them be more challenging for language understanding than common conversational queries, including lexicalsimilar but diverse intents and highly ambiguous words.",a special tailored LU framework for spatial domain queries is necessary.,reasoning
940,dev_940,"Considering that entities are quite diverse and ambiguous, and entities with the same name may belong to different tags.",we will make full use of the tag information of each mention and candidate entities to overcome the ambiguity of entities.,reasoning
941,dev_941,"While some pre-trained models trained with web texts or Wikipedia are public, our preliminary results indicate that fine-tuning of a pre-trained model trained with the same corpus has a better performance.",we performed pre-training from scratch.,reasoning
942,dev_942,"When a sentence describing a complex situation is used in a hypothesis, it is difficult to find the entailing premise sentences.",we decided to use only short token sentences as hypothesis sentences.,reasoning
943,dev_943,"For example, in our experience, we found that errors in entity linking have an adverse effect on learning relation extraction model.","when creating crowdsourcing data, we decided that using a common source text rather than using different source texts for each task would be helpful for the overall analysis of information extraction.",reasoning
944,dev_944,"Second, even the same entity may tagged with different grade and types of entities depending on context and worker.",the final data is created by merging the results of two people's work.,reasoning
945,dev_945,"However, there is not a Korean related work there, and it is not easy to gather Korean worker.","we use Crowdworks 1 platform, which is the representative of Korean crowdsourcing companies.",reasoning
946,dev_946,We found that the most useful features were lemmas and part-of-speech tags.,we discarded the rest of features and conducted experiments to find out the optimal window for which lemma and PoS tags features should be added.,reasoning
947,dev_947,"During the feature tuning process, we discovered that the least informative features were dep rel (44, 45), is ancestor (48, 49), heads second order (46, 47) and path length (53).","we conducted experiments removing all these features and the two least informative 8 (45, 49), but the results did not improve the initial experiment.",reasoning
948,dev_948,"Therefore, we conducted experiments removing all these features and the two least informative 8 (45, 49), but the results did not improve the initial experiment.",we decided to select the initial set (24 features in total) as features for reporting results with the test set.,reasoning
949,dev_949,"(iii) In the gold data (dev+train), a majority of scopes begin in the negation cue (69.50%).",the system tends to take the negation cue as the start of the scope.,reasoning
950,dev_950,"A relatively small decrease in the weights of high-frequency tokens will prevent the generation probabilities of ground-truth tokens from ascending continually, which may result in an obvious degradation of the overall performance.",we ensure that all the token weights are equal to or bigger than 1 considering the training stability as well as designing convenience.,reasoning
951,dev_951,"In this case, we don't consider the factor of noisy tokens so that the weight increases monotonically as the frequency decreases.",this weighting function is suitable for cleaner training data where the extremely low-frequency tokens only take up a small proportion.,reasoning
952,dev_952,"While the aforementioned vanilla transformer is a powerful method, it is less suitable for video paragraph captioning due to its inability to utilize video segments and sentences history information.","given the unified encoder-decoder transformer, we augment it with an external memory module, which helps it to utilize video segments and the corresponding caption history to generate the next sentence.",reasoning
953,dev_953,"Current metrics, such as BLEU, ROUGE and METEOR, are agnostic to the end-task while LERC is trained with the passage and question as input.",lERC assigns a score that better reflects human judgement.,reasoning
954,dev_954,"This raises an issue with the evaluation; a metric can look strong when evaluated on current model outputs, but may in-fact struggle in the future when QA systems produce better answers.",using only these candidates for evaluation could lead to overconfidence in a learned metric's capabilities.,reasoning
955,dev_955,One explanation is that current generative QA models may not generate many candidates that would require the metric to use the passage.,even the complete version of LERC may have learned to ignore the passage.,reasoning
956,dev_956,"Besides a small number of high-resource sentence functions, a large portion of sentence functions is infrequent.",dialogue generation conditioned on these infrequent sentence functions suffers from data deficiency.,reasoning
957,dev_957,"In meta-learning, the goal of the trained model is to quickly learn a new task from a small amount of data.",the model should be able to learn transferable knowledge on a large number of different tasks.,reasoning
958,dev_958,"For example, in the recently released response generation dataset with manually annotated sentence functions STC-SeFun (Bi et al., 2019), more than 40% of utterances are Positive Declarative while utterances annotated with Declarative with Interrogative words account for less than 1% of the entire dataset.",dialogue generation models suffer from data deficiency for these infrequent sentence functions.,reasoning
959,dev_959,"Although we can not compare intervals at ordinal scale, we know, e.g., that ""neutral"" is closer to ""positive"" than ""negative"".",we need another property to verify monotonicity with respect to category closeness.,reasoning
960,dev_960,"This is a metric that integrates aspects from the previous three metric families, including two parameters β1 and β2 to combine different components.",this metric can capture the different quality aspects involved in the OC process.,reasoning
961,dev_961,"Moreover, there are proofs that these poor performances are not influenced by factors such as age, sex, confidence, and experience and that professionals such as psychologists, detectives and judges are no more accurate than students and other citizens in this task (Aamodt and Custer, 2006).",the possible dangers associated with the mentioned phenomena made necessary the development of new approaches for unmasking deceit not relying on human judgement.,reasoning
962,dev_962,"When applied to classification tasks like language recognition, RNNs are typically combined with a ""decoder"": additional layer(s) that map their hidden states to a prediction.","despite differences in state expressiveness, rational RNNs might be able to achieve comparable empirical performance to non-rational RNNs on NLP tasks.",reasoning
963,dev_963,"However, we also construct a language that an LSTM can recognize without a decoder, but a QRNN cannot recognize with any decoder.",no decoder can fully compensate for the weakness of the QRNN compared to the LSTM.,reasoning
964,dev_964,"Finally, we conduct experiments on formal languages, justifying that our theorems correctly predict which languages unsaturated recognizers trained by gradient descent can learn.",we view our hierarchy as a useful formal tool for understanding the relative capabilities of different RNN architectures.,reasoning
965,dev_965,"On the other hand, the value of the RNN and GRU cell is bounded by 1, and QRNN and LSTM cells can only grow linearly in time.",these encoders cannot compute f b .,reasoning
966,dev_966,We then use the decoder as an oracle to decide any RE language.,an RR-complete encoder with an RE decoder is Turing-complete.,reasoning
967,dev_967,Note that we define decoders as functions from the final state to the output.,"adding an additional QRNN layer does not count as a ""decoder"" (as it reads multiple states).",reasoning
968,dev_968,"We subsidiarily annotated two types of event attributes with each bounding box: ""doing-the-action,"" or ""done-the-action"".","of the annotation, we got 2,300 bounding boxes in 272 flow graph recipes.",reasoning
969,dev_969,And some bounding boxes may be linked to the same r-NE because the object can be multiple or separated in the image.,the relationship from bounding boxes to r-NEs is so-called one-to-many.,reasoning
970,dev_970,"As the recipes for our r-FG-BB dataset, we selected, from the r-FG corpus, those having an image to each step.",we had 70 recipes.,reasoning
971,dev_971,"In the computer vision community, researchers build their datasets with bounding boxes that have IoUs larger than 0.5 (Su et al., 2012; Papadopoulos et al., 2017).",we can say that many annotated bounding boxes are suitable for the dataset.,reasoning
972,dev_972,"In our r-FG-BB dataset, some bounding boxes are connected through the flow graph.",we can try an interesting novel task: bounding box linking.,reasoning
973,dev_973,"Procedural text generation from an image sequence is a prominent area because it requires a model to consider the context and the output coherency (Nishimura et al., 2019; Chandu et al., 2019).","these studies focused on generating grounded captions: incorporating a structure into the model implicitly (Chandu et al., 2019) and preferentially decoding important terms (Nishimura et al., 2019).",reasoning
974,dev_974,"The results showed that the proposed simple models could ground bounding boxes with nodes in a flow graph, which gives a linking between the bounding boxes over images while classifying event attributes correctly.",our dataset is useful for contextual visual grounding.,reasoning
975,dev_975,Chr-to-En is also highly meaningful in helping spread Cherokee history and culture.,"in this paper, we contribute our effort to Cherokee revitalization by constructing a clean Cherokee-English parallel dataset, ChrEn, which results in 14,151 pairs of sentences with around 313K English tokens and 206K Cherokee tokens.",reasoning
976,dev_976,"If only one of the two language models' vocabularies contains a given type, then the language model that is missing the type gives a probability of 0.","the interpolated probability for that type would be (p+0)/2, where p is the probability from the language model that contains that type.",reasoning
977,dev_977,"While some recent papers on knowledge-grounded dialogues have paid attention to the problem of knowledge selection (Lian et al., 2019; Kim et al., 2020; Ren et al., 2019), the knowledge selection module is either deeply coupled with the specially configured models (Lian et al., 2019; Ren et al., 2019) and thus is incompatible with the pre-trained language models, or it is learned with human annotations (Dinan et al., 2019; Kim et al., 2018) which are difficult to obtain in practice (e.g., the dataset in (Zhou et al., 2018b) does not contain annotations for knowledge selection).",we propose an unsupervised approach where learning of knowledge selection and fine-tuning of response generation are jointly conducted with unlabeled dialogues.,reasoning
978,dev_978,"The learning algorithm starts from training with pseudo ground-truth that is constructed by making full use of responses as an alternation of human annotations, and then alternatively updates the knowledge selection model and the response generation model through a reinforcement learning approach and a curriculum learning approach respectively.","knowledge selection is further optimized with the feedback from response generation, and the knowledge used for fine-tuning the response generation model gradually moves from the pseudo ground-truth to the prediction of the knowledge selection module.",reasoning
979,dev_979,"We choose BERT (Devlin et al., 2018) as the backbone of the encoder.","the encoder can take advantage of pre-training, and the multi-layer bidirectional attention mechanism in BERT allows a dialogue context and the associated knowledge to sufficiently interact with each other, resulting in context-aware knowledge representations.",reasoning
980,dev_980,"However, many of the existing pruning methods rely on classic regularizers that act on the individual weights by penalizing them to zero (Guo et al., 2019;Sanh et al., 2020).","the pruned model tends to maintain the same architecture as the original model despite the reduced parameter count, which does not practically lead to an improvement in inference latency (Wen et al., 2016).",reasoning
981,dev_981,"While intimacy generally refers to the closeness and interdependence of partners, the extent of self-disclosure, and the warmth or affection experienced within the relationship (Perlman and Fehr, 1987), the concept of intimacy is not restricted to the closeness or interactions between people in intimate relationships, as even people who are not in intimate relationships can have intimate interactions in a certain space and time (Wynne and Wynne, 1986).","a widely-accepted conceptualization of intimacy is to distinguish between intimate interactions and intimate relationships (Hinde, 1981).",reasoning
982,dev_982,"However, individuals are less adherent to these norms as they perceive themselves to be anonymous or when interacting with an individual whom they perceive they will not interact with again (Rubin, 1983; Wynne and Wynne, 1986; Dindia et al., 1997); without the potential loss of face or social capital in such circumstances, individuals are more likely to engage in more intimate communication.",the norms of a social context and expectations around the loss of social capital for violations of these norms act as primary drivers of selecting the degree of intimacy expressed in a given context.,reasoning
983,dev_983,"Second, each sentence in the document are mapped to the node it is most related to.",2 each node will have its own sentence sets.,reasoning
984,dev_984,"The distributional hypothesis suggests that similar (key)words appear in similar contexts (Firth, 1957).",the co-occurrence rate between two keywords reveals helpful clues for their relatedness.,reasoning
985,dev_985,"Our model offers an elegant way to learn features directly from large corpora, bypassing the dependence on mature NLP pipelines.",it is not limited to resource-rich languages and can be used by any applications that operate on text.,reasoning
986,dev_986,"Table 5 clearly shows that ZAP fails to transfer many predicates, perhaps because it has unreliable (or no) word-alignment probabilities for infrequent predicates and it is not fine-tuned for this domain (it was trained on Europarl).","also the argument scores are very low, since for each predicate it misses, the system cannot recover any arguments.",reasoning
987,dev_987,"In some way, an explicit reordering model can be regarded as a LM which constrains candidate words to come from the input sentence.","it may suffer from the same problem as unidirectional LMs: at one time, contexts from only one direction can be utilized instead of from both directions.",reasoning
988,dev_988,"As the attention operation is quadratic to the sequence length, this fundamentally limits the maximum length of the input sequence, and thus restricts the model capacity in terms of capturing long-distance dependencies.","downstream tasks have to either truncate their sequences to leading tokens (Nogueira and Cho, 2019) or split their sequences with a sliding window (Joshi et al., 2019a,b).",reasoning
989,dev_989,"All the models follow the BERT-Base setting, i.e., L = 12, H = 768, A = 12, and are trained on the same corpus -BooksCorpus and English Wikipedia with uncased word piece tokens.","all models use the same vocabulary as Google BERT (uncased version) with vocabulary size 30,522.",reasoning
990,dev_990,"Due to the large size of model parameters and deep architectures, modern neural networks training requires significant amounts of computing resources.","there is an increasing interest in training neural networks with low memory (Sohoni et al., 2019).",reasoning
991,dev_991,"However, due to the insufficient support for sparse tensors from the current deep learning platforms, some of them have to represent a sparse matrix using a dense matrix with a binary mask or rely on customized CUDA kernels (Gray et al., 2017).",the speed-up or reduction in memory consumption is sometimes limited in practice.,reasoning
992,dev_992,"In addition, some puns are created by replacing a word with another word with the same or similar pronunciation as examples shown in Table 1.","to recognize puns, it is essential to model the association between words in the sentence and the pronunciation of words.",reasoning
993,dev_993,Note that we use the average pooling as an alternative when we remove the phonological attention module.,we can see the drop after removing each of the three features.,reasoning
994,dev_994,"Note that when we extract emotion-cause pairs, we obtain the emotions and causes for each text simultaneously.",we also evaluate the performance of emotion extraction and cause extraction.,reasoning
995,dev_995,"For speech recognition, we stream the audio recorded by the headset to IBM Watson servers to receive a transcription, which is then analyzed in a command-based fashion.","our speech module not only handles dictations as in Teixeira et al. (2019), but can correct mistakes in place.",reasoning
996,dev_996,"As with other methods, once a surrogate is assigned, it is held out.",less frequent words are assigned to the next most locally frequent surrogate.,reasoning
997,dev_997,"The aspects are regarded as instances and their sentiment distributions are predicted by an attention-based classifier, while the document is regarded as a bag and its sentiment distribution is computed as a combination of the aspect-level sentiment distributions.",we provide a framework for learning aspectlevel classifier by optimizing the document-level predictions.,reasoning
998,dev_998,"Aiming at easily detect texts and the respective seed URLs, without introducing relevant query biases, we decided to avoid using the category names as query keywords (SchÃƒÂ¤fer and Bildhauer, 2013).",we associated to each category a set of TA keywords belonging to the basic Tunisian vocabulary.,reasoning
999,dev_999,We also tried to learn the writing style from the click-baity headlines since they have shown superior attraction to readers.,"we used The Examiner -SpamClickBait News dataset, denoted as the Clickbait dataset.",reasoning
1000,dev_1000,We analyze the differences in performance on the three languages and show that the reasons for this failure are due to the composition and quality of the k-best lists.,"we show that the gold tree ratio in the English k-best list is much higher than for German and Czech, and that the trees in the English k-best list show a higher variety, thus making it easier for the reranker to distinguish between high-and low-quality trees.",entailment
1001,dev_1001,"We frame the detection problem as a binary classification task: given an excerpt of text, label it as either human-written or machine-generated.",we are interested in how variables such as excerpt length and decoding strategy impact performance on this classification task.,entailment
1002,dev_1002,"In such a scenario, the exclusivity of the relation between the nodes Donald Trump and US will be much higher than the exclusivity of the relation between the nodes John Smith and US, as in the full knowledge graph, the relation is the president of is much less common than the relation is a citizen of.","the stronger the exclusivity of the relation between the two nodes, the higher their semantic relatedness.",entailment
1003,dev_1003,"It does not mention how the articles should be structured, how complex should be the concepts used, or how difficult the inferences that reader needs to make in order to understand the text should be.","we can expect Simple English Wikipedia to be lexically and syntactically simpler than the original English Wikipedia, but not necessarily conceptually simpler.",entailment
1004,dev_1004,"For the efficient collection of dialogue data in various domains, we propose a collection platform using gamification.",we target collecting task-oriented dialogues.,entailment
1005,dev_1005,The table indicates large proportion of annotation disagreement between the annotators involves the CONvey tag.,confusing the CONvey and RE-Quest tags is prominent.,entailment
1006,dev_1006,Generating diverse question-answer pairs is crucial to the performance of downstream RC models.,"diversity of answer spans ensures that various parts of the passage are used, and different question types are generated.",entailment
1007,dev_1007,We can see that using synthetic data from any of the four domains significantly improved the performance for SQuAD.,"when training the RC model with data from all domains + SQuAD training data (last row), there is a large gain in both EM (3.8) and F1 (2.7).",entailment
1008,dev_1008,"Several studies have incorporated a human in the term collection process (Godbole et al., 2010;Coden et al., 2012).","dictionaries are built in an interactive process where the human gives feedback to the machine and the machine suggests candidates based on the given feedback (Alba et al., 2017, 2018)",entailment
1009,dev_1009,HB enjoys both benefits of coverage by LR and quickness by +Fd(p).,"a conventional classifier and our method are complementary; LR becomes favorable when the user prioritizes coverage than quickness, and +Fd(p) becomes favorable when vice versa.",entailment
1010,dev_1010,We use our recast datasets to explore how well different common classes of NLI models capture temporal reasoning.,"we use three types of models: (i) neural bag of words (NBOW; Iyyer et al., 2015) (ii) InferSent (Conneau et al., 2017), and (iii) RoBERTa (Liu et al., 2019).",entailment
1011,dev_1011,"To this end, we made several assumptions about the distribution, modeled the distribution accordingly, and validated each assumption by comparing the goodness of each model.",we considered two types of word classes-the semantic class of direct objects of a verb and the semantic class in a thesaurus-and tried to build models that properly estimate how likely it is that a word in the vector space is a member of a given word class.,entailment
1012,dev_1012,We assumed that the vectors of the words that do not belong to the target word class can be essential clues to distinguish a possible member of a word class from others.,we explored a model based on the offset between positive and negative instances and discriminative learning-based models to investigate the impact of negative instances.,entailment
1013,dev_1013,The results in these tables indicate that the models considering the geometry of the distribution or the existence of subgroups in the word class outperform the centroid-based model (CENT) for both the English and Japanese SP datasets.,a simple Gaussian model (GM) performed the best among the models that only depend on positive instances.,entailment
1014,dev_1014,"Rather than targeting topicdependent models, we target a subclass of arguments.",we focus on arguments that have been classified by Walton et al. (2008) under the argument from consequences scheme.,entailment
1015,dev_1015,"However, it is not true for many NLP tasks due to their pragmatic nature where the meaning of the same sentence might differ depending on the context or background knowledge.","for the NLI task, Manning (2006) advocate that annotation tasks should be ""natural"" for untrained annotators, and the role of NLP should be to model the inferences that humans make in practical settings.",entailment
1016,dev_1016,"It employed 50 independent annotators for a ""graded"" textual inference task, yielding a total of roughly 19,840 annotations, and validates that disagreements among the annotations are reproducible signals.","in their work, the labeling schema is modified from 3-way categorical NLI to a graded one, whereas our study keeps the original 3-way labeling schema to facilitate a direct comparison between old labels and new labels, and focuses more on giving an in-depth analysis regarding the relation between the level of disagreements among humans and the state-of-the-art model performance.",entailment
1017,dev_1017,"Recent work revisiting the entity-mention paradigm (Luo et al., 2004;Webster and Curran, 2014), which seeks to maintain explicit representations only of entities, rather than all their constituent mentions, has shown practical benefits for memory while being competitive with state-of-theart models (Xia et al., 2020).","unlike other approaches to coreference resolution which maintain representations of both mentions and their corresponding entity clusters (Rahman and Ng, 2011;Stoyanov and Eisner, 2012;Clark and Manning, 2015;Wiseman et al., 2016;Lee et al., 2018) , the entity-mention paradigm stores representations only of the entity clusters, which are updated incrementally as coreference predictions are made.",entailment
1018,dev_1018,Empirical results on LitBank and OntoNotes show that the model is competitive with an unbounded memory version and outperforms a strong rule-based baseline.,we report state of the art results on LitBank.,entailment
1019,dev_1019,"Therefore, in this phase, the emulator and compiled knowledge are hard-coded; here the focus is learning the parser.","this sub-goal focuses on extending executable semantic parsing from relatively narrow domains to handle more general literal language on-the-fly, similarly to zero-shot semantic parsing (Givoli and Reichart, 2019).",entailment
1020,dev_1020,Other research projects have also built such collection-based tasks before as well.,"the NLP decathlon (McCann et al., 2018), from which the name of this paper is inspired, collects together a diverse set of NLP tasks -from sentiment detection to parsing.",entailment
1021,dev_1021,"To show such grounding helps, we report results with and without grounding on those tasks in Table 4, reporting perplexity.",for Wizard of Wikipedia (knowledge) and Image Chat (images) such grounding has a clear effect.,entailment
1022,dev_1022,"We use the HotpotQA dataset (Yang et al., 2018), a popular benchmark for multi-hop QA task, for the main evaluation of the SRLGRN",two sub-tasks are included in this dataset: Answer prediction and Supporting facts prediction.,entailment
1023,dev_1023,"Although BERT achieves relatively better performance, ALBERT architecture has significantly fewer parameters (18x) and is faster (about 1.7x running time) than BERT.","aL-BERT reduces memory consumption by cross-layer parameter sharing, increases the speed, and obtains a satisfactory performance.",entailment
1024,dev_1024,"In the ablation study, we disassemble CSS and PSS into the basic components to analyze the contribution of each component.",we consider the proposed two message passing mechanisms POT and BLU.,entailment
1025,dev_1025,"Whereas Sup and UnSup contribute comparably with ""5K all"" annotated lexicon.","at low annotation level, i.e. ”1K unique”, where Sup BLI does not work well, the participation of UnSup extends the valuable additional lexicon.",entailment
1026,dev_1026,"In this work, we demonstrate that certain attention heads of a visually grounded language model actively ground elements of language to image regions.","some heads can map entities to image regions, performing the task known as entity grounding.",entailment
1027,dev_1027,"As such, we propose a novel Hierarchical Variational Auto-Encoder (HVAE) model to tackle sentiment drift problem.",we take sentiment distribution changes as the drifts.,entailment
1028,dev_1028,"Data is processed from a new time period according to the principle of prequential evaluation, and drift adaption is done in an rebuild way.","if drift does not occur when a new period arrives, labels of data are predicted and then appended to the training set to retrain the classifier.",entailment
1029,dev_1029,"Memory Augmented Neural Networks Our entity memory layer is closely tied to memory-based neural layers (Weston et al., 2014;Sukhbaatar et al., 2015).","it can be seen as a memory network where memory access is supervised through entity linking, and memory slots each correspond to a learned entity representation.",entailment
1030,dev_1030,"As discussed in Section 3, there are significant differences between EAE and KNOWBERT other than the choice of entity representation.",kNOWBERT has an explicit entity-entity attention mechanism.,entailment
1031,dev_1031,"In this paper, we propose a multi-task learning (MTL) framework to effectively utilize monolingual data for MNMT.",the model is jointly trained with translation task on multilingual parallel data and two auxiliary tasks: masked language modeling (MLM) and denoising autoencoding (DAE) on the source-side and target-side monolingual data respectively.,entailment
1032,dev_1032,We further present two simple yet effective scheduling strategies for the multilingual and multi-task framework.,we introduce a dynamic temperature-based sampling strategy for the multilingual data.,entailment
1033,dev_1033,"Furthermore, we demonstrate that MTL can effectively improve the translation quality on zero-shot language pairs with no bitext training data.",mTL achieves even better performance than the pivoting approach for multiple low-resource language pairs.,entailment
1034,dev_1034,"Utilizing monolingual data with MTL significantly improves the zero-shot translation quality of the X→X system, further demonstrating the effectiveness of the proposed approach.",mTL achieves significantly better results than the pivoting approach on the high-resource pair  CsÃ¢â€ â€™De and almost all low-resource pairs.,entailment
1035,dev_1035,"We follow HotpotQA (Yang et al., 2018) to construct a more challenging dev/test split in our benchmark","we use some statistical features like the ""size of the table"", ""similarity between answer passage and question"", ""whether question directly mentions the field"", etc.",entailment
1036,dev_1036,"1) Ranking model: As the ""retriever cells"" contain many noises, we leverage a ranker model to predict the ""correct"" linked cells for the next stage.",this model takes each cell c along with its neighboring N c (cells in the same row) and feed them all into the cell encoder to obtain their representations {H c }.,entailment
1037,dev_1037,"During inference, we apply these three models sequentially to get the answer.",we use greedy search at first two steps to remain only the highest probably cell and finally extract the answer using the RC model.,entailment
1038,dev_1038,"In the reasoning phase, we mainly utilize BERT (Devlin et al., 2019) as our encoder for the cells and passages due to its strong semantic understanding.","we use four BERT variants provided by huggingface library 3 , namely baseuncased, based-cased, large-uncased, and largecased.",entailment
1039,dev_1039,"Notably, NVDM (Miao et al., 2016) employs variational autoencoder (VAE) (Kingma and Welling, 2013) to model topic inference and document generation.","nVDM consists of an encoder inferring topics from documents and a decoder generating documents from topics, where the latent topics are constrained by a Gaussian prior.",entailment
1040,dev_1040,"The method allows summaries to be understood in context to prevent a summarizer from distorting the original meaning, of which abstractive summarizers usually fall short.",we present a new method to produce self-contained highlights that are understandable on their own to avoid confusion.,entailment
1041,dev_1041,"To avoid these, we propose to apply ensemble of the top-3 models for each policy.","we first generate distribution with the top-3 models independently with the same policy, and then take the arithmetic average of the three distributions as the final token distribution at that step.",entailment
1042,dev_1042,The embedding size and hidden size in BiLSTM are 100 and 200 respectively.,bERT  mentioned above refer to bERT base .,entailment
1043,dev_1043,"RAE (Zhang et al., 2018) further introduces the likelihood that two attribute values co-participate in a common n-ary fact, and adds the corresponding relatedness loss multiplied by a weight factor to the embedding loss of m-TransH.",rAE applies a fully-connected neural network to model the above likelihood.,entailment
1044,dev_1044,Experimental results manifest the merits and superiority of NeuInfer.,"on simple entity inference, NeuInfer outperforms the state-of-the-art method significantly in terms of all the metrics.",entailment
1045,dev_1045,We design a global-to-local neural network to encode coarse-grained and fine-grained semantic information of entities.,"we learn entity global representations by employing R-GCN (Schlichtkrull et al., 2018) on the created heterogeneous graph, and entity local representations by aggregating multiple mentions of specific entities with multi-head attention (Vaswani et al., 2017).",entailment
1046,dev_1046,"While semantically invariant text transformations can remarkably alter a model's predictions, the complementary problem of model undersensitivity is equally troublesome: a model's text input can often be drastically changed in meaning while retaining the original prediction.","previous works (Feng et al., 2018;Ribeiro et al., 2018a;Welbl et al., 2020) show that even after deletion of all but a small fraction of input words, models often produce the same output.",entailment
1047,dev_1047,This paper proposes a semantic-enhanced Gaussian mixture model (SEG) for unknown intent detection.,"we model utterance embeddings with a Gaussian mixture distribution and inject dynamic class semantic information into Gaussian means, which enables learning more classconcentrated embeddings that help to facilitate downstream outlier detection.",entailment
1048,dev_1048,"To deal with this task, we devise a data-driven global Skill-Aware Multi-Attention generation model, named SAMA.","to model the complex mapping relationships between input and output, we design a hierarchical decoder that we first label the job description with multiple skills, then we generate a complete text guided by the skill labels.",entailment
1049,dev_1049,"To address these challenges, we focus on the richness and accuracy of skills in generated job requirements and propose a global Skill-Aware Multi-Attention (SAMA) model for JPG task.","we devise a two-pass decoder to generate informative, accurate, and fluent job requirement paragraph.",entailment
1050,dev_1050,"To obtain the long-term dependency vector representation, we use a bi-directional LSTM (Schuster and Paliwal, 1997) as the text encoder.","the input sequence is transformed into a hidden state sequence H = (h 1 , h 2 , ..., h m ) by concatenating the representations of the forward and backward hidden states the initiated encoder hidden state h 0 is a zero vector, and the last encoder hidden state h m is used for initiating the skill decoder.",entailment
1051,dev_1051,We consider addressing the limitation of existing work by modeling knowledge connections between domains explicitly.,"a simple baseline to incorporate domain-shared and domain-private features is shared-private framework (Liu et al., 2017; Zhong et al., 2018; Wu et al., 2019b).",entailment
1052,dev_1052,"Generally, all the proposed components are effective to contribute the final performance.",we can clearly observe the effectiveness of our dynamic fusion mechanism where w/o domain-specific knowledge fusion causes 1.8% drops and the same trend in removing domain-shared knowledge fusion.,entailment
1053,dev_1053,"In contrast to the sharedprivate model, a dynamic fusion module (see §2.3) is further introduced to explicitly capture the correlation between domains.","a gate is leveraged to automatically find the correlation between a current input and all domain-specific models, so that a weight can be assigned to each domain for extracting knowledge.",entailment
1054,dev_1054,"In this paper, we propose a novel retrieve-andrewrite initialization method for UMT.",we first retrieve semantically similar sentence pairs from monolingual corpora of two languages with the help of unsupervised cross-lingual sentence embeddings.,entailment
1055,dev_1055,"For a fair comparison, our models and all baselines use the same neural encoder to encode text spans before the attention or OT operation is applied.","we use RoBERTa (Liu et al., 2019), a state-of-the-art pre-trained encoder, for the StackExchange and MultiRC dataset.",entailment
1056,dev_1056,"Lastly, we examine how large a bias-specific dataset needs to be in order to conclude that a given classifier is biased.",we consider a co-reference resolution system that is more accurate on sentences containing stereotypical gender roles.,entailment
1057,dev_1057,"As shown in Table 5, our two systems outperform S2S by a large margin, especially in terms of appropriateness, informativeness, goal success rate and coherence.","s2s tends to generate safe and uninformative responses, failing to complete goals in most of dialogs.",entailment
1058,dev_1058,Our model augments the end-toend neural architecture with the ability to incorporate well-established graphs into both the document representation and summary generation processes.,"a graph-informed attention mechanism is developed to incorporate graphs into the document encoding process, which enables our model to capture richer cross-document relations.",entailment
1059,dev_1059,A natural idea is to combine our graph model with pretrained LMs so as to combine the advantages of them.,the tokenlevel transformer encoding layer of our model can be replaced by a pre-trained LM like BERT.,entailment
1060,dev_1060,The results demonstrate that GraphSum and GraphSum+RoBERTa are able to generate higher quality summaries than other models.,"the summaries generated by GraphSum and GraphSum+RoBERTa usually contains more salient information, and are more fluent and concise than other models.",entailment
1061,dev_1061,"To the best of our knowledge, we are the first to exploit the idea of meta-learning for transferring zeroshot knowledge in a cross-lingual setting for natural language understanding, in particular for the tasks of NLI and QA.","we exploit the usage of Model Agnostic Meta-Learning (MAML) which uses gradient descent and achieves a good generalisation for a variety of tasks (Finn et al., 2017).",entailment
1062,dev_1062,"Few-shot learning methods have initially been introduced within the area of image classification (Vinyals et al., 2016;Ravi and Larochelle, 2017;Finn et al., 2017), but have recently also been applied to NLP tasks such as relation extraction (Han et al., 2018), text classification Rethmeier and Augenstein, 2020) and machine translation (Gu et al., 2018).","in NLP, these few-shot learning approaches include: (i) the transformation of the problem into a different task (e.g., relation extraction is transformed to question answering (Levy et al., 2017;Abdou et al., 2019)); or (ii) meta-learning (Andrychowicz et al., 2016;Finn et al., 2017).",entailment
1063,dev_1063,"However, a narrative plays a different and more specific role than a general context.","a narrative may cover the whole story (a part of a script), thus a good conversation should also cover all the aspects mentioned in a narrative, which is not required with a general context.",entailment
1064,dev_1064,Aspect-based sentiment analysis (ABSA) aims at fine-grained sentiment analysis of online affective texts such as product reviews.,its objective is to determine the sentiment polarities towards one or more aspects appearing in a single sentence.,entailment
1065,dev_1065,"Grounding annotation schemes in formal ontologies, and interlinking them with each other establishes a high degree of interoperability at a comparably low cost.","this approach differs from full-fledged standardization in that it does not require revisions of the actual annotation, but can be solely performed at the level of the vocabularies themselves.",entailment
1066,dev_1066,"To ensure faster convergence, we introduce a new constraint to the likelihood function: for each token position i, the corresponding latent label s i must have a non-zero probability in at least one labelling function (the likelihood of this label is otherwise set to zero for that position).",the aggregation model will only predict a particular label if this label is produced by least one labelling function.,entailment
1067,dev_1067,Evaluation results on two datasets (CoNLL 2003 and news articles from Reuters and Bloomberg) show that the method can boost NER performance by about 7 percentage points on entity-level F 1 .,the proposed model outperforms the unsupervised domain adaptation approach through contextualised embeddings of Han and Eisenstein (2019).,entailment
1068,dev_1068,"In spite of its high relevance, KG embedding methods have not been used for multi-hop KGQA – we fill this gap in this paper","we propose EmbedKGQA, a novel system which leverages KG embeddings to perform multi-hop KGQA.",entailment
1069,dev_1069,Fig. 4 shows the results (higher value/darker color is better): we find that responses generated from the symbolic planner as input do not perform well when compared to the ground truth.,the proportion of time that the ground truth response is preferred over that generated by the symbolic planner is significant (e.g.,entailment
1070,dev_1070,"From the figure, it is observed that for each RW methods, the node expansion based representation beats the performance of the tweet representation without any node expansion.","the sentiment polarized node expansion beats the performance of classifiers with and without non-polarized node expansion by an average margin of 9.19% and 10.57%, respectively.",entailment
1071,dev_1071,This multistep process can serve as a natural benchmark for measuring whether systems achieve localization through a human-like process of progressively getting closer to the target location by interpreting intermediate steps.,this setup may helps researchers make sure that our systems are arriving at the referred location for the right reasons.,entailment
1072,dev_1072,"Out of the 4262 distinct sentences, only 188 were recorded more than once.",the chance of two annotators producing the same output string is quite low.,entailment
1073,dev_1073,"GNNs (Kipf and Welling, 2017) have recently become the paradigm for graph representation learning.","for the entity alignment task, the main merit of GNN-based methods lies in capturing the high-order proximity of entities based on their neighborhood information (Wang et al., 2018).",entailment
1074,dev_1074,"However, HyperKA still exhibits satisfying performance at very small dimensions in comparison to other methods, such as under the dimensions of 10 and 25.","hyperKA with 25 dimension even outperforms a number of methods in Table 2 with much higher dimensions, e.g., AlignE, GCN-Align and KECG.",entailment
1075,dev_1075,"The sequence labelling models, however, outperform both the baselines by a huge margin, demonstrating the effectiveness of the model on the task.",the best performance is achieved by combining pre-trained embeddings from multiple language models trained on different data sources.,entailment
1076,dev_1076,"However, despite impressive results obtained by systems using word embeddings, some issues were largely left unexplored, such as (i) the links between representations delivered through word embeddings vs. lexicographic meaning representations; (ii) the cognitive plausibility of the word embeddings (which is different from testing the agreement with conceptual similarity ratings); and (iii) the ways to acquire word embeddings to deliver common-sense usage of language (more on common-sense knowledge later on).","different from lexicographic resources where the minimal addressable unit of meaning is word sense (the synset), with few notable exceptions (such as NASARI [Camacho-Collados, Pilehvar, and Navigli 2015b] and SENSEEMBED [Iacobacci, Pilehvar, and Navigli 2015]), word embeddings typically describe terms.",entailment
1077,dev_1077,"In order to account for lexical ambiguity, Reisinger and Mooney (2010) propose representing terms as collections of prototype vectors; the contexts of a term are then partitioned to construct a prototype for the sense in each cluster.","for each word different prototypes are induced, by clustering feature vectors acquired for each sense of the considered word.",entailment
1078,dev_1078,The language model proposed by Huang et al. (2012) exploits both local and global context that are acquired through a joint training objective.,"word representations are computed while learning to discriminate the next word, given a local context composed of a short sequence of words, and a global context composed of the whole document where the word sequence occurs.",entailment
1079,dev_1079,"Because we are able to determine not only the distance between each two senses of the input terms, but also the distance between each input term and all of its senses, we use this information to fine tune the computed similarity scores and use ranking as a criterion to grade senses' relevance.","we hypothesize that the relevance of senses for a given term can be helpful for the computation of similarity scores, so we devised a measure that also accounts for the ranking of distances between senses and seed term.",entailment
1080,dev_1080,"Reported results are Pearson correlation indices, measuring the agreement with human annotated data.",we compare the Pearson scores obtained by the HCTI system using LESSLEX and GloVe vectors.,entailment
1081,dev_1081,The investigation on abstract concepts has recently emerged as central in the multidisciplinary debate between grounded views of cognition versus modal (or symbolic) views of cognition (Bolognesi and Steen 2018).,in the first hypothesis cognition might be embodied and grounded in perception and action (Gibbs Jr 2005): accessing concepts would amount to retrieving and instantiating perceptual and motoric experience.,entailment
1082,dev_1082,The first approach is to use models that have explicit mechanisms for representing syntactic structure.,"our results suggest that the most important aspect of syntactic structure to include is constituency structure, as constituency models appear to implicitly learn dependency structure as well.",entailment
1083,dev_1083,Both tasks are particularly challenging as many conditions must be met in a text to ensure it forms a proper WS.,translation is made difficult by the fact that some WS rely on linguistic phenomena that play differently in different languages.,entailment
1084,dev_1084,We initialize the neutral topics and topic intensities with a pre-trained model.,we pre-train a Poisson factorization topic model using the algorithm in Gopalan et al. (2015).,entailment
1085,dev_1085,"Additionally, we use variational inference with reparam-eterization gradients to train all methods.","we perform mean-field variational inference, positing Gaussian variational families on all real variables and lognormal variational families on all positive variables.",entailment
1086,dev_1086,"KBQA includes simple questions that retrieve answers from single-hop triples (""what is Donald Trump's nationality"") (Berant et al., 2013;Yih et al., 2014), multi-hop questions that infer answers over triple chains of at least 2 hops under specific constraints (""who is the president of the European Union 2012"") (Yih et al., 2016;, and complex questions that involve set operations (""how many rivers flow through India and China"") .","complex question answering (CQA) (Saha et al., 2018) is a sophisticated KBQA task in which a sequence of discrete actions-e.g., set intersection and union, counting, comparison-needs to be executed, and is the subject of this paper.",entailment
1087,dev_1087,"Instead of directly transferring the knowledge to the target domain, this paper proposes to borrow the benefit of multi-task learning, which allows a single model to be capable of handling multiple tasks/domains by feeding the corresponding data.",we utilize question answering for learning the capability of rationalization instead of a rationalizationspecific language model.,entailment
1088,dev_1088,We compute the F1 scores as macro F1.,we first compute F1 score for each instance as the average F1 among all predictions in the instance.,entailment
1089,dev_1089,"In this paper, we propose a joint learning approach to improve neural abstractive multi-document summarization by using single-document summarization dataset.","we use the shared document encoder and summary decoder to process each document in the document set, and apply a decoding controller to aggregates all output probabilities from the summary decoder for multi-document summarization.",entailment
1090,dev_1090,"We have used the largest multilingual corpora available on a relatively long time, allowing thanks to its size to set a yearly granularity of analysis.",we used Google Books Ngrams 1 in English and French to conduct the analysis.,entailment
1091,dev_1091,"Our results show that while toxic prompts unsurprisingly yield higher toxicity in generations, nontoxic prompts still can still cause toxic generations at non-trivial rates (Table 2).",all five models have a toxicity probability near or above 0.5 for non-toxic prompts.,entailment
1092,dev_1092,"We find that certain prompts consistently cause all models to generate toxicity (e.g., the four prompts in Figure  1).","there are 327 prompts that yielded at least one generation with 0.9 TOXICITY from all models, and 1,225 prompts when considering only the out-of-the-box language models (i.e., GPT-1, GPT-2, GPT-3, CTRL, CTRL-WIKI).",entailment
1093,dev_1093,"To further investigate the phenomenon of neural toxic degeneration, and partially motivated by the surprising effectiveness of domain-adaptive pretraining on non-toxic data, we turn our focus to two corpora used to pretrain several language models.","we quantify the toxicity in OPENAI-WT (GPT-2's training data; Radford et al., 2019) and its open-source replica OWTC (Gokaslan and Cohen, 2019), inspired by previous work in analyzing social biases in large text corpora (Fast et al., 2016).",entailment
1094,dev_1094,"Other researchers have also shown that language models can ""falsely"" solve the task.","they might be taking advantage of dataset failures or artifacts on the input sentences in order to guess the answer (Gururangan et al., 2018; Agrawal et al., 2016; Levy et al., 2015).",entailment
1095,dev_1095,"To evaluate if Transformer-based models leverage the artifacts, we tested the models by removing the premise sentence in the development set.",the models  are unaware of the premises of the dataset.,entailment
1096,dev_1096,"We also noticed that some adversaries are model-specific, as they affect one model but not the rest.","in the noise tests, we observed that the robustness trend also holds, but noticed some unexpected behavior in relative analysis, as some types of noise affect the models more severely than others, thus revealing specific weak points across all Transformer-based models that did not seem evident at first sight.",entailment
1097,dev_1097,The question-answer alignment and question/answer semantics are expected to be preserved in the representations.,the question/answer embeddings must reflect their semantics in the texts of being aligned as pairs.,entailment
1098,dev_1098,We adapt the RuleTaker dataset to FEVER by introducing a new NOTENOUGHINFO label for unprovable question-context pairs.,"we construct two FEVER-style RuleTaker datasets, namely RuleTaker-CWA and RuleTaker-Skip-Fact (example in Table 2).",entailment
1099,dev_1099,"In fact, this definition is not well suited for any type of machine learning algorithm, but for those types of algorithms that use labeled data as in our case.",a supervised neural network model is a mathematical function whose weights are refined iteration after iteration.,entailment
1100,dev_1100,"As an example, we analyze correlations between content structures and event coreference structures in news articles, and conduct experiments to incorporate system predicted sentence content types into an event coreference resolution system.","we analyze the lifespan and spread of event coreference chains over different content types, and design constraints to capture several prominent observations for event coreference resolution.",entailment
1101,dev_1101,We call such events intra-type events.,an intra-type event chain starts from a sentence of any type will die out within sentences of the same content type.,entailment
1102,dev_1102,"We can see that non-main contents (e.g., content types C2-D3) are more likely to be self-contained from introducing to finishing describing an event.",historical (D1) and anecdotal (D2) contents exhibit an even stronger tendency of having intratype event repetitions compared to other non-main content types.,entailment
1103,dev_1103,"In addition, we built a discourse-aware event singleton classifier, that resembles the sentence type classifier, to identify singleton event mentions in a document.",the singleton classifier combines document and sentence representations provided by the content type classifier with contextualized event word representations obtained from a separate word-level biLSTM layer with 512 hidden units.,entailment
1104,dev_1104,The ILP model constrained by system predicted content structures (the row +Content Structure) outperforms the pairwise classifier baseline system as well as the two most recent systems consistently across all the evaluation metrics over the two benchmark datasets.,"our ILP system outperforms the previous state-of-the-art, the heuristics-based ILP system Choubey and Huang, with average F1 gains of 0.67% and 1.32% on KBP 2016 and KBP 2017 corpora respectively.",entailment
1105,dev_1105,"We examine the language of the SOLO tweets to determine if the concept words loneliness, lonely, and solitude tend to be used in different emotional contexts.",we explore the question of whether Twitter users perceive the concept of solitude as more positive and selfdriven and the concept of loneliness as more negative and externally imposed as suggested by psychology literature.,entailment
1106,dev_1106,"In this section, we measure the emotional context in which the SOLO query terms, loneliness, lonely, and solitude, occur.",we investigate whether people use these terms in different emotional contexts and whether they are associated with the qualities suggested in the psychology literature.,entailment
1107,dev_1107,"In this work we take a step towards these goals by considering grounded dialogue involving open-ended discussion of a given image, a setting that is naturally fun for humans (Hu et al., 2014), and study neural conversational models for task.","we explore both generative and retrieval models that handle multimodal dialogue by fusing Transformer architectures (Vaswani et al., 2017) for encoding dialogue history and responses and ResNet architectures  for encoding images.",entailment
1108,dev_1108,"In this section, we describe our method of computing embeddings for target OOV words by using a weighted sum of pre-trained word embeddings.",we calculate the weights over known words from similarity scores derived on the basis of their surface information (Figure 1).,entailment
1109,dev_1109,"To be consistent with the seq2seq model for AMR parsing, the pre-trained models in this paper are all built on the Transformer.","for each pretraining task listed in Table 1, we learn a seq2seq model which will be used to initialize seq2seq model for AMR parsing in the fine-tuning phase.",entailment
1110,dev_1110,"Despite being a widely spoken language, it has been widely acknowledged that it has few publicly available tools and resources, apart from a few notable exceptions (Mahmoud El-Haj et al., 2015).","arabic NLP lacks resources such as corpora, lexicons, machine-readable dictionaries, Datasets in addition to fully automated fundamental NLP tools such as tokenizers, partof-speech taggers, parsers, stemmers and semantic role labelers.",entailment
1111,dev_1111,"When applying corpus-based techniques, one of the key things to consider is the extent to which size and subject affect the overall performance of the system.","based on the underlying processes involved, the COALS algorithm should be particularly sensitive to changes in domain and semantic space dimension.",entailment
1112,dev_1112,The conjugations of verbs and the declensions of nouns are much different and more complex in Greek language than in English.,"among different conjugations and declensions of a noun or an adjective, a word has different endings.",entailment
1113,dev_1113,This method only considers the absolute distance of token i and j.,it does not distinguish the sign of the distance j - i.,entailment
1114,dev_1114,"To minimize the training cost, we test method 4 on a pre-trained BERT large model.","we load a pre-trained BERT large model, bert-large-uncased-whole-word-masking, from pytorch transformer 5 as the initial model and fine-tune the existing parameters and the new relative position embedding parameters for 3 epochs, staring with a small learning rate of 5e âˆ’ 5.",entailment
1115,dev_1115,"As in (Yih et al., 2016), we have found that careful design of the annotation tool leads to significant improvements in efficiency and accuracy.","we re-affirm the conclusion from (Yih et al., 2016) that having each worker do one task (e.g. labeling a single node in the tree) makes annotation easier for workers)",entailment
1116,dev_1116,We demonstrate the results of several neural parsing models on our dataset.,"we show the results of a re-implementation of (Dong  and Lapata, 2016) adapted to our grammar, and a straightforward fine-tuned BERT model (Devlin et al., 2018).",entailment
1117,dev_1117,"However, previous works (Giannakopoulos et al., 2014) have suggested that having better precision in such a task gives more perceived value for the user than recall.","users prefer small, clean clusters than larger clusters which may contain more of the relevant articles but also more off-topic articles.",entailment
1118,dev_1118,"In this paper we work with DNNs for text analysis and, given a text and a word embedding, consider the problem of quantifying the robustness of the DNN with respect to word substitutions.","we define the maximal safe radius (MSR) of a text as the minimum distance (in the embedding space) of the text from the decision boundary, i.e., from the nearest perturbed text that is classified differently from the original.",entailment
1119,dev_1119,We employ our framework to perform an empirical analysis of the robustness trends of sentiment analysis and news classification tasks for a range of embeddings on vanilla CNN and LTSM models.,"we consider the IMDB dataset (Maas et al., 2011), the Stanford Sentiment Treebank (SST) dataset (Socher et al., 2013), the AG News Corpus Dataset (Zhang et al., 2015) and the NEWS Dataset (Vitale et al., 2012).",entailment
1120,dev_1120,"In this work, we exploit approximate, scalable, linear constraint relaxation methods (Weng et al., 2018a; Zhang et al., 2018; Wong and Kolter, 2018), which do not assume Lipschitz continuity.","we adapt the CNNCert tool (Boopathy et al., 2019) and its recurrent extension POPQORN (Ko et al., 2019) to compute robustness guarantees for text classification in the NLP domain.",entailment
1121,dev_1121,"bounds of MSR for CNNs and LSTMs, respectively, with CNN-Cert and POPQORN tools, we implement the MCTS algorithm introduced in Section 2.2 to search for meaningful perturbations (i.e., upper bounds), regardless of the NN architecture employed.",in Section 3.1 we consider robustness against single and multiple word substitutions and investigate implicit biases of LSTM architectures.,entailment
1122,dev_1122,"we propose to leverage such meaningful k-mers to complement the representation produced by the language model (i.e., z i defined in Eqq. (1)) as “word”-level information.","in the source building, we obtain a k-mer vocabulary using the sensor names and their annotations -every ground-truth segment in a sensor name becomes a k-mer.",entailment
1123,dev_1123,"Since it is impossible for the model to predict for classes out of the training set, we thus only keep the overlapping classes between a pair of source and target buildings in evaluation.","given a pair of buildings, if a class exists only in either of the two buildings, we will mark it as an ""other"" class.",entailment
1124,dev_1124,"We evaluate the performance of SeNsER with regard to chunking and tagging using the precision, recall, and F 1 scores, similar to NER tasks.","for each sensor name, we get a few predicted triplets, i.e., (position begin , position end , category), and only when both the position and category exactly match the ground-truth annotations does it count as a correct extraction.",entailment
1125,dev_1125,"We also examine the generalizability of our method, i.e., how it would perform when applied to a building with a completely distinct vocabulary and naming convention.",we train a tagger using the sensor names and annotations in building A and B and apply it to building C.,entailment
1126,dev_1126,"To this end, we propose a new task towards persona-based empathetic conversations and present the first empirical study on the impact of persona on empathetic responding.",we first present a novel large-scale multi-domain dataset for persona-based empathetic conversations.,entailment
1127,dev_1127,"In this regard, a line of future work, briefly discussed in Section 3., is to further validate the multi-level annotation schemes.",reliability needs to be estimated on the basis of larger and more diverse samples.,entailment
1128,dev_1128,"Through well-designed probing experiments, we empirically validate that the improvement of SSANs can be attributed in part to mitigating two commonly-cited weaknesses of SANs: word order encoding and structure modeling.",the selective mechanism improves SANs by paying more attention to content words that contribute to the meaning of the sentence.,entailment
1129,dev_1129,"We used them as NLP benchmarks, which cover classification, sequence labeling and sequence generation categories.","the performances of semantic role labeling and language inference models heavily rely on structural information (Strubell et al., 2018), while machine translation models need to learn word order and syntactic structure (Chen et al., 2018; Hao et al., 2019c).",entailment
1130,dev_1130," Figure 5 illustrates an example, in which more queries in SSANs attend most to the inserted word ""the"" than SANs.","sANs pay more attention to the surrounding words (e.g., distance < 3), while the inserted word ""the"" only accepts subtle attention.",entailment
1131,dev_1131,"Our proposed RACL is a unified multi-task learning framework which enables propagating the interactive relations (denoted as the same R 1 ..R 4 as those in Figure 1) for improving the ABSA performance, and it can be stacked to multiple layers to interact subtasks at different semantic levels.","we present the overall architecture of RACL in a single RACL layer contains three modules: AE, OE, and SC, where each module is designed for the corresponding subtask.",entailment
1132,dev_1132,A plausible explanation is differences in the libraries.,"the libraries used for training neural networks are in active development, and there may be important changes in short time periods.",entailment
1133,dev_1133,"In this paper, we propose a novel QA model based on text enhanced knowledge graph, which enriches entity representation by text semantic information and complements the relations in KB through structural information of the text.","the model firstly encodes entities in KB combining text information and applies graph convolutional networks (GCN) (Wu et al., 2020) to reason across KB.",entailment
1134,dev_1134,"In KB+Text's setting, our method also achieves the best performance, proving that our proposed enhancement strategy can effectively enhance incomplete KB by fully introducing the semantic and structural information implied in the text.","our model improves a lot compared with KB-only, more than the work of (Sun et al., 2018), which demonstrates our way that treating documents as hyperedges is more productive than regarding them as heterogeneous nodes.",entailment
1135,dev_1135,"AFS eases model convergence, and improves the translation quality by ∼1.3-1.6 BLEU, surpassing several strong baselines.","without data augmentation, AFS narrows the performance gap against the cascade approach, and outperforms it on LibriSpeech En-Fr by 0.29 BLEU, reaching 18.56.",entailment
1136,dev_1136,"Instead, we resort to sparsification techniques which have achieved great success in NLP tasks recently (Correia et al., 2019; Child et al., 2019; Zhang et al., 2020).","we employ L0 DROP (Zhang et al., 2020) for AFS to dynamically retain informative speech features, which is fully differentiable and independent of concrete encoder/decoder architectures.",entailment
1137,dev_1137,"Also, unlike prior work on improving interpretability (Erion et al., 2019;Plumb et al., 2019), it does not require pre-defined important attributions or pre-collected explanations.","we propose variational word masks (VMASK) that are inserted into a neural text classifier, after the word embedding layer, and trained jointly with the model.",entailment
1138,dev_1138,"In this work, we introduce a jointly masked sequence-to-sequence model and explore its application on non-autoregressive neural machine translation (NAT).","we first empirically study the functionalities of the encoder and the decoder in NAT models, and find that the encoder takes a more important role than the decoder regarding the translation quality.",entailment
1139,dev_1139,"Therefore, we propose a jointly masked sequence-to-sequence model which is inspired by the idea of masked language modeling (Devlin et al., 2018).","for the encoder, we follow the masking strategy of BERT (Devlin et al., 2018) and randomly mask a number of tokens of the source sentence.",entailment
1140,dev_1140,"Firstly, we vary the number of encoder and decoder layers respectively to see which will bring more performance gain.","on a basic model with a 5-layer encoder and a 5-layer decoder, we increase the number of layers to the encoder and decoder separately.",entailment
1141,dev_1141,"We follow (Ghazvininejad et al., 2019) and introduce an additional prediction process to estimate the length by the source sentence.",we add a special token to the encoder and predict the target length with the output hidden vector of this token.,entailment
1142,dev_1142,"Next, for each iteration, we apply consecutive masking to the translation candidates as we have done in the training stage.","we select several tokens with the lowest probabilities from the current translation candidates, and mask these tokens as well as their adjacent ones.",entailment
1143,dev_1143,"We propose two mechanisms to exploit the structure of evidence while leveraging the advances of pre-trained models like BERT, GPT or XLNet.","using XLNet as the backbone, we first utilize the graph structure to redefine the relative distances of words, with the intuition that semantically related words should have short distances.",entailment
1144,dev_1144,"Considering the aforementioned issues, we implement an approximate solution to trade off between the efficiency of implementation and the informativeness of the graph.",we reorder evidence sentences with a topology sort algorithm with the intuition that closely linked nodes should exist in neighboring sentences.,entailment
1145,dev_1145,"With a given claim, we represent the retrieved evidence sentences as a graph, and then use the graph structure to guide the reasoning process.","we apply semantic role labeling (SRL) to parse each evidence sentence, and establish links between arguments to construct the graph.",entailment
1146,dev_1146,"To fully harness the power of fine-tuning in a more principled manner, we propose a new learning framework for robust and efficient fine-tuning on the pre-trained language models through regularized optimization techniques.","our framework consists of two important ingredients for preventing overfitting: (I) To effectively control the extremely high complexity of the model, we propose a Smoothnessinducing Adversarial Regularization technique.",entailment
1147,dev_1147,The pre-trained language model is then adapted to downstream tasks and further fine-tuned.,the top layer of the language model can be replaced by a task-specific layer and then continue to train on downstream tasks.,entailment
1148,dev_1148,"We present an evaluation benchmark, GLUECoS, for code-switched languages, that spans several NLP tasks in English-Hindi and English-Spanish.","our evaluation benchmark includes Language Identification from text, POS tagging, Named Entity Recognition, Sentiment Analysis, Question Answering and a new task for code-switching, Natural Language Inference.",entailment
1149,dev_1149,"Multilingual BERT is pre-trained on monolingual corpora of 104 languages and has been shown to perform well on zero shot cross-lingual model transfer and code-switched POS tagging (Pires et al., 2019).",we use the bert-basemultilingual-cased model for our experiments.,entailment
1150,dev_1150,"To predict the labels of the nodes following the practices in (Zhu et al., 2005), we employ a modified Viterbi algorithm in which the nodes in the vertical chain are decoded first.",the constructed graph consists of two types of cliques: one from the horizontal chains and the other from the vertical chain.,entailment
1151,dev_1151,A modified Viterbi algorithm is used to find the best labeling sequence.,we first applies the Viterbi algorithm to decode the vertical chain.,entailment
1152,dev_1152,The BERT-based parser self-trained with 40% silver Fisher trees and 60% gold Switchboard trees is our best model.,"for a batch size of 30, in each mini-batch 12 parse trees come from the silver Fisher data and 18 parse trees from the gold Switchboard.",entailment
1153,dev_1153,"One effective way to obtain domain-invariant features is adversarial training (Ganin et al., 2016;Li et al., 2017;Zheng et al., 2019).","a domain discriminator is learned by minimizing the classification error of distinguishing the source from the target domains, while a deep classification model learns transferable representations that are indistinguishable by the domain discriminator.",entailment
1154,dev_1154,"To address above problems, we design a novel pre-training task to make BERT domain-aware and then improve the BERT's fine-tuning procedure by adversarial training.",a novel post-training procedure is implemented that adapts BERT with unlabeled data from different domains to enhance the domain-awareness.,entailment
1155,dev_1155,"Based on the post-trained BERT, we now could utilize the adversarial training to abandon the distilled domain-specific features to derive the domaininvariant features.",a sentiment classifier and a domain discriminator is designed operating on the hidden state h [CLS] of the special classification embedding [CLS].,entailment
1156,dev_1156,"We experiment with a strong neural QE approach based on BERT (Devlin et al., 2019).",we focus on the bert-base-cased version of the multilingual BERT.,entailment
1157,dev_1157,"In general, the annotation should not depend on the table contents and sorting assumptions.",use direct references to the presented row order id as little as possible.,entailment
1158,dev_1158,"In this paper, we aim to overcome the above problems to automatically generate faithful texts from tables.",we aim to produce the writing that a human without any external knowledge would do given the same table data as input.,entailment
1159,dev_1159,"Our model adopts the powerful Transformer model (Vaswani et al., 2017) to translate a table to a text sequence.","the Transformer is a Seq2Seq model, consisting of an encoder and a decoder.",entailment
1160,dev_1160,Our first idea is inspired by related work in machine translation .,we propose to constrain a table embedding to be close to the corresponding target sentence embedding.,entailment
1161,dev_1161,Patt is the attention weights (probability) returned from the encoder-decoder attention module in the Transformer.,"when generating the current word yi , the encoder-decoder attention module calculates the probability vector Patt denoting the probabilities of attending to each word in the input table.",entailment
1162,dev_1162,"To further reduce the number of parameters and improve the computational efficiency, we adopt the factorized embedding parameterization proposed recently (Lan et al., 2019).","we decompose a word embedding matrix of size V × D into the product of two matrices of sizes V × H and H × D, respectively.",entailment
1163,dev_1163,We posit that generated questions should not be easily classified into either LM-type or copy-type if the two styles were to be inter-mixed in a balanced way.,the style of the questions should not be highly biased toward either side.,entailment
1164,dev_1164,"We show that the choice of probability space puts constraints on the distant supervision assumptions that can be captured, and that all three choices interact, leading to large differences in performance.","we provide a framework for understanding different distant supervision assumptions and the corresponding trade-off among the coverage, quality and strength of distant supervision signal.",entailment
1165,dev_1165,This paper employs a novel knowledgeaware pointer network.,we expand the scope of the original pointer networks by exploiting the attention distribution of knowledge representation.,entailment
1166,dev_1166,"To induce a useful latent generation plan and to effectively condition on a sampled plan, we propose a constrained story decoder and constrained inference network.","our constrained decoder begins a story sentence by deterministic copying the corresponding anchor word, and then generates words to the left and then to the right (Figure 3).",entailment
1167,dev_1167,"Replicability and reproducibility are core ideas of modern scientific methods (Ivie and Thain, 2018), and thus reproducibility of scientific research results is an important topic in many research areas.","over the last decade, terms such as ""reproducibility crisis"" or ""p-hacking"" have gained attention from different scientific communities, especially after studies showed failure in reproduction of researches in life and medicine science (Begley and Ellis, 2012), psychology ans behavioral science (Anderson et al., 2015), as well as astrophysics (Collaboration and others, 2015).",entailment
1168,dev_1168,"In addition to the model architecture presented in paper, the authors describe various components for preprocessing and postprocessing steps taken in the development of the system that effectively raise the system performance.","in the preprocessing steps, they cropped the sentences to only keep the entity pairs and tokens in between, and cleaned the sentences by flattening nested entities and removing all tokens between parentheses and brackets ((, ), [, ]).",entailment
1169,dev_1169,"Due to the lack of jointly labeled data for these relational phenomena and the restriction on the structures they articulate, we propose a joint constrained learning framework for modeling event-event relations.",the framework enforces logical constraints within and across multiple temporal and subevent relations by converting these constraints into differentiable learning objectives.,entailment
1170,dev_1170,"To characterize the event pairs in the document, we employ a neural encoder architecture which provides event representations from two groups of features.",the representation here incorporates the contextualized representations of the event triggers along with statistical commonsense knowledge from several knowledge bases.,entailment
1171,dev_1171,We also incorporate the following sources of commonsense knowledge to characterize event pairs.,"we first extract relevant knowledge from ConceptNet (Speer et al., 2017), which is a large-scale commonsense knowledge graph for commonsense concepts, entities, events and relations.",entailment
1172,dev_1172,"In this section, we present the experiments on eventevent relation extraction.",we conduct evaluation for TempRel and subevent relation extraction based on two benchmark datasets ( §4.1- §4.4).,entailment
1173,dev_1173,"Since there is not a large-scale dataset that amply annotates for both TempRel and subevent relations, we evaluate the joint training and prediction of both categories of relations on two separate datasets.","we use MATRES (Ning et al., 2018b) for TempRel extraction and HiEve  for subevent relation extraction.",entailment
1174,dev_1174," This is motivated by the idea that while the average number of “old” citations per paper is stable (cf. Sec. 3.2), they might be distributed in an unbalanced way.","there might be a subset of publications that does not cite any ""older"" work.",entailment
1175,dev_1175,"Negative training can be derived from Empirical Bayes Risk Minimization (Och, 2003).","the overall objective is to minimize the expected risk that the model exhibits undesirable decoding behavior: where c(x, y) refers to the binary criteria that will be 1 if (x, y) exhibits undesirable behavior, and 0 otherwise.",entailment
1176,dev_1176,In this paper we introduce a method of measuring more specific legislator attitudes using an alternative expression of preferences: tweeting.,we present an embedding-based model for predicting the frequency and sentiment of legislator tweets.,entailment
1177,dev_1177,"Different from classical neural generation models, our generation model is in a two-stage generation manner, motivated by coarse-to-fine decoding (Dong and Lapata, 2018).","given a fluent sentence as the input, in the first stage, a Planner selects the positions of where to insert reparandum; in the second stage, a Generator generates disfluent segments accordingly for the predicted areas.",entailment
1178,dev_1178,"In this paper, we propose a neural model named TWASP for joint CWS and POS tagging following the character-based sequence labeling paradigm, where a two-way attention mechanism is used to incorporate both context feature and their corresponding syntactic knowledge for each input character.","we use existing language processing toolkits to obtain the auto-analyzed syntactic knowledge for the context, and the proposed attention module can learn and benefit from them although their quality may not be perfect.",entailment
1179,dev_1179,"First, for all encoders, the two-way attentions provide consistent enhancement to the baselines with different types of knowledge.","although the baseline model is well-performed when BERT (or ZEN) serves as the encoder, the attention module is still able to further improve its performance with the knowledge produced by the toolkits even though the toolkits have worse-than-baseline results for the joint task",entailment
1180,dev_1180,This suggests that BERT is aware of the structure of the document it is given.,"we observe a decent accuracy in identifying discourse relations between adjacent EDUs, perhaps due to the ""next sentence prediction"" task in pre-training, as pointed out in (Shi and Demberg, 2019).",entailment
1181,dev_1181,Their goal is to check if the attention heads of a given pre-trained model can track syntactic relations better than chance or baselines.,"raganato and Tiedemann (2018) analyze a machine translation model's encoder by extracting dependency trees from its self-attention weights, using Chu-Liu/Edmonds algorithm.",entailment
1182,dev_1182,"Text simplification (Shardlow, 2014) that rewrites a sentence into an easy-to-understand form for language learners (Petersen and Ostendorf, 2007) and children (Belder and Moens, 2010) is attracting attention.","lexical simplification (Paetzold and Specia, 2017a), which paraphrases complex words into simpler ones according to the context while maintaining the syntactic structure of the input sentence, is being actively researched (mainly in English).",entailment
1183,dev_1183,"Complementing these works, we directly manipulate models' modeling of the context surrounding identifier terms by regularizing explanations of these terms.","we use post-hoc explanation algorithms to interpret and modulate finetuned language models like BERT (Devlin et al., 2018), which achieve state of the art performance on many hate speech detection tasks (MacAvaney et al., 2019;Mandl et al., 2019).",entailment
1184,dev_1184,"The goal of this paper is to establish a new state of the art for French NER by (i) providing a new, easy-to-use UDaligned version of the named entity annotation layer in the FTB and (ii) using this corpus as a training and evaluation dataset for carrying out NER experiments using state-ofthe-art architectures, thereby improving over the previous state of the art in French NER.","by using both FastText embeddings (Bojanowski et al., 2017) and one of the versions of the CamemBERT French neural contextual language model (Martin et al., 2019) within an LSTM-CRF architecture, we can reach an F1-score of 90.25, a 6.5point improvement over the previously state-of-the-art system SEM (Dupont, 2017).",entailment
1185,dev_1185,Graph attention is used for capturing such global semantic information in a graph.,"it allows each node to deal with the triples that are composed of the embeddings of the neighbor nodes, embeddings of the corresponding edges, and its own embedding.",entailment
1186,dev_1186,"Most models, including a GCN (Damonte and Cohen, 2019), GGNN (Beck et al., 2018), and GraphLSTM (Song et al., 2018), use a nonpairwise interaction function to represent the information to be aggregated from the neighborhoods.","they ignore the receiver node (i.e., the node to be updated), operating only on the sender node (i.e., the neighbor node) and the edge attribute (Battaglia et al., 2018).",entailment
1187,dev_1187,"However, most previous works are not designed for QDA.",they do not aim to generate context-relevant questions for improving downstream model performance.,entailment
1188,dev_1188,Figure 2 illustrates the process of question rewriting.,we take the process of rewriting an answerable question to a relevant unanswerable question as an example to present the process.,entailment
1189,dev_1189,The reason might be that the autoencoder trained with denoising task will be insensitive to the word embedding revision of CRQDA.,"some revisions guided by the MRC gradients might be filtered out as noises by the autoencoder, which is trained with a denoising task.",entailment
1190,dev_1190,"Experiment results demonstrate its validity and effectiveness where state-of-the-art performance is achieved on many tasks using the ngrams, which are automatically learned from the training data other than external or prior knowledge.",our method outperforms some existing encoders trained on much larger corpora.,entailment
1191,dev_1191,"Compared to ERNIE 2.0, which used many more pre-training tasks and significantly more non-public training data, ZEN is still competitive on SA, SPM and NLI tasks.","zEN outperforms ERNIE 2.0 (B) on SA (TEST) and SPM (TEST), which indicates that ngram enhanced character-based encoders of zEN can achieve performance comparable to approaches using significantly more resources.",entailment
1192,dev_1192,The word suggestions are determined by a language model.,they are the top-n words with highest probability that begin with the prefix of the word that has been typed so far.,entailment
1193,dev_1193,"To fill this gap, we propose to investigate particular orderings of persuasive strategies that affect a request's persuasiveness and identify situations where these orderings are optimal.","we take a closer look at strategies (Table  1) and their orderings in requests from the subreddit/online lending community r/Borrow 1; and utilize them to examine research questions like: When should requesters follow strategy orderings (e.g., ending loan requests with politeness) that rely on social norms?",entailment
1194,dev_1194,"All experiments are performed with the Transformer architecture (Vaswani et al., 2017) using the open-source Tensorflow-Lingvo implementation (Shen et al., 2019).","we use the Transformer Big model containing 375M parameters (6 layers, 16 heads, 8192 hidden dimension) (Chen et al., 2018) and a shared source-target Sen-tencePiece model (SPM) 3 (Kudo and Richardson, 2018).",entailment
1195,dev_1195,We propose a more rigorous annotation paradigm for NLP that helps to close systematic gaps in the test data.,"after a dataset is constructed, we recommend that the dataset authors manually perturb the test instances in small but meaningful ways that (typically) change the gold label, creating contrast sets.",entailment
1196,dev_1196,"This is especially helpful in the case of commonsense KGs (e.g., ConceptNet (Speer et al., 2017)) that consist of non-canonicalized text and hence suffer from severe sparsity (Malaviya et al., 2019).","these methods usually feed concatenated triples (e.g., [HEAD, Relation, TAIL]) into LMs for training or finetuning.",entailment
1197,dev_1197,"Compared to the second class, we learn from free-form text through MLMs rather than triples, which fosters generalization on other downstream tasks.","given a corpus of raw text and a KG, two KG-guided self-supervision tasks are formulated to inject structured knowledge into MLMs.",entailment
1198,dev_1198,"It explores implicit relational information underlying raw text by the guidance of a KG, and is shown to mask more informative entities compared to the previous random approaches.",the scheme is designed to avoid or reduce masking two types of entities: trivial and undeducible.,entailment
1199,dev_1199,"This work is in line with Baidu-ERNIE (Sun et al., 2019a) and SpanBERT  which replace word-level mask (Devlin et al., 2019) with span-level one for knowledge information and longterm dependency.","baidu-ERNIE uses uniformly random masking for phrases and entities, whereas SpanbERT directly masks out token spans sampled under geometric distribution.",entailment
1200,dev_1200,"All these tests try to capture some fixity of the expressions, that tend to entail idomaticity as productive composition rules can not be applied.","the fixedness of a MWE can be identified by applying a transformation on the given MWE that leads to an unexpected meaning shift or an unacceptable sequence, with respect to a regular setting.",entailment
1201,dev_1201,"To this end, a practitioner assumes a probability distribution on the observations y, parameterized by θ, the properties of the systems.",y is assumed to have a distribution 5 with unknown parameters θ.,entailment
1202,dev_1202,A 95% CI of this quantity provides a range of values that are not rejected under the corresponding null-hypothesis.,"a 95% CI gives θ1 − θ2 ∈ [0.0136, 0.057] (details in §A.2).",entailment
1203,dev_1203,"In Bayesian inference frameworks, a priori assumptions and beliefs are encoded in the form of a prior distribution P(θ) on parameters of the model",a prior distribution describes the common belief about the parameters of the model.,entailment
1204,dev_1204,We argue that what is crucial to the cross-modality attention layer is the ability to selectively enrich the semantic representation of a sentence through the aid of an image.,"we need to avoid introducing noises resulted from when the image fails to represent some semantic meaning of words, such as abstract concepts.",entailment
1205,dev_1205,"However, a standard language modeling objective does not lead to a model that handles the two challenges mentioned above; in addition, other systematic issues limit its ability to handle TCS.",language models do not directly utilize the ordinal relationships among temporal units.,entailment
1206,dev_1206,"We assume adjacent units have a distance of 1, and we generate y based on a Gaussian distribution with a standard deviation of 0.5.",we assume the two immediate neighbors of a gold label are reasonably possible.,entailment
1207,dev_1207,"To produce more general representations, we also keep the temporal label and mask the event tokens instead at a certain probability, so that we are able to maximize both P (Tmp-Label|Event) and P (Event|Tmp-Label) in the same learning process, where Tmp-Label refers to the temporal label associated with the event.","we use the reserved ""unused"" tokens in BERT-base model lexicon to construct a 1-to-1 mapping from every value in every dimension to the new vocabulary.",entailment
1208,dev_1208,We use weight adjustment to fix this.,we apply weight adjustment to the total loss with a weight factor calculated as the observed label's count relative to the number of all instances.,entailment
1209,dev_1209,"For example, ""I brush my teeth [Month]"" will be discarded because all candidate answers are approximately uniformly distributed so that one cannot identify a subgroup of labels to be more likely.","we ask one annotator to select from 4 choices regarding each (event, temporal value) tuple.",entailment
1210,dev_1210,"Beyond unsupervised intrinsic experiments, we also evaluate the capability of the event temporal representation as a product of our model.",we finetune both BERT baseline and our model with the same process to compare the internal representations of the transformers.,entailment
1211,dev_1211,Lexical semantic change models build on the assumption that meaning change results in the modification of a word's linguistic distribution.,"with the exception of a few methods based on word frequencies and parts of speech (Michel et al., 2011; Kulkarni et al., 2015), lexical semantic change detection has been addressed following two main approaches: form-based and sense-based (for an overview, see Kutuzov et al., 2018; Tang, 2018).",entailment
1212,dev_1212,"By metaanalyzing a set of existing NLP papers and datasets, we characterize typical power for a variety of settings and conclude that underpowered experiments are common in the NLP literature.","for several tasks in the popular GLUE benchmark, small test sets mean that most attempted comparisons to state of the art models will not be adequately powered.",entailment
1213,dev_1213,"When one does not have access to the baseline model or an informative prior, one can make use of historical trends.","we can try to estimate what a typical improvement will look like, given the current state of the art (SOTA).",entailment
1214,dev_1214,We also observe a slight negative correlation between effect size and sample size.,"as sample size gets larger (and, thus, as estimates get more precise), the estimated effect size gets smaller.",entailment
1215,dev_1215,"In this paper, we present a large dataset to foster computational studies on the natural selection of English words.",the dataset includes sets of synonymous monosemous words and their frequencies in English books across 200 years.,entailment
1216,dev_1216,We follow existing approaches to obtain an opinion set Or for every review in our corpus.,"we used a pre-trained tagging model (Miao et al., 2020) to extract opinion phrases, their polarity, and aspect categories.",entailment
1217,dev_1217,"While CLWE enable many multilingual tasks (Klementiev et al., 2012;Guo et al., 2015;Zhang et al., 2016;Ni et al., 2017), most recent work only evaluates CLWE on bilingual lexicon induction (BLI).","a set of test words are translated with a retrieval heuristic (e.g., nearest neighbor search) and compared against gold translations.",entailment
1218,dev_1218,"This is run with min-occur set to 1, in order to preserve information and provide a fair, higher-AMI clustering that incorporates a maximum amount of corpus knowledge.",we do not eliminate low frequency words from the vocabulary.,entailment
1219,dev_1219,"We attribute this to the Zipf-Mandelbrot distribution of word frequencies (Montemurro, 2001) and the effect frequency has on each word type's contribution to global mutual information.","the majority of words share little mutual information with most other words; thus, most words may be clustered quickly and will not later be moved -later cluster changes are unlikely to have strong far-reaching effects.",entailment
1220,dev_1220,"For the last experiment, we compute and report our ablation results over 2 factors in Table 4.",the scores degrade on FB13 and SEARCH17 when not using the positional embeddings.,entailment
1221,dev_1221,"In the pattern matching of term lists against abstracts, we basically performed matching within generated variations of term list entries.",we applied lemmatization process and regular expression based pattern matching.,entailment
1222,dev_1222,"Moreover, two graph convolutional networks are leveraged to learn the latent representations depicting how sessions interact with one another in terms of users, and how posts are correlated with each other in terms of words.","we address several challenges in this work: (a) how to perform explainable cyberbullying detection that can boost detection performance, (b) how to highlight explainable comments without the ground truth, (c) how to model the correlation between posted text and user comments, and (d) how to model the interactions between sessions in terms of users, and the interactions between textual posts in terms of words.",entailment
1223,dev_1223,"Inspired by (Yang et al., 2016),  we adopt a hierarchical neural network to model word-level and sentence-level representations through selfattention mechanisms.",we first learn the comment embedding vector by utilizing the word encoder with self-attention.,entailment
1224,dev_1224,"That said, we intend to simultaneously learn and derive the attention weights of words on posted text and comments.","first, similar to comment encoding, word embeddings of a posted text are obtained by a pre-trained word2vec model.",entailment
1225,dev_1225,"To answer EQ3, we examine whether HENIN can accurately detect cyberbullying sessions at early stages.",we aim to understand how a model performs given only a partial proportion of observed comments.,entailment
1226,dev_1226,We choose GRU+A as the baselines for comment explainability since it can learn attention weights for comments as a kind of explainability.,we want to see if the top-ranked explainable comments determined by our HENIN are more likely to be related to the major contexts in cyberbullying media sessions.,entailment
1227,dev_1227,"Memory Utilization Surprisingly, the top-1 memory usage of the PKM-augmented PLM at the 4th layer is about 2%, which is remarkably low, though top-32 memory usage at this layer is almost 100%.",the model does not take advantage of the lower memory layer effectively.,entailment
1228,dev_1228,"In this work we conduct a systematic study of the effects of backtranslated data from different sources, as well as how to optimally select subsets of this data taking into account the loss in quality and lexical richness when data is translated with different MT systems.",we aim to (i) provide a systematic analysis of backtranslated data from different sources; and (ii) to exploit a reduction in the amount of training data while maintaining high translation quality.,entailment
1229,dev_1229,concatenate the data backtranslated with all the systems and select the optimal sentence pairs avoiding the selection of the same target sentence more than once.,each selected target sentence will have only one associated source sentence originating from one specific system.,entailment
1230,dev_1230,The vector of a context-insensitive word is assigned a higher norm.,"if a word is usually found in specific contexts, it should be regarded as a significant word (Luhn, 1958).",entailment
1231,dev_1231,"Motivated by these works and our preliminary experimental results, we propose to use the word vector norm as a criterion to determine the difficulty of a sentence.","we first train a simple word embedding model on the training corpus, and then obtain an embedding matrix E w2v .",entailment
1232,dev_1232,"To clear up any doubts, we further conducted the experiments on the large-scale Zh-En translation without tuning these two hyperparameters, that is, directly using λm = 2.5 and λw = 0.5.","the only difference is the use of a large number of training steps in Zh-En, namely, 150K, for the purpose of better model fitting.",entailment
1233,dev_1233,The line before the change is called the source and the line after is the target.,an edit is a pair of the source and the target.,entailment
1234,dev_1234,"We used NanigoNet 8 , a language detector based on GCNNs (Gated Convolutional Neural Networks) (Dauphin et al., 2017) that supports human languages as well as programming languages.",we ran the language detector against both the source and the target and discarded all the edits where either is determined as written in a non-human language.,entailment
1235,dev_1235,"Finally, after annotating a small amount of samples for the three languages, we computed some basic statistics about each edit that may help in classifying typo edits from nontypo ones.",we computed three statistics: 1. Ratio of the target perplexity over the source calculated by a language model 2. Normalized edit distance between the source and the target 3. Binary variable indicating whether the edit purely consists of changes in number,entailment
1236,dev_1236,"Owing to the challenges posed in reasoning over formal representations (Musen and Van Der Lei,1988), and backed by the recent successes of transformers (Vaswani et al., 2017) in NLP, Clark et al. (2020) propose a new version of the problem by replacing the formal representations of rule-bases with natural language (English). ","their task requires predicting the truth value of a statement by reasoning over a set of facts and rules, all expressed in natural language.",entailment
1237,dev_1237,The connectivity constraint provides only marginal improvement as our model mostly predicts connected proofs without any explicit supervision.,only 57 examples have disconnected proofs without this constraint.,entailment
1238,dev_1238,Almost all contemporary search systems are based on datadriven techniques that train computers to improve search and information retrieval.,user activity history is the most crucial data for ranking search results by their popularity and relevance.,entailment
1239,dev_1239,Note that voice suffixes in Turkish can be stacked.,"a passive suffix and a causative suffix can be found on a single verb, or a verb can take two passive suffixes and become a double passive construction.",entailment
1240,dev_1240,Neural network-based language models (LMs) have been shown to learn relevant properties of language without being explicitly trained for them.,"recent work suggests that they are able to capture syntactic relations to a large extent (Gulordava et al., 2018; Kuncoro et al., 2018; Wilcox et al., 2018)",entailment
1241,dev_1241,"SCM requires to model the relationship between cases from the information of different granularity, like fact level, event level and element level.","sCM is a particular form of semantic matching (Xiao et al., 2019), which can benefit the legal information retrieval.",entailment
1242,dev_1242,"Different from previous news classification tasks whose category set is general topics like entertainment and sports, MATINF-C is a fine-grained classification under a single domain.","the distance between different categories is smaller, which provides a more challenging stage to test the continuously evolving state-of-the-art neural models.",entailment
1243,dev_1243,"Though recent studies show that multi-task learning is effective, there is still one more question to answer.","when training models on multiple tasks, multiple datasets are used by default.",entailment
1244,dev_1244,"We take into account only the two ends of the scale, namely only the highly polarized text.","we consider the articles with bias score 1 and 2 as unbiased (negative class), and the ones with bias score 4 and 5 as biased (positive class).",entailment
1245,dev_1245,"As a first step to examine the quality of the human labels, we measure the inter-annotator agreement (ITA) within each collection.","we calculate the agreement for the expert dataset, the Figure Eight dataset and the MTurk dataset separately.",entailment
1246,dev_1246,We model messagelevel representation from its word sequence.,"given u's historical message m, we first use a pre-trained word embedding layer to map each word into a vector space, and then employ a Convolutional Neural Network (CNN) (Kim, 2014) encoder to model word occurrence with their neighbors.",entailment
1247,dev_1247,"We, then, use word-to-word translation to code-switch (CS) the English training set with the target language (T L) for these words.","we replace all utterances of ""important"" words with it's TL dictionary translation.",entailment
1248,dev_1248,"Rather than blaming individual shooters, the German press paid more attention to U.S. public opinion manifesting as gun violence protests and the U.S. gun regulations.","compared to the U.S.'s news coverage, foreign media tended to attribute the responsibility to the U.S. government.",entailment
1249,dev_1249,"Hence, we propose a novel wordaligned attention to exploit explicit word information, which is complementary to various character-based Chinese pre-trained language models.",we devise a pooling mechanism to align the character-level attention to the word level and propose to alleviate the potential issue of segmentation error propagation by multi-source information fusion.,entailment
1250,dev_1250,One possible reason for the result is that the cop (between arguments and predicates) sets up a bridge for sib and gp structures.,these observations suggest that the three structure learning may be complementary.,entailment
1251,dev_1251,"Pre-training can bring about a significant improvement in performance on both in-domain and out-of-domain test sets; however, the in-domain improvement is significantly greater than that of out-of-domain when the two domains are far apart.","the difference between in-domain and out-of-domain in German and English is large, while the two domains in Czech are similar.",entailment
1252,dev_1252,We take as our starting point a state-of-theart image captioning system and develop several model variants that exploit information from human gaze patterns recorded during language production.,we propose the first approach to image description generation where visual processing is modelled sequentially.,entailment
1253,dev_1253,"We hypothesise that a system that encodes gaze data as a proxy for human visual attention will lead to better, more human-like descriptions.",we propose that training such a system with eye-movements sequentially aligned with utterances (see Figure 1) will produce descriptions that reflect the complex coordination across modalities observed in cognitive studies.,entailment
1254,dev_1254,"We utilise the Dutch Image Description and Eye-Tracking Corpus (DIDEC;van Miltenburg et al., 2018).","we use the data collected as part of the description-view task in DIDEC, where participants utter a spoken description in Dutch for each image they look at.",entailment
1255,dev_1255,"To empirically motivate our generation models, as a preliminary experiment we investigate the level of coordination between visual attention and linguistic production in the DIDEC dataset.",we test whether scanpath similarity and sentence similarity are correlated and whether taking into account the sequential nature of the two modalities results in higher cross-modal alignment.,entailment
1256,dev_1256,We take the original model as our baseline and modify it to integrate visual attention defined by gaze behaviour.,we replace the meanpooled vector v by a gaze vector g computed from masked images representing fixation patterns as explained in Section 3.,entailment
1257,dev_1257,"In order to generate story-like textual descriptions that complement the factual captions, we additionally train our model to exploit our diverse completesentence annotations.","instead of producing the commonsense knowledge given the videos and captions, we finetune our pre-trained V2C-Transformer model on predicting the human rewritten texts, and generate complete story-like captions.",entailment
1258,dev_1258,"Since the neural networks can be near-perfect nonlinear function approximators (Liang and Srikant, 2016), we can expect an NAR model to learn the AR translation process quite well, as long as the model has enough capacity.","we first obtain the greedy output of a trained AR model, and use the resulting paired data to train the NAR model.",entailment
1259,dev_1259,"For instance, a sequence labelling model with a 60% accuracy at sentence level means that only 60 % of positive events are covered by the set corresponding to argmax y p Î¸ (y|x) predictions.",only 60 % of the correct outputs of model p Î¸ will be used for constructing the forecaster.,entailment
1260,dev_1260,"Although we confirm the results presented in this work, we demonstrate that the method presented there is not sufficiently robust to handle mappings between a bit more distant languages.",we show that some Slavic languages (Czech and Polish) are quite challenging for the method.,entailment
1261,dev_1261," Turning now to (R2), we argue that work analyzing ""bias"" in NLP systems should provide explicit statements of why the system behaviors that are described as ""bias"" are harmful, in what ways, and to whom, as well as the normative reasoning underlying these statements.","researchers and practitioners should articulate their conceptualizations of ""bias.""",entailment
1262,dev_1262,"Participatory action research in education (Kemmis, 2006) and in language documentation and reclamation (Junker, 2018) is also relevant.","work on language reclamation to support decolonization and tribal sovereignty (Leonard, 2012) and work in sociolinguistics focus-ing on developing co-equal research relationships with community members and supporting linguistic justice efforts (e.g., Bucholtz et al., 2014Bucholtz et al., , 2016Bucholtz et al., , 2019 provide examples of more emancipatory relationships with communities.",entailment
1263,dev_1263,"Different from previous studies which utilize various external information limited to a specific scenario, our model incorporating historical dialogue information into generation is easy to generalize and applied to practical applications.",we introduce a novel historical dialogue selection strategy to find appropriate historical seller responses for the latest customer question.,entailment
1264,dev_1264,These experiments explain such learning phases by showing that the training process is inherently compositional due to bottom-up learning.,"not only are the shorter sequences learned first, but they form the basis for longer relations learned over them.",entailment
1265,dev_1265,These results indicate that predictable patterns play a vital role in shaping the representations of symbols around them by composing in a way that cannot be easily linearized as a sum of the component parts.,"as seen in Figure 10, the DI between open symbol and scaffold is substantially higher for the familiar-setting model and increases throughout training.",entailment
1266,dev_1266,"We use word similarity to extend these seed words and finally got a dictionary with 3,227 fine-grained semantic words.",we use spaCy to compute the similarity between words.,entailment
1267,dev_1267,"Given the MIMIC database as substrate and the aforementioned policy initiatives to reduce unnecessary hospital readmissions, as well as the goal of providing structure to text, we elected to focus on patients who were frequently readmitted to the ICU (Ryan et al., 2015).",a patient who is admitted to the ICU more than three times in a single year.,entailment
1268,dev_1268,"In this work, we adapt general-purpose extractive summarization algorithms (Nallapati et al., 2017;Zheng and Lapata, 2019) to identify informative scenes in screenplays and instill in them knowledge about narrative film structure (Hauge, 2017;Cutting, 2016;Freytag, 1896).",we adopt a scheme commonly used by screenwriters as a practical guide for producing successful screenplays.,entailment
1269,dev_1269,We first present an unsupervised variant which modifies the computation of scene centrality in the directed version of TEXTRANK (Equation 1).,we use the pre-trained network described in Section 3.3 to obtain TP-specific attention distributions.,entailment
1270,dev_1270,We should note that Frermann et al. (2018) discriminate between different cases presented in the same episode in the original CSI dataset.,"there are episodes in the dataset, where except for the primary crime investigation case, a second one is presented occupying a significantly smaller part of the episode.",entailment
1271,dev_1271,"where h is a simple linear layer for classification, and the parameters of both language model and the linear layer will be fine-tuned on the downstream commonsense reasoning task.","in the training process, the objective is to minimize the negative log-likelihood of ground-truth answers a * i as follows.",entailment
1272,dev_1272,"In this paper, we investigate the Knowledge Distillation (KD) method, which has been shown to be effective for knowledge ensembling (Hinton et al., 2015;Kim and Rush, 2016;Furlanello et al., 2018), for heterogeneous structure integration.","we employ a sequential LSTM as the student for distilling heterogeneous syntactic structures from various teacher tree encoders, such as GCN (Kipf and Welling, 2017) and TreeLSTM (Tai et al., 2015a).",entailment
1273,dev_1273,"This work used the Extreme Science and Engineering Discovery Environment (XSEDE), which is supported by National Science Foundation grant number ACI-1548562.",it used the Bridges-GPU AI system at the Pittsburgh Supercomputing Center (PSC) through allocations TG-CCR200004.,entailment
1274,dev_1274,"As for the generation models, we compute several metrics that are commonly used in the domain of Natural Language Generation.","we consider three measures based on n-gram matching: BLEU-2 (Papineni et al., 2002), 8 ROUGE (Lin, 2004), and observed.",entailment
1275,dev_1275,Haber et al. (2019) reported a rise in the proportion of content words for all utterance types in later rounds of the PhotoBook games.,"we also observe such an increase in our referring utterance chains, and a similar trend is exhibited as well by the output of the ReRef and Copy models: generated subsequent references contain a significantly higher proportion of nouns and adjectives compared to first descriptions.",entailment
1276,dev_1276,"In comparison to NEO, SCAN tends to assign even more extreme probabilities.","sCAN tends to make more serious errors: in more than 5 millions cases, the predicted probability is 0 (or close to 0) for the gold sense instead of 1.",entailment
1277,dev_1277,We investigate how the size of each sense (as opposed to the full target size) contributes to the performance of the model.,we observe the difference between targets where the senses have a similar size and targets where there is a strong imbalance between the senses.,entailment
1278,dev_1278,The model architecture of CoMMA is shown in Figure 1.,"coMMA differs from standard Transformer (Vaswani et al., 2017) as follows: 1) Some tokens are randomly replaced by a special mask token M with probability p, and the model is trained to predict original unmasked tokens.",entailment
1279,dev_1279,"It incorporates analyses and predictions from various tools designed for processing texts in Sanskrit, and utilises them to ease the cognitive load of the human annotators.","sHR++ uses sanskrit Heritage Reader (Goyal and Huet, 2016), a lexicon driven shallow parser for enumerating all the phonetically and lexically valid word splits along with their morphological analyses for a given string.",entailment
1280,dev_1280,This section elaborates on the mechanism of our proposed affective neural networks.,how we incorporate affective influence values into affective deep neural networks.,entailment
1281,dev_1281,"It is based on the assumption that people tend to maintain culturally shared perceptions of identities and behaviors in transient impressions during observation and participation of social events (Joseph, 2016).","social perceptions, actions, and emotional experiences are governed by a psychological intention to minimize deflections between fundamental sentiments and transient impressions that are inherited from the dynamic behaviors of such interactions.",entailment
1282,dev_1282,"Hence, the proposed stock embedding represents the price as well as the semantics of the text, as we acquire it by training on both news articles and stock prices.","our stock embedding is trained through a binary classification problem, namely, whether a stock price goes up or down in comparison with the previous day's price.",entailment
1283,dev_1283,"This setting enables learning of the correlation among stocks, in addition to avoiding overfitting and the problem of small sample sizes.","the classifier is shared across all stocks, thus achieving a sample size about 50 to 100 times larger.",entailment
1284,dev_1284,"At the beginning of each year, given some expected gain E, the portfolio was computed by using all news articles and historic prices until the end of the previous year.","for each year, the training set in the experiment consisted of samples strictly earlier than those constituting the test set.",entailment
1285,dev_1285,"While a reader could not know that the visitor is the same individual as the author when reading the letter above, we treat all mentions as coreferent if a reader can determine that they are identical at any point in the narrative.","we annotate from the perspective of the textual reality, rather than from the reader's state of knowledge at the moment of encountering the mention to be resolved.",entailment
1286,dev_1286,"Firstly, teacher-student learning can probably help to learn label preferences for some specific words in the target language.","if a word appears in the unlabeled target-language data and the teacher model consistently predicts it to be associated with an identical label with high probabilities, the student model would learn the preferred label w.r.t that word, and predict it in cases where the sentence context may not provide enough information.",entailment
1287,dev_1287,"Pre-trained Transformers are now ubiquitous in natural language processing, but despite their high end-task performance, little is known empirically about whether they are calibrated.",do these models' posterior probabilities provide an accurate empirical measure of how likely the model is to be correct on a given example?,entailment
1288,dev_1288,"In order to arrive at our goal of data set equivalents of KORE 50 for YAGO, Wikidata and Crunchbase, some work was necessary prior to the manual annotation of input documents.",we had to prepare the KORE 50 data set for the annotation by extracting all sentences from the data set.,entailment
1289,dev_1289,"On the other hand, we observe that the community votes of each answer can be a valuable numerical indicator reflecting its veracity.","in PQA forums, each answer can receive upvotes and downvotes from the former buyers.",entailment
1290,dev_1290,"To investigate the effectiveness of our proposed evidence ranking strategy, we substitute it with two possible alternatives and present the results in Table  5.","we first report the results with QA pair only (""QA only"") as a base model.",entailment
1291,dev_1291,"However, here we expand upon the recently introduced task of unsupervised question answering (Lewis et al., 2019) to examine the extent to which synthetic training data alone can be used to train a QA model.","we focus on the machine reading comprehension setting in which the context is a given paragraph, and the QA model can only access this paragraph to answer a question.",entailment
1292,dev_1292,We focus mainly on factoid QA; the question concerns a concise fact.,"we emphasize questions whose answers are named entities, the majority type of factoid questions.",entailment
1293,dev_1293,"We evaluate the proposed model on three benchmark task-oriented dialog datasets: the Cambridge Restaurant (CamRest676) (Wen et al., 2017b), Stanford In-Car Assistant (In-Car) (Eric et al., 2017) and MultiWOZ (Budzianowski et al., 2018), with 676/3031/10438 dialogs respectively.","multiWOZ is one of the most challenging dataset up-to-date given its multi-domain setting, complex ontology and diverse language styles.",entailment
1294,dev_1294,"In the sentence, the spans highlighted in red are aspect terms and the spans in blue are opinion terms.","the tag A represents that the two words of word-pair (wi , wj ) belong to the same aspect term.",entailment
1295,dev_1295,"We proposed ESD, a context-aware definition generation model that explicitly models the decomposed semantics of words.","we model the decomposed semantics as discrete latent variables, and training with auxiliary losses to ensure that the model learns informative latent codes for definition modeling.",entailment
1296,dev_1296,This motivates us to explore font associations with regular users in a crowd-sourced setting.,we investigate how users relate fonts to different characteristics of the input text.,entailment
1297,dev_1297,Instead we aim to train all human's embeddings to be neutral with respect to sensitive attributes.,"we wish to make it impossible to predict, for example, a person's gender, from their embedding.",entailment
1298,dev_1298,"As a second method of measuring the extent to which sensitive information remains in the trained embeddings, we train a feedforward neural network to try and predict the attributes of a human entity from their embedding alone.","the input to the network is the embedding of dimension d, and the output is a softmax distribution over labels (male and female for gender).",entailment
1299,dev_1299,"However, the results imply that gestures can be employed to predict audience response to some extent as well.",head movements seem to be good indicators.,entailment
1300,dev_1300,"We now fully specify our approach by describing our model, how we find pairs in the unlabeled pool D train all to query, and how we choose the seed set B 1 .","a key technical challenge is that the set of training pairs D train all is too large to enumerate, as it grows quadratically.",entailment
1301,dev_1301,"To address the issues, we propose meta graph learning (MGL), a meta learning framework to learn how to cross-lingual transfer for mPLM.","mGL models each CLT process as heterogeneous information propagation over a dynamic graph, which captures latent language correlations and makes the downstream CLT adaptation more interpretable.",entailment
1302,dev_1302,"Taking the AMR in Figure 1(a) as an example, a model may produce ""the girl wants the boy to go"", which conveys an opposite meaning to the AMR graph.","this can be very likely if ""the girl wants"" appears much more frequent than ""the boy wants"" in the training corpus.",entailment
1303,dev_1303,We proposed reconstructing input graphs as autoencoding processes to encourage preserving the input semantic information for graph-to-text generation.,"the auxiliary losses for recovering two complementary views (triple relations and linearized graph) of input graphs are introduced, so that our model is trained to retain input structures for better generation.",entailment
1304,dev_1304,"For each input phone, one can also define a binary measure of focus at level l, which checks that the focus of the frames at that level has not shifted to an input phone other than the one whose frames it corresponds to.",this binary focus measure is 1 if the focus of the phone at a level as defined above is larger than the contribution from the input frames of every other phone.,entailment
1305,dev_1305,"Finally, we showcase how the structure of OneStopQA annotations can be used for detailed comparisons between human and machine readers.","we demonstrate that human subjects and a state-of-the-art machine reading comprehension model have similar distributions of erroneous answers, suggesting a deeper link between human and machine readers than previously reported.",entailment
1306,dev_1306,"We observe that the two weaker models, Sliding Window and Stanford AR, perform better on RACE than on OneStopQA.","notable is the large drop in the performance of Stanford AR from 42.8 on RACE to 34.3 on OneStopQA (p << .001, ttest).",entailment
1307,dev_1307,"We use datapoints from Github repositories, where each bimodal datapoint is an individual function with paired documentation, and each unimodal code is a function without paired documentation.","we use a recent large dataset  provided by Husain et al. (2019), which includes 2.1M bimodal datapoints and 6.4M unimodal codes across six programming languages (Python, Java, JavaScript, PHP, Ruby, and Go).",entailment
1308,dev_1308,"Although the pre-training objective of Code-BERT does not include generation-based objectives , we would like to investigate to what extent does CodeBERT perform on generation tasks.","we study code-to-NL generation, and report results for the documentation generation task on CodeSearchNet Corpus in six programming languages.",entailment
1309,dev_1309,We focused on only two of the five classes of TPs and FPs.,we focused on the two classes that can help us measure the model's precision.,entailment
1310,dev_1310,HK and TW literature consists of popular books for which many movie and drama adaptations are made.,"for HK literature, the text contains code-mixed characters with Vernacular Cantonese, which is quite unusual in formal publishing practices, and these books are often cited as an example for popularizing Cantonese in the 60s (Snow, 2004).",entailment
1311,dev_1311,"Here, we provide further details on how we applied our methodology to the dataset of counseling conversations in order to measure the orientation of counselor utterances, as described in Section 5.","we list empirical choices  made in extracting and then processing the training set of 351,935 texter and counselor messages used to measure phrasing orientations.",entailment
1312,dev_1312,"Here, we provide further details about the subset of data we used to analyze counselors' orientation behavior (Section 5.4).",our aim was to characterize behavior in typical conversations rather than exceptional cases or those that reflected earlier versions of the training curriculum.,entailment
1313,dev_1313,This can be explained by the geometric similarity between the embedding spaces of the two languages.,"we measure the geometric similarity of the language pairs using the Gromov-Hausdorff (GH) distance (Patra et al., 2019), which is recently proposed to quantitatively estimate isometry between two embedding spaces.",entailment
1314,dev_1314,We further analyze our model by dissecting it and measuring the contribution of its different components.,"our goal is to assess the contribution of back-translation, reconstruction, nonlinearity in the mapper, and non-linearity in the autoencoder.",entailment
1315,dev_1315,"Obtaining salient words by applying existing saliency identification approaches (Ribeiro et al., 2018) is, however, unable to produce unified action representations.","system utterances with the same intention might not share similar wordings, and existing attribution approaches can only identify salient words within utterances.",entailment
1316,dev_1316,"Based on the learned state tracking model, a straightforward idea of obtaining salient words is to apply importance attribution approaches.","these approaches measure the importance of each word by observing the prediction difference caused by replacing it (Ribeiro et al., 2018; Jin et al., 2020).",entailment
1317,dev_1317,"To address this issue, we adopt a denoising training strategy inspired by unsupervised machine translation (Lample et al., 2018(Lample et al., , 2019, and obtain a DST model that is more robust to the attribute transformation.","we apply a noise function g(x) to the utterances, and modify the DST model training loss as: where the noise function corrupts the input utterance by performing word drops and word order shuffling as specified in Lample et al.",entailment
1318,dev_1318,"In the cross-domain setting, we adopt a leave-one-out approach to evaluate the generalization ability via a more challenging few-shot learning task.",we use one domain as low-resource target domain (with only 1% of dialogues are available for training) while the others as source domains.,entailment
1319,dev_1319,"We consider mainly two types of content planning model that works on natural language actions: action decoder and classifier, denoted as Act-DEC and Act-CLS, respectively.","an action decoder generates a text span and feed it to the language generation model, while action classifier conducts classification to select one action from the action set given by the training set.",entailment
1320,dev_1320,We create an auxiliary reading comprehension (RC) task from these documents.,"if a document contains both problem and solution sections, a synthetic example is created where the problem description section is the query, the solution section is the target answer, and the entire document excluding the query section is the context.",entailment
1321,dev_1321,"Although ROBERTA's pretraining corpus is derived from multiple sources, it has not yet been established if these sources are diverse enough to generalize to most of the variation in the English language.",we would like to understand what is out of ROBERTA's domain.,entailment
1322,dev_1322,One benefit of annotating code-switched corpora is that such discrepancies between languages become noticed.,"if the same structure had been annotated differently for two different languages, say MSA and English, for which the treebanks had been developed independently, it now becomes clear when the two languages are juxtaposed in CS data that the annotation principles for at least one of the languages have to change in order to achieve the goal of having a unified annotation across languages.",entailment
1323,dev_1323,"We show here two examples from our corpus before we answer that question: 1. factor (the first factor, literally: the.factor the.first) 2. perspective camera (the perspective camera) In phrase 1, it is apparent that the speaker uses Arabic grammar rules, even though the noun is in English.",the noun as well as the adjective that is in concord with it are both in definite state and carry the Arabic definiteness morpheme.,entailment
1324,dev_1324,"In our experiments, we set the threshold to 0, PMI score lower than it will result in a segmentation.","for each dataset, we use PMI to perform unsupervised segmentation and collect the segmented words from it to build the n-gram lexicon N .",entailment
1325,dev_1325,"Table 8 reports the results in Fscore and OOV recall, which show a similar trend as that in Table 6, where WMSEG outperforms baselines for all five genres.","for genres with large domain variance (e.g., the ones with high OOV rates such as MZ and WEB), CWS is difficult, and its relatively low F-scores in Table 8 from baseline models confirm that.",entailment
1326,dev_1326,"Therefore, we test PMI and DLG in our model and compare them with the previous results from AV (see Table 6).","we use our best performing BERT-based model, i.e., BERT-CRF, with the n-gram lexicons constructed by the aforementioned three measures and run it on all benchmark datasets.",entailment
1327,dev_1327,"As shown in the figure, the performances of using the three measures are very similar, which indicates that WMSEG is able to robustly incorporate the wordhood information from various measures, despite that those measures focus on different aspects of n-grams when determining whether the ngrams should be treated as words.","consider that the lexicons produced by the three measures are rather different in their sizes (as shown in Table 4), the results in Figure 2 strongly demonstrate the effectiveness of our proposed approach in learning with a limited number of n-grams.",entailment
1328,dev_1328,"Therefore, we propose to train convolutional neural networks (CNNs) to generalize knowledge from the preliminary predictions given by the embedding space.","we first pre-train CNNs with soft predictions given by the cosine similarity between document embeddings and topic embeddings, and then adopt a self-training strategy to further refine the CNNs using their highconfident predictions on unlabeled documents.",entailment
1329,dev_1329,"In this paper, we enable the use of supervised techniques for unsupervised summarization.","we automatically generate a synthetic training dataset from a corpus of product reviews, and use this dataset to train a more powerful neural model with supervised learning.",entailment
1330,dev_1330,"The first study assessed the quality of the summaries using Best-Worst Scaling (BWS; Louviere et al., 2015), a less labor-intensive alternative to paired comparisons that has been shown to produce more reliable results than rating scales (Kiritchenko and Mohammad, 2017).","participants were shown the movie/business name, some basic background information, and a gold-standard summary.",entailment
1331,dev_1331,Our approach is simple and agnostic to the training objective.,we introduce an auxiliary loss function to guide the self-attention heads in each layer towards a set of pre-determined patterns (e.g.,entailment
1332,dev_1332,We demonstrate the effectiveness of our attention guidance loss through several empirical studies.,"we 1) report convergence results on masked language modeling, 2) evaluate trained language models on downstream tasks, and 3) analyze the learned attention representations using probes.",entailment
1333,dev_1333,"Motivated by recent studies (Clark et al., 2019;Lin et al., 2019; which posit that individual attention heads can encode linguistic information, we analyze attention patterns in the self-attention heads of our models.",we search for heads that can individually perform coreference resolution.,entailment
1334,dev_1334,"The key idea is to transfer the burden of context understanding from modeling to learning by designing several auxiliary tasks, and leverage the auxiliary tasks as regularization in model estimation.","the model we use for response generation concatenates utterances in a conversation context as a long sequence, and only exploits one-layer self-attention in encoding and one-layer context attention in decoding.",entailment
1335,dev_1335,"In this paper, we address the task of end-to-end speech recognition and disfluency removal.","we investigate whether it is possible to train an ASR model end-to-end to directly map disfluent speech into fluent transcripts, without an intermediate disfluency detection step.",entailment
1336,dev_1336,We design our experiments to determine if training an off-the-shelf LM architecture with our ILM framework can produce effective infilling models for a variety of datasets.,"we train on three datasets of different sizes and semantics (details in Appendix A): short STORIES (Mostafazadeh et al., 2016), CS paper ABSTRACTS, and song LYRICS.",entailment
1337,dev_1337,"At both training and test time, examples are fed from left to right; anything to the left of a green target is available to the model as context when predicting the target.","lM only considers past context, and lM-Rev only considers future.",entailment
1338,dev_1338,"In Table 4, we report results for a mixture of granularities.",we run the same mask function we use for training (Appendix B) on our test data and evaluate PPL on the masked spans.,entailment
1339,dev_1339,"We extract the first word in a chat interaction, the bag-of-words representations (binary flags and tf-idf scores) of the chat interaction and features from sentiment lexica.","we extract flags indicating whether the turn has a positive, negative or neutral word in the list by Hamilton et al. (2016), the sentiment score of the chat interaction (summation of sentiment scores per token over number of tokens), and a flag indicating whether the interaction contains a negative word from the list by Hu and Liu (2004). ",entailment
1340,dev_1340,"Our assumption concerning the need for the sentences used for extracting BERT representations to be a good semantic fit for adjectives in a scale, has not been confirmed by our evaluation.",differences between our methods when relying on carefully vs randomly selected sentences are minor.,entailment
1341,dev_1341,"On the other hand, the proposed measures uncover differences between the initially recalled and later retold stories that mirror the differences found between recalled and imagined stories (Table 2).","retold stories flow significantly more linearly than their initial counterparts in a pairwise comparison (Cohen's |d| = 0.17, p < 0.001; see Figure 3).",entailment
1342,dev_1342,"We crawled patients' public weblogs from TOBYO,5 a Japanese initiative of PatientsLikeMe, and reported the effects of drugs described therein.","we annotated spans describing drug reactions, related drug names, corresponding ICD-10 (the 10th edition of International Statistical Classification of Diseases and Related Health Problems created by the World Health Organisation) codes of reactions, and types of effects.",entailment
1343,dev_1343,"We regarded these sets of labels assigned to the span as a single annotation, i.e., concatenated each type of label as a single label.",we examined the agreement rate of an exact match of all possible annotation labels.,entailment
1344,dev_1344,The Precision values are not that high as numerous additional terms were annotated by the pipeline.,for processes we received twice the number of spurious terms as correct matches.,entailment
1345,dev_1345,"Currently, there are still a large amount of missing terms.","for biological, chemical and physical processes the ontological coverage is low.",entailment
1346,dev_1346,"We first apply sandwich transformers to a different domain, while retaining the other architectural aspects and hyperparameter settings from Baevski and Auli (2019).","we use the Toronto Books Corpus (Zhu et al., 2015), which has previously been used to train GPT (Radford et al., 2018) and also BERT (Devlin et al., 2019) (combined with Wikipedia).",entailment
1347,dev_1347,We propose a new multi-stage crowd workflow that substantially reduces expert involvement without sacrificing accuracy.,we introduce a unique filter stage based on the key observation that crowd workers are able to almost perfectly filter out incorrect options for labels.,entailment
1348,dev_1348,"While these works ask valuable questions, they embrace model-driven approaches for manipulating the attention weights and thereafter evaluate the post-hoc explainability of the generated machine attention.","they overlook the human factor in the evaluation process -which should be integral in assessing the plausibility of the generated explanations (Riedl, 2019).",entailment
1349,dev_1349,"Further, it is well known that human attention is itself subjective: given the same text and task, human annotators may not always agree on which words are important.",one single human's attention should rarely be regarded as the ground-truth for attention.,entailment
1350,dev_1350,"Under this definition, attention scores can be seen as partial transparency.","they provide a look into the inner workings of a model, in that they produce an easily-understandable weighting of hidden states (Wiegreffe and Pinter, 2019).",entailment
1351,dev_1351,"Giving the networks many examples of each construction with a large variety of different content wordsthat is, large amounts of highly varied evidence about the meaning of the closed-class words-we asked during the test phase how fragile this knowledge is when transferred to new open-class words.","our probes combine novel open-class words with familiar closed-class words, to test whether the closed-class words are treated systematically by the network.",entailment
1352,dev_1352,"Instead of only using entities as nodes, for each question we construct a hierarchical graph to capture clues from sources with different levels of granularity.","four types of graph node are introduced: questions, paragraphs, sentences and entities (see Figure 2).",entailment
1353,dev_1353,"For graph propagation, we use Graph Attention Network (GAT)  (Velickovic et al., 2018) to perform message passing over the hierarchical graph.","gAT takes all the nodes as input, and updates node feature h i through its neighbors N i in the graph.",entailment
1354,dev_1354,"If the ground-truth answer does not exist among the entity nodes, the entity loss is zero.","the entity loss will only serve as a regularization term, and the final answer prediction will only rely on the answer span extraction module as follows.",entailment
1355,dev_1355,"We use HotpotQA dataset (Yang et al., 2018) for evaluation, a popular benchmark for multi-hop QA.",two sub-tasks are included in this dataset: (i) Answer prediction; and (ii) Supporting facts prediction.,entailment
1356,dev_1356,"Instead of constructing importance scores over the input texts on which the model makes predictions, such methods rank training examples by their influence on the model's prediction for the test input (Caruana et al., 1999;Koh and Liang, 2017;Card et al., 2019).","we are interested in the use of influence functions (Koh and Liang, 2017), which are in a sense inherently 'faithful' in that they reveal the training examples most responsible for particular predictions.",entailment
1357,dev_1357,"Both models are implemented on top of BERT encoders (Devlin et al., 2019).","we use BERT-Base, with the first 8 of the 12 layers frozen, only fine-tuning the last 4 transformer layers and the final projection layer.",entailment
1358,dev_1358,"To capture and quantify relationships between targets and context words, Octa uses a selective self-attention mechanism that handles implicit or missing targets.","octa involves two layers of attention mechanisms for, respectively, selective attention between targets and context words and attention over words based on aspects.",entailment
1359,dev_1359,Octa outperforms all baselines.,"octa obtains a 2.6% and 1.6% accuracy improvement over BERT on SemEval-15 and SemEval-16, respectively.",entailment
1360,dev_1360,"We also report ROUGE (ROU) (Lin, 2004) and METEOR (MET) (Denkowski and Lavie, 2011) scores.","mETEOR also uses synonyms and stemmed forms of the words in candidate and reference sentences, and thus may be better at quantifying semantic similarities.",entailment
1361,dev_1361,"We hypothesize that mixing the sequence x with x changes the context for all tokens and injects too much noise, hence making learning the labels for the tokens challenging.","the relative distance between x and x in the manifold mapped by neural networks is further in sequence labeling than sentence classification (demonstrated in Figure 2), which is intuitively understandable as every data point in sentence classification is the pooling over all the tokens in one sentence while every token is a single data point in sequence labeling.",entailment
1362,dev_1362,"For instance, for the sentence ""Rare Hendrix song draft sells for almost $17,000"" and its paraphrased sentence ""A rare Hendrix song design is selling for just under $17,000"", although some words are different, the entity Hendrix keeps unchanged, and there are no extra entities added.",both contain one and only one entity (Hendrix) of the same type (Person).,entailment
1363,dev_1363,Hammerton (2003) and Collobert et al. (2011) are among the first several studies to model sequence labeling using neural networks.,"Hammerton (2003) encoded the input sequence using a unidirectional LSTM (hochreiter and Schmidhuber, 1997) while (Collobert et al., 2011) instead used a CNN with character level embedding to encode sentences.",entailment
1364,dev_1364,"Many applications, however, require trustworthy predictions that need to be not only accurate but also well calibrated.","a wellcalibrated model should produce reliable confident estimates for both in-distribution and out-ofdistribution (OOD) data: (1) For in-distribution data, a model should produce predictive probabilities close to the true likelihood for each class, i.e., confidence ≈ true likelihood.",entailment
1365,dev_1365,"As shown in Figure 1, we present the calibration of a BERT-MLP model for a text classification task on the 20NG dataset.","we train a TextCNN (Kim, 2014) and a BERT-MLP using 20NG 15 (the first 15 categories of 20NG) and then evaluate them on both in-distribution and OOD data.",entailment
1366,dev_1366,We propose two new regularizers using pseudo samples both on and off the data manifold to mitigate data scarcity and prevent over-confident predictions.,our method imposes two types of regularization for better calibration during fine-tuning: (1) On-manifold regularization: We first generate on-manifold samples by interpolating the training data and their corresponding labels along the direction learned from hidden feature space; training over such augmented on-manifold data introduces a smoothness constraint within the data manifold to improve the model calibration for in-distribution data.,entailment
1367,dev_1367,"The fixed time to produce phone labels, which must be performed before translation, becomes a greater proportion of overall training time at lower-resource settings.","the phone end-to-end model offers similar training time reduction over the baseline to , where downsampling reduces sequence lengths by up to 60%, with unreduced sequence lengths through earlier convergence; this model offers a better trade-off between time and performance.",entailment
1368,dev_1368,"As far as we know, we are the first to do a large-scale study on actively training Transformer (Vaswani et al., 2017) for NMT.","with a human translation budget of only 20% of the original parallel corpus, we manage to surpass Transformer trained on the entire parallel corpus in three language pairs.",entailment
1369,dev_1369,"In this work, we propose holistic metrics that evaluate distinctive aspects of generated dialogues.","we consider (1) context coherence of a dialogue: the meaningfulness of a response within the context of prior query, (2) language fluency of generated responses: the quality of phrasing relative to a human native speaker, (3) response diversity of a set of generated sentences: the variety in meaning and word choice of responses, and (4) logical self-consistency: the logical consistency of utterances from a dialogue agent.",entailment
1370,dev_1370,"The current work instead proposes to measure response diversity utilizing augmented datasets with controlled paraphrasing, which allows for measuring diversity among top-ranked responses conditional on paraphrased queries and hence avoiding the tradeoff or dependency between diversity and quality.","for a given query, we slightly tilt the corresponding element in the query-response joint space along the query dimension (achieved by paraphrasing-augmentation) and then measure the entropy of high-quality responses in the neighbourhood of the targeted query.",entailment
1371,dev_1371,The automatic metric based on augmented data has a stronger relation with that based on the baseline.,the metric based on CTG augmentation aligns with human judgments the closet.,entailment
1372,dev_1372,"In this paper, we present an evaluation framework to analyze social bias in NRE models.","we evaluate gender bias in English language predictions of a collection of popularly used and open source NRE models 1 (Lin et al., 2016;Wu et al., 2017;Liu et al., 2017;Feng et al., 2018).",entailment
1373,dev_1373,"Furthermore, since some data instances that are collected using distant supervision are noisy, we annotated the correctness of the test instances using Amazon Mechanical Turk annotations to perform a fair comparison.",we asked workers to determine whether or not a given sentence expressed a given relation.,entailment
1374,dev_1374,Our unsupervised HMM+IBM1 alignment model significantly outperforms (with p < 0.001) all baselines.,it gets much higher precision scores compared to all baselines.,entailment
1375,dev_1375,"We go on with studying bilingual word embedding by quantitative analysis of the new word pairs, which are detected by searching bilingual words that are neighbors in the word embedding space, and evaluate them using the ground-truth bilingual dictionary.","we split the Muse dictionary of Chinese-to-English into standard training set and test set as in BLI (Artetxe et al., 2018a).",entailment
1376,dev_1376,"The synthetic data is generated from English Wikipedia 5 , English Gigaword (Parker et al., 2011) and Newscrawl 6 as the previous work (Ge et    2018a; Zhang et al., 2019;Kiyono et al., 2019;Grundkiewicz et al., 2019) did, using back translation and sentence corruption.","we train a transformer (base) model (Vaswani et al., 2017) for back translation using the training data of the restricted track in the BEA-19 shared task.",entailment
1377,dev_1377,"In this paper, we address the above issue by adapting a novel architecture for cross-lingual models called XLM (Conneau and Lample, 2019) to zero-shot abusive language detection, a task that has gained increasing importance given the recent surge in abusive online behavior and the need to develop reliable and efficient methods to detect it.","we evaluate two methods to pre-train bilingual language models, one similar to the original XLM masked model, and the other based on a novel hybrid emoji-based masked model.",entailment
1378,dev_1378,"Our basic architecture relies on the XLM approach described in (Conneau and Lample, 2019), specifically developed to learn joint multilingual representations enabling knowledge transfer across languages.","we borrow from XLM the method developed for unsupervised machine translation, that relies on the Masked Language Model (MLM) objective (Devlin et al., 2019) applied to multiple monolingual datasets as pretraining.",entailment
1379,dev_1379,"With FullyQT, we achieve higher BLEU scores than all other quantization methods for the Transformer on multiple translation tasks and avoid any loss in BLEU compared to full-precision.","out of 35 experiments, 8-bit quantization performed better than full-precision in 21 cases.",entailment
1380,dev_1380,"(1) In low (32) dimensions, we improve over Euclidean-based models by up to 6.1% in the mean reciprocical rank (MRR) metric.","we find that hierarchical relationships, such as WordNet's hypernym and member meronym, significantly benefit from hyperbolic space; we observe a 16% to 24% relative improvement versus Euclidean baselines.",entailment
1381,dev_1381,"Baseline numbers in high dimensions (Table 5) are taken from the original papers, while baseline numbers in the low-dimensional setting (Table 2) are computed using open-source implementations of each model.",we run hyper-parameter searches over the same parameters as the ones in the original papers to compute baseline numbers in the lowdimensional setting.,entailment
1382,dev_1382,One advantage of using relation-specific transformations is that each relation can learn the right geometric operators based on the logical properties it has to satisfy.,"we observe that in both low-and high-dimensional settings, attentionbased models can recover the performance of the best transformation on all datasets (Tables 2 and 5).",entailment
1383,dev_1383,"Furthermore, for relations that are neither symmetric nor anti-symmetric, we find that ATTH can outperform rotations and reflections, suggesting that combining multiple operators with attention can learn more expressive operators to model mixed logical patterns.",attentionbased transformations alleviate the need to conduct experiments with multiple geometric transformations by simply allowing the model to choose which one is best for a given relation.,entailment
1384,dev_1384,"Clearly, topics and tokens lie in the same embedding space, making it possible to measure the relationships between document-topics and summary-tokens via attention.","we choose the top-n topics according to θ¸, and consider these n topic embeddings as extra decoder inputs to guide the generation.",entailment
1385,dev_1385,"As a result, with the increase of the document length, the improvement produced by TA gets more evident.","the global semantics introduced by TA is indeed helpful to Transformer-based models on the summarization task, especially for long documents.",entailment
1386,dev_1386,"Negation is a mechanism that transforms a positive argument into its inverse rejection (Benamara et al., 2012).","in the task of affective analysis, negation plays a critical role as negation words can affect the word or sentence polarity causing the polarity to invert in many cases.",entailment
1387,dev_1387,"This work is funded by Natural Sciences and Engineering Research Council of Canada (NSERC) and the Big Data Research, Analytics, and Information Network (BRAIN) Alliance established by the Ontario Research Fund Research Excellence Program (ORF-RE).",we thank Majid Taghdimi from Questrade to provide us with the computing resources and help in the parallelization algorithm.,entailment
1388,dev_1388,"Due to the capability of capturing sequential information in an efficient manner, Long Short Term Memory (LSTM) (Hochreiter and Schmidhuber, 1997) networks are one of the most widely used models in text classification and generation problems.",bidirectional LSTM (Bi-LSTM) have shown impressive performance by capturing sequential information from the both directions in texts.,entailment
1389,dev_1389,"Recently pre-trained language models like OpenAI GPT (Radford et al., 2018), BERT (Devlin et al., 2018), ULM-FiT (Howard and Ruder, 2018) have made a breakthrough in a wide range of NLP tasks.","bERT and its variant models have shown superior performance in the GLUE benchmark for Natural Language Understanding (NLU) (Wang et al., 2019).",entailment
1390,dev_1390,Subtitle sentences are then temporally aligned with the video frames.,"for each frame v t , we pair it with two neighboring sentences based on the subtitle timestamps.",entailment
1391,dev_1391,"To encode the text input, we use BERT (Devlin et al., 2019), a transformer-based language model (Vaswani et al., 2017) that achieves state-ofthe-art performance on various NLP tasks.",we first fine-tune the BERT-base model using the masked language model and next sentence pre-diction objectives on the subtitles and QA pairs from TVQA+ train set.,entailment
1392,dev_1392,"To have better timestamps, we asked a set of Amazon Mechanical Turk (AMT) workers to refine the original timestamps.",we take the questions that have a localized span length of more than 10 seconds (41.33% of the questions) for refinement while leaving the rest unchanged.,entailment
1393,dev_1393,The tools used for corpora annotation offer to calculate some interannotator agreement statistics.,"the WebAnno we are using, makes it possible to calculate Kohen's Kappa, Fleiss' Kappa and Krippendorff's Alpha.",entailment
1394,dev_1394,The shared model allows utilizing sense correlations across words and therefore allows to transfer common disambiguation rules learned from disambiguating annotation-rich words and applies the rules for improving the disambiguation of annotation-lean words that share a sense alternation pattern.,"we build a single neural network model for WSD that derives sense representations and meanwhile enforces congruence between a word instance and its right sense, by using both lexical resources and sense-annotated data.",entailment
1395,dev_1395,Our approach for word sense disambiguation measures the appropriateness of a word sense in a word context through a unified neural network that uses the same set of parameters for all the words and senses.,"as shown in Figure 1, like the previous neural network-based methods (Raganato et al., 2017a; Luo et al., 2018b; Luo et al., 2018a), we use bidirectional LSTMs (bi-LSTMs) (Hochreiter and Schmidhuber, 1997) for encoding a word context, sense definitions and a prototype example sentence for each sense.",entailment
1396,dev_1396,"Since recognizing and evaluating systematic polysemy is beyond the scope of this work, we use VerbNet 2 (Kipper et al., 2006;Loper and Bird, 2002) to approximately identify verbs that have correlated word senses.",we first identify verbs that have five or less training instances for each of its senses.,entailment
1397,dev_1397,"When using more powerful contextualized ELMo and BERT word embeddings (the third and fourth section of Table 3 respectively), we observe similar trends but with larger performance gains overall.","compared to its equivalent word expert model Word-Specific Classifier BiLST M +Gloss , the Single Classifier BiLST M +Gloss achieved clear performance gains of 2.1% and 2.0% in F1score on the combined test set, when using ELMo embeddings and BERT embeddings respectively.",entailment
1398,dev_1398,A number of researchers have recently questioned the necessity of increasingly complex neural network (NN) architectures.,"several recent papers have shown that simpler, properly tuned models are at least competitive across several NLP tasks.",entailment
1399,dev_1399,"Second, because our model is, in essence, the primary building block of previous models, our results show that some previous papers propose needless complexity, and that gains from these previous complex neural architectures are quite modest.","the state of the art is achieved by careful tuning of simple and wellengineered models, not necessarily by adding more complexity to the model, echoing the sentiments of Lipton and Steinhardt (2018).",entailment
1400,dev_1400,"In addition, the TF-IDF measurement allows us to assign a weight to the words that compose the questions and their contexts according to their frequency in a given document and in all the documents of the corpus.","it is a measure that takes into account their importance, the rarity and therefore the discriminative function of words within the corpus.",entailment
1401,dev_1401,"This table shows very similar results overall as we see  for experiments 4, 6 and 8 for which we get a f-score near 0.62.",we can see the exact distribution of the predictions of our algorithm for experiment 8 with a confusion matrix (figure 3).,entailment
1402,dev_1402,"Our framework directly extends previous work on learning web-based tasks from the Mini Word-of-Bits framework using multiple demonstrations and exploration of the environment (Shi et al., 2017; Liu et al., 2018).",our DSL extends the constraint language defined in Liu et al. (2018)  to explore learning from explained demonstrations instead.,entailment
1403,dev_1403,"We choose these local priors to correspond to distributions that are uniform over assignments that are consistent, and has zero support otherwise, similar to previous work on pragmatic reasoning (Frank and Goodman, 2012; Monroe et al., 2017).",these distributions are proportional to indicator function over valid assignments of variables in each factor.,entailment
1404,dev_1404,"In this paper, we attempt to more accurately estimate the knowledge contained in LMs by automatically discovering better prompts to use in this querying process.","we propose mining-based and paraphrasing-based methods to automatically generate high-quality and diverse prompts, as well as ensemble methods to combine answers from different prompts.",entailment
1405,dev_1405,We propose two automatic methods to systematically improve the breadth and quality of the prompts used to query the existence of a relation (§ 3).,"as shown in Figure 1, these are mining-based methods inspired by previous relation extraction methods (Ravichandran and Hovy, 2002), and paraphrasing-based methods that take a seed prompt (either manually created or automatically mined), and paraphrase it into several other semantically similar expressions.",entailment
1406,dev_1406,Our second method for generating prompts is more targeted-it aims to improve lexical diversity while remaining relatively faithful to the original prompt.,we do so by performing paraphrasing over the original prompt into other semantically similar or identical expressions.,entailment
1407,dev_1407,"In this paper, we are interested in building a model of the student (question asker) in this scenario.","we investigate how to enable the student to reason pragmatically about which questions to ask to efficiently acquire knowledge, given only the topic T and the conversation history H. This setting of information-seeking conversations involves many interesting and challenging problems in natural language processing: Ã¢â‚¬Â¢ Quantifying textual information.",entailment
1408,dev_1408,"Once this classifier is trained, we can make use of the score it assigns different candidate questions to evaluate how specific each is to the current conversation history.",we select two kinds of negative questions: frequent questions from the training set (frequency>1) and random questions other than the observed one from the same conversation.,entailment
1409,dev_1409,"You will be ranking these questions on three different evaluation metrics, where ties are allowed for any metric (and encouraged if there isn't a clear signal setting candidate questions apart).",you will be evaluating these questions on their Overall Quality.,entailment
1410,dev_1410,"This paper explores data augmentation methods for training Neural Machine Translation to make use of similar translations, in a comparable way a human translator employs fuzzy matches.","we show how we can simply feed the neural model with information on both source and target sides of the fuzzy matches, we also extend the similarity to include semantically related translations retrieved using distributed sentence representations.",entailment
1411,dev_1411,All types of matching indicate their suitability showing accuracy gains.,"for fuzzy matching, which seems to be the best for our task.",entailment
1412,dev_1412,"With the help of automatically-mined knowledge, SKEP conducts sentiment masking and constructs three sentiment knowledge prediction objectives, so as to embed sentiment information at the word, polarity and aspect level into pre-trained sentiment representation.","the prediction of aspect-sentiment pairs is converted into multi-label classification, aiming to capture the dependency between words in a pair.",entailment
1413,dev_1413,"Three sentiment knowledge prediction objectives are jointly optimized during pre-training so as to embed sentiment words, polarity, aspect-sentiment pairs into the representation.",the pair prediction is converted into multi-label classification to capture the dependency between aspect and sentiment.,entailment
1414,dev_1414,"For every KG, we can use the average out-degree D out avg of each entity (node) to define its sparsity.","if D out avg of a KG is larger than a threshold, we can say it is a dense or normal KG, otherwise, it is a sparse KG.",entailment
1415,dev_1415,"Therefore, the state of the t-th hop can be defined as s t = (r q , e t , h t ), where h t is the representation of the historical path.","we use an LSTM to encode the historical path information, h t is the output of LSTM at the t-th step.",entailment
1416,dev_1416,"Inspired by the above phenomenon, we propose a new strategy named dynamic anticipation, which introduces the prediction information of the embedding-based models into the multi-hop reasoning models to guide the model learning.","Specifically, for a triple query (es, rq, ?), we use the pretrained KGE models to get the probability vector of all entities being the tail entity.",entailment
1417,dev_1417,"Moreover, we can learn that using either strategy individually will enable our model to achieve better results than the baseline model.","the model using the DC strategy alone performs better than the model using the DA strategy alone, which is predictable, since the DA strategy only allows the agent to make a correct choice, and will not substantially alleviate the sparsity of KGs.",entailment
1418,dev_1418,"It then defines a score function f (e s , r q , e t ) with embeddings to measure the correct probability of each triple.","Specifically, most KGE models can be divided into three categories (Wang et al., 2017): (1) Translation-based models (Bordes et al., 2013; Wang et al., 2014; Lin et al., 2015; Sun et al., 2018) formalize the relation as a translation from a head entity to a tail entity, and often use distance-based score functions derived from these translation operations.",entailment
1419,dev_1419,"Our goal here is not to find the best possible way to do the post-ranking, but only to show that gains are possible.",running the preranker over a larger candidate list is not enough; we find that it is better to see what edits are made for multiple candidates before making the final decision.,entailment
1420,dev_1420,"Following literature in open-domain QA, we evaluate our approach on three datasets, WebQuestions (Berant et al., 2013), Natural Questions (Kwiatkowski et al., 2019) and TriviaQA (Joshi et al., 2017).","webQuestions (wQ) and Natural Questions (NQ) consist of short, noisy questions from web queries, in line with the motivation of our work.",entailment
1421,dev_1421,"Although our method is generic, it is particularly well suited to this task.","we show that FLOP can dynamically learn the embedding dimensions of different word clusters, effectively extending the idea of adaptive embeddings and softmax (Grave et al., 2017;Baevski and Auli, 2019).",entailment
1422,dev_1422,The choice of binary variables z can be regulated by some prior distribution and optimized given the training data.,let q j (z) be the density function of the learnable prior of z j .,entailment
1423,dev_1423,We evaluate the performance of our method on language modeling and BERT fine-tuning.,we consider the following task setup.,entailment
1424,dev_1424,We use a hidden size of 3056 and set the initial factorization dimension r of the parameter matrices to 512.,we replace each weight matrix W in SRU using an explicit factorization PQ with an inner dimension of 512.,entailment
1425,dev_1425,"Since a precise list of such token types is hard to define, we thus estimate the grounding ratio based on existing grounded language corpora.",we consider a token type with more than 100 occurrences in MS COCO (after removing all stop words) as visually-grounded.,entailment
1426,dev_1426,"In Table 1, we compare two ablated instances of ConceptBert with its complete form.",we validate the importance of incorporating the external knowledge into VQA pipelines on top of the vision and language embeddings.,entailment
1427,dev_1427,We illustrate some qualitative results of Concept-Bert complete form CVL by comparing it with the VL model.,"we aim at illustrating the advantage of adding (i) the external knowledge extracted from the ConceptNet knowledge graph, and (ii) concept-vision-language embedding representations.",entailment
1428,dev_1428,"These models fine-tune BERT (Devlin et al., 2019) for DocRED.",two-Phase BERt  is the best reported model.,entailment
1429,dev_1429,This contextual model generates a representation of each word based on the other words in the sentence.,the word vector BERT outputs for a word is dependent on the surrounding context in which it occurs.,entailment
1430,dev_1430,"Among these four models, DNN_2++ and BERT received the best or the second best F1 scores on all POS tags.",dNN_2++ achieved the highest F1 scores on 27 POS tags.,entailment
1431,dev_1431,"The vast majority of previous work (Wan et al., 2007;Wan, 2008;Wan and Xiao, 2009;Wan and Zhang, 2014) creates summaries by ranking textual segments (usually sentences) according to their relationship (e.g., similarity) to other segments and their relevance to the query.","relevance and evidence estimation are subservient to estimating the centrality of a segment (e.g., with a graph-based model).",entailment
1432,dev_1432,"For each document cluster, LEXRANK builds a graph G = (V, E) with nodes V corresponding to sentences and (undirected) edges E whose weights are computed based on similarity.","matrix E represents edge weights where each element E i,j corresponds to the transition probability from vertex i to vertex j.",entailment
1433,dev_1433,"In order to fairly compare against these systems, for every bridging anaphor a, we first map all top 20 span predictions of our system BARQA to the gold/system mentions, then we choose the gold/system mention with the highest confidence score as the predicted antecedent.",we map a predicted span s to a mention m if they share the same head and s is part of m (m is created by removing all postmodifiers from m).,entailment
1434,dev_1434,"In this work, we focus on the task of event detection (ED) to identify event trigger words for the cybersecurity domain.","to facilitate the future research, we introduce a new dataset for this problem, characterizing the manual annotation for 30 important cybersecurity event types and a large dataset size to develop deep learning models.",entailment
1435,dev_1435,"In this work, we examine Information Extraction technologies (IE) in Natural Language Processing (NLP) as a promising candidate for the knowledge extraction task from cybersecurity text.","we focus on Event Detection (ED), an important task in IE that seeks to identify trigger words of specified types of events in text (Ahn, 2006;Ji and Grishman, 2008).",entailment
1436,dev_1436,"In addition, we find that sentences mentioning some events in CySecED often contain at least two event trigger words for the event types.","cybersecurity events in CySecED tend to cooccur with each other in the sentences, suggesting potential inter-dependencies between events.",entailment
1437,dev_1437,"These dependencies can be exploited to further improve the ED performance for cybersecurity domain in the future research (Li et al., 2013;Nguyen et al., 2016a;Nguyen and Nguyen, 2019).","among the sentences in CySecED, 45.4% of the sentences do not contain any event triggers, 50.0% of the sentences host at least two event triggers, and only 4.6% of the sentences involve a single event trigger.",entailment
1438,dev_1438,"As shown in Fig. 1, there exist shared and private information between target extraction and target classification.","the semantic and syntactic information are essential for both tasks, so they are shared information.",entailment
1439,dev_1439,"In this paper, we propose a novel model of Shared-Private Representation Model (SPRM) shown in Fig. 2, which encodes the shared and private information of the target extraction sub-task and the target classification sub-task effectively at a lower cost.","a Shared BERT Network is designed to encode as much shared information of both sub-tasks as possible, and two Private BiLSTMs are introduced to get the supplementary private representations for each task with fewer parameters than BERT.",entailment
1440,dev_1440,"Although we have corrected spelling errors that affect more than one token, these entries have been removed from the training data set.",the model has been trained exclusively on unigrams.,entailment
1441,dev_1441,The goal of our table semantic segmentation model is to classify cells into categories.,"instead of performing structural segmentation where one tries to distinguish between captions, headers and rows in a stream of text (Pinto et al., 2003) we focus on semantic segmentation (i.e., assigning roles to each cell) of tables.",entailment
1442,dev_1442,To tackle this problem effectively we define subtasks that take us from paper to results.,"we introduce the AXCELL pipeline that consists of the following subtasks: (i) table type classification, identifying whether a table in a paper has relevant results; (ii) table segmentation, segmenting and classifying table cells according to whether they hold metrics, datasets, models, etc.",entailment
1443,dev_1443,We take inspiration from unsupervised grammar induction (UGI) techniques originally proposed for natural language.,"we use them to investigate if the languages that emerge in the typical setup of referential games exhibit interesting syntactic structure, and to what extent this depends on the maximum message length and number of symbols that the agents are allowed to use.",entailment
1444,dev_1444,Previous work that focused on the analysis of emergent languages has primarily concentrated on semantics-based analysis.,"they considered whether agents transmit information about categories or objects, or instead communicate using low-level feature information (Steels, 2010;Lazaridou et al., 2017;Bouchacourt and Baroni, 2018; Mihai and Hare, 2019, i.a.).",entailment
1445,dev_1445,We first qualitatively assess the extent to which CCL-BMM and DIORA-BMM are able to infer the correct grammars for the structured baseline languages described in the previous section.,"we consider if the induced grammars reflect the correct word classes defined by the preterminals, and if they capture the simple hierarchy defined on top of these word-classes.",entailment
1446,dev_1446,"A natural question, then, is: in the absence of argumentannotated training data, is argument mining doomed to fail?",are argument-annotated training data as indispensable as they seem in enabling state-of-the-art argument mining systems to achieve their current level of performance?,entailment
1447,dev_1447,"First, our competitive results call for a reexamination of existing supervised approaches to argument mining.",future work should seek to understand what caused their performances to be rivaled by an unsupervised system.,entailment
1448,dev_1448,"Similarly, they applied their learned RI classifier to classify only the relation between two gold argument components.",they simplified both tasks by avoiding the challenging task of identifying the locations of argument components.,entailment
1449,dev_1449,"Further, we run additional experiments for MT systems that are known to have low correlation with automatic metrics calculated with standard references.",we investigated MT systems augmented with either back-translation or automatic post-editing (APE).,entailment
1450,dev_1450,"Interestingly, previous work (Bojar et al., 2016a) has shown that a higher correlation can be achieved when comparing similar systems than when comparing different types of systems, e.g. phrase-based vs neural vs rulebased.","rule-based systems can be penalized as they produce less common translations, even when such translations are fluent and adequate.",entailment
1451,dev_1451,We suspect that this may at least in part be an artifact of the rating methodology.,translations whose word order matches that of the source (i.e. translationese) are easier to rate than translations that use very different sentence structures and phrasing than the source sentence.,entailment
1452,dev_1452,"Comparing the two paraphrased references, we see that HQ(P) shows higher correlation for chrF and Yisi when compared to WMT.p.",yisi (which is based on word embeddings) seems to benefit from the higher accuracy of the reference translation.,entailment
1453,dev_1453,We run experiments with a variety of models that have been shown that their actual quality scores have low correlation with automatic metrics.,"we focus on backtranslation (Sennrich et al., 2016) and Automatic Post Editing (APE, Freitag et al. (2019)) augmented systems trained on WMT 2014 English→German.",entailment
1454,dev_1454,Table 4 shows that our unsupervised model is competitive with recent models using full set of Switchboard training data.,"our unsupervised model even achieves slightly improvement over the supervised methods without using contextualized word embeddings, demonstrating the effectiveness of our unsupervised model.",entailment
1455,dev_1455,"Despite intensive research efforts to remove noise automatically (Han and Sun, 2016;Hoffmann et al., 2011;Jiang et al., 2016;Surdeanu et al., 2012;Zhou et al., 2016), this problem has yet to be solved.","some groups (Angeli et al., 2014;Liu et al., 2016;Pershina et al., 2014;Zhang et al., 2012) have attempted to boost the performance of relation classifiers through crowdsourcingbased training data collection for relation extraction and using them along with training data for DS learning.",entailment
1456,dev_1456,We first present a machine learning system that processes negation in Spanish.,we focus on two tasks: i) negation cue detection and ii) scope identification.,entailment
1457,dev_1457,The test set has a total of 836 negation cues.,"there are 83 different negation cues, of which 15 are simple cues, 19 are continuous cues and 49 are discontinuous cues.",entailment
1458,dev_1458,"We use the CRF implementation in CRFsuite (Okazaki, 2007) and scikit-learn (Pedregosa et al., 2011) with the L-BFGS training algorithm (default) and Elastic Net (L1 + L2) regularization.","we train two classifiers: the first one takes as input a sentence and predicts the negation cue BIO labels, and the second one takes as input a sentence along with information about the predicted cues and predicts the scope BIO labels.",entailment
1459,dev_1459,"In recent years, significant progress was made in the field of argument mining, automatic identification and extraction of argumentative structures in text (Lawrence and Reed, 2020).","several works focused on topic-related argument mining from the Web or other massive corpora(Levy et al., 2017, 2018; Wachsmuth et al., 2017; Stab et al., 2018a,b; Ein-Dor et al., 2020).",entailment
1460,dev_1460,This example highlights the most problematic linguistic challenge that we encountered in the development of the ACQDIV database and corpus aggregation pipeline.,the same morphological phenomena may be encoded differently per corpus.,entailment
1461,dev_1461,"During the cleaning procedure, we also undertake a routine for speaker unification.","we identify the same speakers across different recording sessions, so that we can populate a UNIQUESPEAKERS table in our database.",entailment
1462,dev_1462,"In recent years, Deep Learning methods have become very popular in Natural Language Processing (NLP), e.g., they reach high performances by relying on very simple input representations (for example, in (Kim, 2014;Goldberg, 2016;Kim et al., 2016)).","transformer-based architectures, e.g., BERt (Devlin et al., 2019), provide representations of their inputs as a result of a pre-training stage.",entailment
1463,dev_1463,"In this paper, we extend the BERT training with unlabeled data in a generative adversarial setting.","we enrich the BERT fine-tuning process with an SS-GAN perspective, in the so-called GAN-BERT 1 model.",entailment
1464,dev_1464,"In particular, we enrich the BERT fine-tuning process with an SS-GAN perspective, in the so-called GAN-BERT 1 model.","a generator produces ""fake"" examples resembling the data distribution, while BERT is used as a discriminator.",entailment
1465,dev_1465,"As suggested in (Salimans et al., 2016), G should generate data approximating the statistics of real data as much as possible.",the average example generated in a batch by G should be similar to the real prototypical one.,entailment
1466,dev_1466,"Both automatic evaluation and human evaluation show that MART generates more satisfying results than previous LSTM-based approaches (Xiong et al., 2018;Zhou et al., 2019;Zhang et al., 2018) and transformer-based approaches (Zhou et al., 2018;.","mART can generate more coherent (e.g., coreference and order), less redundant paragraphs without losing paragraph accuracy (visual relevance).",entailment
1467,dev_1467,"To resolve this issue, Transformer-XL  introduces the idea of recurrence to the transformer language model.",the modeling of a new language segment in Transformer-XL is conditioned on hidden states from previous language segments.,entailment
1468,dev_1468,"Compared to the two baselines, MART produces more coherent and less redundant paragraphs.","we noticed that vanilla transformer often uses incoherent pronouns/person mentions, while MART and Transformer-XL is able to use suitable pronouns/person mentions across the sentences and thus improve the coherence of the paragraph.",entailment
1469,dev_1469,Experimental results on two standard datasets show that MART has better overall performance than the baseline methods.,"mART can generate more coherent, less redundant paragraphs without any degradation in relevance.",entailment
1470,dev_1470,Various metrics have been proposed to quantify biases in model predictions.,several of them evaluate disparity in model performance between protected groups and advantaged groups in the test corpus.,entailment
1471,dev_1471,"However, both K-Means and LOGAN successfully detect strong local group bias.",lOGAN identifies a local region that the model has difficulties in making correct predictions for female group.,entailment
1472,dev_1472,"DecOp is composed of both truthful and deceptive first-person opinions about five different domains, is compiled in two different languages and has been developed for allowing several kinds of classification experiments.","beyond the more usual withindomain classification task, DecOp allows cross-domain, author-based and cross-language classification tasks.",entailment
1473,dev_1473,"Furthermore, unlike prior work employing either classification (Gong and Zhang, 2016) or generation models (Wang et al., 2019a), we propose a unified framework to couple the advantages of keyphrase classification and generation.","in addition to the joint training of both modules, we further extend the copy mechanism (See et al., 2017) to explicitly aggregate classification outputs together with tokens from the source input.",entailment
1474,dev_1474,These methods undergo labor-intensive feature engineering and hence lead to the growing popularity of adopting data-driven neural networks.,"for social media keyphrase prediction, most efforts are based on sequence tagging style extraction (Zhang et al., 2016, 2018) or classification from a predefined candidate list (Gong and Zhang, 2016; Zhang et al., 2017), which are however unable to produce keyphrases absent in the post or the fixed list",entailment
1475,dev_1475,"Following Cai et al. (2019), we first train an attribute predictor based on the Resnet-152 (He et al., 2016) features on MS-COCO 2014 caption dataset (Lin et al., 2014).",we extract noun and adjective tokens from the image captions as the attribute labels.,entailment
1476,dev_1476,"Since there are no publicly available datasets for multi-modal keyphrase annotation, we contribute a new dataset with social media posts from Twitter.",we employ the Twitter advanced search API 4 to query English tweets that contain both images and hashtags from January to June 2019.,entailment
1477,dev_1477,"We promote output diversity by training f para on an aggressivelyfiltered subset of PARANMT-50M (Wieting and Gimpel, 2018), a large corpus of backtranslated text.","we apply three filters: (1) removing sentence pairs with more than 50% trigram or unigram overlap to maximize lexical diversity and discourage copying; (2) removing pairs with lower than 50% reordering of shared words, measured by Kendall's tau (Kendall, 1938), to promote syntactic diversity; and (3) removing pairs with low semantic similarity, measured by the SIM model from Wieting et al. (2019)",entailment
1478,dev_1478,"We focus exclusively on semantics-preserving style transfer tasks, which means that we do not evaluate on attribute transfer datasets such as sentiment, gender, and political transfer.",we use two standard benchmark datasets for Shakespeare author imitation and formality transfer to compare STRAP against prior work.,entailment
1479,dev_1479,"The models are finetuned using a small learning rate of 5e-5 and converge to a good solution fairly quickly as noticed by recent work (Li et al., 2020;Kaplan et al., 2020).","each experiment completed within a day of training on a single GPU, and many experiments with small datasets took a lot less time.",entailment
1480,dev_1480,Evaluating with adjusted perplexity showed that a background model interpolated with a user-only model performs well when larger amounts of user-specific text are available.,neural background interpolated with either user-only model outperforms all other models when using 10k tokens or more of the user's text.,entailment
1481,dev_1481,"Encouraged by the results on pre-training for dialogue generation and knowledge-grounded dialogue generation, and motivated by the problems in both sides, we consider bringing the two together in this work.",we propose knowledgegrounded dialogue generation with pre-trained language models in order to endow a generative model with both rich knowledge and good generalization ability 1 .,entailment
1482,dev_1482,"Therefore, we propose an unsupervised approach where learning of knowledge selection and fine-tuning of response generation are jointly conducted with unlabeled dialogues.","we build the knowledge selection module on the basis of BERT, and formalize knowledge selection as a sequence prediction process, by which the model can take advantage of the pre-training techniques and dynamically determine the relevant knowledge for a given context.",entailment
1483,dev_1483,We conduct experiments with BERT on 5 GLUE benchmark tasks to demonstrate that SNIP achieves effective pruning results while maintaining comparable performance.,we improve the performance over the state-of-the-art by 0.5 to 1.0% on average at 50% compression ratio.,entailment
1484,dev_1484,The design of residual connection can provide us with a promising way to find identity mappings for the Transformer model.,"residual connection (He et al., 2016b) can be formalized as H(x) = F(x) + x, where F could be either MHA or FFN and H is the sub-layer output.",entailment
1485,dev_1485,"While sociolinguistics and social psychology have long pointed to how people shape their language to convey social information (Labov, 1972; Brown and Levinson, 1978; Clark and Schunk, 1980; Weber, 2008; Locher and Graham, 2010), only recently, have computational models focused on making this information explicit (Choi et al., 2012; Danescu-Niculescu-Mizil et al., 2013; Bak et al., 2014).","works on social status and power have shown how individuals use lexical cues and linguistic strategies like accommodation to express their perceived status in relation to others (Danescu-Niculescu-Mizil et al., 2013;Prabhakaran et al., 2014).",entailment
1486,dev_1486,"Here, we connect interpersonal pragmatics to the language of intimacy, showing how individuals perform pragmatic acts in their questions to mitigates risk as intimacy increases, much like how politeness is employed to save face (Brown et al., 1987).","we examine pragmatic choices in questions around (i) the speaker's certainty, expressed in hedges from Hyland (2005) (ii) the speaker's belief of the social distance, expressed in swearing.",entailment
1487,dev_1487,The behavior of different part-of-speech classes can also explain some of the differences observed across languages.,"as can be seen in Table 1, most of the languages that show a clear preference for UD -Chinese, Hebrew, Hindi, Italian and Japanese -are all characterized by a high proportion of adpositions.",entailment
1488,dev_1488,"To reduce the expenses for evaluating multidocument summaries, we investigate unsupervised evaluation methods, which require neither human annotations nor reference summaries.","we focus on evaluating the relevance (Peyrard, 2019) of multi-document summaries, i.e. measuring how much salient information from the source documents is covered by the summaries. ",entailment
1489,dev_1489,Our work thus leverages this computational efficiency of TMs for efficient and scalable fine-tuning for BERT in document classification.,"our contributions(1) Complementary Fine-tuning: We present a novel framework: TopicBERT, i.e., topic-aware BERT that leverages the advantages of both neural network-based TM and Transformer-based BERT to achieve an improved document-level understanding.",entailment
1490,dev_1490,"We run a second annotation round where two annotators with linguistic background re-validate the instances that were flagged as special cases by translators during the first round (more concretely, the possible translation shifts).","annotators in this phase decide, for each special case, if the annotated label should be deleted or corrected.",entailment
1491,dev_1491,"Instead, we take a novel approach and rely on the shared space of mBERT embeddings (Devlin et al., 2019).",we compute pair-wise cosine similarity between source and target tokens and emulate word-alignments according to this measure 16 .,entailment
1492,dev_1492,This is the bias of unidirectional decoders and we replace them with simpler word selectors.,we only ask the model to select original neighbors for each word that loses its local word order information.,entailment
1493,dev_1493,"If we adopt pre-trained encoders, as in the second and third group, the performance clearly improves for all training sizes.","in the low-resource (1k) settings, the performance drops from the 10k settings are much smaller than those in the first group.",entailment
1494,dev_1494,"Analyzing the surrogates, we observed that most of the OOV tokens were punctuation or uncommon ideographs, which we expected to, and confirmed to have little effect in the downstream task performance.","we attribute the negligible gains to the nature of the task itself, as it is a news article classification task.",entailment
1495,dev_1495,"To this end, we propose a novel Diversified Multiple Instance Learning Network (D-MILN), which is able to achieve aspect-level sentiment classification with only document-level weak supervision.","we connect aspect-level and document-level sentiment by formulating this problem as multiple instance learning, providing a way to learn aspect-level classifier from the back propagation of document-level supervision.",entailment
1496,dev_1496,"In our experiments, we consider all utterances from the last plot update to the current one from both interlocutors.","starting from the last plot update, the Describer's instruction and all the clarification questions and responses are concatenated and provided as the dialog history.",entailment
1497,dev_1497,"Our model leverages a multitasking framework to train both a summarization model on headline-article pairs, and a Denoising Autoencoder (DAE) on a style corpus.","based on the transformer architecture (Vaswani et al., 2017), we use the style-dependent layer normalization and the style-guided encoder-attention to disentangle the language style factors from the text.",entailment
1498,dev_1498,We randomly sampled 50 news abstracts from the test set and asked three native-speaker annotators for evaluation to score the generated headlines.,"we conduct two tasks to evaluate on four criteria: (1) relevance, (2) attractiveness, (3) language fluency, and (4) style strength.",entailment
1499,dev_1499,"We progressively expand TitleStylist to include all three target styles (humor, romance, and clickbait) to demonstrate the flexibility of our model.",we simultaneously trained the summarization task on the headlines data and the DAE task on the three target style corpora.,entailment
1500,dev_1500,"Nonetheless, words and mathematical terms are interdependent in the context of mathematical discourse.","the proposed model presents a significantly slower decline (25%), showing better scalability properties in the context of the premise selection problem.",neutral
1501,dev_1501,"The contribution of this work is an interactive visualisation tool, called Starmap 1 to help TTS developers navigate through thousands of audio files of utterances originating from a target domain, and select evaluation materials that are varied, and at the same time representative of the most important communicative acts, pragmatic and expressive functions the speaker needs to perform in that domain.",a significant majority of listeners preferred the TCC voice for the solo-host podcast domain over the TGD voice (p 0.001).,neutral
1502,dev_1502,"In this section, we present the extended version of our sensitivity study (§4.3).",we keep the estimated natural error distribution for evaluation and use a simplified synthetic error model for training.,neutral
1503,dev_1503,"First, news articles on news websites update very quickly.","we would like to thank Xi Chen, Virl Hill, Jesse Pannoni, Sally Salas and Ting Cai in the Microsoft News team for their great support in releasing this dataset and for their great help in preparing the data.",neutral
1504,dev_1504,Another interesting finding is that the combination of LSTM and attention can achieve the best performance.,we hope MIND can serve as a benchmark dataset for news recommendation and facilitate the research in this area.,neutral
1505,dev_1505,"Based on these datasets, many well-known recommendation methods have been developed.","we compare 6 methods, including simple average of the representations of previously clicked news (Average), attention mechanism used in (wu et al., 2019a) (Attention), candidate-aware attention used in (wang et al., 2018) (Candidate-Att), gated recurrent unit used in (Okura et al., 2017) (GRU), long-and short-term user representation used in ) (LSTUR) and multi-head self-attention used in (wu et al., 2019c) (Self-Att).",neutral
1506,dev_1506,"The entity linker used in the originally proposed framework (Hulpus, et al., 2019) is not freely available",both endpoints expect a HTTP POST message with a json payload and the header 'Content-Type: application/json'.,neutral
1507,dev_1507,"To actively engage readers in the text they are reading and maintain their interest in the topic, texts needs to be on an adequate level for the reader in terms of its lexical, syntactic, as well as its conceptual complexity (McNamara et al., 2006).","in the current implementation, we use DBpedia Spotlight (Daiber et al., 2013) which is freely available for several languages (DBpediaSpotlight, 2019).",neutral
1508,dev_1508,This architecture decreases the implementation costs significantly.,"as a further extension, we are constructing a ranking system where players can compare their score against others, to arouse players' competitive motivation.",neutral
1509,dev_1509,An overview of our platform is shown in Figure 2.,"the dialogue act selection is obligatory, i.e. the speaker can not make their utterance without the dialogue act selection",neutral
1510,dev_1510,"The neural models see a 10% gain in accuracy over the template-sensitive majority, indicating that the models are learning the range of durations for different entities.",we compare this model to a model that additionally includes a fixed effect for the entailment label associated with the pair by our recasting.,neutral
1511,dev_1511,We test existing models trained on MNLI on our datasets and find that a generic NLI model is not able to capture temporal reasoning.,"we use three types of models: (i) neural bag of words (NBOW; Iyyer et al., 2015) (ii) InferSent (Conneau et al., 2017), and (iii) RoBERTa (Liu et al., 2019).",neutral
1512,dev_1512,"When we focused on each combination of the embedding and distribution models, we found that the highest and second highest scores were achieved by OffSet with GloVe and GMM with SGNS, respectively.","in this study, we seek to understand how these vectors are distributed in the pre-trained word vector space without using contextual or lexical information.",neutral
1513,dev_1513,"The composed lexicon contains sentiment values in the range  [−1, 1].","to create a balanced dataset that covers a large variety of topics, we randomly selected 5 pro and 5 con arguments of each debate.",neutral
1514,dev_1514,"By comparison, the majority vote matches 79.30% of the original stance labels.",most of the targets are found by word similarity and the fewest by the acronym.,neutral
1515,dev_1515,The third set is the entire αNLI development set introduced in Bhagavatula et al. (2020).,this indicates that naturally occurring examples in ChaosNLI-α are either highly certain or uncertain among human judgements.,neutral
1516,dev_1516,"To be specific, the estimated collective human performance gives JSD and KL scores far below 0.1 on all three sets.","figure 6 and 7 show the screenshots for NLI and αNLI collection, respectively.",neutral
1517,dev_1517,column summarizes the difference in performance for each of the classes.,"in this paper we describe the semiautomatic process of building a sentiment lexicon in the financial/economic domain, which assumes the existence of a general-language sentiment lexicon.",neutral
1518,dev_1518,"Johnson had also met AstraZeneca and GSK, whose headquarters are in Britain, while O’Brien had been to the Paris headquarters of the French firm, SanofiAventis.","such resources can be automatically created (Lu et al., 2011; Tai and Kao, 2013) or crafted manually.",neutral
1519,dev_1519,The ideal method for displaying information to the Deaf community would be through their sign language.,hamNoSys is an alphabetic system describing signs mostly on a phonetic level.,neutral
1520,dev_1520,SiGML is an XML-compliant machine-readable format that enables avatars to animate HamNoSys symbols.,"hence, it is not of easy access to the Deaf community.",neutral
1521,dev_1521,Each crate contains 4 boxes.,"the proposed architecture, drawing on contemporary cognitive science, aims to address key limitations of current NLU systems through mental simulation and grounded metaphoric inference.",neutral
1522,dev_1522,The current deep-learning paradigm is a statistical pattern-recognition approach predominantly applied to relatively narrow task-specific prediction.,this ambiguity is challenging for non-neural (symbolic) simulationbased approaches.,neutral
1523,dev_1523,"Speaker A: hi , how are you doing today ?",the findings are similar to the pairwise ACUtE-Eval results in the main paper.,neutral
1524,dev_1524,"To show such grounding helps, we report results with and without grounding on those tasks in Table 4, reporting perplexity.",what we feel entitled to is a better world .,neutral
1525,dev_1525,Specific tasks for which the corpora could be used to evaluate the impact of processing negation.,"it introduced a new element for the annotation of negation, the focus.",neutral
1526,dev_1526,"Overall negation processing tasks for which the corpora could be used, by language.",the predicate NOt was used to annotate any explicit statements of the non-existence of a relationship.,neutral
1527,dev_1527,"Thus, the average number of sentences with negation in English texts is 17.94% and in Japanese 16.59%, whereas for Spanish it is 29.13%, for Italian 21.55%, and for Chinese 26.82%.","an annotation guideline explaining the process and each of the contextual properties was provided, but it is not available.",neutral
1528,dev_1528,"The ConanDoyle-neg (Morante and Daelemans 2012) is a corpus of Conan Doyle stories annotated with negation cues and their scopes, as well as the event or property that is negated.","it is noteworthy that in some of the corpora (BioInfer, Genia Event, Product Review, EMC Dutch, IxaMed-GS, and German negation and speculation corpus) negation cues have not been annotated, despite the fact that the cue is the element that denotes the presence of negation in a sentence and the one to which the rest of the elements (scope, event, and focus) are connected.",neutral
1529,dev_1529,"Several shared tasks have addressed negation processing for English: the BioNLP’09
Shared Task 3 (Kim et al. 2009), the i2b2 NLP Challenge (Uzuner et al. 2011), the *SEM
2012 Shared Task (Morante and Blanco 2012), and the ShARe/CLEF eHealth Evaluation
Lab 2014 Task 2 (Mowery et al. 2014).",the tweet corpus has 301 sentences and 59 were annotated as negated (19.60%).,neutral
1530,dev_1530,Words derived (by affixation and reduplication) are listed as sub-entries under the basewords.,"the main goal of our project was to produce a high quality, human-curated resource.",neutral
1531,dev_1531,The passive voice forms are not regarded as variants in the Old Javanese Wordnet.,an example of this spreadsheet is shown in Table 4.,neutral
1532,dev_1532,"Practically, sentiments are represented into a 2D vector, whose dimensions and values correspond to polarities (positive or negative) and corresponding intensities respectively.","under the condition of processing extremely unstable inputs (big drifts), many of the values will be very close to 1, which decreases system performance.",neutral
1533,dev_1533,EAE's average accuracy is similar to BERTlarge.,table 1 shows the results for all our models.,neutral
1534,dev_1534,"Second, we introduce two simple yet effective scheduling strategies, namely the dynamic temperature-based sampling and dynamic noising ratio strategy.","furthermore, we show the effectiveness of MTL over pre-training approaches for both NMT and cross-lingual transfer learning NLU tasks; the proposed approach outperforms massive scale models trained on single task.",neutral
1535,dev_1535,"Back translation (BT) (Sennrich et al., 2016), which leverages a target-to-source model to translate the target-side monolingual data into source language and generate pseudo bitext, has been one of the most effective approaches in NMT.","back translation (Sennrich et al., 2016) utilizes the target-side monolingual data.",neutral
1536,dev_1536,The neighboring text tokens are embedded using a word embedding table.,"to most prior work on information extraction (Sarawagi, 2008), templatic documents do not contain much prose.",neutral
1537,dev_1537,Table 1 lists the fitting results for all the languages 8 in the Europarl corpus.,the third parameter provides a depiction of the rigidness of different coefficients of proportionality.,neutral
1538,dev_1538,These datasets are previously used as benchmarks for multi-document summarization competitions.,"importantly, and distinguishing our work from earlier literature, we make a first attempt to generate self-contained highlights, drawing on the successes of deep contextualized representations and their extraordinary ability of encoding syntactic structure (Clark et al., 2019;Hewitt and Manning, 2019).",neutral
1539,dev_1539,"When the class is span, the start and end positions of slot values are obtained in the dialogue context.",this hidden vector is then mapped to distribution over the vocabulary V and over the dialogue history as shown in Eq (1).,neutral
1540,dev_1540,"The instructional text is regularly divided into multiple steps, which should be performed in a specified sequence.","instead, we seek representations that are capable of capturing the long-term dependencies across passages of text to derive higher-level information from the entire semantic block of each step, i.e., knowing that the expansion bays are detached without requiring any tool.",neutral
1541,dev_1541,"As mentioned in Section 3, the expected supervision for our model is the word-level edit matrix, but existing datasets only contain rewritten utterances.","instead of generating from scratch, such a formulation introduces edit operations and shapes the problem as prediction of a word-level edit matrix.",neutral
1542,dev_1542,"""Ques"" is short for questions, ""Avg"" for average, ""len"" for length, ""Con"" for context utterance, ""Cur"" for current utterance, and ""Rew"" for rewritten utterance.","the predicted Y is not guaranteed to meet this requirement, indicating the need for a standardization step.",neutral
1543,dev_1543,The newly proposed flexible knowledge inference focuses on n-ary facts of arities greater than 2.,"we then optimize NeuInfer via backpropagation, and Adam (Kingma and Ba, 2015) with learning rate λ is used as the optimizer.",neutral
1544,dev_1544,"By differentiating the primary triple from other auxiliary description(s), NeuInfer considers the validity of the primary triple and the compatibility between the primary triple and its auxiliary description(s) to model each n-ary fact more appropriately and reasonably.","They can be divided into tensor/matrix based methods, translation based methods, and neural network based ones.",neutral
1545,dev_1545,"Both these wordnets are very large, by virtue of the automatic processes used to gather their contents, but on the flip side they lack the thorough validation only granted by a manual process.",only 4.1% of all word senses included this specific kind of gloss.,neutral
1546,dev_1546,"We follow the setting in LCML (Lin and Xu, 2019) for unknown intent detection.","as shown in Figure 2, a typical generalized zeroshot classification framework can be abstracted into two layers, the encoder layer and the zero-shot classifier layer.",neutral
1547,dev_1547,"Events realized by nouns can correspond to nominalizations, event nouns, contextual event readings or implicit events.","Attribution is a linguistic phenomenon that consists in “ascribing the ownership of an attitude towards some linguistic material, i.e. the text itself, a portion of it or its semantic content, to an entity” (Prasad et al., 2006; Pareti, 2015).",neutral
1548,dev_1548,"As for adjectives in attributive position, they can be marked as events only when their occurrence implies actual occurrences, such as the events leading up to its own existence.",the focus of this task was to identify all claim-like statements.,neutral
1549,dev_1549,"As shown in Kim et al. (2020), such a sequential way can better simulate a multi-turn dialog and facilitate knowledge selection in later turns.","we thus devise the disentangled variant as following, where the roles of two types of information are separated, which makes it feasible to conduct ablation study.",neutral
1550,dev_1550,The knowledge selection of PostKS is supervised by a BOW loss.,these works have a different task setting from ours.,neutral
1551,dev_1551,This makes our query vector combine the domain-shared feature with domain-specific feature.,"as shown in the Figure 7, for a specific target domain, different examples may have different gate distributions, which indicates that our framework successfully learns how to transfer knowledge between different domains.",neutral
1552,dev_1552,"In addition, we take inspiration from Guo et al. (2018), who successfully apply the mix-of-the-experts (MoE) mechanism in multi-sources domain and cross-lingual6352 adaption tasks.","a simple baseline to incorporate domain-shared and domain-private features is shared-private framework (Liu et al., 2017; Zhong et al., 2018; Wu et al., 2019b).",neutral
1553,dev_1553,"Our next question is whether this difference is due to the differing syntactic complexity among our MWEs, and between our MWEs and those in previous work (which generally are shorter and simpler).",to most previous compositionality datasets we also consider syntactically complex constructions and publish a formal specification of each expression.,neutral
1554,dev_1554,"As the task scope was extended from specific-to open-domain QA, several models have been proposed to select a relevant paragraph from the text to predict the answer span (Wang et al., 2018;Clark and Gardner, 2018).",detecting supporting sentences is an essential step being able to answer the question.,neutral
1555,dev_1555,"These methods successfully demonstrated their potential and effectiveness in understanding relational datasets, such as entity linking in heterogeneous knowledge graphs, product recommendation systems, and detecting side effects in drug (Wu et al., 2019;Fan et al., 2019;Zitnik et al., 2018).",all the model variations undergo performance degradation compared to the original topology (PS-rnn-elmo-s).,neutral
1556,dev_1556,"Unlike measuring embedding bias, measuring classification bias is difficult: most NLP datasets are not annotated with protected attributes, precluding the use of standard fairness measures such as equal opportunity (Hardt et al., 2016).","Equalized odds requires that both true and false positive rates be equal across groups (Hardt et al., 2016).",neutral
1557,dev_1557,"Unlike measuring embedding bias, measuring classification bias is difficult: most NLP datasets are not annotated with protected attributes, precluding the use of standard fairness measures such as equal opportunity (Hardt et al., 2016).","as shown in section 3.3, datasets currently used to estimate classification bias in NLP – such as WinoBias (Zhao et al., 2018b) and WinoGender (Rudinger et al., 2018) – are too small to conclusively identify bias except in the most egregious cases.",neutral
1558,dev_1558,"As the source documents are very long and messy, they are split into multiple paragraphs by line-breaks.","to their approach, we incorporate explicit graph representations into the encoding process via a graphinformed attention mechanism.",neutral
1559,dev_1559,"An example is shown in Figure 1, where the narrative is uploaded to retell several lines of a script in a movie.","(1) To our best knowledge, this is the first investigation on movie script generation with a narrative.",neutral
1560,dev_1560,"However, a narrative plays a different and more specific role than a general context.","this is consistent with our intuition: when a narrative is more detailed and better aligned with the session in wording, it is easier to choose the best responses.",neutral
1561,dev_1561,"Recently, deep neural networks have been used to tackle the problem (Bamman et al., 2019), and related problems such as generating coherent and cohesive text (Cho et al., 2019) and identifying relations in generated stories (Roemmele, 2019) have also been addressed.",we manually review the data and remove such non-narrative data.,neutral
1562,dev_1562,"Compared to the dot-product attentions in GAT, KGAT's Edge attention focuses on fewer tokens and has a smaller entropy.","the BERt sentence retrieval outperforms ESIM sentence retrieval significantly, thus also helps improve KGAt's reasoning accuracy.",neutral
1563,dev_1563,"The evidence propagation and per-node label prediction in KGAT are conducted by Edge Kernels, which attentively propagate information among nodes in the graph G along the edges with the kernel attention mechanism.",sentence Level Claim Label Prediction.,neutral
1564,dev_1564,"This is because MetaQA KG is fairly sparse, with only 135k triples for 43k entities.",performance on 2-hop and 3-hop questions suggest that EmbedKGQA is able to infer the correct relation from the neighboring edges because the KG embeddings can model composition of relations.,neutral
1565,dev_1565,"Their task was to choose which of the learned response plans was better suited to the realization task (CTX, PSA, Both or Neither).","We also note that there were cases where the grammar, e.g. pronoun usage, is inconsistent.",neutral
1566,dev_1566,Additional examples of success and failure cases are uploaded in the Appendix.,"these models do not achieve the same level of consistent performance on generative modeling tasks as opposed to language understanding tasks (Ziegler et al., 2019;Edunov et al., 2019).",neutral
1567,dev_1567,"Although the original tweet mentions @narendramodi PM of India and uses Hindi keywords, but the nodes selected for expansion rightfully capture about finance ministry (@arunjaitley, @finminindia), home ministry (@amitshah), economic transformation and mostly positive sentiments about it.","fourth, it also addresses under-specificity and noisy text for sentiment classification by expanding or shrinking the network representing the tweets.",neutral
1568,dev_1568,Majority of the recent studies focus on the application of neural network models.,we see substantial performance gain for N2V Rw in both the datasets when augmented with any node expansion.,neutral
1569,dev_1569,The second tweet is one under-specified tweet where India's Prime Minister greets soldiers.,we evaluate the proposed method over datasets in different domains.,neutral
1570,dev_1570," Kazemzadeh et al. (2014), Hu et al. (2017a), and Mao et al. (2016) introduce two benchmark datasets for the real-world 2D images","in our experiments, we presented one of these scenarios (single instruction, static, and pixellevel) since it was the closest to the pre-existing Touchdown-SDR system.",neutral
1571,dev_1571,We thank members of MultiComp Lab at CMU and Berg Lab at UCSD for useful discussions.,table 7: Results for instruction ablation human study.,neutral
1572,dev_1572,"Since we use objects near to the target location as anchor points, this is also another useful metric.","with Touchdown, in our setup instructors, followers, and learning systems observe a partial FoV of the scene, but they can change the FoV continuously to explore the scene.",neutral
1573,dev_1573,Relying on uconv's built-in deromanization is not optimal.,"for languages that are related to a pretraining language with a different script (groups (b) and (c)), there is an added benefit of using romanization.",neutral
1574,dev_1574,"The participants ranged from 16 years old to 100 years old, almost in equal numbers of men and women, and they were all native speakers of Mapudungun.","because Machi (traditional Mapuche healers) were interviewed, we asked the transcribers to delete any culturally proprietary knowledge that a Machi may have revealed during the conversation.",neutral
1575,dev_1575,"Out of the 4262 distinct sentences, only 188 were recorded more than once.",tense changes and some form of negation or banning also keep the vectors very similar.,neutral
1576,dev_1576,"""One photon torpedo and you're a space toast.""",the chance of two annotators producing the same output string is quite low.,neutral
1577,dev_1577,"In fact, out of the 62,501 unique tokens in the dataset, 57% appear just once, and 78% appear 3 or fewer times.","to decide the boost values, we calculate the average percentage word overlap between a segment in the question and its correct answer from AskUbuntu on the train and val sets.",neutral
1578,dev_1578,Rows 2 and 3 in Table 3 present the results of using attention.,the best performance is achieved by combining pre-trained embeddings from multiple language models trained on different data sources.,neutral
1579,dev_1579,"Also sequence-to-sequence encoder-decoder architectures have been devised, to train systems on parallel corpora with the specific aim of news translation (Hassan et al. 2018).","one major challenge in the lexical semantics field is, to date, that of dealing with as many as possible languages at the same time (e.g., BabelNet covers 284 different languages), so to enable truly multilingual and crosslingual applications.",neutral
1580,dev_1580,"For example, word embeddings tend to be consistent across language variations (Aldarmaki, Mohan, and Diab 2018), whereas multilingual vector spaces have more difficulty in representing individual words (such as, e.g., homographs with unrelated senses and phrasal verbs) because of their different usage distributions.","among the main areas where multilingual and crosslingual resources and approaches are solicited, there are of course machine translation (Cho et al. 2014; Luong, Pham, and Manning 2015), crosslingual document categorization (Kocisky, Hermann, and Blunsom 2014; Gouws, Bengio, and Corrado 2015), and sentiment analysis (Tang et al. 2014).",neutral
1581,dev_1581,"With regard to the handling of polysemy, the embeddings obtained through the described approach reflect the multiple senses assumed by the word in different contexts.","such scores are higher than the agreement among human raters, which can be thought of as an upper bound to systems' performance.",neutral
1582,dev_1582,Our edit-based model achieves a higher number of exact matches and a higher SARI score compared to prior work on sentence splitting.,"our inference scheme in Sec. 2.2 still needs three times more time steps than the number of edits, i.e. around 4.0 × 3 = 12 for native English (last row in Table 11). ",neutral
1583,dev_1583,"As part of the token-based approaches, we use Okapi BM25 (Robertson et al., 2009) and a variant, BM25+ (Lv and Zhai, 2011a).","among the various types of sources, they mostly rely on online news articles, which often serve to disseminate medical findings from research studies (Medlock et al., 2015).",neutral
1584,dev_1584,"We show a screenshot of the claim writing interface in Figure 6, and the claim verification interface in Figure 7.","the reason why we do not use the entirety of a large research corpus like S2ORC as our fact-checking corpus is that doing so would introduce many false negative retrievals: abstracts containing evidence relevant to a given claim, but not mentioned in the claim's source citance.",neutral
1585,dev_1585,"Susan Collins (R-ME) remains near the middle; she is among the most moderate senators in vote-based, speechbased, and tweet-based models.",the model lays the senators out on the real line and accurately separates them by party.,neutral
1586,dev_1586,"The topics related to education (Topics 5 and 6) and government services (Topic 10) and are more prominent in ukWac, partly because of the relative ease of crawling the educational and government websites, which less often rely on Javascript and have fewer explicit anti-robot restrictions.","more specifically, huberm and S n are computed for the distribution of probabilities over all documents in which a word occurs.",neutral
1587,dev_1587,"Many pre-trained language models, such as ELMO, BERT or GPT, have been produced by taking Web resources, such as the 1B Word Benchmark for ELMO, Wikipedia with the Toronto Book Corpus for BERT or WebText for GPT.",the way of dealing with this issue is by using robust methods to detect outliers within non-zero frequency documents and to use the traditional mean of the discounted frequencies (Winsorisation).,neutral
1588,dev_1588,"The values of the normalising constants b = 1.48 for M AD and c = 1.19 for S n are used to match the standard deviation value when the measures are applied to normally distributed data (Rousseeuw and Croux, 1993).","to extraction of popular URLs, ukWac is a corpus produced by crawling the .uk Internet domain (Baroni et al., 2009).",neutral
1589,dev_1589,Such strong performance indicates the effectiveness of our CQA framework.,nSM annotates the questions and then anchors the model to the high-reward programs by assigning them with a deterministic probability.,neutral
1590,dev_1590,"For movie reviews, we compare our model with the baselines provided by DeYoung et al. (2019). ","in addition, there is a task-specific predictor added after the encoder for each distinct task, so they would not intervene with one another while training.",neutral
1591,dev_1591,"To better understand the limits and potential of our proposed method, we further study about the QA IOU F1 Token F1  6.3 13.9 Bert-To-Bert 2019  ability and comprehensiveness of our model.","for the learning rate, we found that when using 1e - 5 without warm-up, the valid loss of SQuAD is 10% higher than using 5e - 6.",neutral
1592,dev_1592,"The predictor structure is the same as one in the beer rating task, where a dense layer inputs e0 and outputs one value vsent to form the rating score y movie .","annotating rationales requires much effort and only few datasets contain such labeled rationales, making supervised learning for rationalization difficult.",neutral
1593,dev_1593,"For instance, it allows for: the rapid development of (sub-)vocabularies; accurate indexes of words and their occurrence in the context of specific works or authors; comparative studies on different literary schools, different authors or different creative periods of a given author; diachronic studies concerned with the evolution of the Portuguese language; among many others.","its unique set of characteristics, namely being composed of complete documents instead of fragments, the carefully edited text, the variety of genres and authors, and the wide time span and orthographic conventions covered, make of it an invaluable and versatile resource for multiple research purposes, both for language technology and digital humanities.",neutral
1594,dev_1594,"This paper introduces the BDCamoes Collection of Portuguese Literary Documents, 1 a new language resource that is suitable for the scientific study and the technological preparation of the Portuguese language.","to many existing corpora aimed at primarily supporting the development and testing of natural language processing tools and applications, BDCamoes has a number of less common, very interesting set of characteristics that together turn it into an invaluable research resource, complementing other related resources.",neutral
1595,dev_1595,"To create a large semantic tagging resource for English words, we apply POS-aware Prediction with k = 3 for all words in the vocabulary of the Sketch Engine POS-specific word embeddings.",brants (2000) highlighted the importance of handling unknown words in part-of-speech tagging.,neutral
1596,dev_1596,"Given the well-established usefulness of part-of-speech tag annotations in many syntactically oriented downstream NLP tasks, the recently proposed notion of semantic tagging (Bjerva et al., 2016) aims at tagging words with tags informed by semantic distinctions, which are likely to be useful across a range of semantic tasks.","the Universal Semantic Tag scheme explicitly considers a sizeable number of different categories of named entities, and in Table 4, we saw that the prediction quality for them (NAM) is fairly high.",neutral
1597,dev_1597,"In order to unify the symbols, single-document summarization is regarded as a special input case of I = 1.","we take the DUC-04 as the test set, and DUC-03 is used for tuning the model when evaluating on DUC-04 dataset.",neutral
1598,dev_1598,"In this paper, we propose a joint learning approach to improve neural abstractive multi-document summarization by using single-document summarization dataset.","experimental results show the efficacy of our approach, and it can substantially outperform several strong baselines.",neutral
1599,dev_1599,It involves identifying important information and filtering out redundant information from input sources.,it blurs the boundaries between documents and loses the hierarchy within the document cluster.,neutral
1600,dev_1600,"Computational approaches have also been conducted to analyze them (Gulordava and Baroni, 2011), proposing novel approaches for understanding lexical semantic change -for an overview, we refer to the survey by (Tahmasebi et al., 2018).",the frequency of all forms of a word were summed for each year to compute the total frequency of the word for that year.,neutral
1601,dev_1601,"In addition, most prior studies focused only on English, whereas comparing two or more languages can shed light on how they actually co-evolved over time.","such effects are often difficult to determine, especially when the causes are less known.",neutral
1602,dev_1602,"Despite its inherent problems (Pechenick et al., 2015), it is one of the few corpora of this size available in both French and English.","nevertheless, to the best of our knowledge, there has been no automatic study of the frequency correlations and patterns of cognates over time across different languages, especially one that uses large datasets.",neutral
1603,dev_1603,We investigate the effectiveness of recent controllable generation methods at steering away from toxicity using REALTOXICITYPROMPTS.,"lastly, because OPENAI-WT does not have available metadata, and due to the imperfect coverage of our subreddit and news reliability data, we only provide lower bound estimates of toxicity in web text corpora.",neutral
1604,dev_1604,"Furthermore, Jin et al. (2019) showed that BERT is the language model that best performs under adversary attacks when compared to CNN and LSTM in terms of success rate and perturbation rate, preservation of semantic content, and efficiency for text classification tasks.","Swap Noise: For each word in the text, one random pair of consecutive characters is swapped (e.g. expression → exrpession).",neutral
1605,dev_1605,One way to evaluate this is by decreasing the lexical similarity between premise and hypothesis.,biLSTM-based models show significant proportion of correctly classified samples without even looking at the premise (which is an undesirable behavior).,neutral
1606,dev_1606,Personality modeling from language is becoming increasingly important for many social scientific  applications.,"judges showed a preference towards the high-attention messages for OPE and AGR, while CON and NEU were no better than chance.",neutral
1607,dev_1607,We adapt the RuleTaker dataset to FEVER by introducing a new NOTENOUGHINFO label for unprovable question-context pairs.,Clark et al. (2020) analyze the logical reasoning capabilities of transformer-based models on a variety of question-answering and reading comprehension tasks.,neutral
1608,dev_1608,"These experiments showed that the information credibility on Twitter will become a key component for solving social problems, for instance.","around 3:00 PM, there is a remarkable increase in credibility due to another tweet posted by the president, which led to a sudden increase in credibility, followed by a constant drop.",neutral
1609,dev_1609,"In order to compute credibility scores for tweets, we needed training data.",a supervised neural network model is a mathematical function whose weights are refined iteration after iteration.,neutral
1610,dev_1610,"We use deep biaffine (Dozat and Manning, 2016) as the attention score of the pointer networks, and this model performs both the mention detection and the coreference resolution.",our model observes consistent performance regardless of 10 different initializations.,neutral
1611,dev_1611,"Interestingly, in addition to verbs we expected (acknowledge, admit, concede), we also find verbs like understand, agree, realize, know.",we settle on a task design as follows: annotators are told that we are collecting their judgments of Gw stance for a series of sentences; we then show an instructions page and guide them through 6 practice trials.,neutral
1612,dev_1612,"In both these examples, the embedded clause (that global warming is serious) is presented as an opinion belonging to a source entity (scientists).","Our work is related to social psychology research on persuasion (Cialdini, 1993; Orji et al., 2015) and recent NLP research on argumentation, such as predicting argument convincingness (Habernal and Gurevych, 2016; Simpson and Gurevych, 2018) and studying discourse-level and non-linguistic features predictive of persuasion (Yang and Kraut, 2017; Zhang et al., 2016).",neutral
1613,dev_1613," In tweets with the word loneliness, users less often describe their own experiences (e.g., “The level of loneliness I’ve reached is at an all time high”), and more often make general statements (e.g., “we don’t know how to appreciate loneliness”) and quote celebrities and literary sources (e.g., “If you are afraid of loneliness, don’t marry. -Anton Chekhov”), than in tweets with the words lonely and solitude.","we identify words that are associated with the SOLO query terms, loneliness, lonely, and solitude, i.e., words that tend to appear in tweets with these query terms more often than they do in the General Tweet Corpus.",neutral
1614,dev_1614,"This is consistent with the conceptual definition of solitude as a positive, voluntary state of being alone.",we also computationally identify and compare words strongly associated with each of these terms.,neutral
1615,dev_1615,We observed that the proposed method outperformed all baselines except for Simple back-off on the TOEFL dataset.,tables 4 and 5 list the results for the two tasks.,neutral
1616,dev_1616,"In such varieties, additional factors, such as influence from the regional languages, such as influences from Hausa, Yaruba and Igbo on Nigerian English (Olaniyi, 2014Í¾ Kperogi, 2015Í¾ Isiaka, 2019, come into play.","most lines that were obtained from external resources were later edited or pruned for length and target word and phoneme coverage, while keeping the semantics and facts intact.",neutral
1617,dev_1617,"The third column contains the transcription of the audio files, which have the same name as the utterance identifiers.",this rather affordable and portable hardware setup forms the core part of our inventory for collecting highquality speech data for low-resource languages and dialects across the world.,neutral
1618,dev_1618,"It consists of 370 texts, which total roughly 2.45 million words of text or about 300 hours of speech, excluding all interviewer utterances, collected in nine regions of the United Kingdom (such as the Hebrides and Scottish Highlands).","here and below we refer to the constituent elements of transcriptions as ""tokens"" or ""word tokens"" rather than words.",neutral
1619,dev_1619,"e b is the reification of John's ""blond-ness"", i.e., it represents the fact that John is blond.",those more specific rules are then exceptions to the general rule.,neutral
1620,dev_1620,"In (Searle, 1995)'s terminology, C defines when something counts as something else in the domain.","this could be needed, for instance, in argumentation systems, where the weight of each argument is assigned at the beginning, then it is inferred which arguments override other ones.",neutral
1621,dev_1621,In this section we investigate the impact of the size of pre-training data to check whether AMR parsing benefits more from pre-trained models that are trained on larger datasets.,"each input s in the fine-tuning task is now equipped with k + 1 outputs, one for the finetuning task while the other k for the k pre-training tasks.",neutral
1622,dev_1622,"Since BPE-dropout produces more fine-grained segmentation, sentences segmented with BPEdropout are longer; distribution of sentence lengths are shown in Figure 4 (a) (with p = 0.1, on average about 1.25 times longer).",we choose the first option to stay in the same setting as the standard BPE.,neutral
1623,dev_1623,Figure 6 shows several examples.,"to confirm this, we reduce dimensionality of embeddings by SVD and visualize (Figure 7).",neutral
1624,dev_1624,"The only difference from BPE is how a word is segmented during model training: BPE-dropout randomly drops some merges from the BPE merge table, which results in different segmentations for the same word.",even for large datasets using BPE-dropout can result in substantially better quality for practical applications where input is likely to be noisy.,neutral
1625,dev_1625,Each test consists of 16 short answer questions (a total of 48 questions).,"additionally, this research (Gomaa and Fahmy, 2014b) presented the first (and the only one to our knowledge) arabic dataset (the Cairo university dataset).",neutral
1626,dev_1626,"In 54.14%(1155 answers), the difference is at most one point.","they used Zahran Word Embedding (Zahran et al., 2015).",neutral
1627,dev_1627,"It is larger than the original one for the English language (Mikolov et al., 2013a) and is enhanced with specific linguistic aspects of the Greek language.",the category of antonyms includes pairs of words that their relationship as antonyms includes higher complexity.,neutral
1628,dev_1628,"we re-affirm the conclusion from (Yih et al., 2016) that having each worker do one task (e.g. labeling a single node in the tree) makes annotation easier for workers.","to fully utilize powerful neural network approaches, it is necessary to have large numbers of training examples.",neutral
1629,dev_1629,"In general, the events for the 84th T.I.F. dataset contain many more articles than the Elections one, but in both datasets the clusters are non-trivial.","Furthermore, by using multiple documents mentioning the entity, in order to describe an event, helps to clarify its type (e.g. if an employee ""left"" the company to go home or was fired) and what actually happened (Hong et al., 2011).",neutral
1630,dev_1630,"The pipeline for the creation of events from the news articles is supported by the Elasticsearch (Gormley and Tong, 2015) database.","looking at the articles that we gather we see that most of them are published between 9 AM to around 9 PM, so the separation of events by day should not be a problem.",neutral
1631,dev_1631,"Recently, neural sequential models (Lample et al., 2016; Akbik et al., 2018; Vaswani et al., 2017) have shown strong performance for various sequence labeling task.","we use the model from Huggingface Transformer codebase , and the repository to finetune our model for sequence labeling task.",neutral
1632,dev_1632,Least Confidence (LC) Culotta and McCallum (2005) measure the uncertainty of sequence models by the most likely predicted sequence.,"these neural models usually require exhaustive human efforts for generating labels for each token, and may not perform well in lowresource settings.",neutral
1633,dev_1633,"Another direction of explainability evaluation is to compare the agreement of salient words annotated by humans to the saliency scores assigned by explanation techniques (DeYoung et al., 2020).","when a model recognizes a highly indicative pattern of the predicted class k, the tokens involved in the pattern would have highly positive saliency scores for this class and highly negative saliency scores for the remaining classes.",neutral
1634,dev_1634,"Deep neural networks (DNNs) have shown great promise in Natural Language Processing (NLP), outperforming other machine learning techniques in sentiment analysis (Devlin et al., 2018), language translation (Chorowski et al., 2015), speech recognition (Jia et al., 2018) and many other tasks 1 .","the vulnerabilities of NLP models have been exposed via, for example, small character perturbations (Ebrahimi et al., 2018), syntactically controlled paraphrasing (Iyyer et al., 2018), targeted keywords attacks (Alzantot et al., 2018;Cheng et al., 2018), and exploitation of back-translation systems (Ribeiro et al., 2018).",neutral
1635,dev_1635,"We further leverage a k-mer-based matching procedure to provide ""word""-level information, as well as a dictionary comprised of prior knowledge about sensor names, to boost the tagging performance.","anecdotally, annotating one sensor name may cost several hundred dollars, and it takes weeks to do so for one typical building with thousands of sensing and control points.",neutral
1636,dev_1636,"Without human input, it is difficult for our model to correctly infer the meaning of such segments.","seNsER achieves over 79% and 67% F 1 in chunking and tagging, respectively -a notable 13-point improvement in tagging over the best compared method.",neutral
1637,dev_1637,"we propose to leverage such meaningful k-mers to complement the representation produced by the language model (i.e., z i defined in Eqq. (1)) as “word”-level information.","here, we present a case study about the learned k-mer embedding results.",neutral
1638,dev_1638,"Our main assumptions for disfluency events are: (1) Repetition-like disfluency events exhibit a common underlying structure property in the frequency domain, (2) filled pauses exhibit specific acoustic correlates with a steady frequency signature (Gabrea and O'Shaughnessy, 2000), (3) these filled pauses have usually adjacent unfilled pauses/silences (Daly, 1994).",the extraction of these two tracks from continuous speech can be decomposed in several engineering tasks (see Figure 1).,neutral
1639,dev_1639,Italic for the primary track and Bold for the collateral track.,"for every time-step t, for a given window-scale s, we compute the similarity ψ(t, s, i) of the frequency representation xt centered on t with its i-th closest neighbours.",neutral
1640,dev_1640,"We categorize the 20 classes into 4 categories based on the types of sentences: question sentence (“* SQ .”), declarative sentence (“* NP VP *” etc.), clause sentence (“SBAR *” and “S *”), and others (“OTHER”).","the performance gap between the SSANs variants is much lower that that on the local reordering task (i.e., 4% vs. 15%).",neutral
1641,dev_1641,"In this example, the word ""talk"" performs attention operation over input sequence, where the words ""Bush"", ""held"" and ""Sharon"" are chosen as the truly-significant words.","due to their high frequency with a limited vocabulary (e.g., 150 words 9 ), content-free words, or function words generally receive a lot of attention, although they have very little substantive meaning.",neutral
1642,dev_1642,This further demonstrates that the learning process of each subtask can be enhanced by the collaborative learning.,hence we can model R 2 by propagating R 1 to M ctx .,neutral
1643,dev_1643,"In the complete ABSA task, the aspect terms are unknown and SC will assign a polarity to every word.","aBSa normally involves three subtasks, namely aspect term extraction (aE), opinion term extraction (OE), and aspect-level sentiment classification (SC).",neutral
1644,dev_1644,"Given a clear recipe to produce the values in the selected figures and tables, we assume that the aim is closer to replication according to our definition.",this paper presents our reproduction efforts of an earlier study of automatic essay scoring (AES) for determining the proficiency of second language learners in a multilingual setting.,neutral
1645,dev_1645,We find that the model trained on backtranslated data is often conservative choosing to leave many input sentences almost unchanged.,our final sentence paraphrasing dataset used to train the abstractor P PM contains 8.6M pairs.,neutral
1646,dev_1646,"We find that even when some context window performs well on the source language task, that is often not the best choice for the target language.",the performance of the small-window embeddings does not transfer to the test languages.,neutral
1647,dev_1647,"Based on the attentional encoder-decoder framework (Bahdanau et al., 2015), it optimizes model parameters under direct translation supervision.","to cascading, another option is to perform direct speech-to-text translation.",neutral
1648,dev_1648,The results on the TREC dataset are very close because top 5 words are possible to include all informative words for short sentences with the average length of 10.,we adopt SP-LIME proposed by Ribeiro et al.,neutral
1649,dev_1649,"We evaluate the local interpretability of VMASKbased models against the base models via the AOPC score (Nguyen, 2018;Samek et al., 2016) and the global interpretability against the IBAbased models via post-hoc accuracy (Chen et al., 2018).","in each iteration, the first term in Equation 9 is approximated with a single sample from q(R|x (i) ) (Kingma and Welling, 2014).",neutral
1650,dev_1650,"As shown in our motivating example in Figure 1 and the constructed graph in Figure 3, the reasoning process needs to operate on span/argument-level, where the basic computational unit typically consists of multiple words like ""Rodney King riots"" and ""the most popular county in the USA"".",the algorithm begins from nodes without incident relations.,neutral
1651,dev_1651,"While this makes sense for most existing datasets, it does not take into account the highlighted cells t highlight in our task.",each example in the development and test sets was annotated by three annotators.,neutral
1652,dev_1652,"The original BERT model is pre-trained with both Wikipedia and the Books corpus (Zhu et al., 2015), the former of which contains our (unrevised) test targets.",the collected annotation examples are noisy since a sentence s may only be partially supported by the table t.,neutral
1653,dev_1653,"In this work, we propose TOTTO, an opendomain table-to-text generation dataset that introduces a novel task design and annotation process to address the above challenges.","data-to-text tasks that are limited to verbalizing a fully specified meaning representation (Gardent et al., 2017b) do not test a model's ability to perform inference and thus remove a considerable amount of challenge from the task.",neutral
1654,dev_1654,"We apply a separately trained language model to calculate the likelihood of the given sentence, which is similar to previous works (Miao et al., 2019; Liu et al., 2019).","we run our algorithm for 100 epochs, and finally, select the sentence with the smallest loss as the final result.",neutral
1655,dev_1655,"In this section, we would like to introduce the design of differentiable cost functions for different objectives.","when the search space is too large, beam-search-based methods always fail to find the constrained optimal solution.",neutral
1656,dev_1656,This method makes use of parallel corpora as well as word alignments to learn cross-lingual embeddings.,"note that we report this to situate our results in context of the same, and these cannot be directly compared, since each task's SOTA is obtained by varied training architecture, suited to perform well in one particular task alone.",neutral
1657,dev_1657,"Zero pronoun resolution (Zhao and Ng, 2007; Kong and Zhou, 2010; Chen and Ng, 2016; Yin et al., 2017, 2018) is a line of research closely related to dropped pronoun recovery.","in dropped pronoun recovery, we consider both anaphoric and non-anaphoric pronouns, and attempt to recover the type of dropped pronoun but not its referent.",neutral
1658,dev_1658,We randomly split the 87-word lowest-IAA class (15) into three equal 29-word subsets.,"only some of those pairs are included in SimVerb (e.g., out of Class 9 pairs decidechoose, decide-select, decide-elect, decide-pick, only the first one is present in SimVerb).",neutral
1659,dev_1659,This is followed by another set of max-pooling and average-pooling layers identical to the first layer.,the objective behind creating two gold-standards is to enable the researchers to evaluate the hatespeech detection approaches on both easier (coarsegrained) and challenging (fine-grained) scenarios.,neutral
1660,dev_1660,"These results substantiate the findings on coarse-grained classification task which suggest that instead of training embeddings, using existing pre-trained embeddings by fine-tuning them on the task in hand is a more perceptive choice.",rest of the paper is organized as follows.,neutral
1661,dev_1661,"As RomUrEm is already trained on a corpora of hate-speech tweets, the same cannot be concluded for this particular embedding.","Tweet: Aap apni behan. Beti.. maan ... aur bivi ka march karwa do phir Translation: Then do a march of you sister, daughter, mom and wife",neutral
1662,dev_1662,"This is closely followed by two other ensemble models i.e., BERT+LASER+GBDT and BERT+LAMB, with an F1-score of 0.89.","on forwarded high activations, the notion of bigram, trigram, and quadgram holds true.",neutral
1663,dev_1663,Additional experiments related to efficiency of intent classification have been conducted by Casanueva et al. (2020).,"we also probe the usefulness of ConveRT encodings for transfer learning in the intent classification task: the model must classify the user's utterance into one of several predefined classes, that is, intents (e.g., within e-banking intents can be card lost or replace card).",neutral
1664,dev_1664,"As for correction performance, Table 6 shows the evaluation result of our human evaluation.","(...) It features the spirited siblings from the beloved classic ""One Fish Two Fish Red Fish Blue Fish"" and is believed to have been written between 1958 and 1962.",neutral
1665,dev_1665,BART is a sequence-to-sequence auto-regressive transformer model that is pretrained as a denoising auto-encoder.,low recall on the inconsistent summaries and false positive samples remain as challenges.,neutral
1666,dev_1666,"Inspired by ULMFiT (Howard and Ruder, 2018), we propose a two-stage pre-training method to train our lattice language model.","applying these models to the spoken scenarios poses several discrepancies between the pre-training task and the target task, such as the domain mismatch between written texts and spoken utterances with ASR errors.",neutral
1667,dev_1667,QE datasets should have a mixture of instances that model both high and low adequacy irrespective of the fluency.,"when we examine the estimations from our QE models, we find that they rarely output values above 0.3, which implies that these models fail to capture sentences with lowquality scores.",neutral
1668,dev_1668,"Our models perform competitively to the state-of-theart QE models (Kepler et al., 2019a;Kim et al., 2019).","With the advent of NMT models, we have seen an increase in the quality of translation systems.",neutral
1669,dev_1669,"The strong performances on partial-inputs show that these datasets are cheatable, and QE systems trained on them would not generalize well (Feng et al., 2019).",hTER would miss-classify it as a good translation since there is only one token that requires post-editing.,neutral
1670,dev_1670,ALIGN outperforms SEQ2SEQ + in ACC EXE on 9 out of the 10 most frequent templates.,"table H5: Dev logical form (ACC LF ), template (ACC tEMP ) and column (ACC COL ) accuracies on the 10 most frequent templates.",neutral
1671,dev_1671,Consider the bottom example in Figure 1: A decoder can benefit from knowing that ORDER BY . . . LIMIT 1 comes from “the highest” (where rank 1 is best); and an encoder should,"wTQ questions are authored by humans under no specific constraints, and as a result wTQ includes more diverse semantics and logical operations.",neutral
1672,dev_1672,"Comparatively, our method enforces faithfulness by including the proposed table-text optimal-transport matching loss and table-text embedding similarity loss.",we train our models end-to-end to minimize our objective function with/without the copy mechanism.,neutral
1673,dev_1673,"We design our evaluation criteria based on (Wang et al., 2018; Tian et al., 2019), but our criteria differs from (Tian et al., 2019) in several aspects.",1: The sentence is not fluent at all and people cannot understand its meaning.,neutral
1674,dev_1674,✗ means do not use the corresponding column component.,one key element of our model is to enforce a generated text sequence to be consistent with (or faithful to) the table input.,neutral
1675,dev_1675,Note that the precision in PARENT-T corresponds to the percentage of words in a text sequence that co-occur in the table; and the recall corresponds to the percentage of words in a table that co-occur in the text.,let Pvocab be the output of the Transformer decoder.,neutral
1676,dev_1676,This special issue includes three papers that focus on different crosslingual challenges at the level of the lexical representation.,shorter sentence representations increase the accuracy in non-trainable similarity tasks.,neutral
1677,dev_1677,Reversed and symmetric question prefixes are converted to a more general label for fair comparison.,we repeat this process 3 times and show the average agreement scores in Table 7.,neutral
1678,dev_1678,"Discourse relations describe how two propositions relate to one another, and identifying them automatically is an integral part of natural language understanding.","we implement the model using BERT (Devlin et al., 2019) in its standard fine-tuning setting, except that the Softmax layer is replaced by a Sigmoid activation function to support multi-label classification.",neutral
1679,dev_1679,"The QG models are based on BERT-HLSQG (Chan and Fan, 2019), with the hyperparameters provided by the authors and minor modifications to apply penalized sampling as in Keskar et al. (2019).",the second example suggests that our model suffers from the problem of handling pronouns.,neutral
1680,dev_1680,"The model mainly plays the role of a leading player assigned with an explicit goal, a knowledge path comprised of two topics, and is provided with knowledge related to these two topics.","based on the Seq2Seq framework, we aggrandize it with each key component of model KIC progressively and the results are summarized in Table 4 and Table 5.",neutral
1681,dev_1681,"Namely, for T1, we invert the order of tokens between two entities of REVERSE instances and treated the resulting token sequences as non-REVERSE instances.","in our reproduction work, at each run we set the random state by selecting the number of the random seed from a range of 0 to 10000 to ensure the train and validation data is split without being introduced too much human bias.",neutral
1682,dev_1682,"We experimented with various cutoff dates in an attempt to replicate the data that would have been available at the time of publication of the ETH-DS3Lab system, and picked December 31, 2017 (the deadline of the SE18T7 was January 22).","with the advancement of Information Retrieval (IR) techniques and Human Language Technology (HLT), text-based search engines have played a major role in research, communication, and publication in many academic fields.",neutral
1683,dev_1683,"In this section, we present the experiments on eventevent relation extraction.","despite the scarce annotation for both tasks, the proposed method surpasses the SOTA TempRel extraction method on MATRES by relatively 3.27% in F 1 ; it also offers promising performance on the HiEve dataset for subevent relation extraction, relatively surpassing previous methods by at least 3.12% in F 1 .",neutral
1684,dev_1684,The TempRels are considered for all event pairs on the same axis and within a context of two adjacent sentences.,"the proposed joint constrained learning framework surpasses the best baseline method by a relative gain of 3.27% in F 1 , and excels in terms of both precision and recall.",neutral
1685,dev_1685," This is motivated by the idea that while the average number of “old” citations per paper is stable (cf. Sec. 3.2), they might be distributed in an unbalanced way.",future work includes a deeper qualitative analysis of which (type of) papers are being cited; a more fine-grained analysis of different research topics in NLP to determine whether changes are more prevalent within certain areas than others; or extending the analysis to a larger set of the papers in the ACL Anthology.,neutral
1686,dev_1686,"We use the train, validation, test split provided by Hancock et al. (2018) for Disease, and split the development set of Spouse randomly into a validation and test set (the split was done at a document level).",we trained ExpBERT and the NoExp baseline with varying fractions of Spouse and TACRED training data (Figure 3).,neutral
1687,dev_1687,The incorporation of text into ideal point modeling is not limited to legislators: Sim et al. (2016) model U.S. Supreme Court behavior using a generative model for amicus briefs,we present an embedding-based model for predicting the frequency and sentiment of legislator tweets.,neutral
1688,dev_1688,"These augmented sentences generated from Insertion are often not natural, since those inserted mgrams are randomly picked from the whole corpus which may be irrelevant to the current sentence.","their results could not serve as augmented data to pretrain sequence tagging models, since there was no indication where were the disfluent segments in output sentences.",neutral
1689,dev_1689,This example shows that syntactic structure provides useful cues for CWS and POS tagging.,"we use existing language processing toolkits to obtain the auto-analyzed syntactic knowledge for the context, and the proposed attention module can learn and benefit from them although their quality may not be perfect.",neutral
1690,dev_1690,"We experimented on two datasets from SemEval 2014 (Pontiki et al., 2014), which consist of reviews and comments from two categories: LAPTOP and RESTAURANT.","giving the superior performance of BERT on downstream tasks, it is natural to ask if BERT is learning an empirically useful structure of language.",neutral
1691,dev_1691,"UD is based on a lexicalist view of syntax, which means that dependency relations hold between words, and that morphological features are encoded as properties of words with no attempt at segmenting words into morphemes.","Conjoined predicates often share dependents (e.g., a subject) and conjoined dependents share a head.",neutral
1692,dev_1692,"It is key for models to not ignore identifiers, but to match them with the right context.","we use post-hoc explanation algorithms to interpret and modulate finetuned language models like BERT (Devlin et al., 2018), which achieve state of the art performance on many hate speech detection tasks (MacAvaney et al., 2019;Mandl et al., 2019).",neutral
1693,dev_1693,We would therefore not have been able to provide a url to this data as is required for submissions to the REPROLANG 2020 shared task.,"These thirteen language sets are Danish, Spanish, Basque, French, French Sequoia, Hungarian, Croatian, Indonesian, Japanese, Dutch Lassy Small, Norwegian Bokmaal, Norwegian Nynorsk, and Russian SynTagRus, which was noted by Bohnet et al. (2018) in the caption of Table 2 of their document.",neutral
1694,dev_1694,"Our comparison of two model configurations shows the parameter values from the paper resulting in F1-scores that are closest to the reported scores for 25 out of 46 data sets, with 1 tie.",some of the languages in the data do not have meaningful XPOs tags.,neutral
1695,dev_1695,Our models use the acronyms WWM and SWM respectively to indicate the type of masking they used.,first important result that should be noted is that LSTM+CRf and LSTM+seq2seq models have similar performances to that of the SEM (CRf) baseline when they are not augmented with any kind of embeddings.,neutral
1696,dev_1696,Just adding classical fastText word embeddings dramatically increases the performance of the model.,"as opposed to adding ELMo, the difference with/without CamemBERT is equally considerable for both the LSTM-seq2seq and LSTM-CRF.",neutral
1697,dev_1697,"The LDC2015E86 dataset contains 16,833 instances for the training, 1,368 for the development, and 1,371 for the test.","the overall architecture of Graph transformer is shown in Figure 2, with an example AMR graph and its corresponding sentence.",neutral
1698,dev_1698,Such a method may lose information from the graph structure.,these graph encoders still cannot significantly outperform sequence encoders.,neutral
1699,dev_1699,"Both of its encoder and decoder consist of 6-layer Transformers, where the inner dimension of feed-forward networks (FFN), hidden state size, and the number of attention head are set to 4096, 1024, and 16.","we implement Back-Translation based on the source code6 to generate a new question data for each original question; (3) Text-VAE (Bowman et al., 2016;Liu et al., 2019a): it uses RNNbased VAE to generate a new question data for each question of SQuAD 2.0.",neutral
1700,dev_1700,"Different from previous work, ZEN provides an alternative way of learning larger granular text for pre-trained models, where the structure of BERT is extended by another Transformer-style encoder to represent the extracted n-grams for each input text instance.","The second step of n-gram extraction is performed during pre-training, where some n-grams in L are selected according to each training instance c = (c1, c2, ..., ci, ..., ckc) with kc characters.",neutral
1701,dev_1701,"It shows that the number 32 (2 5 ) gives a good tradeoff between performance and computation, although there is a small gain by using more n-grams.","first, both methods rely on the word masking strategy so that the encoder can only be trained with existing word and phrase information.",neutral
1702,dev_1702,"If we consider the Direct CLWE approach in terms of Levenshtein distance, the distance between a word in the corpus, and a word in the lexicon, must be 0 for them to match.","Table 7: Keystroke saving rate for language models trained for both tokenization strategies, with differing approaches to initialization, for varying numbers of suggestions, on both the dev and test sets.",neutral
1703,dev_1703,"This is expected because during inference, many key terms may be masked out, making the task harder.","in both examples, the discourse marker appears in the first sentence but the second sentence has anaphora referring to an antecedent in the first sentence.",neutral
1704,dev_1704,"We show that our model achieves a new stateof-the-art on DiscoEval, improving the results on 5 of the 7 tasks and increasing accuracy by up to 13% and an average of over 4% absolute across all tasks.","we are unable to achieve similar results despite training on 24 times more examples, and including CCNews (Liu et al., 2019), a larger and higher quality data source.",neutral
1705,dev_1705,"Two economic advisers estimated in a 2009 report that with the stimulus plan, the unemployment rate would peak near 8 percent before dropping to less than 6 percent by now.",table 8 presents examples of selected oracles that serve as gold labels during training the extractive summarization model.,neutral
1706,dev_1706,Table 8 presents examples of selected oracles that serve as gold labels during training the extractive summarization model.,"explain-extr is ranked higher than explain-MT in terms of Non-redundancy and Non-contradiction, where the last criterion was disagreed upon, and the rank improvement for the first one is only marginal at 0.04.",neutral
1707,dev_1707,"In this example, the model is penalized for Claude, even though the time-interval for Claude exactly matches the query.","e.g., Pierre is also a member of the assembly, but during [2002,2003].",neutral
1708,dev_1708,"Each interval T is represented as [t b , t e ], with begin and end time instants.",all the datasets we used had at least 99% of facts with temporal information.,neutral
1709,dev_1709,"Natural Language Visual Reasoning 2 (NLVR2) Given a natural language sentence about two photographs, the task is to determine if the sentence is true .","contrast sets are model-agnostic, constructed by experts to characterize whether a model's decision boundary locally aligns to the true decision boundary around some point.",neutral
1710,dev_1710,The masking proportion is lifted from 15% to 20% without tuning compared with BERT and RoBERTa.,gLM yields an extra 1.3% (67.7% to 69.0%) improvement by better data exploitation.,neutral
1711,dev_1711,It was therefore not entirely surprising to us that some colleagues specializing on the subject participated in the game.,"For each test, we purposely crafted two short sentences, with only one possible annotation, so that the players can easily apply their new knowledge, gain confidence, and not be confused upon completing the training phase.",neutral
1712,dev_1712,"Each entry can have zero, one or multiple translations.","we repeat this process for each of the three paired lists and merge the resulting lists, removing duplicate entries in the process.",neutral
1713,dev_1713,"Finally, we compare the results for both the monolingual and multilingual models to understand how they  perform on the French dataset.",finally we extend our thanks to the whole Illuin Technology team for their reviewing and constructive feedbacks.,neutral
1714,dev_1714,"The more answers to a question there are, the more likely it is that any other answer is equal to one of the expected answers.",we observe also that enriching native French training data with the translated samples does not improve the performances on the native evaluation set.,neutral
1715,dev_1715,"v,v denote the congruent image and the incongruent image, respectively.","However, our experimental results show that the model of Xu et al. (2019) may be insufficient to identify which attribute a value corresponds to.",neutral
1716,dev_1716,"Though plenty of systems have been proposed to supplement product attribute values (Putthividhya and Hu, 2011;  More, 2016; Shinzato and Sekine, 2013; Zheng et al., 2018; Xu et al., 2019), the relationship between product attributes and values are not sufficiently explored, and most of these approaches primarily focus on the text information.","to sum up, using the visual product information indiscriminately poses detrimental effects on the model, and selectively utilizing visual product information with global and regional visual gates are essential for our tasks.",neutral
1717,dev_1717,"For example, given a sentence ""The red collar and golden buttons in the shirt form a colorful fashion topic"" and the predicted product attribute ""Color"", it is easy to recognize the value ""golden"" corresponding to attribute ""Color"" instead of ""Material"".","we evaluate the ScalingUp model to predict the value for each given attribute on our dataset, and the result is unsatisfactory.",neutral
1718,dev_1718,We use the original baseline system and interchange transformer weights to compare between BERT and ours.,2019-19051600006 under the BETTER Program and by Contract FA8750-19-2-1004 with the US Defense Advanced Research Projects Agency (DARPA).,neutral
1719,dev_1719,"As described in detail in Section 2, past reevaluations of human parity claims were hampered by sub-optimal test settings.","they focus only on the effect of translationese with re-spect to human evaluation, without considering its differing effect on automatic evaluation.",neutral
1720,dev_1720,Cross-entropy loss based optimization is traditionally used for the sequence generation tasks.,"bandit-based variant to improve all metrics but by using multiple bandits which are controlled by a controller, called Hierarchical Multi-reward Bandits (HM-Bandit, Fig. 2).",neutral
1721,dev_1721,Very dissimilar usage distributions yield high JSD whereas low JSD values indicate that the proportions of usage types barely change across periods.,"we propose a novel method that exploits the BERT neural language model to obtain representations of word usages, clusters these representations into usage types, and measures change along time with three proposed metrics.",neutral
1722,dev_1722,"For that reason we generated artificial data automatically labeled with slot and intent labels, defined by a smart home context.","table 7 (Seq2seq(6)) includes performances significantly lower than the other Att-RNN and Seq2seq models due to a strong tendency towards none intent prediction with ESLO2 data as part of the training set (Figure 3 Seq2seq(6)) (Desot et al., 2019a;Desot et al., 2019b).",neutral
1723,dev_1723,Only out of domain utterances were kept for collecting none intent training data.,an artificial data version was generated without alignment between source and target series of labels and intent classes for a sequence generation approach.,neutral
1724,dev_1724,"Table 7 (Seq2seq(6)) includes performances significantly lower than the other Att-RNN and Seq2seq models due to a strong tendency towards none intent prediction with ESLO2 data as part of the training set (Figure 3 Seq2seq(6)) (Desot et al., 2019a;Desot et al., 2019b).","these systems include multiple modules, such as a Spoken Language Understanding (SLU) module that must be able to extract the intent of the user from the voice command and its named entities.",neutral
1725,dev_1725,"Percentages of words with more than 3 morphemes (>3 Morph.), surface segmentation (Surf.), canonical segmentation (Canon.), and without segmentation (NoSeg.), as well as the average number of morphemes per word (M./W.) and characters per word (Ch./W.).","by manual inspection, we identify five not mutually exclusive types of errors: Oversegmentation (Overseg.) arises when the number of morpheme boundaries in the prediction is higher than in the gold standard annotation. ",neutral
1726,dev_1726,"PGNet shows no strong wins or problems regarding these errors, except for English, where it performs better for undersegmentation.","instead of using maximum likelihood estimation (MLE), training is done with imitation learning.",neutral
1727,dev_1727,"The performance of IL is consistently better on all metrics, with substantial gains for Tepehua of 6.5% accuracy over the closest system (semiCRF) and 10.4% accuracy over PGNet.","we find a large gap between the emulated and the real low-resource scenarios: while accuracy is above 50% for all high-resource languages even with reduced amounts of training data, for Popoluca and Tepehua, our best model only obtains 37.4% and 28.4% accuracy, respectively.",neutral
1728,dev_1728,Previous methods have mostly relied on supervised learning techniques which require labeled corpora.,"it efficiently captures the skew in the distribution of languages, thereby making the disparity in language usage more clearer.",neutral
1729,dev_1729,"These Process entities can be further selected by combining another query, for example, a compound name.","these Process entities can be further selected by combining another query, for example, a compound name.",neutral
1730,dev_1730,"To evaluate the performance of cyberbullying detection methods, we use the following metrics, which are commonly used to evaluate classifiers: Accuracy (Acc), Precision (Pre), Recall (Rec), and F1-Score (F1).",the latter comment is selected to be a more important evidence for cyberbullying prediction.,neutral
1731,dev_1731,"To measure the difference, we calculate (1) KL divergence between two distributions (positive/negative) and (2) intersection over union (IOU), which is a widely used metric in object detection (Ren et al., 2015) on the top-1 memory usage.",each memory slot in Lample et al. (2019) and ours does not have explicit meaning.,neutral
1732,dev_1732,"For BERT, words in the Verb set were removed if they were assigned more than one token, as BERT does not model the joint distribution over multiple masked tokens.",this variation is not explained by frequency of occurrence in natural text.,neutral
1733,dev_1733,"In order to assess the quality of OCR for AMZ, 23 we transcribed a small random sample of pages of issue 25.",12 Part of this material is also freely downloadable from The Language Bank of Finland provided by the FIN-CLARIN consortium.,neutral
1734,dev_1734,"In this case, the estimate Q(a, s) can be arbitrarily bad (Fujimoto et al., 2018).",we solve these problems by developing a new method for offline RL.,neutral
1735,dev_1735,"While our KL-control models achieved higher qualitative ratings than the other offline RL algorithms, none of the RL models received higher qualitative ratings than the VHRED-EI Model (Table 4).","we reward semantic similarity between the user's input and the bot's response, to encourage the bot to stay on topic and produce reasonable answers.",neutral
1736,dev_1736,"We conduct experiments on synthetic, hand-authored, and human-paraphrased rule-bases to show promising results for QA and proof generation, with strong generalization performance.",model Interpretability: PROVER follows a significant body of previous work on developing interpretable neural models for NLP tasks to foster explainability.,neutral
1737,dev_1737,"This helps us understand the effectiveness of our NAF learning; (3) Unconstrained Train + No ILP: Through this model, we study the effectiveness of our global constraints.","multi-hop QA datasets like HotpotQA (Yang et al., 2018) require multiple reasoning steps, but the inference rules needed are again implicitly inferred, rather than explicitly provided.",neutral
1738,dev_1738,"We evaluate the generalization ability of PROVER compared to RuleTakers by training models on the train splits of DU0, DU1, DU2 and DU3, and testing the QA performance on the overall test set for DU5, which includes questions with higher depth than seen during training.","their task requires predicting the truth value of a statement by reasoning over a set of facts and rules, all expressed in natural language.",neutral
1739,dev_1739,"Although the bulk semantic information is based on adjectives in this kind of sentences, the copular verb ""to be"" does play a role in the sentence and annotation of the copular verb is also required for complete semantic representation.",the verb has to have a base form that can stand on its own and the base has to share its definition with the derived form.,neutral
1740,dev_1740,"And finally, sample sentences were added for each entry in the data set.",the annotations include not only arguments but adjuncts as well.,neutral
1741,dev_1741,"Verbs constitute a major category in human languages, expressing the critical information concerning a state or an event.","verbs can be categorized based on the number of their core arguments: intransitive (1), transitive (2) and ditransitive (3).",neutral
1742,dev_1742,"One example is -(y)Abil, historically derived from the verb bil-""to know"", which adds the meaning of ability, permission, or possibility.",their inclusion would be redundant.,neutral
1743,dev_1743,"Note that many existing generator architectures (Miyato and Koyama, 2018; Wang et al., 2018; Karras et al., 2019, 2020) have residual blocks starting from higher dimensions (eg. 512, 1024) in lowresolution then gradually decrease the dimension as feature maps are spatial upsampled.",we use the same vocabulary used in BERT 4 and LXMERT with size 30522.,neutral
1744,dev_1744,The AVG model performs slightly better than the BiLSTM on both generation tasks.,"for each object, we collect its id, type (boundary, bar, jar, circle), color (red, green, blue, purple, gray, black), state (dynamic, static), and (x, y) coordinates.",neutral
1745,dev_1745,"To learn c's representation, we encode both word occurrence in each turn (via turn-level modeling) and interactions between conversation turns (via conversation-level modeling).",our model performs the best in conversation cold start.,neutral
1746,dev_1746,This phenomenon is referred to as conversation cold start.,graph-structured encoder may be a suitable alternative for capturing rich turn interactions in Reddit conversations.,neutral
1747,dev_1747,"Rather than blaming individual shooters, the German press paid more attention to U.S. public opinion manifesting as gun violence protests and the U.S. gun regulations.","their approach predicts only a single frame, which is insufficient given the multifaceted nature of news framing in which multiple frames often co-occur in the same headline.",neutral
1748,dev_1748,"Each of these matrices is of size vocab_size � hidden_size, and thus each token in the vocabulary has its corresponding q, k, and v vectors.","we replace all utterances of ""important"" words with it's T L dictionary translation.",neutral
1749,dev_1749,These experiments used 100 examples sampled from the manually annotated CNN/DM test set.,"on the more abstractive XSum data, results show a reverse trend with the MNLI model achieving highest performance.",neutral
1750,dev_1750,When training our CatBoost model (section 2.2.) we did not have a manually-annotated evaluation set available to tune against,"for example, letras giz vetores (Spanish) was predicted to be Portuguese and cacau seco (Portuguese) as Spanish.",neutral
1751,dev_1751,It is a powerful fundamental model for wide use of natural language processing tasks.,"with a few vetting-estimating iterations, evaluation results can be dramatically close to that of human evaluation by using limited vetted data and all noisy data.",neutral
1752,dev_1752,"PCNN+ATT+RL (Qin et al., 2018b) adopts reinforcement learning to overcome wrong labeling problem for distant supervision.","for the PR curve, every point depends on P @K for different K. this vetting strategy is also useful for the PR curve.",neutral
1753,dev_1753,"Our model achieves new state-of-the-art results of 70.49% (German) and 90.75% (Czech) F1-score, significantly outperforming the previous best system (Lyu et al., 2019).",we use mean field variational inference approximates to obtain the final arc distribution.,neutral
1754,dev_1754,"In order to generate story-like textual descriptions that complement the factual captions, we additionally train our model to exploit our diverse completesentence annotations.","this setting is consistent with the NSP task in (Devlin et al., 2019).",neutral
1755,dev_1755,"We use SpaCy linguistic features (Honnibal and Montani, 2017) along with the LemmInflect library (https://github.com/bjascob/LemmInflect) and templatebased generation to convert the captions, intentions, effects, and attributes from V2C to create questions and ground-truth answers.",we want to make sure that these descriptions are also relevant to the video.,neutral
1756,dev_1756,"The word2vec word embeddings for the Polish language were downloaded from Wikipedia2vec (Yamada et al., 2018) and cleaned by removing embeddings of tokens consisting of multiple words.","as mentioned earlier, the self-learning procedure consists of two steps.",neutral
1757,dev_1757,"It is clear that such a strong assumption does not hold exactly since that would mean that e.g., the languages have the same number of words or that they have the same number of synonyms for each concept.",we show that some Slavic languages (Czech and Polish) are quite challenging for the method.,neutral
1758,dev_1758,A major issue is that engineers know little biology or few details of plants or animals.,determining whether the sentence expresses a trade-off requires additional reasoning and often domainspecific knowledge.,neutral
1759,dev_1759,"The training set contains 30% more images with ""woman cooking"" than ""man cooking"".",we further propose a bias mitigation approach based on posterior regularization.,neutral
1760,dev_1760,"We posit that the requirement of making hard predictions (i.e., maximum a posteriori estimation) also amplifies the bias when evaluating the top predictions.","given corpus-level constraints and a distribution predicted by a model, we 1) define a feasible set of the distributions with respect to the constraints; 2) find the closest distribution in the feasible set from given distribution; 3) do maximum a posteriori (MAP) inference on the optimal feasible distribution.",neutral
1761,dev_1761,"Though our experiments are based on a Chinese dataset, our approach can be easily adapted to other languages, such as English and Japanese.",figure 2: The historical dialogue selection module.,neutral
1762,dev_1762,"proposed a review response generation model in the E-commerce platform, which used the reinforcement learning and copy mechanism to fuse external product information, thereby generating informative and diverse responses.","these models are difficult to generalize, and their results are unsatisfied since responses maybe vary a lot for the same question towards different occasions and speakers.",neutral
1763,dev_1763,The application of a curriculum is based on the often unspoken assumption that the representation of a complex pattern can be reached more easily from a simpler pattern.,this could be explained by the idea that they never acquire the either/or rule (instead memorizing the entire sequence).,neutral
1764,dev_1764,"For example, a ""slice of cake"" can be broken into the individual meanings of ""slice"", ""of"", and ""cake"", but an idiomatic expression such as ""piece of cake"", meaning a simple task, cannot be broken into the individual meanings of ""piece"", ""of"", and ""cake"".","knowing that ""trick"" and ""student"" co-occur is not sufficient to clarify the meaning and connotations of either word or compose a shared meaning.",neutral
1765,dev_1765,Each of the baseline model is a binary classifier indicating whether a given phenotype is present in the input patient note.,"example: ""past medical history of alcohol abuse who was diagnosed with alcoholic cirrhosis on this admission"".",neutral
1766,dev_1766,"To the best of our knowledge, this is the first paper that attempts solving dialogue evaluation by treating it as an anomaly detection problem.",participants had to create dialogue systems that had to fulfill specific criteria.,neutral
1767,dev_1767,"In addition, Da and Kusai (2019) proves that pre-trained language models have the ability to encode some commonsense knowledge in the embedding space through the attribute classification evaluation.","from figure 5, we can see that the layout of question, the correct answer 'garage' and the wrong answer 'utility room' are 'a person' with 'a truck', 'cars', and 'chairs' and 'old televisions', respectively.",neutral
1768,dev_1768,"For example, we could find many images where fire extinguishers appear in these scenes of public places.",here we use commonsenseQA as an example to demonstrate our method.,neutral
1769,dev_1769,"Experimental results on two commonsense reasoning problems, i.e. commonsense question answering and pronoun resolution, demonstrate that Loire outperforms traditional language-based methods.","they also show that the encoded commonsense knowledge is limited, which could be improved by introducing some supplementary data, like ConceptNet.",neutral
1770,dev_1770,Detailed evaluation metrics for this process are described in Dumitrache et al. (2018).,it was translated into the word meog-da 'eat' because the word aziwau was used as a metaphor in the Japanese sentence to represent the concept of ingestion.,neutral
1771,dev_1771,"When the results were evaluated, no significant difference was observed between the two groups of workers and the annotation quality.","the crowd workers tended to select more specific frames instead of comprehensive frames, such as the frame Intentionally act.",neutral
1772,dev_1772,"In (Akhtar et al., 2016), a dataset for Hindi was created and in (Akhtar et al., 2018), an approach was developed for ABSA in Hindi using the created dataset.",the number of neutral aspect terms is relatively low.,neutral
1773,dev_1773,"For instance, the marker +Aux differentiates auxiliary from other verbs, the marker +NProp differentiates proper nouns from other nouns, while markers +ProN and +ProA differentiate nominal from adjectival pronouns.","this comes as no surprise, due to the fact that it is a very specific text, which is fully covered by the new dictionary used for the tt19 model.",neutral
1774,dev_1774,"The developers reveal that this is due to the underlying architecture that contains a hidden convolutional layer shared between a tagger, parser and a named entity recognizer.",publishing of new versions of annotated Serbian corpus requires an accurate automatic tagging system.,neutral
1775,dev_1775,"Raw data are stored in a specific folder (raw/), as are additional information pertaining to reference catalogs, such as Glottocodes or orthography profiles (etc/), or additional, userprovided commands (commands/).","with cldfbench, we hope to make a first step into the direction of potential users who might want to try to lift their own or other published datasets to a higher level of cross-linguistic comparability.",neutral
1776,dev_1776,"Technically, cldfbench provides a layer on top of the pycldf package that provides low-level access to read, write, and validate CLDF datasets (https://pypi.org/pycldf).","cldfbench encourages transparent, replicable data curation -which is essential for making constantly evolving data Reusable.",neutral
1777,dev_1777,An example of this task is provided in Figure 1.,"For each unlabeled dataset, we create a randomly sampled validation set of about 30K samples during these experiments.",neutral
1778,dev_1778,"The storage overhead is minor compared to non-structured irregular pruning (Han et al., 2016).",we report our reproduced results using the same network architectures in the second row.,neutral
1779,dev_1779,"In particular, we consider three measures based on n-gram matching: BLEU-2 (Papineni et al., 2002), ROUGE (Lin, 2004), and observed.","this is in line with Downing (1977), who argues that novel (i.e., not yet lexicalised) noun-noun compounds can be built by speakers on the fly based on a temporary, implicit relationship tying the two nouns, e.g., 'the guy taking a picture with a camera'.",neutral
1780,dev_1780,This allows a more flexible comparison of the dissimilarity with respect to the alignment of the two series across time.,"in (Emms and Kumar Jayapal, 2016), the model is evaluated qualitatively on the Google NGrams corpus (Michel et al., 2011), using a few manually selected target words.",neutral
1781,dev_1781,It starts from the smallest sense (in proportion; rank first) and increases to the largest (rank last).,"in this paper we propose an evaluation method based on largescale time-stamped annotated biomedical data, and a range of evaluation measures suited to the task.",neutral
1782,dev_1782,"A different model was proposed by Frermann and Lapata (2016), focusing instead on capturing the subtle meaning changes within a sense over time.","for every CUI, the corresponding MeSH descriptor is extracted from UMLS.",neutral
1783,dev_1783,Figure 1: Distribution of the probabilities predicted by NEO and SCAN systems: the red distribution represents the predicted probability of the gold sense for every instance in the data; the blue distribution represents the highest predicted probability for every instance.,classification measures and MAE are susceptible to show complementary aspects of performance.,neutral
1784,dev_1784,Is there a grid in this graph ?,"bringing human-generated questions into the proposed datasets is a challenge since human subjects would be required to possess a deep understanding of the different charts, before being able to ask reasonable and difficult questions.",neutral
1785,dev_1785,"Furthermore, English as source language produces higher numbers of ambiguous words compared to English as target language.","recent works suggest that the state-of-the-art Transformer architecture (Vaswani et al., 2017) for neural MT (NMT) is able to deal with lexical ambiguity quite well (Tang et al., 2018;Tang et al., 2019), learning to distinguish between senses during translation with high precision.",neutral
1786,dev_1786,Guo et al. (2019a) convert the source token to target token with phrase table or embedding mapping for alignments. Ren et al. (2019) predict the duration (the number of mel-spectrograms) of each phoneme,we apply this alignment constraint for ASR only in the training stage.,neutral
1787,dev_1787,"Past work requires these constraints and the HSMM, when trained without them, does poorly, learning to capture diversity across videos rather than to identify steps.","a given step for a task can occur multiple times, or not at all, in any of the task's videos.",neutral
1788,dev_1788,Our weakly-supervised results show that: (1) Both action segmentation metrics -all label accuracy and step label accuracy -are important to evaluate whether models adequately distinguish meaningful actions from background.,(3) ordering supervision alone is not sufficient to allow these models to learn better segmentations than a simple baseline that just uses the ordering to assign labels (ordered uniform); narration is also required.,neutral
1789,dev_1789,"Based on the predictions from these systems 5 , the relevant candidate words are highlighted so as to assist the annotator by inviting her attention to those words.","the presence of an advanced discipline of phonetics in Sanskrit formalises this euphonic assimilation of phones as Sandhi (Goyal and Huet, 2016).",neutral
1790,dev_1790,"In this paper, we attempt to address this problem by incorporating an affective lexicon as numerical influence values into affective neural network models through the framework of the Affect Control Theory (ACT).","by default, the hyper-parameters α, β and γ in Formula 1 and 2 are set equivalently to 0.33, and a is experimentally set to 1.15 as the optimized setting.",neutral
1791,dev_1791,This section probes into the individual role of each attribute to the performance improvement.,attention weights are normally obtained using local context information.,neutral
1792,dev_1792,We hypothesise that this is because it is better to build up representations with local context before exploiting long-range correlations.,"this gives evidence that we do not need to store many separate representations for long-range memory to perform well at test time, but the approach does require storing them during training -and incurs significant slowdown to the model.",neutral
1793,dev_1793,We calculate entropy as H(d e ).,"Comparatively larger resources, however, exist for German literature—Krug et al. (2017) create a dataset of coreference annotations between character mentions in German novels, which helped assess a rule-based system for coreference resolution (Krug et al., 2015).",neutral
1794,dev_1794,"This poses a challenge not only for users who want to learn CQL, especially when their background is in the humanities, but also for experienced users.",the created subcorpus can keep the user-specified proportion of the main registers without the need to specify individual texts.,neutral
1795,dev_1795,"Vowel length errors occur, when a vowel length mark is present in a wordform, but is missing in the corresponding stem or suffix in lexc.","adjectives inside the noun phrase do not agree with the noun, but may be used with nominal suffixes in case of ellipsis.",neutral
1796,dev_1796,"It's a fundamental component in many downstream tasks, and has been greatly advanced by deep neural networks (Lample et al., 2016; Chiu and Nichols, 2016; Peters et al., 2017).","in this paper, we propose a teacher-student learning method to address such limitations, where NER models in the source languages are used as teachers to train a student model on unlabeled data in the target language.",neutral
1797,dev_1797,Our proposed teacher-student learning method then uses those K source-language models as teachers to train an effective student NER model for the target language on its unlabeled data D tgt .,"for each experiment, we conduct 5 runs and report the average f1-score.",neutral
1798,dev_1798,"Results show BERT and RoBERTa coupled with temperature scaling achieve low ECEs in-domain, and when trained with label smoothing, are also competitive out-of-domain.",optimal temperature scaling values are bounded within a small interval.,neutral
1799,dev_1799,"In most cases, MLE models do not perform well on out-of-domain datasets, with ECEs ranging from 8-12.","table 6: Out-of-the-box calibration development set results for in-domain (SNLI, QQP, SWAG) and out-ofdomain (MNLI, twitterPPDB, HellaSWAG) datasets using pre-trained models.",neutral
1800,dev_1800,"For example, 1.89 on the top right explains how much information gain was achieved using DBpedia in comparison to Crunchbase.","our goal is to provide an evaluation data set that considers each of our listed limitations and can be used with ease by other developers as well, therefore allowing for a broader spectrum of application.",neutral
1801,dev_1801,"In some cases, for example year, more than one entity is possible",annotation methods can only be evaluated on a small part of the KG concerning a specific domain.,neutral
1802,dev_1802,"Five product domains with the largest number of QA pairs are selected, namely, Electronics, Home and Kitchen, Sports and Outdoors, Health and Personal Care, and Cell Phones and Accessories, con- Community Votes stituting around 2.7 million QA pairs in total.","one closely related work in the CQA context is a recent attempt of investigating the fact checking task in QA settings (Mihaylova et al., 2018), which was later adopted as the SemEval-2019 Task 8 (Mihaylova et al., 2019).",neutral
1803,dev_1803,An agreement-matching strategy is then employed to model the self-coherence of the evidence sentences for obtaining reliable combined evidence embeddings to verify the answer verdict.,"methods involving small datasets often use hand-crafted features to represent the claim (Mihaylova et al., 2018).",neutral
1804,dev_1804,"As pointed out in Mihaylova et al. (2019), verifying the verdict of answers in CQA requires using rich world knowledge.","for the evidence agreement matching module, we perform a grid search over n a and d a with the following hyperparameters where the final setting is underlined: n a = [2, 3, 4] and [64,128,256].",neutral
1805,dev_1805,"Recently, a new shared task, namely SemEval-2019 Task 8 (Mihaylova et al., 2019) investigates the fact checking problem in question answering scenario, requiring a system to classify the veracity of answers in a web forum.","in E-commerce scenario, product descriptions from the manufacture and user reviews from the former buyers contain rich product information, which can be treated as the candidate information pool for the retrieval process.",neutral
1806,dev_1806,"A possible drawback of our approach is that it only relies on entities, which do not fully cover the sentence semantics.","finally, performing outlier-aware meta-evaluation which was recently shown to be important in such settings (Mathur et al., 2020) could be beneficial.",neutral
1807,dev_1807,"Recently, large-scale pretrained language models (LM) such as BERT (Devlin et al., 2019) and GPT-2 (Radford et al., 2019) are used to improve the performance of dialog models, however in the cost of tens-fold larger model sizes and computations.","remarkably, LABES-S2S is optimized under the principled variational learning framework.",neutral
1808,dev_1808,"A two words of word-pair (wi , wj) belong to the same aspect term.",we can see that the key opinon pair extraction of aspect term and opinion term is still accomplished in pipeline and their approach also suffers from error propagation.,neutral
1809,dev_1809,They take a word embedding as input and generate a definition of the word.,we first compute the representation H D =h 1:T of the definition D = d 1:T with a bidirectional LSTM network.,neutral
1810,dev_1810,"NRC Model Similar to the GloVe-BiLSTM Model, this model is LSTM-based.",we show that emotional representations can be successfully used to capture the underlying characteristics of sentences to suggest proper fonts.,neutral
1811,dev_1811,This motivates us to explore font associations with regular users in a crowd-sourced setting.,"5 GloVe-BiLSTM Model In this model, we use GloVe embeddings (Pennington et al., 2014) as input and a BiLSTM layer to encode word sequence information in forward and backward directions.",neutral
1812,dev_1812,"For example, when scoring the likelihood of the triple (person1, speaks languages, french), we allow the model to use a person's nationality.","we calculate the scores of the positive triples using Equation 1 (shown in Box 2a), and then for each positive triple calculate the scores of N negative triples, with negatives created by randomly permuting the entities on either side; we permute the right hand side (rhs) of T 1 with N = 2 in Box 3 of the example figure.",neutral
1813,dev_1813,The scalar weight w KL controls the emphasis the model puts on debiasing vs. the original prediction task.,"this conclusion is mirrored in table 6, which shows the accuracy of a neural network trained to predict the sensitive attributes from the trained embeddings.",neutral
1814,dev_1814,"As a result, even as we increase w KL to 100.0, the difference in scores approaches an asymptote.","for Wikidata, enough sensitive information remains to be able to predict some of the attributes very accurately.",neutral
1815,dev_1815,Cao and Clark (2019) leverage constituency parsing for generation.,we lowercase and tokenize our system outputs to have fair comparisons with previous systems.,neutral
1816,dev_1816,"TOD-BERT is initialized from BERT, a good starting parameter set, then is further pre-trained on those task-oriented corpora.","the slot accuracy individually compares each (domain, slot, value) triplet to its ground truth label.",neutral
1817,dev_1817,"Naive Bayes, Random Forest and Neural Network classification models were trained on the extracted text and evaluated on a manually annotated dataset to ascertain the models ability to generalize on unseen data.","additionally, we evaluate event extraction over the corpus using the DaNIEL system.",neutral
1818,dev_1818,The local context layer allowed the model to emphasize semantic-relative contextual words.,"the input sentence is converted to the format ""[CLS]"" + Input sequence + ""[SEP ]"".",neutral
1819,dev_1819,CDW helps to boost the performance of LCFS-ASC model more than the CDM.,the aspect sentiment classifier was unable to account for the syntactical correlation between aspect terms and the context words.,neutral
1820,dev_1820,"The aim of the task is binary sentiment classification, where each review document is classified into positive or negative sentiment.","Additionally, we compare with the start-of-the-art baseline LAPS (Ahuja et al., 2020), which relies on external task-specific cross-lingual parallel data (Ahuja et al., 2020), i.e., productto-product and query-to-query correspondences among all 5 languages.",neutral
1821,dev_1821,"To bridge the gaps between languages, numerous CLT algorithms have emerged, ranging from early translation-based methods (Prettenhofer and Stein, 2010), cross-lingual word representation learning (Conneau et al., 2018a), to powerful mPLM (Devlin et al., 2019;Lample and Conneau, 2019), from which the versatile multilingual representations derived suffice it to become a mainstream approach for various downstream CLT tasks.","another research efforts made on cross-lingual word representation learning (Zou et al., 2013;Mikolov et al., 2013;Conneau et al., 2018a;artetxe et al., 2018) and mPLM (Devlin et al., 2019;Lample and Conneau, 2019;Eisenschlos et al., 2019;Chidambaram et al., 2019), which exploit unsupervised learning on large-scale multilingual corpus to learn versatile multilingual contextualized embeddings.",neutral
1822,dev_1822,"In the meta graph G, each instance is regarded as a node.",existing mPLM-based methods focus on designing costly model pre-training while ignoring equally crucial downstream adaptation.,neutral
1823,dev_1823,"Besides, human studies show that our approach is indeed beneficial for preserving more concepts and relations from input graphs.",our approach: i recommend you to go to see your doctor too.,neutral
1824,dev_1824,A potential solution for this issue is improving the training signal to enhance preserving of structural information.,"applying Loss 1 alone achieves an improvement of 1.36 BLEU points, and Loss 2 alone obtains 0.66 more points than Loss 1.",neutral
1825,dev_1825,"For more detail, we remove any abbreviations from a KG node (such as ""New York (NY)"" is changed to ""New York""), before finding the first phrase in the sentence that matches the longest prefix of the node.","as illustrated in the slashed blue box of Figure  2, the result contains several labeled arcs, each connecting a word pair (such as ""wants"" and ""boy"").",neutral
1826,dev_1826,"JamSpell and Pyenchant spelling checkers are inadequate for correcting text errors at character-level, these performed equally poorly, introducing significantly more errors than they fixed.","because of the difficulty in logging real wikitext errors introduced by human editors, we developed a sub-system that artificially can add human-like editing errors to the original text and convert it to training data.",neutral
1827,dev_1827,"Here, 'dictionary' refers to the word-list in the mapping table.",chinese NLP practitioners apply script converters 1   dataset into their desired language.,neutral
1828,dev_1828,Simplified Chinese to Traditional Chinese character conversion is a common preprocessing step in Chinese NLP.,the LIHKG posts are shorter and forums titles are generally one sentence each (average length of nearly 50 characters).,neutral
1829,dev_1829,"In each conversation, a crisis counselor's highlevel goal is to guide the texter towards a calmer mental state.","in general, the directions of the effects we observe hold with stronger effects if we do not take this split.",neutral
1830,dev_1830,"A texter may start to counterproductively rehash or ruminate on their concerns (Nolen-Hoeksema et al., 2008; Jones et al., 2009); indeed, prior psychological work has highlighted the thin line between productive reflection and rumination (Rose et al., 2007; Landphair and Preddy, 2012).",our aim was to characterize behavior in typical conversations rather than exceptional cases or those that reflected earlier versions of the training curriculum.,neutral
1831,dev_1831,"Most of the successful and predominant methods for Bilingual Lexicon Induction (BLI) are mapping-based, where a linear mapping function is learned with the assumption that the word embedding spaces of different languages exhibit similar geometric structures (i.e., approximately isomorphic).","the MUSE dataset consists of Fasttext monolingual embeddings of 300 dimensions (Bojanowski et al., 2017) trained on Wikipedia monolingual corpus and gold dictionaries for 110 language pairs.",neutral
1832,dev_1832,We will conduct a detailed analysis in the next section.,"we use the encoded context hctx given by fctx(bt) from the dialogue state tracking model as query vectors, and attempt to recover the dialogue state from the memory component.",neutral
1833,dev_1833,"We choose the embedding dimensionality d among {50, 75, 100, 150, 200}, the hyperparameters α and β in [0.01, 1.0].",such an approach relies on system action annotations which are expensive to obtain.,neutral
1834,dev_1834,"To further enhance the generalization capability and boost the learning efficiency, we consider re-use the memory component for conditioned response generation.",memory slots with higher probability indicate that the corresponding words are expected to be more salient to represent the system utterance.,neutral
1835,dev_1835,"To obtain compact action representations, we propose an auxiliary task based on pseudo parallel corpus, i.e., dialogue context and state annotation pairs.","system utterances with the same intention might not share similar wordings, and existing attribution approaches can only identify salient words within utterances.",neutral
1836,dev_1836,"For targets that are not already in-domain for ROBERTA, our experiments show that contin-ued pretraining on the domain (which we refer to as domain-adaptive pretraining or DAPT) consistently improves performance on tasks from the target domain, in both high-and low-resource settings.","further adding to the realistic approach of the characters in this show is the depth of their personalities -These are dangerous men, most of them murderers, but by God if you don't love them too.",neutral
1837,dev_1837,"In MSA corpora, this has always to be considered a noun or an adjective.","regarding adjectives, there is a tie between both languages, as the number of adjectives in both Arabic and English is roughly similar.",neutral
1838,dev_1838,"The number of texts relates to the document sort making up the corpus, i.e. abstracts, full texts, sentences or other.",both groups are internally ordered chronologically by first release of the corpus or their publication year.,neutral
1839,dev_1839,Each model training took 4 to 5h on an NVIDIA GeForce RTX 2080.,"the training time can be significantly reduced by using the default number of epochs (3) which, in turn, lowers the amount of training time to less than one hour per run.",neutral
1840,dev_1840,"While lexical frequency effects are difficult to control in unconstrained purely spontaneous language production, language produced during the picture description task is much more constrained in that the picture provides a fixed set of objects, attributes, and relations that serve as referents for the the person describing the picture.",This is consistent with recent work by Weiner et al. (2018) that found diminished perplexity was of some (albeit modest) utility in predicting transitions to AD,neutral
1841,dev_1841,"The results demonstrate that the association between perplexity and lexical frequency is significant and positive for the control LM (coeff: 0.563, p < 0.001) and negative for dementia LM (coeff: -0.543, p < 0.001).","it is currently unclear as to whether this level of accuracy is due to dementia-specific linguistic markers, or a result of markers of other significant differences between the case and control group such as age (x¯ = 71.4 vs. 63) and years of education (x¯= 12.1 vs. 14.3) (Becker et al., 1994)",neutral
1842,dev_1842,"Unlike most written languages in the world, the Chinese writing system does not use explicit delimiters (e.g., white space) to separate words in written text.",it has not been fully explored what would be the best way of representing contextual information such as wordhood features in neural CWS models.,neutral
1843,dev_1843,"Then for each input character, the memory module addresses all the n-grams in the key list that contain the character and uses their corresponding values to generate an output vector to enhance the decoder for assigning a segmentation label to the character.","we use our best performing BERT-based model, i.e., BERT-CRF, with the n-gram lexicons constructed by the aforementioned three measures and run it on all benchmark datasets.",neutral
1844,dev_1844,Several weakly-supervised methods address this problem by using a few keywords per aspect as supervision to guide the learning process.,"s1, on the other hand, does not address the target with plain and general words, but instead use more specific words like ""semi-private"" and ""date"" which are uniquely used when people feel good about the ambience instead of other aspects.",neutral
1845,dev_1845,"The increases in loss are recorded in Table 5, which shows that [Next,Prev] patterns are most important, followed by [First] and [Period], while [Delim] isn’t very useful",we find that RoBERTa-AG is very robust and does not need much tuning.,neutral
1846,dev_1846,"We test the proposed approach with three benchmarks including the Ubuntu Dialogue Corpus (Lowe et al., 2015), DailyDialog (Li et al., 2017), and PERSONA-CHAT .",the last two columns of the tables compare different models in terms of parameter size and decoding speed.,neutral
1847,dev_1847,"Align 2, on the other hand, is what we expect an aligner to produce in order to have meaningful FER and DER evaluations.",we use two sets of weights for finding an alignment between the reference and the integrated model output.,neutral
1848,dev_1848,"The problem that arises 
here is that since many disfluent words are copies 
of fluent words, if the same cost is used to align 
fluent and disfluent words, the alignment will be 
ambiguous (i.e. there will be multiple alignments with the same cost).","as shown in Table 1, the alignment cost is slightly higher for inserting, copying and substituting a disfluent word and slightly lower for deleting a disfluent word.",neutral
1849,dev_1849,"Self-training and ensembling have also shown to provide benefit to disfluency detection (Jamshid Lou and Johnson, 2020).",the end-to-end model sometimes fails at detecting repetitions which are the most common type of disfluency.,neutral
1850,dev_1850,"In addition to its conceptual simplicity, our experiments show that ILM enables off-the-shelf LMs to infill effectively.","then, we compute PPL only on the tokens which comprise the masked span, i.e., PPL is computed for all models on exactly the same set of tokens.",neutral
1851,dev_1851," Language models are (1) capable of generatingremarkably coherent text (Zellers et al., 2019; See et al., 2019), (2) efficient at generating text, and (3) conceptually simple, but cannot infill effectively as they can only leverage context in a single direction (usually the past).",we can thus cast infilling as learning p(y |x) without loss of generality.,neutral
1852,dev_1852,Having access to candidate NPs during inference alone improves the performance on SuperGLUE WSC.,for WSC and use spaCy to mine candidate NPs.,neutral
1853,dev_1853,"We compare our results to the FREQ and SENSE baselines, and to the best results obtained by Cocos et al. (2018) who use information obtained from lexico-syntactic patterns, a lexicon annotated with intensity (SO-CAL) (Taboada et al., 2011), and paraphrases from PPDB.",more details about this filtering are given in Appendix A.,neutral
1854,dev_1854,"To answer the question whether or not we can recognize the structure in obituaries we formulate the task as sentence classification, where each sentence will be assigned to one of the eight classes we defined previously.","we define the following eight classes: Personal information, Biographical sketch, Characteristics, Tribute, Expression of gratitude, Family, Funeral information, and Other to structure obituaries at the sentence level.",neutral
1855,dev_1855,We suspect that error propagation from antecedent-ranking may downgrade the quality of refinement.,"it demonstrates that the benefits from HOi is diminished because the effects are two-sided: there are roughly same amounts of links (about 1%) becoming correct or wrong after HOi, therefore neither HOi method leads to much improvement overall.",neutral
1856,dev_1856,"SemCor alone attains 69.2 points, 1.3 points less than Clustercont.","indeed, language models like BERT (Devlin et al., 2019), RoBERTa , XLNet (Yang et al., 2019), etc., enable architectures built on top of them to attain performances that were previously out of reach (Wang et al., 2019).",neutral
1857,dev_1857,"We collect first-person perspective stories in three stages on Amazon Mechanical Turk (MTurk), using a pairing mechanism to account for topical variation between imagined and recalled stories.","we find no significant differences in demographics between the authors of imagined and recalled stories, 12 but authors of imagined stories scored slightly higher on measures of creativity and openness to experience (Cohen's d = 0.08, p = 0.01).",neutral
1858,dev_1858,"(TONE, positive and negative emotion) and evoke more cognitive processes.",we found no other significant associations with TIMESINCEEVENT.,neutral
1859,dev_1859,"With development and test F 1 scores of 83.7% and 75.8%, respectively, our event tagger slightly outperforms the best performing model in Sims et al.",the proposed measures uncover differences between the initially recalled and later retold stories that mirror the differences found between recalled and imagined stories (Table 2).,neutral
1860,dev_1860,The goal of these checks is to ensure that the final hypernym graph produced by the OMW is a directed acyclic graph.,"finally, after the Global Wordnet Association decided to adopt CILI, OMW became the natural place to coordinate it.",neutral
1861,dev_1861,"The DTD can be easily used to check if the XML is well-formed, which can help projects create their wordnets.","figure 1 shows a screenshot of CILI concept i46645, using a test version of the OMW interface with only six wordnets uploaded.",neutral
1862,dev_1862,"These include the presence of a unique English definition, and the fact that these new concepts link to the CILI hierarchy through an adequate semantic relation.","we decided to try to shift this burden, as far as possible, to the individual wordnet projects.",neutral
1863,dev_1863,"Notable extensions include: confidence, corpus frequency, orthographic variants, lexicalized and non-lexicalized synsets and lemmas, new parts of speech, and more.","this is a much more manageable goal, and projects receive the immediate gratification of seeing their projects (or newer versions of their old projects) updated almost immediately.",neutral
1864,dev_1864,This process is illustrated in Figure 2.,"it obtains a lower pairwise score, but to the detriment of a lower mBLEU score.",neutral
1865,dev_1865,We found that workers had difficulty identifying the correct answer because the number of options for labels in SRL can be overwhelming and workers lack the linguistic expertise to handle subtle cases.,the predicate word and argument spans are automatically identified using the Akbik and Li (2016) system.,neutral
1866,dev_1866,"We present the workers with spans by projecting the head-word, as we expected spans to be more intuitive for workers.",we would like to thank Laura Burdick for helpful feedback on earlier drafts of this paper and the anonymous reviewers for their helpful suggestions.,neutral
1867,dev_1867,An important goal for building systems that learn and generalize like people is to engineer systems with inductive biases for the right degree of systematicity.,We make use of the Natural language inference (NLI) task to study the question of systematicity.,neutral
1868,dev_1868,"There has been much interest in the problem of systematic generalization in recent years (Bahdanau et al., 2019; Bentivogli et al., 2016; Lake et al., 2017a,b; Gershman and Tenenbaum, 2015; McCoy et al., 2019a; Veldhoen and Zuidema, 2017; Soulos et al., 2019; Prasad et al., 2019; Richardson et al., 2019; Johnson et al., 2017, inter alia).",our analyses contain two ideas that may be useful for future studies of systematicity.,neutral
1869,dev_1869," Finally, Kim et al. (2019) explore pre-training schemes' abilities to learn prepositions and wh-words with syntactic transformations (two kinds of closedclass words which our work does not address).","our probes combine novel open-class words with familiar closed-class words, to test whether the closed-class words are treated systematically by the network.",neutral
1870,dev_1870,"Our implementation is based on the Transformer library (Wolf et al., 2019).","it fails to predict S1 as the supporting facts, while HGN succeeds, potentially due to the explicit connections between sentences in the constructed graph.",neutral
1871,dev_1871,"In each step estimating the Hessian-vector product, we took a batch of 8 training examples for stability.",we posit that influence functions may be a more suitable approach to interpreting models for such relatively complex natural language 'understanding' tasks (while simpler attribution methods like gradients may be sufficient for tasks like sentiment analysis).,neutral
1872,dev_1872,"While Koh and Liang (2017) show that influence functions can be a good approximation even when the convexity assumption is not satisfied (in their case, a CNN for image classification), it is still not obvious that the influence function would work for BERT.",McCoy et al. (2019) hypothesize that the main artifact NLI models might learn is lexical overlap.,neutral
1873,dev_1873,We see one potential problem out of the above method: it can only be applied to a certain group of examples and imply a general model behavior by examining the prediction imbalance.,"furthermore, we develop a new quantitative measure based on influence functions that can reveal artifacts in training data.",neutral
1874,dev_1874,"It is worth noting that influence functions are guaranteed to be accurate only when the model is strictly convex (i.e., its Hessian is positive definite and thus invertible) and is trained to convergence.","we are interested in the use of influence functions (Koh and Liang, 2017), which are in a sense inherently 'faithful' in that they reveal the training examples most responsible for particular predictions.",neutral
1875,dev_1875,All of the updated models still preserve the utility in recognizing the overt toxicity.,table 2 shows the performance of the models improved by each method.,neutral
1876,dev_1876,"The authors argue that the lack—or the overabundance—of context information prevents annotators from making a reliable assessment, which leads to noisy and uncertain annotations.",induced by our interpretation of the task.,neutral
1877,dev_1877,"Finally, if the input sentence is already in the target style, our model won't add any stylistic markers and thus would allow the input to flow as is.","mETEOR also uses synonyms and stemmed forms of the words in candidate and reference sentences, and thus may be better at quantifying semantic similarities.",neutral
1878,dev_1878,Our method has two variations: Intra-LADA and Inter-LADA.,data point would be augmented through Intra-LADA with a probability π and Inter-LADA with a probability 1 - π.,neutral
1879,dev_1879,"For Intra-LADA, as it broke the sentence structures, it cannot be applied to Flair that was based on LSTM-CRF.","in practice, we set the probability 0.3, and kept the settings for each kind of LADA the same.",neutral
1880,dev_1880,"Loss on the Development Set To illustrate that our LADA could also help the overfitting problem, we plotted the loss on the development set of BERT, BERT + Inter-LADA and BERT + Semi-Inter-LADA on CoNLL and GermEval training with 5% labeled data in Figure 3.",both contain one and only one entity (Hendrix) of the same type (Person).,neutral
1881,dev_1881,These techniques can help us obtain x' and x'' more efficiently,"at the pre-training stage, they are trained on a huge amount of unlabeled data in an unsupervised manner, e.g., T5 is pre-trained on 745 GB text.",neutral
1882,dev_1882,"As we discussed in Section 1 and 2, the output probability of a calibrated model should reflect the true likelihood.","For indistribution data, a well-calibrated model is expected to output prediction confidence comparable to its classification accuracy.",neutral
1883,dev_1883,"We instead rely on the observation that as we increase p in NS@p to make generation more diverse, the cardinality of N also goes up, on average, and so does the probability P (GT 2 N) that N contains the GT token.","entropy is an unbounded measure, and has a non-linear inverse growth relative to our proposed accuracy metric, which makes their mathematical combination difficult.",neutral
1884,dev_1884,"To improve performance at different data sizes we set the mini-batch size to 6K tokens for the 30K-sentence datasets, 12K tokens for 0.5Msentence datasets, and 24K for the remaining larger datasets (Popel and Bojar, 2018).","to the best of our knowledge, this problem has not yet been directly addressed in the NLG setting.",neutral
1885,dev_1885,"The scarcity of the training corpus is a common problem for many language pairs, which might lead to the NMT model's poor performance.","the evaluation metric is BLEU (Papineni et al., 2002).",neutral
1886,dev_1886,"We also tried visual features extracted with a neural object recognizer (Simonyan and Zisserman, 2014) which only give a small improvement over colour histograms.","in human cognition, world knowledge supports the perception of object colours: knowing that trees are typically green helps to perceive their colour in certain contexts.",neutral
1887,dev_1887,"For example, in a database of basketball game results, the predicate ""A wins"" is equivalent to ""scoreA > scoreB"" according to common sense.",we report the mean / std / max of these two statistics among 21 dev set submissions.,neutral
1888,dev_1888,"We focus on the queries from the 21 submissions that are considered incorrect by ESM but correct by our test suite evaluation, randomly sampled and manually examined 100 of them.","the current Spider metric leads to a 2.5% false negative rate on average and 8.1% in the worst case, indicating that test suite accuracy is needed.",neutral
1889,dev_1889,Hence a response can be acceptable to human annotators even if it does not align well with the reference either in terms of word-overlap or semantic embedding.,"to prior art, our means of evaluation captures not only the quality of generation, but also the diversity and logical consistency of responses.",neutral
1890,dev_1890,"Then, we feed the sentence with erroneous span annotations to a seq2seq model for ESC.","table 3: In-depth time cost (in second) analysis in CoNLL-14 which contains 1,312 test sentences.",neutral
1891,dev_1891,Same issue happens with the case of 1-to-N and N-to-1 predictions.,on WN18RR our results achieve the new state-of-the-art performance.,neutral
1892,dev_1892,"However, these knowledge graphs need to be updated with new facts periodically.","The hyper-parameters of our model are tuned by grid search during training process, including learning rate, embedding dimension d and sub-embedding dimension d s .",neutral
1893,dev_1893,"Distance-based knowledge graph embeddings have shown substantial improvement on the knowledge graph link prediction task, from TransE to the latest state-of-the-art RotatE.","we examine the proposed model in terms of the following aspects: Impact of sub-embedding dimension: we fix the embedding dimension as 400, and increasewe examine the proposed model in terms of the following aspects: Impact of sub-embedding dimension: we fix the embedding dimension as 400, and increase the subembedding dimension d s from 2 to 20, the MRR of OTE is improved from 0.327 to 0.355 (See Row 3 and Row 4).3 and Row 4).",neutral
1894,dev_1894,Our English-Spanish models show a similar behaviour to the one observed for the English-Italian pair.,"while the original XLM operates on streams of text, split by sentence separators, we split the stream of tweets, so that each example contains only one tweet.",neutral
1895,dev_1895,"Section 5 reports on the evaluation results, while Section 6 summarizes our findings.","since emojis are not always present in each tweet, we adopt a hybrid approach: when emojis are not present, the previously described MLM objective is trained.",neutral
1896,dev_1896,"Our quantization scheme was chosen to be uniform, meaning that the step size between two quantized values is constant.",we proposed a full quantization strategy for the Transformer architecture.,neutral
1897,dev_1897,"A few variations to this additive attention mechanism have been proposed, such as multiplicative and self-attention (Luong et al., 2015; Cheng et al., 2016; Lin et al., 2017).","numerical values can be represented using fewer bits (Tang and Kwan, 1993; Marchesi et al., 1993).",neutral
1898,dev_1898,"We consider a relation to be hierarchical when its corresponding graph is close to tree-like (low curvature, high Khs G ).","it provides an analogue through the lens of parallel transport: given two points x, y and a vector v in T c x , there is a unique vector in T c y which creates the same angle as v with the direction of the geodesic (shortest path) connecting x to y.",neutral
1899,dev_1899,"In Transformer-based models, the multi-head attention explores the relationships among tokens by calculating the token similarities in implicit feature spaces.","bertSUM: Road Home, Louisiana grant program for homeowners who lost their houses to hurricanes Katrina and Rita, is expected to cost far more than $7.5 billion provided by Federal Government, in part because many more families have applied than officials had anticipated.",neutral
1900,dev_1900,"In the next section, we describe the data sets we use for the experiments.","there are still a number of questions remaining about how well such models really work for real applications, and how much data is needed to achieve acceptable performance.",neutral
1901,dev_1901,"Wikipedia contents describing news media were useful for predicting the political bias and the factuality of these media (Baly et al., 2018a).","given the scale of the proliferation of false information online, it became clear that it was unfeasible to fact-check every single suspicious claim, even when this was done automatically, not only due to computational challenges but also due to timing.",neutral
1902,dev_1902,"As a few-shot natural language generation model, diversity is a very important indicator for quality evaluation.",b4 fails to transfer R4 into the movie domain.,neutral
1903,dev_1903,"Our method answers 56% of questions while maintaining 80% accuracy; in contrast, directly using the model's probabilities only answers 48% at 80% accuracy.","for each, we sampled 100 errors in which the system confidently gave a wrong answer (overconfident), and 100 errors in which the system abstained but would have gotten the question correct if it had answered (underconfident).",neutral
1904,dev_1904,"Figure 3a shows that MaxProb values are generally lower for OOD examples than in-domain examples, following previously reported trends (Hendrycks and Gimpel, 2017; Liang et al., 2018)","45% of underconfidence errors are due to the passage requiring coreference resolution over long distances, including with the article title.",neutral
1905,dev_1905,"Convolutional Encoder Inspired by the recent trend of replacing recurrent networks with CNNs (Dauphin et al., 2016; Yu et al., 2018a) and Transformers (Vaswani et al., 2017; Devlin et al., 2019) for sequence modeling, we use positional encoding (PE), CNNs, and layer normalization (Ba et al., 2016) to build our basic encoding block.",comprehensive ablation studies demonstrate how each of our annotations and model components helps to improve the performance of the tasks.,neutral
1906,dev_1906,"This model is pretrained on a large amount of image-text pairs from multiple image captioning (Lin et al., 2014; Krishna et al., 2017) and image question answering (Goyal et al., 2017; Hudson and Manning, 2019; Zhu et al., 2016a) datasets.","second, sTAGE computes attention scores from each QA word to object regions and subtitle words.",neutral
1907,dev_1907,"Temporal and Spatial Attention Attention has shown great success on many vision and language tasks, such as image captioning (Anderson et al., 2018;Xu et al., 2015), visual question answering (Anderson et al., 2018;Trott et al., 2018), language grounding (Yu et al., 2018b), etc.","it is also of reasonable size compared to the grounded video captioning dataset ANet-Entities (Zhou et al., 2019).",neutral
1908,dev_1908,The results presented in table 4 show that the most influential is decision whether to correct morphosyntactic annotation of a token or not.,"finally, in section 6. we discuss the preliminary interannotator agreement results of two phases of annotation calculated for a small fragment of the corpus that is already annotated by two linguists.",neutral
1909,dev_1909,"Typical MWEs may be compositional (e.g. dawka śmiertelna ‘deadly dose’ is a ‘dose’) or not (e.g. there is not a meaning for centrum ‘centre’ for centrum handlowe ‘shopping centre’, ‘mall’",this paper examines the procedure for lexico-semantic annotation of the Basic Corpus of Polish Metaphors that is the first step for annotating metaphoric expressions occurring in it.,neutral
1910,dev_1910,"Then, we segment word senses into four portions with a reasonable density (> 10% of the test set) and ensure that senses with the same number of training instances are in one segment.","when using word-specific classifiers, the sparseness of annotations leads to inferior sense disambiguation performance on less frequently seen words.",neutral
1911,dev_1911,"Following Kudugunta et al. (2019), we perform SVCCA on the encoder final outputs mean-pooled over timesteps, using a multiparallel evaluation set.","Default: max 2400 tokens/pair, 0.2 dropout.",neutral
1912,dev_1912,"Given a review sentence S, we first tokenize it using the WordPiece vocabulary (Wu et al., 2016) and add tokens [CLS] and [SEP] to the beginning and the end of the tokenized sentence, respectively.","besides, HAST+RD, IMN+RD and RINANTE+RD, which utilize the aspect and opinion term co-extraction models, achieve better performances than DE-CNN+RD.",neutral
1913,dev_1913,"For example, if 'overrated' is used to modify 'pizza', this relation could provide guidance to extract the aspect 'pizza' and the opinion expression 'overrated'.","then, the probability of the predicted sequence Y t can be calculated as follows: where Y t X denotes all possible label sequences.",neutral
1914,dev_1914,A common template about the general structure of user explanations is reflected from the parameter values.,"for this, crowdsourced workers on Amazon Mechanical Turk were asked to demonstrate how to complete these tasks and provide stepwise explanations to an AI assistant on how to complete the task.",neutral
1915,dev_1915,"Today's conversational assistants such as Alexa or Cortana act on a small number of preprogrammed language commands (e.g., ""What is the weather going to be like?"").",f1i = ? denotes that feature i was not relevant.,neutral
1916,dev_1916,We further demonstrate that using a diversity of prompts through ensembling further improves accuracy to 39.6%.,"while this paradigm has been used to achieve a number of intriguing results regarding the knowledge expressed by LMs, they usually rely on prompts that were manually created based on the intuition of the experimenter.",neutral
1917,dev_1917,"Previous work has approached generating coherent utterances in conversations through encouraging the model to learn similar distributed representations throughout the conversation (Baheti et al., 2018; Xu et al., 2018; Zhang et al., 2018a).","is phrased rather vaguely, the QA model is able to identify its correct answer from the paragraph The band released their third album, True, in March 1983, which offers new information (note the answer in the figure only reflects the actual human-human conversation, not this hypothetical one).",neutral
1918,dev_1918,"This corpus contains 5,800 sentences pairs from news sources on the web, human-annotated as either paraphrases or unrelated.","for each sentence pair, the sentence similarity models are used to estimate the similarity score between the second sentence of the pair and all available replacement sentences.",neutral
1919,dev_1919,"We generate a ground truth by randomly choosing sentence pairs from the SPAADIA and Switchboard corpus respectively, and annotate whether they share a dialogue act.",a valid replacement such as this one has to be chosen from a list of available sentences to successfully complete the sentence swapping task.,neutral
1920,dev_1920,"During deployment, none of the machine learning based approaches needs additional data.","in the following, a short overview of the chosen approaches as well as a discussion of their characteristics is given.",neutral
1921,dev_1921,They find that the ability to identify contextual paraphrases is of great importance to the overall performance of the approach.,"in our work, we include a greater number of sentence pairs in our understanding of paraphrases: two sentences are considered contextual paraphrases if they can fulfil the same function in the context of a conversation.",neutral
1922,dev_1922,This constitutes a substantial improvement from the majority class prediction of 0.5.,"in human-human interaction, we regularly express our intention with phrases that are vastly different regarding both word content and syntactic structure.",neutral
1923,dev_1923,Some pages also contained tags to indicate that.,"after the statement has been correctly translated, it can be checked using an automatic tool.",neutral
1924,dev_1924,These results highlight the importance of both functions of the first-round re-ranker.,"namely, queries are split into five equal-sized partitions.",neutral
1925,dev_1925,"As we mentioned in Section 3.1, we use an LSTM to store the historical path information.","besides, for every state s t , we also add an additional action (r LOOP , e t ), where LOOP is a manually added selfloop relation.",neutral
1926,dev_1926,"Based on this strategy, the dynamic completion strategy introduces some additional actions during the reasoning process to increase the number of paths, which can alleviate the sparsity of KGs.","the model using the DC strategy alone performs better than the model using the DA strategy alone, which is predictable, since the DA strategy only allows the agent to make a correct choice, and will not substantially alleviate the sparsity of KGs.",neutral
1927,dev_1927,The performance drops when we remove either one of them.,this means the ASR task is necessary for both the advanced courses and St.,neutral
1928,dev_1928,"Unless noted, we use N = 8 encoder blocks to perform the ASR and the FMLM pre-training tasks.",our method still outperforms the simple pre-training method by a large margin.,neutral
1929,dev_1929,"In this paper, we propose to use dice loss in replacement of the standard cross-entropy objective for data-imbalanced NLP tasks.","the number of tokens with tagging class O is 5 times as many as those with entity labels for the CoNLL03 dataset and 8 times for the OntoNotes5.0 dataset; Dataimbalanced issue is more severe for MRC tasks (Rajpurkar et al., 2016; Nguyen et al., 2016; Rajpurkar et al., 2018; Kocisky et al., 2018; Dasigi et al., 2019) with the value of negative-positive ratio being 50-200, which is due to the reason that the task of MRC is usually formalized as predicting the starting and ending indexes conditioned on the query and the context, and given a chunk of text of an arbitrary length, only two tokens are positive (or of interest) with all the rest being background.",neutral
1930,dev_1930,We hypothesize that this is because LEXSUB learns the lexical relations in a linear subspace which happens to be the simplest possible manifold.,this embedding layer is initialized with the embedding that is to be evaluated and is not fine-tuned during training.,neutral
1931,dev_1931,"However, recent studies (Ghaeini et al., 2018; Jain et al., 2019; Wiegreffe and Pinter, 2019) have questioned the validity of attention as a faithful explanation of model's behavior.","this is a commonly used measure for input attributions (Shrikumar et al., 2016; Selvaraju et al., 2019).",neutral
1932,dev_1932,This model uses the same sentence encoder as DirectSup but differs in the attention mechanism used to decide sentence importance.,there are 1950 bags and 6444 sentences.,neutral
1933,dev_1933,"We propose to use low-rank factorization as a less restrictive, yet powerful representation and obtain parameter reduction by pruning rank-1 components.",no factorization is used for this baseline.,neutral
1934,dev_1934,Previous sections illustrate the potential external supervision by assuming the existence of vokens.,"This low grounding ratio leads to low coverage of visual supervision in previous approaches (Frome et al., 2013; Kiela et al., 2018).",neutral
1935,dev_1935,"Using our proposed vokenizer with a contextualized token-image matching model, we generate vokens for English Wikipedia.","we introduce a ""revokenization"" technique to address this limitation.",neutral
1936,dev_1936, A KB in this form is often called a Knowledge Graph (KG) (Bollacker et al.) due to its graphical representation,"then, we use G and the image embedding, feed them to the vision-language module, and send its output to a classifier and check the answer.",neutral
1937,dev_1937,It creates a joint representation in a single space of the three different embedding spaces.,"this module alone is not able to answer questions that require insights that are neither in the image, nor in the question.",neutral
1938,dev_1938,Danescu-Niculescu-Mizil et al. (2013) utilizes requests annotated for politeness to create a framework specifically to relate politeness and social power.,"the annotation scheme underwent five revisions, each time with three different conversations, eventually yielding a high Cohen's Kappa score of 0.85 across all face acts (Cohen, 1960).",neutral
1939,dev_1939,"As can be seen, our models outperform strong comparison systems on both DUC test sets: QUERYSUM S achieves the best R-1 while QUERY-SUM P achieves the best R-2 and R-SU4.","to previous work, our proposal does not simultaneously perform segment selection and query matching.",neutral
1940,dev_1940,"Generally, we observed that the models were close to 30-40% in all categories meaning that they were sufficiently similar to the ground truth distribution of data (the neutral options were chosen more frequently).","Note that h, l, and a define the sizes of the encoder and decoder transformers individually.",neutral
1941,dev_1941,"For every goal configuration c derived by LTF or LTL, the AM dependency tree described by c is well-typed.",we also consider a transition system in which the lexical type is chosen after deciding on the outgoing edges.,neutral
1942,dev_1942,We have made our code publicly available to facilitate future research.,"Among other noteworthy works, API usage information (Hu et al., 2018b), reinforcement learning (Wan et al., 2018), dual learning (Wei et al., 2019), retrieval-based techniques (Zhang et al., 2020) are leveraged to further enhance the code summarization models.",neutral
1943,dev_1943,"In this work, we study an alternative of the relative position representations that ignores the directional information (Ahmad et al., 2019).","In our experiments, we observe that a deeper model (more layers) performs better than a wider model (larger d model).",neutral
1944,dev_1944,Our focus in this paper is on the problem of extracting and interpreting content of tables characteristic to machine learning papers.,this interface allows annotators on Papers with Code to take a paper and label it with results tuples.,neutral
1945,dev_1945,Table D.7: Average number of pre-terminal groups and their generating non-terminals.,"we consider if the induced grammars reflect the correct word classes defined by the preterminals, and if they capture the simple hierarchy defined on top of these word-classes.",neutral
1946,dev_1946,The dataset serves as the empirical basis for the lexicographic work on extending the Wortprofil and for the enrichment of GermaNet with new lexical relations.,"we use a feed-forward neural network with one hidden layer of size 4 (hidden layer size was tuned on validation, see Appendix B) and a ReLU non-linearity and apply early stopping.",neutral
1947,dev_1947,The selected preceding or succeeding ACC can neither overlap with a previously heuristically labeled ACC nor occur in a different sentence than the discourse marker that triggered its labeling.,major claims often follow the phrases in the first row of the major claim column.,neutral
1948,dev_1948,They improved generalisation of the relation models by mapping context onto vector spaces.,"a collection of 18,386 texts in total was selected for the annotation process.",neutral
1949,dev_1949,"They are all EP monolinguals, aged 3;2 to 11,05.","these generalizations often come with partially or completely untested assumptions about the irrelevance of potential noise in the data, the nature of which may influence results in ways which remain elusive to the researcher.",neutral
1950,dev_1950,"As an essential task in task-oriented dialog systems, slot filling requires extensive training data in a certain domain.","the Ct framework suffers from the difficulty of capturing the whole slot entity, while our framework is able to recognize the slot entity tokens by sharing its parameters across all slot types.",neutral
1951,dev_1951,"It utilizes the hierarchical relationship among query type, mention type and query intent to obtain the final intent, which is illustrated in Figure 4(a).",the loss function L mt is set to the cross entropy on {S mt i }.,neutral
1952,dev_1952,The two auxiliary tasks can also help to improve the entity linking task.,there are no existing studies about intent detection on spatial domain queries.,neutral
1953,dev_1953,"""Select"" means our unsupervised self-training method with grammaticality judgment model.",most previous disfluency detection work focuses on detecting reparandums.,neutral
1954,dev_1954,It makes easy to validate the annotation and analyze system errors.,it is easy to find entailment pairs from the corpus.,neutral
1955,dev_1955,Their method is simple but powerful.,false entailment examples may exist.,neutral
1956,dev_1956,Replacing nothing (nada) with anything (algo) is incorrect in Spanish.,a qualitative error analysis has shown that the methods applied are not optimal.,neutral
1957,dev_1957,We are able to automatically tag large sets of users according to their stance of preset topics.,"solely using the retweeted accounts as features has been shown to be effective for stance classification (Darwish et al., 2020;Magdy et al., 2016a).",neutral
1958,dev_1958,"In Section 5, we provide instructions for how programmers can extend our PYTHON package to include new corpora from TOOLBOX files or from the more than 130 corpora encoded in CHILDES CHAT, which are openly available in TalkBank.","in this paper, we have given an overview of the ACQDiV corpus database and aggregation pipeline, which is available as a PYTHON package via PYPi.",neutral
1959,dev_1959,"MOCHA contains human judgement scores on 40K candidates, an order of magnitude larger than prior work  (Chen et al., 2019). ",lERC assigns a score that better reflects human judgement.,neutral
1960,dev_1960,"In our work, we use toxicity classification as one example to detect local group bias in texts and show that such local group bias could be caused by different topics in the texts.","to analyze and detect such local bias, we propose LOGAN, a new bias detection technique based on clustering.",neutral
1961,dev_1961,Machine learning techniques have been widely used in natural language processing (NLP).,"Other applications such as cross-lingual transfer learning (Zhao et al., 2020) and natural language generation (Sheng et al., 2019) also exhibit unintended biases.",neutral
1962,dev_1962,"For example, utterances belong to Wh-style Interrogative and Yes-no Interrogative may share some transferable word patterns while word patterns in Wh-style Interrogative and Exclamatory with interjections are totally different.","moreover, since mTL never sees responses in target sentence functions in training, the generated responses are not coherent with the given sentence function at all.",neutral
1963,dev_1963,Here is how we apply MAML to response generation on infrequent sentence functions.,similar sentence functions trigger similar initializations and dissimilar sentence functions trigger different ones.,neutral
1964,dev_1964,Figure 1 presents how sentence functions influence the responses.,"the meta-learned model is not necessarily a good model on its own, but it adapts fast on any new task with a few gradient update steps.",neutral
1965,dev_1965,The UD project requires each language to share their annotation specification with other treebanks of same language to increase consistency and parallelism.,three phrase structure parsers are available.,neutral
1966,dev_1966,This is followed by a feed forward layer (g) and a dense layer to finally assign probabilities to each position (p) in the input utterance.,we overcome this by providing global supervision.,neutral
1967,dev_1967,The time allotted for each task was 20 minutes and only a single submission per Turker was allowed.,"after a preliminary investigation, we argue that this gap is acceptable.",neutral
1968,dev_1968,"Prior work has combined these three scores into a single number using geometric averaging (Xu et al., 2018) or learned weights (Pang and Gimpel, 2019).","Attribute transfer has been criticized for its limited real-world applications: Pang (2019) argue that semantic preservation is critical for author obfuscation (Shetty et al., 2018), data augmentation (Xie et al., 2019;Kaushik et al., 2020), text simplification (Xu et al., 2015), writing assistance (Heidorn, 2000).",neutral
1969,dev_1969,We extend the result in Theorem 3 as follows.,we explore which languages can be decided by different encoder-decoder pairings.,neutral
1970,dev_1970,"If x starts with a, then we accept iff there exists a sequence of bs following the prefix of as such that both sequences have the same length.",see Appendix A for further discussion of this.,neutral
1971,dev_1971,"Then, we calculate the embedding vector of the k-th r-NE as the average of the vectors of the words consisting that r-NE: R = (r1, r2, . . . , rk, . . . , rK).",a node of type F has a tendency to be linked to bounding boxes for unprocessed ingredients (see Figure 2).,neutral
1972,dev_1972,A recipe describes instructions for a dish.,we assume that each step in the recipes of our dataset has an image.,neutral
1973,dev_1973,"Given a procedural text with its image sequence and flow graph, annotators put a bounding box of an object in an image, which is linked to a node of the flow graph.",sequential bounding boxes and a flow graph will be useful for multimodal state tracking.,neutral
1974,dev_1974,"This is perfectly understandable given the complexity of such a reproduction, in particular in the multitask learning setting of end-to-end RE and often without (documented) source code.",we also use negative sampling by randomly selecting 100 negative spans during training.,neutral
1975,dev_1975,This allows us to better model interactions between arguments and triggers.,"next, we use that model to tag unlabeled data and get a much larger but noisy silver dataset (Sec. 3).",neutral
1976,dev_1976,"In terms of modeling, their approaches used regular BERT as their encoders, where the argument representations are not explicitly conditioned on triggers.",(2) Our model does not achieve the highest scores on AI.,neutral
1977,dev_1977,It is reasonable to expect that better performing language models for individual people will result in better performing systems for these downstream tasks for individual people.,"the interpolated probability for that type would be (p+0)/2, where p is the probability from the language model that contains that type.",neutral
1978,dev_1978,"Classification of the 3-class directness results in an UAR of 56 %, and the binary directness reaches an UAR of 75 %.","for the classification of the elaborateness, the SVM classifier performs comparable to the ANN classifier.",neutral
1979,dev_1979,Self-attention sub-layer The attention mechanism can be formulated as querying a dictionary with key-value pairs.,the performance is evaluated by the accuracy.,neutral
1980,dev_1980,"For pre-training, we use the same data as BERT, which consists of 3.3 Billion tokens from Wikipedia and BooksCorpus (Zhu et al., 2015).",this also indicates that splitting the pruning for attention heads could have more flexibility for the model to find an optimal architecture.,neutral
1981,dev_1981,Fan et al. (2020) applies random pruning to the entire layers.,the left column shows the percentage of pruned parameters.,neutral
1982,dev_1982,"However, individuals are less adherent to these norms as they perceive themselves to be anonymous or when interacting with an individual whom they perceive they will not interact with again (Rubin, 1983; Wynne and Wynne, 1986; Dindia et al., 1997); without the potential loss of face or social capital in such circumstances, individuals are more likely to engage in more intimate communication.","the authors conducted several rounds of pilot annotation trials among seven annotators, prior to beginning annotation for the current study's data.",neutral
1983,dev_1983,"Individuals in these encounters have little likelihood of future interactions, removing the consequences for violating intimacy norms around increased disclosure (Thibaut, 2017; Wynne and Wynne, 1986).",our models would allow tracking intimacy changes to separate offensive questions from those in conversations that gradually become more intimate.,neutral
1984,dev_1984,"Finally, in order to process long sequences, Xie et al. (2019) and Joshi et al. (2019) investigate simple approaches of truncating or partitioning them into smaller sequences, e.g., to fit within 512 token limit of BERT for classification; However, such partitioning leads to a loss of discriminative cross-partition information and is still computationally inefficient",table 4 shows data statistics of 5 datasets used in complementary + finetuning evaluation of our proposed topicBERt model via Document Classification task.,neutral
1985,dev_1985,"When using only mBERT with S2T alignments we have high recall but a very mediocre precision; when using INTER alignments we see big gains in precision at the expense of lower recall, as expected.","this highlights the main advantages of our method: by relying on a big multilingual language model i) we obtain high-quality word alignments featuring high precision and recall, and ii) we do not need to re-train for other language pairs nor different domains.",neutral
1986,dev_1986,They also examine the effect of decreasing the size of the dataset.,we trained two pipeline models (pipe-ind and pipeseq) which only differ in their training procedure (see Section 3.2.2).,neutral
1987,dev_1987,Recent work showed that these models can be improved if transcriptions are available at training time.,"even though the model works on ground-truth text (no translation involved), we still see a 4% drop in R@10 between the reduced english condition and Japanese.",neutral
1988,dev_1988,"The architecture (summarized in Figure 2c) is basically composed of an ASR module which maps speech to text, followed by the text-image system we just described (our NLU component).",it is not clear how an end-to-end approach compares to a traditional pipeline-based approach when one has access to transcriptions.,neutral
1989,dev_1989,"Formally, assume that we have an input sequence of w0, w1, . . . , wn−1, and we generate their corrupted positions p0, p1, . . . , pn−1 with our local bag strategy.","it may suffer from the same problem as unidirectional LMs: at one time, contexts from only one direction can be utilized instead of from both directions.",neutral
1990,dev_1990,"If stored using the same precision, the optimizer memory should be three times of model memory.","to validate our claim that BlockBERt with n Ã¢â€¡Â¥ n blocks can reduce the O(N 2 ) memory usage by a factor of n, we perform the same memory profiling as described in sections 2.1 and 2.2.",neutral
1991,dev_1991,Training BERT is a memory-intensive process.,"when n = 2, we denote 10:2 to be the configuration which assigns 10 heads to permutation (1, 2) and 2 to permutation (2, 1); when n = 3, we denote 8:2:2 to be the configuration which assigns 8, 2, 2 heads to permutation (1, 2, 3), (2, 3, 1), and (3, 1, 2), respectively.",neutral
1992,dev_1992,"Based on the phoneme embeddings of a word, we apply the attention mechanism (Bahdanau et al., 2015) to simultaneously identify important phonemes and derive the pronunciation embedding T P i .","to resolve the issues of sparseness and heterographics, the word embedding techniques (Mikolov et al., 2013; Pennington et al., 2014) provide flexible representations to model puns (Hurtado et al., 2017; Indurthi and Oota, 2017; Cai et al., 2018).",neutral
1993,dev_1993,"To detect the pun, Pedersen (2017) supposes that if there is one pun in the sentence, when adopting different Word Sense Disambiguation (WSD) methods, the sense assigned to the sentence will be different.",static word embeddings are insufficient to represent words.,neutral
1994,dev_1994,We run experiments on one Tesla V100 16GB GPU and each epoch takes several minutes.,"human annotation of aspectlevel sentiment is laborious and expensive, therefore, some researches focus on weakly supervised DMSC.",neutral
1995,dev_1995,"This can be manually annotated in at least 7,5 days, but thanks to the automatic annotation accuracy, it was manually corrected into 3 days.","at the present stage of research, TarC consists of 25.000 tokens, however our work is in progress and for future research we plan to enforce the semi-automatic transcription, which has already shown encouraging results (accuracy = 70%).",neutral
1996,dev_1996,"CODA TUN proposes to keep the MSA rule of maintaining a space between the first negation mark and the verb, in order to uniform CODA TUN to the first CODA (Habash et al., 2012).","first of all, the resource will be useful to give an overview of the TA.",neutral
1997,dev_1997,"Since there is a one-to-one mapping between Text Plot Specifications (TPSpecs) and plot images, we only need to generate TPSpecs.","the system is in charge of all plotting details, which are not accessible to users.",neutral
1998,dev_1998,"First proposed by Shen et al. (2017b), it has achieved great progress in recent years (Xu et al., 2018; Lample et al., 2019; Zhang et al., 2018b; Fu et al., 2018; Jin et al., 2019; Yang et al., 2018; Jin et al., 2020).","we present a novel headline generation model, TitleStylist, to produce enticing titles with target styles including humorous, romantic, and click-baity.",neutral
1999,dev_1999,"Many recent works extended ABS by utilizing additional features (Chopra et al., 2016;Takase et al., 2016;Nallapati et al., 2016;Shen et al., 2016Shen et al., , 2017aTan et al., 2017;Guo et al., 2017).","without samples from P (A, T ), this is a challenging or even impossible task if E S and E T , or G S and G T are completely independent of each other.",neutral
