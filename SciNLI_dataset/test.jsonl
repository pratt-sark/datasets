{"id": "test_0", "sentence1": "On one hand, assuming that the parallel sentences have the same meaning, many datasets find the aligned sentences to have higher string overlap (as measured by BLEU).", "sentence2": "the two sentences should have different styles, and may vary a lot in expressions: and thus leading to a lower BLEU.", "label": "contrasting"}
{"id": "test_1", "sentence1": "Recent solutions (Gidaris and Komodakis, 2018) leverage a memory component to maintain models' learning experience, e.g., by finding from a supervised stage the content that is similar to the unseen classes, leading to the state-of-the-art performance.", "sentence2": "the memory weights are static during inference and the capability of the model is still limited when adapted to new classes.", "label": "contrasting"}
{"id": "test_2", "sentence1": "A larger KES leads to predict more unique keyphrases, append less absolutely incorrect keyphrases and improve the chance to output more accurate keyphrases.", "sentence2": "generating more unique keyphrases may also lead to more incorrect predictions, which will degrade the F 1 @M scores since F 1 @M considers all the unique predictions without a fixed cutoff.", "label": "contrasting"}
{"id": "test_3", "sentence1": "For instance, all the baselines produce the keyphrase \"debugging\" at least three times.", "sentence2": "our ExHiRD-h only generates it once, which demonstrates that our proposed method is more powerful in avoiding duplicated keyphrases.", "label": "contrasting"}
{"id": "test_4", "sentence1": "Those models mainly focus on improving decoders based on the constraint of hierarchical paths.", "sentence2": "we propose an effective hierarchy-aware global model, HiAGM, that extracts label-wise text features with hierarchy encoders based on prior hierarchy information.", "label": "contrasting"}
{"id": "test_5", "sentence1": "Previous global models classify labels upon the original textual information and improve the decoder with predefined hierarchy paths.", "sentence2": "we construct a novel end-to-end hierarchy-aware global model (HiAGM) for the mutual interaction of text features and label correlations.", "label": "contrasting"}
{"id": "test_6", "sentence1": "As for the amount of operators' effort, we observed a slight decrease in HTER with the increase of pre-filtering conditions, indicating an improvement in the quality of candidates.", "sentence2": "hTER scores were all between 0.1 and 0.2, much below the 0.4 acceptability threshold defined by Turchi et al.", "label": "contrasting"}
{"id": "test_7", "sentence1": "Finally, we observe that despite reducing the ouput diversity and novelty, the reduction of expert effort by Reviewer\u22652 in terms of the percentage of the obtained pairs is not attainable by a machine yet.", "sentence2": "automatic filtering (Reviewer machine ) is a viable solution since (i) it helps the NGO operators save time better than human filter \u22651, (ii) it preserves diversity and novelty better than Reviewer\u22652 and in line with Reviewer\u22651 .", "label": "contrasting"}
{"id": "test_8", "sentence1": "In this scenario, automation strategies, such as natural language generation, are necessary to help NGO operators in their countering effort.", "sentence2": "these automation approaches are not mature yet, since they suffer from the lack of sufficient amount of quality data and tend to produce generic/repetitive responses.", "label": "contrasting"}
{"id": "test_9", "sentence1": "However, gold data for the target language (stage) is usually inaccessible, often preventing evaluation against human judgment.", "sentence2": "we here propose several alternative evaluation set-ups as an integral part of our methodology.", "label": "contrasting"}
{"id": "test_10", "sentence1": "Words, such as German Sonnenschein for which a translational equivalent already exists in the Source (\"sunshine\"; see Figure 1), mainly rely on translation, while the prediction step acts as an optional refinement procedure.", "sentence2": "the prediction step is crucial for words, such as Erdbeben, whose translational equivalents (\"earthquake\") are missing in the Source.", "label": "contrasting"}
{"id": "test_11", "sentence1": "We want to point out that not every single entry should be considered meaningful because of noise in the embedding vocabulary caused by typos and tokenization errors.", "sentence2": "choosing the \"best\" size for an emotion lexicon necessarily translates into a quality-coverage trade-off for which there is no general solution.", "label": "contrasting"}
{"id": "test_12", "sentence1": "Neural MT (NMT) approaches have certainly made significant progress in this direction.", "sentence2": "the diversity of possible outcomes makes it harder to evaluate MT models.", "label": "contrasting"}
{"id": "test_13", "sentence1": "Dreyer and Marcu (2012) showed that if multiple human translations are used, any automatic MT evaluation metric achieves a substantially higher correlation with human judgments.", "sentence2": "multiple translations are hardly ever available in practice due to the cost of collecting them.", "label": "contrasting"}
{"id": "test_14", "sentence1": "The distinction between intended and perceived sarcasm, also referred to as encoded and decoded sarcasm, respectively, has been pointed out in previous research (Kaufer, 1981;Rockwell and Theriot, 2001).", "sentence2": "it has not been considered in a computational context thus far when building datasets for textual sarcasm detection.", "label": "contrasting"}
{"id": "test_15", "sentence1": "Text summarization has recently received increased attention with the rise of deep learning-based endto-end models, both for extractive and abstractive variants.", "sentence2": "so far, only single-document summarization has profited from this trend.", "label": "contrasting"}
{"id": "test_16", "sentence1": "Apparently, a summarization method is desirable to achieve a ROUGE score of 100, i.e., a system output is identical to the reference.", "sentence2": "this is an unrealistic goal for the task setting on the Gigaword dataset.", "label": "contrasting"}
{"id": "test_17", "sentence1": "They addressed the problem where an abstractive model made mistakes in facts (e.g., tuples of subjects, predicates, and objects).", "sentence2": "we also regularly see examples where the abstractive model generates unexpected words.", "label": "contrasting"}
{"id": "test_18", "sentence1": "For JNC, we use the pretrained BERT model for Japanese text (Kikuta, 2019).", "sentence2": "no large-scale Japanese corpus for semantic inference (counterpart to MultiNLI) is available.", "label": "contrasting"}
{"id": "test_19", "sentence1": "We could confirm the improvements from the support scores, entailment ratio, and human judgments.", "sentence2": "the ROUGE scores between system and reference headlines did not indicate a clear difference.", "label": "contrasting"}
{"id": "test_20", "sentence1": "Likert-score based self-reported user rating is widely adopted by social conversational systems, such as Amazon Alexa Prize chatbots.", "sentence2": "selfreported user rating suffers from bias and variance among different users.", "label": "contrasting"}
{"id": "test_21", "sentence1": "ELMo (Peters et al., 2018), BERT (Devlin et al., 2019), and XLNet (Yang et al., 2019) have achieved great success in many NLP tasks.", "sentence2": "it is difficult to apply them in the industrial dialog system due to their low computational efficiency.", "label": "contrasting"}
{"id": "test_22", "sentence1": "Previous work has demonstrated that neural encoders capture a rich hierarchy of syntactic and semantic information (Jawahar et al., 2019;Clark et al., 2019).", "sentence2": "reasoning capability and commonsense knowledge are not captured sufficiently (Young et al., 2018).", "label": "contrasting"}
{"id": "test_23", "sentence1": "BERT-MC and RoBERTa-MC obtain similar results with BERT and RoBERTa, respectively.", "sentence2": "even RoBERTa is far behind human performance 23 points on R@1, indicating that MuTual is indeed a challenging dataset, which opens the door for tackling new and complex reasoning problems in multi-turn conversations.", "label": "contrasting"}
{"id": "test_24", "sentence1": "The language score is evaluated individually, without considering the discourse coherence.", "sentence2": "a reasonable response should establish links in meaning with context, which is also an important aspect of humanlike responses.", "label": "contrasting"}
{"id": "test_25", "sentence1": "In practice, the solver can always find a solution to linearize the subtrees with the constraints.", "sentence2": "it sometimes cannot find any solution to directly linearize the full tree within the time limit (1-10% of the cases depending on the treebank), because there are more nodes and more constraints in the full tree.", "label": "contrasting"}
{"id": "test_26", "sentence1": "However, these approaches only consider sentence-level QG.", "sentence2": "our work focus on the challenge of generating deep questions with multi-hop reasoning over document-level contexts.", "label": "contrasting"}
{"id": "test_27", "sentence1": "Among them, \"Semantic Error\", \"Redundant\", and \"Unanswerable\" are noticeable errors for all models.", "sentence2": "we find that baselines have more unreasonable subject-predicate-object collocations (semantic errors) than our model.", "label": "contrasting"}
{"id": "test_28", "sentence1": "Extracting relational triples from unstructured text is crucial for large-scale knowledge graph construction.", "sentence2": "few existing works excel in solving the overlapping triple problem where multiple relational triples in the same sentence share the same entities.", "label": "contrasting"}
{"id": "test_29", "sentence1": "To reduce manual work, recent studies have investigated neural network-based methods, which deliver state-of-the-art performance.", "sentence2": "most existing neural models like (Miwa and Bansal, 2016) achieve joint learning of entities and relations only through parameter sharing but not joint decoding.", "label": "contrasting"}
{"id": "test_30", "sentence1": "Therefore, the object tagger for relation \"Work in\" will not identify the span of \"Washington\", i.e., the output of both start and end position are all zeros as shown in Figure 2.", "sentence2": "the relation \"Birth place\" holds between \"Jackie R. Brown\" and \"Washington\", so the corresponding object tagger outputs the span of the candidate object \"Washington\".", "label": "contrasting"}
{"id": "test_31", "sentence1": "Such inconsistent data distribution of two datasets leads to a comparatively better performance on NYT and a worse performance on WebNLG for all the baselines, exposing their drawbacks in extracting overlapping relational triples.", "sentence2": "the CASREL model and its variants (i.e., CASREL random and CAS-REL LST M ) all achieve a stable and competitive performance on both NYT and WebNLG datasets, demonstrating the effectiveness of the proposed framework in solving the overlapping problem.", "label": "contrasting"}
{"id": "test_32", "sentence1": "In other words, it implies that identifying relations is somehow easier than identifying entities for our model.", "sentence2": "to NYT, for WebNLG, the performance gap between (E1, E2) and (E1, R, E2) is comparatively larger than that between (E1, R, E2) and (E1, R)/(R, E2).", "label": "contrasting"}
{"id": "test_33", "sentence1": "We also find that there is only a trivial gap between the F1-score on (E1, E2) and (E1, R, E2), but an obvious gap between (E1, R, E2) and (E1, R)/(R, E2).", "sentence2": "it reveals that most relations for the entity pairs in extracted triples are correctly identified while some extracted entities fail to form a valid relational triple", "label": "contrasting"}
{"id": "test_34", "sentence1": "Information Extraction (IE), and specifically Relation Extraction (RE), can improve the access to central information for downstream tasks (Santos et al., 2015;Zeng et al., 2014;Jiang et al., 2016;Miwa and Bansal, 2016;Luan et al., 2018a).", "sentence2": "the focus of current RE systems and datasets is either too narrow, i.e., a handful of semantic relations, such as 'USED-FOR' and 'SYNONYMY', or too broad, i.e., an unbounded number of generic relations extracted from large, heterogeneous corpora (Niklaus et al., 2018), referred to as Open IE (OIE) (Etzioni et al., 2005;Banko et al., 2007).", "label": "contrasting"}
{"id": "test_35", "sentence1": "It has been shown that scientific texts contain many unique relation types and, therefore, it is not feasible to create separate narrow IE classifiers for these (Groth et al., 2018).", "sentence2": "oIE systems are primarily developed for the Web and news-wire domain and have been shown to perform poorly on scientific texts.", "label": "contrasting"}
{"id": "test_36", "sentence1": "Lei et al. (2017) conduct word pair interaction score to capture both linear and quadratic relation for argument representation.", "sentence2": "these methods utilize the pre-trained embeddings for mining the interaction features and ignore the geometric structure information entailed in discourse arguments and their relation.", "label": "contrasting"}
{"id": "test_37", "sentence1": "Xu et al. (2019) propose a topic tensor network (TTN) to model the sentence-level interactions and topic-level rel\u0002evance among arguments for this task.", "sentence2": "few studies model discourse relations by translating them in the low-dimensional embedding space as we do in this work.", "label": "contrasting"}
{"id": "test_38", "sentence1": "With the increasing of the number of encoder layers, the model could capture the richer semantic information.", "sentence2": "the results imply that with the more encoder layers considered, the model could incur the over-fitting problem due to adding more parameters.", "label": "contrasting"}
{"id": "test_39", "sentence1": "Based on BLEU (Papineni et al., 2002) scores, previous work (Belinkov et al., 2017) suggests that translating into morphologically rich languages, such as Hungarian or Finnish, is harder than translating into morphologically poor ones, such as English.", "sentence2": "a major obstacle in the crosslingual comparison of MT systems is that many automatic evaluation metrics, including BLEU and METEOR (Banerjee and Lavie, 2005), are not cross-lingually comparable.", "label": "contrasting"}
{"id": "test_40", "sentence1": "Reliable reference-free evaluation metrics, directly measuring the (semantic) correspondence between the source language text and system translation, would remove the need for human references and allow for unlimited MT evaluations: any monolingual corpus could be used for evaluating MT systems.", "sentence2": "the proposals of referencefree MT evaluation metrics have been few and far apart and have required either non-negligible supervision (i.e., human translation quality labels) (Specia et al., 2010) or language-specific preprocessing like semantic parsing (Lo et al., 2014;Lo, 2019), both hindering the wide applicability of the proposed metrics.", "label": "contrasting"}
{"id": "test_41", "sentence1": "Position encoding (PE), an essential part of self-attention networks (SANs), is used to preserve the word order information for natural language processing tasks, generating fixed position indices for input sequences.", "sentence2": "in cross-lingual scenarios, e.g., machine translation, the PEs of source and target sentences are modeled independently.", "label": "contrasting"}
{"id": "test_42", "sentence1": "The filtering step as performed by Grave et al. (2018) consisted in only keeping the lines exceeding 100  bytes in length.", "sentence2": "considering that Common Crawl is a mutilingual UTF-8 encoded corpus, this 100-byte threshold creates a huge disparity between ASCII and non-ASCII encoded languages.", "label": "contrasting"}
{"id": "test_43", "sentence1": "Considering the discussion above, we believe an interesting follow-up to our experiments would be training the ELMo models for more of the languages included in the OSCAR corpus.", "sentence2": "training ELMo is computationally costly, and one way to estimate this cost, as pointed out by Strubell et al. (2019), is by using the training times of each model to compute both power consumption and CO2 emissions.", "label": "contrasting"}
{"id": "test_44", "sentence1": "Even though it would have been interesting to replicate all our experiments and computational cost estimations with state-of-the-art fine-tuning models such as BERT, XLNet, RoBERTa or AL-BERT, we recall that these transformer-based architectures are extremely costly to train, as noted by the BERT authors on the official BERT GitHub repository, 21 and are currently beyond the scope of our computational infrastructure.", "sentence2": "we believe that ELMo contextualized word embeddings remain a useful model that still provide an extremely good trade-off between performance to training cost, even setting new state-of-the-art scores in parsing and POS tagging for our five chosen languages, performing even better than the multilingual mBERT model.", "label": "contrasting"}
{"id": "test_45", "sentence1": "All neural models achieve a SG score significantly greater than a random baseline (dashed line).", "sentence2": "the range within neural models is notable, with the bestperforming model (GPT-2-XL) scoring over twice as high as the worst-performing model (LSTM).", "label": "contrasting"}
{"id": "test_46", "sentence1": "The TTG ap-proach cannot make use at run-time of an En QE model without translating the caption back to English and thus again requiring perfect translation in order not to ruin the predicted quality score.", "sentence2": "the PLuGS approach appears to be best suited for leveraging an existing En QE model, due to the availability of the generated bilingual output that tends to maintain consistency between the generated EN-& X-language outputs, with respect to accuracy; therefore, directly applying an English QE model appears to be the most appropriate scalable solution.", "label": "contrasting"}
{"id": "test_47", "sentence1": "They read one sentence at a time and provided a suspense judgement using the fivepoint scale consisting of Big Decrease in suspense (1% of the cases), Decrease (11%), Same (50%), Increase (31%), and Big Increase (7%).", "sentence2": "to prior work (Delatorre et al., 2018), a relative rather than absolute scale was used.", "label": "contrasting"}
{"id": "test_48", "sentence1": "One of our main hypotheses is that modeling edit sequences is better suited for this task than generating comments from scratch.", "sentence2": "a counter argument could be that a comment generation model could be trained from substantially more data, since it is much easier to obtain parallel data in the form (method, comment), without the constraints of simultaneous code/comment edits.", "label": "contrasting"}
{"id": "test_49", "sentence1": "Most of these approaches focus on code summarization or comment generation which only require single code-NL pairs for training and evaluation as the task entails generating a natural language summary of a given code snippet.", "sentence2": "our proposed task requires two code-NL pairs that are assumed to hold specific parallel relationships with one another.", "label": "contrasting"}
{"id": "test_50", "sentence1": "FACTEDITOR has a larger number of correct editing (CQT) than ENCDECEDITOR for fact-based text editing.", "sentence2": "eNCDeCeDITOR often includes a larger number of unnecessary rephrasings (UPARA) than FACTeDITOR.", "label": "contrasting"}
{"id": "test_51", "sentence1": "ENCDECEDITOR often generates the same facts multiple times (RPT) or facts in different relations (DREL).", "sentence2": "fACTE-DITOR can seldomly make such errors.", "label": "contrasting"}
{"id": "test_52", "sentence1": "ENCDECEDITOR cannot effectively eliminate the description about an unsupported fact (in orange) appearing in the draft text.", "sentence2": "fACTEDI-TOR can deal with the problem well.", "label": "contrasting"}
{"id": "test_53", "sentence1": "Gehrmann et al. (2018) utilized a data-efficient content selector, by aligning source and target, to restrict the model\u2019s attention to likely-to-copy phrases.", "sentence2": "we use the content selector to find domain knowledge alignment between source and target.", "label": "contrasting"}
{"id": "test_54", "sentence1": "Such data-driven approaches achieve good performance on several benchmarks like E2E challenge (Novikova et al., 2017), WebNLG challenge (Gardent et al., 2017) and WIKIBIO (Lebret et al., 2016).", "sentence2": "they rely on massive amount of training data.", "label": "contrasting"}
{"id": "test_55", "sentence1": "Ma et al. (2019) propose low-resource table-to-text generation with 1,000 paired examples and large-scale target-side examples.", "sentence2": "in our setting, only tens to hundreds of paired training examples are required, meanwhile without the need for any target examples.", "label": "contrasting"}
{"id": "test_56", "sentence1": "This spillover is potentially sensitive only to Levenshtein distance.", "sentence2": "confusability is sensitive to fine-grained perceptual structure.", "label": "contrasting"}
{"id": "test_57", "sentence1": "For this case, IG, IC, and subjectivity all have overlapping confidence intervals, so we conclude that there is no evidence that one is better than the other.", "sentence2": "we do have evidence that IG and IC are more accurate than PMI when estimated based on clusters.", "label": "contrasting"}
{"id": "test_58", "sentence1": "The idea of adding the NOTA option to a candidate set is also widely used in other language technology fields like speaker verification (Pathak and Raj, 2013).", "sentence2": "the effect of adding NOTA is rarely introduced in dialog retrieval research problems.", "label": "contrasting"}
{"id": "test_59", "sentence1": "D-GPT gets the wrong answer 18% of the time (option a and c), because the input answer predicted by the CoQA baseline is also incorrect 17% of the time.", "sentence2": "with oracle answers, it is able to generate correct responses 77% of the times (option e).", "label": "contrasting"}
{"id": "test_60", "sentence1": "Question Answering Using crowd-sourcing methods to create QA datasets (Rajpurkar et al., 2016;Bajaj et al., 2016;Rajpurkar et al., 2018), conversational datasets (Dinan et al., 2018), and ConvQA datasets (Choi et al., 2018;Reddy et al., 2019;Elgohary et al., 2018;Saha et al., 2018) has largely driven recent methodological advances.", "sentence2": "models trained on these ConvQA datasets typically select exact answer spans instead of generating them (Yatskar, 2019b).", "label": "contrasting"}
{"id": "test_61", "sentence1": "As shown in Table 1, the hidden dimension of each building block is only 128.", "sentence2": "we introduce two linear transformations for each building block to adjust its input and output dimensions to 512.", "label": "contrasting"}
{"id": "test_62", "sentence1": "One may either only use the bottlenecks for MobileBERT (correspondingly the teacher becomes BERT LARGE ) or only the invertedbottlenecks for IB-BERT (then there is no bottleneck in MobileBERT) to align their feature maps.", "sentence2": "when using both of them, we can allow IB-BERT LARGE to preserve the performance of BERT LARGE while having MobileBERT sufficiently compact.", "label": "contrasting"}
{"id": "test_63", "sentence1": "This has enabled ever-increasing performance on benchmark data sets.", "sentence2": "one thing has remained relatively constant: the softmax of a dot product as the output layer.", "label": "contrasting"}
{"id": "test_64", "sentence1": "Recently Graph Neural Network (GNN) has shown to be powerful in successfully tackling many tasks.", "sentence2": "there has been no attempt to exploit GNN to create taxonomies.", "label": "contrasting"}
{"id": "test_65", "sentence1": "We get better performance if we tune the thresholds.", "sentence2": "we chose a harder task and proved our model has better performance than others even we simply use 0.5 as the threshold.", "label": "contrasting"}
{"id": "test_66", "sentence1": "The model identifies words related to community (\"kids,\" \"neighborhood,\" \"we\") as strong negative signals for depression, supporting that depressed language reflects detachment from community.", "sentence2": "the model only focuses on these semantic themes in responses to generic backchannel categories.", "label": "contrasting"}
{"id": "test_67", "sentence1": "Thanks to the increased complexity of deep neural networks and use of knowledge transfer from the language models pre\u0002trained on large-scale corpora (Peters et al., 2018; Devlin et al., 2019; Dong et al., 2019), the state of-the-art QA models have achieved human-level performance on several benchmark datasets (Rajpurkar et al., 2016, 2018)", "sentence2": "what is also crucial to the success of the recent data-driven mod\u0002els, is the availability of large-scale QA datasets", "label": "contrasting"}
{"id": "test_68", "sentence1": "Some of the recent works resort to semi-supervised learning, by leveraging large amount of unlabeled text (e.g. Wikipedia) to generate synthetic QA pairs with the help of QG systems (Tang et al., 2017; Yang et al., 2017; Tang et al., 2018; Sachan and Xing, 2018).", "sentence2": "existing QG systems have overlooked an important point that generating QA pairs from a context consisting of unstructured texts, is essentially a one-to-many problem.", "label": "contrasting"}
{"id": "test_69", "sentence1": "They should be semantically consistent, such that it is possible to predict the answer given the question and the context.", "sentence2": "neural QG or QAG models often generate questions irrelevant to the context and the answer (Zhang and Bansal, 2019) due to the lack of the mechanism enforcing this consistency.", "label": "contrasting"}
{"id": "test_70", "sentence1": "For example, when both models are trained with 1% of the Yelp dataset, the accuracy gap is around 9%.", "sentence2": "as we increases the amount of training data to 90%, the accuracy gap drops to within 2%.", "label": "contrasting"}
{"id": "test_71", "sentence1": "Upon further investigation, we find that experiments which use probabilities with image based features have an inter-quartile range of 0.05 and 0.1 for EBG and BLOG respectively whereas for experiments using probabilities with binning based features, this range is 0.32 for both datasets.", "sentence2": "inter-quartile range for exper-iments using ranks with image based features is 0.08 and 0.05 for EBG and BLOG whereas for experiments using ranks with binning based features, this range is 0.49 and 0.42 respectively.", "label": "contrasting"}
{"id": "test_72", "sentence1": "If we have a large number of training samples, the architecture is capable of learning how to discriminate correctly between classes only with the original training data.", "sentence2": "in less-resourced scenarios, our proposed approaches with external knowledge integration could achieve a high positive impact.", "label": "contrasting"}
{"id": "test_73", "sentence1": "These offer obvious benefits to users in terms of immediacy, interaction and convenience.", "sentence2": "it remains challenging for application providers to assess language content collected through these means.", "label": "contrasting"}
{"id": "test_74", "sentence1": "We make our code publicly available for others to use for benchmarking and replication experiments.", "sentence2": "to feature-based scoring, we instead train neural networks on ASR transcriptions which are labeled with proficiency scores assigned by human examiners, and guide the networks with objectives that prioritize language understanding.", "label": "contrasting"}
{"id": "test_75", "sentence1": "These results were not significantly better than the single-task POS prediction model, though we did not explore tuning the alpha weighting values for the combination models.", "sentence2": "bERT only receives a significant improvement in grading ability when using the L1 prediction task.", "label": "contrasting"}
{"id": "test_76", "sentence1": "Figure 4 shows, as expected, that training a speech grader with data from an ASR system with lower word error rates produces better results.", "sentence2": "it is interesting to note that this holds true even when evaluating with data from inferior ASR systems.", "label": "contrasting"}
{"id": "test_77", "sentence1": "This is because SciBERT, like other pretrained language models, is trained via language modeling objectives, which only predict words or sentences given their in-document, nearby textual context.", "sentence2": "we propose to incorporate citations into the model as a signal of inter-document relatedness, while still leveraging the model's existing strength in modeling language.", "label": "contrasting"}
{"id": "test_78", "sentence1": "The candidate program should adhere to the grammatical specification of the target language.", "sentence2": "since incorporating the complete set of C++ grammatical constraints would require significant engineering effort, we instead restrict our attention to the set of \"primary expressions\" consisting of high-level control structures such as if, else, for loops, function declarations, etc.", "label": "contrasting"}
{"id": "test_79", "sentence1": "For example, when there is only one statement within an if statement, the programmer can optionally include a curly brace.", "sentence2": "the pseudocode does not contain such detailed information about style.", "label": "contrasting"}
{"id": "test_80", "sentence1": "This error can be ruled out by SymTable constraint if variable A is undeclared.", "sentence2": "symTable constraints do not preclude all errors related to declarations.", "label": "contrasting"}
{"id": "test_81", "sentence1": "Prior works regarded SQG as a dialog generation task and recurrently produced each question.", "sentence2": "they suffered from problems caused by error cascades and could only capture limited context dependencies.", "label": "contrasting"}
{"id": "test_82", "sentence1": "We expect that this category is rare because the premise is not text.", "sentence2": "since there are some textual elements in the tables, the hypothesis could paraphrase them.", "label": "contrasting"}
{"id": "test_83", "sentence1": "Finally, research into multimodal or multi-view deep learning (Ngiam et al., 2011; Li et al., 2018) offers insights to effectively combine multiple data modalities or views on the same learning problem.", "sentence2": "most work does not directly apply to our problem: i) the audio-text modality is significantly under-represented, ii) the models are typically not required to work online, and iii) most tasks are cast as document-level classification and not sequence labeling (Zadeh et al., 2018).", "label": "contrasting"}
{"id": "test_84", "sentence1": "Current ASR approaches rely solely on utilizing audio input to produce transcriptions.", "sentence2": "the wide availability of cameras in smartphones and home devices acts as motivation to build AV-ASR models that rely on and benefit from multimodal input.", "label": "contrasting"}
{"id": "test_85", "sentence1": "Even for datasets with dialogue taking place in a similar domain as improv, they naturally contain only a small proportion of yes-ands.", "sentence2": "the relatively large sizes of these datasets still make them useful for dialogue systems.", "label": "contrasting"}
{"id": "test_86", "sentence1": "Their model uses an exemplar sentence as a syntactic guide during generation; the generated paraphrase is trained to incorporate the semantics of the input sentence while emulating the syntactic structure of the exemplar (see Appendix D for examples).", "sentence2": "their proposed approach depends on the availability of such exemplars at test time; they manually constructed these for their test set (800 examples).", "label": "contrasting"}
{"id": "test_87", "sentence1": "Recent work on controlled generation aims at controlling attributes such as sentiment (Shen et al., 2017), gender or political slant (Prabhumoye et al., 2018), topic (Wang et al., 2017), etc.", "sentence2": "these methods cannot achieve fine-grained control over a property like syntax.", "label": "contrasting"}
{"id": "test_88", "sentence1": "In the context of translation, there is often a canonical reordering that should be applied to align better with the target language; for instance, head-final languages like Japanese exhibit highly regular syntax-governed reorderings compared to English.", "sentence2": "in diverse paraphrase generation, there doesn't exist a single canonical reordering, making our problem quite different.", "label": "contrasting"}
{"id": "test_89", "sentence1": "Still, dialogue research papers tend to report scores based on word-overlap metrics from the machine translation literature (e.g. BLEU (Papineni et al., 2002), METEOR (Denkowski and Lavie, 2014)).", "sentence2": "word-overlap metrics aggressively penalize the generated response based on lexical differences with the ground truth and correlate poorly to human judgements (Liu et al., 2016).", "label": "contrasting"}
{"id": "test_90", "sentence1": "Lowe et al. (2017) propose a learned referenced metric named ADEM, which learns an alignment score be\u0002tween context and response to predict human score annotations.", "sentence2": "since the score is trained to mimic human judgements, it requires collecting large-scale human annotations on the dataset in question and cannot be easily applicable to new datasets (Lowe, 2019).", "label": "contrasting"}
{"id": "test_91", "sentence1": "Recently, Tao et al. (2017) proposed a hybrid referenced-unreferenced metric named RUBER, where the metric is trained without requiring hu\u0002man responses by bootstrapping negative samples directly from the dataset.", "sentence2": "referenced metrics (including RUBER, as it is part referenced) are not feasible for evaluation of dialogue models in an online setting-when the model is pitched against a human agent (model-human) or a model agent (model-model)-due to lack of a reference response.", "label": "contrasting"}
{"id": "test_92", "sentence1": "All models achieve high scores on the semantic positive samples when only trained with syntactical adversaries.", "sentence2": "training only with syntactical negative samples results in adverse effect on detecting semantic negative items.", "label": "contrasting"}
{"id": "test_93", "sentence1": "It has shown that response timings vary based on the semantic content of dialogue responses and the preceding turn (Levinson and Torreira, 2015), and that listeners are sensitive to these fluctuations in timing (Bogels and Levinson, 2017).", "sentence2": "the question of whether certain response timings within different contexts are considered more realistic than others has not been fully investigated.", "label": "contrasting"}
{"id": "test_94", "sentence1": "While Step-By-Step uses heuristic string matching to extract plans from the referenced sentences, other methods (GRU and transformer), as well as ours, use plans provided in the enriched WebNLG dataset (Castro Ferreira et al., 2018).", "sentence2": "step-By-step reported worse BLEU results on these plans.", "label": "contrasting"}
{"id": "test_95", "sentence1": "GCN does not perform well on Coverage, which demonstrates that the structural gap between encoding and decoding indeed makes generation more difficult.", "sentence2": "it has the smallest difference between Coverage and Faithfulness among all the baselines, indicating that the fidelity of generation can benefit from the encoding of graph-level structural information.", "label": "contrasting"}
{"id": "test_96", "sentence1": "These existing neural models have achieved encouraging results.", "sentence2": "when a new condition is added (e.g., a new topic for categorical generation), they require a full retraining or finetuning.", "label": "contrasting"}
{"id": "test_97", "sentence1": "Many great works have attempted to solve various subtasks like dialogue generation (Li et al., 2016), poetry generation (Yi et al., 2018) and story generation (Fan et al., 2018) and new techniques keep emerging (Bowman et al., 2016;Yu et al., 2017;Zhou et al., 2020).", "sentence2": "due to the blackbox nature of neural networks, the recent proposed generic models suffer the problem of lacking interpretability and controllability.", "label": "contrasting"}
{"id": "test_98", "sentence1": "Previous methods (Kingma et al., 2014; Hu et al., 2017) learn the joint conditional space by jointly considering all conditions.", "sentence2": "once the model is trained, it is not possible to add a new condition without a full retraining.", "label": "contrasting"}
{"id": "test_99", "sentence1": "These methods collect user feedback after the model-predicting stage and treat user feedback as additional offline training data to improve the model.", "sentence2": "our model leverages user interaction to increase prediction performance.", "label": "contrasting"}
{"id": "test_100", "sentence1": "Pretrained autoregressive models such as GPT (Radford et al., 2018, 2019) are especially capable of generating fluent and coherent text that highly resembles human-written text", "sentence2": "unidirectional attention brings two limitations.", "label": "contrasting"}
{"id": "test_101", "sentence1": "This can result in different computational complexity.", "sentence2": "since a typical Graphics Processing Unit (GPU) computes matrices in parallel, the actual difference in inference time is not that significant.", "label": "contrasting"}
{"id": "test_102", "sentence1": "The Wikitext103 dataset is more similar to the pretraining datasets, containing long articles.", "sentence2": "the One-Billion Words dataset contains only single sentences, roughly half of which contain less than 24 tokens.", "label": "contrasting"}
{"id": "test_103", "sentence1": "Besides, the results show that there are few differences between relative positional embedding and absolute positional embedding for u-PMLM.", "sentence2": "although BERT supports generation in arbitrary word order as well, the PPL for BERT is significantly worse than our proposed u-PMLM for both \"sequential\" and \"random\" settings, demonstrating the effectiveness of the proposed probabilistic masking scheme.", "label": "contrasting"}
{"id": "test_104", "sentence1": "We show more cases of text generation in random order for u-PMLM-A and BERT in Appendix B.", "sentence2": "for PPL on One-Billion Words, the performances of u-PMLM and BERT are not satisfactory in comparison with GPT.", "label": "contrasting"}
{"id": "test_105", "sentence1": "For GPT, the input text can only be placed in the beginning and the generation process become uncontrollable, resulting in generating sentences with topic drift.", "sentence2": "u-PMLM allows manually placing anchor sentences in the middle or end of the generated text to guide the topic of the generated text.", "label": "contrasting"}
{"id": "test_106", "sentence1": "Existing uses of pretrained MLMs in sequenceto-sequence models for automatic speech recognition (ASR) or neural machine translation (NMT) involve integrating their weights (Clinchant et al., 2019) or representations (Zhu et al., 2020) into the encoder and/or decoder during training.", "sentence2": "we train a sequence model independently, then rescore its n-best outputs with an existing MLM.", "label": "contrasting"}
{"id": "test_107", "sentence1": "As the MLM gets stronger, the improvement from adding scores from GPT-2 goes to zero, suggesting that their roles overlap at the limit.", "sentence2": "unlike recent work (Shin et al., 2019) but like previous work (Chen et al., 2017), we found that interpolating with a unidirectional LM remained optimal, though our models are trained on different datasets and may have an ensembling effect.", "label": "contrasting"}
{"id": "test_108", "sentence1": "In the IID setting, large pretrained Transformer models can attain near human-level performance on numerous tasks (Wang et al., 2019)", "sentence2": "high IID accuracy does not necessarily translate to OOD robustness for image classifiers (Hendrycks and Dietterich, 2019), and pretrained Transformers may embody this same fragility.", "label": "contrasting"}
{"id": "test_109", "sentence1": "The recent work of Pruthi et al. (2019), which uses a typo-corrector to defend against adver\u0002sarial typos, is such a reusable defense: it is trained once, then reused across different tasks.", "sentence2": "we find that current typo-correctors do not perform well against even heuristic attacks, limiting their applicability.", "label": "contrasting"}
{"id": "test_110", "sentence1": "During training, each occurrence of \"at\" and \"abet\" is replaced with z.", "sentence2": "since \"at\" is much more frequent, classifiers treat z similarly to \"at in order to achieve good overall performance.", "label": "contrasting"}
{"id": "test_111", "sentence1": "This data consists of approximately 2 million instances constructed using the abstract and body structure of Wikipedia.", "sentence2": "our ap-proach to pre-training can generate data in unlimited quantity from any text source without assuming a particular document structure.", "label": "contrasting"}
{"id": "test_112", "sentence1": "Both improve with multiple iterations, though the improvement is much larger with CMLM.", "sentence2": "even with  10 iterations, ENGINE is comparable to CMLM on DE-EN and outperforms it on RO-EN", "label": "contrasting"}
{"id": "test_113", "sentence1": "As in EWISE, in EWISER logits are computed by a dot product between a matrix of hidden scores and output synset embeddings.", "sentence2": "we do not train our own synset embeddings: rather, we employ off-the-shelf vectors.", "label": "contrasting"}
{"id": "test_114", "sentence1": "Consequently, the general-language and domain-specific contexts are maximally similar in these cases.", "sentence2": "we assume that the contexts will vary more strongly for basic terms, and for non-terms we do not expect to find domain-specific sentences in the generallanguage corpus at all.", "label": "contrasting"}
{"id": "test_115", "sentence1": "Recent research on fairness has primarily focused on racial and gender biases within distributed word representations (Bolukbasi et al., 2016), coreference resolution (Rudinger et al., 2018), sentence encoders (May et al., 2019), and language models .", "sentence2": "we posit that there exists a significant potential for linguistic bias that has yet to be investigated, which is the motivation for our work.", "label": "contrasting"}
{"id": "test_116", "sentence1": "In the context of question answering, SpanBERT appears to be slightly more robust than vanilla BERT when comparing overall performance on the two SQuAD datasets.", "sentence2": "the difference becomes significant if we look only at the SQuAD 2.0-fine-tuned models' performance on answerable questions (7% difference).", "label": "contrasting"}
{"id": "test_117", "sentence1": "Existing adversarial training approaches have shown that retraining the model on the augmented training set improves robustness (Belinkov and Bisk, 2018; Eger et al., 2019; Jin et al., 2019).", "sentence2": "this requires substantial compute resources.", "label": "contrasting"}
{"id": "test_118", "sentence1": "As depicted in Figure 1, we are interested in identifying clusters of subtly distinctive glyph shapes as these correspond to distinct metal stamps in the type-cases used by printers.", "sentence2": "other sources of variation (inking, for example, as depicted in Figure 1) are likely to dominate conventional clustering methods.", "label": "contrasting"}
{"id": "test_119", "sentence1": "For example, Gulcehre et al. (2014) explored the influence of selecting different pool\u0002ing norms on the performance of different im\u0002age classification tasks.", "sentence2": "the norms in their method are manually tuned, which are usually very time-consuming and may not be optimal.", "label": "contrasting"}
{"id": "test_120", "sentence1": "Multi-task learning (MTL) and transfer learning (TL) are techniques to overcome the issue of data scarcity when training state-of-theart neural networks.", "sentence2": "finding beneficial auxiliary datasets for MTL or TL is a time-and resource-consuming trial-and-error approach.", "label": "contrasting"}
{"id": "test_121", "sentence1": "This is reasonable as the \"O\" labels by far make up the majority of all labels in NER datasets.", "sentence2": "this does not help to find similar dataset in other cases, because there is no meaningful ordering of the entropy values when comparing any of the POS samples with all the other samples.", "label": "contrasting"}
{"id": "test_122", "sentence1": "The incorporation of pseudo-tags is a standard technique widely used in the NLP community, (Rico et al., 2016; Melvin et al., 2017).", "sentence2": "to the best of our knowledge, our approach is the first attempt to incorporate pseudo-tags as an identification marker of virtual models within a single model.", "label": "contrasting"}
{"id": "test_123", "sentence1": "As displayed in Table 2, SINGLEENS surpassed SINGLE by 0.44 and 0.14 on CoNLL-2003 and CoNLL-2000, respectively, for TFM:ELMO with the same parameter size.", "sentence2": "nORMALEnS produced the best results in this setting.", "label": "contrasting"}
{"id": "test_124", "sentence1": "Multi-modal neural machine translation (NMT) aims to translate source sentences into a target language paired with images.", "sentence2": "dominant multi-modal NMT models do not fully exploit fine-grained semantic correspondences between semantic units of different modalities, which have potential to refine multi-modal representation learning.", "label": "contrasting"}
{"id": "test_125", "sentence1": "Non-autoregressive neural machine translation (NAT) predicts the entire target sequence simultaneously and significantly accelerates inference process.", "sentence2": "nAT discards the dependency information in a sentence, and thus inevitably suffers from the multi-modality problem: the target tokens may be provided by different possible translations, often causing token repetitions or missing.", "label": "contrasting"}
{"id": "test_126", "sentence1": "Therefore, the decoder has richer target-side information to detect and recover from such errors.", "sentence2": "it is non-trivial to train the model to learn such behaviour while maintaining a reasonable speedup.", "label": "contrasting"}
{"id": "test_127", "sentence1": "The study of calibration on classification tasks has a long history, from statistical machine learning (Platt et al., 1999;Niculescu-Mizil and Caruana, 2005) to deep learning (Guo et al., 2017).", "sentence2": "calibration on structured generation tasks such as neural machine translation (NMT) has not been well studied.", "label": "contrasting"}
{"id": "test_128", "sentence1": "Modern neural networks have been found to be miscalibrated on classification tasks in the direction of overestimation (Guo et al., 2017).", "sentence2": "nMT models also suffer from under-estimation problems.", "label": "contrasting"}
{"id": "test_129", "sentence1": "For instance, if the spam candidate mutates at the critical positions, the label of the augmented text is likely to change.", "sentence2": "normal candidates are less likely to be affected by this situation.", "label": "contrasting"}
{"id": "test_130", "sentence1": "Since manual coding is very laborious and prone to errors, many methods have been proposed for the automatic ICD coding task.", "sentence2": "most of existing methods independently predict each code, ignoring two important characteristics: Code Hierarchy and Code Co-occurrence.", "label": "contrasting"}
{"id": "test_131", "sentence1": "(2) The effectiveness of hyperbolic representations: Our proposed model and the CNN+Attention can both correctly predict the code \"518.81\".", "sentence2": "the CNN+Attention model gives contradictory predictions.", "label": "contrasting"}
{"id": "test_132", "sentence1": "For example, label \"movie\" should have the largest scalar projection onto a document about \"movie\".", "sentence2": "even the learned label representation of \"music\" can be distinguished from \"movie\", it may also have a large scalar projection onto the document.", "label": "contrasting"}
{"id": "test_133", "sentence1": "(Zhao et al., 2019) improves the scalability of capsule networks for MLC.", "sentence2": "they only use CNN to construct capsules, which capture local contextual information (Wang et al., 2016).", "label": "contrasting"}
{"id": "test_134", "sentence1": "The typical MLC method SLEEC takes advantage of label correlations by embedding the label co-occurrence graph.", "sentence2": "sLEEC uses TF-IDF vectors to represent documents, thus word order is also ignored.", "label": "contrasting"}
{"id": "test_135", "sentence1": "REGGNN is generally superior to both of them as it combines the local and global contextual information dynamically and takes label correlations into consideration using a regularized loss.", "sentence2": "the two capsulebased methods NLP-CAP and HYPERCAPS consistently outperform all the other methods owing to dynamic routing, which aggregates the fine-grained capsule features in a label-aware manner.", "label": "contrasting"}
{"id": "test_136", "sentence1": "In the hospitals, the doctors will make a comprehensive analysis mainly based on CC, HPI, PE, TR and the basic information, and make a diagnosis.", "sentence2": "it is very hard for computers to automatically understand all the diverse sections and capture the key information before making an appropriate diagnosis.", "label": "contrasting"}
{"id": "test_137", "sentence1": "Zhang et al. (2017) combines the variational auto-encoder and the variational recurrent neural network together to make diagnosis based on laboratory test data.", "sentence2": "laboratory test data are not the only resources considered in this paper.", "label": "contrasting"}
{"id": "test_138", "sentence1": "Although ECNN also outputs a probability distribution over all diseases, the result is not interpretable due to its end-to-end nature.", "sentence2": "the interpretability is very important in the CDS to explain how the diagnosis is generated by machines.", "label": "contrasting"}
{"id": "test_139", "sentence1": "Remarkable success has been achieved when sufficient labeled training data is available.", "sentence2": "annotating sufficient data is labor-intensive, which establishes significant barriers for generalizing the stance classifier to the data with new targets.", "label": "contrasting"}
{"id": "test_140", "sentence1": "The aspect-opinion pairs can provide a global profile about a product or service for consumers and opinion mining systems.", "sentence2": "traditional methods can not directly output aspect-opinion pairs without given aspect terms or opinion terms.", "label": "contrasting"}
{"id": "test_141", "sentence1": "As the example sentence shown in Figure 1, (service, great), (prices, great) and (atmosphere, nice friendly) are three aspect-opinion pairs.", "sentence2": "the co-extraction methods can only output the AT set {service, prices, atmosphere} and the OT set {great, nice friendly} jointly.", "label": "contrasting"}
{"id": "test_142", "sentence1": "Most of the previous AT and OT extraction meth\u0002ods formulate the task as a sequence tagging prob\u0002lem (Wang et al., 2016, 2017; Wang and Pan, 2018; Yu et al., 2019), specifically using a 5-class tag set: {BA (beginning of aspect), IA (inside of aspect), BP (beginning of opinion), IP (inside of opinion), O (others)}.", "sentence2": "the sequence tagging methods suffer from a huge search space due to the compositionality of labels for extractive ABSA tasks, which has been proven in (Lee et al., 2017b;Hu et al., 2019).", "label": "contrasting"}
{"id": "test_143", "sentence1": "Motivated by the correlations between the two tasks, SRL has been utilized to help the ORL task by many previous studies (Ruppenhofer et al., 2008; Marasovic and Frank, 2018; Zhang et al., 2019b).", "sentence2": "when opinion expressions and ar\u0002guments compose complicated syntactic structures, it is difficult to correctly recognize the opinion ar\u0002guments even with shallow semantic representation like SRL (Marasovic and Frank, 2018).", "label": "contrasting"}
{"id": "test_144", "sentence1": "Specifically, the pipeline way first trains the dependency parser and then fixes the parser components during training the ORL model.", "sentence2": "the MTL way trains both the parser and the ORL model at the same time.", "label": "contrasting"}
{"id": "test_145", "sentence1": "As a baseline, Figure 2-(c) shows the most com\u0002mon MTL method, which shares a common encoder and uses multiple task-specific output layers, known as the hard-parameter-sharing MTL (Ruder, 2017; Marasovic and Frank, 2018).", "sentence2": "this approach is not suitable for our scenario where the auxiliary parsing task has much more labeled data than the main ORL task, since the shared encoder is very likely to bias toward to parsing performance (Xia et al., 2019a).", "label": "contrasting"}
{"id": "test_146", "sentence1": "For example, Stab and Gurevych (2017) introduced Argument Annotated Essays (hereafter, Essay), and researchers attempted to predict tree arguments in the corpus (Eger et al., 2017;Potash et al., 2017;Kuribayashi et al., 2019).", "sentence2": "these techniques lack the capability of dealing with more flexible arguments such as reason edges where a proposition can have several parents.", "label": "contrasting"}
{"id": "test_147", "sentence1": "Potash et al. (2017) developed a pointer network architec\u0002ture to predict edges.", "sentence2": "we cannot simply utilize them for non-tree arguments because these models were built upon the assumption that an argument forms a tree structure.", "label": "contrasting"}
{"id": "test_148", "sentence1": "However, if one wants to apply WSD to some specific corpus, additional annotated training data might be required to meet the similar performance as ours, which defeats the purpose of a weakly supervised setting.", "sentence2": "our contextualization, building upon (Devlin et al., 2019), is adaptive to the input corpus, without requiring any additional human annotations.", "label": "contrasting"}
{"id": "test_149", "sentence1": "In micro average, all the span predictions are aggregated together and then compared with the gold spans to get the precision and recall.", "sentence2": "macro average is obtained by calculating the F1 score for each individual sentence and then take an average over all the sentences.", "label": "contrasting"}
{"id": "test_150", "sentence1": "Multi-threading is employed since sentences are mutually independent.", "sentence2": "we find that using more than 4 threads does not further improve the speed.", "label": "contrasting"}
{"id": "test_151", "sentence1": "We can see that the performance gap is quite steady when we gradually reduce the number of training sentences.", "sentence2": "the gap clearly becomes larger when each training sentence has less annotated dependencies.", "label": "contrasting"}
{"id": "test_152", "sentence1": "In BiLSTM-CRF, the CRF layer models the relation between neighbouring labels which leads to better results than simply predicting each label separately based on the BiLSTM outputs.", "sentence2": "the CRF structure models the label sequence globally with the correlations between neighboring labels, which increases the difficulty in distilling the knowledge from the teacher models.", "label": "contrasting"}
{"id": "test_153", "sentence1": "In particular, discarding the conversion matrix in the ESD module also leads to the performance drop, which indicates the usefulness of capturing the label correspondence between the auxiliary module and our main MNER task.", "sentence2": "as the main contribution of  our MMI module, Image-Aware Word Representations (WR) demonstrates its indispensable role in the final performance due to the moderate performance drop after removal.", "label": "contrasting"}
{"id": "test_154", "sentence1": "These neural approaches have been shown to achieve the state-of-the-art performance on different benchmark datasets based on formal text (Yang et al., 2018).", "sentence2": "when applying these approaches to social media text, most of them fail to achieve satisfactory results.", "label": "contrasting"}
{"id": "test_155", "sentence1": "Despite not being exposed to explicit syntactic supervision, neural language models (LMs), such as recurrent neural networks, are able to generate fluent and natural sentences, suggesting that they induce syntactic knowledge about the language to some extent.", "sentence2": "it is still under debate whether such induced knowledge about grammar is robust enough to deal with syntactically challenging constructions such as long-distance subjectverb agreement.", "label": "contrasting"}
{"id": "test_156", "sentence1": "We expect that the main reason for lower performance for object RCs is due to frequency, and with our augmentation the accuracy will reach the same level as that for subject RCs.", "sentence2": "for both all and animate cases, accuracies are below those for subject rCs (Figure 2).", "label": "contrasting"}
{"id": "test_157", "sentence1": "Moreover, Huang et al. (2019) im\u0002prove TextGCN by introducing the message pass\u0002ing mechanism and reducing the memory consump\u0002tion", "sentence2": "there are two major drawbacks in these graph-based methods.", "label": "contrasting"}
{"id": "test_158", "sentence1": "A concurrent work (Warstadt et al., 2019b) facilitates diagnosing language models by creating linguistic minimal pairs datasets for 67 isolate grammatical paradigms in English using linguistcrafted templates.", "sentence2": "we do not rely heavily on artificial vocabulary and templates.", "label": "contrasting"}
{"id": "test_159", "sentence1": "Such attention weights measure the relative importance of the token within a specific input sequence.", "sentence2": "the attention score a j captures the absolute importance of the token.", "label": "contrasting"}
{"id": "test_160", "sentence1": "After that, both of them directly use the word representation of two languages to retrieve the initial bilingual lexicons by computing the cosine distances of source and target word representations.", "sentence2": "directly finding word alignments from scratch has some demerits.", "label": "contrasting"}
{"id": "test_161", "sentence1": "Unsupervised neural machine translation (UNMT) has recently achieved remarkable results for several language pairs.", "sentence2": "it can only translate between a single language pair and cannot produce translation results for multiple language pairs at the same time.", "label": "contrasting"}
{"id": "test_162", "sentence1": "For example, Xu et al. (2019) and Sen et al. (2019) proposed a multilingual scheme that jointly trains multiple languages with multiple decoders.", "sentence2": "the performance of their MUNMT is much worse than our re-implemented individual baselines (shown in Tables 2 and 3) and the scale of their study is modest (i.e., 4-5 languages).", "label": "contrasting"}
{"id": "test_163", "sentence1": "Moreover, the MUNMT model could alleviate the poor performance achieved with low-resource language pairs, such as En-Lt and En-Lv.", "sentence2": "the performance of MUNMT is slightly worse than SM in some language pairs.", "label": "contrasting"}
{"id": "test_164", "sentence1": "The standard training algorithm in neural machine translation (NMT) suffers from exposure bias, and alternative algorithms have been proposed to mitigate this.", "sentence2": "the practical impact of exposure bias is under debate.", "label": "contrasting"}
{"id": "test_165", "sentence1": "Previous work has sought to reduce exposure bias in training (Bengio et al., 2015; Ranzato et al., 2016; Shen et al., 2016; Wiseman and Rush, 2016; Zhang et al., 2019).", "sentence2": "the relevance of error propagation is under debate: Wu et al. (2018) argue that its role is overstated in literature, and that linguistic features explain some of the accuracy drop at higher time steps.", "label": "contrasting"}
{"id": "test_166", "sentence1": "Advanced pre-trained models for text representation have achieved state-of-the-art performance on various text classification tasks.", "sentence2": "the discrepancy between the semantic similarity of texts and labelling standards affects classifiers, i.e. leading to lower performance in cases where classifiers should assign different labels to semantically similar texts.", "label": "contrasting"}
{"id": "test_167", "sentence1": "In general, AAN achieved greater performance than AM.", "sentence2": "their effectiveness turned out to be task-dependent.", "label": "contrasting"}
{"id": "test_168", "sentence1": "Previous studies aimed to improve multiple tasks; hence, they required multiple sets of annotated datasets.", "sentence2": "our method does not require any extra labelled datasets and is easily applicable to various classification tasks.", "label": "contrasting"}
{"id": "test_169", "sentence1": "On top of it, Crosslingual training (or bilingual, denoted by \"Cross\") obtains marginal improvements for moderately lowresource languages.", "sentence2": "the performance drops dramatically for two extremely low-resource languages, i.e., JA from 0.740 to 0.711 and EL from 0.702 to 0.684.", "label": "contrasting"}
{"id": "test_170", "sentence1": "Previous studies in multimodal sentiment analysis have used limited datasets, which only contain unified multimodal annotations.", "sentence2": "the unified annotations do not always reflect the independent sentiment of single modalities and limit the model to capture the difference between modalities.", "label": "contrasting"}
{"id": "test_171", "sentence1": "An intuitive idea is that the greater the difference between inter-modal representations, the better the complementarity of intermodal fusion.", "sentence2": "it is not easy for existing late-fusion models to learn the differences between different modalities, further limits the performance of fusion.", "label": "contrasting"}
{"id": "test_172", "sentence1": "The CHEAVD (Li et al., 2017) is also a Chinese multimodal dataset, but it only contains two modalities (vision and audio) and one unified annotation.", "sentence2": "sIMs has three modalities and unimodal annotations except for multimodal annotations for each clip.", "label": "contrasting"}
{"id": "test_173", "sentence1": "However, these existing multimodal datasets only contain a unified multimodal annotation for each multimodal corpus.", "sentence2": "sIMs contains both unimodal and multimodal annotations.", "label": "contrasting"}
{"id": "test_174", "sentence1": "Hierarchical FM performs better than MLP+CNN by incorporating additional attributes that provide the visual semantic information and generating better feature representations via a hierarchical fusion framework.", "sentence2": "these multimodal baselines pay more attention to the fusion of multimodal features.", "label": "contrasting"}
{"id": "test_175", "sentence1": "Thus, their performances are worse than MIARN, which focuses on textual context to model the contrast information between individual words and phrases.", "sentence2": "due to the nature of short text, relying on textual information is often insufficient, especially in multimodal tweets where cross-modality context relies the most important role.", "label": "contrasting"}
{"id": "test_176", "sentence1": "As interpretability is important for understanding and debugging the translation process and particularly to further improve NMT models, many efforts have been devoted to explanation methods for NMT (Ding et al., 2017;Alvarez-Melis and Jaakkola, 2017;Li et al., 2019;Ding et al., 2019;.", "sentence2": "little progress has been made on evaluation metric to study how good these explanation methods are and which method is better than others for NMT.", "label": "contrasting"}
{"id": "test_177", "sentence1": "In terms of i), Word Alignment Error Rate (AER) can be used as a metric to evaluate an explanation method by measuring agreement between human-annotated word alignment and that derived from the explanation method.", "sentence2": "aER can not measure explanation methods on those target words that are not aligned to any source words according to human annotation.", "label": "contrasting"}
{"id": "test_178", "sentence1": "On one hand, the real data distribution of c t is unknowable, making it impossible to exactly define the expectation with respect to an unknown distribution.", "sentence2": "the domain of a proxy model Q is not bounded, and it is difficult to minimize a model Q within an unbounded domain.", "label": "contrasting"}
{"id": "test_179", "sentence1": "This backpropagation through the generated data, combined with adversarial learning instabilities, has proven to be a compelling challenge when applying GANs for discrete data such as text.", "sentence2": "it remains unknown if this is also an issue for feature matching networks since the effectiveness of GFMN for sequential discrete data has not yet been studied.", "label": "contrasting"}
{"id": "test_180", "sentence1": "An interesting comparison would be between Se-qGFMN and GANs that use BERT as a pre-trained discriminator.", "sentence2": "gANs fail to train when a very deep network is used as the discriminator Moreover, SeqgFMN also outperforms gAN generators even when shallow word embeddings (glove / FastText) are used to perform feature matching.", "label": "contrasting"}
{"id": "test_181", "sentence1": "Extractive MRC requires a model to extract an answer span to a question from reference documents, such as the tasks in SQuAD (Rajpurkar et al., 2016) and CoQA (Reddy et al., 2019).", "sentence2": "non-extractive MRC infers answers based on some evidence in reference documents, including Yes/No question answering (Clark et al., 2019), multiple-choice MRC (Lai et al., 2017; Khashabi et al., 2018; Sun et al., 2019), and open domain question answering (Dhingra et al., 2017b).", "label": "contrasting"}
{"id": "test_182", "sentence1": "RL methods can indeed train a better extractor without evidence labels.", "sentence2": "they are much more complicated and unstable to train, and highly dependent on model pre-training.", "label": "contrasting"}
{"id": "test_183", "sentence1": "As the innermost ring shows, about 80% of the evidence predicted by BERT-HA (iter 0) was incorrect.", "sentence2": "the proportion of wrong instances reduced to 60% after self-training (iter 3).", "label": "contrasting"}
{"id": "test_184", "sentence1": "Earlier studies have attempted to perform the MWP task via statistical machine learning methods (Kushman et al., 2014; Hosseini et al., 2014; Mitra and Baral, 2016; Roy and Roth, 2018) and seman\u0002tic parsing approaches (Shi et al., 2015; Koncel\u0002Kedziorski et al., 2015; Roy and Roth, 2015; Huang et al., 2017).", "sentence2": "these methods are nonscalable as tremendous efforts are required to design suitable features and expression templates.", "label": "contrasting"}
{"id": "test_185", "sentence1": "To enrich the representation of a quantity, the relationships between the descriptive words associated with a quantity need to be modeled.", "sentence2": "such relationships cannot be effectively modeled using recurrent models, which are commonly used in the existing MWP deep learning methods.", "label": "contrasting"}
{"id": "test_186", "sentence1": "While all of these methods are bag-of-words models, Liu et al. (2019a) recently proposed an architecture based on context2vec (Melamud et al., 2016).", "sentence2": "in contrast to our work, they (i) do not incorporate surface-form information and (ii) do not directly access the hidden states of context2vec, but instead simply use its output distribution.", "label": "contrasting"}
{"id": "test_187", "sentence1": "For this reason, previous works used an in-house mapping between BabelNet versions to make them up to date.", "sentence2": "in this process, several gold instances were lost making the datasets smaller than the original ones.", "label": "contrasting"}
{"id": "test_188", "sentence1": "Word-Net provides information about sense frequency that is either manually-annotated or derived from SemCor (Miller et al., 1993), i.e., a corpus where words are manually tagged with WordNet meanings.", "sentence2": "neither WordNet nor SemCor have been updated in the past 10 years, thus making their information about sense frequency outdated.", "label": "contrasting"}
{"id": "test_189", "sentence1": "The method of applying REINFORCE to the discriminative parser is straightforward because sampling trees from the discriminative parser is easy.", "sentence2": "that is not the case for the generative model from which we have to sample both trees and sentences at the same time.", "label": "contrasting"}
{"id": "test_190", "sentence1": "In this task, models are expected to make predictions with the semantic information rather than with the demographic group identity information (e.g., \"gay\", \"black\") contained in the sentences.", "sentence2": "recent research points out that there widely exist some unintended biases in text classification datasets.", "label": "contrasting"}
{"id": "test_191", "sentence1": "In other words, a non-discrimination model should perform similarly across sentences containing different demographic groups.", "sentence2": "\"perform similarly\" is indeed hard to define.", "label": "contrasting"}
{"id": "test_192", "sentence1": "Similar to results on Toxicity Comments, we find that both Weight and Supplement perform significantly better than Baseline in terms of IPTTS AUC and FPED, and the results of Weight and Supplement are comparable.", "sentence2": "we notice that Weight and Supplement improve FNED slightly, while the differences are not statistically significant at confidence level 0.05.", "label": "contrasting"}
{"id": "test_193", "sentence1": "Current approaches define interpretation in a rather ad-hoc manner, motivated by practical usecases and applications.", "sentence2": "this view often fails to distinguish between distinct aspects of the interpretation's quality, such as readability, plausibility and faithfulness (Herman, 2017).", "label": "contrasting"}
{"id": "test_194", "sentence1": "For example, Serrano and Smith (2019) and Jain and Wallace (2019) show that high attention weights need not necessarily correspond to a higher impact on the model's predictions and hence they do not provide a faithful explanation for the model's predictions.", "sentence2": "wiegreffe and Pinter (2019) argues that there is still a possibility that attention distributions may provide a plausible explanation for the predictions.", "label": "contrasting"}
{"id": "test_195", "sentence1": "Our main goal is to show that our proposed models provide more faithful and plausible explanations for their predictions.", "sentence2": "before we go there we need to show that the predictive performance of our models is comparable to that of a vanilla LSTM model and significantly better than non-contextual models.", "label": "contrasting"}
{"id": "test_196", "sentence1": "We observe that randomly permuting the attention weights in the Diversity and Orthogonal LSTM model results in significantly different outputs.", "sentence2": "there is little change in the vanilla LSTM model's output for several datasets suggesting that the attention weights are not so meaningful.", "label": "contrasting"}
{"id": "test_197", "sentence1": "Several other works (Shao et al., 2019; Martins and Astudillo, 2016; Malaviya et al., 2018; Niculae and Blondel, 2017; Maruf et al., 2019; Peters et al., 2018) focus on improving the interpretability of attention distributions by inducing sparsity.", "sentence2": "the extent to which sparse attention distributions actually offer faithful and plausible explanations haven't been studied in detail.", "label": "contrasting"}
{"id": "test_198", "sentence1": "The plotted eight words are gathered together, and it can be seen that hidden representations of the same word gather in the same place regardless of correctness.", "sentence2": "fine-tuned BERT produces a vector space that demonstrates correct and incorrect words on different sides, showing that hidden representations take grammatical errors into account when fine-tuned on GEC corpora.", "label": "contrasting"}
{"id": "test_199", "sentence1": "For instance, DKN (Wang et al., 2018) learns knowledge-aware news representation via multi-channel CNN and gets a representation of a user by aggregating her clicked news history with different weights.", "sentence2": "these methods (Wu et al., 2019b; Zhu et al., 2019; An et al., 2019) usu\u0002ally focus on news contents, and seldom consider the collaborative signal in the form of high-order connectivity underlying the user-news interactions.", "label": "contrasting"}
{"id": "test_200", "sentence1": "Wang et al. (2019) explored the GNN to capture high-order connectivity information in user-item graph by propagating embeddings on it, which achieves better performance on recommendation.", "sentence2": "existing news recommendation methods focus on, and rely heavily on news contents.", "label": "contrasting"}
{"id": "test_201", "sentence1": "Initially, we set z u,k = s u,k .", "sentence2": "after obtaining the latent variables {r d,k }, we can find an estimate of z u,k by aggregating information from the clicked news, which is computed as Eq.", "label": "contrasting"}
{"id": "test_202", "sentence1": "Most existing methods usually learn the representations of users and news from news contents for recommendation.", "sentence2": "they seldom consider highorder connectivity underlying the user-news interactions.", "label": "contrasting"}
{"id": "test_203", "sentence1": "It supposes that comparing to less important roles, the roles with bigger impact are expected to appear at more places and are more evenly distributed over the story.", "sentence2": "this assumption ignores actions of roles (denoted as behavioral semantic information), which may be a key factor that estimates their impacts in legalcontext scenarios.", "label": "contrasting"}
{"id": "test_204", "sentence1": "Position or frequency information does not effectively reflect the status of a role in such samples.", "sentence2": "our method captures this information by the cooperation mode feature between Yin and Zhao, with the help of verb \"instructed\".", "label": "contrasting"}
{"id": "test_205", "sentence1": "As we can see from Figure 2(a), the plain nets suffer from the degradation problem, which is not caused by overfitting, as they exhibit lower training BLEU.", "sentence2": "the 72-layer MSC exhibits higher training BLEU than the 36-layer counterpart and is generalizable to the validation data.", "label": "contrasting"}
{"id": "test_206", "sentence1": "Figure 4A) shows, as first identified by Kozlowski et al. (2019), that much of this is due to the variance of the survey data along that dimension; the correlation between variance and the coeffi\u0002cients in Figure 3 is 0.91", "sentence2": "as discussed above, Kozlowski et al. (2019) study more general concepts on more general dimensions, and note that they have no easy way to connect their observations to any critical social processes. ", "label": "contrasting"}
{"id": "test_207", "sentence1": "On the other hand, from the \"bias\" per-spective, this suggests that a vast array of social biases are encoded in embeddings.", "sentence2": "we also find that some beliefs-specifically, extreme beliefs on salient dimensions -are easier to measure than others.", "label": "contrasting"}
{"id": "test_208", "sentence1": "Attention mechanisms learn to assign soft weights to (usually contextualized) token representations, and so one can extract highly weighted tokens as rationales.", "sentence2": "attention weights do not in general provide faithful explanations for predictions (Jain and Wallace, 2019; Serrano and Smith, 2019; Wiegreffe and Pinter, 2019; Zhong et al., 2019; Pruthi et al., 2020; Brunner et al., 2020; Moradi et al., 2019; Vashishth et al., 2019).", "label": "contrasting"}
{"id": "test_209", "sentence1": "Original rationale annotations were not necessarily comprehensive; we thus collected comprehensive rationales on the final two folds of the original dataset (Pang and Lee, 2004).", "sentence2": "to most other datasets, the rationale annotations here are span level as opposed to sentence level.", "label": "contrasting"}
{"id": "test_210", "sentence1": "In general, the rationales we have for tasks are sufficient to make judgments, but not necessarily comprehensive.", "sentence2": "for some datasets we have explicitly collected comprehensive rationales for at least a subset of the test set.", "label": "contrasting"}
{"id": "test_211", "sentence1": "Since DeFormer retains much of the original structure, we can initialize this model with the pre-trained weights of the original Transformer and fine-tune directly on downstream tasks.", "sentence2": "deFormer looses some information in the representations of the lower layers.", "label": "contrasting"}
{"id": "test_212", "sentence1": "The upper layers can learn to compensate for this during finetuning.", "sentence2": "we can go further and use the original model behavior as an additional source of supervision.", "label": "contrasting"}
{"id": "test_213", "sentence1": "This is an orthogonal approach that can be combined with our decomposition idea.", "sentence2": "for the paired-input tasks we consider, pruning heads only provides limited speedup.", "label": "contrasting"}
{"id": "test_214", "sentence1": "This is because the candidate justifications are coming from a relatively small numbers of paragraphs in MultiRC; thus even shorter queries (= 2 words) can retrieve relevant justifications.", "sentence2": "the number of candidate justifications in QASC is much higher, which requires longer queries for disambiguation (>= 4 words).", "label": "contrasting"}
{"id": "test_215", "sentence1": "Access to such data can greatly facilitate investigation of phonetic typology at a large scale and across many languages.", "sentence2": "it is nontrivial and computationally intensive to obtain such alignments for hundreds of languages, many of which have few to no resources presently available.", "label": "contrasting"}
{"id": "test_216", "sentence1": "In addition to its coverage, the CMU Wilderness corpus is unique in two additional aspects: cleanly recorded, read speech exists for all languages in the corpus, and the same content (modulo translation) exists across all languages.", "sentence2": "this massively multilingual speech corpus is challenging to work with directly.", "label": "contrasting"}
{"id": "test_217", "sentence1": "Since our greedy opportunistic decoding doesn't change the final output, there is no difference in BLEU compared with normal decoding, but the latency is reduced.", "sentence2": "by applying beam search, we can achieve 3.1 BLEU improvement and 2.4 latency reduction on wait-7 policy.", "label": "contrasting"}
{"id": "test_218", "sentence1": "Thanks to the wealth of high-quality annotated images available in popular repositories such as ImageNet, multimodal language-vision research is in full bloom.", "sentence2": "events, feelings and many other kinds of concepts which can be visually grounded are not well represented in current datasets.", "label": "contrasting"}
{"id": "test_219", "sentence1": "On one hand, the inclusion of NC concepts would be an important step towards wide-coverage image semantic understanding.", "sentence2": "it also goes in the same direction as recent mul\u0002timodal language-vision approaches, e.g., mono\u0002and cross-lingual Visual Sense Disambiguation (Barnard and Johnson, 2005; Loeff et al., 2006; Saenko and Darrell, 2008; Gella et al., 2016, 2019).", "label": "contrasting"}
{"id": "test_220", "sentence1": "Our experiments show that both systems are reliable on our task, achieving precision and F1 scores that are over 70% on all the splits (see Table 2).", "sentence2": "the F-VLP model proves to be the most stable for the task.", "label": "contrasting"}
{"id": "test_221", "sentence1": "This accordance to some extent verifies that the neurons found through influence paths are functionally important.", "sentence2": "the t-values shown in Table 1 show that both neuron 125 and 337 are influential regardless of the subject number, whereas Lakretz et al. assign a subject number for each of these two neurons due to their disparate effect in lowering accuracy in ablation experiment.", "label": "contrasting"}
{"id": "test_222", "sentence1": "A slightly worse NA task performance (Lakretz et al., 2019) in cases of attractors (SP, PS) indicates that they interfere with prediction of the correct verb.", "sentence2": "we also observe that helpful nouns (SS, PP) contribute positively to the correct verb number (although they should not from a grammar perspective).", "label": "contrasting"}
{"id": "test_223", "sentence1": "In particular, in the largest setting with N = 1M, the BERT-24 embeddings distilled from the best-performing layer for each dataset drastically outperform both Word2Vec and GloVe.", "sentence2": "this can be seen as an unfair comparison given that we are selecting specific layers for specific datasets.", "label": "contrasting"}
{"id": "test_224", "sentence1": "As such, the validity of treating the resulting static embeddings as reliable proxies for the original contextualized model still remains open.", "sentence2": "human language processing has often been conjectured to have both context-dependent and context-independent properties (Barsalou, 1982; Rubio-Fernandez, 2008; Depraetere, 2014, 2019).", "label": "contrasting"}
{"id": "test_225", "sentence1": "We find that each of the tested word features can be encoded in contextual embeddings for other words of the sentence, often with perfect or nearperfect recoverability.", "sentence2": "we see substantial variation across encoders in how robustly each information type is distributed to which tokens.", "label": "contrasting"}
{"id": "test_226", "sentence1": "CheckList provides a framework for such techniques to systematically evaluate these alongside a variety of other capabilities.", "sentence2": "checkList cannot be directly used for non-behavioral issues such as data versioning problems (Amershi et al., 2019), labeling errors, annotator biases (Geva et al., 2019), worst-case security issues (Wallace et al., 2019), or lack of interpretability (Ribeiro et al., 2016).", "label": "contrasting"}
{"id": "test_227", "sentence1": "These experimental results show the critical role of triggers in dialogue-based relation extraction.", "sentence2": "trigger identification is perhaps as difficult as relation extraction, and it is labor-intensive to annotate large-scale datasets with triggers.", "label": "contrasting"}
{"id": "test_228", "sentence1": "RST Graph is constructed from RST parse trees over EDUs of the document.", "sentence2": "coreference Graph connects entities and their coreference clusters/mentions across the document.", "label": "contrasting"}
{"id": "test_229", "sentence1": "As observed in Louis et al. (2010), the RST tree structure already serves as a strong indicator for content selection.", "sentence2": "the agreement between rhetorical relations tends to be lower and more ambiguous.", "label": "contrasting"}
{"id": "test_230", "sentence1": "BERT is originally trained to encode a single sentence or sentence pair.", "sentence2": "a news article typically contains more than 500 words, hence we need to make some adaptation to apply BERT for document encoding.", "label": "contrasting"}
{"id": "test_231", "sentence1": "Because of the similarity to our task, we use a BERT-based neural network as the architecture for the coverage model.", "sentence2": "the coverage task differs from MLM in two ways.", "label": "contrasting"}
{"id": "test_232", "sentence1": "Just as with the Summarizer, by using a standardized architecture and model size, we can make use of pretrained models.", "sentence2": "it is important for Fluency to fine tune the language model on the target domain, so that the Summarizer is rewarded for generating text similar to target content.", "label": "contrasting"}
{"id": "test_233", "sentence1": "EMONET was conceived as a multiclass classification task for Plutchik-8 emotions (Abdul-Mageed and Ungar, 2017).", "sentence2": "we introduce binary classification tasks, one for each Plutchik-8 emotion.", "label": "contrasting"}
{"id": "test_234", "sentence1": "In our work, we raise similar concerns but through a different angle by highlighting issues with the evaluation procedure used by several recent methods. Chandrahas et al. (2018) analyze the geometry of KG embeddings and its correlation with task performance while Nayyeri et al. (2019) examine the effect of different loss functions on performance.", "sentence2": "their analysis is restricted to non-neural approaches.", "label": "contrasting"}
{"id": "test_235", "sentence1": "Several recently proposed methods report high performance gains on a particular dataset.", "sentence2": "their performance on another dataset is not consistently improved.", "label": "contrasting"}
{"id": "test_236", "sentence1": "Recently many reading comprehension datasets requiring complex and compositional reasoning over text have been introduced, including HotpotQA (Yang et al., 2018), DROP (Dua et al., 2019), Quoref , and ROPES (Lin et al., 2019).", "sentence2": "models trained on these datasets (Hu et al., 2019;Andor et al., 2019) only have the final answer as supervision, leaving the model guessing at the correct latent reasoning.", "label": "contrasting"}
{"id": "test_237", "sentence1": "Recent proposed approaches have made promising progress in dialogue state tracking (DST).", "sentence2": "in multi-domain scenarios, ellipsis and reference are frequently adopted by users to express values that have been mentioned by slots from other domains.", "label": "contrasting"}
{"id": "test_238", "sentence1": "Open vocabulary models show the promising performance in multidomain DST.", "sentence2": "ellipsis and reference phenomena among multi-domain slots are still less explored in existing literature.", "label": "contrasting"}
{"id": "test_239", "sentence1": "Some proposed solutions rely on leveraging knowledge distillation in the pre-training step, e.g., (Sanh et al., 2019), or used parameter reduction techniques (Lan et al., 2019) to reduce inference cost.", "sentence2": "the effectiveness of these approaches varies depending on the target task they have been applied to.", "label": "contrasting"}
{"id": "test_240", "sentence1": "This may be seen as a generalization of the ST approach, where the student needs to learn a simpler task than the teacher.", "sentence2": "our approach is significantly different from the traditional ST setting, which our preliminary investigation showed to be not very effective.", "label": "contrasting"}
{"id": "test_241", "sentence1": "These two dialogue-specific LM approaches, ULM and UOP, give very marginal improvement over the baseline models, that is rather surprising.", "sentence2": "they show good improvement when combined with UID, implying that pre-training language models may not be enough to enhance the performance by itself but can be effective when it is coupled with an appropriate fine-tuning approach.", "label": "contrasting"}
{"id": "test_242", "sentence1": "Recently, pretrained language representation models (Kocijan et al., 2019;Radford et al., 2019;Liu et al., 2019) have demonstrated significant improvements in both unsupervised and supervised settings.", "sentence2": "as these approaches treat the concept 'commonsense knowledge' as a black box, we are not clear about why they can do better (e.g., can these models understand commonsense or they just capture the statistical bias of the dataset) and do not know how to further improve them.", "label": "contrasting"}
{"id": "test_243", "sentence1": "For evaluation purposes, we may have labeled documents in the target language.", "sentence2": "they are only used during the test period.", "label": "contrasting"}
{"id": "test_244", "sentence1": "For the last layer before softmax, even though XLM-FT also generates reasonable representations to separate positive and negative reviews, the data points are scattered randomly.", "sentence2": "our model's output in the lower right panel of Figure 3 shows two more obvious clusters with corresponding labels that can be easily separated.", "label": "contrasting"}
{"id": "test_245", "sentence1": "This rating method, also known as Likert scale or Mean Opinion Score, is known to have two major drawbacks (Ye and Doermann, 2013): (1) Absolute rating is often treated as if it produces data on an interval scale.", "sentence2": "assessors rarely perceive labels as equidistant, thus producing only ordinal data.", "label": "contrasting"}
{"id": "test_246", "sentence1": "Overall, the Bradley-Terry model appears to be a promising candidate for our purposes: its robustness and statistical properties have been studied in great detail (Hunter, 2004), and it can be efficiently computed (Chen et al., 2013).", "sentence2": "an alternative offline sampling method has to be formulated, which we introduce in the following section.", "label": "contrasting"}
{"id": "test_247", "sentence1": "This can be generalized to higher step sizes s: for instance, if s = 2, all items that are separated by two positions around the ring are compared.", "sentence2": "this strategy suffers from the major drawback that for some step sizes, the resulting graph has multiple unconnected components, thus violating the restriction that the comparison matrix must form a strongly connected graph.", "label": "contrasting"}
{"id": "test_248", "sentence1": "Using a higher temperature yields a softer attention distribution.", "sentence2": "a sharper attention distribution might be more suitable for NER because only a few tokens in the sentence are named entities.", "label": "contrasting"}
{"id": "test_249", "sentence1": " In this work, we follow Chen et al. (2019) and use exactly the same functions.", "sentence2": "as shown in 7 (c), understanding this statement requires the function of difference time, which is not covered by the current set.", "label": "contrasting"}
{"id": "test_250", "sentence1": "Word-level attacking, which can be regarded as a combinatorial optimization problem, is a well-studied class of textual attack methods.", "sentence2": "existing word-level attack models are far from perfect, largely because unsuitable search space reduction methods and inefficient optimization algorithms are employed.", "label": "contrasting"}
{"id": "test_251", "sentence1": "Nonetheless, its attack validity rates against BiLSTM and BERT on SST-2 dramatically fall to 59.5% and 56.5%.", "sentence2": "ours are 70.5% and 72.0%, and their differences are significant according to the results of significance tests in Appendix D. In this section, we conduct detailed decomposition analyses of different word substitution methods (search space reduction methods) and different search algorithms, aiming to further demonstrate the advantages of our sememe-based word substitution method and PSO-based search algorithm.", "label": "contrasting"}
{"id": "test_252", "sentence1": "Mixed counting models that use the negative binomial distribution as the prior can well model over-dispersed and hierarchically dependent random variables; thus they have attracted much attention in mining dispersed document topics.", "sentence2": "the existing parameter inference method like Monte Carlo sampling is quite time-consuming.", "label": "contrasting"}
{"id": "test_253", "sentence1": "On the one hand, NVI-based models are fast and easy to estimate but hard to interpret.", "sentence2": "document modeling via mixed counting models is easy to interpret but difficult to infer.", "label": "contrasting"}
{"id": "test_254", "sentence1": "Such a framework learns the distribution of input data well, enabling it to combine with the traditional probability graphical models (e.g., LDA) and infer model parameters quickly (Srivastava and Sutton, 2017).", "sentence2": "how to effectively integrate the distributed dependencies in mixed counting models into the framework of variational inference is still quite a challenging problem.", "label": "contrasting"}
{"id": "test_255", "sentence1": "From these results, we can observe that the proportion of topics obtained by NB-NTM is close to the topic-word number distribution.", "sentence2": "gNB-NTM obtains more dispersed proportions of topics than NB-NTM.", "label": "contrasting"}
{"id": "test_256", "sentence1": "Everything was a point in a vector space, and everything about the nature of language could be learned from data.", "sentence2": "most computational linguists had linguistic theories and the poverty-of-thestimulus argument.", "label": "contrasting"}
{"id": "test_257", "sentence1": "And deep learning allows many aspects of these structured representations to be learned from data.", "sentence2": "successful deep learning architectures for natural language currently still have many handcoded aspects.", "label": "contrasting"}
{"id": "test_258", "sentence1": "(Alex et al., 2007) propose several different modeling techniques (layering and cascading) to combine multiple CRFs for nested NER.", "sentence2": "their approach cannot handle nested entities of the same entity type.", "label": "contrasting"}
{"id": "test_259", "sentence1": "Here, the two central entities (both indicate the city Liverpool) have similar sizes of neighborhoods and three common neighbors.", "sentence2": "the three common neighbors (indicate United Kingdom, England and Labour Party (UK), respectively) are not discriminative enough.", "label": "contrasting"}
{"id": "test_260", "sentence1": "Most similar to our work are (Chen et al., 2019)  and (Ghosh et al., 2019), as both studies are considered using the concept of question answering to address NLVL.", "sentence2": "both studies do not explain the similarity and differences between NLVL and traditional span-based QA, and they do not adopt the standard span-based QA framework.", "label": "contrasting"}
{"id": "test_261", "sentence1": "By treating input video as text passage, the above frameworks are all applicable to NLVL in principle.", "sentence2": "these frameworks are not designed to consider the differences between video and text passage.", "label": "contrasting"}
{"id": "test_262", "sentence1": "Figure 9 shows that VSLBase tends to predict longer moments, e.g., more samples with length error larger than 4 seconds in Charades-STA or 30 seconds in Activ-ityNet.", "sentence2": "constrained by QGH, VSLNet tends to predict shorter moments, e.g., more samples with length error smaller that -4 seconds in Charades-STA or -20 seconds in ActivityNet Caption.", "label": "contrasting"}
{"id": "test_263", "sentence1": "A very recent work makes use of attention over spans instead of syntactic distance to inject inductive bias to language models (Peng et al., 2019).", "sentence2": "the time complexity of injecting supervision is much higher than distancebased approach (O(n 2 ) VS O(n) ).", "label": "contrasting"}
{"id": "test_264", "sentence1": "For example, all punctuation symbols are removed, all characters are lower-cased, the vocabulary size is truncated at 10,000 and all sentences are concatenated.", "sentence2": "this version of PTB discards the parse tree structures, which makes it unsuitable for comparing sequential language models with those utilizing tree structures.", "label": "contrasting"}
{"id": "test_265", "sentence1": "Because of the sequential and parallel nature of our model, it can directly inherit and benefit from this set of tricks.", "sentence2": "it is non-trivial to use them for RNNG and URNNG.", "label": "contrasting"}
{"id": "test_266", "sentence1": "In particular, Kim et al. (2019a) report that unsupervised URNNG achieves 45.4 WSJ F1 in a similar setting, while another URNNG that finetunes a supervised RNNG model gives a much better F1 of 72.8, leading a 27.4 F1 improvement.", "sentence2": "the F1 of our structure prediction trees is 61.3 in unbiased algorithm.", "label": "contrasting"}
{"id": "test_267", "sentence1": "But this strategy does not consider that it is properly difficult to acquire a dictionary with high quality for a brand new domain.", "sentence2": "we develop a simple and efficient strategy to perform domain-specific words mining without any predefined dictionaries.", "label": "contrasting"}
{"id": "test_268", "sentence1": "In some languages, predicting declension class is argued to be easier if we know the noun's phonological form (Aronoff, 1992;Dressler and Thornton, 1996) or lexical semantics (Carstairs-McCarthy, 1994;Corbett and Fraser, 2000).", "sentence2": "semantic and phonological clues are, at best, only very imperfect hints as to class (Wurzel, 1989;Harris, , 1992Aronoff, 1992;Halle and Marantz, 1994;Corbett and Fraser, 2000;Aronoff, 2007).", "label": "contrasting"}
{"id": "test_269", "sentence1": "Until now, we have assumed a one-to-one mapping between paradigm slots and surface form changes.", "sentence2": "different EDIT TREES may indeed represent the same inflection.", "label": "contrasting"}
{"id": "test_270", "sentence1": "Our system, thus, needs to learn to apply the correct transformation for a combination of lemma and paradigm slot.", "sentence2": "mapping lemmas and paradigm slots to inflected forms corresponds exactly to the morphological inflection task, which has been the subject of multiple shared tasks over the last years (Cotterell et al., 2018).", "label": "contrasting"}
{"id": "test_271", "sentence1": "Systems for supervised or semi-supervised paradigm completion are commonly being evalu\u0002ated using word-level accuracy (Dreyer and Eisner, 2011; Cotterell et al., 2017).", "sentence2": "this is not possible for our task because our system cannot access the gold data paradigm slot descriptions and, thus, does not necessarily produce one word for each ground-truth inflected form.", "label": "contrasting"}
{"id": "test_272", "sentence1": "On the one hand, applying more than one iteration of additional lemma retrieval impacts the results only slightly, as those lemmas are assigned very small weights.", "sentence2": "we see performance differences > 2% between PCS-III-C and PCS-III-H for DEU, MLT, and SWE.", "label": "contrasting"}
{"id": "test_273", "sentence1": "All these approaches first find a set of semantically similar sentences.", "sentence2": "finding isolated similar sentences are not enough to construct a dialog utterances' paraphrase.", "label": "contrasting"}
{"id": "test_274", "sentence1": "Under the guidance of the reasoning chain, we learn a neural QG model to make the result satisfy the logical correspondence with the answer.", "sentence2": "the neural model is data-hungry, and the scale of training data mostly limits its performance.", "label": "contrasting"}
{"id": "test_275", "sentence1": "Recently, the character-word lattice structure has been proved to be effective for Chinese named entity recognition (NER) by incorporating the word information.", "sentence2": "since the lattice structure is complex and dynamic, most existing lattice-based models are hard to fully utilize the parallel computation of GPUs and usually have a low inference-speed.", "label": "contrasting"}
{"id": "test_276", "sentence1": "For example, queries \"red nike running shoes\", \"running nike shoes, red\" and \"red running shoes nike\" all refer to the same general product, despite differing in structure.", "sentence2": "item titles are structured, with brand, size, color, etc. all mentioned in a long sequence, which is also not how a conventional sentence is structured.", "label": "contrasting"}
{"id": "test_277", "sentence1": "In this case, Q gen is similar to Q in that the item is somewhat related to Q gen , and there's a chance that I may be matched to Q gen due to keyword stuffing by sellers, or poor semantic matching.", "sentence2": "another mismatched query Q gen = pizza cutter is not a good candidate to generate, since it's highly unlikely that a reasonable search engine will show shoes for a query about pizza cutters.", "label": "contrasting"}
{"id": "test_278", "sentence1": "Wu el al. (2019) applied dynamic convolutions using shared softmax-normalized filters of depth-wise on GLU-regulated inputs within a fixed reception field rather than global contexts, challenging the common self-attention-dominated intuition.", "sentence2": "all of the models, as mentioned earlier, adopt stacked CNNs rather than self-attention networks (SAN) to attend to the global contexts.", "label": "contrasting"}
{"id": "test_279", "sentence1": "It can be also quantified by other manners, e.g. estimating the data likelihood with Monte Carlo approximation (Der Kiureghian and Ditlevsen, 2009) or validating the translation dis\u0002tribution using a well-trained NMT model (Zhang et al., 2018).", "sentence2": "to these time-consuming techniques, LM marginally increases the computational cost and easy to be applied, conforming to the original motivation of CL.", "label": "contrasting"}
{"id": "test_280", "sentence1": "Since the speaker information is indispensable for coreference resolution, previous methods (Wiseman et al., 2016;Lee et al., 2017;Joshi et al., 2019a) usually convert the speaker information into binary features indicating whether two mentions are from the same speaker.", "sentence2": "we use a straightforward strategy that directly concatenates the speaker's name with the corresponding utterance.", "label": "contrasting"}
{"id": "test_281", "sentence1": "Comparing with existing models (Lee et al., 2017Joshi et al., 2019b), the proposed question answering formalization has the flexibility of retrieving mentions left out at the mention proposal stage.", "sentence2": "since we still have the mention proposal model, we need to know in which situation missed mentions could be retrieved and in which situation they cannot.", "label": "contrasting"}
{"id": "test_282", "sentence1": "The one-one target-source alignment 2(a) is the ideal condition of the projection.", "sentence2": "there could be many-to-one cases for the given words, leading to semantic role conflicts at the target language words.", "label": "contrasting"}
{"id": "test_283", "sentence1": "Metrics which measure the word-level overlap like BLEU (Papineni et al., 2002) have been widely used for dialogue evaluation.", "sentence2": "these metrics do not fit into our setting well as we would like to diversify the response generation with an external corpus, the generations will inevitably differ greatly from the ground-truth references in the original conversational corpus.", "label": "contrasting"}
{"id": "test_284", "sentence1": "The second class seeks to bring in extra information into existing corpus like structured knowledge (Zhao et al., 2018;Ghazvininejad et al., 2018;Dinan et al., 2019), personal information (Li et al., 2016b;Zhang et al., 2018a) or emotions (Shen et al., 2017b;Zhou et al., 2018).", "sentence2": "corpus with such annotations can be extremely costly to obtain and is usually limited to a specific domain with small data size.", "label": "contrasting"}
{"id": "test_285", "sentence1": "The user requests to book one ticket in the second example, yet both HDSA and Human Response ask about the number once again.", "sentence2": "our model directly answers the questions with correct information.", "label": "contrasting"}
{"id": "test_286", "sentence1": "One limitation of ReGAT (Li et al., 2019) lies in the fact that it solely consider the relations between objects in an image while neglect the importance of text information.", "sentence2": "our DC-GCN simultaneously capture visual relations in an image and textual relations in a question.", "label": "contrasting"}
{"id": "test_287", "sentence1": "Figure 6a shows that in terms of validation perplexity, MDR and FB perform very similarly across target rates.", "sentence2": "figure 6b shows that at the end of training the difference between the target rate and the validation rate is smaller for MDR.", "label": "contrasting"}
{"id": "test_288", "sentence1": "Previous conversational QA datasets provide the relevant document or passage that contain the answer of a query.", "sentence2": "in many real world scenarios such as FAQs, the answers need to be searched over the whole document collection.", "label": "contrasting"}
{"id": "test_289", "sentence1": "For instance, all the span-based QA datasets, except CQ (Bao et al., 2016), contain more than 100k samples.", "sentence2": "the data size of most existing MCQA datasets are far less than 100k (see Table 1), and the smallest one only contains 660 samples.", "label": "contrasting"}
{"id": "test_290", "sentence1": "On the one hand, technical proposals as pre-trained embeddings, finetuning, and end-to-end modeling, have advanced NLP greatly.", "sentence2": "neural advances often overlook MRL complexities, and disregard strategies that were proven useful for MRLs in the past.", "label": "contrasting"}
{"id": "test_291", "sentence1": "Document-level information extraction requires a global understanding of the full document to annotate entities, their relations, and their saliency.", "sentence2": "annotating a scientific article is timeconsuming and requires expert annotators.", "label": "contrasting"}
{"id": "test_292", "sentence1": "One common characteristic of most of the tasks is that the texts are not restricted to some rigid formats when generating.", "sentence2": "we may confront some special text paradigms such as Lyrics (assume the music score is given), Sonnet, SongCi (classical Chinese poetry of the Song dynasty), etc.", "label": "contrasting"}
{"id": "test_293", "sentence1": "Our model can still generate high quality results on the aspects of format, rhyme as well as integrity.", "sentence2": "for corpus Sonnet, even though the model can generate 14 lines text, the quality is not as good as SongCi due to the insufficient training-set (only 100 samples).", "label": "contrasting"}
{"id": "test_294", "sentence1": "Our relevance framework is partially inspired by the local components matching which we apply here to model the relevance of the components of the model's inputs.", "sentence2": "our work differs in several significant ways.", "label": "contrasting"}
{"id": "test_295", "sentence1": "VisualBERT and CMR have a similar cross-modality alignment approach.", "sentence2": "visualBERT only uses the Transformer representations while CMR uses the relevance representations.", "label": "contrasting"}
{"id": "test_296", "sentence1": "As we increase the number of layers in the visual Transformer and the cross-modality Transformer, it tends to improve accuracy.", "sentence2": "the performance becomes stable when there are more than five layers.", "label": "contrasting"}
{"id": "test_297", "sentence1": "An agent needs to perform a functional communication task in a natural language (in this work, English).", "sentence2": "examples of linguistic communication about this functional task are not available -the only natural language data that can be used consist of examples of generic natural language, which are not grounded in the functional task.", "label": "contrasting"}
{"id": "test_298", "sentence1": "Single-headed cross attention speeds up decoding: Despite removing learned self-attention from both the encoder and decoder, we did not observe huge efficiency or speed gains.", "sentence2": "reducing the source attention to just a single head results in more significant improvements.", "label": "contrasting"}
{"id": "test_299", "sentence1": "We do find that the largest improvement in WinoMT accuracy consistently corresponds to the model predicting male and female entities in the closest ratio (see Appendix A).", "sentence2": "the best ratios for models adapted to these datasets are 2:1 or higher, and the accuracy improvement is small.", "label": "contrasting"}
{"id": "test_300", "sentence1": "Ribeiro et al. (2018) test for comprehension of minimally modified sentences in an adversarial setup while trying to keep the overall semantics the same.", "sentence2": "we investigate large changes of meaning (negation) and context (mispriming).", "label": "contrasting"}
{"id": "test_301", "sentence1": "Clustering of such short text streams has thus gained increasing attention in recent years due to many real-world applications like event tracking, hot topic detection, and news recommendation (Hadifar et al., 2019).", "sentence2": "due to the unique properties of short text streams such as infinite length, evolving patterns and sparse data representation, short text stream clustering is still a big challenge (Aggarwal et al., 2003;Mahdiraji, 2009).", "label": "contrasting"}
{"id": "test_302", "sentence1": "The similarity-based text clustering approaches usually follow vector space model (VSM) to represent the cluster feature space (Din and Shao, 2020).", "sentence2": "a topic needs to be represented as the subspace of global feature space.", "label": "contrasting"}
{"id": "test_303", "sentence1": "Human judges show surprisingly inferior performance on user profiling tasks, grounding their judgement in topical stereotypes (Carpenter et al., 2017).", "sentence2": "albeit more accurate thanks to capturing stylistic variation elements, statistical models are prone to stereotype propagation as well (Costa-jussa et al., 2019; Koolen and van Cranenburgh, 2017).", "label": "contrasting"}
{"id": "test_304", "sentence1": "For the foreseeable future, legal decision-making will be the province of lawyers, not AI.", "sentence2": "one plausible use for MRC in a legal setting is as a screening tool for helping non-lawyers determine whether a case has enough merit to bother bringing in a lawyer.", "label": "contrasting"}
{"id": "test_305", "sentence1": "Recent work has shown gains by improving the distribution of masked tokens , the order in which masked tokens are predicted (Yang et al., 2019), and the available context for replacing masked tokens (Dong et al., 2019).", "sentence2": "these methods typically focus on particular types of end tasks (e.g. span prediction, generation, etc.), limiting their applicability.", "label": "contrasting"}
{"id": "test_306", "sentence1": "We aim, as much as possible, to control for differences unrelated to the pre-training objective.", "sentence2": "we do make minor changes to the learning rate and usage of layer normalisation in order to improve performance (tuning these separately for each objective).", "label": "contrasting"}
{"id": "test_307", "sentence1": "Bidirectional encoders are crucial for SQuAD As noted in previous work (Devlin et al., 2019), just left-to-right decoder performs poorly on SQuAD, because future context is crucial in classification decisions.", "sentence2": "bART achieves similar performance with only half the number of bidirectional layers.", "label": "contrasting"}
{"id": "test_308", "sentence1": "Unsurprisingly, model output is fluent and grammatical English.", "sentence2": "outputs are also highly abstractive, with few copied phrases.", "label": "contrasting"}
{"id": "test_309", "sentence1": "One of the issues in the original ON-LSTM is that the master gates and the model-based importance score for each word are only conditioned on the word itself and the left context encoded in the previous hidden state.", "sentence2": "in order to infer the importance for a word in the overall sentence effectively, it is crucial to have a view over the entire sentence (i.e., including the context words on the right).", "label": "contrasting"}
{"id": "test_310", "sentence1": "On the one hand, as GCN is directly dependent on the syntactic structures of the input sentences, it would not be able to learn effective representations for the sentences with new structures in the GCN-failure examples for RE.", "sentence2": "as CEON-LSTM only exploits a relaxed general form of the tree structures (i.e., the importance scores of the words), it will be able to generalize better to the new structures in the GCN-failure examples where the general tree form is still helpful to induce effective representations for RE.", "label": "contrasting"}
{"id": "test_311", "sentence1": "ELMo down-samples the outputs of its convolutional layers by max-pooling over the feature maps.", "sentence2": "this operation is not ideal to adapt to new morphological patterns from other languages as the model tends to discard patterns from languages other than English.", "label": "contrasting"}
{"id": "test_312", "sentence1": "The soft gazetteer features we propose instead take advantage of existing limited gazetteers and English knowledge bases using lowresource EL methods.", "sentence2": "to typical binary gazetteer features, the soft gazetteer feature values are continuous, lying between 0 and 1.", "label": "contrasting"}
{"id": "test_313", "sentence1": "In addition, CGExpan-NoCN outperforms most baseline models, meaning that the pre-trained LM itself is powerful to capture entity similarities.", "sentence2": "it still cannot beat CGExpan-NoFilter model, which shows that we can properly guide the set expansion process by incorporating generated class names.", "label": "contrasting"}
{"id": "test_314", "sentence1": "HINT proposes a ranking loss between humanbased importance scores (Das et al., 2016) and the gradient-based sensitivities.", "sentence2": "sCR does not require exact saliency ranks.", "label": "contrasting"}
{"id": "test_315", "sentence1": "As observed by Selvaraju et al. (2019) and as shown in Fig. 2, we observe small improvements on VQAv2 when the models are fine-tuned on the entire train set.", "sentence2": "if we were to compare against the improvements in VQA-CPv2 in a fair manner, i.e., only use the instances with visual cues while fine-tuning, then, the performance on VQAv2 drops continuously during the course of the training.", "label": "contrasting"}
{"id": "test_316", "sentence1": "In the original paper, Das et al. (2017) find that models which structurally encode dialog history, such as Memory Networks (Bordes et al., 2016) or Hierarchical Recurrent Encoders (Serban et al., 2017) improve performance.", "sentence2": "\"naive\" history modelling (in this case an encoder with late fusion/concatenation of current question, image and history encodings) might actually hurt performance.", "label": "contrasting"}
{"id": "test_317", "sentence1": "In this paper, we show that competitive results on VisDial can indeed be achieved by replicating the top performing model for VQA (Yu et al., 2019b) -and effectively treating visual dialog as multiple rounds of question-answering, without taking history into account.", "sentence2": "we also show that these results can be significantly improved by encoding dialog history, as well as by fine-tuning on a more meaningful retrieval metric.", "label": "contrasting"}
{"id": "test_318", "sentence1": "Other visual dialog tasks, such as GuessWhich? (Chattopadhyay et al., 2017) and GuessWhat?! (De Vries et al., 2017) take place in a goal-oriented setting, which according to Schlangen (2019), will lead to data containing more natural dialog phenomena.", "sentence2": "there is very limited evidence that dialog history indeed matters for these tasks (Yang et al., 2019).", "label": "contrasting"}
{"id": "test_319", "sentence1": "The combined features approach models the relationships between the different features explicitly, but the large target spaces for morphologically rich languages further increase sparsity.", "sentence2": "separate feature modeling guarantees smaller target spaces for the individual features, but the hard separation between the features prevents modeling any interfeature dependencies.", "label": "contrasting"}
{"id": "test_320", "sentence1": "The results are lower, both for MSA and EGY.", "sentence2": "the result for MSA is very close to the (Zalmout and Habash, 2017) baseline, which uses separate feature models (with the analyzer).", "label": "contrasting"}
{"id": "test_321", "sentence1": "Although increases exist across all domains, these are most prominent in domains like TC (+5.36) that have a low density of named entities and where indomain models have access to limited amounts of data.", "sentence2": "the in-domain performance is better than the pooled method of training, which shows consistent drops in performance on some domains (-8.69 on WB, -6.77 on BC, -1.98 on CoNLL), where information from other domains did not benefit the model.", "label": "contrasting"}
{"id": "test_322", "sentence1": "Our proposed model architecture takes 0.15 ms (33% increase) longer for inference than InDomain or PoolDomain models, which is a result of more model parameters.", "sentence2": "our proposed architecture is still 0.19 ms faster than using the InDomain+DomainClassifier approach.", "label": "contrasting"}
{"id": "test_323", "sentence1": "State-of-the-art approaches for attribute value extraction (Zheng et al., 2018; Xu et al., 2019; Rezk et al., 2019) have employed deep learning to capture features of product attributes effectively for the extraction purpose.", "sentence2": "they are all designed without considering the product categories and thus cannot effectively capture the diversity of categories across the product taxonomy.", "label": "contrasting"}
{"id": "test_324", "sentence1": "The CT and CAT models learn to map source code and natural language tokens into a joint embedding space such that semantically similar code-natural language pairs are projected to vectors that are close to each other.", "sentence2": "these two representations interact only in the final step when the global similarity of the sequence embeddings is calculated, but not during the first step when each sequence is encoded into its corresponding embedding.", "label": "contrasting"}
{"id": "test_325", "sentence1": "Currently, the TClda are trained on student essays, while the TCpr only works on the source article.", "sentence2": "TCattn uses both student essays and the source article for TC generation.", "label": "contrasting"}
{"id": "test_326", "sentence1": "Entity linking systems consider three sources of information: 1) similarity between mention strings and names for the KB entity; 2) comparison of the document con\u0002text to information about the KB entity (e.g. entity description); 3) information contained in the KB, such as entity popularity or inter-entity relations", "sentence2": "to the dense KBs in entity linking, concept linking uses sparse ontologies, which contain a unique identifier (CUI), title, and links to synonyms and related concepts, but rarely longform text.", "label": "contrasting"}
{"id": "test_327", "sentence1": "We ran experiments that padded the names with synonyms or other forms of available text within the knowledge base.", "sentence2": "we did not see consistent improvements.", "label": "contrasting"}
{"id": "test_328", "sentence1": "Depending on the application, a less accurate but faster linker might be a better choice (e.g. for all clinical notes at a medical institution).", "sentence2": "a more complex linker, such as ours, maybe a better option for specific subsets of notes that require better accuracy (e.g., the results of specific clinical studies).", "label": "contrasting"}
{"id": "test_329", "sentence1": "In natural language processing, Natural Language Inference (NLI)-a task whereby a system determines whether a pair of sentences instantiates in an entailment, a contradiction, or a neutral relation-has been useful for training and evaluating models on sentential reasoning.", "sentence2": "linguists and philosophers now recognize that there are separate semantic and pragmatic modes of reasoning (Grice, 1975; Clark, 1996; Beaver, 1997; Horn and Ward, 2004; Potts, 2015), and it is not clear which of these modes, if either, NLI models learn", "label": "contrasting"}
{"id": "test_330", "sentence1": "For example, the Independent model will produce identical scores for each output label, if it chooses to completely ignore the input explanations.", "sentence2": "the model is still free to learn a different kind of bias which is an outcome of the fact that natural language explanations convey ideas through both content and form.", "label": "contrasting"}
{"id": "test_331", "sentence1": "The results demonstrate a much weaker link between NILE-NS's predictions and associated explanations.", "sentence2": "nILE behaves more expectedly.", "label": "contrasting"}
{"id": "test_332", "sentence1": "This led folk wisdom to suggest that modeling higher-order features in a neural parser would not bring additional advantages, and nearly all recent research on dependency parsing was restricted to first-order models (Dozat and Manning, 2016; Smith et al., 2018a). Kulmizev et al. (2019) further reinforced this belief comparing transition and graph-based decoders (but none of which higher order); Falenska and Kuhn (2019) suggested that higher-order features become redundant because the parsing models encode them implicitly.", "sentence2": "there is some evidence that neural parsers still benefit from structure modeling.", "label": "contrasting"}
{"id": "test_333", "sentence1": "This approach, named adversarial training (AT), has been reported to be highly effective on image classification (Goodfellow et al., 2015), text classification (Miyato et al., 2017), as well as sequence labeling (Yasunaga et al., 2018).", "sentence2": "aT is limited to a supervised scenario, which uses the labels to compute adversarial losses.", "label": "contrasting"}
{"id": "test_334", "sentence1": "To apply the conventional VAT on a model with CRF, one can calculate the KL divergence on the label distribution of each token between the original examples and adversarial examples.", "sentence2": "it is sub-optimal because the transition probabilities are not taken into account.", "label": "contrasting"}
{"id": "test_335", "sentence1": "VAT achieved state-of-the-art performance for image classification tasks (Miyato et al., 2019), and proved to be more efficient than traditional semi-supervised approaches, such as entropy minimization (Grandvalet and Bengio, 2004) and selftraining (Yarowsky, 1995), from a recent study (Oliver et al., 2018).", "sentence2": "despite the successful applications on text classification (Miyato et al., 2017), VAT has not shown great benefits to semi-supervised sequence labeling tasks, due to its incompatibility with CRF.", "label": "contrasting"}
{"id": "test_336", "sentence1": "With multiple layers, SpellGCN can aggregate the information in more hops and therefore, achieve better performance.", "sentence2": "the F1score drops when the number of layers is larger than 3.", "label": "contrasting"}
{"id": "test_337", "sentence1": "The evident way to construct a corpus with NL questions and their corresponding OT queries would consist of two main parts: first, collect a set of NL questions, and then create the corresponding OT queries to these questions.", "sentence2": "this approach is very time-consuming and has a major issue.", "label": "contrasting"}
{"id": "test_338", "sentence1": "On the other hand, LC-QuaD 2.0 contains an average of 2 hops (equivalent to two joins in relational databases) per query, which lies in the nature of graph database queries that are optimized for handling queries that range over multiple triple patterns.", "sentence2": "lC-QuaD 2.0 lacks complexity when considering more complex components (e.g., Group By, Set-Operation, etc.).", "label": "contrasting"}
{"id": "test_339", "sentence1": "Table 2 is a comparison of existing English MWP corpora.", "sentence2": "these existing corpora are either limited in terms of the diversity of the associated problem types (as well as lexicon usage patterns), or lacking information such as difficulty levels.", "label": "contrasting"}
{"id": "test_340", "sentence1": "Likewise, we could also enlarge the training-set by duplicating MWPs without affecting the CLD value against the test-set.", "sentence2": "it would be also meaningless as no new information would be provided.", "label": "contrasting"}
{"id": "test_341", "sentence1": "Because this type of evaluation is typically task-specific, it can be conducted in multilingual settings.", "sentence2": "training a range of task-specific multilingual models might require significant resources, namely, training time and computational power.", "label": "contrasting"}
{"id": "test_342", "sentence1": "Typelevel probing tasks have the advantage of containing less bias (domain, annotator, and majority class); whereas token-level tests might be sensitive to the domain biases from the underlying full-text data.", "sentence2": "token-level tests have the advantage of being more lexically diverse; whereas type-level tasks can be less diverse for some languages like Spanish, French, and English.", "label": "contrasting"}
{"id": "test_343", "sentence1": "Unlike previously introduced embedding models, ELMo provides contextualized embeddings, that is, the same words would have different representations when used in different contexts.", "sentence2": "our probing tests are type-level (as opposed to token-level), thus we only use the representations generated independently per each token both for the intrinsic and extrinsic experiments.", "label": "contrasting"}
{"id": "test_344", "sentence1": "Another potential reason for the difference in ranking is the domain of the data underlying the respective data sets: For the majority of the languages, POS, DEP, and SRL data originates from the same treebanks and has gold (expert) annotations.", "sentence2": "nER and XnLI data sets are generally compiled from a different, and often diverse set of resources.", "label": "contrasting"}
{"id": "test_345", "sentence1": "The abstract syntax can be vastly different in domains ranging from mathematics to tourist phrasebooks.", "sentence2": "the linguistic mechanisms needed in the concrete syntax-morphology, agreement, word order-are largely the same in all areas of discourse.", "label": "contrasting"}
{"id": "test_346", "sentence1": "For this purpose, it is enough to express all desired content in one way: One does not need to cover all possible ways to express things.", "sentence2": "in wide-coverage parsing, this is a serious limitation.", "label": "contrasting"}
{"id": "test_347", "sentence1": "This led to a series of extensions as described in Section 4.5, first meant to cover the missing English structures.", "sentence2": "if the ultimate goal is to build an interlingual grammar, the structures designed for English are not necessarily adequate for other languages-in particular, they might not allow for compositional linearizations.", "label": "contrasting"}
{"id": "test_348", "sentence1": "There, every synset corresponds to one abstract function and then the function's linearization in each language produces all words in the language as variants.", "sentence2": "a more detailed analysis shows that this is not ideal.", "label": "contrasting"}
{"id": "test_349", "sentence1": "Our focus in this paper has been on recognizing valid chains of reasoning, assuming a retrieval step that retrieves a reasonable pool of candidates to start with (Section 3.2).", "sentence2": "the retrieval step itself is not perfect: For QASC, designed so that at least one valid chain always exists, the retrieved pool of 10 contains no valid chains for 24% of the questions (upper bound in Table 2), capping the overall system's performance.", "label": "contrasting"}
{"id": "test_350", "sentence1": "Multitask learning (Caruana, 1997;Collobert and Weston, 2008) seeks to learn a single model that can solve multiple tasks simultaneously, similar to our framework that seeks to learn a model that can solve many tasks.", "sentence2": "in multitask learning each task is learned from examples, and the model is not able to generalize to unseen tasks.", "label": "contrasting"}
{"id": "test_351", "sentence1": "Attribution of natural disasters/collective misfortune is a widely-studied political science problem.", "sentence2": "such studies typically rely on surveys, expert opinions, or external signals such as voting outcomes.", "label": "contrasting"}
{"id": "test_352", "sentence1": "For instance, the most-recent PEW survey (Pew) focused on India was conducted in 2018 on only 2,521 users.", "sentence2": "our data set consists of comments from 43,859 users.", "label": "contrasting"}
{"id": "test_353", "sentence1": "We observe that, on the detection task, all the BERT based models perform similarly.", "sentence2": "on the resolution task, the F1 score substantially improves as we keep adding sophistication to our model architecture.", "label": "contrasting"}
{"id": "test_354", "sentence1": "Third, a more comprehensive evaluation methodology would consider both the exact-match accuracy and the execution-match accuracy, because two logic forms can be semantically equivalent yet do not match precisely in their surface forms.", "sentence2": "as shown in Table 1, most existing work is only evaluated with the exact-match accuracy.", "label": "contrasting"}
{"id": "test_355", "sentence1": "Consequently, the execution engines of domain-specific MRs need to be significantly customized for different domains, requiring plenty of manual efforts.", "sentence2": "sQL is a domain-general MR for querying relational databases.", "label": "contrasting"}
{"id": "test_356", "sentence1": "There is a predicate tomorrow in all three domainspecific MRs, and this predicate can directly align to the description in the utterance.", "sentence2": "one needs to explicitly express the concrete date values in the SQL query; this requirement can be a heavy burden for neural approaches, especially when the values will change over time.", "label": "contrasting"}
{"id": "test_357", "sentence1": "Unfortunately, this integral is intractable due to the complex relationship between X and Z.", "sentence2": "related latent variable models like variational autoencoders (VAEs; Kingma and Welling (2013)) learn by optimizing a variational lower bound on the log marginal likelihood.", "label": "contrasting"}
{"id": "test_358", "sentence1": "For instance, we could feed both sentences into the semantic encoder and pool their representations.", "sentence2": "in practice we find that alternating works well and also can be used to obtain sentence embeddings for text that is not part of a translation pair.", "label": "contrasting"}
{"id": "test_359", "sentence1": "This model is similar to Infersent (Conneau et al., 2017) in that it is trained on natural language inference data, SNLI (Bowman et al., 2015).", "sentence2": "instead of using pretrained word embeddings, they fine-tune BERT in a way to induce sentence embeddings.", "label": "contrasting"}
{"id": "test_360", "sentence1": "Since BGT W/O LANGVARS also has significantly better performance on these tasks, most of this gain seems to be due to the prior having a regularizing effect.", "sentence2": "bGT outperforms bGT W/O LANGVARS overall, and we hypothesize that the gap in performance between these two models is due to bGT being able to strip away the language-specific information in the representations with its languagespecific variables, allowing for the semantics of the sentences to be more directly compared.", "label": "contrasting"}
{"id": "test_361", "sentence1": "Japanese is a very distant language to English both in its writing system and in its sentence structure (it is an SOV language, where English is an SVO language).", "sentence2": "despite these difference, the semantic encoder strongly outperforms the English language-specific encoder, suggesting that the underlying meaning of the sentence is much better captured by the semantic encoder.", "label": "contrasting"}
{"id": "test_362", "sentence1": "We can observe that the inherent data imbalance problem also exists in MAVEN.", "sentence2": "as MAVEN is large-scale, 41% and 82% event types have more than 500 and 100 instances respectively.", "label": "contrasting"}
{"id": "test_363", "sentence1": "Most recently, continuous improvements have been achieved by combining multiple kinds of information in KGs or using more sophisticated embedding models.", "sentence2": "the performances of most approaches are still not satisfactory.", "label": "contrasting"}
{"id": "test_364", "sentence1": "To generate the PCG of two KGs, we can first pair all the entities from two KGs as nodes, and then use Equation 1 to generate edges between nodes.", "sentence2": "kGs usually contain large number of entities, the PCG of two large-scale kGs will contain huge number of nodes.", "label": "contrasting"}
{"id": "test_365", "sentence1": "Recent studies on single-document summarization (SDS) benefit from the advances in neural sequence learning (Nallapati et al., 2016;See et al., 2017;Chen and Bansal, 2018;Narayan et al., 2018) as well as pretrained language models (Liu and Lapata, 2019;Lewis et al., 2019;Zhang et al., 2020) and make great progress.", "sentence2": "in multi-document summarization (MDS) tasks, neural models are still facing challenges and often underperform classical statistical methods built upon handcrafted features (Kulesza and Taskar, 2012).", "label": "contrasting"}
{"id": "test_366", "sentence1": "One extension (Cho et al., 2019) of these studies uses capsule networks (Hinton et al., 2018) to improve redundancy measures.", "sentence2": "its capsule networks are pre-trained on SDS and fixed as feature inputs of classical methods without end-to-end representation learning.", "label": "contrasting"}
{"id": "test_367", "sentence1": "Compared to hard cutoff, our soft attention favors top-ranked candidates of the sentence ranker (MMR).", "sentence2": "it does not discard low-ranked ones, as the ranker is imperfect, and those sentences ranked low may also contribute to a high-quality summary.", "label": "contrasting"}
{"id": "test_368", "sentence1": "RL-MMR has a more salient and non-redundant summary, as it is end-to-end trained with advances in SDS for sentence representation learning while maintaining the benefits of classical MDS approaches.", "sentence2": "mmR alone only considers lexical similarity; The redundancy mea-sure in DPP-Caps-Comb is pre-trained on one SDS dataset with weak supervision and fixed during the training of DPP.", "label": "contrasting"}
{"id": "test_369", "sentence1": "The authors considered several predefined probe architectures and picked one of them based on a manually defined criterion.", "sentence2": "the variational code gives probe architecture as a byproduct of training and does not need human guidance.", "label": "contrasting"}
{"id": "test_370", "sentence1": "To this day, scientific publications still serve as a fundamental fixed-domain benchmark for neural KPE methods (Meng et al., 2017;Alzaidy et al., 2019;Sahrawat et al., 2019) due to the availability of ample data of this kind.", "sentence2": "experiments have revealed that KPE methods trained directly on such corpora do not generalize well to other web-related genres or other types of documents (Chen et al., 2018;Xiong et al., 2019), where there may be far more heterogeneity in topics, content and structure, and there may be more variation in terms of where a key phrase may appear.", "label": "contrasting"}
{"id": "test_371", "sentence1": "Case #2 shows a similar situation where the model with visual features finds the proper keyphrases that are much larger in font size, while the text-only model selects nouns elsewhere.", "sentence2": "case #3 demonstrates a typical kind of web page where visual features can be misleading: an indexing page.", "label": "contrasting"}
{"id": "test_372", "sentence1": "As a result, the relationships between entities are not captured.", "sentence2": "since KB is naturally a graph structure (nodes are entities and edges are relations between entities).", "label": "contrasting"}
{"id": "test_373", "sentence1": "Moreover, structural knowledge such as dependency relationships has recently been investigated on some tasks (e.g., relation extraction) (Peng et al., 2017;Song et al., 2018) and shown to be effective in the model's generalizability.", "sentence2": "such dependency relationships (essentially also graph structure) have not been explored in dialogue systems, again missing great potential for improvements.", "label": "contrasting"}
{"id": "test_374", "sentence1": "different predecessors in H ) should have different impacts on the output hidden state h t , and we expect our model to capture that.", "sentence2": "the inputs may have different number of predecessors at different timesteps.", "label": "contrasting"}
{"id": "test_375", "sentence1": "We can observe that our model without the graph encoder has a 1.6% absolute value loss (over 25% in ratio) in BLEU score and a 1.1% absolute value loss (9.8% in ratio) in entity F1 on MultiWOZ 2.1, which suggests that the overall quality of the generated sentences are better improved by our graph encoder.", "sentence2": "ours without knowledge graph means that we do not use the graph structure to store and retrieve the external knowledge data.", "label": "contrasting"}
{"id": "test_376", "sentence1": "These systems rely on offline (batch) training and have drawn recent criticism due to their inability to adapt to new contexts (Linzen, 2020).", "sentence2": "humans acquire language from evolving environments, require a small memory footprint (Mc-Clelland et al., 1995), and can generalize their knowledge to newer tasks (Sprouse et al., 2013).", "label": "contrasting"}
{"id": "test_377", "sentence1": "However, these works are mainly designed for image classification tasks where the training data has \"clear\" task boundaries-i.e., training stream are partitioned into disjoint subsequences.", "sentence2": "task boundaries in VisCOLL are unknown and \"smooth\" (i.e., with gradual transitions between tasks)-a setting that is closer to real-world situations.", "label": "contrasting"}
{"id": "test_378", "sentence1": "In particular, Li et al. (2020) study a closely related task of continual learning of sequence prediction for synthetic instruction following", "sentence2": "their techniques for separating semantics and syntax is restricted to text-only case.", "label": "contrasting"}
{"id": "test_379", "sentence1": "Prior work uses only the article content and metadata including title, date, domain, and authors.", "sentence2": "news articles often contain photos and captions as well.", "label": "contrasting"}
{"id": "test_380", "sentence1": "Despite the fact that leveraging metadata significantly improves the performance of Grover, it also appears that the accuracy does not vary much with the exclusion of different types of metadata.", "sentence2": "we observe a surprising observation that leveraging all metadata causes the detection accuracy to decrease.", "label": "contrasting"}
{"id": "test_381", "sentence1": "Todd Frazier's sacrifice fly accounted for the first run before Jose Bautista drove in the next two with a line drive RBI single to right, and a bases-loaded single by Todd Frazier also scored a run.", "sentence2": "deJong and Bader homered off Bobby Wahl to begin the Cardinals' comeback.", "label": "contrasting"}
{"id": "test_382", "sentence1": "Each sub-problem is worthy of being standardized and continually studied given a well defined objective and data sets so that the performance could be fairly evaluated and the progress can be continually made.", "sentence2": "it is not easy in the current methodology, since each pipeline's strategies are closely bonded to own implementation.", "label": "contrasting"}
{"id": "test_383", "sentence1": "Finetuning a pretrained language model (Dai and Le, 2015;Howard and Ruder, 2018) often delivers competitive performance partly because pretraining leads to a better initialization across various downstream tasks than training from scratch (Hao et al., 2019).", "sentence2": "finetuning on individual NLP tasks is not parameter-efficient.", "label": "contrasting"}
{"id": "test_384", "sentence1": "Mallya et al. (2018) explicitly update weights in a task-specific classifier layer.", "sentence2": "we show that end-to-end learning of selective masks, consistently for both the pretrained language model and a randomly initialized classifier layer, achieves good performance.", "label": "contrasting"}
{"id": "test_385", "sentence1": "Large-scale training datasets lie at the core of the recent success of neural machine translation (NMT) models.", "sentence2": "the complex patterns and potential noises in the large-scale data make training NMT models difficult.", "label": "contrasting"}
{"id": "test_386", "sentence1": "Neural machine translation (NMT) is a data-hungry approach, which requires a large amount of data to train a well-performing NMT model (Koehn and Knowles, 2017).", "sentence2": "the complex patterns and potential noises in the large-scale data make training NMT models difficult.", "label": "contrasting"}
{"id": "test_387", "sentence1": "Another stream is to schedule the order of training examples according to their difficulty, e.g., curriculum learning which has been applied to the training of NMT models successfully (Kocmi and Bojar, 2017; Zhang et al., 2018; Platanios et al., 2019; Liu et al., 2020b).", "sentence2": "we explore strategies to simplify the difficult (i.e., inactive) examples without changing the model architecture and model training strategy.", "label": "contrasting"}
{"id": "test_388", "sentence1": "For the latter, NMT models tend to prefer a more typical alternative to a relatively rare but correct one (e.g., French \"Il\" is often wrongly translated to the more common \"it\" than \"he\" ).", "sentence2": "However, these seemingly trivial errors can erode translation to the extent that they can be easily distinguishable from human-translated texts (Laubli et al. \u00a8 , 2018).", "label": "contrasting"}
{"id": "test_389", "sentence1": "Both of the discriminative losses essentially promote the probability of the positive (i.e., correct) sample.", "sentence2": "the intuition behind using the additional loss over the standard loss is that the fine-tuning here focuses on improving the positive sample over the negative sample that the model has learnt to produce, rather than over the entire probability distribution over the full vocabulary.", "label": "contrasting"}
{"id": "test_390", "sentence1": "In the second example, we observe a biased anticipation  case where the NMT system had to emit a wrong translation chien ('dog') before seeing the noun 'bird'.", "sentence2": "the multimodal model successfully leveraged the visual context for anticipation and correctly handled the adjective-noun placement phenomenon.", "label": "contrasting"}
{"id": "test_391", "sentence1": "Our approach is most similar to Bjerva et al. (2019a), as they build a generative model from typological features and use language embeddings, extracted from factored language modelling at character-level, as a prior of the model to extend the language coverage.", "sentence2": "our method primarily differs as it is mainly based in linear algebra, encodes information from both sources since the beginning, and can deal with a small number of shared entries (e.g. 23 from LW) to compute robust representations.", "label": "contrasting"}
{"id": "test_392", "sentence1": "We work with 53 languages pre-processed by (Qi et al., 2018), from where we mapped the ISO 639-1 codes to the ISO 693-2 standard.", "sentence2": "we need to manually correct the mapping of some codes to identify the correct language vector in the URIEL (Littell et al., 2017) library: \u2022 zh (zho , Chinese macro-language) mapped to cmn (Mandarin Chinese).", "label": "contrasting"}
{"id": "test_393", "sentence1": "In German, we reach the maximum 0.41 when the number of words in each topic equals 2, and the minimum when it equals 100.", "sentence2": "we observe the most noticeable changes when we vary the number of topics in French (Ousidhoum et al., 2019) such that B 1 = 0.34 when |T| = 2 versus 0.21 when |T| = 7 and back to 0.37 when |T| = 100.", "label": "contrasting"}
{"id": "test_394", "sentence1": "On the other hand, we observe the most noticeable changes when we vary the number of topics in French (Ousidhoum et al., 2019) such that B 1 = 0.34 when |T| = 2 versus 0.21 when |T| = 7 and back to 0.37 when |T| = 100.", "sentence2": "we remark overall cohesion despite the change in topic numbers especially in the case of Italian and Portuguese caused by the limited numbers of search keywords, that equal 5 and 7 respectively.", "label": "contrasting"}
{"id": "test_395", "sentence1": "Waseem and Hovy (2016), Founta et al. (2018) and Ousidhoum et al. (2019) report using different keywords and hashtags to collect tweets.", "sentence2": "the scores shown in Table 4 indicate that the datasets might carry similar meanings, specifically because WUP relies on hypernymy rather than common vocabulary use.", "label": "contrasting"}
{"id": "test_396", "sentence1": "On the other hand, the copy model (row 3) significantly improves the BLEU scores by 36.2-37.6 points, by learning to re-use words in input texts 4 .", "sentence2": "it still suffers the small data size, and its outputs are worse than the original questions without any transformation (row 1).", "label": "contrasting"}
{"id": "test_397", "sentence1": "For system-level evaluation, metrics which can use the reference translations for quality estimation, such as BLEU, generally achieved consistently high correlation with human evaluation for all language pairs.", "sentence2": "qE models (including our qE model and submitted systems for the qE as a Metric task) are not allowed to use the reference translations for quality estimation and tend to generate more unstable results: high correlation with human evaluation for some language pairs but very low or even negative Pearson correlation with human evaluation for some other language pairs.", "label": "contrasting"}
{"id": "test_398", "sentence1": "As a sequence-to-sequence generation task, neural machine translation (NMT) naturally contains intrinsic uncertainty, where a single sentence in one language has multiple valid counterparts in the other.", "sentence2": "the dominant methods for NMT only observe one of them from the parallel corpora for the model training but have to deal with adequate variations under the same meaning at inference.", "label": "contrasting"}
{"id": "test_399", "sentence1": "Recently, there are increasing number of studies investigating the effects of quantifying uncertainties in different applications Kendall and Gal, 2017;Xiao and Wang, 2018;Zhang et al., 2019b,a;Shen et al., 2019).", "sentence2": "most work in NMT has focused on improving accuracy without much consideration for the intrinsic uncertainty of the translation task itself.", "label": "contrasting"}
{"id": "test_400", "sentence1": "when h tends to 0 our controlled sampling method achieves lowest BLEU scores but highest edit distances.", "sentence2": "if we increase h gradually, it can be quickly simplified to greedy search.", "label": "contrasting"}
{"id": "test_401", "sentence1": "A sequence-to-sequence (seq2seq) learning with neural networks empirically shows to be an effective framework for grammatical error correction (GEC), which takes a sentence with errors as input and outputs the corrected one.", "sentence2": "the performance of GEC models with the seq2seq framework heavily relies on the size and quality of the corpus on hand.", "label": "contrasting"}
{"id": "test_402", "sentence1": "The former applies text editing operations such as substitution, deletion, insertion and shuffle, to introduce noises into original sentences, and the latter trains a clean-to-noise model for error generation.", "sentence2": "the noise-corrupted sentences are often poorly readable, which are quite different from those made by humans.", "label": "contrasting"}
{"id": "test_403", "sentence1": "Once a vulnerable position is determined, the token at that position is usually replaced with one of its synonyms.", "sentence2": "generating adversarial examples through such synonym-based replacement is no longer applicable to the GEC task.", "label": "contrasting"}
{"id": "test_404", "sentence1": "Adversarial training by means of adding the adversarial examples into the training set can effectively improve the models' robustness.", "sentence2": "some studies show that the models tend to overfit the noises, and the accuracy of the clean data will drop if the number of adversarial examples dominates the training set.", "label": "contrasting"}
{"id": "test_405", "sentence1": "Indeed, LDA implicitly assumes that \u03a8\u00a8 = Unif(1, .., K) deterministically-i.e., that every topic is assumed a priori to contain the same number of tokens.", "sentence2": "the HDP model learns this distribution from the data by letting \u03a8 \u223c GEM(\u03b3).", "label": "contrasting"}
{"id": "test_406", "sentence1": "Semisupervised methods that utilize such external corpora have been successful in English STS.", "sentence2": "the need for external corpora is a major obstacle when applying STS, a fundamental technology, to low-resource languages.", "label": "contrasting"}
{"id": "test_407", "sentence1": "One particularly promising usage of BERT-based models for unsupervised STS is BERTScore , which was originally proposed as an automatic evaluation metric.", "sentence2": "our preliminary experiments 17 show that BERTScore performs poorly on unsupervised STS.", "label": "contrasting"}
{"id": "test_408", "sentence1": "From the figure, we find that overall the average accuracy raises when K increases from 2 to 8, which suggests the importance of disentangling components.", "sentence2": "when K grows larger than 8, the performance starts to decline.", "label": "contrasting"}
{"id": "test_409", "sentence1": "As shown in Figure 6(b), except for the case of n = 1, the other settings have comparable performance.", "sentence2": "it can be seen that when n = 4, the average accuracy on the last task is the highest, which indicates that the model has the strongest ability to avoid catastrophic forgetting problem when n = 4.", "label": "contrasting"}
{"id": "test_410", "sentence1": "The subproblems are separately solved using existing techniques.", "sentence2": "existing unsupervised multilingual approaches (Chen and Cardie, 2018;Heyman et al., 2019;Alaux et al., 2019) solve the above subproblems jointly.", "label": "contrasting"}
{"id": "test_411", "sentence1": "We also observe that UMWE fails at mapping Dutch language embeddings in the multilingual space even though Dutch is close to English.", "sentence2": "in a separate bilingual experiment, UMWE learns an effective English-Dutch crosslingual space (obtaining an average en-nl and nl-en score of 75.2).", "label": "contrasting"}
{"id": "test_412", "sentence1": "We observe that the proposed SL-GeoMM learns a highly effective multilingual space and obtains the best overall result, illustrating its robustness in this challenging setting.", "sentence2": "other multilingual approaches fail to learn a reasonably good multilingual space.", "label": "contrasting"}
{"id": "test_413", "sentence1": "In recent years, pre-trained language models, such as GPT (Radford et al., 2018), BERT (Devlin et al., 2018), XL-Net (Yang et al., 2019), have been proposed and applied to many NLP tasks, yielding state-of-the-art performances.", "sentence2": "the promising results of the pre-trained language models come with the high costs of computation and memory in inference, which obstruct these pre-trained language models to be deployed on resource-constrained devices and real-time applications.", "label": "contrasting"}
{"id": "test_414", "sentence1": "Concretely, both the embedding-layer distillation and the prediction-layer distillation employ the one-to-one layer mapping as in TinyBERT and BERT-PKD, where the two student layers are guided by the corresponding teacher layers, respectively.", "sentence2": "different from the previous works, we propose to exploit the many-to-many layer mapping for Transformer (intermediate lay-ers) distillation (attention-based distillation and hidden states based distillation), where each student attention layer (resp. hidden layers).", "label": "contrasting"}
{"id": "test_415", "sentence1": "In this paper, we compare our BERT-EMD with several state-of-the-art BERT compression approaches, including the original 4/6-layer BERT models (Devlin et al., 2018), DistilBERT (Tang et al., 2019), BERT-PKD , Tiny-BERT (Jiao et al., 2019), BERT-of-Theseus (Xu et al., 2020).", "sentence2": "the original TinyBERT employs a data augmentation strategy in the training process, which is different from the other baseline models.", "label": "contrasting"}
{"id": "test_416", "sentence1": "Previous works have shown that as the number of retrieved passages increases, so does the performance of the reader.", "sentence2": "they assume all retrieved passages are of equal importance and allocate the same amount of computation to them, leading to a substantial increase in computational cost.", "label": "contrasting"}
{"id": "test_417", "sentence1": "Open-Domain Question Answering (ODQA) requires a system to answer questions using a large collection of documents as the information source.", "sentence2": "to context-based machine comprehension, where models are to extract answers from single paragraphs or documents, it poses a fundamental technical challenge in machine reading at scale (Chen et al., 2017) .", "label": "contrasting"}
{"id": "test_418", "sentence1": "Models for reading comprehension (RC) commonly restrict their output space to the set of all single contiguous spans from the input, in order to alleviate the learning problem and avoid the need for a model that generates text explicitly.", "sentence2": "forcing an answer to be a single span can be restrictive, and some recent datasets also include multi-span questions, i.e., questions whose answer is a set of non-contiguous spans in the text.", "label": "contrasting"}
{"id": "test_419", "sentence1": "When the answer spans appear only once in the input, this is simple, since the ground-truth tagging is immediately available.", "sentence2": "there are many cases where a given answer span appears multiple times in the input.", "label": "contrasting"}
{"id": "test_420", "sentence1": "For query generation, prior research has focused mostly on extending standard Seq2Seq models where the input is a concatenation of earlier queries a user has submitted in a session (Sordoni et al.,Figure 1: An example search session where a user issues queries and optionally performs clicking at timestamps 1 to n. At time n+1, the user issues q n+1 following the previous search context of length n. 2015; Dehghani et al., 2017).", "sentence2": "literature often leaves out the influence of clickthrough actions (i.e., red blocks in Figure 1), which we argue should be taken into account in the generative process as they could be surrogates of the user's implicit search intent (Yin et al., 2016).", "label": "contrasting"}
{"id": "test_421", "sentence1": "One of the widely exercised steps to establish a semantic understanding of social media is Entity Linking (EL), i.e., the task of linking entities within a text to a suitable concept in a reference Knowledge Graph (KG) (Liu et al., 2013;Yang and Chang, 2015;Yang et al., 2016; Ran et al., 2018).", "sentence2": "it is well-documented that poorly composed contexts, the ubiquitous presence of colloquialisms, shortened forms, typing/spelling mistakes, and out-of-vocabulary words introduce challenges for effective utilisation of social media text (Baldwin et al., 2013;Michel and Neubig, 2018).", "label": "contrasting"}
{"id": "test_422", "sentence1": "As noted by Ethayarajh (2019) the deeper BERT goes, the more \"contextualized\" its representation becomes.", "sentence2": "interpreting semantics of entities requires contextual knowledge in different degrees and always taking the last layer's output may not be the best solution.", "label": "contrasting"}
{"id": "test_423", "sentence1": "Compared to similar corpora, COMETA has the largest scale.", "sentence2": "from a learning perspective the lack of sufficient regularity in the data could still leave its toll at test phase.", "label": "contrasting"}
{"id": "test_424", "sentence1": "Much of the recent progress in NLP is due to the transfer learning paradigm in which Transformerbased models first try to learn task-independent linguistic knowledge from large corpora, and then get fine-tuned on small datasets for specific tasks.", "sentence2": "these models are overparametrized: we now know that most Transformer heads and even layers can be pruned without significant loss in performance (Voita et al., 2019;Kovaleva et al., 2019;Michel et al., 2019).", "label": "contrasting"}
{"id": "test_425", "sentence1": "There are recent works (Nguyen et al., 2019; Agarwal et al., 2020) also applying the Transformer to model the interactions among many entities.", "sentence2": "their models neglect the important early interaction of the answer entity and cannot naturally leverage the pretrained language representations from BERT like ours.", "label": "contrasting"}
{"id": "test_426", "sentence1": "In the example, both the baseline model and the model with the sub-instruction module completes the task successfully.", "sentence2": "unlike the baseline model which fails to follow the instruction and stops within 3 meters of the target by chance, our model correctly identifies the completeness of each sub-instruction, guides the agent to walk on the described path and eventually stops right at the target position.", "label": "contrasting"}
{"id": "test_427", "sentence1": "Although replacing a real user with a user simulator could address the issue, the simulator only roughly approximates real user statistics, and its development process is costly (Su et al., 2016).", "sentence2": "humans could independently reason potential responses based on past experiences from the true environment.", "label": "contrasting"}
{"id": "test_428", "sentence1": "We propose a model-agnostic approach, COPT, that can be applied to any adversarial learning-based dialogue generation models.", "sentence2": "to existing approaches, it learns on counterfactual responses inferred from the structural causal model, taking advantage of observed responses.", "label": "contrasting"}
{"id": "test_429", "sentence1": "As an important research issue in the natural language processing community, multi-label emotion detection has been drawing more and more attention in the last few years.", "sentence2": "almost all existing studies focus on one modality (e.g., textual modality).", "label": "contrasting"}
{"id": "test_430", "sentence1": "This implies that the success of previous models may over-rely on the confounding non-target aspects, but not necessarily on the target aspect only.", "sentence2": "no datasets can be used to analyze the aspect robustness more in depth.", "label": "contrasting"}
{"id": "test_431", "sentence1": "These two ratios should ideally be both 400%, because there are three generation strategies, plus one original sentence.", "sentence2": "this gap is because not every original test sentence can qualify for every generation strategy.", "label": "contrasting"}
{"id": "test_432", "sentence1": "That is to say, whether one sentence could be selected depends on its salience and the redundancy with other selected sentences.", "sentence2": "it is still difficult to model the dependency exactly.", "label": "contrasting"}
{"id": "test_433", "sentence1": "Neural models have achieved remarkable success on relation extraction (RE) benchmarks.", "sentence2": "there is no clear understanding which type of information affects existing RE models to make decisions and how to further improve the performance of these models.", "label": "contrasting"}
{"id": "test_434", "sentence1": "From the observations in Section 2, we know that both context and entity type information is beneficial for RE models.", "sentence2": "in some cases RE models cannot well understand the relational patterns in context and rely on the shallow cues of entity mentions for classification.", "label": "contrasting"}
{"id": "test_435", "sentence1": "Alt et al. (2020) also point out that there may exist shallow cues in entity mentions.", "sentence2": "there have not been systematical analyses about the topic and to the best of our knowledge, we are the first one to thoroughly carry out these studies.", "label": "contrasting"}
{"id": "test_436", "sentence1": "Other models selected operands first before constructing expression trees with operators in the second step (Roy et al., 2015; Roy and Roth, 2015).", "sentence2": "such two-step procedures in these early attempts can be performed via a single-step procedure with neural models.", "label": "contrasting"}
{"id": "test_437", "sentence1": "It has received significant attention in question answering systems for structured data (Wang et al., 2015; Zhong et al., 2017; Yu et al., 2018b; Xu et al., 2020).", "sentence2": "training a semantic parser with good accuracy requires a large amount of annotated data, which is expensive to acquire.", "label": "contrasting"}
{"id": "test_438", "sentence1": "Neural networks have the merits of convenient end-to-end training and good generalization, however, they typically need a lot of training data and are not interpretable.", "sentence2": "logicbased expert systems are interpretable and require less or no training data.", "label": "contrasting"}
{"id": "test_439", "sentence1": "A unique feature of this operationalisation of lexical ambiguity is that it is language independent.", "sentence2": "the quality of a possible approximation will vary from language to language, depending on the models and the data available in that language.", "label": "contrasting"}
{"id": "test_440", "sentence1": "If p(m | w) is concentrated in a small region of the meaning space (corresponding to a word with nuanced implementations of the same sense), the bound in eq. (13) could be relatively tight.", "sentence2": "a word with several unrelated homophones would correspond to a highly structured p(m | w) (e.g. with multiple modes in far distant regions of the space) for which this normal approximation would result in a very loose upper bound.", "label": "contrasting"}
{"id": "test_441", "sentence1": "Deep learning has led to significant improvement in text summarization with various methods investigated and improved ROUGE scores reported over the years.", "sentence2": "gaps still exist between summaries produced by automatic summarizers and human professionals.", "label": "contrasting"}
{"id": "test_442", "sentence1": "In the research literature, human evaluation has been conducted as a complement (Narayan et al., 2018).", "sentence2": "human evaluation reports that accompany ROUGE scores are limited in scope and coverage.", "label": "contrasting"}
{"id": "test_443", "sentence1": "The above methods assign one score to each summarization output.", "sentence2": "to these methods, our errorcount based metrics are motivated by MQM for human writing, and are more fine-grained and informative.", "label": "contrasting"}
{"id": "test_444", "sentence1": "On PolyTope, as a representative of abstractive models, BART overwhelmingly outperforms the others (p < 0.01 using t-test).", "sentence2": "excluding BART, extractive models take the following top three places.", "label": "contrasting"}
{"id": "test_445", "sentence1": "With respect to Accuracy, extractive methods are notably stronger in terms of Inacc Intrinsic and Extrinsic, which reflects that through directly copying snippets from the source, extractive methods are guaranteed to produce a summary with fair grammaticality, rationality and loyalty.", "sentence2": "extractive methods do not show stronger performances in Addition and Omission, which is because extracted sentences contain information not directly relevant to the main points.", "label": "contrasting"}
{"id": "test_446", "sentence1": "There is a high proportion in the first five sentences and a smooth tail over all positions for reference summaries.", "sentence2": "bertSumExt and SummaRuN-Ner extract sentences mostly from the beginning, thereby missing useful information towards the end.", "label": "contrasting"}
{"id": "test_447", "sentence1": "Compared with Point-Generator, Point-Generator-with-Coverage reduces Duplication errors from 68 to 11 and Omission errors from 286 to 256, proving that coverage is useful for better content selection.", "sentence2": "point-Generator-with-Coverage yields more Addition and Inacc Intrinsic errors than point-Generator.", "label": "contrasting"}
{"id": "test_448", "sentence1": "As can be seen, abstractive models tend to neglect sentences in the middle and at the end of source documents (e.g.,  Bottom-Up, BertSumExtAbs), indicating that performance of abstractive summarizers is strongly affected by the leading bias of dataset.", "sentence2": "bART can attend to sentences all around the whole document, slightly closer to the distribution of golden reference.", "label": "contrasting"}
{"id": "test_449", "sentence1": "Their main goal is to verify the faithfulness and factuality in abstractive models.", "sentence2": "we evaluate both rule-based baselines and extractive/abstractive summarizers on 8 error metrics, among which faithfulness and factuality are included.", "label": "contrasting"}
{"id": "test_450", "sentence1": "It has been conjectured that multilingual information can help monolingual word sense disambiguation (WSD).", "sentence2": "existing WSD systems rarely consider multilingual information, and no effective method has been proposed for improving WSD by generating translations.", "label": "contrasting"}
{"id": "test_451", "sentence1": "Our first method extends the idea of Apidianaki and Gong (2015) to constrain S(e) based on sensetranslation mappings in BabelNet.", "sentence2": "instead of relying on a single translation, we incorporate multiple languages by taking the intersection of the individual sets of senses; that is, we rule out senses if their corresponding BabelNet synsets do not contain translations from all target languages.", "label": "contrasting"}
{"id": "test_452", "sentence1": "Supervised systems are trained on sense-annotated corpora and generally outperform knowledge-based systems.", "sentence2": "knowledge-based systems usually apply graph-based algorithms to a semantic network and thus do not require any sense-annotated corpora.", "label": "contrasting"}
{"id": "test_453", "sentence1": "The ability to fuse sentences is highly attractive for summarization systems because it is an essential step to produce succinct abstracts.", "sentence2": "to date, summarizers can fail on fusing sentences.", "label": "contrasting"}
{"id": "test_454", "sentence1": "Fusing two sentences together coherently requires connective phrases and sometimes requires rephrasing parts of sentences.", "sentence2": "higher abstraction does not mean higher quality fusions, especially in neural models.", "label": "contrasting"}
{"id": "test_455", "sentence1": "Recent innovations in Transformer-based ranking models have advanced the state-ofthe-art in information retrieval.", "sentence2": "these Transformers are computationally expensive, and their opaque hidden states make it hard to understand the ranking process.", "label": "contrasting"}
{"id": "test_456", "sentence1": "One could argue that this is a superficial problem, as we can always give the model more free bits and decrease the loss in intermediary positions.", "sentence2": "this is not so simple because increasing capacity leads to a worse model fit, as was noted by Alemi et al. (2018).", "label": "contrasting"}
{"id": "test_457", "sentence1": "While Yang et al. (2017) and Kim et al. (2018) both consider the use of pretrained LMs as encoders, the weights are not frozen such that it is hard to disentangle the impact of pretraining from subsequent training.", "sentence2": "we freeze the weights so that the effect of pretraining can not be overridden.", "label": "contrasting"}
{"id": "test_458", "sentence1": "Both baselines and variants have roughly similarly high agreement.", "sentence2": "our variants produce more diverse beginnings, while still managing to reproduce the topic or sentiment of the original document.", "label": "contrasting"}
{"id": "test_459", "sentence1": "Finally, verb-shuffling focuses on verbs as the salient element of an event, and should teach both principles of verb ordering and of verb suitability for context, and avoid artifacts from reordering arguments.", "sentence2": "since verbs are shuffled naively, the task can in some cases be too easy due to differences in verb selectional preferences.", "label": "contrasting"}
{"id": "test_460", "sentence1": "In the vision and machine learning community, unsupervised induction of structured image representations (aka scene graphs or world models) has been receiving increasing attention (Eslami et al., 2016; Burgess et al., 2019; Kipf et al., 2020).", "sentence2": "they typically rely solely on visual signal.", "label": "contrasting"}
{"id": "test_461", "sentence1": "Previous work has shown that incorporating natural language explanation into the classification training loop is effective in various settings (Andreas et al., 2018; Mu et al., 2020).", "sentence2": "previous work neglects the fact that there is usually a limited time budget to interact with domain experts (e.g., medical experts, biologists)  and high-quality natural language explanations are expensive, by nature.", "label": "contrasting"}
{"id": "test_462", "sentence1": "For example, an image with a Ringbilled gull has the description: \"This is a white bird with a grey wing and orange eyes and beak.\"", "sentence2": "this description also fits perfectly with a California gull (Figure 1).", "label": "contrasting"}
{"id": "test_463", "sentence1": "Our results indicate that too many parameters can also harm multilinguality.", "sentence2": "in practice it is difficult to create a model with so many parameters that it is overparameterized when being trained on 104 Wikipedias.", "label": "contrasting"}
{"id": "test_464", "sentence1": "One might argue that our model 17 in Table 1 of the main paper is simply not trained enough and thus not multilingual.", "sentence2": "table 10 shows that even when continuing to train this model for a long time no multilinguality arises.", "label": "contrasting"}
{"id": "test_465", "sentence1": "This suggests that multilingual models can stimulate positive transfer for low-resource languages when monolingual models overfit.", "sentence2": "when we compare bilingual models on English, models trained using different sizes of fr/ru data obtain similar performance, indicating that the training size of the source language has little impact on negative interference on the target language (English in this case).", "label": "contrasting"}
{"id": "test_466", "sentence1": "Unlike language-specific adapters that can hinder transferability, shared adapters improve both within-language and cross-lingual performance with the extra capacity.", "sentence2": "meta adapters still obtain better performance.", "label": "contrasting"}
{"id": "test_467", "sentence1": "They observe that having more languages results in better zero-shot performance.", "sentence2": "several artifacts arise, as described by Dabre et al. (2020); Zhang et al. (2020); Aharoni et al. (2019); Arivazhagan et al. (2019), like off\u0002target translation and insufficient modeling capac\u0002ity of the MNMT models.", "label": "contrasting"}
{"id": "test_468", "sentence1": "This might indicate that -at least during the adaptation -important information is captured in the encoder's adapter layer (in line with previous reports by Kudugunta et al., 2019) or that the decoder adaptation grows dependent on the encoder adapters, to the point where dropping the latter degrades the system.", "sentence2": "further analysis would be needed to confirm either of these hypotheses.", "label": "contrasting"}
{"id": "test_469", "sentence1": "Not only is beam search usually more accurate than greedy search, but it also outputs a diverse set of decodings, enabling reranking approaches to further improve accuracy (Yee et al., 2019; Ng et al., 2019; Charniak and Johnson, 2005; Ge and Mooney, 2006).", "sentence2": "it is challenging to optimize the performance of beam search for modern neural architectures.", "label": "contrasting"}
{"id": "test_470", "sentence1": "FIXED-OURS is slower than Fairseq's implementation.", "sentence2": "while the two implementations achieve more similar BLEU on the development set, FIXED-OURS achieves higher BLEU on the test set (49.75 vs 49.57 on De-En and 39.19 vs 38.98 on Ru-En).", "label": "contrasting"}
{"id": "test_471", "sentence1": "The produced meaning representations can then potentially be used to improve downstream NLP applications (e.g., Issa et al., 2018;Song et al., 2019;Mihaylov and Frank, 2019), though the introduction of large pretrained language models has shown that explicit formal meaning representations might not be a necessary component to achieve high accuracy.", "sentence2": "it is now known that these models lack reasoning capabilities, often simply exploiting statistical artifacts in the data sets, instead of actually understanding language (Niven and Kao, 2019;McCoy et al., 2019).", "label": "contrasting"}
{"id": "test_472", "sentence1": "A possible advantage of this model is that it might handle longer sentences and documents better.", "sentence2": "it might be harder to tune (Popel and Bojar, 2018) 2 and its improved performance has mainly been shown for large data sets, as opposed to the generally smaller semantic parsing data sets (Section 3.3).", "label": "contrasting"}
{"id": "test_473", "sentence1": "For both methods, it results in a clear and significant improvement over the BERT-only baseline, 87.6 versus 88.1.", "sentence2": "another common method of improving performance is adding linguistic features to the tokenlevel representations.", "label": "contrasting"}
{"id": "test_474", "sentence1": "This was done for efficiency and memory purposes, it did not make a difference in terms of F1-score.", "sentence2": "for the Transformer model this improved F1-score by around 0.5.", "label": "contrasting"}
{"id": "test_475", "sentence1": "Data efficiency can be improved by optimizing pre-training directly for future fine-tuning with few examples; this can be treated as a meta-learning problem.", "sentence2": "standard meta-learning techniques require many training tasks in order to generalize; unfortunately, finding a diverse set of such supervised tasks is usually difficult.", "label": "contrasting"}
{"id": "test_476", "sentence1": "Bansal et al. (2019) proposed an approach that applies to diverse tasks to enable practical meta-learning models and evaluate on generalization to new tasks.", "sentence2": "they rely on supervised task data from multiple tasks and suffer from meta-overfitting as we show in our empirical results.", "label": "contrasting"}
{"id": "test_477", "sentence1": "Owing to the warp layers, our training time per step and the GPU memory footprint is lower than LEOPARD (Bansal et al., 2019).", "sentence2": "our training typically runs much longer as the model doesn't overfit unlike LEOPARD (see learning rate trajectory in main paper).", "label": "contrasting"}
{"id": "test_478", "sentence1": "As Wiki itself is a collaborative knowledge repository, editors are likely to attack others due to disputes on specific domain knowledge.", "sentence2": "the users are the general public who post comments and tweets more casually for Yahoo and Twitter.", "label": "contrasting"}
{"id": "test_479", "sentence1": "Multilingual contextual embeddings have demonstrated state-of-the-art performance in zero-shot cross-lingual transfer learning, where multilingual BERT is fine-tuned on one source language and evaluated on a different target language.", "sentence2": "published results for mBERT zero-shot accuracy vary as much as 17 points on the MLDoc classification task across four papers.", "label": "contrasting"}
{"id": "test_480", "sentence1": "Many models inspired by BERT have since surpassed its performance.", "sentence2": "in contrast to the original BERT paper, many obtained better results by excluding the NSP task.", "label": "contrasting"}
{"id": "test_481", "sentence1": "The decoupled biLSTM extended with ELMo inputs is able to outperform the transformer model initialised with RoBERTa pretraining.", "sentence2": "the best performance is achieved by using the transformer model with BART-large pretraining, with the decoupled model fine-tuned jointly on top of it (Lewis et al., 2019).", "label": "contrasting"}
{"id": "test_482", "sentence1": "The concept of Dialogue Act (DA) is universal across different task-oriented dialogue domains-the act of \"request\" carries the same speaker intention whether it is for restaurant reservation or flight booking.", "sentence2": "dA taggers trained on one domain do not generalize well to other domains, which leaves us with the expensive need for a large amount of annotated data in the target domain.", "label": "contrasting"}
{"id": "test_483", "sentence1": "It is often challenging and costly to obtain a large amount of in-domain dialogues with annotations.", "sentence2": "unlabeled dialogue corpora in target domain can easily be curated from past conversation logs or collected via crowd-sourcing (Byrne et al., 2019;Budzianowski et al., 2018) at a more reasonable cost.", "label": "contrasting"}
{"id": "test_484", "sentence1": "In prior work (Xie et al., 2019;Wei and Zou, 2019), unsupervised data augmentation methods including word replacement and backtranslation have been shown useful for short written text classification.", "sentence2": "such augmentation methods are shown to be less effective (Shleifer, 2019) when used with pre-trained models.", "label": "contrasting"}
{"id": "test_485", "sentence1": "We find that for both tense and mood in the Indo-Aryan family, our model identifies required-agreement primarily for conjoined verbs, which mostly need to agree only if they share the same subject.", "sentence2": "subsequent analysis revealed that in the treebanks nearly 50% of the agreeing verbs do not share the same subject but do agree by chance.", "label": "contrasting"}
{"id": "test_486", "sentence1": "Professor Tanja Kallio and doctoral candidate Sami Tuomi consider the realisation of this goal entirely possible.", "sentence2": "\"scientifically we are in the dark about the consequences of rewilding, and we worry about the general lack of critical thinking surrounding these often very expensive attempts at conservation.", "label": "contrasting"}
{"id": "test_487", "sentence1": "Such pairs show consistent improvement (+5 to +10), which suggests that the model learns to align the parallel knowledge from the source language to the target language.", "sentence2": "we also must note that the effect is strongly dependent on the size of the overlapping sets.", "label": "contrasting"}
{"id": "test_488", "sentence1": "Students need good textbooks to study before they can pass an exam, and the same holds for a good machine reading model.", "sentence2": "finding the information needed to answer a question, especially for questions in such a narrow domain as the subjects studied in high schools, usually requires a collection of specialized texts.", "label": "contrasting"}
{"id": "test_489", "sentence1": "However, little work has looked further up the pipeline and relied on the assumption that biases in data originate in human cognition.", "sentence2": "this assumption motivates our work: an unsupervised approach to detecting implicit gender bias in text.", "label": "contrasting"}
{"id": "test_490", "sentence1": "Psychology studies often examine human perceptions through word associations (Greenwald et al., 1998).", "sentence2": "the implicit nature of bias suggests that human annotations for bias detection may not be reliable, which motivates an unsupervised approach.", "label": "contrasting"}
{"id": "test_491", "sentence1": "is likely addressed towards a woman and identify it as biased.", "sentence2": "we only want the model to learn that references to appearance are indicative of gender if they occur in unsolicited contexts.", "label": "contrasting"}
{"id": "test_492", "sentence1": "For example, humans need the supervision of what is a noun before they do POS tagging, or what is a tiger in Wordnet before they classify an image of tiger in ImageNet.", "sentence2": "for NLI, people are able to entail that a A man plays a piano contradicts b A man plays the clarinet for his family without any supervision from the NLI labels.", "label": "contrasting"}
{"id": "test_493", "sentence1": "Both depGCN and kumaGCN can correctly classify the sentiment of \"service\" as negative.", "sentence2": "depGCN cannot recognize the positive sentiment of \"atmosphere\" while kumaGCN can.", "label": "contrasting"}
{"id": "test_494", "sentence1": "For the target \"atmosphere\", depGCN assigns the highest weight to the word \"terrible\", which is an irrelevant sentiment word to this target, leading to an incorrect prediction.", "sentence2": "our model assigns the largest weight to the key sentiment word \"cozy\", classifying it correctly.", "label": "contrasting"}
{"id": "test_495", "sentence1": "Although collecting tags from users is time\u0002consuming and often suffers from coverage issues (Katakis et al., 2008), NLP techniques like those in Kar et al. (2018b) and Gorinski and Lapata (2018) can be employed to generate tags automatically from written narratives such as synopses.", "sentence2": "existing supervised approaches suffer from two significant weaknesses.", "label": "contrasting"}
{"id": "test_496", "sentence1": "August is selected to perform the rhapsody he's been composing at the same concert.", "sentence2": "wizard, who found out about August's performance by Arthur, interrupts the rehearsal and claims to be his father, and manages to pull August out of the school.", "label": "contrasting"}
{"id": "test_497", "sentence1": "Mozart would be an absolute imbecile compared to this little kid August Rush, and for those familiar with music, this aspect (the foundation, really) just kills the movie.It is impossible to play like Michael Hedges in your first few minutes with a guitar.", "sentence2": "i just finished watching August Rush and i am in no way exaggerating when i say that it is by far the best movie i have ever seen.", "label": "contrasting"}
{"id": "test_498", "sentence1": "Im not sure who would actually enjoy this movie, maybe if you're 70, or under 12 but for everyone else I'd save your time.The acting itself wasn't bad, though the more interesting characters were played by Terrence Howard and Robin Williams, and they were both severely under-developed as you wanted to know more about them and less about this kid with the stupid smile all the time..", "sentence2": "while the movie has a modern setting, it shares many plot elements with OLIVER TWIST, ending even better.It begins with a young couple of musicians that meets and has a one-night stand, and when she becomes pregnant her dad does everything to make her believe that the child died at birth, although he just put the child for adoption.A decade later the boy, Evan, lives in a orphanage and is mocked by the other kids because of his talents in music, that makes him like a savant with powerful skills.", "label": "contrasting"}
{"id": "test_499", "sentence1": "Although this film plays well to a broad audience, it is very mystical and based on simple, yet emotional themes that will play flat to some movie-goers.If you have strong parental feelings or enjoy movies centered on the power of human love and attraction, this story will move you like few films ever have.", "sentence2": "if you are easily bored with themes that are lacking in danger and suspense or prefer gritty true-to-life movies, this one may come off as a disappointment.The screenplay seems written as a spiritual message intimating that there is an energy field that connects all of life, and music is one of the domains available to any who care to experience it.The plot is simple but deep in implication-an orphaned boy wants to reunite with his parents and feels that his inherited musical genius can somehow guarantee their return.", "label": "contrasting"}
{"id": "test_500", "sentence1": "Graph convolutional networks (GCN) is demonstrated to be an effective approach to model such contextual information between words in many NLP tasks (Marcheggiani and Titov, 2017;Huang and Carley, 2019;De Cao et al., 2019); thus we want to determine whether this approach can also help CCG supertagging.", "sentence2": "we cannot directly apply conventional GCN models to CCG supertagging because in most of the previous studies the GCN models are built over the edges in the dependency tree of an input sentence.", "label": "contrasting"}
{"id": "test_501", "sentence1": "Having more training data can help reduce overfitting and improve model robustness.", "sentence2": "preparing a large amount of annotated data is usually costly, labor intensive and time-consuming.", "label": "contrasting"}
{"id": "test_502", "sentence1": "In this work, we will focus on denoising recurrent neural network autoencoders (Vincent et al., 2010;Shen et al., 2020; see Appendix A).", "sentence2": "any advancement in this research direction will directly benefit our framework.", "label": "contrasting"}
{"id": "test_503", "sentence1": "This observation may seem counter to the widely seen success of finetuning across other NLP scenarios, in particular with pretrained transformer models like BERT (Devlin et al., 2019).", "sentence2": "finetuning does not always lead to better performance.", "label": "contrasting"}
{"id": "test_504", "sentence1": "Recent work starts to use gradient (Michel et al., 2019;Ebrahimi et al., 2017) to guide the search for universal trigger (Wallace et al., 2019) that are applicable to arbitrary sentences to fool the learner, though the reported attack success rate is rather low or they suffer from inefficiency when applied to other NLP tasks.", "sentence2": "our proposed T3 framework is able to effectively generate syntactically correct adversarial text, achieving high targeted attack success rates across different models on multiple tasks.", "label": "contrasting"}
{"id": "test_505", "sentence1": "There are also systems (Luo et al., 2018; Kumar et al., 2019) that incorporate sense definitions into language models and achieve state-of-the-art performance.", "sentence2": "most of the systems are implemented in a supervised manner using a widely exploited sense-annotated corpus, SemCor (Miller et al., 1994), and merging knowledge from the sense inventory as a supplement.", "label": "contrasting"}
{"id": "test_506", "sentence1": "By using regex-based extractors and a list of comprehensive dictionaries that capture crucial domain vocabularies, LUSTRE can generate rules that achieve SoTA results.", "sentence2": "for more complex and realistic scenarios, dictionaries may not be available and regex-based extractors alone are not expressive enough.", "label": "contrasting"}
{"id": "test_507", "sentence1": "EMR and LwF can achieve competitive performance at the beginning.", "sentence2": "the gap between the two baselines and our method KCN becomes wider as more new classes arrive.", "label": "contrasting"}
{"id": "test_508", "sentence1": "Very few models exist that can predict either open vocab (Rashkin et al., 2018), or variable size output .", "sentence2": "no existing task has both open vocabulary and variable-size low specificity-placing OPENPI in a novel space.", "label": "contrasting"}
{"id": "test_509", "sentence1": "The SCoNE dataset (Long et al., 2016) contains paragraphs describing a changing world state in three synthetic, deterministic domains.", "sentence2": "approaches developed using synthetic data often fail to handle the inherent complexity in language when applied to organic, real-world data (Hermann et al., 2015;Winograd, 1972).", "label": "contrasting"}
{"id": "test_510", "sentence1": "For informativeness, we notice that all models perform well on the seen domains.", "sentence2": "on unseen domains, the Naive approach fares poorly.", "label": "contrasting"}
{"id": "test_511", "sentence1": "Very similar to our task, Kang et al. (2019) developed language models informed by discourse relations on the bridging task; given the first and last sen\u0002tences, predicting the intermediate sentences (bidirectional flow).", "sentence2": "they did not explicitly predict content words given context nor use them as a self-supervision signal in training.", "label": "contrasting"}
{"id": "test_512", "sentence1": "As an alternative metric of attention explainablity, (Jain and Wallace, 2019) considers the relationship between attention weights and gradient-based feature importance score of each word.", "sentence2": "prior research suggests using word as a unit of importance feature is rather artificial, as word is contextualized by, and interacts with other words: (Wiegreffe and Pinter, 2019) observes such limitation, and Shapley (Chen et al., 2018) measures interaction between features for capturing dependency of arbitrary subsets.", "label": "contrasting"}
{"id": "test_513", "sentence1": "The GNN-based models are particularly strong in this setting (see Appendix C), and this suggests that transferring knowledge about the relevancy of facts from structured to unstructured models may be a promising direction.", "sentence2": "at the same time, the improvements for generalization were less substantial, indicating that some reasoning capacities are difficult to distill in this manner.", "label": "contrasting"}
{"id": "test_514", "sentence1": "This is not surprising as the generalization ability is a known issue in modern NLP models and is an ongoing research topic (Bahdanau et al., 2019; Andreas, 2019).", "sentence2": "the generalization is in parallel with our contribution that is to improve the reasoning ability of NLP models.", "label": "contrasting"}
{"id": "test_515", "sentence1": "Predictive methods such as probing are flexible: Any task with data can be assessed.", "sentence2": "they only track predictability of pre-defined categories, limiting their descriptive power.", "label": "contrasting"}
{"id": "test_516", "sentence1": "Since nPMI is information-theoretic and chance-corrected, it is a reliable indicator of the degree of information about gold labels contained in a set of predicted clusters.", "sentence2": "it is relatively insensitive to cluster granularity (e.g., the total number of predicted categories, or whether a single gold category is split into many different predicted clusters), which is better understood through our other metrics.", "label": "contrasting"}
{"id": "test_517", "sentence1": "On one hand, this reflects surface patterns: primary core arguments are usually close to the verb, with ARG0 on the left and ARG1 on the right; trailing arguments and modifiers tend to be prepositional phrases or subordinate clauses; and modals and negation are identified by lexical and positional cues.", "sentence2": "this also reflects error patterns in state-of-the-art systems, where label errors can sometimes be traced to ontological choices in PropBank, which distinguish between arguments and adjuncts that have very similar meaning Kingsbury et al., 2002).", "label": "contrasting"}
{"id": "test_518", "sentence1": "Most of the existing work has adopted static sentiment lexicons as linguistic resource (Qian et al., 2017; Chen et al., 2019), and equipped each word with a fixed sentiment polarity across different contexts.", "sentence2": "the same word may play different sentiment roles in different contexts due to the variety of part-ofspeech tags and word senses.", "label": "contrasting"}
{"id": "test_519", "sentence1": "We observe that our proposed MT-H-LSTM-CRF consistently outperforms the baseline models.", "sentence2": "it performs slightly worse on RR-submission than on RR-passage, plausibly because there is no context information (i.e., background knowledge from original submissions) shared between different passage pairs.", "label": "contrasting"}
{"id": "test_520", "sentence1": "Sentence [1] is non-hyperbolic because the fact that \"her one step equals my two steps\" is not anything that would be surprising to anyone.", "sentence2": "if one changes the number from \"two\" to \"100\", then the resulting sentence becomes hyperbolic because in reality it is not possible that one person's step would equal another person's 100 steps.", "label": "contrasting"}
{"id": "test_521", "sentence1": "Their proposal is similar to ours; they exclude attention weights that do not affect the output owing to the application of transformation f and input x in the analysis.", "sentence2": "our proposal differs from theirs in some aspects.", "label": "contrasting"}
{"id": "test_522", "sentence1": "The target word in (1 a) is associated 3 with the gold gloss (1 b) from WordNet (Fellbaum, 1998), the most used sense inventory in WSD.", "sentence2": "generationary arguably provides a better gloss (1 c).", "label": "contrasting"}
{"id": "test_523", "sentence1": "It is not surprising that machine learning methods can easily surpass human performance if sufficient data is available (Wang et al., 2018).", "sentence2": "data acquisition is a challenging task for some special domains.", "label": "contrasting"}
{"id": "test_524", "sentence1": "The core idea of our method is finding a different entity for intervening on an entity in the observational example.", "sentence2": "finding a new entity set in a specific domain needs human efforts to collect entities, which has no difference from annotating more data.", "label": "contrasting"}
{"id": "test_525", "sentence1": "Second, the training and test data in these benchmarks are sampled from the same corpus, and therefore the training data usually have high mention coverage on the test data, i.e., a large proportion of mentions in the test set have been observed in the training set.", "sentence2": "it is obvious that this high coverage is inconsistent with the primary goal of NER models, which is expected to identify unseen mentions from new data by capturing the generalization knowledge about names and contexts.", "label": "contrasting"}
{"id": "test_526", "sentence1": "This is because they only annotate named mentions but ignore nominal and pronominal mentions.", "sentence2": "the context of named and nominal/pronominal mentions is generally identical, and therefore the models will be unable to distinguish between them once name regularity is removed.", "label": "contrasting"}
{"id": "test_527", "sentence1": "Temporal KGs often exhibit multiple simultaneous non-Euclidean structures, such as hierarchical and cyclic structures.", "sentence2": "existing embedding approaches for temporal KGs typically learn entity representations and their dynamic evolution in the Euclidean space, which might not capture such intrinsic structures very well.", "label": "contrasting"}
{"id": "test_528", "sentence1": "More recently,  generalized manifolds of constant curvature to a product manifold combining hyperbolic, spherical, and Euclidean components.", "sentence2": "these methods consider graph data as static models and lack the ability to capture temporally evolving dynamics.", "label": "contrasting"}
{"id": "test_529", "sentence1": "Building upon recent NLI systems, our approach leverages representations from unsupervised pretraining, and finetunes a multiclass classifier over the BERT model (Devlin et al., 2019).", "sentence2": "we first consider other models for related tasks.", "label": "contrasting"}
{"id": "test_530", "sentence1": "Such results are problematic for entailment (since it is defined to depend on the truth of the premise).", "sentence2": "our problem is primarily about the meaning of answers.", "label": "contrasting"}
{"id": "test_531", "sentence1": "The approach achieves consistently better performance compared to the first two rows on the inter-domain structure prediction task (For both, original Parseval and RST-Parseval), as we have previously shown in Huber and Carenini (2019).", "sentence2": "only considering two out of three nuclearity classes (N-S and S-N), the system performs rather poorly on the nuclearity classification task.", "label": "contrasting"}
{"id": "test_532", "sentence1": "Our proposed new method (BERT-BASE-LWAN) that employs LWAN on top of BERT-BASE has the best results among all methods on EURLEX57K and AMAZON13K, when all and frequent labels are considered.", "sentence2": "in both datasets, the results are comparable to BERT-BASE, indicating that the multi-head attention mechanism of BERT can effectively handle the large number of labels.", "label": "contrasting"}
{"id": "test_533", "sentence1": "To identify whether an example is biased, they employ a shallow model f b , a simple model trained to directly compute p(y|b(x)), where the features b(x) are hand-crafted based on the task-specific knowledge of the biases.", "sentence2": "obtaining the prior information to design b(x) requires a dataset-specific analysis (Sharma et al., 2018).", "label": "contrasting"}
{"id": "test_534", "sentence1": "Training a shallow model The analysis suggests that we can obtain a substitute f b by taking a checkpoint of the main model early in the training, i.e., when the model has only seen a small portion of the training data.", "sentence2": "we observe that the resulting model makes predictions with rather low confidence, i.e., assigns a low probability to the predicted label.", "label": "contrasting"}
{"id": "test_535", "sentence1": "This indicates that unregularized training optimizes faster on certain examples, possibly due to the presence of biases.", "sentence2": "self-debiased training maintains relatively less variability of losses throughout the training.", "label": "contrasting"}
{"id": "test_536", "sentence1": "Closely related to our work, Singh et al. (2019) showed that replacing segments of the training data with their translation during fine-tuning is helpful.", "sentence2": "they attribute this behavior to a data augmentation effect, which we believe should be reconsidered given the new evidence we provide.", "label": "contrasting"}
{"id": "test_537", "sentence1": "For example, by framing the immigration issue using the morality frame or using the security frame, the reader is primed to accept the liberal or conservative perspectives, respectively.", "sentence2": "as shown in Example 1, in some cases this analysis is too coarse grained, as both articles frame the issue using the economic frame, suggesting that a finer grained analysis is needed to capture the differences in perspective.", "label": "contrasting"}
{"id": "test_538", "sentence1": "In Example 1, both texts use the Economic frame using same unigram indicator ('wage').", "sentence2": "other words in the text can help identify the nuanced talking points (e.g., 'minimum wage' in case of left and 'stagnant wages' in case of right).", "label": "contrasting"}
{"id": "test_539", "sentence1": "Availability of large-scale datasets has enabled the use of statistical machine learning in vision and language understanding, and has lead to significant advances.", "sentence2": "the commonly used evaluation criterion is the performance of models on test-samples drawn from the same distribution as the training dataset, which cannot be a measure of generalization.", "label": "contrasting"}
{"id": "test_540", "sentence1": "The goal of OOD generalization is to mitigate negative bias while learning to perform the task.", "sentence2": "existing methods such as LMH (Clark et al., 2019) try to remove all biases between question-answer pairs, by penalizing examples that can be answered without looking at the image; we believe this to be counterproductive.", "label": "contrasting"}
{"id": "test_541", "sentence1": "Notice that both mutations do not significantly change the input, most of the pixels in the image and words in the question are unchanged, and the type of reasoning required to answer the question is unchanged.", "sentence2": "the mutation significantly changes the answer.", "label": "contrasting"}
{"id": "test_542", "sentence1": "As expected, the batch-aware strategies, DAL and Core-Set, which were designed to increase diversity, are characterized by the most diverse batches, with DAL achieving the highest diversity values, demonstrating the success of using mini-queries (Gissin and Shalev-Shwartz, 2019) to reduce redundancy of the selected examples.", "sentence2": "the other strategies tend to select less diverse batches, i.e., they are prone to choose redundant examples, especially in the imbalanced-practical scenario.", "label": "contrasting"}
{"id": "test_543", "sentence1": "This roughly translates to increasing the throughput of the training process.", "sentence2": "when performing inference on a single data point, the latency of making predictions seems to dominate the runtime (Jouppi et al., 2017).", "label": "contrasting"}
{"id": "test_544", "sentence1": "Recent work has shown that contextualised embeddings pre-trained on large written corpora can be fine-tuned on smaller spoken language corpora to learn structures of spoken language (Tran et al., 2019).", "sentence2": "for NLP tasks, fillers and all disfluencies are typically removed in pre-processing, as NLP models achieve highest accuracy on syntactically correct utterances.", "label": "contrasting"}
{"id": "test_545", "sentence1": "An assumption one could make based on the work by Radford et al. (2019), is that with this model, the results for any further downstream task would be improved by the presence of fillers.", "sentence2": "we observe that to predict the persuasiveness of the speaker (using the high level attribute of persuasiveness annotated in the dataset (Park et al., 2014)), following the same procedure as outlined in subsubsection 2.1.2, that fillers, in fact, are not a discriminative feature.", "label": "contrasting"}
{"id": "test_546", "sentence1": "Stehwien and Vu (2017) and Stehwien et al. (2018) (henceforth, SVS18) showed that neural methods can perform comparably to traditional methods us\u0002ing a relatively small amount of speech context\u2014 just a single word on either side of the target word.", "sentence2": "since pitch accents are deviations from a speaker\u2019s average pitch, intensity, and duration, we hypothesize that, as in some non-neural mod\u0002els (e.g. Levow 2005; Rosenberg and Hirschberg 2009), a wider input context will allow the model to better determine the speaker\u2019s baseline for these features an", "label": "contrasting"}
{"id": "test_547", "sentence1": "Recent advances in deep learning present a promising prospect in multimodal stock forecasting by analyzing online news , and social media (Guo et al., 2018) to learn latent patterns affecting stock prices (Jiang, 2020).", "sentence2": "the challenging aspect in stock forecasting is that most existing work treats stock movements to be independent of each other, contrary to true market function (Diebold and Y\u0131lmaz, 2014).", "label": "contrasting"}
{"id": "test_548", "sentence1": "The news interview setting revolves around sets of questions and answers-naively, one may assume the interviewer to be the sole questioner.", "sentence2": "media dialog has steadily deviated from this rigid structure, tending toward the broadly conversational (Fairclough, 1988).", "label": "contrasting"}
{"id": "test_549", "sentence1": "Natural language inference (NLI) data has proven useful in benchmarking and, especially, as pretraining data for tasks requiring language understanding.", "sentence2": "the crowdsourcing protocol that was used to collect this data has known issues and was not explicitly optimized for either of these purposes, so it is likely far from ideal.", "label": "contrasting"}
{"id": "test_550", "sentence1": "Longer texts offer the potential for discourse-level inferences, the addition of which should yield a dataset that is more difficult, more diverse, and less likely to contain trivial artifacts.", "sentence2": "one might expect that asking annotators to read full paragraphs should increase the time required to create a single example; time which could potentially be better spent creating more examples.", "label": "contrasting"}
{"id": "test_551", "sentence1": "Giving annotators difficult and varying constraints could encourage creativity and prevent annotators from falling into patterns in their writing that lead to easier or more repetitive data.", "sentence2": "as with the use of longer contexts in PARAGRAPH, this protocol risks substantially slowing the annotation process.", "label": "contrasting"}
{"id": "test_552", "sentence1": "Our chief results on transfer learning are conclusively negative: All four interventions yield substantially worse transfer performance than our base MNLI data collection protocol.", "sentence2": "we also observe promising signs that all four of our interventions help to reduce the prevalence of artifacts in the generated hypotheses that reveal the label.", "label": "contrasting"}
{"id": "test_553", "sentence1": "We bring up textual entailment as a unified solver for such NLP problems.", "sentence2": "current research of textual entailment has not spilled much ink on the following questions: (i) How well does a pretrained textual entailment system generalize across domains with only a handful of domainspecific examples?", "label": "contrasting"}
{"id": "test_554", "sentence1": "Thus, various stress-testing datasets have been proposed that probe NLI models for simple lexical inferences (Glockner et al., 2018), quantifiers (Geiger et al., 2018), numerical reasoning, antonymy and negation (Naik et al., 2018).", "sentence2": "despite the heavy usage of conjunctions in English, there is no specific NLI dataset that tests their understanding in detail.", "label": "contrasting"}
{"id": "test_555", "sentence1": "We presented some initial solutions via adversarial training and a predicate-aware RoBERTa model, and achieved some reasonable performance gains on CONJNLI.", "sentence2": "we also show limitations of our proposed methods, thereby encouraging future work on CONJNLI for better understanding of conjunctive semantics.", "label": "contrasting"}
{"id": "test_556", "sentence1": "This method is later extended to a hierarchical setting with a pre-defined hierarchy (Meng et al., 2019); ConWea (Mekala and Shang, 2020) leverages contextualized representation techniques to provide contextualized weak supervision for text classification.", "sentence2": "all these techniques consider only the text data and don't leverage metadata information for classification.", "label": "contrasting"}
{"id": "test_557", "sentence1": "Note that the same hypothesis can also be made at the paragraph level.", "sentence2": "a major limitation of this approach is that paragraph sizes vary widely, ranging from a single word to a considerably huge block of text.", "label": "contrasting"}
{"id": "test_558", "sentence1": "We use bidirectional contextual representation (Devlin et al., 2018) for encoding article text.", "sentence2": "contrary to document representation using BERT (Adhikari et al., 2019), which is not adequate for large text documents, we first segment articles organically based on sections.", "label": "contrasting"}
{"id": "test_559", "sentence1": "Finally, there has been some work on directly training a model to extract entities and associated negation constraints (Bhatia et al., 2019).", "sentence2": "these works usually assume the availability of good quality annotated negated entities.", "label": "contrasting"}
{"id": "test_560", "sentence1": "This behavior unique to S C+R is safe for  the noisy data filtering task since it can successfully detect lower-quality pairs with high precision.", "sentence2": "improperly underestimating some acceptable pairs (i.e., low recall) is one downside of S C+R , and we discuss its influences in Section 6.3.", "label": "contrasting"}
{"id": "test_561", "sentence1": "TXtract (Karamanolakis et al., 2020) incorporated the categorical structure into the value tagging system.", "sentence2": "these methods suffer from irrelevant articles and is not able to filter out noisy answers.", "label": "contrasting"}
{"id": "test_562", "sentence1": "Similar to prior work (Lee et al., 2017), our training objective is to maximize the probability of the correct antecedent (cluster) for each mention span.", "sentence2": "rather than considering all correct antecedents, we are only interested in the cluster for the most recent one.", "label": "contrasting"}
{"id": "test_563", "sentence1": "These plots show that models have relatively modest memory usage during inference.", "sentence2": "their usage grows in training, due to gradients and optimizer parameters.", "label": "contrasting"}
{"id": "test_564", "sentence1": "This would \"correct\" the training objective to match prior work.", "sentence2": "this did not have a noticeable effect on performance.", "label": "contrasting"}
{"id": "test_565", "sentence1": "Likewise, we were able to train a competitive model for which only the SpanBERT encoder from Joshi et al. (2019) was retained and the span scorer and pairwise scorer were randomly initialized.", "sentence2": "we opted not to use that for the full experiments because training was more expensive in time.", "label": "contrasting"}
{"id": "test_566", "sentence1": "Neural generation models based on different strategies like softtemplate (Wiseman et al., 2018; Ye et al., 2020), copy-mechanism (See et al., 2017), content planning (Reed et al., 2018; Moryossef et al., 2019), and structure awareness Colin and Gardent, 2019) have achieved impressive results.", "sentence2": "existing studies are primarily focused on fully supervised setting requiring substantial labeled annotated data for each subtask, which restricts their adoption in real-world applications.", "label": "contrasting"}
{"id": "test_567", "sentence1": "The work closest to our concept is Switch-GPT-2 (Chen et al., 2020b), which fits the pre-trained GPT-2 model as the decoder part to perform table-to-text generation.", "sentence2": "their knowledge encoder is still trained from scratch, which compromises the performance.", "label": "contrasting"}
{"id": "test_568", "sentence1": "GPT (Radford, 2018) and GPT-2 (Radford et al., 2019) use a leftto-right Transformer decoder to generate a text sequence token-by-token, which lacks an encoder to condition generation on context.", "sentence2": "MASS (Song et al., 2019) and BART (Lewis et al., 2019) both employ a Transformer-based encoder\u0002decoder framework, with a bidirectional encoder over corrupted (masked) text and a left-to-right decoder reconstructing the original text.", "label": "contrasting"}
{"id": "test_569", "sentence1": "However, these autoencoding methods are not applicable to text generation where bidirectional contexts are not available.", "sentence2": "an autoregressive model, such as GPT (Radford, 2018; Radford et al., 2019), is only trained to encode unidirectional context (either forward or backward).", "label": "contrasting"}
{"id": "test_570", "sentence1": "A difference between UniLMs and PALM is that UniLMs are not fully autoregressive in the pre-training process.", "sentence2": "pALM reduces the mismatch between pre-training and context-conditioned generation tasks by forcing the decoder to predict the continuation of text input on an unlabeled corpus.", "label": "contrasting"}
{"id": "test_571", "sentence1": "For instance in Figure 1, players might prefer the command \"move rug\" over \"knock on door\" since the door is nailed shut.", "sentence2": "even the state-of-the-art game-playing agents do not incorporate such priors, and instead rely on rule-based heuristics (Hausknecht et al., 2019a) or handicaps provided by the learning environment (Hausknecht et al., 2019a;Ammanabrolu and Hausknecht, 2020) to circumvent these issues.", "label": "contrasting"}
{"id": "test_572", "sentence1": "In a slightly different setting, Urbanek et al. (2019) trained BERT (Devlin et al., 2018) to generate contextually relevant dialogue utterances and actions in fantasy settings.", "sentence2": "these approaches are game-specific and do not use any reinforcement learning to optimize gameplay.", "label": "contrasting"}
{"id": "test_573", "sentence1": "When k is small, CALM (n-gram) benefits from its strong action assumption of one verb plus one object.", "sentence2": "this assumption also restricts CALM (n-gram) from generating more complex actions (e.g.  \u2018open case with key\u2019) that CALM (GPT\u00022) can produce.", "label": "contrasting"}
{"id": "test_574", "sentence1": "It is really the complex actions captured when k > 10 that makes GPT-2 much better than ngram.", "sentence2": "though k = 20, 30, 40 achieve similar overall performance, they achieve different results for different games.", "label": "contrasting"}
{"id": "test_575", "sentence1": "It is interesting that CALM (w/ Jericho) is significantly better than CALM (GPT-2) on the games of Temple and Deephome (non-trivial scores achieved), which are not the games with ClubFloyd scripts added.", "sentence2": "games like 905 and moonlit have scripts added, but do not get improved.", "label": "contrasting"}
{"id": "test_576", "sentence1": "Natural Language Generation (NLG) is a challenging problem in Natural Language Processing (NLP)-the complex nature of NLG tasks arise particularly in the output space.", "sentence2": "to text classification or regression problems with finite output space, generation could be seen as a combinatorial optimization problem, where we often have exponentially many options |V | (here |V | is the size of the vocabulary and is the sentence length).", "label": "contrasting"}
{"id": "test_577", "sentence1": "It is possible to stop training the decomposition model based on downstream QA accuracy.", "sentence2": "training a QA model on each decom-position model checkpoint (1) is computationally expensive and (2) ties decompositions to a specific, downstream QA model.", "label": "contrasting"}
{"id": "test_578", "sentence1": "The similarity between BERT sentence embeddings can be reduced to the similarity between BERT context embeddings h T c h c 2 .", "sentence2": "as shown in Equation 1, the pretraining of BERT does not explicitly involve the computation of h T c h c .", "label": "contrasting"}
{"id": "test_579", "sentence1": "Note that BERT sentence embeddings are produced by averaging the context embeddings, which is a convexitypreserving operation.", "sentence2": "the holes violate the convexity of the embedding space.", "label": "contrasting"}
{"id": "test_580", "sentence1": "We argue that NATSV can help eliminate anisotropy but it may also discard some useful information contained in the nulled vectors.", "sentence2": "our method directly learns an invertible mapping to isotropic latent space without discarding any information.", "label": "contrasting"}
{"id": "test_581", "sentence1": "The transferred model both increased the quality and diversity of the generation.", "sentence2": "the transferred model exhibits narrower vocabulary usage.", "label": "contrasting"}
{"id": "test_582", "sentence1": "Statistic-based automatic metrics, such as BLEU (Papineni et al., 2002), mostly rely on the degree of word overlap between a dialogue response and its corresponding gold response.", "sentence2": "due to the ignorance of the underlying semantic of a response, they are biased and correlate poorly with human judgements in terms of response coherence (Liu et al., 2016).", "label": "contrasting"}
{"id": "test_583", "sentence1": "For example, BLEU computes the geometric average of the n-gram precisions.", "sentence2": "they can not cope with the one-to-many problem and have weak correlations with human judgements (Liu et al., 2016).", "label": "contrasting"}
{"id": "test_584", "sentence1": "ADEM proposed by Lowe et al. (2017) achieves higher correlations with human judgements than the statistic-based metrics, which is trained with human-annotated data in a supervised manner.", "sentence2": "it is time-consuming and expensive to obtain large amounts of annotated data.", "label": "contrasting"}
{"id": "test_585", "sentence1": "From the example in the first row, we can see that the score given by our metric is closer to the human score than the other two baseline metrics.", "sentence2": "in the second-row example, our metric performs poorly.", "label": "contrasting"}
{"id": "test_586", "sentence1": "In this hard case, the topics of the model response are relevant to the dialogue context so that both our GRADE and BERT-RUBER, as learning-based metrics, deem that the response greatly matches the context.", "sentence2": "the truth is that the model response is more likely a response for the previous utterance U1 rather than U2, which is hard for metrics to recognize.", "label": "contrasting"}
{"id": "test_587", "sentence1": "Such tasks include probing syntax (Hewitt and Manning, 2019; Lin et al., 2019; Tenney et al., 2019a), semantics (Yaghoobzadeh et al., 2019), discourse features (Chen et al., 2019; Liu et al., 2019; Tenney et al., 2019b), and commonsense knowledge (Petroni et al., 2019; Poerner et al., 2019).", "sentence2": "appropriate criteria for selecting a good probe is under debate.", "label": "contrasting"}
{"id": "test_588", "sentence1": "BLEURT (Sellam et al., 2020) applies fine tuning of BERT, including training on prior human judgements.", "sentence2": "our work exploits parallel bitext and doesn't require training on human judgements.", "label": "contrasting"}
{"id": "test_589", "sentence1": "We find that a copy of the input is almost as probable as beam search output for the Prism model.", "sentence2": "the model trained on ParaBank 2 prefers its own beam search output to a copy of the input.", "label": "contrasting"}
{"id": "test_590", "sentence1": "We find that the probability of sys as estimated by an LM, as well as and the cosine distance between LASER embeddings of sys and ref, both have decent correlation with human judgments and are complementary.", "sentence2": "cosine distance between LASER embeddings of sys and src have only weak correlation.", "label": "contrasting"}
{"id": "test_591", "sentence1": "Its creation is a manifestation of creativity, and, as such, hard to automate.", "sentence2": "since the development of creative machines is a crucial step towards real artificial intelligence, automatic poem generation is an important task at the intersection of computational creativity and natural language generation, and earliest attempts date back several decades; see Goncalo Oliveira (2017) for an overview.", "label": "contrasting"}
{"id": "test_592", "sentence1": "Since those differ significantly in style from the poems in KnownTopicPoems and Unknown-TopicPoems, we do not train our language model directly on them.", "sentence2": "we make use of the fact that sonnets follow a known rhyming scheme, and leverage them to train a neural model to produce rhymes, which will be explained in detail in Subsection 3.2.", "label": "contrasting"}
{"id": "test_593", "sentence1": "In particular, the generated poems seem to be more fluent and coherent than the alternatives.", "sentence2": "they do not relate to any specific topic, which probably causes the drop in quality for poeticness, where this model always performs worse than NeuralPoet.", "label": "contrasting"}
{"id": "test_594", "sentence1": "The increase of K continues to bring benefits until K = 4.", "sentence2": "performance begins to drop when K > 3.", "label": "contrasting"}
{"id": "test_595", "sentence1": "Neural Graph Encoding Graph Attention Networks (GAT) (Velickovic et al., 2018) incorporates attention mechanism in feature aggregation, RGCN (Schlichtkrull et al., 2018) proposes relational message passing which makes it applicable to multi-relational graphs.", "sentence2": "they only perform single-hop message passing and cannot be interpreted at path level.", "label": "contrasting"}
{"id": "test_596", "sentence1": "RGCNs (Schlichtkrull et al., 2018) generalize GCNs by performing relationspecific aggregation, making it applicable to multirelational graphs.", "sentence2": "these models do not distinguish the importance of different neighbors or relation types and thus cannot provide explicit relational paths for model behavior interpretation.", "label": "contrasting"}
{"id": "test_597", "sentence1": "This problem is clearly related a continual learning (CL) (Chen and Liu, 2018; Parisi et al., 2019; Li and Hoiem, 2017; Wu et al., 2018; Schwarz et al., 2018; Hu et al., 2019; Ahn et al., 2019), which also aims to learn a sequence of tasks incrementally.", "sentence2": "the main objective of the current CL techniques is to solve the catastrophic forgetting (CF) problem (McCloskey and Cohen, 1989).", "label": "contrasting"}
{"id": "test_598", "sentence1": "That is, in learning each new task, the network parameters need to be modified in order to learn the new task.", "sentence2": "this modification can result in accuracy degradation for the previously learned tasks.", "label": "contrasting"}
{"id": "test_599", "sentence1": "For sentiment classification, recent deep learning models have been shown to outperform traditional methods (Kim, 2014;Devlin et al., 2018;Shen et al., 2018;Qin et al., 2020).", "sentence2": "these models don't retain or transfer the knowledge to new tasks.", "label": "contrasting"}
{"id": "test_600", "sentence1": "MTL is often considered the upper bound of continual learning because it trains all the tasks together.", "sentence2": "its loss is the sum of the losses of all tasks, which does not mean it optimizes for every individual task.", "label": "contrasting"}
{"id": "test_601", "sentence1": "Automated radiology report generation has the potential to reduce the time clinicians spend manually reviewing radiographs and streamline clinical care.", "sentence2": "past work has shown that typical abstractive methods tend to produce fluent, but clinically incorrect radiology reports.", "label": "contrasting"}
{"id": "test_602", "sentence1": "In this work we focused on developing abstractive techniques as was done by past work on the MIMIC-CXR dataset (Liu et al., 2019; Boag et al., 2019).", "sentence2": "in the future we intend to combine the abstractive methods developed in this work with retrieval methods to further improve upon our framework.", "label": "contrasting"}
{"id": "test_603", "sentence1": "Sentence fusion has the lowest TER, indicating that obtaining the fused targets requires only a limited number of local edits.", "sentence2": "these edits require modeling the discourse relation between the two input sentences, since a common edit type is predicting the correct discourse connective (Geva et al., 2019).", "label": "contrasting"}
{"id": "test_604", "sentence1": "Meng and Rumshisky (2018) propose a global context layer (GCL) to store/read the solved TLINK history upon a pre-trained pair-wise classifier.", "sentence2": "they find slow converge when training the GCL and pair-wise classifier simultaneously.", "label": "contrasting"}
{"id": "test_605", "sentence1": "Meanwhile, a two-way deliberation decoder (Xia et al., 2017) was used for response generation.", "sentence2": "the relationship between the dialogue history and the last utterance is not well studied.", "label": "contrasting"}
{"id": "test_606", "sentence1": "As a result, capturing the incongruity between modalities is significant for multi-modal sarcasm detection.", "sentence2": "the existing models for multi-modal sarcasm detection either concatenate the features from multi modalities (Schifanella et al., 2016) or fuse the information from different modalities in a designed manner (Cai et al., 2019).", "label": "contrasting"}
{"id": "test_607", "sentence1": "Thus, an effective sarcasm detector is beneficial to applications like sentiment analysis, opinion mining (Pang and Lee, 2007), and other tasks that require people's real sentiment.", "sentence2": "the figurative nature of sarcasm makes it a challenging task (Liu, 2010).", "label": "contrasting"}
{"id": "test_608", "sentence1": "For the store owner, the task of correctly identifying the buying-intent utterances is paramount.", "sentence2": "the number of utterances related to searching for products is expected to be significantly higher, thus biasing the classifier toward this intent.", "label": "contrasting"}
{"id": "test_609", "sentence1": "Other approaches for data balancing can include weak-labeling of available unlabeled data (Ratner et al., 2020), or even active learning (Settles, 2009).", "sentence2": "both of these approaches require additional domain data which is not always available.", "label": "contrasting"}
{"id": "test_610", "sentence1": "We focused our evaluation on the Semantic Utterance Classification (SUC) domain which is characterized by highly imbalanced data.", "sentence2": "it is desirable to validate the applicability of our general balancing approach on other textual domains.", "label": "contrasting"}
{"id": "test_611", "sentence1": "Knowledge+BERT turns out to be the strongest baseline, outperforming the other three baselines, which also shows the importance of leveraging external knowledge for the OAC2 task.", "sentence2": "our model achieves superior performance over Knowledge+BERT which indicates leveraging domain-specific knowledge indeed helps.", "label": "contrasting"}
{"id": "test_612", "sentence1": "This is expected as these tweets include less standard words, such as insults.", "sentence2": "except for perhaps emotion detection and offensive language identification, the difference is not significant, considering that the original RoBERTa tokenizer was not trained on Twitter text.", "label": "contrasting"}
{"id": "test_613", "sentence1": "In normal attention, all n-grams are weighted globally and short n-grams may dominate the attention because they occur much more frequently than long ones and are intensively updated.", "sentence2": "there are cases that long n-grams can play an important role in parsing when they carry useful context and boundary information.", "label": "contrasting"}
{"id": "test_614", "sentence1": "These results could be explained by that frequent short n-grams dominate the general attentions so that the long ones containing more contextual information fail to function well in filling the missing information in the span representation, and thus harm the understanding of long spans, which results in inferior results in complete match score.", "sentence2": "the categorical span attention is able to weight n-grams in different length separately, so that the attentions are not dominated by high-frequency short n-grams and thus reasonable weights can be assigned to long n-grams.", "label": "contrasting"}
{"id": "test_615", "sentence1": "This is not surprising because short n-grams occur more frequently and are thus updated more times than long ones.", "sentence2": "the models with CATSA show a different weight distribution (the blue bars) among n-grams with different lengths, which indicates that the CATSA module could balance the weights distribution and thus enable the model to learn from infrequent long n-grams.", "label": "contrasting"}
{"id": "test_616", "sentence1": "Since the distances between the boundary positions of the wrongly predicted spans (highlighted in red) are relatively long, the baseline system, which simply represents the span as subtraction of the hidden vectors at the boundary positions, may fail to capture the important context information within the text span.", "sentence2": "the span representations used in our model are enhanced by weighted n-gram information and thus contain more context information.", "label": "contrasting"}
{"id": "test_617", "sentence1": "Because training with soft targets provides smoother output distribution, T/S learning could outperform the single model training (Li et al., 2014;Hinton et al., 2015;Meng et al., 2018).", "sentence2": "does a teacher always outperform a student?", "label": "contrasting"}
{"id": "test_618", "sentence1": "All models benefit from the increasing of D as expected.", "sentence2": "it is clear that Recurrence Online is the best performing model when D is small.", "label": "contrasting"}
{"id": "test_619", "sentence1": "We observe that the use of Static Rebalancing (Equation 6) instead, which is an extreme version of AISLe, is better than not resampling at all.", "sentence2": "it is unable to reach the performance of AISLe on coverage metrics.", "label": "contrasting"}
{"id": "test_620", "sentence1": "Kreutzer and Sokolov (2018) proposed to jointly learn to segment and translate by using hierarchical RNN (Graves, 2016), but the method is not model-agnostic and slow due to the increased sequence length of characterlevel inputs.", "sentence2": "our method is model-agnostic and operates on the word-level.", "label": "contrasting"}
{"id": "test_621", "sentence1": "Kudo (2018) also report scores using n-best decoding, which averages scores from n-best segmentation results.", "sentence2": "n-best decoding is n-times time consuming compared to the standard decoding method.", "label": "contrasting"}
{"id": "test_622", "sentence1": "Starting from machine translation, it has been shown that subword regularization can improve the robustness of NLP models in various tasks (Kim, 2019;Provilkov et al., 2019;Drexler and Glass, 2019;M\u00fcller et al., 2019).", "sentence2": "subword regularization relies on the unigram language models to sample candidates, where the language models are optimized based on the corpus-level statistics from training data with no regard to the translation task objective.", "label": "contrasting"}
{"id": "test_623", "sentence1": "SurfCon (Wang et al., 2019b) discovered synonyms on privacy-aware clinical data by utilizing the surface form information and the global context information.", "sentence2": "they suffer from either low precision or low recall.", "label": "contrasting"}
{"id": "test_624", "sentence1": "In this example, the word victim in the first English sentence is identified by our tagger as a human entity.", "sentence2": "its French translation victime is feminine by definition, and cannot be assigned another gender regardless of the context, causing a false positive result.", "label": "contrasting"}
{"id": "test_625", "sentence1": "Furthermore, they explain IBT as a way to better approximate the true posterior distribution with the target-to-source model.", "sentence2": "it is unclear how their heuristic objective relates to the ideal objective of maximizing the model's marginal likelihood of the target language monolingual data.", "label": "contrasting"}
{"id": "test_626", "sentence1": "Deep neural models have demonstrated promising results in text classification tasks (Kim, 2014;Zhang et al., 2015;Howard and Ruder, 2018), owing to their strong expressive power and less requirement for feature engineering.", "sentence2": "the deeper and more complex the neural model, the more it is essential for them to be trained on substantial amount of training data.", "label": "contrasting"}
{"id": "test_627", "sentence1": "Several natural language processing methods, including deep neural network (DNN) models, have been applied to address this problem.", "sentence2": "these methods were trained with hard-labeled data, which tend to become over-confident, leading to degradation of the model reliability.", "label": "contrasting"}
{"id": "test_628", "sentence1": "In the training step, the model is trained to maximize the output probability of the correct class.", "sentence2": "some studies reported that the deep learning classifier trained with hard-labeled data (1 for correct class, 0 for else) tends to become over-confident (Nixon et al., 2019;Thulasidasan et al., 2019).", "label": "contrasting"}
{"id": "test_629", "sentence1": "These deep learning methods can effectively generate abstractive document summaries by directly optimizing pre-defined goals.", "sentence2": "the meeting summarization task inherently bears a number of challenges that make it more difficult for end-to-end training than document summarization.", "label": "contrasting"}
{"id": "test_630", "sentence1": "As shown in Figure 1, the medical report generation system should generate correct and concise reports for the input images.", "sentence2": "data imbalance may reduce the quality of automatically generated reports.", "label": "contrasting"}
{"id": "test_631", "sentence1": "To improve the clinical correctness of the generated reports, Liu et al. (2019a) and Irvin et al. (2019) adopted clinically coherent rewards for RL with CheXpert Labeler (Irvin et al., 2019), a rule-based finding mention annotator", "sentence2": "in the medical domain, no such annotator is available in most cases other than English chest X-ray reports.", "label": "contrasting"}
{"id": "test_632", "sentence1": "The input data, which comprise a set of finding labels, can be augmented easily by adding or removing a finding label automatically.", "sentence2": "the augmentation cost is higher for the target reports than the input data because the target reports are written in natural language.", "label": "contrasting"}
{"id": "test_633", "sentence1": "In addition to (c) above, we apply the modification process to the finding labels predicted by the image diagnosis module.", "sentence2": "it is too expensive to evaluate the model in this condition because the cost of radiologist services is too high.", "label": "contrasting"}
{"id": "test_634", "sentence1": "For comparison with the previous image captioning approaches, we used BLEU-1, BLEU-2, BLEU-3, and BLEU-4 metrics calculated by the nlg-eval 10 library.", "sentence2": "word-overlap based metrics, such as BLEU, fail to assume the factual correctness of generated reports.", "label": "contrasting"}
{"id": "test_635", "sentence1": "In ERNIE, entity embeddings are learned by TransE (Bordes et al., 2013), which is a popular transitionbased method for knowledge representation learning (KRL).", "sentence2": "transE cannot deal with the modeling of complex relations , such as 1-to-n, n-to-1 and n-to-n relations.", "label": "contrasting"}
{"id": "test_636", "sentence1": "An intuitive way for vanilla GCN to exploit these labels is to encode different types of dependency relation with different convolutional filters, which is similar to RGCN (Kipf and Welling, 2017).", "sentence2": "rGCN suffers from over-parameterization, where the number of parameters grows rapidly with the number of relations.", "label": "contrasting"}
{"id": "test_637", "sentence1": "We considered each sentence as a single claim to keep our experimental setting clean and avoid noise from an automatic claim extractor.", "sentence2": "some generations contain multiple claims that could be independently assessed.", "label": "contrasting"}
{"id": "test_638", "sentence1": "By thorough error analysis, we realize that for the order h-t-r (t-h-r follows the same logic), the model has to predict all t with regard to h in the second time step, without constraints from the r, and this makes every possible entity to be a prediction candidate.", "sentence2": "the model is unable to eliminate no-relation entity pairs at the third time step, thus the model is prone to feed entity pairs to the classification layer with an low odds (low recall) but high confidence (high precision).", "label": "contrasting"}
{"id": "test_639", "sentence1": "Over the past two decades, significant progress has been made in the development of word embedding techniques (Lund and Burgess, 1996; Bengio et al., 2003; Bullinaria and Levy, 2007; Mikolov et al., 2013b; Pennington et al., 2014).", "sentence2": "existing word embedding methods do not handle numerals adequately and cannot directly encode the numeracy and magnitude of a numeral Naik et al. (2019).", "label": "contrasting"}
{"id": "test_640", "sentence1": "These studies conclude that when certain nouns are dropped from the dominant language modality, multimodal models are capable of properly using the semantics provided by the image.", "sentence2": "unlike this work, their explorations are limited to nouns and not expanded to other types of words.", "label": "contrasting"}
{"id": "test_641", "sentence1": "They demonstrate high compression rate with little loss of performance.", "sentence2": "they compress only the input embedding and not the softmax layer for language modeling and machine translation.", "label": "contrasting"}
{"id": "test_642", "sentence1": "Specifically, they regard each segmentation criterion as a single  task under the framework of multi-task learning, where a shared layer is used to extract the criteriainvariant features, and a private layer is used to extract the criteria-specific features.", "sentence2": "it is unnecessary to use a specific private layer for each criterion.", "label": "contrasting"}
{"id": "test_643", "sentence1": "As shown in several previous research (Pang et al., 2016;Yang et al., 2016;Mitra et al., 2017;Xiong et al., 2017;Devlin et al., 2018), interaction-focused models usually achieve better performances for text pair tasks.", "sentence2": "it is difficult to serve these types of models for applications involving large inference sets in practice.", "label": "contrasting"}
{"id": "test_644", "sentence1": "However, it is difficult to serve these types of models for applications involving large inference sets in practice.", "sentence2": "text embeddings from dual encoder models can be learned independently and thus pre-computed, leading to faster inference efficiency but at the cost of reduced quality.", "label": "contrasting"}
{"id": "test_645", "sentence1": "Recently the PreTTR model (MacAvaney et al., 2020) aimed to reduce the query-time latency of deep transformer networks by pre-computing part of the document term representations.", "sentence2": "their model still required modeling the full document/query input length in the head, thus limiting inference speedup.", "label": "contrasting"}
{"id": "test_646", "sentence1": "One of the most effective ways to reduce the running time is to reduce the input sequence length.", "sentence2": "as Table 4 reveals, blindly truncating the input to a BERT model will lead to a quick performance drop.", "label": "contrasting"}
{"id": "test_647", "sentence1": "When the head is transformerbased, the two-stage training plays an important role: the AUC ROC improves from 0.891 to 0.930.", "sentence2": "the gain introduced by using two-stage training is less significant in other approaches such as DE-FFNN and DIPAIRFFNN.", "label": "contrasting"}
{"id": "test_648", "sentence1": "Recall that, in our framework, each encoder outputs its first few token embeddings as the input to the head, and we end to end to train the model to force the encoder to push the information of the input text into those outputted embeddings.", "sentence2": "it is unclear to us what those outputted embeddings actually learn.", "label": "contrasting"}
{"id": "test_649", "sentence1": "We formalize word reordering as a combinatorial optimization problem to find the permutation with the highest probability estimated by a POS-based language model.", "sentence2": "it is computationally difficult to obtain the optimal word order.", "label": "contrasting"}
{"id": "test_650", "sentence1": "With some classifiers, we reached the same F1-score as when training on the original dataset, which is 20x larger.", "sentence2": "performance varied markedly between classifiers.", "label": "contrasting"}
{"id": "test_651", "sentence1": "This demonstrates that GPT-2 significantly increased the vocabulary range of the training set, specifically with offensive words likely to be relevant for toxic language classification.", "sentence2": "there is a risk that human annotators might not label GPT-2-generated documents as toxic.", "label": "contrasting"}
{"id": "test_652", "sentence1": "TABLE-BERT is a BERT-base model that similar to our approach directly predicts the truth value of the statement.", "sentence2": "the model does not use special embeddings to encode the table structure but relies on a template approach to format the table as natural language.", "label": "contrasting"}
{"id": "test_653", "sentence1": "In language tasks, adversarial training brings wordlevel robustness by adding input noise, which is beneficial for text classification.", "sentence2": "it lacks sufficient contextual information enhancement and thus is less useful for sequence labelling tasks such as chunking and named entity recognition (NER).", "label": "contrasting"}
{"id": "test_654", "sentence1": "Masked language model (Devlin et al., 2018) smooths this inconsistency by applying replacement of tokens for some data while masking the rest (equivalent to word dropout).", "sentence2": "the replacement in masked language model is randomly chosen from the full vocabulary, but the substitution in real sce\u0002narios follows some distribution (e.g. replacing \u201cMassachusetts\u201d with a location name is more likely than an animal name), which is not considered in masked language model.", "label": "contrasting"}
{"id": "test_655", "sentence1": "Zhao et al. (2018) proposed the learning scheme to generate a gender-neutral version of Glove, called GN-Glove, which forces preserving the gender information in pre-specified embedding dimensions while other embedding dimensions are inferred to be gender-neutral.", "sentence2": "learning new word embeddings for large-scale corpus can be difficult and expensive.", "label": "contrasting"}
{"id": "test_656", "sentence1": "Table 4 shows that there are constant performance degradation effects for all debiasing methods from the original embedding.", "sentence2": "our methods minimized the degradation of performances across the baseline models.", "label": "contrasting"}
{"id": "test_657", "sentence1": "A clear-cut solution to this problem is to focus more on samples that are more relevant to the target task during pretraining.", "sentence2": "this requires a task-specific pretraining, which in most cases is computational or time prohibitive.", "label": "contrasting"}
{"id": "test_658", "sentence1": "Further, Moreo et al. (2019) concatenates label embedding with word embeddings.", "sentence2": "this approach cannot be directly implemented into PLMs since the new (concatenated) embedding is not compatible with the pretrained parameters.", "label": "contrasting"}
{"id": "test_659", "sentence1": "The growing interest in argument mining and computational argumentation brings with it a plethora of Natural Language Understanding (NLU) tasks and corresponding datasets.", "sentence2": "as with many other NLU tasks, the dominant language is English, with resources in other languages being few and far between.", "label": "contrasting"}
{"id": "test_660", "sentence1": "The ZS and TT baselines are almost always outperformed by the best translate-train model.", "sentence2": "when a large-scale English corpus is available (Figure 2b), the TT baseline becomes comparable to the best translate-train models.", "label": "contrasting"}
{"id": "test_661", "sentence1": "Dialogue policy learning for Task-oriented Dialogue Systems (TDSs) has enjoyed great progress recently mostly through employing Reinforcement Learning (RL) methods.", "sentence2": "these approaches have become very sophisticated.", "label": "contrasting"}
{"id": "test_662", "sentence1": "With respect to success rate, DiaAdv manages to achieve the highest performance by 6% compared to the second highest method GDPL.", "sentence2": "diaAdv is not able to beat GdPL in terms of average turns.", "label": "contrasting"}
{"id": "test_663", "sentence1": "As to DiaSeq, it can achieve almost the same  performance as GDPL from different perspectives while GDPL has a slightly higher F1 score.", "sentence2": "the potential cost benefits of DiaSeq are huge since it does not require a user simulator in the training loop.", "label": "contrasting"}
{"id": "test_664", "sentence1": "Beyond this, DiaMultiClass does not benefit from the increase in expert dialogues and starts to fluctuate between 55% and 59%.", "sentence2": "di-aSeq can achieve higher performance when there are only 10% expert dialogue pairs and the success rate increases with the number of available expert dialogues.", "label": "contrasting"}
{"id": "test_665", "sentence1": "The proposed methods can achieve state-of-the-art performance suggested by existing approaches based on Reinforcement Learning (RL) and adversarial learning.", "sentence2": "we have demonstrated that our methods require fewer training efforts, namely the domain knowledge needed to design a user simulator and the intractable parameter tuning for RL or adversarial learning.", "label": "contrasting"}
{"id": "test_666", "sentence1": "Our evaluation settings hiding one of the three inputs to the MCQA models -are similar to Kaushik and Lipton 2018's partial input settings which were designed to point out the existence of dataset artifacts in reading comprehension datasets.", "sentence2": "we argue that our results additionally point to a need for more robust training methodologies and propose an improved training approach.", "label": "contrasting"}
{"id": "test_667", "sentence1": "Among these, hyperedge replacement grammar (HRG) has been explored for parsing into semantic graphs (Habel, 1992;Chiang et al., 2013).", "sentence2": "parsing with HRGs is not practical due to its complexity and large number of possible derivations per graph (Groschwitz et al., 2015).", "label": "contrasting"}
{"id": "test_668", "sentence1": "Drawing on this result, a recent work by Fancellu et al. (2019) introduces recurrent neural network RDGs, a sequential decoder that models graph generation as a rewriting process with an underlying RDG.", "sentence2": "despite the promising framework the approach in FA19 2 falls short in several aspects.", "label": "contrasting"}
{"id": "test_669", "sentence1": "Composition is constrained by the rank of a nonterminal so to ensure that at each decoding step the model is always aware of the placement of reentrant nodes.", "sentence2": "we do not ensure semantic well-formedness in that words are predicted separately from their fragments and we do not rely on alignment information.", "label": "contrasting"}
{"id": "test_670", "sentence1": "Early CLWE approaches required expensive parallel data (Klementiev et al., 2012; T\u00e4ckstr\u00f6m et al., 2012).", "sentence2": "later approaches rely on high-coverage bilingual dictionaries (Gliozzo and Strapparava, 2006; Faruqui and Dyer, 2014; or smaller \"seed\" dictionaries (Gouws and S\u00f8gaard, 2015; Artetxe et al., 2017).", "label": "contrasting"}
{"id": "test_671", "sentence1": "Multilingual BERT performs well on zero-shot cross-lingual transfer (Wu and Dredze, 2019; Pires et al., 2019) and its performance can be further improved by considering target-language documents through self-training (Dong and de Melo, 2019).", "sentence2": "our approach does not require multilingual language models and sometimes outperforms multilingual BERT using a monolingual BERT student.", "label": "contrasting"}
{"id": "test_672", "sentence1": "Neural network-based models augmented with unsupervised pre-trained knowledge have achieved impressive performance on text summarization.", "sentence2": "most existing evaluation methods are limited to an in-domain setting, where summarizers are trained and evaluated on the same dataset.", "label": "contrasting"}
{"id": "test_673", "sentence1": "Bigpatent B also exhibits relatively higher copy rate in summary but the copy segments is shorter than CNNDM.", "sentence2": "bigaptent b, Xsum obtain higher sentence fusion score, which suggests that the proportion of fused sentences in these two datasets are high.", "label": "contrasting"}
{"id": "test_674", "sentence1": "2) BART (SOTA system) is superior over other abstractive models and even comparable with extractive models in terms of stiffness (ROUGE).", "sentence2": "it is robust when transferring between datasets as it possesses high stableness (ROUGE).", "label": "contrasting"}
{"id": "test_675", "sentence1": "Typical sources of transfer loss concern differences in features between domains (Blitzer et al., 2007;Ben-David et al., 2010).", "sentence2": "other factors may govern model degradation for depression clas-sification.", "label": "contrasting"}
{"id": "test_676", "sentence1": "Topical nuances in language may appropriately reflect elements of identity associated with mental health disorders (i.e. traumatic experiences, coping mechanisms)", "sentence2": "if not contextualized during model training, this type of signal has the potential to raise several false alarms upon application to new populations.", "label": "contrasting"}
{"id": "test_677", "sentence1": "Figure 3b shows that BiLSTM uses 35% of context for short sentences, 20% for medium, and only 10% for long sentences.", "sentence2": "bERT leverages fixed 75% of context words regardless of the sentence length.", "label": "contrasting"}
{"id": "test_678", "sentence1": "VQA requires techniques from both image recognition and natural language processing, and most existing works use Convolutional Neural Networks (CNNs) to extract visual features from images and Recurrent Neural Networks (RNNs) to generate textual features from questions, and then combine them to generate the final answers.", "sentence2": "most existing VQA datasets are created in a way that is not suitable as training data for real-world applications.", "label": "contrasting"}
{"id": "test_679", "sentence1": "VQA models following this setting take characteristics of all answer candidates like word embeddings as the input to make a selection (Sha et al., 2018; Jabri et al., 2016).", "sentence2": "in the open-ended setting, there is neither prior knowledge nor answer candidates provided, and the model can respond with any freeform answers.", "label": "contrasting"}
{"id": "test_680", "sentence1": "We conjecture that this is because when we have limited amount of target data, having more prior knowledge is beneficial to model performance, while having more target data will make prior knowledge less helpful.", "sentence2": "our method can stably improve the performance because it sufficiently makes use of target data and source data.", "label": "contrasting"}
{"id": "test_681", "sentence1": "Importantly, we do not define a precondition event as an absolute requirement for the target (the door opening) to occur in all scenarios.", "sentence2": "we do require that the target event likely would not have occurred in the current context.", "label": "contrasting"}
{"id": "test_682", "sentence1": "This reveals the source of improvement in attack success rate between GENETICATTACK and TEXTFOOLER to be more lenient constraint application.", "sentence2": "gE-NETICATTACK's genetic algorithm is far more computationally expensive, requiring over 40x more model queries.", "label": "contrasting"}
{"id": "test_683", "sentence1": "Gilmer et al. (2018) laid out a set of potential constraints for the attack space when generating adversarial examples, which are each useful in different real-world scenarios.", "sentence2": "they did not discuss NLP attacks in particular.", "label": "contrasting"}
{"id": "test_684", "sentence1": "Object manipulation and configuration is another subject that has been studied along with language and vision grounding (Bisk et al., 2016;Wang et al., 2016;Li et al., 2016;Bisk et al., 2018).", "sentence2": "most studies focus on addressing the problem in relatively simple environments from a third-person view.", "label": "contrasting"}
{"id": "test_685", "sentence1": "It is possible for instructions to be written that can pass all automated checks and still be of poor quality.", "sentence2": "there is no quick and reliable way to automatically check if an instruction passes the tests but is still vague or misleading.", "label": "contrasting"}
{"id": "test_686", "sentence1": "There are several benchmarks (Wen et al., 2017;El Asri et al., 2017;Eric and Manning, 2017;Wei et al., 2018) to evaluate the performance of neural models for goal-oriented dialog.", "sentence2": "these benchmarks assume a world of a \"perfect\" user who always provides precise, con- cise, and correct utterances.", "label": "contrasting"}
{"id": "test_687", "sentence1": "Zhao and Eskenazi (2018) created SimDial, which simulates spoken language phenomena, e.g. self-repair and hesitation. Sankar et al. (2019) introduce utterance-level and word\u0002level perturbations on various benchmarks.", "sentence2": "such variations have been largely artificial and do not reflect the \"natural variation\" commonly found in naturally occuring conversational data.", "label": "contrasting"}
{"id": "test_688", "sentence1": "The conversational activity patterns (denoted by A) handle the main business of conversation, i.e. the user request and the services provided by agent.", "sentence2": "conversation management patterns help the user and agent to manage the conversation itself.", "label": "contrasting"}
{"id": "test_689", "sentence1": "Since the models are evaluated only on the agent responses present in the original test set, additional user and agent utterances for incorporating natural variation do not affect performance  Table 5: Ablation results for GLMP model on SMD too much.", "sentence2": "sMD is a real-world dataset of human-to-human conversations collected by crowdsourcing and we observe a much higher drop across both BLEU and Ent F1 scores.", "label": "contrasting"}
{"id": "test_690", "sentence1": "This resulted in some novelty in the data collected and prevented the user utterances to be repetitive.", "sentence2": "to control data collection, the participants were asked to follow a set of instructions which resulted in user utterances largely focused on the task.", "label": "contrasting"}
{"id": "test_691", "sentence1": "The dataset is the largest currently as it has largest context complexity and state complexity (based on all possible combinations of customer and agent context features, like number of flights in the database, number of airlines, airport codes and dialogue action states), in comparison to other existing datasets mentioned above.", "sentence2": "the authors don't share details on how the dataset was collected and instructions provided to the participants", "label": "contrasting"}
{"id": "test_692", "sentence1": "As shown in Figure 2, a correlation exists between some relevant events (such as the first joint press release) and the number of articles published.", "sentence2": "a higher volume of articles does not always correlate with higher disagreement rates between annotators: interestingly, it seems that some events (such as the merger agreement) spread more uncertainty around the merger than others (such as the start of the antitrust trial).", "label": "contrasting"}
{"id": "test_693", "sentence1": "Similar to our baselines ScRNN (Sakaguchi et al., 2017) and MUDE (Wang et al., 2019), Li et al. (2018) proposed a nested RNN to hierarchically encode characters to word representations, then correct each word using a nested GRU .", "sentence2": "these previous works either only train models on natural misspellings (Sakaguchi et al., 2017) or synthetic misspellings , and only focus on denoising the input texts from orthographic perspective without leveraging the retained semantics of the noisy input.", "label": "contrasting"}
{"id": "test_694", "sentence1": "These LMs captures the probability of a word or a sentence given their context, which plays a crucial role in correcting real-word misspellings.", "sentence2": "all of the LMs mentioned are based on subword embeddings, such as WordPiece (Peters et al., 2018) or Byte Pair Encoding (Gage, 1994) to avoid OOV words.", "label": "contrasting"}
{"id": "test_695", "sentence1": "XLNet (Yang et al., 2019) also marginalize over all possible factorizations.", "sentence2": "their work is focused on the conditional distribution p(y|x), and they do not marginalize over all possible factorizations of the joint distribution.", "label": "contrasting"}
{"id": "test_696", "sentence1": "KERMIT is a generative joint distribution model that also learns all possible factorizations.", "sentence2": "kERMIT is constrained to two languages, while MGLM is a generative joint distribution model across any/all languages/text while learning all possible factorizations of the joint distribution.", "label": "contrasting"}
{"id": "test_697", "sentence1": "Multilingual Neural Language Model (Wada and Iwata, 2018) uses a shared encoder and language-dependent decoders to generate word embeddings and evaluate word alignment tasks.", "sentence2": "our work unifies the neural architecture with a straightforward stack of self-attention layers.", "label": "contrasting"}
{"id": "test_698", "sentence1": "Our work focused on a specific instantiation of channels as languages.", "sentence2": "mGLm is not limited to only languages and can generalize to other notions of channels.", "label": "contrasting"}
{"id": "test_699", "sentence1": "suggest a misleading \"PERSON\" label 19 because of their context features, so that an incorrect NER prediction is expected if treating the three types of syntactic information equally.", "sentence2": "the syntactic constituents give strong indication of the correct label through the word \"Rights\" for a \"LAW\" entity.", "label": "contrasting"}
{"id": "test_700", "sentence1": "Recently, neural models play dominant roles in NER because of their effectiveness in capturing contextual information in the text without requir\u0002ing to extract manually crafted features (Huang et al., 2015; Lample et al., 2016; Strubell et al., 2017; Zhang and Yang, 2018; Peters et al., 2018; Yadav and Bethard, 2018; Cetoli et al., 2018; Ak\u0002bik et al., 2018, 2019; Chen et al., 2019; Devlin et al., 2019; Zhu and Wang, 2019; Liu et al., 2019b; Baevski et al., 2019; Yan et al., 2019; Xu et al., 2019a; Zhu et al., 2020; Luo et al.).", "sentence2": "to enhance NER, it is straightforward to incorporate more knowledge to it than only modeling from contexts.", "label": "contrasting"}
{"id": "test_701", "sentence1": "It is thus far more important to evaluate various seed configurations that various target documents.", "sentence2": "we wanted to keep the computational cost of evaluation reasonably small, so either the number of seed configurations had to be  reduced or the number of target documents for each configuration.", "label": "contrasting"}
{"id": "test_702", "sentence1": "In a recent edition, Rabelo et al. (2019) used a BERT model fine-tuned on a provided training set in a supervised manner, and achieved the highest F-score among all teams.", "sentence2": "due to the reasons discussed in Section 4, their approach is not consistent with the nearest neighbor search, which is what we are aiming for.", "label": "contrasting"}
{"id": "test_703", "sentence1": "Deep neural models have achieved impressive success in many areas.", "sentence2": "their interpretability and explainability have remained broadly limited", "label": "contrasting"}
{"id": "test_704", "sentence1": "Such methods extract parts of the model input that are important to the output according to some criterion.", "sentence2": "they are not suited to evaluate NL explanations that are not part of the input, which motivates our new simulatability metric.", "label": "contrasting"}
{"id": "test_705", "sentence1": "Among others, dependency trees help to directly link the aspect term to the syntactically related words in the sentence, thus facilitating the graph convolutional neural networks (GCN) (Kipf and Welling, 2017) to enrich the representation vectors for the aspect terms.", "sentence2": "there are at least two major issues in these graph-based models that should be addressed to boost the performance.", "label": "contrasting"}
{"id": "test_706", "sentence1": "These statements represent generic commonsense hypotheses about social behaviors and their acceptability that are held as norms in a society.", "sentence2": "such normative judgments can also be strengthened or weakened given appropriate context.", "label": "contrasting"}
{"id": "test_707", "sentence1": "Hyperbolic spaces offer a mathematically appealing approach for learning hierarchical representations of symbolic data.", "sentence2": "it is not clear how to integrate hyperbolic components into downstream tasks.", "label": "contrasting"}
{"id": "test_708", "sentence1": "Many models that fuse visual and linguistic features have been proposed.", "sentence2": "few models consider the fusion of linguistic features with multiple visual features with different sizes of receptive fields, though the proper size of the receptive field of visual features intuitively varies depending on expressions.", "label": "contrasting"}
{"id": "test_709", "sentence1": "Zhao et al. (2018) also proposes a model with a structure that fuses multiple scales and languages for weakly supervised learning.", "sentence2": "they use concatenation as the method of fusion, whereas we use FiLM.", "label": "contrasting"}
{"id": "test_710", "sentence1": "The paraphrase ratio of the augmented training set remains similar as the original set.", "sentence2": "the ratio increases in the augmented testing set indicating the paraphrase clusters are sparser in the testing set.", "label": "contrasting"}
{"id": "test_711", "sentence1": "Another line of work learns Hornclause style reasoning rules from the KG and stores them in its parameters (Rocktaschel and Riedel, 2017; Das et al., 2018; Minervini et al., 2020).", "sentence2": "these parametric approaches work with a fixed set of entities and it is unclear how these models will adapt to new entities.", "label": "contrasting"}
{"id": "test_712", "sentence1": "For example, the performance (MRR) of ROTATE model (Sun et al., 2019) drops by 11 points (absolute) on WN18RR in this setting (\u00a73.4).", "sentence2": "we show that with new data, the performance of our model is consistent as it is able to seamlessly reason with the newly arrived data.", "label": "contrasting"}
{"id": "test_713", "sentence1": "Recent works (Teru et al., 2020;Wang et al., 2020) learn entity independent relation representations and hence allow them to handle unseen entities.", "sentence2": "they do not perform contextual reasoning by gathering reasoning paths from similar entities.", "label": "contrasting"}
{"id": "test_714", "sentence1": "As a result, many of the query relations were different from what was present in the splits of NELL-995 and hence is not a good representative.", "sentence2": "we report test results for the best hyper-parameter values that we got on this validation set.", "label": "contrasting"}
{"id": "test_715", "sentence1": "For sentences in GENIA, the number of candidate regions generated by HiRe is 77.9% less than that of the enumeration method discarding 1.3% long entities and more than that of (Zheng et al., 2019).", "sentence2": "the true recall of candidate regions generated by the enumeration method and HiRe are 98.7% and 98.1%, respectively.", "label": "contrasting"}
{"id": "test_716", "sentence1": "HiRe without HRR employs Average Word Representation (denoted as AWR) instead with precision 78.3%, recall 73.7% and F1 measure 75.9%.", "sentence2": "to HiRe AWR , the absolute F1 measure improvement of HiRe HRR is 0.6%.", "label": "contrasting"}
{"id": "test_717", "sentence1": "Therefore some recent researches attempt to endow the bots with proactivity through external knowledge to transform the role from a listener to a speaker with a hypothesis that the speaker expresses more just like a knowledge disseminator.", "sentence2": "along with the proactive manner introduced into a dialogue agent, an issue arises that, with too many knowledge facts to express, the agent starts to talks endlessly, and even completely ignores what the other expresses in dialogue sometimes, which greatly harms the interest of the other chatter to continue the conversation.", "label": "contrasting"}
{"id": "test_718", "sentence1": "Models facilitated with external knowledge indeed generate more meaningful responses than peers that train only on the source-target dialogue dataset.", "sentence2": "these models tend to fall into another situation where the machine agent talks too much ignoring what the other has said, let alone the inappropriate use of knowledge.", "label": "contrasting"}
{"id": "test_719", "sentence1": "What's more, with copy mechanism, CopyNet, DeepCopy, and Initiative-Imitate perform better in terms of fluency and coherence because of the utilizing of proper knowledge.", "sentence2": "comparing CopyNet and DeepCopy with Seq2Seq attn , the Engagement becomes worse because too much knowledge harms the ability to react to the proposed ques-tion very likely.", "label": "contrasting"}
{"id": "test_720", "sentence1": "Lexical resources such as WordNet (Miller, 1995) capture such synonyms (say, tell) and hypernyms (whisper, talk), as well as antonyms, which can be used to refer to the same event when the arguments are reversed ([a] 0 beat [a] 1 , [a] 1 lose to [a] 0 ).", "sentence2": "WordNet\u2019s coverage is insufficient, in particular, missing contextspecific paraphrases (e.g. (hide, launder), in the context of money).", "label": "contrasting"}
{"id": "test_721", "sentence1": "During training, each encoder learns a language model specific to an individual MT source, yielding diversity among experts in the final system.", "sentence2": "in order to improve robustness of each encoder to translation variability, inputs to each encoder are shuffled by some tuned probability p shuffle .", "label": "contrasting"}
{"id": "test_722", "sentence1": "Previous LSTM-based ensemble approaches propose training full parallel networks and ensemble at the final decoding step.", "sentence2": "we found this was too expensive given the nonrecurrent Transformer model.", "label": "contrasting"}
{"id": "test_723", "sentence1": "Most current multi-hop relation reasoning models require a good amount of training data (fact triples) for each query relation.", "sentence2": "the relation frequency distribution in KB is usually longtail , showing that a large portion of relations only have few-shot fact triples for model training.", "label": "contrasting"}
{"id": "test_724", "sentence1": "We look into the task of generalizing word embeddings: extrapolating a set of pre-trained word embeddings to words out of its fixed vocabulary, without extra access to contextual information (e.g. example sentences or text corpus).", "sentence2": "the more common task of learning word embeddings, or often just word embedding, is to obtain distributed representations of words directly from large unlabeled text.", "label": "contrasting"}
{"id": "test_725", "sentence1": "We omit the prediction time for KVQ-FH, as we found it hard to separate the actual inference time from time used for other processes such as batching and data transfer between CPU and GPU.", "sentence2": "we believe the overall trend should be similar as for the training time.", "label": "contrasting"}
{"id": "test_726", "sentence1": "In this field, the supervised methods, ranging from the conventional graph models (McCallum et al., 2000; Malouf, 2002; McCallum and Li, 2003; Settles, 2004) to the dominant deep neural methods (Collobert et al., 2011; Huang et al., 2015; Lample et al., 2016; Gridach, 2017; Liu et al., 2018; Zhang and Yang, 2018; Jiang et al., 2019; Gui et al., 2019), have achieved great success.", "sentence2": "these supervised methods usually require large scale labeled data to achieve good performance, while the annotation of NER data is often laborious and time-consuming.", "label": "contrasting"}
{"id": "test_727", "sentence1": "Then, it finetunes the model pretrained on the source task (with the output layer being replaced) using the re-annotated data to perform the target task.", "sentence2": "it is worth noting that the NER labels of words are contextdependent.", "label": "contrasting"}
{"id": "test_728", "sentence1": "However, given that style transfer can be viewed as a monolingual machine translation (MT) task, and that seq2seq models such as the transformer have shown to outperform unsupervised methods in multi-lingual MT when a sufficiently large parallel corpus is available (Lample et al., 2018; Artetxe et al., 2019; Subramanian et al., 2018), in our opinion it is expected that seq2seq would outperform unsupervised approaches if parallel data is available for style transfer.", "sentence2": "to the best of our knowledge, a parallel corpus for style transfer currently does not exist.", "label": "contrasting"}
{"id": "test_729", "sentence1": "Therefore, finding the value for STAcc is trivial once C has been found.", "sentence2": "finding a value for C is the main issue for the metric, since it depends on evaluating the set of generated outputs how many of them were converted successfully.", "label": "contrasting"}
{"id": "test_730", "sentence1": "We show that in a data-rich setting, with sufficient training examples, our approach outperforms a classification-based encoder-only model.", "sentence2": "our sequence-to-sequence model appears to be far more data-efficient, significantly outperforming BERT with few training examples in a data-poor setting.", "label": "contrasting"}
{"id": "test_731", "sentence1": "We discuss this question in Section 5.4.", "sentence2": "as a preview, we find that the choice of target tokens has a large impact on effectiveness in some circumstances, and these experiments shed light on why T5 works well for document ranking.", "label": "contrasting"}
{"id": "test_732", "sentence1": "While the approach can exploit pretrained knowledge when fine-tuning the latent representations, the final mapping (i.e., the fully-connected layer) needs to be learned from scratch (since it is randomly initialized).", "sentence2": "T5 can exploit both pretrained knowledge and knowledge gleaned from fine-tuning in learning task-specific latent representations as well as the mapping to relevance decisions; specifically, we note that T5 is pretrained with tasks whose outputs are \"true\" and \"false\".", "label": "contrasting"}
{"id": "test_733", "sentence1": "It has long been observed that most relation tuples follow syntactic regularity, and many syntactic patterns have been designed for extracting tuples, such as TEXTRUNNER (Banko et al., 2007) and ReVerb (Fader et al., 2011).", "sentence2": "it is difficult to design high coverage syntactic patterns, although many extensions have been proposed, such as WOE (Wu and Weld, 2010), OLLIE (Mausam et al., 2012), ClausIE (Corro and Gemulla, 2013), Standford Open IE , PropS  and OpenIE4 (Mausam, 2016).", "label": "contrasting"}
{"id": "test_734", "sentence1": "If BERT considers either name to be a common French name, then a correct answer is insufficient evidence for factual knowledge about the entity Jean Marais.", "sentence2": "if neither Jean nor Marais are considered French, but a correct answer is given regardless, we consider it sufficient evidence of factual knowledge.", "label": "contrasting"}
{"id": "test_735", "sentence1": "Existing approaches to improve generalization in QA either are only applicable when there exist multiple training domains (Talmor and Berant, 2019;Takahashi et al., 2019; or rely on models and ensembles with larger capacity (Longpre et al., 2019;Su et al., 2019;.", "sentence2": "our novel debiasing approach can be applied to both single and multi-domain scenarios, and it improves the model generalization without requiring larger pre-trained language models.", "label": "contrasting"}
{"id": "test_736", "sentence1": "Mahabadi et al. (2020) handle multiple biases jointly and show that their debiasing methods can improve the performance across datasets if they fine-tune their debiasing methods on each target dataset to adjust the debiasing parameters.", "sentence2": "the impact of their method is unclear on generalization to unseen evaluation sets.", "label": "contrasting"}
{"id": "test_737", "sentence1": "In addition, some works (Sukhbaatar et al., 2015;Madotto et al., 2018;Wu et al., 2019) have considered integrating KBs in a task-oriented dialogue system to generate a suitable response and have achieved promising performance.", "sentence2": "these methods either are limited by predefined configurations or do not scale to large KBs.", "label": "contrasting"}
{"id": "test_738", "sentence1": "However, as the KBs continue to grow in the real-world scenarios, such end-to-end methods of directly encoding and integrating whole KBs will eventually result in inefficiency and incorrect responses.", "sentence2": "some works may put the user utterances through a semantic parser to obtain executable logical forms and apply this symbolic query to the KB to retrieve entries based on their attributes.", "label": "contrasting"}
{"id": "test_739", "sentence1": "In the transformer, the representation of each query token gets updated by self-attending to the representations of all the query tokens and graph nodes in the previous layer.", "sentence2": "the representation of each graph node gets updated by self-attending only to its graph neighbors according to the connections of the sparsely connected transformer as well as all query tokens.", "label": "contrasting"}
{"id": "test_740", "sentence1": "Thus, we explore the possibility of augmenting the user-generated data with synthetic data in order to train a better model.", "sentence2": "one needs to be careful with data augmentation using synthetic data as it inevitably has a different distribution.", "label": "contrasting"}
{"id": "test_741", "sentence1": "However, when the size of task-related data is large enough, using a pre-trained model does not deliver much benefits (TS2 and TS all ft).", "sentence2": "finetuning clearly improves the performance of TS2 pt in both human and automatic metrics, where using only 1k domain data already produces satisfying scores in human metrics.", "label": "contrasting"}
{"id": "test_742", "sentence1": "Multi2 OIE yields the highest recall for all languages by approximately 20%p.", "sentence2": "argOE has relatively high precision, but low recall negatively impacts its F1 score.", "label": "contrasting"}
{"id": "test_743", "sentence1": "Most of the systems available for French fit in those three approaches.", "sentence2": "none of these systems have been thoroughly compared to each other, even with the release, in 2013, of a large coreference annotated corpus (Muzerelle et al., 2014), since each system uses slightly different versions of the corpus for evaluation (e.g. different train and test sets).", "label": "contrasting"}
{"id": "test_744", "sentence1": "CROC uses a feature indicating whether a mention is a new entity in the text, i.e. whether a mention is the first in its coreference chain.", "sentence2": "this feature is usually only available when the corpus has been previously annotated or after the coreference resolution task: this is why we removed it.", "label": "contrasting"}
{"id": "test_745", "sentence1": "It is difficult to study coreference errors of an end-to-end system, since it is not possible to fully separate mention misidentifications from coreference issues.", "sentence2": "it allows a better understanding of error source.", "label": "contrasting"}
{"id": "test_746", "sentence1": "One reason for this is that the newspapers and magazines that were used for our corpus tend to contain quite complex texts (political commentary and reports in historical German).", "sentence2": "we also observed some systematic difficulties to apply our annotation system that is rooted in narrative theory to journalistic writing, e.g.", "label": "contrasting"}
{"id": "test_747", "sentence1": "We generally follow this idea: reported is more summarizing and less precise, while indirect ST&WR can usually be read as a transformation of direct ST&WR that allows us to reconstruct the 'original' quote in more detail.", "sentence2": "there are sentences that follow the typical structure of indirect ST&WRa framing clause and a dependent subordinate clause containing the content -but do not allow such a reconstruction", "label": "contrasting"}
{"id": "test_748", "sentence1": "There is a large number of tools and software packages providing access to data repositories such as NLTK (Loper and Bird, 2002) or Spacy 1 .", "sentence2": "many of these resources are not powerful enough to exploit this data to their full extent.", "label": "contrasting"}
{"id": "test_749", "sentence1": "Therefore it is normally only available through a web GUI hosted by the Institute of the Czech National Corpus.", "sentence2": "we obtained a tabular text file with the Czech-German alignment on request.", "label": "contrasting"}
{"id": "test_750", "sentence1": "Reddit users make less use of argumentation proposition types in general: they use less normative language than the candidates and express less desire than Republican candidates.", "sentence2": "they use reported speech often, partly because their discussions occurred after the debates had occurred.", "label": "contrasting"}
{"id": "test_751", "sentence1": "We found that models trained through multi-task learning where the primary task consists of argument component classification and the secondary task consists of specificity classification almost always outperform models that only perform argument component classification.", "sentence2": "the corpus used in our previous study is not publicly available and therefore our previous results are not reproducible by other members of the research community.", "label": "contrasting"}
{"id": "test_752", "sentence1": "In our prior work (Lugini and Litman, 2018) on argument component classification for discussions, we used oversam\u0002pling to alleviate the class imbalance present in argumenta\u0002tion labels (which is also present in the Discussion Tracker corpus).", "sentence2": "since our Discussion Tracker experiments also include 3 task multi-task learning, oversampling with respect to argumentation labels might have negative impact on other tasks.", "label": "contrasting"}
{"id": "test_753", "sentence1": "These hypotheses are motivated by our observation of differences between collaboration label distributions across argumentative moves.", "sentence2": "given the different unit of analysis for the annotation of collaboration (turn) versus argumentation and specificity (argument discourse unit), for the multi-task learning setting the collaboration annotations have been converted to BIO format in order to have one annotation per argument move 2 .", "label": "contrasting"}
{"id": "test_754", "sentence1": "Punctuation symbols often indicates segment boundaries.", "sentence2": "there may be cases where EDUs are not segmented.", "label": "contrasting"}
{"id": "test_755", "sentence1": "The baseline model fails to identify the comparative \u2018enough . . . to' as a correlative and does not segment the sentence.", "sentence2": "training for syntactic features allowed the model to correctly identify this construct and hence perform correct segmentation.", "label": "contrasting"}
{"id": "test_756", "sentence1": "As suspected, the baseline model performs poorly when the sentences are longer.", "sentence2": "formulating the problem in an alternate fashion and injecting syntax make the model perform much better.", "label": "contrasting"}
{"id": "test_757", "sentence1": "Despite its simple mechanism, this algorithm comes with a high bias, which is unfavorable for learning new directions within the data.", "sentence2": "multi-View-Training (Zhou and Goldman, 2004;S\u00f8gaard, 2010) tries to compensate this bias by different views of the data.", "label": "contrasting"}
{"id": "test_758", "sentence1": "They collected explicit argument pairs with freely omissible discourse connectives which can be dropped independently of the context without changing the interpretation of the discourse relation.", "sentence2": "sporleder and Lascarides (2008) argued training on explicit argument pairs was not a good strategy.", "label": "contrasting"}
{"id": "test_759", "sentence1": "Note that Wu et al. (2017) collected explicit argument pairs using a similar method.", "sentence2": "they only used argument pairs located within the same sentence while we do not apply this constraint.", "label": "contrasting"}
{"id": "test_760", "sentence1": "We also use a content extraction tool to extract article content from an HTML file, and apply a shingling-based method to identify near-duplicate articles.", "sentence2": "our systems differ in two major ways.", "label": "contrasting"}
{"id": "test_761", "sentence1": "Furthermore, some datasets are available for evaluating additional dimensions of essay quality in English (Mathias and Bhattacharyya, 2018).", "sentence2": "only a few evaluation datasets are available for Japanese writings, and even fewer Japanese learner essay datasets are.", "label": "contrasting"}
{"id": "test_762", "sentence1": "We created the feature-based models using linguistic features based on (Lee and Hasebe, 2017).", "sentence2": "whether these features are enough to perform AES is unclear.", "label": "contrasting"}
{"id": "test_763", "sentence1": "As a result, the neural approach for AES has been actively studied in recent years (Taghipour and Ng, 2016).", "sentence2": "no neural-network-based AES system is available for the Japanese language; furthermore, the BERT model has not been applied for an AES task with multiple dimensions thus far.", "label": "contrasting"}
{"id": "test_764", "sentence1": "The feature-based model predicted a score that was two points lower than the actual content and organization trait scores in essay A and a score that was two points lower than the organization trait score in essay B.", "sentence2": "the neural-network-based model predicted the score correctly for essay A and predicted a score that was only one point lower than the actual language trait score in essay B.", "label": "contrasting"}
{"id": "test_765", "sentence1": "Further, this model may provide a high score for an unexpected input.", "sentence2": "the neural-network-based model predicted low scores for all columns.", "label": "contrasting"}
{"id": "test_766", "sentence1": "Reported results were obtained with traditional machine learning methods and, to some extent, it would be interesting to test more recent classification methods, such as deep neural networks.", "sentence2": "the corpus might not be large enough for such an approach, which further motivates this kind of experiment.", "label": "contrasting"}
{"id": "test_767", "sentence1": "They proved to be a strong baseline in the binary classification task, outperforming the surface text-based features and the graph-based deep semantic features.", "sentence2": "on the five-level classification task, they were outperformed by all other feature sets.", "label": "contrasting"}
{"id": "test_768", "sentence1": "To create such collections, there is a substantial need for automatic approaches that can distinguish the documents of interest for a collection out of the large collections (of millions in size) from Web Archiving institutions.", "sentence2": "the patterns of the documents of interest can differ substantially from one document to another, which makes the automatic classification task very challenging.", "label": "contrasting"}
{"id": "test_769", "sentence1": "The time-domain features offer a simple way to analyse audio signals and are directly extracted from the samples of the audio signal (waveform).", "sentence2": "frequencydomain features are extracted from the sound spectrum, a representation of the distribution of the frequency content of sounds (Giannakopoulos and Pikrakis, 2014d).", "label": "contrasting"}
{"id": "test_770", "sentence1": "The corpus contains tweets annotated with 28 emotions categories and captures the language used to express an emotion explicitly and implicitly.", "sentence2": "the availability of datasets created specifically for languages other than English is very limited.", "label": "contrasting"}
{"id": "test_771", "sentence1": "For several years, affect in speech has been encoded using discrete categories such as anger, sadness or neutral speech.", "sentence2": "in many recent papers, researchers preferred using affective dimensions.", "label": "contrasting"}
{"id": "test_772", "sentence1": "Regarding the effect of hesitation on fundamental frequency (f0), a study on German spontaneous speech (Mixdorff and Pfitzinger, 2005) found no impact of hesitations marked by fillers on the overall f0 pattern at the utterance level.", "sentence2": "a study relying on synthesized speech (Carlson et al., 2006) in Swedish showed a moderate effect of the f0 slope on perceived hesitation, as well as a moderate effect of the insertion of creaky voice.", "label": "contrasting"}
{"id": "test_773", "sentence1": "Thus all adaptations of the speaking styles to different degrees of hesitation are individual as well and cannot be summed up as a group mean.", "sentence2": "the tendencies of the individual changes remain similar across the group.", "label": "contrasting"}
{"id": "test_774", "sentence1": "Child language studies are crucial in improving our understanding of child well-being; especially in determining the factors that impact happiness, the sources of anxiety, techniques of emotion regulation, and the mechanisms to cope with stress.", "sentence2": "much of this research is stymied by the lack of availability of large child-written texts.", "label": "contrasting"}
{"id": "test_775", "sentence1": "Valence was significantly negatively associated with arousal (r = -.06, p < .001), although the effect was small, suggesting minimal collinearity.", "sentence2": "correlations with dominance (both A-D and D-V) were much stronger and significant (p < .001).", "label": "contrasting"}
{"id": "test_776", "sentence1": "Interpreting it at face value, we might conclude that the results reflect increased capabilities in emotion regulation (i.e., being more in control of one's emotions) (Zimmermann and Iwanski, 2014).", "sentence2": "we are hesitant to make this conclusion because individual words likely have poor correspondence with emotion regulation, which involves complex processes.", "label": "contrasting"}
{"id": "test_777", "sentence1": "In our results, we observe that when maximum of the 3 CCCs computed on each pair is low, the predicted satisfaction is likely to be bad.", "sentence2": "if this maximum is high, the predicted satisfaction is likely to be good.", "label": "contrasting"}
{"id": "test_778", "sentence1": "It often carries both positive and negative feelings.", "sentence2": "since this label is quite infrequent, and not available in all subsets of the data, we annotated it with an additional Beauty/Joy or Sadness label to ensure annotation consistency.", "label": "contrasting"}
{"id": "test_779", "sentence1": "The results of the crowdsourcing experiment, on the other hand, are a mixed bag as evidenced by a much sparser distribution of emotion labels.", "sentence2": "we note that these differences can be caused by 1) the disparate training procedure for the experts and crowds, and 2) the lack of opportunities for close supervision and on-going training of the crowds, as opposed to the in-house expert annotators.", "label": "contrasting"}
{"id": "test_780", "sentence1": "Nostalgia is still available in the gold standard (then with a second label Beauty/Joy or Sadness to keep consistency).", "sentence2": "confusion, Boredom and Other are not available in any sub-corpus.", "label": "contrasting"}
{"id": "test_781", "sentence1": "This line of work is predominantly based on word-level supervision.", "sentence2": "we learn word ratings from document-level ratings.", "label": "contrasting"}
{"id": "test_782", "sentence1": "Mean Star Rating, Binary Star Rating, and Regressions Weights learn exclusively from the available document-level gold data.", "sentence2": "one of the major advantages of the MLFFN is that it builds on pre-trained word embeddings, thus implicitly leveraging vast amounts of unlabeled text data.", "label": "contrasting"}
{"id": "test_783", "sentence1": "Another seemingly obvious evaluation strategy would be to predict document-level ratings from derived word-level lexica using the empathic reactions dataset in a cross-validation setup.", "sentence2": "we found that this approach has two major drawbacks.", "label": "contrasting"}
{"id": "test_784", "sentence1": "The clusters tend to be consistent regarding NE types, as illustrated in Table 3.", "sentence2": "both false positives (FP; non-NE entries in NE clusters) as well as false negatives (FN; NE entries in non-NE clusters) do occur.", "label": "contrasting"}
{"id": "test_785", "sentence1": "The transcription of the production as well as the target form are generally available in an orthographic form.", "sentence2": "if we are interested primarily in oral production and as this oral production is sometimes restricted to isolated words, it is ultimately more important to place the analysis at the phonological level.", "label": "contrasting"}
{"id": "test_786", "sentence1": "In this characterization, /p/ (+ coronal, + anterior) differs from /t/ (+ coronal) by one feature and similarly from /k/ (-anterior).", "sentence2": "/t/ (+ coronal, + anterior) differs from /k/ (-coronal, -anterior) by two features, which is not very satisfactory from an articulatory point of view where it would seem logical to respect the order /ptk/, that is to say /t/ equidistant from /p/ and /k/, /p/ and /k/ being more distant.", "label": "contrasting"}
{"id": "test_787", "sentence1": "The maximum precision score that Terrier reached is 0.92 indicating that the optimum of 1.0 was never achieved.", "sentence2": "sODA reached the maximum score of 1.0 in five cases.", "label": "contrasting"}
{"id": "test_788", "sentence1": "Indeed lemmatization, stemming, numeral masking and entity masking did not improve results.", "sentence2": "stop word filtering produces better word embeddings for this task.", "label": "contrasting"}
{"id": "test_789", "sentence1": "Currently, the serial corpora provided by NLPCC are the mainstream evaluation benchmarks for Chinese EL.", "sentence2": "all of them stem from Chinese microblogs, which can be fairly short and noisy.", "label": "contrasting"}
{"id": "test_790", "sentence1": "Evidently, mentions in the Hard document are rather ambiguous, as Hinrich, Chandler can refer to many different entities.", "sentence2": "easy document contains very obvious mentions such as BRICS, UN and the country names.", "label": "contrasting"}
{"id": "test_791", "sentence1": "These comments are useful for the learner.", "sentence2": "comments are noise for an evaluation dataset because automatic evaluation methods utilizing corrected sentences typically rely on the matching rate between the system output and the corrected sentences to calculate a score.", "label": "contrasting"}
{"id": "test_792", "sentence1": "In this model, we tokenized the learner sentence at the character level.", "sentence2": "we tokenized a corrected sentence at the word level.", "label": "contrasting"}
{"id": "test_793", "sentence1": "Therefore, it turns out that a CNN-based method is effective for errors that can be corrected with only the local context (Chollampatt and Ng, 2018).", "sentence2": "both the NMT and SMT systems could hardly correct errors that needed to be considered in context, for example, abbreviation or formal and casual style errors.", "label": "contrasting"}
{"id": "test_794", "sentence1": "The number of true positives (TP) in the NMT system was larger than that in the SMT system.", "sentence2": "the number of false positives (FP) in the NMT system was considerably larger than that in the SMT system.", "label": "contrasting"}
{"id": "test_795", "sentence1": "Lang-8's original annotation contains annotator's comments that are noise for evaluation.", "sentence2": "our evaluation corpus does not contain such comments.", "label": "contrasting"}
{"id": "test_796", "sentence1": "The second sentence does match the index query, so the full traversal is performed.", "sentence2": "because there is an intervening xcomp relation, the traversal fails.", "label": "contrasting"}
{"id": "test_797", "sentence1": "In the above example, \u201c\u0906\u0924\u0902\u0915\u0940 \u0939\u092e\u0932\u093e\u201d  (terrorist attack) is a multiword event trigger with annotation labels B_Event and I_Event respectively.", "sentence2": " \u2018\u0939\u092e\u0932\u093e' (attack) itself is an event trigger with annotation label B_Event.", "label": "contrasting"}
{"id": "test_798", "sentence1": "The recognition of medical concepts and their attributes in EEG reports is vital for many applications requiring data-driven representation of EEG-specific knowledge, including decision support systems.", "sentence2": "the identification of the medical concepts in the EEG reports is not sufficient, as these concepts also exhibit clinically-relevant relations between them.", "label": "contrasting"}
{"id": "test_799", "sentence1": "Since the Morphology best defines the EEG activities, we decided to use it as an anchor for each mention of an EEG activity in the EEG report.", "sentence2": "Morphology represents the type or \"form\" of an EEG activity, which may have multiple values, as seen in Table 2, therefore the Morphology remains also as an attribute of the EEG activities.", "label": "contrasting"}
{"id": "test_800", "sentence1": "In deciding the nodes of the HAD, we have consulted the Epilepsy Syndrome and Seizure Ontology (ESSO) 2 , which encodes 2,705 classes with an upper ontology targeting epilepsy and selected the concepts that best describe EEG activities.", "sentence2": "eeG events, which are frequently mentioned in eeG reports as well, can be recognized only by identifying the text span where they are mentioned and their polarity and modality attributes.", "label": "contrasting"}
{"id": "test_801", "sentence1": "In a controlled laboratory environment, participants used the Crowdee platform for performing the summary quality evaluation task.", "sentence2": "to the crowdsourcing study, all the participants were also instructed in a written form following the standard practice for laboratory tests.", "label": "contrasting"}
{"id": "test_802", "sentence1": "Automatic analysis of connected speech by natural language processing techniques is a promising direction for diagnosing cognitive impairments.", "sentence2": "some difficulties still remain: the time required for manual narrative transcription and the decision on how transcripts should be divided into sentences for successful application of parsers used in metrics, such as Idea Density, to analyze the transcripts.", "label": "contrasting"}
{"id": "test_803", "sentence1": "Prosodic features have been shown to be very effective to discriminate between different types of sentence boundaries and in general their usage reflects better results (Shriberg et al., 2009;Huang et al., 2014;Khomitsevich et al., 2015).", "sentence2": "to put prosodic features into practice we need alignments between the audio and its transcription, which is hard to obtain mainly due to the low quality of the recordings.", "label": "contrasting"}
{"id": "test_804", "sentence1": "From these results, we can assume that sequenced-figures narratives bring linguistic features also present in retellings, but the reverse direction is not true, as we can see in Table 5.", "sentence2": "if a researcher will only work on retelling tasks, Table  5 shows that using only retelling datasets for training led to better results for the retelling task.", "label": "contrasting"}
{"id": "test_805", "sentence1": "For a script that is not phonetic, e.g., Chinese characters, grapheme-tophoneme conversion is considered compulsory.", "sentence2": "as Hangul is phonetic, in other words, text in Hangul sounds as it is written, we stick with graphemes rather than converting them into phonemes.", "label": "contrasting"}
{"id": "test_806", "sentence1": "Much of the information about temples is available as text in the open web, which can be utilized to conduct such a study.", "sentence2": "this information is not in the form of a learning resource, which can be readily used for such studies.", "label": "contrasting"}
{"id": "test_807", "sentence1": "On the one hand high quality resources are needed that contain (English) glosses, part of speech tagging as well as underlying morphophonemes forms.", "sentence2": "the resource needs to be large enough for the wanted forms to occur in the data.", "label": "contrasting"}
{"id": "test_808", "sentence1": "On a positive side, 50% of the sentences were different from one seed strategy to the other, suggesting for an approach where strategies are mixed.", "sentence2": "we also observed that (a) tends to yield more similar queries over time and (c) is too time-consuming for practical use.", "label": "contrasting"}
{"id": "test_809", "sentence1": "When English is the source language, and Japanese is the target language, there are only 5 pairs in the test data where the source and target words are identical, i.e., cases where the copy baseline is correct.", "sentence2": "in the case of English being the target language, and Japanese being the source language, there are 270 pairs where the source and target words are identical.", "label": "contrasting"}
{"id": "test_810", "sentence1": "Wikipedia is usually used as a high-quality freely available multilingual corpus as compared to noisier data such as Common Crawl.", "sentence2": "for the two languages under study, Wikipedia resulted to have too much noise: interference from other languages, text clearly written by non-native speakers, lack of diacritics and mixture of dialects.", "label": "contrasting"}
{"id": "test_811", "sentence1": "For example, a sentence describing the English cricket team's victory over India could invoke negative sentiment, given the annotator's strong support of the latter.", "sentence2": "the actual label of such a statement would be positive because of the author's intention.", "label": "contrasting"}
{"id": "test_812", "sentence1": "Logistic Regression offers marginally better performance than Linear-SVM in terms of precision (Precision for LR is 0.675).", "sentence2": "the former fails to outperform the latter in the other three metrics of evaluation.", "label": "contrasting"}
{"id": "test_813", "sentence1": "The choice of approach has a fundamental effect on the end result: in the case of expansion (translation), the new wordnet will be fully meaning-aligned with the source language (English), which is ideal for cross-lingual uses: as most wordnets are already aligned with PWN, we get bilingual translations to all those languages 'for free'.", "sentence2": "a certain linguistic bias is introduced by the fact that only meanings for which English lexicalisations exist will appear in the wordnet.", "label": "contrasting"}
{"id": "test_814", "sentence1": "A common form of sarcasm consists of a positive sentiment contrasted with a negative situation (Riloff et al., 2013), therefore it was likely that learning the emotional information of a text would facilitate the task of irony/sarcasm prediction.", "sentence2": "it was seen that the majority of Persian Twitter users include either humor, irony or sarcasm in their posts.", "label": "contrasting"}
{"id": "test_815", "sentence1": "pre-trained a neural network model to predict emojis in the text and then transferred the model for different related tasks including sarcasm detection (Felbo et al., 2017).", "sentence2": "with approaches that use feature engineering to extract features , in (Amir et al., 2016) features are automatically extracted by learning user embeddings which requires users' preceding messages.", "label": "contrasting"}
{"id": "test_816", "sentence1": "Please note that we carry out our analysis on the whole corpus.", "sentence2": " if one were interested only in the most reliable portions of the corpus, i.e. the cases all annotators agreed upon, different confidence thresholds can be set, as shown in Table 2.", "label": "contrasting"}
{"id": "test_817", "sentence1": "The high frequency of idioms in persuasive and rhetorical language corroborates the statements by McCarthy (1998) that idioms are used for commenting on the world, rather than describing it, and Minugh 2008, who finds that idioms are used most often by those with some authority, especially when conveying 'received wisdom'.", "sentence2": "this genre distinction is still quite crude.", "label": "contrasting"}
{"id": "test_818", "sentence1": "Due to the fact that the majority of indigenous languages were traditionally exclusively oral cultures, manuscripts typically do not play a primary role in the study of those languages.", "sentence2": "in particular handwritten notes that were created by researchers during fieldwork often are important information sources that, beyond other things, contain highly relevant information, ranging from object language data with attached translations and glossings, over lexical and grammatical descriptions to complex metadata, figural data and of course individual interpretation by the respective researcher.", "label": "contrasting"}
{"id": "test_819", "sentence1": "The resulting derived resource on the one hand shows which data from the resource catalogue and which sessions from the corpora have been published in certain bibliographic items.", "sentence2": "it demonstrates that some have actually been published in different bibliographic items.", "label": "contrasting"}
{"id": "test_820", "sentence1": "A popular and widely method is crawling different web pages.", "sentence2": "this is only possible under the assumption that there are sufficient web sites written in the target language.", "label": "contrasting"}
{"id": "test_821", "sentence1": "In some cases, the large number of hapax is related to a poor quality of the corpus that might be caused by spelling errors or the presence of foreign words (Nagata et al., 2018).", "sentence2": "our scenario is expected given the agglutinative nature of the four target languages, so they might present a vast vocabulary diversity.", "label": "contrasting"}
{"id": "test_822", "sentence1": "Crowdsourcing platforms, such as Amazon Mechanical Turk, have been an effective method for collecting such large amounts of data.", "sentence2": "difficulties arise when task-based dialogues require expert domain knowledge or rapid access to domain-relevant information, such as databases for tourism.", "label": "contrasting"}
{"id": "test_823", "sentence1": "Prior crowdsourced wizarded data collections have divided the dialogue up into turns and each worker's job consists of one turn utterance generation given a static dialogue context, as in the MultiWoZ dataset (Budzianowski et al., 2018).", "sentence2": "this can limit naturalness of the dialogues by restricting forward planning, collaboration and use of memory that humans use for complex multi-stage tasks in a shared dynamic environment/context.", "label": "contrasting"}
{"id": "test_824", "sentence1": "The first WordNet for Bulgarian was built in the BalkaNet project (Koeva and Genov, 2004).", "sentence2": "to this date the lexicon is not freely available.", "label": "contrasting"}
{"id": "test_825", "sentence1": ". A free core-WordNet for Bulgarian was made available in the BulTreeBank Wordnet (Simov and Osenova, 2010), but unfortunately its size is rather small - 8 936 senses.", "sentence2": "it has very good quality, so when we had to choose a translation for a word in English, we first looked for a corresponding synset in the BulTreeBank Wordnet.", "label": "contrasting"}
{"id": "test_826", "sentence1": "The dictionary is compatible with GF, and contains morphology and English-Bulgarian translations.", "sentence2": "the translations are not sense annotated.", "label": "contrasting"}
{"id": "test_827", "sentence1": "Sense annotations are available only for the words exemplified with that sentence.", "sentence2": "in order to provide good translations, we sense tagged all words in the corpus.", "label": "contrasting"}
{"id": "test_828", "sentence1": "The target audience of the digital literature on this platform is young people (roughly below 30 years of age), it thus has the potential of being biased in age.", "sentence2": "this is the age group that is the most fluent in and most likely to use written Cantonese and therefore it reflects the current usage of written Cantonese in the society.", "label": "contrasting"}
{"id": "test_829", "sentence1": "Authors like Brysbaert and New (2009) suggest that a size of about 15 millions tokens guarantees a robust estimation of the term frequencies (i.e. which correlates well with psycholinguistic measures)", "sentence2": "because HKC is not particularly well resourced and that corpus data (especially spoken) is not always freely available, we made do with what is available at the time, and have much less than that target size.", "label": "contrasting"}
{"id": "test_830", "sentence1": "In order to handle these cases (which become more frequent as the resources to be modelled become more 'scholarly') we decided to make etymology a class, Etymology, in Part 3.", "sentence2": "since etymologies usually represent an ordering of etymons (and, of course, etymons can be associated with more than one etymology and even more than one etymology for the same entry), we opted to create indirect rather than direct associations between etymologies and etymons.", "label": "contrasting"}
{"id": "test_831", "sentence1": "If a lemma differ from one source to another, we create multiple entries and disambiguate them manually based on the definitions obtained from other resources.", "sentence2": "if the lemma is the same we fuse their information.", "label": "contrasting"}
{"id": "test_832", "sentence1": "We need to enrich it and validate it by Old French or diachrony specialists.", "sentence2": "the manual process is long and tedious especially when it comes to enrich the lexicon by decreasing the silence rate.", "label": "contrasting"}
{"id": "test_833", "sentence1": "In recent years, people have started investigating neologisms computationally (e.g. Ahmad (2000; Kerremans et al. (2011)), and online dictionaries and datasets provide convenient electronic versions of a word's year of first use.", "sentence2": "these resources vary in the amount of information they provide and are often limited to a handful of languages.", "label": "contrasting"}
{"id": "test_834", "sentence1": "The post-editing speed here was lower, around 1.5K words/hour.", "sentence2": "the proportion of tags edited, 1.8%, is only slightly higher.", "label": "contrasting"}
{"id": "test_835", "sentence1": "When given the same set of essays to evaluate and enough graded samples, AES systems tend to achieve high agreement levels with trained human raters (Taghipour and Ng, 2016).", "sentence2": "there is a sizeable literature in cognitive science, psychology and other social studies offering evidence that biases can create situations that lead us to make decisions that project our experiences and values onto others (Baron, 2007).", "label": "contrasting"}
{"id": "test_836", "sentence1": "Here, the target language expression is typically either a translation or a definition.", "sentence2": "these cannot be reliably distinguished in an automated way, so that target language information is best represented as a definition rather than as a translation.", "label": "contrasting"}
{"id": "test_837", "sentence1": "There are many existing Arabic corpora (Atwell, 2019).", "sentence2": "we are only interested in those that include Hadith or classical Arabic text in general.", "label": "contrasting"}
{"id": "test_838", "sentence1": "In another study, a survey was conducted to enumerate the freely available Arabic corpora and stated the existence of one Hadith corpus.", "sentence2": "it was not accessible, mentioned or used in the literature (Zaghouani, 2017).", "label": "contrasting"}
{"id": "test_839", "sentence1": "The number of tokens in the English Hadiths is larger than the Arabic version.", "sentence2": "the Arabic Hadiths are richer in vocabulary as it contains more unique words than the English version as shown in Table 4.", "label": "contrasting"}
{"id": "test_840", "sentence1": "Applications that allow users to interact with technology via spoken or written natural language are emerging in all areas, and access to language resources and open-source software libraries enables faster development for new domains and languages.", "sentence2": "lT is highly language dependent and it takes considerable resources to develop lT for new languages.", "label": "contrasting"}
{"id": "test_841", "sentence1": "Because of the exploratory nature of the project and the type of information that has been collected, the language actor documentation is very detailed and often shaped by the organization and work environment of the specific institution.", "sentence2": "some good candidates for facets did emerge from the data when we analyzed it specifically with this aim in mind.", "label": "contrasting"}
{"id": "test_842", "sentence1": "A straightforward approach would be to share the character level vocabulary between CJK languages, as it was possible between Chinese and Japanese.", "sentence2": "this, unfortunately, is not a straightforward operation, as Hangul (the Korean writing system) is phonetic, unlike the other two examples.", "label": "contrasting"}
{"id": "test_843", "sentence1": "The elaborate deep learning models created new standards in OCR.", "sentence2": "like any machine learning method, deep learning models also need training material.", "label": "contrasting"}
{"id": "test_844", "sentence1": "Like kraken, it allows the user to specify the structure of the neural network with VGSL.", "sentence2": "to kraken, Tesseract is not GPU-enabled.", "label": "contrasting"}
{"id": "test_845", "sentence1": "It became evident during our work that character error rates (CER) are a good indicator about the models\u2019 ability to identifying characters correctly.", "sentence2": "for any further data processing which may include indexing or applying text mining techniques, the bag-of-words F1-measure provides a better picture of the systems' performances.", "label": "contrasting"}
{"id": "test_846", "sentence1": "Also, the Opus dataset is a much widely used parallel corpus resource in various researcher's works.", "sentence2": "we observed that in both of these well-known parallel resources there are many repeated sentences, which may results into the wrong results (can be higher or lower) after dividing into train, validation, and test sets, as many of the sentences, occur both in train and test sets.", "label": "contrasting"}
{"id": "test_847", "sentence1": "Regardless of the MT approach applied, a MT system automatically generates an equivalent version (in some target language) of an input sentence (in some source language).", "sentence2": "despite the huge effort of the MT community, it is not possible yet to generate a perfect completely automatic translation for unrestricted domains.", "label": "contrasting"}
{"id": "test_848", "sentence1": "Finding definite references and their antecedents in the coreference resolution data is easy.", "sentence2": "as we described in the experiment section, it is difficult to make the correct answer rate be 50%, because most articles can be predicted using language models.", "label": "contrasting"}
{"id": "test_849", "sentence1": "For pro-drop languages like Japanese and Chinese, zero pronoun was known to be one of the most difficult problems and many specific extensions for baseline translation methods have been discussed in previous research (Taira et al., 2012;Kudo et al., 2014;Takeno et al., 2016;Wang et al., 2016;Wang et al., 2018).", "sentence2": "it seems that contextaware neural machine translation can handle Japanese zero pronouns just as effectively as overt pronouns in Englishto-Russian translation (Voita et al., 2018).", "label": "contrasting"}
{"id": "test_850", "sentence1": "They built a large-scale test set from German-English bilingual texts using coreference resolution and word alignment tools.", "sentence2": "to build a large-scale test set for Japanese zero pronouns, we have to develop accurate tools for Japanese empty category detection (zero pronoun identification) and Japanese coreference resolution, which remains open problems.", "label": "contrasting"}
{"id": "test_851", "sentence1": "The results of the 6th WAT suggest that most sentences that are typical in TDDC and do not depend on context are translated correctly.", "sentence2": "there are mistranslations in sentences that contain words that are not present in TDDC or whose meaning changes depending on the context.", "label": "contrasting"}
{"id": "test_852", "sentence1": "The most comparable resource to the one presented here is the COPPA Corpus version 2 which contains around 13 million sentences.", "sentence2": "for other language pairs our corpus is larger, e.g. for there are 6.6M English/Japanese sentences while the JW300 corpus (Agic\u00b4 and Vulic, 2019) contains around 2.1M.", "label": "contrasting"}
{"id": "test_853", "sentence1": "As shown in Section 2.1, the standard NMT usually models a text by considering isolated sentences based on a strict assumption that the sentences in a text are independent of one another.", "sentence2": "disregarding dependencies across sentences will negatively affect translation outputs of a text in terms of discourse properties.", "label": "contrasting"}
{"id": "test_854", "sentence1": "MADAMIRA (Pasha et al., 2014) combines MADA (Morphological Analysis and Disambiguation of Arabic) which is built on SAMA (Standard Arabic Morphological Analyser) and AMIRA (a morphological system for colloquial Egyptian Arabic).", "sentence2": "to MADAMIRA, FSAM's rule-based system focuses on MSA templatic morphological analysis yielding root and pattern, generation and diacritization.", "label": "contrasting"}
{"id": "test_855", "sentence1": "On composing both FSTs, a weighted FST mapping surface form to weighted lexical forms will be generated.", "sentence2": "if the second FST doesn't have a path for a certain analysis then the surface-form:analysis pair will be dropped.", "label": "contrasting"}
{"id": "test_856", "sentence1": "For example, named entities, cognates/loanwords, and morphologically complex words that contain multiple morphemes are extremely challenging to properly tokenise because the occurrences of such terms are rare even in large training datasets.", "sentence2": "substrings of such terms are likely to be more frequent.", "label": "contrasting"}
{"id": "test_857", "sentence1": "Modern Standard Arabic (MSA), the official language of the Arab world, is well studied in NLP and has an abundance of resources including corpora and tools.", "sentence2": "most Arabic dialects are considered under-resourced, with the exception of Egyptian Arabic (EGY).", "label": "contrasting"}
{"id": "test_858", "sentence1": "Such models are well equipped to model some aspects of morphology implicitly as part of an end-to-end system without requiring explicit feature engineering.", "sentence2": "these models are very data-intensive, and do not scale down well in the case of low-resource languages.", "label": "contrasting"}
{"id": "test_859", "sentence1": "The different analyzers provide minor or no improvements over the Neural Joint Model alone when embedding the candidate tags.", "sentence2": "the ranking approach reduces the accuracy drastically for different combinations of analyzers.", "label": "contrasting"}
{"id": "test_860", "sentence1": "Indeed, in some languages (e.g., Basque) 100 words cannot cover even a single verb paradigm.", "sentence2": "even in such restricted conditions some systems perform significantly better than others, the state-of-the-art approach is imitation learning via minimization of Levenshtein distance between the network output and the correct word form (Makarov and Clematide, 2018b).", "label": "contrasting"}
{"id": "test_861", "sentence1": "They were also ex\u0002tensively used in Najafi et al. (2018) system, that took the second place in Sigmorphon 2018 Shared Task.", "sentence2": "they utilized the complete Unimorph data, which is sufficiently more than 1000 word forms used in our work.", "label": "contrasting"}
{"id": "test_862", "sentence1": "By restricting transformations to orthogonal linear mappings, VecMap and MUSE rely on the assumption that the monolingual embeddings spaces are approximately isomorphic (Barone, 2016).", "sentence2": "it has been argued that this assumption is overly restrictive, as the isomorphism assumption is not always satisfied (S\u00f8gaard et al., 2018;.", "label": "contrasting"}
{"id": "test_863", "sentence1": "Not further improving the results for German, Czech and Italian languages might be because of the sufficiency of the target embedding usage for domain adaptation (Jurafsky and Martin, 2014) in those.", "sentence2": "the fact that Spanish and French performances improved on both Wikipedia and Twitter domains when Dom-Drift is used, might show that the necessity of DomDrift can be related to certain property of the target language, which can be further explored as future work.", "label": "contrasting"}
{"id": "test_864", "sentence1": "Moreover, Turkish, Russian, Tigrigna, Polish, Uyghur, Croatian, Wolaytta, Bulgarian, German, Swedish are also characterized by high OOV rates.", "sentence2": "mandarin, Thai, Hausa, Japanese, Vietnamese and English are characterized by low OOV rate.", "label": "contrasting"}
{"id": "test_865", "sentence1": "Frame-semantic parsers, however, are normally trained on manually annotated resources such as the FrameNet corpus (Baker et al., 1998) or the OntoNotes corpus (Pradhan and Xue, 2009;Weischedel et al., 2013).", "sentence2": "such annotations only exist for a small subset of the world's languages.", "label": "contrasting"}
{"id": "test_866", "sentence1": "For both setups, we normalize labels to be conform with the PropBank (Palmer et al., 2005) notation (e.g., A1 becomes ARG1).", "sentence2": "as shown in Figure 1, the experiments with the full label set have a slightly better accuracy than the ones with a simplified label set, so we will present only the results for the former.", "label": "contrasting"}
{"id": "test_867", "sentence1": "Given that CS is language-dependent, a corpus for each language pair is needed.", "sentence2": "collecting CS corpora is a very challenging task, thus the collected, and available, corpora are very scarce and cover few language pairs.", "label": "contrasting"}
{"id": "test_868", "sentence1": "The above-mentioned differences are statistically significant.", "sentence2": "relatively large standard deviations of the metrics should be taken into account.", "label": "contrasting"}
{"id": "test_869", "sentence1": "More specifically, we exploit the fact that Twitter users can make use of Twitter screen names (e.g., @UserScreen-Name) in their tweet posts to mention other users, which provides us with unambiguous mentions.", "sentence2": "e ob\u0002serve that many tweets also contain proper names (e.g. last names or acronyms for organizations) to refer to other Twitter users, thereby creating ambiguities about the user (entity) they refer to.", "label": "contrasting"}
{"id": "test_870", "sentence1": "Note that we do not claim that all multimedia analysis work adopts an overly simplistic conceptualization of how text and images relate.", "sentence2": "we find the lack of research on realistic connections between text and images is serious enough that it may hold back the state of the art in multimedia analysis for disaster management.", "label": "contrasting"}
{"id": "test_871", "sentence1": "In sum, our analysis reveals that the image caption to some extent describes the content of the image.", "sentence2": "in many cases the caption provides additional information which is not conveyed by the image alone.", "label": "contrasting"}
{"id": "test_872", "sentence1": "Since the news articles in our collection are news reports, rather than editorials or feature articles, recency of what is reported in the text and depicted in the accompanying images is to be expected.", "sentence2": "there is also a fair proportion where the image is less recent.", "label": "contrasting"}
{"id": "test_873", "sentence1": "Up until this point, we have investigated temporal distance.", "sentence2": "we have an important point to make about spatial distance that emerged from our manual analysis.", "label": "contrasting"}
{"id": "test_874", "sentence1": "Success at that task could ultimately also form the basis of an automatic annotation in the future.", "sentence2": "here we limit ourselves to a pilot, which provides a basic demonstration that the categories of news articles and images can be automatically distinguished.", "label": "contrasting"}
{"id": "test_875", "sentence1": "Further, articles about ongoing flooding often are associated with flood-related images.", "sentence2": "it is not advisable to assume that a flood-related image will directly relate to a flooding-event described in the corresponding article.", "label": "contrasting"}
{"id": "test_876", "sentence1": "As in them, we constructed our questions and answers based on both textual and visual cues from short video clips.", "sentence2": "unlike them, our proposed dataset relies on video clips that were recorded naturally by people, without predefined scripts.", "label": "contrasting"}
{"id": "test_877", "sentence1": "This insight is in line with our previous work (Schulte im Walde et al., 2016) which also demonstrated that empirical modifier properties do not have a consistent effect on the quality of predicting compound compositionality.", "sentence2": "ranges zooming into the prediction results for compounds with high-, mid and low-productivity heads (see Table 6), we do observe patterns for compound subsets.", "label": "contrasting"}
{"id": "test_878", "sentence1": "This is probably one of the reasons why many studies that investigated idiomatic expressions, only collected limited information about idiom properties for very small numbers of idioms only.", "sentence2": "this is problematic for research, because it hinders comparability of results.", "label": "contrasting"}
{"id": "test_879", "sentence1": "On the other hand, in concrete applications, crucial domain-specific entities need to be identified in a reliable way, such as designations of legal norms and references to other legal documents (laws, ordinances, regulations, decisions, etc.).", "sentence2": "most NER solutions operate in the general or news domain, which makes them inapplicable to the analysis of legal documents (Bourgonje et al., 2017;Rehm et al., 2017).", "label": "contrasting"}
{"id": "test_880", "sentence1": "We hypothesize that an increase in training data would yield better results for BiLSTM-CRF but not outperform transfer learning approach of MTL (or even BioBERT).", "sentence2": "to other common NER corpora, like CoNLL 2003 14 , even the best baseline system only achieves relatively low scores.", "label": "contrasting"}
{"id": "test_881", "sentence1": "It connects sentiment analysis and Natural Language Generation (Zhang et al., 2018a) and facilitates a lot of NLP applications such as fighting against offensive language in social media (Santos et al., 2018), news rewriting, and building controllable dialogue systems.", "sentence2": "this task is difficult in practice due to the lack of parallel data (sentences with similar content but different sentiments).", "label": "contrasting"}
{"id": "test_882", "sentence1": "It suggests that the semantic representation is also essential to preserve content.", "sentence2": "the lack of semantic representation brings little decrease in sentiment transfer accuracy.", "label": "contrasting"}
{"id": "test_883", "sentence1": "Natural Language Processing (NLP) can help unlock the vast troves of unstructured data in clinical text and thus improve healthcare research.", "sentence2": "a big barrier to developments in this field is data access due to patient confidentiality which prohibits the sharing of this data, resulting in small, fragmented and sequestered openly available datasets.", "label": "contrasting"}
{"id": "test_884", "sentence1": "Natural Language Processing (NLP) has enormous potential to advance many aspects of healthcare by facilitating the analysis of unstructured text (Esteva et al., 2019).", "sentence2": "a key obstacle to the development of more powerful NLP methods in the clinical domain is a lack of accessible data.", "label": "contrasting"}
{"id": "test_885", "sentence1": "We cannot say for certain whether using GPT-2 or EDA could positively impact our results.", "sentence2": "it appears that our EDA baseline generally performs even worse than our Transformer and GPT-2 augmentations and the Original data itself for both MimicText-98 and MimicText-9.", "label": "contrasting"}
{"id": "test_886", "sentence1": "It is our hypothesis that these inaccuracies can provide an optimal amount of noise when using a model that has been pretrained on biomedical texts, thus allowing them to better generalise.", "sentence2": "this noise proves too much for models that have only been pretrained on non-medical text.", "label": "contrasting"}
{"id": "test_887", "sentence1": "This leads us to hypothesise that this task might be too easy and that even weaker models are able to relatively accurately identify the phenotypes of patients from their discharge summaries.", "sentence2": "we still note that our baseline models report the highest values across our metrics, especially our 'Original' data using the BioBERT model which reports the best accuracy and F1 scores.", "label": "contrasting"}
{"id": "test_888", "sentence1": "Recently, contextualized word embeddings such as BERT (Devlin et al., 2019) have largely improved the performance of NLP tasks compared to static embeddings such as word2vec (Mikolov et al., 2013), GloVe (Pennington et al., 2014).", "sentence2": "static embeddings are still frequently used to various studies for sentence embeddings (Yang et al., 2019;Almarwani et al., 2019) and even the other domains such as the extraction of interaction between drugs in the biomedical field (Sun et al., 2019).", "label": "contrasting"}
{"id": "test_889", "sentence1": "These approaches effectively handle surface-variation of words such as inflected forms and typos.", "sentence2": "this is only feasible when the roots of words are existed in a vocabulary.", "label": "contrasting"}
{"id": "test_890", "sentence1": "The authors show that CamemBERT obtains significant improvements on many French tasks compared to the publicly available multilingual BERT.", "sentence2": "the architecture used in CamemBERT is different to BERT, which makes the comparison among the models less straightforward.", "label": "contrasting"}
{"id": "test_891", "sentence1": "Such results show that mean smiling intensity seems to be a more robust criterium than the sole presence or absence of smile to evaluate the impact of smiling on the success or failure of humor.", "sentence2": "based on only four participants including one exception (MA), such a result cannot be more precise.", "label": "contrasting"}
{"id": "test_892", "sentence1": "This result could indicate that mean smiling intensity has a larger impact of the success or failure of humor than the simple presence of smiling.", "sentence2": "such a result cannot be considered meaningful either because, this only holds for three participants.", "label": "contrasting"}
{"id": "test_893", "sentence1": "For example, an NMT system might translate the source sentence given in (1) as the viable Spanish translation given in (2).", "sentence2": "in a given organizational context (3) or even (4) might instead be the approved translation.", "label": "contrasting"}
{"id": "test_894", "sentence1": "The current implementation only uses a flat list of nonhierarchical source-target term pairs (often referred to as a \"glossary\") to seed the injection process, which increases the likelihood of polysemic collisions.", "sentence2": "terminology management practices involve much more complex termbases that express several types of lexical, domain, semantic, hierarchical (taxonomic), ontological, overlapping, and nesting relationships among terms.", "label": "contrasting"}
{"id": "test_895", "sentence1": "Overall, the percentage of rare words gets smaller as corpus size increases, as more and more words appear over 10 times.", "sentence2": "the hyperparameters seem to have different effects on this value depending on corpus size as well.", "label": "contrasting"}
{"id": "test_896", "sentence1": "The naming form distribution in the GTTC does not reflect the natural distribution of naming forms because we oversampled Dr.-containing tweets.", "sentence2": "the relation between naming and stance should not be affected by oversampling.", "label": "contrasting"}
{"id": "test_897", "sentence1": "Finally, the political orientation of users was determined by a proxy that assumes that if you criticise right-wing politicians you are more likely to be left-leaning and vice versa.", "sentence2": "of course, you can also criticise politicians from your own political spectrum.", "label": "contrasting"}
{"id": "test_898", "sentence1": "A sample of titlecontaining tweets suggests that titles are not a definite signal that an otherwise positive-sounding German tweet is meant to be interpreted negatively (or vica versa).", "sentence2": "since the use of honorifics can be indicative of sarcasm (Liu et al., 2014), it is worth investigating whether the use of titles alongside explicit negative stance should be interpreted as sarcasm, and whether this sarcastic use plays a role in causing the weaker positive association with formal naming in left-leaning discourse.", "label": "contrasting"}
{"id": "test_899", "sentence1": "A typical application of classical SA in an industrial setting would be to classify a document like a product review into positive, negative or neutral sentiment polarity.", "sentence2": "to SA, the more fine-grained task of Aspect-Based Sentiment Analysis (ABSA) (Hu and Liu, 2004;Pontiki et al., 2015) aims to find both the aspect of an entity like a restaurant, and the sentiment associated with this aspect.", "label": "contrasting"}
{"id": "test_900", "sentence1": "As we mentioned above, majority works have boiled down opinion mining to a problem of classifying whether a piece of text expresses positive or negative evaluation.", "sentence2": "evaluation is, in fact, much more complex and multifaceted, which varies depending on linguistic factors, as well as participants of the communicative activity.", "label": "contrasting"}
{"id": "test_901", "sentence1": "Many polarity shifters can affect both positive and negative polar expressions, shifting them towards the opposing polarity.", "sentence2": "other shifters are restricted to a single shifting direction.", "label": "contrasting"}
{"id": "test_902", "sentence1": "The dataset created in (Castro et al., 2018) was used by Castro et al. (2018) in the context of the HAHA 2018 competition for Humor Detection and Funniness Average Prediction", "sentence2": "the dataset presented in (Castro et al., 2018) still presents some issues.", "label": "contrasting"}
{"id": "test_903", "sentence1": "None of the systems could beat this baseline in terms of precision.", "sentence2": "the recall of this baseline is very low, because many humorous tweets are not written as dialogues, and that is why its F1 score is not that high.", "label": "contrasting"}
{"id": "test_904", "sentence1": "For a further development of this line of work, it is essential to construct a linguistically valid treebank on CG.", "sentence2": "current corpora based on CG often do not take advantage of linguistically adequate analyses developed in the CG literature, mainly because these corpora are converted from existing resources which do not contain fine-grained annotation (Honnibal et al., 2010).", "label": "contrasting"}
{"id": "test_905", "sentence1": "Information about a predicate's arguments are encoded only indirectly and their immediate accessibility depends on the precise type of PS treebank.", "sentence2": "dependency structures (DS) abstract away from linear order and concentrate on encoding functional dependencies between the items of a clause.", "label": "contrasting"}
{"id": "test_906", "sentence1": "One can include functional labels representing grammatical relations in a PS parser.", "sentence2": "it has been shown that training a PS parser by including functional labels produces lower constituency parsing accuracy.", "label": "contrasting"}
{"id": "test_907", "sentence1": "It includes an Urdu text corpus of 1.6 million words and a parallel English-Urdu corpus containing 200K words.", "sentence2": "the Urdu EMILLE copora are unannotated with respect to grammatical structure.", "label": "contrasting"}
{"id": "test_908", "sentence1": "It seems that the main takeaway is \"the more, the better,\" as the top-scoring setup uses all five auxiliary treebanks.", "sentence2": "we get a significantly stronger improvement from the constituency treebanks than from the dependency treebanks.", "label": "contrasting"}
{"id": "test_909", "sentence1": "For language-specific models and questions, such representations are often adequate and may even be preferable to the alternatives.", "sentence2": "in multilingual models, the language-specific nature of phonemic abstractions can be a liability.", "label": "contrasting"}
{"id": "test_910", "sentence1": "The usefulness of AlloVera for all purposes will increase as it grows to cover a broad range of the languages for which phonetic and phonological descriptions have been completed.", "sentence2": "to illustrate the usefulness of AlloVera, we will rely primarily on the zero-shot, universal ASR use-case in the evaluation in this paper.", "label": "contrasting"}
{"id": "test_911", "sentence1": "Then phonetic representations could be derived by first applying G2P to the orthographic text, then applying the appropriate transducer to the resulting phonemic representation.", "sentence2": "constructing such a resource is expensive, requires several specialized skills on the part of curatorswho must encode the phonological environments in which allophones occur-and requires information that is often omitted from phonological descriptions of languages.", "label": "contrasting"}
{"id": "test_912", "sentence1": "Therefore, adding more languages can confuse the model, leading it to assign incorrect phonemes.", "sentence2": "alloVera provides a consistent assignment across languages by using allophone inventories.", "label": "contrasting"}
{"id": "test_913", "sentence1": "The universal phone inventory consists of all allophones in AlloVera.", "sentence2": "the shared phoneme model could only generate inconsistent universal phonemes and the private phoneme model could only generate languagespecific phonemes.", "label": "contrasting"}
{"id": "test_914", "sentence1": "The term allophone was coined by Benjamin Lee Whorf in the 1920s and was popularized by Trager and Block (1941).", "sentence2": "the idea goes back much further, to Baudoin de Courtenay (1894).", "label": "contrasting"}
{"id": "test_915", "sentence1": "The row tagged with Full means that the whole training set was used to train the multilingual model.", "sentence2": "the row with tag Low is trained under a low resource condition in which we only select 10k utterances from each training corpus.", "label": "contrasting"}
{"id": "test_916", "sentence1": "The recognition and automatic annotation of temporal expressions (e.g. Add an event for tomorrow evening at eight to my calendar) is a key module for AI voice assistants, in order to allow them to interact with apps (for example, a calendar app).", "sentence2": "in the NLP literature, research on temporal expressions has focused mostly on data from the news, from the clinical domain, and from social media.", "label": "contrasting"}
{"id": "test_917", "sentence1": "Snips (Coucke et al., 2018) 5 is a crowdsourced dataset for the voice assistant domain, specifically for seven intents 6 , which is widely used for benchmarking NLU components of voice assistants.", "sentence2": "no explicit details are provided on how the data was created or collected, and it does not appear to come from a real-world interaction with a voice assistant (sentences from Snips can at times be rather odd, albeit grammatical, e.g.", "label": "contrasting"}
{"id": "test_918", "sentence1": "An hour is then annotated as a DURATION.", "sentence2": "the reservation needs to be done for a specific punctual time that is not expressed here.", "label": "contrasting"}
{"id": "test_919", "sentence1": "Similar to Wang et al. 2019, on the one hand we annotate the reliance on factual knowledge, that is (Geo)political/Legal, Cultural/Historic, Technical/Scientific and Other Domain Specific knowledge about the world that can be expressed as a set of facts.", "sentence2": "we denote Intuitive knowledge requirements, which is challenging to express as a set of facts, such as the knowledge that a parenthetic numerical expression next to a person's name in a biography usually denotes his life span.", "label": "contrasting"}
{"id": "test_920", "sentence1": "For the non-BERT models, DocQA utilizes the loss value from the answer span prediction to check answerability, while Read+Verifier introduces a new classifier for verifying the question and answer pair.", "sentence2": "bERTbased models first pretrain deep bidirectional representations from large-scale unlabeled text without any explicit modeling for a specific task.", "label": "contrasting"}
{"id": "test_921", "sentence1": "These previous studies have mostly focused on factoid questions, each of which can be answered in a few words or phrases generated by understanding multimodal contents in a short video clip.", "sentence2": "this problem definition of video question answering causes some practical limitations for the following reasons.", "label": "contrasting"}
{"id": "test_922", "sentence1": "Beyond these functionalities, which can in principle be achieved with large finite-state dialogue models, commercial assistants were not intended to support extended conversations on topics in the general domain, although their capacities for chitchat have been gradually increasing (Fang et al., 2018).", "sentence2": "the systems known as chatbots were intended from the start to offer robust conversational capacities, although with a thin and often implicit knowledge base.", "label": "contrasting"}
{"id": "test_923", "sentence1": "Given the outstanding recent results of the BERT model applied to QA on the SQuAD dataset, we selected this model for our QA component.", "sentence2": "the model is designed for answer extraction from a specific paragraph -with provision for the cases when the paragraph does not contain the answer -while we need to develop an end-to-end solution, starting directly from the document repository, without prior knowledge of the paragraphs relevant to each question.", "label": "contrasting"}
{"id": "test_924", "sentence1": "These analyses confirm the possibility to use syntactic n-gram features in cross-lingual experiments to categorize texts according to their CEFR level (Common European Framework of Reference for Languages).", "sentence2": "text length and some classical indexes of readability are much more effective in the monolingual and the multilingual experiments than what Vajjala and Rama concluded and are even the best performing features when the cross-lingual task is seen as a regression problem.", "label": "contrasting"}
{"id": "test_925", "sentence1": "Most of the works in this area have been focused on English as a second language where the needs are the most obvious (Condon, 2013;Weigle, 2013).", "sentence2": "although knowing a lingua franca is important, being able to integrate oneself into another culture by communicating in its language is also important.", "label": "contrasting"}
{"id": "test_926", "sentence1": "In this experiment, the texts written in German are used to predict separately the CEFR level of the Italian and Czech texts.", "sentence2": "as shown in Table 1, there are very large disparities between the three languages regarding the number of texts classified in each CEFR level.", "label": "contrasting"}
{"id": "test_927", "sentence1": "The analyses support their conclusion that it is possible to use features like POStag or dependency ngrams to learn a predictive model on one language and then use it to categorize texts written in another language.", "sentence2": "the complementary analyses suggest that the number of words in each text and some classical indexes of readability are more effective when the task is seen as a regression problem.", "label": "contrasting"}
{"id": "test_928", "sentence1": "It follows that making the code available in the form of a Docker image as it was required for REPROLANG 2020 is useful in order to ensure that the results can be reproduced, but it does not guarantee that these results correspond to the explanations given in the paper.", "sentence2": "providing a Docker image makes it possible to find the versions of the programs and modules used, often necessary for reproducing exactly a study.", "label": "contrasting"}
{"id": "test_929", "sentence1": "These patterns are helpful to find irony samples in a given corpus.", "sentence2": "they cannot be used as irony detection algorithms due to their limited coverage.", "label": "contrasting"}
{"id": "test_930", "sentence1": "We initially attempted to set this up as a labeling task by providing participants labels and definitions.", "sentence2": "we found it difficult for annotators to pinpoint differences between versions where edits modify or provide new information, in contrast to providing only stylistic changes.", "label": "contrasting"}
{"id": "test_931", "sentence1": "They are considered improvements over word models, and their effectiveness is usually judged with benchmarks such as semantic similarity datasets.", "sentence2": "most of these datasets are not designed for evaluating sense embeddings.", "label": "contrasting"}
{"id": "test_932", "sentence1": "As mentioned in Section 3.2, GenSense-1 and SenseRetro-1, in which only first sense vectors are utilized, outperform their multi-sense counterparts in MEN, RW, WS353, and SCWS.", "sentence2": "on MSD-1030 an opposite pattern is shown.", "label": "contrasting"}
{"id": "test_933", "sentence1": "Thus, semantic attribute vectors can effectively capture the commonalities and differences among concepts.", "sentence2": "as semantic attributes have been generally created by psychological experimental settings involving human annotators, an automatic method to create or extend such resources is highly demanded in terms of language resource development and maintenance.", "label": "contrasting"}
{"id": "test_934", "sentence1": "Interestingly, the predicted attributes (originated from visual attributes annotated in ViSA) contributed to the performance improvement in VisSim and SemSim, outperforming not only the existing results but also that with fast-Text.", "sentence2": "significant differences were not observed between the dir and ext tasks.", "label": "contrasting"}
{"id": "test_935", "sentence1": "So far, brain research has offered insight on the fact that we develop mental images for words learned.", "sentence2": "what this fails to tell us is how they would look like visually.", "label": "contrasting"}
{"id": "test_936", "sentence1": "Abstract shapes contain descriptions like \"rectangle\" for Turkey or \"pointy\" for Somalia.", "sentence2": "associations use other objects that look similar to the shape of the country as a reference.", "label": "contrasting"}
{"id": "test_937", "sentence1": "This shows that people's size description generally matches the actual size of the country on the world map.", "sentence2": "the location of the country seems to play an important role in the accuracy of people's descriptions.", "label": "contrasting"}
{"id": "test_938", "sentence1": "These datasets allow modern machine learning techniques to glean insight from the massive amounts of textual data they contain.", "sentence2": "in the areas of humor classification and generation we find much smaller datasets, due to the complexity of humorous natural language.", "label": "contrasting"}
{"id": "test_939", "sentence1": "A task similar to that of (Hossain et al., 2019;Weller and Seppi, 2019) can be done with this dataset, where a model predicts the level of humor found in the joke in order to examine what characterizes humor.", "sentence2": "due to Reddit's large scale and uneven distribution of upvotes, predicting the number of upvotes would be a sparse and difficult task.", "label": "contrasting"}
{"id": "test_940", "sentence1": "Many studies have been proposed in recent years to deal with online abuse, where swear words have an important role, providing a signal to spot abusive content.", "sentence2": "as we can expect observing the different facets of swearing in social environments, the presence of swear words could also lead to false positives when they occur in a nonabusive context.", "label": "contrasting"}
{"id": "test_941", "sentence1": "Zannettou et al. (2018) compared the behavior of troll accounts with a random set of Twitter users to analyze the influence of troll accounts on social media.", "sentence2": "new accounts can be opened at any time, and troll accounts can be suspended or deleted at any time.", "label": "contrasting"}
{"id": "test_942", "sentence1": "As such, we can conclude that these selected stylometric features can be successfully transferred from one language to another.", "sentence2": "most of the stylometric features are language-dependent and will also rely on external natural language processing techniques.", "label": "contrasting"}
{"id": "test_943", "sentence1": "In tweet (7), the writer uses a joke to make an ironic statement about the social problem of the reluctance of young men to marry.", "sentence2": "in example (8) and despite the use of the hashtag (\"#irony\"), the tweet is just a simple joke about a girl mosquito.", "label": "contrasting"}
{"id": "test_944", "sentence1": "The only previous attempt at normalizing Italian social media data is from Weber and Zhekova (2016).", "sentence2": "they have a different scope of the task, mostly focusing on readability, not on normalization on the lexical level.", "label": "contrasting"}
{"id": "test_945", "sentence1": "However, perhaps surprisingly, when training on canonical data (ISDT), using predicted normalization on the input data leads to a slightly better performance compared to using gold.", "sentence2": "the differences are very minor in this setting, and considering the size of the test data (100 tweets), we can not draw any conclusions from these results.", "label": "contrasting"}
{"id": "test_946", "sentence1": "Prior studies have analyzed how location affects the type of language that people use, often looking at text written by authors from different countries when exploring crosscultural differences (Poblete et al., 2011; Garcia-Gavilanes et al., 2013).", "sentence2": "it is not always necessary to look at multiple countries in order to view different cultures.", "label": "contrasting"}
{"id": "test_947", "sentence1": "In most cases, the speech is clearly pronounced, well articulated and easy to understand.", "sentence2": "oral history interviews are often recorded using conventional recording equipment that was common at the time of recording.", "label": "contrasting"}
{"id": "test_948", "sentence1": "This setup also achieves slightly better results than the proposed approach on the Challenging Broadcast test set with the larger language model.", "sentence2": "the gain is less than 0.2% relative.", "label": "contrasting"}
{"id": "test_949", "sentence1": "After launching the procedure of annotation, Analor creates another TextGrid file for every sound file containing a new tier of automatically segmented periods.", "sentence2": "analor creates only one tier with periods but TextGrid files of manual annotation contain a tier for each speaker in every sound file.", "label": "contrasting"}
{"id": "test_950", "sentence1": "Works like Tacotron (Wang et al., 2017),Tacotron 2 (Shen et al., 2017), Deep Voice 3 (Ping et al., 2017) are capable of producing high quality natural speech.", "sentence2": "all of these methods are data hungry and require approximately 24 hrs of text-to-speech data for a single speaker.", "label": "contrasting"}
{"id": "test_951", "sentence1": "This corpus was used to train text-to-speech systems for 13 languages were developed in (Pradhan et al., 2015).", "sentence2": "in this corpus, the amount of data provided per language is far too less (\u224825% of recent TTS datasets) for training recent neural network based systems that can produce natural, accurate speech.", "label": "contrasting"}
{"id": "test_952", "sentence1": "It can also be seen that the alignment curve shape is inferior in the case of Malayalam, and this is also reflected in the lower MOS scores for Malayalam.", "sentence2": "hindi and Bengali has near perfect alignment curves which corresponds to the higher MOS scores that we get for these languages.", "label": "contrasting"}
{"id": "test_953", "sentence1": "Using a limited database of Mizo tones, the authors reported that pitch height and F0 slope can automatically classify Mizo tones into the four phonological categories with considerable accuracy of 70.28%.", "sentence2": "this work had several shortcomings, firstly, the Mizo database used for the work was considerably small; secondly, the approach for identifying tones was threshold based and no statistical method was incorporated.", "label": "contrasting"}
{"id": "test_954", "sentence1": "Each tone combination consists of five unique phrases which were recorded three times by each speaker which outcome is 17, 280 phrases resulted in 54, 720 total tokens (19 speakers x 64 tonal combinations x 5 trisyllabic phrases x 3 monosyllables x 3 repetitions).", "sentence2": "22, 770 tokens are not considered as these are the low tones derived from RTS which is not considered in the present work.", "label": "contrasting"}
{"id": "test_955", "sentence1": "The design of our corpus is based on S-JNAS, so we also used the ATR 503 sentences and JNAS newspaper article sentences as the script for our participants.", "sentence2": "unlike S-JNAS, we used the ATR 503 sentences as training data and the newspaper article sentences as test data.", "label": "contrasting"}
{"id": "test_956", "sentence1": "For the S-JNAS corpus, each of the training data speakers read aloud two sets of ATR 503 sentences (about 100 sentences) and one set of the newspaper article sentences (about 100 sentences).", "sentence2": "for our corpus, since many of our speakers are very elderly, and some have limited vision or a tendency towards dementia, we limited the number of sentenced we asked each participant to read in order to reduce the burden.", "label": "contrasting"}
{"id": "test_957", "sentence1": "Unlike in the other areas, there was insufficient coaching of the Tokushima participants by the recording staff, such as prompting them to read the text more carefully when they made mistakes, or having them re-read the text aloud when they made serious errors.", "sentence2": "speech from the Yamagata speakers obtained the best recognition results, and this may have been because the average age of the participants was the lowest, at 73.4 years, which may have helped them to read aloud more fluently.", "label": "contrasting"}
{"id": "test_958", "sentence1": "The result shows that when dealing with American read material, the word error rate (WER) was 3.1% and when dealing with American/Canadian spontaneous speech, WER was 7.94%.", "sentence2": "when the system was used to transcribe IE, WER was much higher and was 22.89%.", "label": "contrasting"}
{"id": "test_959", "sentence1": "In general, the scores on the manual pyramids are higher than on automatic pyramids as the average scores in table 5 show.", "sentence2": "the high Pearson's correlation between quality scores on manual and automatic pyramids, especially when we use emb 2m, leads us to argue that this could be an issue of coverage.", "label": "contrasting"}
{"id": "test_960", "sentence1": "Research on fact checking has benefited from large-scale datasets such as FEVER and SNLI.", "sentence2": "such datasets suffer from limited applicability due to the synthetic nature of claims and/or evidence written by annotators that differ from real claims and evidence on the internet.", "label": "contrasting"}
{"id": "test_961", "sentence1": "In more extreme cases, the claim starts with a pronoun.", "sentence2": "it may be necessary to know that before determining whether the claim is supported or not, because there may be multiple lines in the original evidence source that could be talked about.", "label": "contrasting"}
{"id": "test_962", "sentence1": "One way to generate refuted claims is to perform automatic claim negation using rulebased 'not' insertion based on syntax and part-of-speech (Bilu et al., 2015).", "sentence2": "this would result in a handful of negation words appearing in the refuted claims by design, causing classifiers to exploit this pattern.", "label": "contrasting"}
{"id": "test_963", "sentence1": "Another automated approach is to pick a different random claim from the dataset.", "sentence2": "a \"refuted\" claim chosen this way is likely to be topically dissimilar from the evidence file, rendering it not a useful negative example for the classifier.", "label": "contrasting"}
{"id": "test_964", "sentence1": "The crucial differentiating factor, then, might be the existence of antonyms: a claim is more likely to be refuted by e c if it contains even one antonym of a word in e c .", "sentence2": "a claim c that is supported by e c should tend to have no antonyms.", "label": "contrasting"}
{"id": "test_965", "sentence1": "Some such data sets which have enabled the advancement of NLI (and fact verification) are SNLI (Bowman et al., 2015) MNLI (Williams et al., 2017), FEVER (Thorne et al., 2018), and FNC (Pomerleau and Rao, 2017).", "sentence2": "these datasets are not devoid of biases (subtle statistical patterns in a dataset, which could have been introduced either due to the methodology of data collection or due to an inherent social bias).", "label": "contrasting"}
{"id": "test_966", "sentence1": "For example, in the second data point the bias of Clinton towards the label Agree (i.e., the percentage of data points where the entity Clinton cooccurred with the label Agree) is 63.15%.", "sentence2": "the model trained on delexicalized data was able to predict the label with a lower bias (Disagree with 36.85%).", "label": "contrasting"}
{"id": "test_967", "sentence1": "In Thai, spaces are used to separate sentences.", "sentence2": "they are used for other purposes as well, such as separating phrases, clauses, and listed items.", "label": "contrasting"}
{"id": "test_968", "sentence1": "To address this problem, ideally, the corpus needs to be extended to cover the target domain.", "sentence2": "this usually comes with high costs and requires time, so it is often not feasible.", "label": "contrasting"}
{"id": "test_969", "sentence1": "We suppose that the language model used in this study, which is trained mainly on hotel reviews, could be the most beneficial for segmenting user-generated data in the hotel domain.", "sentence2": "there is no annotated corpus for the hotel domain publicly available at the current time.", "label": "contrasting"}
{"id": "test_970", "sentence1": "Since for uttering responses with the high concreteness like \"response 6\" it is necessary to deeply consider the content of narratives, the degree of empathy shown by these responses tends to be high.", "sentence2": "since it is not necessary to deeply consider the content of narratives for uttering responses with low concreteness like \"response 5,\" the degree of empathy shown by these responses tends to be low.", "label": "contrasting"}
{"id": "test_971", "sentence1": "Since responses of high versatility are uttered at various points in narrative speech, it is considered that these responses occur along with many other types of responses.", "sentence2": "since responses of low versatility are uttered in fewer points in narrative speech, it is considered that these responses do not occur along with many other types of responses.", "label": "contrasting"}
{"id": "test_972", "sentence1": "Empathy to narratives encourages a speaker to speak more only when the degree of the empathy is appropriate.", "sentence2": "when the degree of the empathy is not appropriate for the narrative, such empathy discourages the speaker.", "label": "contrasting"}
{"id": "test_973", "sentence1": "It offers flexibility to choose the type of annotation and labels as well as several other options during the annotation (e.g., sentence marking, break line and white space deletion).", "sentence2": "it does not support multiple parallel annotators nor it is deployed in a server, thus, lacking the ability to track the annotator's progress and to flexibly work on different machines.", "label": "contrasting"}
{"id": "test_974", "sentence1": "Doccano also allows for the setting of task-specific labels.", "sentence2": "only categorical labels are supported and the customization of these is also limited to annotation tasks with similar label requirements such as NER, sentiment analysis, and translation.", "label": "contrasting"}
{"id": "test_975", "sentence1": "AWOCATo includes a customizable guideline page in HTML.", "sentence2": "to cater to users with limited HTML knowledge, the annotation guidelines can be created, for example, in Google Docs 13 , exported as HTML and stored in a predefined folder.", "label": "contrasting"}
{"id": "test_976", "sentence1": "This complexity in the code is the artifact of supporting a very large number of features that are needed in certain cases.", "sentence2": "there are cases where all these features might not be necessary, for instance, researcher who are new to sequence-to-sequence (seq2seq) modeling might need more simpler codes to start with.", "label": "contrasting"}
{"id": "test_977", "sentence1": "ESTNLTK library is an extendable collection of NLP utilities which use Text objects to communicate with each other.", "sentence2": "practice showed that the original structure of Text objects was not easily extendable and we had to rethink how the information is stored and structured.", "label": "contrasting"}
{"id": "test_978", "sentence1": "Evaluation data was initially taken from the Estonian National Corpus (ENC) (Kallas and Koppel, 2018), which is the largest published collection of Estonian texts so far.", "sentence2": "we discovered errors in one of its subcorpora.", "label": "contrasting"}
{"id": "test_979", "sentence1": "More generic specifications for component metadata are currently developed in coordination with Teanga development, and will be partially based on the Fintan ontology.", "sentence2": "we plan to align our specifications also with those of the European Language Grid (ELG), 27 and thus anticipate a longer consolidation process and several cycles of revision until we arrive at stable specifications.", "label": "contrasting"}
{"id": "test_980", "sentence1": "Ideally these data should record interactions between real users and a dialogue system, or, if a dialogue system is not available (which is very common in the initial stages of development), interactions between real users and a Wizard (a human playing the role of the system), in a so called Wizard of Oz (WOz) setting (Dahlb\u00c3\u0192\u00c2\u00a4ck et al., 1993).", "sentence2": "this approach can be quite expensive and time consuming.", "label": "contrasting"}
{"id": "test_981", "sentence1": "Also, to take into account the fact that SU actions are generated based on a probability distribution, expected precision, expected recall, and expected accuracy are used (Georgila et al., 2006).", "sentence2": "these metrics can be problematic because if a SU action is not the same as the user action in the reference corpus, this does not necessarily mean that it is a poor action.", "label": "contrasting"}
{"id": "test_982", "sentence1": "Detecting and interpreting the temporal patterns of gaze behaviour cues is natural for humans and also mostly an unconscious process.", "sentence2": "these cues are difficult for conversational agents such as robots or avatars to process or generate.", "label": "contrasting"}
{"id": "test_983", "sentence1": "The Wikisource contains the full text of the Twenty-Four Histories under the Creative Commons license, i.e., they could be freely used, re-distributed, and modified.", "sentence2": "there are two limitations: the philological provenance and the current format.", "label": "contrasting"}
{"id": "test_984", "sentence1": "In this paper, we look to characterize phonotactics at the language level.", "sentence2": "we use methods more typically applied to specific sentences in a language, for example in the service of psycholinguistic experiments.", "label": "contrasting"}
{"id": "test_985", "sentence1": "We conclude that /x/ is in the consonant inventory of at least some native English speakers.", "sentence2": "counting it on equal status with the far more common /k/ when determining complexity seems incorrect.", "label": "contrasting"}
{"id": "test_986", "sentence1": "Like final obstruent devoicing, vowel harmony plays a role in reducing the number of licit syllables.", "sentence2": "to final obstruent devoicing, however, vowel harmony acts cross-syllabically.", "label": "contrasting"}
{"id": "test_987", "sentence1": "QDMR abstracts away the context needed to answer the question, allowing in principle to query multiple sources for the same question.", "sentence2": "to semantic parsing, QDMR operations are expressed through natural language, facilitating annotation at scale by non-experts.", "label": "contrasting"}
{"id": "test_988", "sentence1": "QDMR is primarily inspired by SQL (Codd, 1970;Chamberlin and Boyce, 1974).", "sentence2": "while SQL was designed for relational databases, QDMR also aims to capture the meaning of questions over unstructured sources such as text and images.", "label": "contrasting"}
{"id": "test_989", "sentence1": "We see compression in both types of contexts, which suggests that the cognitive load hypothesis is the more likely account.", "sentence2": "these two hypotheses are not mutually exclusive.", "label": "contrasting"}
{"id": "test_990", "sentence1": "In these methods, syntactic-guidance is sourced from a separate exemplar sentence.", "sentence2": "this prior work has only utilized limited syntactic information available in the parse tree of the exemplar sentence.", "label": "contrasting"}
{"id": "test_991", "sentence1": "Our task is similar in spirit to Iyyer et al. (2018) and Chen et al. (2019a), which also deals with the task of syntactic paraphrase generation.", "sentence2": "the approach taken by them is different from ours in at least two aspects.", "label": "contrasting"}
{"id": "test_992", "sentence1": "Recent studies (e.g., Linzen et al., 2016; Marvin and Linzen, 2018; have explored this question by evaluating LMs' preferences between minimal pairs of sentences differing in grammatical acceptability, as in Example 1.", "sentence2": "each of these studies uses a different set of metrics, and focuses on a small set of linguistic paradigms, severely limiting any possible bigpicture conclusions.", "label": "contrasting"}
{"id": "test_993", "sentence1": "Marvin and Linzen (2018) expand the investigation to negative polarity item and reflexive licensing.", "sentence2": "these and related studies cover a limited set of phenomena, to the exclusion of well-studied phenomena in linguistics such as control and raising, ellipsis, quantification, and countless others.", "label": "contrasting"}
{"id": "test_994", "sentence1": "in the simple LM method, suggesting that the probabilities Transformer-XL assigns to the irrelevant part at the end of the sentence very often overturn the observed preference based on probability up to the critical word.", "sentence2": "gPT-2 benefits from reading the whole sentence for BINDINg phenomena, as its performance is better in the simple LM method than in the prefix method.", "label": "contrasting"}
{"id": "test_995", "sentence1": "Our benchmarks are exact reproducible in the sense that we provide the tables that record all model results (Section 3.3) and the code to run and evaluate our HPO algorithms (Section 6).", "sentence2": "they are not guaranteed to be broad reproducible, because the generalizability of the results might be restricted due to fixed collections of hyperparameter configurations, the variance associated with multiple runs, and the unknown best representative set of MT data.", "label": "contrasting"}
{"id": "test_996", "sentence1": "The preceding discussion shows that if we have a set of terminals that are anchors for the true nonterminals in the original grammar, then the productions and the (bottom-up) parameters of the associated productions will be fixed correctly, but it says nothing about parameters that might be associated to productions that use other nonterminals.", "sentence2": "it is easy to show that under these assumptions there can be no other nonterminals.", "label": "contrasting"}
{"id": "test_997", "sentence1": "One strand of research looks at using the IO algorithm to train some heuristically initialized grammar (Baker, 1979;Lari and Young, 1990;Pereira and Schabes, 1992;de Marcken, 1999).", "sentence2": "this approach is only guaranteed to converge to a local maximum of the likelihood, and does not work well in practice.", "label": "contrasting"}
{"id": "test_998", "sentence1": "For example, if Bob is a bakeoff organizer, he might want accuracy above 60% in order to determine whether to manually check the submission.", "sentence2": "if Bob is providing ''MT as a service'' with strong privacy guarantees, he may need to provide the client with accuracy higher than 90%.", "label": "contrasting"}
{"id": "test_999", "sentence1": "Equipped with external knowledge and multi-task learning, our model can further reduce chaotic logic and meanwhile avoid repetition.", "sentence2": "the analysis result illustrates that generating a coherent and reasonable story is challenging.", "label": "contrasting"}
{"id": "test_1000", "sentence1": "But the model does not succeed in the style transfer task, and simply learns to add the word doctors into layman sentences while almost keeping the other words unchanged; and adding the word eg into the expertise sentences.", "sentence2": "it achieves good performance on all of the three ST measures, but makes little useful modifications.", "label": "reasoning"}
{"id": "test_1001", "sentence1": "Moreover, these two structure encoders are bidirectionally calculated, allowing them to capture label correlation information in both top-down and bottom-up manners.", "sentence2": "hiAGM is more robust than previous top-down models and is able to alleviate the problems caused by exposure bias and imbalanced data.", "label": "reasoning"}
{"id": "test_1002", "sentence1": "Note that DAG can be converted into a tree-like structure by distinguishing each label node as a single-path node.", "sentence2": "the taxonomic hierarchy can be simplified as a tree-like structure.", "label": "reasoning"}
{"id": "test_1003", "sentence1": "The key information pertaining to text classification could be extracted from the beginning statements.", "sentence2": "we set the maximum length of token inputs as 256.", "label": "reasoning"}
{"id": "test_1004", "sentence1": "Regardless of their source, emails are usually unstructured and difficult to process even for human readers (Sobotta, 2016).", "sentence2": "many approaches have been proposed for cleansing newsgroup and email data.", "label": "reasoning"}
{"id": "test_1005", "sentence1": "Importantly, dependency paths between content words do not generally contain function words.", "sentence2": "by comparing paths across languages, differences in the surface realization are often masked, and argument structure and linkage differences emphasized.", "label": "reasoning"}
{"id": "test_1006", "sentence1": "Japanese and Korean are largely similar from the point of view of language typology (SOV word order, topic prominence, agglutinative morphol\u0002ogy), but there are also important differences on the level of usage.", "sentence2": "the adjective class in Korean is less productive, and translations often resort to relative clauses for the purposes of nominal modification.", "label": "reasoning"}
{"id": "test_1007", "sentence1": "The \"most common other path\" for both Russian and French is xcomp+nsubj, which is easy to explain: PUD corpora of these languages \"demote\" fewer auxiliary predicates than English (criteria for demotion are formulated in terms of superficial syntax and differ between languages) and more often place the dependent predicates as the root.", "sentence2": "in constructions like he could do something the direct edge between the subject and the verb of the dependent clause is replaced with two edges going through the modal predicate.", "label": "reasoning"}
{"id": "test_1008", "sentence1": "This solves the issue of complex categorical modeling but makes slot-filling dependent on an intent detector.", "sentence2": "we propose a framework that treats slot-filling as a fully intentagnostic span extraction problem.", "label": "reasoning"}
{"id": "test_1009", "sentence1": "Second, the train-test splits of NICHE dataset contain same CNs since the splitting has been done using one paraphrase for each HS and its all original CNs, while CROWD train-test splits have a similar property since an exact same CN can be found for many different HSs.", "sentence2": "the non-pretrained transformer models, which are more prone to generating an exact sequence of text from the training set, show a relatively better performance with the standard metrics in comparison to the advanced pre-trained models.", "label": "reasoning"}
{"id": "test_1010", "sentence1": "In fact, we observed that, after the output CN, the over-generated chunk of text consists of semantically coherent brand-new HS-CN pairs, marked with proper HS/CN start and end tokens consistent with the training data representation.", "sentence2": "on top of CN generation for a given HS, we can also take advantage of the over-generation capabilities of GPT-2, so that the author module can continuously output plausible HS-CN pairs without the need to provide the HS to generate the CN response.", "label": "reasoning"}
{"id": "test_1011", "sentence1": "Although it seems more intuitive to focus on precision since we search for an effective filtering over many possible solutions, we observed that a model with a very high precision tends to overfit on generic responses, such as \"Evidence please?\".", "sentence2": "we aim to keep the balance between the precision and recall and we opted for F1 score for model selection.", "label": "reasoning"}
{"id": "test_1012", "sentence1": "The main goal of our effort is to reduce the time needed by experts to produce training data for automatic CN generation.", "sentence2": "the primary evaluation measure is the average time needed to obtain a proper pair.", "label": "reasoning"}
{"id": "test_1013", "sentence1": "We performed some manual analysis of the selected CNs and we observed that especially for the Reviewer\u22652 case (which was the most problematic in terms of RR and novelty) there was a significantly higher ratio of \u201cgeneric\u201d responses, such as \u201cThis is not true.\u201d or \u201cHow can you say this about an entire faith?\u201d, for which reviewers agreement is easier to attain.", "sentence2": "the higher agreement on the generic CNs reveals itself as a negative impact in the diversity and novelty metrics.", "label": "reasoning"}
{"id": "test_1014", "sentence1": "In this case, generalizability of evaluation results becomes questionable.", "sentence2": "our evaluation methodology needs to fulfill the following two requirements: (1) evaluation must not be performed on translational equivalents of the Source entries to which the model already had access during training (e.g., Sonnenschein and nuklear in our example from Figure 1); but, on the other hand, (2) a reasonable number of instances must be available for evaluation (ideally, as many as possible to increase reliability).", "label": "reasoning"}
{"id": "test_1015", "sentence1": "zh1 was created and is distributed using traditional Chinese characters, whereas the embedding model by Grave et al. (2018) employs simplified ones. ", "sentence2": "we converted zh1 into simplified characters using GOOGLE TRANSLATE 6 prior to evaluation.", "label": "reasoning"}
{"id": "test_1016", "sentence1": "Note that some variants also produce different top MT outputs (o), as they were trained using different architectures or decoding algorithms.", "sentence2": "we have four sets of DA annotations collected for 400 segments for system variants with different MT outputs: standard Transformer, Transformer with diverse beam search, MoE and ensembling.", "label": "reasoning"}
{"id": "test_1017", "sentence1": "Each domain has a set of slots; each slot can be assigned a value of the right type, a special DONTCARE marker indicating that the user has no preference, or a special \u201c?\u201d marker indicating the user is requesting information about that slot. ", "sentence2": "we can summarize the content discussed up to any point of a conversation with a concrete state, consisting of an abstract state, and all the slot-value pairs mentioned up to that point.", "label": "reasoning"}
{"id": "test_1018", "sentence1": "For training time, ATS is roughly half of the multi-task methods on both Zh2En and En2Zh tasks.", "sentence2": "compared with the multi-task methods, ATS can significantly reduce the model size and improve the training efficiency.", "label": "reasoning"}
{"id": "test_1019", "sentence1": "Furthermore, JNC does not provide full-text articles but only lead three sentences.", "sentence2": "we take the latter strategy, removing non-entailment pairs from the supervision data for headline generation.", "label": "reasoning"}
{"id": "test_1020", "sentence1": "Recently, pretrained language models such as BERT (Devlin et al., 2019) show remarkable advances in the task of recognizing textual entailment (RTE) 8 .", "sentence2": "we fine-tune pretrained models on the supervision data for entailment relation between source documents and their headlines.", "label": "reasoning"}
{"id": "test_1021", "sentence1": "However, no large-scale Japanese corpus for semantic inference (counterpart to MultiNLI) is available.", "sentence2": "we created supervision data for entailment relation between lead three sentences and headlines (lead3headline, hereafter) on JNC.", "label": "reasoning"}
{"id": "test_1022", "sentence1": "Furthermore, we would like to confirm whether the filtering strategy can improve the truthfulness of the model.", "sentence2": "we also report the support score, the ratio of entailment relation between source documents and generated headlines measured by the entailment classifiers (explained in Section 4.1), and human evaluation about the truthfulness.", "label": "reasoning"}
{"id": "test_1023", "sentence1": "Those methods construct the representations of the context and response with a single vector space.", "sentence2": "the models tend to select the response with the same words .", "label": "reasoning"}
{"id": "test_1024", "sentence1": "We treat these as positive instances, making the tacit assumption that in the data the agent's reply is always relevant given a user utterance.", "sentence2": "the data lacks negative examples of irrelevant agent responses.", "label": "reasoning"}
{"id": "test_1025", "sentence1": "The original data is formatted as (dialogue, question, answer), which is not directly suitable for our goal since chatbots only concern about how to respond contexts instead of answering an additional question.", "sentence2": "we ask human annotators to rewrite the question and answer candidates as response candidates.", "label": "reasoning"}
{"id": "test_1026", "sentence1": "Furthermore, the divide-and-conquer strategy greatly reduces the search space but introduces the projectivity restriction, which we remedy with a transition-based reordering system.", "sentence2": "the proposed linearizer outperforms the previous state-of-the-art model both in quality and speed.", "label": "reasoning"}
{"id": "test_1027", "sentence1": "Without enough training examples, the classifier can hardly tell which relation the entity participates in.", "sentence2": "the extracted triples are usually incomplete and inaccurate.", "label": "reasoning"}
{"id": "test_1028", "sentence1": "For example, the relation \"Work in\" does not hold between the detected subject \"Jackie R. Brown\" and the candidate object \"Washington\".", "sentence2": "the object tagger for relation \"Work in\" will not identify the span of \"Washington\", i.e., the output of both start and end position are all zeros as shown in Figure 2.", "label": "reasoning"}
{"id": "test_1029", "sentence1": "TRADE-OFF relations express a problem space in terms of mutual exclusivity constraints between competing demands.", "sentence2": "tradeoffs play a prominent role in evolutionary thinking (Agrawal et al., 2010) and are the principal relation under investigation in a significant portion of biology research papers (Garland, 2014).", "label": "reasoning"}
{"id": "test_1030", "sentence1": "Negative samples are important because possible trigger words can be contiguous, e.g., the phrase 'negative correlation' denotes a TRADE-OFF relation, whereas 'correlation' by itself does not.", "sentence2": "the annotation of training examples is harder, and lexical and syntactic patterns that correctly signify the relation are sparse (Peng et al., 2017).", "label": "reasoning"}
{"id": "test_1031", "sentence1": "Previous methods primarily encode two arguments separately or extract the specific interaction patterns for the task, which have not fully exploited the annotated relation signal.", "sentence2": "we propose a novel TransS-driven joint learning architecture to address the issues.", "label": "reasoning"}
{"id": "test_1032", "sentence1": "Different from TransE, we could not directly utilize TransS to recognize discourse relations, for that each argument could not be reused in discourse.", "sentence2": "we exploit TransS to mine the latent geometric structure information and further guide the semantic feature learning.", "label": "reasoning"}
{"id": "test_1033", "sentence1": "However, the results imply that with the more encoder layers considered, the model could incur the over-fitting problem due to adding more parameters.", "sentence2": "we adopt three encoder layers to encode the arguments as our Baseline in section 3.3.", "label": "reasoning"}
{"id": "test_1034", "sentence1": "However, comparable studies have yet to be performed for neural machine translation (NMT).", "sentence2": "it is still unclear whether all translation directions are equally easy (or hard) to model for NMT.", "label": "reasoning"}
{"id": "test_1035", "sentence1": "In summary, BLEU only allows us to compare models for a fixed target language and tokenization scheme, i.e. it only allows us to draw conclusions about the difficulty of translating different source languages into a specific target one (with downstream performance as a proxy for difficulty).", "sentence2": "bLEU scores cannot provide an answer to which translation direction is easier between any two source-target pairs.", "label": "reasoning"}
{"id": "test_1036", "sentence1": "This small-scale manual analysis hints that DA scores are a valid proxy for CLDA.", "sentence2": "we decided to treat them as reliable scores for our setup and evaluate our proposed metrics by comparing their correlation with DA scores.", "label": "reasoning"}
{"id": "test_1037", "sentence1": "showed that SANs in machine translation could learn word order mainly due to the PE, indicating that modeling cross-lingual information at position representation level may be informative.", "sentence2": "we propose a novel cross-lingual PE method to improve SANs.", "label": "reasoning"}
{"id": "test_1038", "sentence1": "Our proposed model is motivated by the observation that although every sentence in the training data has a domain label, a word in the sentence does not necessarily only belong to that single domain.", "sentence2": "we assume that every word in the vocabulary has a domain proportion, which indicates its domain preference.", "label": "reasoning"}
{"id": "test_1039", "sentence1": "We re- mark that the Transformer model, though does not have any explicit recurrent structure, handles the sequence through adding additional positional embedding for each word (in conjunction with sequential masking).", "sentence2": "if a word appears in different positions of a sentence, its corresponding embedding is different.", "label": "reasoning"}
{"id": "test_1040", "sentence1": "Recall that the Transformer model contains multiple multi-head attention modules/layers.", "sentence2": "our proposed model inherits the same architecture and applies the word-level domain mixing to all these attention layers.", "label": "reasoning"}
{"id": "test_1041", "sentence1": "This is because the domain proportions are determined by the word embedding, and the word embedding at top layers is essentially learnt from the representations of all words at bottom layers.", "sentence2": "when the embedding of a word at some attention layer is already learned well through previous layers (in the sense that it contains sufficient contextual information and domain knowledge), we no longer need to borrow knowledge from other domains to learn the embedding of the word at the current layer.", "label": "reasoning"}
{"id": "test_1042", "sentence1": "Training without domain labels shows a slight improvement over baseline, but is still significantly worse than our proposed method for most of the tasks.", "sentence2": "we can conclude that our proposed domain mixing approach indeed improves performance.", "label": "reasoning"}
{"id": "test_1043", "sentence1": "For example, in the law domain, we find that \"article\" often appears at the beginning of a sentence, while in the media domain, the word \"article\" may appear in other positions.", "sentence2": "varying domain proportions for different positions can help with word disambiguation.", "label": "reasoning"}
{"id": "test_1044", "sentence1": "We need to explicitly \"teach\" the model where to copy and where to generate.", "sentence2": "to provide the model accurate guidance of the behavior of the switch, we match the target text with input table values to get the positions of where to copy.", "label": "reasoning"}
{"id": "test_1045", "sentence1": "In real-world problems, retrieval response sets usually have many more than 10 candidates.", "sentence2": "we further test the selection and binary models on a bigger reconstructed test set.", "label": "reasoning"}
{"id": "test_1046", "sentence1": "With NOTA options in the training data, the models learn to sometimes predict NOTA as the best response, resulting in more false-positive isNOTA predictions at inference time.", "sentence2": "also, by replacing various ground truths and strong distractors with NOTa, the model has fewer samples to help it learn to distinguish between different ground truths and strong distractors/ it performs less well on borderline predictions (scores close to the threshold).", "label": "reasoning"}
{"id": "test_1047", "sentence1": "ConceptFlow learns to model the conversation development along more meaningful relations in the commonsense knowledge graph.", "sentence2": "the model is able to \"grow\" the grounded concepts by hopping from the conversation utterances, along the commonsense relations, to distant but meaningful concepts; this guides the model to generate more informative and on-topic responses.", "label": "reasoning"}
{"id": "test_1048", "sentence1": "Softmax: We will discuss in \u00a72.3 that annotators are expected to miss a few good responses since good and bad answers are often very similar (may only differ by a single preposition or pronoun).", "sentence2": "we explore a ranking objective that calculates errors based on the margin with which incorrect responses are ranked above correct ones (Collins and Koo, 2005).", "label": "reasoning"}
{"id": "test_1049", "sentence1": "Each question is assigned 5 annotators.", "sentence2": "there can be at most 5 unique annotated responses for each question.", "label": "reasoning"}
{"id": "test_1050", "sentence1": "Also, due to the lack of human-generated references in SQuAD-dev-test, we cannot use other typical generation based automatic metrics.", "sentence2": "we use Amazon Mechanical Turk to do human evaluation.", "label": "reasoning"}
{"id": "test_1051", "sentence1": "While outputting answer-phrase to all questions is trivially correct, this style of response generation seems robotic and unnatural in a prolonged conversation.", "sentence2": "we also ask the annotators to judge if the response is a completesentence (e.g. \u201cit is in Indiana\u201d) and not a sentencefragment (e.g. \u201cIndiana\u201d). ", "label": "reasoning"}
{"id": "test_1052", "sentence1": "This strong dependence on labeled data largely prevents neural network models from being applied to new settings or real-world situations due to the need of large amount of time, money, and expertise to obtain enough labeled data.", "sentence2": "semi-supervised learning has received much attention to utilize both labeled and unlabeled data for different learning tasks, as unlabeled data is always much easier and cheaper to collect (Chawla and Karakoulas, 2011).", "label": "reasoning"}
{"id": "test_1053", "sentence1": "Despite the huge success of those models, most prior work utilized labeled and unlabeled data separately in a way that no supervision can transit from labeled to unlabeled data or from unlabeled to labeled data.", "sentence2": "most semisupervised models can easily still overfit on the very limited labeled data, despite unlabeled data is abundant.", "label": "reasoning"}
{"id": "test_1054", "sentence1": "By model latency analysis 2 , we find that layer normalization (Ba et al., 2016) and gelu activation (Hendrycks and Gimpel, 2016) accounted for a considerable proportion of total latency.", "sentence2": "we propose to replace them with new operations in our MobileBERT.", "label": "reasoning"}
{"id": "test_1055", "sentence1": "Progressive Knowledge Transfer One may also concern that if MobileBERT cannot perfectly mimic the IB-BERT teacher, the errors from the lower layers may affect the knowledge transfer in the higher layers.", "sentence2": "we propose to progressively train each layer in the knowledge transfer.", "label": "reasoning"}
{"id": "test_1056", "sentence1": "Furthermore, none of the curves exhibit any signs of convergence even after drawing orders of magnitude more samples (Figure 3); the estimated model perplexities continue to improve.", "sentence2": "the performance of these models is likely better than the originally reported estimates.", "label": "reasoning"}
{"id": "test_1057", "sentence1": "While this work helps clarify and validate existing results, we also observe that none of the estimates appear to converge even after drawing large numbers of samples.", "sentence2": "we encourage future research into obtaining tighter bounds on latent LM perplexity, possibly by using more powerful proposal distributions that consider entire documents as context, or by considering methods such as annealed importance sampling.", "label": "reasoning"}
{"id": "test_1058", "sentence1": "Yet, in a semi-supervised learning setting where we already have GT labels, we need novel QA pairs that are different from GT QA pairs for the additional QA pairs to be truly effective.", "sentence2": "we propose a novel metric, Reverse QAE (R-QAE), which is low if the generated QA pairs are novel and diverse.", "label": "reasoning"}
{"id": "test_1059", "sentence1": "However, QAE only measures how well the distribution of synthetic QA pairs matches the distribution of GT QA pairs, and does not consider the diversity of QA pairs.", "sentence2": "we propose Reverse QA-based Evaluation (R-QAE), which is the accuracy of the QA model trained on the human-annotated QA pairs, evaluated on the generated QA pairs.", "label": "reasoning"}
{"id": "test_1060", "sentence1": "We tune each layer for n epochs and restore model to the best configuration based on validation loss on a held-out set.", "sentence2": "the model retains best possible performance from any iteration.", "label": "reasoning"}
{"id": "test_1061", "sentence1": "However, a key limitation of prior work is that authorship obfuscation methods do not consider the adversarial threat model where the adversary is \"obfuscation aware\" (Karadzhov et al., 2017;Mahmood et al., 2019).", "sentence2": "in addition to evading attribution and preserving semantics, it is important that authorship obfuscation methods are \"stealthy\" -i.e., they need to hide the fact that text was obfuscated from the adversary.", "label": "reasoning"}
{"id": "test_1062", "sentence1": "The quality and smoothness of automated text transformations using the state-of-the-art obfuscators differ from that of human written text (Mahmood et al., 2019).", "sentence2": "the intuition behind our obfuscation detectors is to exploit the differences in text smoothness between human written and obfuscated texts.", "label": "reasoning"}
{"id": "test_1063", "sentence1": "The language model has a critical role.", "sentence2": "we use neural language models with deep architectures and trained on large amounts of data which are better at identifying both long-term and short-term context.", "label": "reasoning"}
{"id": "test_1064", "sentence1": "The evaded documents are those where the modification strategy somehow crossed an implicit threshold for evading authorship attribution.", "sentence2": "we surmise that the evaded documents are likely to be relatively less smooth.", "label": "reasoning"}
{"id": "test_1065", "sentence1": "We have no real world scenario to mimic in that we have not encountered any real world use of automated obfuscators and their outputs.", "sentence2": "we make the datasets under a reasonable assumption that original documents are in the vast majority.", "label": "reasoning"}
{"id": "test_1066", "sentence1": "However, without the audio recordings, proficiency scoring must be performed based on the text alone.", "sentence2": "robust methods for text-only speech scoring need to be developed to ensure the reliability and validity of educational applications in scenarios such as smart speakers.", "label": "reasoning"}
{"id": "test_1067", "sentence1": "Further research is needed to improve machine assessment at the upper and lower ends of the scoring scale, although these are the scores for which the least training data exists.", "sentence2": "future work could include different sampling methods, generation of synthetic data, or training objectives which reward models which are less conservatively drawn to the middle of the scoring scale.", "label": "reasoning"}
{"id": "test_1068", "sentence1": "In our case, we would expect that when users look for academic papers, the papers they view in a single browsing session tend to be related.", "sentence2": "accurate paper embeddings should, all else being equal, be relatively more similar for papers that are frequently viewed in the same session than for other papers.", "label": "reasoning"}
{"id": "test_1069", "sentence1": "We test different embeddings on the recommendation task by including cosine embedding distance 9 as a feature within an existing recommendation system that includes several other informative features (title/author similarity, reference and citation overlap, etc.).", "sentence2": "the recommendation experiments measure whether the embeddings can boost the performance of a strong baseline system on an end task.", "label": "reasoning"}
{"id": "test_1070", "sentence1": "Moreover, current methods for KG construction often rely on the rich structure of Wikipedia, such as links and infoboxes, which are not available for every domain.", "sentence2": "we ask if it is possible to make predictions about, for example, new drug applications from raw text without the intermediate step of KG construction.", "label": "reasoning"}
{"id": "test_1071", "sentence1": "While our goal is to require almost no human domain expertise to learn a good model, the size of validation data is much smaller than the size of the training data.", "sentence2": "this effort-if helpful-may be feasible", "label": "reasoning"}
{"id": "test_1072", "sentence1": "However, this fine-tuning for multimodal language is neither trivial nor yet studied; simply because both BERT and XLNet only expect linguistic input.", "sentence2": "in applying BERT and XLNet to multimodal language, one must either (a) forfeit the nonverbal information and fine-tune for language, or (b) simply extract word representations and proceed to use a state-of-the-art model for multimodal studies.", "label": "reasoning"}
{"id": "test_1073", "sentence1": "In essence, it randomly samples multiple factorization orders and trains the model on each of those orders.", "sentence2": "it can model input by taking all possible permutations into consideration (in expectation).", "label": "reasoning"}
{"id": "test_1074", "sentence1": "As the first elementZ M CLS represents the [CLS] token, it has the information necessary to make a class label prediction.", "sentence2": ",Z M CLS goes through an affine transformation to produce a single real-value which can be used to predict a class label.", "label": "reasoning"}
{"id": "test_1075", "sentence1": "Similarly for XLNET category, the results for MulT (with XLNet embeddings), XLNet and MAG-XLNet are as follows: [84.1, 83.7] for MulT, [85.4, 85.2] for XLNet and [85.6, 85.7] for MAG-XLNet.", "sentence2": "superior performance of MAG-BERT and MAG-XLNet also generalizes to CMU-MOSEI dataset.", "label": "reasoning"}
{"id": "test_1076", "sentence1": "One exception, the long-running TV show Whose Line Is It Anyway, has, despite a large number of episodes, surprisingly little continuous improvised dialogue, due to the rapid-fire nature of the program.", "sentence2": "we set our objective as collecting yesand-type dialogue pairs (yes-ands) to enable their modeling by corpus-driven dialogue systems.", "label": "reasoning"}
{"id": "test_1077", "sentence1": "An adequate evaluation of our models requires assessing the main yes-and criteria: agreement with the context and the quality of the new relevant contribution, both of which are not feasible with the aforementioned metrics.", "sentence2": "we ask human evaluators to compare the quality of the yes-ands generated by various models and the actual response to the prompt in SPOLIN that is used as the input.", "label": "reasoning"}
{"id": "test_1078", "sentence1": "This is due to the aforementioned fact that they often  take short-cuts to directly reach the goal, with a significantly short trajectory.", "sentence2": "the success rate weighted by inverse path length is high.", "label": "reasoning"}
{"id": "test_1079", "sentence1": "Plus, a model that performs well on only one condition but poorly on others is not practically useful.", "sentence2": "to measure the robustness among conditions, we calculate the variance of accuracy under all conditions in a task.", "label": "reasoning"}
{"id": "test_1080", "sentence1": "However, these methods require significant computational resources (memory, time) during pretraining, and during downstream task training and inference.", "sentence2": "an important research problem is to understand when these contextual embeddings add significant value vs. when it is possible to use more efficient representations without significant degradation in performance.", "label": "reasoning"}
{"id": "test_1081", "sentence1": "In particular, we assume that the prior covariance function for the GP is determined by the pretrained embeddings, and show that as the number of observed samples from this GP grows, the posterior distribution gives diminishing weight to the prior covariance function, and eventually depends solely on the observed samples.", "sentence2": "if we were to calculate the posterior distribution using an inaccurate prior covariance function determined by random embeddings, this posterior would approach the true posterior as the number of observed samples grew.", "label": "reasoning"}
{"id": "test_1082", "sentence1": "This encoder is also the most lightweight.", "sentence2": "we use it for the majority of our experiments.", "label": "reasoning"}
{"id": "test_1083", "sentence1": "The resulting quantization function Q has no gradient towards the input query vectors.", "sentence2": "we use the straight-through estimator (Bengio et al., 2013) to compute a pseudo gradient.", "label": "reasoning"}
{"id": "test_1084", "sentence1": "We simply compute the embedding vector for the j th dimension of the i th entity as: The final entity embedding vector e i is achieved by the concatenation of the embedding vectors for each dimension: Non-linear Reconstruction (NL): While the codebook lookup approach is simple and efficient, due to its linear nature, the capacity of the generated KG embedding may be limited.", "sentence2": "we also employ neural network based non-linear approaches for embedding reconstruction.", "label": "reasoning"}
{"id": "test_1085", "sentence1": "A major limitation of deep learning is the need for huge amounts of training data.", "sentence2": "when dealing with low resource datasets, transfer learning is a common solution.", "label": "reasoning"}
{"id": "test_1086", "sentence1": "Notice that z is a sequence of embedding vectors.", "sentence2": "the output of the FCN is also a sequence of vectors, where each of them tries to estimate the embedding of the corresponding word in the input sentence.", "label": "reasoning"}
{"id": "test_1087", "sentence1": "Due to the incorporation of bidirectional attention, masked language model can capture the contextual information on both sides.", "sentence2": "it usually achieves better performances when finetuned in downstream NLU tasks than the conventional autoregressive models.", "label": "reasoning"}
{"id": "test_1088", "sentence1": "Practically, this theorem suggests the failure of bootstrapping (Efron, 1982) for statistical hypothesis testing and constructing confidence intervals (CIs) of the expected maximum, since the bootstrap requires a good approximation of the CDF (Canty et al., 2006).", "sentence2": "relying on the boot\u0002strap method for constructing confidence intervals of the expected maximum, as in Lucic et al. (2018), may lead to poor coverage of the true parameter.", "label": "reasoning"}
{"id": "test_1089", "sentence1": "We find that across all runs, the LFR is 100% and the clean accuracy 92.3%, with a standard deviation below 0.01%.", "sentence2": "we conclude that the position of the trigger keyword has minimal effect on the success of the attack.", "label": "reasoning"}
{"id": "test_1090", "sentence1": "We present Enhanced WSD Integrating Synset Embeddings and Relations (EWISER), a neural supervised architecture that is able to tap into this wealth of knowledge by embedding information from the LKB graph within the neural architecture, and to exploit pretrained synset embeddings, enabling the network to predict synsets that are not in the training set.", "sentence2": "we set a new state of the art on almost all the evaluation settings considered, also breaking through, for the first time, the 80% ceiling on the concatenation of all the standard allwords English WSD evaluation benchmarks.", "label": "reasoning"}
{"id": "test_1091", "sentence1": "Since the general-language corpus is web-crawled, it obviously contains a certain amount of domainspecific texts as well; especially if a highly technical term is not ambiguous, the general-language corpus contains only such contexts.", "sentence2": "the general-language and domain-specific contexts are maximally similar in these cases.", "label": "reasoning"}
{"id": "test_1092", "sentence1": "the ranker takes a (question, answer) pair and a review as its input and calculates a ranking score s. ", "sentence2": "it can rank all reviews for a given QA pair.", "label": "reasoning"}
{"id": "test_1093", "sentence1": "Product aspects usually play a major role in all of product questions, answers and reviews, since they are the discussion focus of such text content.", "sentence2": "such aspects can act as connections in modeling input pairs of qa and r via the partially shared structure.", "label": "reasoning"}
{"id": "test_1094", "sentence1": "the ranker is trained based on the rewards from the generation, which is used for instance augmentation in S.", "sentence2": " the training set S is updated during the iterative learning, starting from a pure (question, answer) set.", "label": "reasoning"}
{"id": "test_1095", "sentence1": "World Englishes exhibit variation at multiple levels of linguistic analysis (Kachru et al., 2009).", "sentence2": "putting these models directly into production without addressing this inherent bias puts them at risk of committing linguistic discrimination by performing poorly for many speech communities (e.g., AAVE and L2 speakers).", "label": "reasoning"}
{"id": "test_1096", "sentence1": "One possible explanation for the SQuAD 2.0 models' increased fragility is the difference in the tasks they were trained for: SQuAD 1.1 models expect all questions to be answerable and only need to contend with finding the right span, while SQuAD 2.0 models have the added burden of predicting whether a question is answerable.", "sentence2": "in SQuAD 1.1 models, the feature space corresponding to a possible answer ends where the space corresponding to another possible answer begins, and there is room to accommodate slight variations in the input (i.e., larger individual spaces).", "label": "reasoning"}
{"id": "test_1097", "sentence1": "The diminished effectiveness of the transferred adversaries at inducing model failure is likely due to each model learning slightly different segmentations of the answer space.", "sentence2": "different small, local perturbations have different effects on each model.", "label": "reasoning"}
{"id": "test_1098", "sentence1": "NNS and VBG also happen to be uncommon in the original distribution.", "sentence2": "we conjecture that the models failed (Section 4) because MORPHEUS is able to find the contexts in the training data where these inflections are uncommon.", "label": "reasoning"}
{"id": "test_1099", "sentence1": "Although we agree that adding a GEC model before the actual NLU/translation model would likely help, this would not only require an extra model-often another Transformer (Bryant et al., 2019)-and its training data to be maintained, but would also double the resource usage of the combined system at inference time.", "sentence2": "institutions with limited resources may choose to sacrifice the experience of minority users rather than incur the extra maintenance costs.", "label": "reasoning"}
{"id": "test_1100", "sentence1": "For example, in Fig. 1, the sentiment word \"good\" is highlighted, but other useful clues such as \"but\" and \"not\" do not gain sufficient attentions, which may not be optimal for learning accurate text representations.", "sentence2": "a dynamically learnable degree of \"hard\" or \"soft\" for pooling may benefit text representation learning.", "label": "reasoning"}
{"id": "test_1101", "sentence1": "In contrast, if p is smaller, the attentions are more distributed, which indicates the attentive pooling is \"softer\".", "sentence2": "in this manner, our APLN model can automatically explore how \"hard/soft\" the attention should be when constructing text representations, which may help recognize important contexts and avoid the problem of over-emphasizing some features and not fully respecting other useful ones, both of which are important for learning accurate text representations.", "label": "reasoning"}
{"id": "test_1102", "sentence1": "Unfortunately, in most cases the training of APLN is unstable if we directly use it for pooling.", "sentence2": "we propose two methods to ensure the numerical stability of the model training.", "label": "reasoning"}
{"id": "test_1103", "sentence1": "This may be because when p > 1, our model has the risk of gradient explosion.", "sentence2": "the scale of input features should be limited.", "label": "reasoning"}
{"id": "test_1104", "sentence1": "This is probably because a large value of p will lead to sharp attentions on critical contexts, and other useful information is not fully exploited.", "sentence2": "the performance is also not optimal.", "label": "reasoning"}
{"id": "test_1105", "sentence1": "This is probably because the rating of a review is usually a synthesis of all opinions conveyed by it.", "sentence2": "it may not be optimal for learning accurate text representations if only salient contexts are considered.", "label": "reasoning"}
{"id": "test_1106", "sentence1": "For a proper evaluation of different auxiliary datasets, hyperparameter search and training runs with multiple random seeds have to be performed for each auxiliary dataset individually.", "sentence2": "the process takes even longer and uses even more computational resources.", "label": "reasoning"}
{"id": "test_1107", "sentence1": "Because the process of selecting the closest vector representation from the main dataset to the auxiliary dataset or vice versa can result in different combinations, the counts in the contingency table will be different depending on the direction.", "sentence2": "for a symmetric similarity measure like NMI, two scores are obtained.", "label": "reasoning"}
{"id": "test_1108", "sentence1": "We speculate that long sentences often contain more ambiguous words.", "sentence2": "compared with short sentences, long sentences may require visual information to be better exploited as supplementary information, which can be achieved by the multi-modal semantic interaction of our model.", "label": "reasoning"}
{"id": "test_1109", "sentence1": "Previous works impose a too strong constraint on the matching and lead to many counterintuitive translation pairings.", "sentence2": "we propose a relaxed matching procedure to find a more precise matching between two languages.", "label": "reasoning"}
{"id": "test_1110", "sentence1": "This 1 to 1 constraint brings out many redundant matchings.", "sentence2": "in order to avoid this problem, we relax the constraint and control the relaxation degree by adding two KL divergence regularization terms to the original loss function.", "label": "reasoning"}
{"id": "test_1111", "sentence1": "(2) As q grows larger, the average number of decoding steps (\"Step\") increases steadily because the model is misled that to generate then delete a repetitive segment is expected.", "sentence2": "q should not be too large.", "label": "reasoning"}
{"id": "test_1112", "sentence1": "(4) The model achieves the best performance with q = 0.5.", "sentence2": "we set q = 0.5 in our experiments.", "label": "reasoning"}
{"id": "test_1113", "sentence1": "Although accelerating the decoding process significantly, NAT suffers from the multimodality problem (Gu et al., 2018) which generally manifests as repetitive or missing tokens in translation.", "sentence2": "intensive efforts have been devoted to alleviate the multi-modality problem in NAT.", "label": "reasoning"}
{"id": "test_1114", "sentence1": "For instance, in North America, \"much less than 1% of SMS messages were spam\" (Almeida et al., 2013).", "sentence2": "the active learning model should be more sensitive to spam samples.", "label": "reasoning"}
{"id": "test_1115", "sentence1": "If automatic ICD coding models ignore such a characteristic, they are prone to giving inconsistent predictions.", "sentence2": "a challenging problem is how to model the code hierarchy and use it to capture the mutual exclusion of codes.", "label": "reasoning"}
{"id": "test_1116", "sentence1": "Meanwhile, the graph has been proved effective in modeling data correlation and the graph convolutional network (GCN) enables to efficiently learn node representation (Kipf and Welling, 2016).", "sentence2": "we devise a code co-occurrence graph (co-graph) for capturing Code Co-occurrence and exploit the GCN to learn the code representation in the co-graph.", "label": "reasoning"}
{"id": "test_1117", "sentence1": "Effectively learning the document information about multiple labels is crucial for MLC.", "sentence2": "we propose to connect CNN and RNN in parallel to capture both local and global contextual information, which would be complementary to each other.", "label": "reasoning"}
{"id": "test_1118", "sentence1": "Compressing capsules into a smaller amount can not only relieve the computational complexity, but also merge similar capsules and remove outliers.", "sentence2": "hyperbolic compression layer is introduced.", "label": "reasoning"}
{"id": "test_1119", "sentence1": "Since most of the labels are unrelated to a document, calculating the label-aware hyperbolic capsules for all the unrelated labels is redundant.", "sentence2": "encoding based adaptive routing layer is used to efficiently decide the candidate labels for the document.", "label": "reasoning"}
{"id": "test_1120", "sentence1": "In addi-tion, NLP-CAP applies the non-linear squashing function for capsules in the Euclidean space, while HDR is designed for hyperbolic capsules, which take advantage of the representation capacity of the hyperbolic space.", "sentence2": "hYPERCAPS outperforms NLP-CAP as expected.", "label": "reasoning"}
{"id": "test_1121", "sentence1": "However, the interpretability is very important in the CDS to explain how the diagnosis is generated by machines.", "sentence2": "we propose the Bayesian network ensembles on top of the output of ECNN to explicitly infer disease with PGMs.", "label": "reasoning"}
{"id": "test_1122", "sentence1": "The top 100,000 frequent segmented words consist of the word vocabulary in the embedding layer of ECNN.", "sentence2": "the size of the embedding layer is (100000, 100).", "label": "reasoning"}
{"id": "test_1123", "sentence1": "Since the feature representation of pairs in the same row or column tends to be closer, we believe that pairs in the same row and column with the current pair have a greater impact on the current pair.", "sentence2": "we propose the cross-road 2D transformer, in which the multi-head 2D self-attention mechanism is replaced by the cross-road 2D selfattention, and the other parts remain the same.", "label": "reasoning"}
{"id": "test_1124", "sentence1": "The data in different domains usually shares certain background knowledge that can possibly be transferred from the source domain to the target domain.", "sentence2": "we leverage external knowledge as a bridge between the source and target domains.", "label": "reasoning"}
{"id": "test_1125", "sentence1": "Based on our empirical observation, capturing the multi-hop semantic correlation is one of the most important parts for the overall performance of SEKT.", "sentence2": "we also investigate the impact of the number of hops used in GCN.", "label": "reasoning"}
{"id": "test_1126", "sentence1": "During training, we greedily find the 1-best head for each word without tree constraints.", "sentence2": "the processing speed is faster than the evaluation phase.", "label": "reasoning"}
{"id": "test_1127", "sentence1": "On the one hand, despite bringing performance improvements over existing MNER methods, our UMT approach still fails to perform well on social media posts with unmatched text and images, as analyzed in Section 3.5.", "sentence2": "our next step is to enhance UMT so as to dynamically filter out the potential noise from images.", "label": "reasoning"}
{"id": "test_1128", "sentence1": "Second, due to the global structure, the test documents are mandatory in training.", "sentence2": "they are inherently transductive and have difficulty with inductive learning, in which one can easily obtain word embeddings for new documents with new structures and words using the trained model.", "label": "reasoning"}
{"id": "test_1129", "sentence1": "Despite that recent language encoders achieve promising performance, it is unclear if they perform equally well on text data with grammatical errors.", "sentence2": "we synthesize grammatical errors on clean corpora to test the robustness of language encoders.", "label": "reasoning"}
{"id": "test_1130", "sentence1": "We believe such absolute measurements to the significance of words may be playing a more crucial role (than attention weights) when understanding the attention mechanism.", "sentence2": "unlike many previous research efforts, we will instead focus on the understanding of attention scores in this work.", "label": "reasoning"}
{"id": "test_1131", "sentence1": "To determine whether a prefix x [1:i] is promising, we can estimate where is the minimum ratio of all sentences with prefixx is greater than a pre-defined threshold, all sentences with prefix x [1:i] should be rejected.", "sentence2": "we do not need to waste time to continue sampling.", "label": "reasoning"}
{"id": "test_1132", "sentence1": "However, a richer latent space does not guarantee a better probability estimation result.", "sentence2": "in this part, we delve deeper into whether the decoder signal matching mechanism helps improve probability estimation.", "label": "reasoning"}
{"id": "test_1133", "sentence1": "As it is shown in Table 5, our method is less likely to perturb some easily-modified semantics (e.g. numbers are edited to other \"forms\", but not different numbers), while search tends to generate semantically different tokens to achieve degradation.", "sentence2": "our agent can lead to more insightful and plausible analyses for neural machine translation than search by gradient.", "label": "reasoning"}
{"id": "test_1134", "sentence1": "However, there are still some prob\u0002lems with machine translation in the document\u0002level context (Laubli et al. , 2018).", "sentence2": "more recent work (Jean et al., 2017;Wang et al., 2017;Tiedemann and Scherrer, 2017;Maruf and Haffari, 2018;Bawden et al., 2018;Voita et al., 2019a;Junczys-Dowmunt, 2019) is focusing on the document-level machine translation.", "label": "reasoning"}
{"id": "test_1135", "sentence1": "The flat structure adopts a unified encoder that does not distinguish the context sentences and the source sentences.", "sentence2": "we introduce the segment embedding to identify these two types of inputs.", "label": "reasoning"}
{"id": "test_1136", "sentence1": "Intuitively, the less the direction of accumulated gradients is moved by the gradients of a new minibatch, the more certainty there is about the gradient direction.", "sentence2": "we propose that the magnitude of the angle fluctuation relates to the certainty of the model parameter optimization direction, and may therefore serve as a measure of optimization difficulty.", "label": "reasoning"}
{"id": "test_1137", "sentence1": "But after the direction of gradients has stabilized, accumulating more mini-batches seems useless as the gradient direction starts to fluctuate.", "sentence2": "we suggest to compute dynamic and efficient batch sizes by accumulating gradients of mini-batches, while evaluating the gradient direction change with each new mini-batch, and stop accumulating more mini-batches and perform an optimization step when the gradient direction fluctuates.", "label": "reasoning"}
{"id": "test_1138", "sentence1": "Encoders and decoders are (partially) shared between L 1 and L 2 .", "sentence2": "l 1 and l 2 must use the same vocabulary.", "label": "reasoning"}
{"id": "test_1139", "sentence1": "The LBUNMT model trained in the same language branch performed better than the single model because similar languages have a positive interaction during the training process as shown in Tables 2 and  3.", "sentence2": "the distilled information of LBUNMT is used to guide the MUNMT model during backtranslation.", "label": "reasoning"}
{"id": "test_1140", "sentence1": "As the number of languages increases, the number of translation directions increases quadratically.", "sentence2": "zero-shot translation accuracy is important to the MUNMT model.", "label": "reasoning"}
{"id": "test_1141", "sentence1": "Specifically, training with teacher forcing only exposes the model to gold history, while previous predictions during inference may be erroneous.", "sentence2": "the model trained with teacher forcing may over-rely on previously predicted words, which would exacerbate error propagation.", "label": "reasoning"}
{"id": "test_1142", "sentence1": "Indeed, viral claims often come back after a while in social media, and politicians are known to repeat the same claims over and over again.", "sentence2": "before spending hours fact-checking a claim manually, it is worth first making sure that nobody has done it already.", "label": "reasoning"}
{"id": "test_1143", "sentence1": "Previous work has argued that BERT by itself does not yield good sentence representation.", "sentence2": "approaches such as sentence-BERT (Reimers and Gurevych, 2019) have been proposed, which are specifically trained to produce good sentence-level representations.", "label": "reasoning"}
{"id": "test_1144", "sentence1": "In general, there is a 1:1 correspondence, but in some cases an Input claim is mapped to multiple VerClaim claims in the database, and in other cases, multiple Input claims are matched to the same VerClaim claim.", "sentence2": "the task in Section 3 reads as follows when instantiated to the PolitiFact dataset: given an Input claim, rank all 16,636 VerClaim claims, so that its matching VerClaim claims are ranked at the top.", "label": "reasoning"}
{"id": "test_1145", "sentence1": "We treat the task as a ranking problem.", "sentence2": "we use ranking evaluation measures, namely mean reciprocal rank (MRR), Mean Average Precision (MAP), and MAP truncated to rank k (MAP@k).", "label": "reasoning"}
{"id": "test_1146", "sentence1": "Initially, we tried to fine-tune BERT (Devlin et al., 2019), but this did not work well, probably because we did not have enough data to perform the fine-tuning.", "sentence2": "eventually we opted to use BERT (and variations thereof) as a sentence encoder, and to perform max-pooling on the penultimate layer to obtain a representation for an input piece of text.", "label": "reasoning"}
{"id": "test_1147", "sentence1": "For the purpose of comparison, we tried to filter out the text of the input tweet from the text of the article body before attempting the matching, but we still got unrealistically high results.", "sentence2": "ultimately we decided to abandon these experiments.", "label": "reasoning"}
{"id": "test_1148", "sentence1": "Subsequently, larger values of \u03bb reduced the BLEU scores, suggesting that excessive biased content word translation may be weak at translating function words", "sentence2": "Therefore, we set the hyper\u0002parameter \u03bb to 0.4 to control the loss of target content words in our experiments (Table 1).", "label": "reasoning"}
{"id": "test_1149", "sentence1": "Especially for the LEFT-ARC lt action, there is only about 0.43% in the total actions, turning out to be the most difficult action to learn given the relatively small training samples.", "sentence2": "as shown in Figure 5(a), the accuracy for LEFT-ARC lt is 0, which drops the overall performance heavily.", "label": "reasoning"}
{"id": "test_1150", "sentence1": "Shown as Figure 3, based on late-fusion multimodal learning framework (Cambria et al., 2017; Zadeh et al., 2017), we add independent output units for three unimodal representations: text, audio, and vision", "sentence2": "these unimodal representations not only participate in feature fusion but are used to generate their predictive outputs.", "label": "reasoning"}
{"id": "test_1151", "sentence1": "It is relatively obvious that new models learn more distinctive unimodal representations compare to original models.", "sentence2": "unimodal annotations can help the model to obtain more differentiated information and improve the complementarity between modalities.", "label": "reasoning"}
{"id": "test_1152", "sentence1": "Different from joint training, meta-transfer learning computes the firstorder optimization using the gradients from monolingual resources constrained to the code-switching validation set.", "sentence2": "instead of learning one model that is able to generalize to all tasks, we focus on judiciously extracting useful information from the monolingual resources.", "label": "reasoning"}
{"id": "test_1153", "sentence1": "In multimodal context, sarcasm is no longer a pure linguistic phenomenon, and due to the nature of social media short text, the opposite is more often manifested via cross-modality expressions.", "sentence2": "traditional text-based methods are insufficient to detect multimodal sarcasm.", "label": "reasoning"}
{"id": "test_1154", "sentence1": "For example, in Fig.1b, we can not reason about sarcasm intention simply from the short text 'Perfect flying weather in April' until we notice the downpour outside the airplane window in the attached image.", "sentence2": "compared to text-based methods, the essential research issue in multimodal sarcasm detection is the reasoning of cross-modality contrast in the associated situation.", "label": "reasoning"}
{"id": "test_1155", "sentence1": "Our work focus on the multimodal sarcasm detection using image and text modalities.", "sentence2": "we compare our model with the only two existing related models using the same modalities.", "label": "reasoning"}
{"id": "test_1156", "sentence1": "The MLP+CNN model simply takes the multimodal sarcasm detection as a general multimodal classification task via directly concatenating multimodal features for classification.", "sentence2": "it gets the worst performance.", "label": "reasoning"}
{"id": "test_1157", "sentence1": "CNN and BiLSTM just treat the sarcasm detection task as a text classification task, ignoring the contextual contrast information.", "sentence2": "their performances are worse than MIARN, which focuses on textual context to model the contrast information between individual words and phrases.", "label": "reasoning"}
{"id": "test_1158", "sentence1": "After removing the D-Net, the model only accepts the text and ANPs inputs.", "sentence2": "we further incorporate image information via directly concatenating image encoding in the final fusion layer (see row 2).", "label": "reasoning"}
{"id": "test_1159", "sentence1": "In Fig.4b, our model pays more attention to the textual phrase 'these lovely books' with stupid sign, strange sign, and bad sign ANPs which refer to the emoji in the attached image.", "sentence2": "it is easy for our model to detect the sarcasm intention that the books are NOT 'lovely' at all.", "label": "reasoning"}
{"id": "test_1160", "sentence1": "In multimodal sarcastic tweets, we expect our model to focus more on the opposite between different modality information.", "sentence2": "we reinforce discrepancy between image and text, and on the contrary, weaken their commonality.", "label": "reasoning"}
{"id": "test_1161", "sentence1": "We have already extracted multiple ANPs as the visual semantic information, which is beneficial to model multi-view associations between image and text according to different views of ANPs.", "sentence2": "we propose the ANP-aware cross-modality attention layer to align textual words and ANPs via utilizing each ANP to query each textual word and computing their pertinence.", "label": "reasoning"}
{"id": "test_1162", "sentence1": "However, the attention weights are difficult to learn, and the attention weights of SimulSpeech model are more difficult to learn than that of the simultaneous ASR and NMT models since SimulSpeech is much more challenging.", "sentence2": "we propose to distill the knowledge from the multiplication of the attention weights of the simultaneous ASR and NMT, as shown in Figure 2b and Figure 3.", "label": "reasoning"}
{"id": "test_1163", "sentence1": "We add attention-level knowledge distillation (Row 5 vs. Row 3) to the model and find that the accuracy can also be improved.", "sentence2": "we combine all the techniques together (Row 6, SimulSpeech) and obtain the best BLEU scores across different wait-k, which demonstrates the effectiveness of all techniques we proposed for the training of Simul-Speech.", "label": "reasoning"}
{"id": "test_1164", "sentence1": "As shown in Figure 5, simultaneous ASR model makes a mistake which further affects the accuracy of downstream simultaneous NMT model, while SimulSpeech is not suffered by this problem.", "sentence2": "simulspeech outperforms cascaded models.", "label": "reasoning"}
{"id": "test_1165", "sentence1": "Our proposed approach aims to exploit speech signal to word encoder learnt using an architecture similar to Speech2Vec as lower level dynamic word representations for the utterance classifier.", "sentence2": "our system never actually needs to know what word it is but only word segmentation information.", "label": "reasoning"}
{"id": "test_1166", "sentence1": "We found there was not a big difference in encoder output quality with higher dimensions.", "sentence2": "we use a 50 dimensional LSTM cell, thus the resulting encoder output becomes 100 (Bidirectional last hidden states) + 100 (cell state) = 200 dimensions.", "label": "reasoning"}
{"id": "test_1167", "sentence1": "One challenge is that SSWE and Speech2Vec generally needs large amount of transcribed data to learn high quality word embeddings.", "sentence2": "we first train SSWE on a general speech corpus (here, LibreSpeech (Libre)) before fine-tuning it on our classifier training data (results with * show this experiment).", "label": "reasoning"}
{"id": "test_1168", "sentence1": "We hypothesize that it can be due to the fact that our behavior code prediction data was split to minimize the speaker overlap.", "sentence2": "it becomes easier to overfit when we fine-tune it on some speaker-related properties instead of generalizing for behaviour code prediction task.", "label": "reasoning"}
{"id": "test_1169", "sentence1": "SeqGFMN has a stable training because it does not concurrently train a discriminator, which in principle could easily learn to distinguish between one-hot and soft one-hot representations.", "sentence2": "we can use soft one-hot representations that the generator outputs during training without using the Gumbel softmax or REINFORCE algorithm as needed in GANs for text.", "label": "reasoning"}
{"id": "test_1170", "sentence1": "A natural task that fits into this problem formulation is commonsense reasoning.", "sentence2": "it will be the main focus of the present paper.", "label": "reasoning"}
{"id": "test_1171", "sentence1": "For example, on HellaSwag, the target hypothesis mode is only 8% better than the hypothesis only mode (58.8% versus 50.8%), which confirms that on this setting our zero-shot method is mainly taking advantage of the bias in the hypotheses.", "sentence2": "we refrain from doing more zero-shot experiments on both datasets.", "label": "reasoning"}
{"id": "test_1172", "sentence1": "The time complexity of function f 3 is O(k 2 d) because there are k 3 dot product terms r x , h y , t w in total.", "sentence2": "the scoring function f 3 needs k 3 times of dot product to compute the score of a triple (h, r, t).", "label": "reasoning"}
{"id": "test_1173", "sentence1": "For the space complexity, the dimension of entity and relation embeddings is d, and there are no other parameters in our SEEK framework.", "sentence2": "the space complexity of SEEK is O(d).", "label": "reasoning"}
{"id": "test_1174", "sentence1": "And (5) another deep programming logic (DPL) method, GPT+DPL , is complicated, and the source code is not provided.", "sentence2": "we directly used the results from the original paper and did not evaluate it on BERT.", "label": "reasoning"}
{"id": "test_1175", "sentence1": "It can be seen that BERT-HA+STM outperformed the base model BERT-HA by a large margin in terms of all the metrics.", "sentence2": "the evidence extractor augmented with STM pro-vided more evidential information for the answer predictor, which may explain the improvements of BERT-HA+STM on the two datasets.", "label": "reasoning"}
{"id": "test_1176", "sentence1": "Otherwise, 0 would be assigned.", "sentence2": "we compute the adjacency matrix A qcomp for graph G qcomp and A qcell for G qcell .", "label": "reasoning"}
{"id": "test_1177", "sentence1": "Though a significant amount of parameters are introduced for incorporating phrase representation into the Transformer model, our approach (\"+Max+Attn+TA\") improved the performance of the Transformer Base model by +1.29 BLEU on the WMT 14 En-De news task, and the proposed Transformer model with phrase representation still performs competitively compared to the Transformer Big model with only about half the number of parameters and 1/3 of the training steps.", "sentence2": "we suggest our improvements are not only because of introducing parameters, but also due to the modeling and utilization of phrase representation.", "label": "reasoning"}
{"id": "test_1178", "sentence1": "The tweets collected with these hashtags may contain reported sexist acts towards both men and women.", "sentence2": "we collected around 205, 000 tweets, among which about 70, 000 contain the specific hashtags.", "label": "reasoning"}
{"id": "test_1179", "sentence1": "To this date there have been no proposals for a dynamic oracle for CCG parsing with F1 metric over CCG dependency structures and it is not even clear if there is a polynomial solution to this problem.", "sentence2": "this is not an option that we can use.", "label": "reasoning"}
{"id": "test_1180", "sentence1": "For example, texts containing some demographic identity-terms (e.g., \"gay\", \"black\") are more likely to be abusive in existing abusive language detection datasets.", "sentence2": "models trained with these datasets may consider sentences like \"She makes me happy to be gay\" as abusive simply because of the word \"gay.\"", "label": "reasoning"}
{"id": "test_1181", "sentence1": "Because of such a phenomenon, models trained with the dataset may capture the unintended biases and perform differently for texts containing various identity-terms.", "sentence2": "predictions of models may discriminate against some demographic minority groups.", "label": "reasoning"}
{"id": "test_1182", "sentence1": "However, \"perform similarly\" is indeed hard to define.", "sentence2": "we pay more attention to some criteria defined on demographic groups.", "label": "reasoning"}
{"id": "test_1183", "sentence1": "Attention flow can indicate a set of input tokens that are important for the final decision.", "sentence2": "we do not get sharp distinctions among them.", "label": "reasoning"}
{"id": "test_1184", "sentence1": "The lack of explicit claims by research may cause misinformation to potential users of the technology, who are not versed in its inner workings.", "sentence2": "clear distinction between these terms is critical.", "label": "reasoning"}
{"id": "test_1185", "sentence1": "On average, the Diversity LSTM model provides 53.52 % (relative) more attention to rationales than the vanilla LSTM across the 8 Text classification datasets.", "sentence2": "the attention weights in the Diversity LSTM are able to better indicate words that are important for making predictions.", "label": "reasoning"}
{"id": "test_1186", "sentence1": "While the system is still uncertain, the users often receive inappropriate (e.g., too hard or too easy) exercises.", "sentence2": "they get the impression that the system does not work properly, which is especially harmful during the inception phase of an application, as the community opinion largely defines its success.", "label": "reasoning"}
{"id": "test_1187", "sentence1": "Less motivated learners or learners who suffer from distractions, interruptions, or frustration, however, may show different paces in their learning speed or even deteriorate in their proficiency.", "sentence2": "we study four prototypical types of learner behavior: -Static learners (STAT) do not improve their skills over the course of our experiments.", "label": "reasoning"}
{"id": "test_1188", "sentence1": "In GEC, it is important to evaluate the model with multiple datasets .", "sentence2": "we used GEC evaluation data such as W&I-test, CoNLL-2014 (Ng et al., 2014), FCE-test and JFLEG (Napoles et al., 2017). ", "label": "reasoning"}
{"id": "test_1189", "sentence1": "Following Ye et al. (2018), we regard the paragraph start with \u201cour court identified that\u201d and end with \u201cthe above facts\u201d as the fact description. Burges et al. (2005) shows that training on ties makes little difference", "sentence2": "we could consider only defendant pairs (A, B) such that A plays a more important role than B and label it 1.", "label": "reasoning"}
{"id": "test_1190", "sentence1": "For humans, the most natural way to communicate is by natural language.", "sentence2": "future intelligent systems must be programmable in everyday language.", "label": "reasoning"}
{"id": "test_1191", "sentence1": "Utterances that were labeled as non-teaching in the first stage also run through the third stage, except for signature synthesis.", "sentence2": "we only construct scripts for this type of utterances.", "label": "reasoning"}
{"id": "test_1192", "sentence1": "Most encouragingly, the average rank of the correct element is near 1.", "sentence2": "our scoring mechanism succeeds in placing the right elements on top of the list.", "label": "reasoning"}
{"id": "test_1193", "sentence1": "In short chunks each word is important.", "sentence2": "unmapped words are strongly penalized.", "label": "reasoning"}
{"id": "test_1194", "sentence1": "However, the vast majority of current datasets do not include the preceding comments in a conversation and such context was not shown to the annotators who provided the gold toxicity labels.", "sentence2": "systems trained on these datasets ignore the conversational context.", "label": "reasoning"}
{"id": "test_1195", "sentence1": "To investigate whether adding context can benefit toxicity detection classifiers, we could not use CAT-SMALL, because its 250 comments are too few to effectively train a classifier.", "sentence2": "we proceeded with the development of a larger dataset.", "label": "reasoning"}
{"id": "test_1196", "sentence1": "TAPAS predicts a minimal program by selecting a subset of the table cells and a possible aggregation operation to be executed on top of them.", "sentence2": "tAPAS can learn operations from natural language, without the need to specify them in some formalism.", "label": "reasoning"}
{"id": "test_1197", "sentence1": "All of the end task datasets we experiment with only contain horizontal tables with a header row with column names.", "sentence2": "we only extract Wiki tables of this form using the <th> tag to identify headers.", "label": "reasoning"}
{"id": "test_1198", "sentence1": "A scalar answer s that also appears in the table (thus C 6= \u2205) is ambiguous, as in some cases the question implies aggregation (question 3 in Figure 3), while in other cases a table cell should be predicted (question 4 in Figure 3).", "sentence2": "in this case we dynamically let the model choose the supervision (cell selection or scalar answer) according to its current policy.", "label": "reasoning"}
{"id": "test_1199", "sentence1": "The Krippendorff\u2019s \u03b1 of the original 3,600 an\u0002notations of response appropriateness is 0.431, which is considered not good according to the interpretation of the number in Table 5", "sentence2": "we decided to remove the outliers to improve the inter-annotator agreement.", "label": "reasoning"}
{"id": "test_1200", "sentence1": "Moreover, multi-modal input helps the model to understand the intent and the sentiment of the speaker with more certainty.", "sentence2": "in the context of a dialogue, multi-modal data such as video (acoustic + visual) along with text helps to understand the sentiment and emotion of the speaker, and in turn, helps to detect sarcasm in the conversation.", "label": "reasoning"}
{"id": "test_1201", "sentence1": "Whereas, in the case of visual modality, it majorly contains the image of the speaker along with sentiment and emotion information.", "sentence2": "visual will not have a similar kind of problem as acoustic.", "label": "reasoning"}
{"id": "test_1202", "sentence1": "As we described in Section 2, accurately locating the previous statements about the claim is a very challenging problem.", "sentence2": "instead of directly searching for a possible previous statement, we search for related context, where the source are describing a statement related to the claim.", "label": "reasoning"}
{"id": "test_1203", "sentence1": "However, an article can include multiple different statements about the same claim with different opinions, and multiple articles can refer to the same statement about the claim from a common source.", "sentence2": "the majority vote by opinions in article level is not good enough, since it suffers from (1) opinions which are too coarse-grained and (2) overcounting the opinions from the same source, which is also known as collusion or dependency of sources problem in truth finding (Pochampally et al., 2014).", "label": "reasoning"}
{"id": "test_1204", "sentence1": "MPQA dataset is originally developed for identifying sources for the given opinion, and the opinion sometimes can be a noun phrase or an entity, while in our problem we are to extract sources for claims.", "sentence2": "we only leave the opinions which are sentences as the query claim, and perform 10-fold cross validation to evaluate the performance of our models and the baselines.", "label": "reasoning"}
{"id": "test_1205", "sentence1": "The 'quality' of extracted rationales will depend on their intended use.", "sentence2": "we propose an initial set of metrics to evaluate rationales that are meant to measure different varieties of 'interpretability'.", "label": "reasoning"}
{"id": "test_1206", "sentence1": "When deploying a CliniRC system to a new environment (e.g., a new set of clinical records, a new hospital, etc.), it is infeasible to create new QA pairs for training every time", "sentence2": "an ideal CliniRC system is able to generalize to unseen documents and questions after being fully trained.", "label": "reasoning"}
{"id": "test_1207", "sentence1": "We draw several observation from the evidence selection results: (1) AIR vs. unsupervised methods -AIR outperforms all the unsupervised baselines and previous works in both MultiRC (row 9-15 vs. row 23 in table 1) and QASC(rows 0-6 vs. row 18).", "sentence2": "highlighting strengths of AIR over the standard IR baselines.", "label": "reasoning"}
{"id": "test_1208", "sentence1": "We cannot use Webster et al.\u2019s GAP dataset directly, because their data is constrained that the \u201cgender\u201d of the two possible antecedents is \u201cthe same\u201d7 ; for us, we are specifically interested in how annotators make decisions even when additional gender infor\u0002mation is available.", "sentence2": "we construct a dataset called Maybe Ambiguous Pronoun (MAP) follow-ing Webster et al.'s  approach, but we do not restrict the two names to match gender.", "label": "reasoning"}
{"id": "test_1209", "sentence1": "As it is shown in Fig. 3, there might be multiple changes for each output words during the translation, and we only start to calculate the latency for this word once it agrees with the final results.", "sentence2": "it is necessary to locate the last change for each word.", "label": "reasoning"}
{"id": "test_1210", "sentence1": "Many speculate that these representations encode a continuous analogue of discrete linguis\u0002tic properties, e.g., part-of-speech tags, due to the networks\u2019 impressive performance on many NLP tasks (Belinkov et al., 2017).", "sentence2": "of this speculation, one common thread of research focuses on the construction of probes, i.e., supervised models that are trained to extract the linguistic properties directly Conneau et al., 2018;Peters et al., 2018b;Zhang and Bowman, 2018;Naik et al., 2018;Tenney et al., 2019).", "label": "reasoning"}
{"id": "test_1211", "sentence1": "Since TurkCorpus was adopted as the standard dataset for evaluating SS models, several system outputs on this data are already publicly available (Zhang and Lapata, 2017;Zhao et al., 2018;Martin et al., 2020).", "sentence2": "we can now assess the capabilities of these and other systems in scenarios with varying simplification expectations: lexical paraphrasing with TurkCorpus, sentence splitting with HSplit, and multiple transformations with ASSET.", "label": "reasoning"}
{"id": "test_1212", "sentence1": "The two images illustrate different NC concepts (i.e., HIGH JUMP and POLE VAULT) which are different configurations of the same elementary objects (i.e., PERSON, ROD, BLEACHERS).", "sentence2": "nC concepts require complex image understanding, integrating a fair amount of common sense knowledge.", "label": "reasoning"}
{"id": "test_1213", "sentence1": "For each label, these weights are given by its learned correlation with all the other labels.", "sentence2": "the prediction score of each label is affected by the prediction score of the other labels, based on the correlation between label pairs.", "label": "reasoning"}
{"id": "test_1214", "sentence1": "As a side-effect, we observe that older interpretability methods for static embeddings-while more mature than those available for their dynamic counterparts-are underutilized in studying newer contextualized representations.", "sentence2": "we introduce simple and fully general methods for converting from contextualized representations to static lookup-table embeddings which we apply to 5 popular pretrained models and 9 sets of pretrained weights.", "label": "reasoning"}
{"id": "test_1215", "sentence1": "Through a human study, we show that our manipulated attention-based explanations deceive people into thinking that predictions from a model biased against gender minorities do not rely on the gender.", "sentence2": "our results cast doubt on attention's reliability as a tool for auditing algorithms in the context of fairness and accountability.", "label": "reasoning"}
{"id": "test_1216", "sentence1": "Thus, the models (trained on unanonymized data) make use of gender indicators to obtain a higher task performance.", "sentence2": "we consider gender indicators as impermissible tokens for this task.", "label": "reasoning"}
{"id": "test_1217", "sentence1": "Since the feasible space is the same for both kinds of constraints, the performance difference is due to the randomness of the ILP solver picking different solutions with the same objective value.", "sentence2": "the entity and relation experiments in this section demonstrate that our approach can recover the designed constraints and provide a way of interpreting these constraints.", "label": "reasoning"}
{"id": "test_1218", "sentence1": "In contrast, our method for learning constraints uses general constraint features, and does not rely on domain knowledge.", "sentence2": "our method is suited to tasks where little is known about the underlying domain.", "label": "reasoning"}
{"id": "test_1219", "sentence1": "Such a z' is a negative example for the constraint learning task because z' has a lower objective value than z.", "sentence2": "it violates at least one of the constraints in Eq.", "label": "reasoning"}
{"id": "test_1220", "sentence1": "This feature looks at a pair of entities and focuses on the two relation labels between them, one in each direction.", "sentence2": "our running example will give us two positive examples with features (OrgBasedIn, NoRel) and (NoRel,OrgBasedIn).", "label": "reasoning"}
{"id": "test_1221", "sentence1": "Despite the high correlation, we also find that the estimated FAR scores may vary in range compared to the ground-truth FAR.", "sentence2": "we further use the estimations of different sentence regression approaches to train a linear regression model to fit the ground-truth FAR (denoted as AutoFAR).", "label": "reasoning"}
{"id": "test_1222", "sentence1": "On the other hand, the agreement between rhetorical relations tends to be lower and more ambiguous.", "sentence2": "we do not encode rhetorical relations explicitly in our model.", "label": "reasoning"}
{"id": "test_1223", "sentence1": "Equipped with the metrics for abstractiveness above, we want to further understand how abstractive the generated summaries are, and whether the amount of abstractiveness is a result of the training data or the model.", "sentence2": "we compute abstractiveness scores for both the reference summaries and summaries generated from a diverse set of models on two datasets.", "label": "reasoning"}
{"id": "test_1224", "sentence1": "Our analysis above shows that the number of unfaithful sentences increases significantly as more abstractive summaries are generated.", "sentence2": "the key challenge to faithfulness evaluation is to verify highly abstractive sentences against the source document, where surface similarity matching would fail.", "label": "reasoning"}
{"id": "test_1225", "sentence1": "Given the right corpus, we argue that a language model's probability can be modified into a Fluency Score.", "sentence2": "we adapt a language model into the Fluency Model.", "label": "reasoning"}
{"id": "test_1226", "sentence1": "Speakers distill their past experience of language use into what we call \"meaning\" here, and produce new attempts at using language based on this; this attempt is successful if the listener correctly deduces the speaker's communicative intent.", "sentence2": "standing meanings evolve over time as speakers can different experiences (e.g. McConnell\u0002Ginet, 1984), and a reflection of such change can be observed in their changing textual distribution (e.g. Herbelot et al., 2012; Hamilton et al., 2016).", "label": "reasoning"}
{"id": "test_1227", "sentence1": "Nonetheless, given the immense volume of scientific literature, the relative ease with which one can track citations using services such as Google Scholar (GS), and given the lack of other easily applicable and effec-tive metrics, citation analysis is an imperfect but useful window into research impact.", "sentence2": "citation metrics are often a factor when making decisions about funding research and hiring scientists.", "label": "reasoning"}
{"id": "test_1228", "sentence1": "Citation analysis can also be used to gauge the influence of outside fields on one's field and the influence of one's field on other fields.", "sentence2": "it can be used to determine the relationship of a field with the wider academic community.", "label": "reasoning"}
{"id": "test_1229", "sentence1": "However, scientometric researchers estimated that it included about 389 million documents in January 2018 (Gusenbauer, 2019)-making it the world's largest source of academic information.", "sentence2": "there is growing interest in the use of Google Scholar information to draw inferences about scholarly research in gen\u0002eral (Howland, 2010; Orduna-Malea et al. , 2014; Khabsa and Giles, 2014; Mingers and Leydesdorff, 2015; Mart\u00b4\u0131n-Mart\u00b4\u0131n et al., 2018) and on scholarly impact in particular (Priem and Hemminger, 2010; Yogatama et al., 2011; Bulaitis, 2017; Ravenscroft et al., 2017; Bos and Nitza, 2019; Ioannidis et al., 2019).", "label": "reasoning"}
{"id": "test_1230", "sentence1": "However, algorithms also provide systematic ways to reduce bias, and some see the mitigation of bias in algorithm decisions as a potential opportunity to move the needle positively (Kleinberg et al., 2018).", "sentence2": "we can apply frameworks of contemporaries in human behavior to machines (Rahwan et al., 2019), and perhaps benefit from a more scalable experimentation process.", "label": "reasoning"}
{"id": "test_1231", "sentence1": "The language of demographic groups systematically differs from each other for syntactic attributes.", "sentence2": "models trained on samples whose demographic composition (e.g., age and ethnicity) differs from the target perform significantly worse.", "label": "reasoning"}
{"id": "test_1232", "sentence1": "In contrast, the per-worker PEA scores for our annotations are shifted towards the right, indicating better agreement than the random baseline.", "sentence2": "we interpret our annotations as showing \"moderate agreement\" under the PEA metric.", "label": "reasoning"}
{"id": "test_1233", "sentence1": "In most cases, Equation 2 is not equal to the ordinary conditional distribution P (Y | T = t) since the latter is simply filtering to the sub-population and the former is changing the underlying data distribution via intervention.", "sentence2": "for observational studies that lack intervention, one needs an identification strategy in order to represent P (Y | do(T = t)) in terms of distributions of observed variables.", "label": "reasoning"}
{"id": "test_1234", "sentence1": "For instance, studies have shown that pre-processing decisions dramatically change topic models (Denny and Spirling, 2018;Schofield et al., 2017); embeddings are sensitive to hyperparameter tuning (Levy et al., 2015) and the construction of the training corpus (Antoniak and Mimno, 2018); and fine-tuned language model performance is sensitive to random restarts (Phang et al., 2018).", "sentence2": "reporting sensitivity analysis of the causal effects from these decisions seems crucial: how robust are the results to variations in modeling specifications?", "label": "reasoning"}
{"id": "test_1235", "sentence1": "However, as Gentzel et al. (2019) discuss, synthetic data has no \u201cunknown unknowns\u201d and many researcher de\u0002grees of freedom, which limits their effectiveness.", "sentence2": "we encourage researchers to evaluate with constructed observational studies or semi-synthetic datasets, although measuring latent confounders from text increases the difficulty of creating realistic datasets that can be used for empirical evaluation of causal methods.", "label": "reasoning"}
{"id": "test_1236", "sentence1": "Our key insight in this paper is that the context or relations through which specific information is propagated among different players in the legislative process (e.g., money donors and legislators), can be leveraged to further improve the performance.", "sentence2": "we build a shared relational architecture that models the text of a bill and its context into a graph; Our model captures the behavior of individual legislators, language of bills, and influence of contributions on the decision to identify demographic cleavages.", "label": "reasoning"}
{"id": "test_1237", "sentence1": "A close look reveals that the legislative process cannot be captured in a simple graph as there can be multiple relations between a pair of nodes (e.g., sponsorship and vote between legislators and bills), and the graph consists of several nodes types with different attributes and labels (e.g., bills with competitive labels).", "sentence2": "we model the process using a heterogeneous multi-relational graph, as follows: Node attributes: The nodes in our proposed legislative graph come with a rich set of features and information: (1) Bill nodes contain title, description, and full text of the house and senate state bills.", "label": "reasoning"}
{"id": "test_1238", "sentence1": "In NLP, dropped pronouns can cause loss of important information, such as the subject or object of the central predicate in a sentence, introducing ambiguity to applications such as machine translation (Nakaiwa and Shirai, 1996; Wang et al., 2016; Takeno et al., 2016), question answering (Choi et al., 2018; Reddy et al., 2019; Sun et al., 2019; Chen and Choi, 2016) and dialogue understanding (Chen et al., 2017; Rolih, 2018).", "sentence2": "zero pronouns have recently received much research attention (Liu et al., 2017; Yin et al., 2018a,b)", "label": "reasoning"}
{"id": "test_1239", "sentence1": "Compared to semantic frames (Fillmore and Baker, 2001), the meanings projected by pragmatic frames are richer, and thus cannot be easily formalized using only categorical labels.", "sentence2": "as illustrated in Figure 1, our formalism combines hierarchical categories of biased implications such as intent and offensiveness with implicatures described in free-form text such as groups referenced and implied statements.", "label": "reasoning"}
{"id": "test_1240", "sentence1": "In the Post round, users are given the same data, but they are also equipped with explanations of the model predictions for the original inputs.", "sentence2": "any improvement in performance is attributable to the addition of explanations.", "label": "reasoning"}
{"id": "test_1241", "sentence1": "As explained, given end-task supervision only, modules may not act as intended, since their parameters are only trained for minimizing the end-task loss.", "sentence2": "a straightforward way to improve interpretability is to train modules with additional atomic-task supervision.", "label": "reasoning"}
{"id": "test_1242", "sentence1": "Note that since a single proposed bounding box can align with multiple annotated bounding boxes, it is possible for the numerator to exceed the denominator.", "sentence2": "these two choices for a common numerator have issues, and we avoid these issues by defining the numerators of precision and recall separately.", "label": "reasoning"}
{"id": "test_1243", "sentence1": "Specially, DST-SC is designed with a slot connecting mechanism to establish the connection between the target slot and its source slot explicitly.", "sentence2": "it can take advantage of the source slot value directly instead of reasoning from preceding turns.", "label": "reasoning"}
{"id": "test_1244", "sentence1": "As claimed in Section 1, connecting the target slot with its source slot helps to decrease the reasoning difficulty.", "sentence2": "we enhance the copyaugmented encoder-decoder model with a slot connecting mechanism to model slot correlations directly.", "label": "reasoning"}
{"id": "test_1245", "sentence1": "Their applications are usually limited in a single domain.", "sentence2": "several open vocabulary approaches in generative fashion (Xu and Hu, 2018;Wu et al., 2019;Ren et al., 2019) are proposed to handle unlimited slot values in more complicated dialogues.", "label": "reasoning"}
{"id": "test_1246", "sentence1": "A wide range of NLP tasks have greatly benefited from the pre-trained BERT model.", "sentence2": "we also finetune the pre-trained BERT-Large model on our task through sequence pair classification schema.", "label": "reasoning"}
{"id": "test_1247", "sentence1": "In Example 4, BERT-ft prefers A but the answer is C. The reason why BERT-ft chooses A may be that \"enjoy life\" happens in the context, but summarizing the next sentence is necessary to achieve the correct answer.", "sentence2": "it is necessary to improve the ability of BERT to represent meaning at the sentence level beyond representing individual words in context.", "label": "reasoning"}
{"id": "test_1248", "sentence1": "A potential artifact type for our task is whether we could detect distractors without passages.", "sentence2": "we finetune BERT-Large as a binary classifier, the input of which is just distractors and other correct candidates.", "label": "reasoning"}
{"id": "test_1249", "sentence1": "With |B| = 5 blanks and |C| = 7 candidates, the size of answer space, |A|, is number of permutations |B| objects taken |C| at a time, i.e., P(7, 5) = 2520.", "sentence2": "the probability of answering all blanks correctly is 1/2520 = 0.03% What are the chances of getting answers partially correct?", "label": "reasoning"}
{"id": "test_1250", "sentence1": "While fine-tuning for span-based QA, every utterance as well as the question are separated encoded and multi-head attentions and additional transformers are built on the token and utterance embeddings respectively to provide a more comprehensive view of the dialogue to the QA model.", "sentence2": "our model achieves a new state-of-the-art result on a span-based QA task where the evidence documents are multiparty dialogue.", "label": "reasoning"}
{"id": "test_1251", "sentence1": "One important reason behind this is that, due to the vague definition of commonsense knowledge, we are not clear about what the essential knowledge types are and thus we are unclear about how to represent, acquire, and use them.", "sentence2": "we can only treat commonsense knowledge as a black box and try to learn it from limited training data.", "label": "reasoning"}
{"id": "test_1252", "sentence1": "If at least four annotators think the reason is plausible, we will accept that reason.", "sentence2": "we identify 992 valid reasons.", "label": "reasoning"}
{"id": "test_1253", "sentence1": "Note that each reason may contain inference over multiple knowledge types.", "sentence2": "for each reason, we invite five different annotators to provide annotations.", "label": "reasoning"}
{"id": "test_1254", "sentence1": "Each annotators are provided with detailed instruction of the job, descriptions of each candidate category, and examples for the category.", "sentence2": "we collect 4,960 annotations.", "label": "reasoning"}
{"id": "test_1255", "sentence1": "Besides the above analysis, we are also interested in how different models perform on questions that require complex reasoning types.", "sentence2": "we divide all WSC questions based on how many knowledge types are required to solve these questions and show the result in Table 5.", "label": "reasoning"}
{"id": "test_1256", "sentence1": "One possible reason is that even though the designers of WSC are trying to avoid any statistical correlation between the answer and the trigger word, such statistical correlation still exists.", "sentence2": "pre-trained language representation models can learn such correlation from large-scale training corpus and thus can answer WSC questions without fully understanding the reasons behind.", "label": "reasoning"}
{"id": "test_1257", "sentence1": "Research in Cyber Argumentation has shown that incorporating both stance polarity and intensity information into online discussions improves the analysis of discussions and the various phenomena that arise during a debate, including opinion polarization (Sirrianni et al., 2018), and identifying outlier opinions (Arvapally et al., 2017), compared to using stance polarity alone.", "sentence2": "automatically identifying both the post's stance polarity and intensity, allows these powerful analytical models to be applied to unstructured debate data from platforms such as Twitter, Facebook, Wikipedia, comment threads, and online forums.", "label": "reasoning"}
{"id": "test_1258", "sentence1": "The difference between strong opposition and weak opposition is often expressed through subtle word choices and conversational behaviors.", "sentence2": "to accurately predict agreement intensity, a learned model must understand the nuances between word choices in the context of the discussion.", "label": "reasoning"}
{"id": "test_1259", "sentence1": "The authors were instructed on how to annotate their posts, but the annotations themselves were left to the post's author's discretion.", "sentence2": "including author information into our models would likely improve the stance polarity and intensity prediction results.", "label": "reasoning"}
{"id": "test_1260", "sentence1": "Our full model outperforms state-ofthe-art unsupervised fine-tuning approaches and partially supervised approaches using crosslingual resources in 8/11 tasks.", "sentence2": "our results provide a strong lower bound performance on what future semi-supervised or supervised approaches are expected to produce.", "label": "reasoning"}
{"id": "test_1261", "sentence1": "The maximization is guaranteed to converge to the unique maximum likelihood estimator in finite steps under the assumption that in every possible partition of the items into two nonempty subsets, some subject in the second set beats some subject in the first set at least once (Hunter, 2004).", "sentence2": "a pairwise comparison experiment is restricted in two ways: (i) The matrix formed by the comparisons must construct a strongly connected graph; (ii) The comparisons between the partitions cannot all be won by subjects from the same group, i.e., no item has losses or wins exclusively.", "label": "reasoning"}
{"id": "test_1262", "sentence1": "However, this strategy suffers from the major drawback that for some step sizes, the resulting graph has multiple unconnected components, thus violating the restriction that the comparison matrix must form a strongly connected graph.", "sentence2": "complex combinations of different step sizes are needed, resulting in needlessly complicated experimental setups.", "label": "reasoning"}
{"id": "test_1263", "sentence1": "By example, going from x = 1, k = 16 to x = 1, k = 4 ends up at the same number of comparisons as x = 2, k = 8, but has a slightly higher ranking accuracy.", "sentence2": "it is more economical to increase the sampling rate until the required accuracy is met than collecting multiple judgments.", "label": "reasoning"}
{"id": "test_1264", "sentence1": "However, the specific choice of k depends on scale and domain of the data as well as trustworthiness of comparisons.", "sentence2": "we refrain from making a general suggestion for the choice of k. Thus, if the model is to be adapted to drastically different domains or item counts, exploratory studies are advised to estimate the quality tradeoff for a specific use case.", "label": "reasoning"}
{"id": "test_1265", "sentence1": "While this could hint at a data bias, with crowd workers just voting for longer texts in the comparison but not actually reading all of it, the effect is much less pronounced when only measuring the correlation in texts longer than 100 words (n = 869).", "sentence2": "much of the pronounced effect can be explained by short texts receiving justified low scores rather than longer texts being voted higher regardless of content.", "label": "reasoning"}
{"id": "test_1266", "sentence1": "The first step of the PCA accounts for 73% of the data variance, and is equally influenced by all three quality dimensions.", "sentence2": "evidence is given towards the hypothesis.", "label": "reasoning"}
{"id": "test_1267", "sentence1": "To account for this, the score distributions are equally shifted into the positive domain.", "sentence2": "a standardized scalar value for overall argument quality can be calculated.", "label": "reasoning"}
{"id": "test_1268", "sentence1": "While this paradigm works to a certain extent, it usually retrieves knowledge facts only based on the entity word itself, without considering the specific dialogue context.", "sentence2": "the introduction of the context-irrelevant knowledge facts can impact the quality of generations.", "label": "reasoning"}
{"id": "test_1269", "sentence1": "To summarize, Felicitous Fact mechanism can alleviate the first two issues, and the next two techniques solve the last issue.", "sentence2": "our approach can improve the utilization rate of knowledge graphs, as well as can promote the diversity and informativeness of the generated responses.", "label": "reasoning"}
{"id": "test_1270", "sentence1": "In the field of natural language processing (NLP) which widely employs DNNs, practical systems such as spam filtering (Stringhini et al., 2010) and malware detection (Kolter and Maloof, 2006) have been broadly used, but at the same time the concerns about their security are growing.", "sentence2": "the research on textual adversarial attacks becomes increasingly important.", "label": "reasoning"}
{"id": "test_1271", "sentence1": "Instead, the successful uses of neural networks in computational linguistics have replaced specific pieces of computational-linguistic models with new neural network architectures which bring together continuous vector spaces with structured representations in ways which are novel for both machine learning and computational linguistics.", "sentence2": "the great progress which we have made through the application of neural networks to natural language processing should not be viewed as a conquest, but as a compromise.", "label": "reasoning"}
{"id": "test_1272", "sentence1": "With parameters shared across entities and sensitive to these properties and relations, learned rules are parameterised in terms of these structures.", "sentence2": "transformer is a deep learning architecture with the kind of generalisation ability required to exhibit systematicity, as in (Fodor and Pylyshyn, 1988).", "label": "reasoning"}
{"id": "test_1273", "sentence1": "Since most of the common neighbors would be popular entities, they will be neighbors of many other entities.", "sentence2": "it is still challenging to align such entities.", "label": "reasoning"}
{"id": "test_1274", "sentence1": "However, not all one-hop neighbors contribute positively to characterizing the target entity.", "sentence2": "considering all of them without careful selection can introduce noise and degrade the performance.", "label": "reasoning"}
{"id": "test_1275", "sentence1": "On another scenario, recent analysis also reveals that state-of-the-art sequential neural language models still fail to learn certain long-range syntactic dependencies (Kuncoro et al., 2018).", "sentence2": "it is an interesting problem to explore the relation between language models and syntax and investigate whether syntax can be integrated to enhance neural language models.", "label": "reasoning"}
{"id": "test_1276", "sentence1": "Their differences are such that they can not be easily collapsed into a single meta-tag.", "sentence2": "we do not penalize the model for producing any variation of equally valid analyses given the surface form, and for each model we adjust the evaluation for syncretism in a post-processing step.", "label": "reasoning"}
{"id": "test_1277", "sentence1": "Chinese is an ideographic language and lacks word delimiters between words in written sentences.", "sentence2": "chinese word segmentation (cWS) is often regarded as a prerequisite to downstream tasks in chinese natural language processing.", "label": "reasoning"}
{"id": "test_1278", "sentence1": "Source domain data and target domain data generally have different distributions.", "sentence2": "models built on source domain data tend to degrade performance when they are applied to target domain data.", "label": "reasoning"}
{"id": "test_1279", "sentence1": "Chinese word segmentation is typically formalized as a sequence tagging problem.", "sentence2": "traditional machine learning models such as Hidden Markov Models (HMMs) and Conditional Random Fields (CRFs) are widely employed for CWS in the early stage (Wong and Chan, 1996;Gao et al., 2005;Zhao et al., 2010).", "label": "reasoning"}
{"id": "test_1280", "sentence1": "Furthermore, the system outputs pseudo-tags, and the mapping from pseudo-tags to paradigm slots is unknown.", "sentence2": "we propose to use best-match accuracy (BMAcc), the best accuracy among all mappings from pseudo-tags to paradigm slots, for evaluation.", "label": "reasoning"}
{"id": "test_1281", "sentence1": "Hiring crowd-sourcing workers to perform these annotations is very costly.", "sentence2": "we propose automated data augmentation methods to expand existing well-annotated dialog datasets, and thereby train better dialog systems.", "label": "reasoning"}
{"id": "test_1282", "sentence1": "In other words, a paraphrased dialog utterance needs to serve the same function as the original utterance under the same dialog context.", "sentence2": "we propose to construct dialog paraphrases that consider dialog context in order to improve dialog generation quality.", "label": "reasoning"}
{"id": "test_1283", "sentence1": "These patterns can be seen as the \"template\" to produce the questions.", "sentence2": "we can use the patterns as the prior to regularize the QG model and obtain better results accordingly.", "label": "reasoning"}
{"id": "test_1284", "sentence1": "These methods often need a lot of labeled data for training, but the data is expensive to obtain.", "sentence2": "we are inspired to apply our generated results to enrich the training set for the task of MRC-QA.", "label": "reasoning"}
{"id": "test_1285", "sentence1": "Slightly modified queries such as iPhone X charger and case for iPhone X refer to different products.", "sentence2": "it is hard for distributed representations to capture the nuances.", "label": "reasoning"}
{"id": "test_1286", "sentence1": "BLEU scores do not indicate whether or not a generated queries is a \"realistic\" modification of the original query.", "sentence2": "we also had 2500 generated pairs annotated by human experts who were specifically trained to decide if a query-item pair is matched or not", "label": "reasoning"}
{"id": "test_1287", "sentence1": "To account for these differences between query strings and item titles, we separately train word embeddings using word2vec (Mikolov et al., 2013) on anonymized query logs and item titles.", "sentence2": "the same word can have two embeddings, one for the query and one for the title.", "label": "reasoning"}
{"id": "test_1288", "sentence1": "Then, the evaluation of model uncertainty is conducted on D U to mirror the confidence over the current curriculum.", "sentence2": "our approach reserves the efficiency in CL, in the meanwhile, guiding the duration of each curriculum in a self-adaptive fashion.", "label": "reasoning"}
{"id": "test_1289", "sentence1": "This phenomenon reveals that the most \"simple\" and \"complex\" sentences quantified by different measures are relatively similar, and the main diversity lies in those sentences of which the difficulties hardly to be distinguished.", "sentence2": "we argue that the improvements of the proposed method may mainly contribute by the differences in these two steps.", "label": "reasoning"}
{"id": "test_1290", "sentence1": "We noticed that the Spanish tokenizer sometimes merges multi-word expressions into a single token joined with underscores for contiguous words.", "sentence2": "some tokens cannot be aligned with the corresponding entity annotations.", "label": "reasoning"}
{"id": "test_1291", "sentence1": "We restrict our analysis to Spanish since the data is labeled with both de-identification and concept information (see Section 4.1).", "sentence2": "we can also investigate the difference between gold and predicted de-identification labels.", "label": "reasoning"}
{"id": "test_1292", "sentence1": "Semantic matching operations between two mentions (and their contexts) are performed only at the output layer and are relatively superficial.", "sentence2": "it is hard for their models to capture all the lexical, semantic and syntactic cues in the context.", "label": "reasoning"}
{"id": "test_1293", "sentence1": "Moreover, there can be multiple dialogue acts mentioned in a single dialogue turn, which requires the model to attend to different acts for different sub-sequences.", "sentence2": "a global vector is unable to capture the inter-relationships among acts, nor is it flexible for response generation especially when more than one act is mentioned.", "label": "reasoning"}
{"id": "test_1294", "sentence1": "Being a span enumeration type model, DYGIE++ only works on paragraph level texts and extracts relations between mentions in the same sentence only.", "sentence2": "we subdivide SCIREX documents into sections and formulate each section as a single training example.", "label": "reasoning"}
{"id": "test_1295", "sentence1": "The target of our framework is to conduct the formats controlled text generation.", "sentence2": "the indicating symbols for format and rhyme as well as the sentence integrity are designed based on the target output sequence.", "label": "reasoning"}
{"id": "test_1296", "sentence1": "But the Rhyme accuracy and the sentence integrity will drop simultaneously.", "sentence2": "in the experiments we let k = 32 to obtain a trade-off between the diversity and the general quality.", "label": "reasoning"}
{"id": "test_1297", "sentence1": "Since the gradients from optimizing the functional task are sent all the way into the base captioning model, this causes catastrophic forgetting of the core knowledge of language, leading to language drift.", "sentence2": "we use a language regularizer term in the form of Kullback-Leibler divergence between pre-trained and fine-tuned language modeling distributions (Havrylov and Titov, 2017).", "label": "reasoning"}
{"id": "test_1298", "sentence1": "We can observe that the larger the validation loss, the lower the BLEU score.", "sentence2": "the validation loss can be a good performance proxy.", "label": "reasoning"}
{"id": "test_1299", "sentence1": "Page's argument is that the original student is not going to be much worse off with a com-puter than with an (average) human reader, because originality is a subjective construct.", "sentence2": "once research uncovers objective and measurable aspects of \"original\" writing, relevant features can be added into an AWE system; finding such aspects, as well as measuring them, is still work in progress.", "label": "reasoning"}
{"id": "test_1300", "sentence1": "In particular, a story entails a highly structured network of relations (timelines, causality, etc.).", "sentence2": "stories do exercise abilities beyond simple factoid extraction.", "label": "reasoning"}
{"id": "test_1301", "sentence1": "The ones canonicalized by the guidelines and by annotators following them may not always be the most useful.", "sentence2": "it may prove beneficial to appeal directly to human intuition about what understanding entails.", "label": "reasoning"}
{"id": "test_1302", "sentence1": "We expect that introducing such importance information for the words in the deep learning models might lead to improved performance for RE.", "sentence2": "in this work, we propose to obtain an importance score for each word in the sentences from the dependency trees (called the syntax-based importance scores).", "label": "reasoning"}
{"id": "test_1303", "sentence1": "This dataset does not provide training, development, or test splits due to the small number of samples.", "sentence2": "we run 5-fold cross validations and report the average scores.", "label": "reasoning"}
{"id": "test_1304", "sentence1": "First, we notice that the class name generation goal is similar to the hypernymy detection task which aims to find a general hypernym (e.g., \"mammal\") for a given specific hyponym (e.g., \"panda\").", "sentence2": "we leverage the six Hearst patterns (Hearst, 1992), widely used for hypernymy detection, to construct the class-probing query.", "label": "reasoning"}
{"id": "test_1305", "sentence1": "Most state-of-the-art diacritic restoration models are built on character level information which helps generalize the model to unseen data, but presumably lose useful information at the word level.", "sentence2": "to compensate for this loss, we investigate the use of multi-task learning to jointly optimize diacritic restoration with related NLP problems namely word segmentation, part-of-speech tagging, and syntactic diacritization.", "label": "reasoning"}
{"id": "test_1306", "sentence1": "Despite leveraging tasks focused on syntax (SYN/POS) or morpheme boundaries (SEG), the improvements extend to lexical diacritics as well.", "sentence2": "the proposed joint diacritic restoration model is also helpful in settings beyond word final syntactic related diacritics.", "label": "reasoning"}
{"id": "test_1307", "sentence1": "In an average development document with 201 candidates per mention, the number of pairwise queries needed to fully label a document is 15, 050, while the maximum number of discrete queries is only 201 (i.e., asking for the antecedent of every mention).", "sentence2": "the average document can be fully annotated via discrete annotation in only 2.6% of the time it takes to fully label it with pairwise annotation, suggesting that our framework is also a viable exhaustive annotation scheme.", "label": "reasoning"}
{"id": "test_1308", "sentence1": "However, structured attributes in product catalogs are often sparse, leading to unsatisfactory search results and various kinds of defects.", "sentence2": "it is invaluable if such structured information can be extracted from product profiles such as product titles and descriptions.", "label": "reasoning"}
{"id": "test_1309", "sentence1": "Our main idea is that by encouraging TXtract to predict the product categories using only the product profile, the model will learn token embeddings that are discriminative of the product categories.", "sentence2": "we introduce an inductive bias for more effective category-specific attribute value extraction.", "label": "reasoning"}
{"id": "test_1310", "sentence1": "The insight behind our loss function is that a product assigned under\u00c3\u201e\u00e2\u20ac\u00b0 could also be assigned under any of the ancestors of\u00c3\u201e\u00e2\u20ac\u00b0.", "sentence2": "we consider hierarchical multi-label classification and encourage TXtract to assign a product to all nodes in the path from\u00c3\u201e\u00e2\u20ac\u00b0 to the root, denoted by (\u00c3\u201e\u00e2\u20ac\u00b0 K ,\u00c3\u201e\u00e2\u20ac\u00b0 K\u00c3\u00a2\u00cb\u2020\u00e2\u20ac\u21221 , .", "label": "reasoning"}
{"id": "test_1311", "sentence1": "It might be hard to say that the superior performance of TCattn is due to the neural architecture and attention scores rather than the richer training resources.", "sentence2": "a comparison between TCattn and a model that uses both student essays and the source article is needed.", "label": "reasoning"}
{"id": "test_1312", "sentence1": "As creation is expensive, most annotated clinical datasets are small, such as for our task.", "sentence2": "we look to alternative data sources for pre-training our model.", "label": "reasoning"}
{"id": "test_1313", "sentence1": "However, training on synonyms will allow for a greater variety of terms to be seen by our model than otherwise possible.", "sentence2": "using all synonyms taken from the annotated subset of the UMLS, we pre-train our linker before training on the annotated clinical notes.", "label": "reasoning"}
{"id": "test_1314", "sentence1": "Because of this, the common practice is to test new methods on a small number of languages or domains, often semi-arbitrarily chosen based on previous work or the experimenters' intuition.", "sentence2": "this practice impedes the NLP community from gaining a comprehensive understanding of newly-proposed models.", "label": "reasoning"}
{"id": "test_1315", "sentence1": "Another limitation is that generated data is of limited use for training models, since it contains simple regularities that supervised classifiers may learn to exploit.", "sentence2": "we create IMP-PRES solely for the purpose of evaluating NLI models trained on standard datasets like MultiNLI.", "label": "reasoning"}
{"id": "test_1316", "sentence1": "Thus, we anticipate two possible rational behaviors for a MultiNLI-trained model tested on an implicature: (a) be pragmatic, and compute the implicature, concluding that the premise and hypothesis are in an 'entailment' relation, (b) be logical, i.e., consider only the literal content, and not compute the implicature, concluding they are in a 'neutral' relation.", "sentence2": "we measure both possible conclusions, by tagging sentence pairs for scalar implicature with two sets of NLI labels to reflect the behavior expected under \"logical\" and \"pragmatic\" modes of inference, as shown in Table 2.", "label": "reasoning"}
{"id": "test_1317", "sentence1": "Overall, more than 20% of the treebanks in the UD 2.2 collection have flat structures in more than 20% of their training-set sentences.", "sentence2": "a parsing approach taking into account the special status of headless structural representations can potentially benefit models for a large number of languages and treebanks.", "label": "reasoning"}
{"id": "test_1318", "sentence1": "CRF models the conditional probability of the whole label sequence given the whole input sequence.", "sentence2": "instead of using the label distribution over individual token, we could use the probability distribution for the whole label sequence, to compute KL divergence.", "label": "reasoning"}
{"id": "test_1319", "sentence1": "But as explained in Sec.1, the adversarial loss of conventional VAT cannot be calculated on top of CRF.", "sentence2": "vAT in the second set of Table.2 only applies CRF for label loss.", "label": "reasoning"}
{"id": "test_1320", "sentence1": "And the meaning of each character changes dramatically when the context changes.", "sentence2": "a CSC system needs to recognize the semantics and aggregate the surrounding information for necessary modifications.", "label": "reasoning"}
{"id": "test_1321", "sentence1": "By contrast, the similar characters are semantically distinct in CSC.", "sentence2": "we deeply investigate the effect of our SpellGCN and propose several essential techniques.", "label": "reasoning"}
{"id": "test_1322", "sentence1": "Since the pronunciation similarity is more fine-grained compared with the shape similarity category, we combine the pronunciation similarities into one graph.", "sentence2": "we construct two graphs corresponding to pronunciation and shape similarities.", "label": "reasoning"}
{"id": "test_1323", "sentence1": "However, more than half of the databases in Spider contain 5 tables or less.", "sentence2": "we also report the coverage of attributes only considering the databases which have more than 5 tables, where Spider only covers 49.6% of attributes.", "label": "reasoning"}
{"id": "test_1324", "sentence1": "Table 2 shows that our corpus contains a much higher lexical complexity of the questions than Spider (0.67 instead of 0.52).", "sentence2": "our approach seems to avoid trivial or monotonous questions, which also matches with our impression from manual inspection.", "label": "reasoning"}
{"id": "test_1325", "sentence1": "Roy and Roth (2017) shown significantly lowered performance if highly similar MWPs are removed.", "sentence2": "dataset diversity is more critical than the dataset size for accurately judging the true capability of an MWP solver.", "label": "reasoning"}
{"id": "test_1326", "sentence1": "Since MWPs are usually clearly specified (with a sure answer), there is no ambiguous interpretation once the answer is given.", "sentence2": "as opposed to other corpora in which annotations (mostly linguistic attributes) are mainly based on human subjective judgment, the MWP answer/equation annotation is more objective and must be consistent.", "label": "reasoning"}
{"id": "test_1327", "sentence1": "Therefore, as opposed to other corpora in which annotations (mostly linguistic attributes) are mainly based on human subjective judgment, the MWP answer/equation annotation is more objective and must be consistent.", "sentence2": "human carefulness, instead of human agreement, is a more critical issue in this task.", "label": "reasoning"}
{"id": "test_1328", "sentence1": "In grades 5 and 6, improved math skills enable students to solve difficult MWPs that require more aggregative operations and additional domain knowledge.", "sentence2": "the grade level is a useful indicator of difficulty and can be employed to evaluate the capability of MWP solving systems.", "label": "reasoning"}
{"id": "test_1329", "sentence1": "The \"words\" in abstract syntax can be seen as word senses, which the concrete syntax can realize by different word forms.", "sentence2": "the abstract function Love in Figure 7 corresponds to words in different languages used for expressing a certain sense of the English word love.", "label": "reasoning"}
{"id": "test_1330", "sentence1": "Segment analysis is also used when forming compound words in languages like Finnish, German, and Swedish.", "sentence2": "english summer time translates compositionally to Swedish sommar+tid, which is rendered as sommartid.", "label": "reasoning"}
{"id": "test_1331", "sentence1": "Because of this information loss, one cannot expect that such details will be correctly deduced or guessed, especially without a wider context.", "sentence2": "the default linearization by the GF generator (and the guessed linearization by the JAMR generator) of the AMR concept person in Figure 20 is in the singular form.", "label": "reasoning"}
{"id": "test_1332", "sentence1": "Recall that our method first collects the top M candidate chains, ordered by retrieval score (Section 3.2).", "sentence2": "a simple baseline is to use that retrieval score itself as a measure of chain validity.", "label": "reasoning"}
{"id": "test_1333", "sentence1": "For output structure generalization, we formatted the answers as JSON to enable more complex zero-shot relation extraction tasks.", "sentence2": "the models output answers as both text and JSON, in a seq-to-seq fashion, depending on the question type.", "label": "reasoning"}
{"id": "test_1334", "sentence1": "\"Chris\", supposedly tagged with \"Person\" in this example sentence, is tagged as other labels in most cases.", "sentence2": "in the predicting process, it is difficult to label \"Chris\" correctly.", "label": "reasoning"}
{"id": "test_1335", "sentence1": "The advantage of stance over TS is indirect stances.", "sentence2": "we also investigate how well various methods perform on indirect stance.", "label": "reasoning"}
{"id": "test_1336", "sentence1": "Custom methods for other targets also behave in a similar manner (c.f Figure 4), with certain targets like Putin outperforming the best OTS method, STB in this case, with fewer than 195 labeled tweets.", "sentence2": "instead of having different training sizes for different targets, we use the same amount and find that the LR custom methods outperform OTS methods for all targets except Macron.", "label": "reasoning"}
{"id": "test_1337", "sentence1": "Although researchers have designed a lot of meaning representations, recent work focuses on only a few of them.", "sentence2": "the impact of meaning representation on semantic parsing is less understood.", "label": "reasoning"}
{"id": "test_1338", "sentence1": "A semantically equivalent program may have many syntactically different forms.", "sentence2": "if the training and testing data have a difference in their syntactic distributions of logic forms, a naive maximum likelihood estimation can suffer from this difference because it fails to capture the semantic equivalence (Bunel et al., 2018).", "label": "reasoning"}
{"id": "test_1339", "sentence1": "We regard Prolog, Lambda Calculus, and FunQL as domainspecific MRs, since the predicates defined in them are specific for a given domain.", "sentence2": "the execution engines of domain-specific MRs need to be significantly customized for different domains, requiring plenty of manual efforts.", "label": "reasoning"}
{"id": "test_1340", "sentence1": "With these resources, we crossvalidate the correctness of annotations and execution engines by comparing the execution results of logical forms.", "sentence2": "we found nearly 30 Prolog logical forms with annotation mistakes and two bugs in the execution engines of Prolog and FunQL.", "label": "reasoning"}
{"id": "test_1341", "sentence1": "We use two strategies for this purpose: (1) we explicitly introduce distinct divergence categories for unrelated sentences and sentences that overlap in meaning; and (2) we ask for annotation rationales (Zaidan et al., 2007) by requiring annotators to highlight tokens indicative of meaning differences in each sentence-pair.", "sentence2": "our approach strikes a balance between coarsely annotating sentences with binary distinctions that are fully based on annotators' intuitions (Vyas et al., 2018), and exhaustively annotating all spans of a sentence-pair with fine-grained labels of translation processes (Zhai et al., 2018).", "label": "reasoning"}
{"id": "test_1342", "sentence1": "Without this, the model can learn the goal task (such as translation) with reasonable accuracy, but the learned semantic embeddings are of poor quality until batch sizes approximately reach 25,000 tokens.", "sentence2": "we use a maximum batch size of 50,000 tokens in our ENGLISHTRANS, BILIN-GUALTRANS, and BGT W/O PRIOR, experiments and 25,000 tokens in our BGT W/O LANGVARS and BGT experiments.", "label": "reasoning"}
{"id": "test_1343", "sentence1": "We hypothesize that these datasets contain many examples where their gold scores are easy to predict by either having similar structure and word choice and a high score or dissimilar structure and word choice and a low score.", "sentence2": "we split the data using symmetric word error rate (SWER), 7 finding sentence pairs with low SWER and low gold scores as well as sentence pairs with high SWER and high gold scores.", "label": "reasoning"}
{"id": "test_1344", "sentence1": "Most existing KGs are built separately by different organizations, using different data sources and languages.", "sentence2": "kGs are heterogeneous that the same entity may exist in different kGs in different surface forms.", "label": "reasoning"}
{"id": "test_1345", "sentence1": "Equivalent entities in two KGs are usually neighbored by some other equivalent entities.", "sentence2": "structure information in KGs are very important for discovering entity alignments.", "label": "reasoning"}
{"id": "test_1346", "sentence1": "However, such a hard cutoff of the search space makes these approaches insufficient in the exploration of the (already scarce) labeled data and limited by the ranker since most sentences are discarded, 2 albeit the discarded sentences are important and could have been favored.", "sentence2": "although these studies perform better than directly applying their base SDS models (See et al., 2017;Tan et al., 2017) to MDS, they do not outperform state-of-the-art MDS methods (Gillick and Favre, 2009;Kulesza and Taskar, 2012).", "label": "reasoning"}
{"id": "test_1347", "sentence1": "This variant solves L2 but may re-expose the RL agent to L1 since its MMR module and neural module are loosely coupled and there is a learnable layer in their combination.", "sentence2": "we design a second variant, RL-MMR SOFT-ATTN , which addresses both L1 and L2 by tightly incorporating MMR into neural representation learning via soft attention.", "label": "reasoning"}
{"id": "test_1348", "sentence1": "The number of epochs is set to 10,000 and we adopt early stopping -the training process terminates if RL-MMR cannot achieve better results on the validation set after 30 continuous evaluations.", "sentence2": "the runs often terminate before 5,000 epochs, and the overall training time ranges from 40 to 90 minutes.", "label": "reasoning"}
{"id": "test_1349", "sentence1": "Note that since labels are transmitted using a model, the model has to be transmitted as well (directly or indirectly).", "sentence2": "the overall codelength is a combination of the quality of fit of the model (compressed data length) with the cost of transmitting the model itself.", "label": "reasoning"}
{"id": "test_1350", "sentence1": "However, despite multiple recent efforts on this newly proposed dataset, published work so far in multimodal KPE has either omitted available features (Sun et al., 2020), or has adopted a brute force approach to feature encoding (direct concatenation of raw features) (Xiong et al., 2019).", "sentence2": "in this work we strive for a more nuanced approach to leveraging available features for multimodal KPE and offer a uniquely comprehensive approach.", "label": "reasoning"}
{"id": "test_1351", "sentence1": "Second, the behavior and characteristics of visual and text modality features are different from one another.", "sentence2": "the first-step self-attention should be modeled in separate networks for text and visual features.", "label": "reasoning"}
{"id": "test_1352", "sentence1": "First, unlike previous continual learning works on image classification (Kirkpatrick et al., 2017;Zenke et al., 2017), VisCOLL requires predicting, for example, a noun with a verb or an adjectivewhich results in a significantly large search space.", "sentence2": "of this increased search space, memory based continual methods (Robins, 1995;Aljundi et al., 2019a) cannot expect to store prototypes of each visited compositions.", "label": "reasoning"}
{"id": "test_1353", "sentence1": "Second, the increased search space makes it infeasible to view all possible combinations of atomic words at train time.", "sentence2": "to succeed on VisCOLL, models should generalize to novel compositions at test time (also called composition generalization) (Lake and Baroni, 2017; Keysers et al., 2020).", "label": "reasoning"}
{"id": "test_1354", "sentence1": "In contrast, task boundaries in VisCOLL are unknown and \"smooth\" (i.e., with gradual transitions between tasks)-a setting that is closer to real-world situations.", "sentence2": "visCOLL rules out many continual learning algorithms which require explicit task identity and boundary (Kirkpatrick et al., 2017;Rusu et al., 2016).", "label": "reasoning"}
{"id": "test_1355", "sentence1": "Finally, the algorithm greedily tries to put the proposed number of instances into each time interval to construct the stream.", "sentence2": "the constructed data stream has a gradually shifting task distribution without strict boundaries.", "label": "reasoning"}
{"id": "test_1356", "sentence1": "For (i), the target probability of each word is set proportional to the square root of its frequency in the visited stream.", "sentence2": "highly frequent words would take a smaller portion compared to reservoir sampling where the word distribution in the memory is linear to its frequency in the visited stream, leaving space for storing more diverse examples.", "label": "reasoning"}
{"id": "test_1357", "sentence1": "We find that (i) diversifying storage improves performance at the early stage of the stream but not in the later stages; (ii) prioritizing words likely to be forgotten does not improve performance.", "sentence2": "future works should find a balance between storing more diverse or important examples and respecting original data distribution.", "label": "reasoning"}
{"id": "test_1358", "sentence1": "Unlike Multistream, which leverages fine-grained region-level features, our results are reported on global framelevel features.", "sentence2": "it may be difficult for HERO to capture the inconsistency between hypothesis and video content.", "label": "reasoning"}
{"id": "test_1359", "sentence1": "Adversaries could easily exploit this to disseminate realistic-looking neural fake news.", "sentence2": "exploring the visual-semantic consistency between the article text and images could prove to be an important area for research in defending against generated disinformation.", "label": "reasoning"}
{"id": "test_1360", "sentence1": "In contrast, Type C articles have the potential to be exploited by adversaries to disseminate large amount of misleading disinformation due to its generated article contents.", "sentence2": "our proposed approach is geared towards addressing this particular type of generated articles.", "label": "reasoning"}
{"id": "test_1361", "sentence1": "Furthermore, each OIE system extracts the interested facts in the desired form at the time of development and omits the uninterested facts.", "sentence2": "they are not adaptable to new requirements.", "label": "reasoning"}
{"id": "test_1362", "sentence1": "It is also very abstract that sentences with the same meaning but in very different expressions will share the same AMR annotation.", "sentence2": "aMR is difficult to label (cost about 10 min to label a sample 4 ) and is very difficult to learn.", "label": "reasoning"}
{"id": "test_1363", "sentence1": "Due to resource limitations and in the spirit of environmental responsibility (Strubell et al., 2019;Schwartz et al., 2019), we conduct our experiments on the base models: BERT-baseuncased, RoBERTa-base, and DistilBERT-baseuncased.", "sentence2": "the BERT/RoBERTa models we use have 12 transformer blocks (0\u201311 indexed) producing 768-dimension vectors; the DistilBERT model we use has the same dimension but contains 6 transformer blocks (0\u20135 indexed).", "label": "reasoning"}
{"id": "test_1364", "sentence1": "Masking and finetuning achieve accuracy 84.79% and 85.25%, which are comparable and both outperform the baseline 50%, demonstrating successful knowledge transfer.", "sentence2": "finetuning and masking yield models with similar generalization ability.", "label": "reasoning"}
{"id": "test_1365", "sentence1": "For POS, after wordpiece tokenization, we see 1 sentence in dev and 2 sentences in test have more than 126 (the [CLS] and [SEP] need to be considered) wordpieces.", "sentence2": "we exclude 5 annotated words in dev and 87 annotated words in test.", "label": "reasoning"}
{"id": "test_1366", "sentence1": "Intuitively, if a training example has a low sentence-level probability, it is less likely to provide useful information for improving model performance, and thus is regarded as an inactive example.", "sentence2": "we adopt sentence-level probability P (y|x) as the metric to measure the activeness level of each training example: where T is the number of target words in the training example.", "label": "reasoning"}
{"id": "test_1367", "sentence1": "To save the time cost, a promising strategy is to let the identification model take the responsibility of rejuvenation.", "sentence2": "we used the TRANSFORMER-BIG model with the large batch configuration trained on the raw data to accomplish both identification and rejuvenation.", "label": "reasoning"}
{"id": "test_1368", "sentence1": "In the target vocabulary, words are sorted in the descending order of their frequencies in the whole training data, and the frequency rank of a word is its position in the dictionary.", "sentence2": "the higher the frequency rank is, the more rare the word is in the training data.", "label": "reasoning"}
{"id": "test_1369", "sentence1": "The language coverage could be broadened with other knowledge, such as that encoded in WALS, to distinguish even more language properties.", "sentence2": "to obtain the best of both views (KB and task-learned) with minimal information loss, we project a shared space of discrete and continuous features using a variant of canonical correlation analysis (Raghu et al., 2017).", "label": "reasoning"}
{"id": "test_1370", "sentence1": "We then can assess their applicability on multilingual NMT tasks that require guidance from language relationships.", "sentence2": "language clustering and ranking related partner languages for (multilingual) transfer are our study cases (\u00a76).", "label": "reasoning"}
{"id": "test_1371", "sentence1": "The list is a crafted set of concepts for comparative linguistics (e.g. I, eye, sleep), and it is usually processed by lexicostatistics methods to study language relationship through time.", "sentence2": "we prefer to argue that corpus-based embeddings could partially encode lexical similarity of languages.", "label": "reasoning"}
{"id": "test_1372", "sentence1": "However, the lack of an unequivocal definition of hate speech, the use of slurs in friendly conversations as opposed to sarcasm and metaphors in elusive hate speech (Malmasi and Zampieri, 2018), and the data collection timeline (Liu et al., 2019) contribute to the complexity and imbalance of the available datasets.", "sentence2": "training hate speech classifiers easily produces false positives when tested on posts that contain controversial or search-related identity words (Park et al., 2018;Sap et al., 2019;Davidson et al., 2019;Kim et al., 2020).", "label": "reasoning"}
{"id": "test_1373", "sentence1": "The initial list of predefined keywords such as the ones we have shown in Table 1 carries additional words in English and Arabic.", "sentence2": "for these two datasets, we have measured bias using two predefined lists of keywords: the initial list and one that is specific to the dataset in question.", "label": "reasoning"}
{"id": "test_1374", "sentence1": "The datasets were too large to be fit into GPU as a whole.", "sentence2": "we shifted the neighbor search to CPU, but that again took more than a day to complete.", "label": "reasoning"}
{"id": "test_1375", "sentence1": "The reason is that both of them synthesize sentences are either of less diverse or of less quality.", "sentence2": "we propose a controllable sampling strategy to generate reasonable source sentences: at each decoding step, if the word distribution is sharp then we take the word with the maximum probability, otherwise the sampling method formulated in Eq.", "label": "reasoning"}
{"id": "test_1376", "sentence1": "However, observe that this new rule performs two tests that could be done independently: 1. the right span boundary of the first antecedent must match the left span boundary of the second one; 2. the right span boundary of the second antecedent must match the left span boundary of the third antecedent.", "sentence2": "we can break the deduction into two sequential deductions, first testing the \"k\" boundary then the \"l\" boundary.", "label": "reasoning"}
{"id": "test_1377", "sentence1": "A popular solution tackles the grammatical error correction as a monolingual machine translation task where ungrammatical sentences are regarded as the source language and corrected sentences as the target language (Ji et al., 2017;Chollampatt and Ng, 2018a).", "sentence2": "the GEC can be modeled using some relatively mature machine translation models, such as the sequence-to-sequence (seq2seq) paradigm (Sutskever et al., 2014).", "label": "reasoning"}
{"id": "test_1378", "sentence1": "Assuming that a token is selected to be replaced, and its candidate substitutes are retrieved by the mapping, we want the selected substitute can fit in well with the token's context and maintain both the semantic and syntactic coherence.", "sentence2": "we define a function s based on the edit distance (Marzal and Vidal, 1993) to estimate the similarity scores between two sentences.", "label": "reasoning"}
{"id": "test_1379", "sentence1": "We would also like to know which type of words to modify is most likely to form a successful attack.", "sentence2": "we calculate the correction rates of the newly added errors with different types of part-ofspeech.", "label": "reasoning"}
{"id": "test_1380", "sentence1": "As it is difficult to ensure high quality annotations for 21 languages using crowdsourcing, we relied on colleagues by reaching out on NLP and Linguistics mailing lists.", "sentence2": "the number of evaluators per language varies (cf.", "label": "reasoning"}
{"id": "test_1381", "sentence1": "Specifically, when the LLL model is trained on a new task, we assign a teacher model to first learn the new task, and pass the knowledge to the LLL model via knowledge distillation.", "sentence2": "the LLL model can better adapt to the new task while keeping the previously learned knowledge.", "label": "reasoning"}
{"id": "test_1382", "sentence1": "Inspired by knowledge distillation (Bucila et al., 2006;Hinton et al., 2015;Kim and Rush, 2016), in which a student (smaller) model is trained to imitate the behavior of a teacher (larger) model in order to reach the performance closer to the teacher model, the LLL model in L2KD can be seen as a weak learner that needs to compress knowledge from different tasks into a compact single model.", "sentence2": "lll can benefit from the similar procedure of knowledge distillation, although the model size is equal to its teacher model.", "label": "reasoning"}
{"id": "test_1383", "sentence1": "By way of assuming \u03a8 \u223c GEM(\u03b3), an HDP assumes an infinite number of topics are present a priori, with the number of tokens per topic decreasing rapidly with the topic's index in a manner controlled by \u03b3.", "sentence2": "under the model, a topic with a sufficiently large index should contain no tokens with high probability.", "label": "reasoning"}
{"id": "test_1384", "sentence1": "The subcluster split-merge algorithm is designed to converge with fewer iterations, but is more costly to run per iteration.", "sentence2": "we used a fixed computational budget of 24 hours of wall-clock time for both algorithms.", "label": "reasoning"}
{"id": "test_1385", "sentence1": "However, several alignment-based STS methods employ Euclidean distance  or dot product  to compute the word dissimilarity.", "sentence2": "the question arises as to which is the most suitable method for computing word dissimilarity.", "label": "reasoning"}
{"id": "test_1386", "sentence1": "The key difference lies in the fact that ADD treats a sentence as a single vector (the barycenter of direction vectors), whereas WRD treats a sentence as a set of direction vectors.", "sentence2": "it is natural that WRD had a positive effect on STS tasks, given that STS tasks require the word alignment (i.e., they assume that words are treated disjointedly).", "label": "reasoning"}
{"id": "test_1387", "sentence1": "The phenomenon, however, is often overlooked in existing matching models.", "sentence2": "the feature vectors are constructed without any regularization, which inevitably increases the difficulty of learning the downstream matching functions.", "label": "reasoning"}
{"id": "test_1388", "sentence1": "In WD-Match, a Wasserstein distance-based regularizer is defined to regularize the features vectors projected from different domains.", "sentence2": "the method enforces the feature projection function to generate vectors such that those correspond to different domains cannot be easily discriminated.", "label": "reasoning"}
{"id": "test_1389", "sentence1": "G module is implemented as a two-layer MLP (the number of neurons in the second layer is set as one).", "sentence2": "the additional computing cost comes from the training of the two-layer MLP, which is of O(T * N * K * 1), where T is the number of training iterations, N number of training examples, K number of neurons in the first layer of MLP (without considering the compute cost of the activation function).", "label": "reasoning"}
{"id": "test_1390", "sentence1": "We observe that the proposed two-stage methods, GW-GeoMM and SL-GeoMM, obtain scores on par with state-of-the-art methods, UMWE and UMH.", "sentence2": "multilingual approaches can learn an effective multilingual space for closeby languages.", "label": "reasoning"}
{"id": "test_1391", "sentence1": "In addition, most previous works do not consider the importance of each teacher layer and use the same layer weights among various tasks, which create a substantial barrier for generalizing the compressed model to different NLP tasks.", "sentence2": "an adaptive compression model should be designed to transfer knowledge from all teacher layers dynamically and effectively for different NLP tasks.", "label": "reasoning"}
{"id": "test_1392", "sentence1": "Since different attention and hidden layers of BERT can learn different levels of linguistic knowledge, these layers should have different weights for various NLP tasks.", "sentence2": "we propose a cost attention mechanism to assign weights for each attention and hidden layers automatically.", "label": "reasoning"}
{"id": "test_1393", "sentence1": "Given an event like \"Jerry repels Tom's attack\", to approximate the phrases in Atomic, we firstly annotate the person roles, that is, replacing the subject person with \"PersonX\" and the other person with \"PersonY\".", "sentence2": "we get \"PersonX repels PersonY's attack\".", "label": "reasoning"}
{"id": "test_1394", "sentence1": "However, the counterfactual samples generated by most previous methods are simply added to the training data for augmentation and are not fully utilized.", "sentence2": "we introduce a novel selfsupervised contrastive learning mechanism to learn the relationship between original samples, factual samples and counterfactual samples.", "label": "reasoning"}
{"id": "test_1395", "sentence1": "Although the MAMS described in Section 5.3 provides a training set with diversity, it remains difficult to improve aspect robustness for other domains, or future new datasets.", "sentence2": "we propose a flexible method, adversarial training, for aspect robustness, which is applicable to any given dataset.", "label": "reasoning"}
{"id": "test_1396", "sentence1": "A possible explanation is that the short reference summaries fail to capture all the important information of original documents.", "sentence2": "directly comparing with document representations will suffer much less information loss.", "label": "reasoning"}
{"id": "test_1397", "sentence1": "We make use of the heuristics that nearby sequences in the document contain the most important information to recover the masked words.", "sentence2": "the challenging retrieval part can be replaced by soft-attention mechanism, making our model much easier to train.", "label": "reasoning"}
{"id": "test_1398", "sentence1": "During training, we fix the position embeddings for the pre-appended special tokens, and randomly select 64 continuous positions from 0 to 564 for the other words.", "sentence2": "the model can be used to encode longer sequences in downstream tasks.", "label": "reasoning"}
{"id": "test_1399", "sentence1": "Rather a pointer is made to the location where the number 8 occurred in an algebraic word problem.", "sentence2": "using such an \"operand-context pointer\" enables a model to access contextual information about the number directly, as shown in Figure 1 (c); thus, the operand-context separation issue can be addressed.", "label": "reasoning"}
{"id": "test_1400", "sentence1": "We observed that the existing pure neural model's performance on low-complexity dataset of MAWPS was relatively high at 78.9%, compared to that of high-complexity dataset of ALG514 (44.5%).", "sentence2": "using Expression tokens and operand-context pointers contributed to higher performance when applied to high-complexity datasets of ALG514 and DRAW-1K, as shown in Table 5.", "label": "reasoning"}
{"id": "test_1401", "sentence1": "As the expression fragmentation issue can arise for each token, probability of fragmentation issues' occurrence increases exponentially as the number of unknowns/Op tokens in a problem increases.", "sentence2": "the vanilla Transformer model, which could not handle the fragmentation issue, yields low accuracy on high-complexity datasets.", "label": "reasoning"}
{"id": "test_1402", "sentence1": "When generating solution equations for the comparative phrases, the order of arguments is a matter for an equation that contains non-commutative operators, such as subtractions or divisions.", "sentence2": "errors occurred when the order of arguments for comparative phrases with non-commutative operators was mixed up.", "label": "reasoning"}
{"id": "test_1403", "sentence1": "However, neural networks are less interpretable and need to be trained with a large amount of data to make it possible to learn such implicit logic.", "sentence2": "we consider tackling the problems by exploiting logic knowledge.", "label": "reasoning"}
{"id": "test_1404", "sentence1": "Notice that the intent classifier is typically implemented using standard text classification algorithms (Weiss et al., 2012;Larson et al., 2019;Casanueva et al., 2020).", "sentence2": "to per\u0002form OOS sample detection, methods often rely on one-class classification or threshold rejection\u0002based techniques using the probability outputs for each class (Larson et al., 2019) or reconstruction errors (Ryu et al., 2017, 2018).", "label": "reasoning"}
{"id": "test_1405", "sentence1": "However, in practice, collecting OOS data can be a burden for intent classifier creation, which is generally carried out by domain experts and not by machine learning experts.", "sentence2": "in the ideal world, one should rely solely on in-scope data for this task because it is very difficult to collect a set of data that appropriately represents the space of the very unpredictable OOS inputs.", "label": "reasoning"}
{"id": "test_1406", "sentence1": "It is a language representation model pre-trained on unlabeled text and conditioned on both the left and right contexts.", "sentence2": "a simple output layer can be fine-tuned to attain strong results in many different tasks.", "label": "reasoning"}
{"id": "test_1407", "sentence1": "But, although BERT+ has not been significantly better than BERT with PT-BR chatbots, the proposed word graph-based approach had a great impact in reducing that 5% difference, since both present similar EER values, and still had a huge impact in FRR rates since BERT+ presented significantly better values.", "sentence2": "it is likely that by improving the mapping of sentence and graph embeddings for those datasets, and consequently reducing that 5% gap in ISER, BERT+ will stand out as a significantly better approach than BERT.", "label": "reasoning"}
{"id": "test_1408", "sentence1": "Unlike the constraintbased methods, which use translations of the focus word to post-process the output of a WSD system, t emb provides the translation information in the form of an embedding directly as input to the WSD system.", "sentence2": "translation information is used as an additional feature to improve sense predictions of the base WSD system.", "label": "reasoning"}
{"id": "test_1409", "sentence1": "Although attention weights in some NMT systems may be used to derive word alignment, such an approach is not necessarily more accurate than off-the-shelf alignment tools (Li et al., 2019).", "sentence2": "our approach is to instead identify the word-level translations by performing a bitext-based alignment between the source focus words and their translations.", "label": "reasoning"}
{"id": "test_1410", "sentence1": "To highlight the improvement in contextualization alone, since the Within Word tasks before lemmatization may contain different word forms of the same lemma as the target words in each pair, we lemmatize all the target words in the dataset.", "sentence2": "each pair in the Within Word tasks now contains the identical target word.", "label": "reasoning"}
{"id": "test_1411", "sentence1": "Moreover, latent-variable models can represent multimodal distributions.", "sentence2": "for these conditional tasks, the latent variable can be used as a source of stochasticity to ensure more diverse translations (Pagnoni et al., 2018) or answers in a dialogue (Serban et al., 2017).", "label": "reasoning"}
{"id": "test_1412", "sentence1": "However, this model would not be more useful than a standard, left-to-right autoregressive models.", "sentence2": "it is necessary to check that such useless, purely local features are not learned.", "label": "reasoning"}
{"id": "test_1413", "sentence1": "Moreover, if the latent variable of the VAEs did encode the label perfectly and exclusively, they would reconstruct the first words or recover sentence length with much lower accuracy than what is observed.", "sentence2": "we conclude that seq2seq VAEs are biased towards memorizing the first few words and the sentence length.", "label": "reasoning"}
{"id": "test_1414", "sentence1": " As Long et al. (2019) reported, the max-pooling operator is better than the average operator, both when the encoder is a LSTM and BoW (possibly because the maximum introduces a non-linearity).", "sentence2": "we use the maximum operator.", "label": "reasoning"}
{"id": "test_1415", "sentence1": "The latent variable is more predictive of global features and memorisation of the first words and sentence length is decreased.", "sentence2": "these models are more suitable for diverse and controllable generation.", "label": "reasoning"}
{"id": "test_1416", "sentence1": "However, information related to the second word in the latent variable can help the decoder predict the first word.", "sentence2": "gains in position i can only be attributed to information pertaining to the words in positions >=i.", "label": "reasoning"}
{"id": "test_1417", "sentence1": "However, previous work neglects the fact that there is usually a limited time budget to interact with domain experts (e.g., medical experts, biologists)  and high-quality natural language explanations are expensive, by nature.", "sentence2": "we focus on eliciting fewer but more informative explanations to reduce expert involvement.", "label": "reasoning"}
{"id": "test_1418", "sentence1": "Contrastive Natural Language Explanations Existing research in social science and cognitive science (Miller, 2019; Mittelstadt et al., 2019) suggests contrastive explanations are more effective in human learning than descriptive explanations.", "sentence2": "we choose contrastive natural language explanations to benefit our learners.", "label": "reasoning"}
{"id": "test_1419", "sentence1": "Unlike previous active learning on data-points, our class-based active learning is empirically insensitive to the change of random seeds and hyper-parameter (e.g., batch size).", "sentence2": "we could collect the explanations in an on-demand manner.", "label": "reasoning"}
{"id": "test_1420", "sentence1": "However, Table 10 shows that even when continuing to train this model for a long time no multilinguality arises.", "sentence2": "in this configuration the model has enough capacity to model the languages independently of each other -and due to the modifications apparently no incentive to try to align the language representations.", "label": "reasoning"}
{"id": "test_1421", "sentence1": "Recent work (Yu et al., 2020) shows that gradient conflict between dissimilar tasks, defined as a negative cosine similarity between gradients, is predictive of negative interference in multi-task learning.", "sentence2": "we study whether gradient conflicts exist between languages in multilingual models.", "label": "reasoning"}
{"id": "test_1422", "sentence1": "As shown by the expansions per step in Table 2, VAR-STREAM uses the batch capacity of 100 most efficiently.", "sentence2": "vAR-STREAM is faster than both vAR-BATCH and FIXED, despite overhead which is exacerbated in a small model.", "label": "reasoning"}
{"id": "test_1423", "sentence1": "However, since some languages do not typically use whitespace between words (e.g., Thai), we used the heuristic of SentencePiece meta symbol U+2581 to designate the beginning of the word.", "sentence2": "a word is defined as the token span between two successive U+2581 symbols.", "label": "reasoning"}
{"id": "test_1424", "sentence1": "Using three encoders did not yield clear improvements over two encoders.", "sentence2": "we do not experiment with using more than three encoders.", "label": "reasoning"}
{"id": "test_1425", "sentence1": "Bansal et al. (2019) demon\u0002strated that better feature learning from super\u0002vised tasks helps few-shot learning.", "sentence2": "we also evaluate multi-task learning and multi-task meta-learning for few-shot generalization.", "label": "reasoning"}
{"id": "test_1426", "sentence1": "A few recent projects reveal that GLUE tasks may be not sophisticated enough and do not require much tasks-specific linguistic knowledge (Kovaleva et al., 2019;Warstadt et al., 2019).", "sentence2": "superGLUE benchmark, being more challenging, becomes much more preferable for evaluation of language models.", "label": "reasoning"}
{"id": "test_1427", "sentence1": "Furthermore, the normalization involves the prediction of both operation types and token labels, enabling TNT to learn from more challenging tasks than the standard task of masked word recovery.", "sentence2": "the experiments demonstrate that TNT outperforms strong baselines on the hate speech classification task.", "label": "reasoning"}
{"id": "test_1428", "sentence1": "However, we showed that using En dev accuracy for checkpoint selection leads to somewhat arbitrary zero-shot results.", "sentence2": "we propose reporting oracle accuracies, where one still fine-tunes using English data, but selects a checkpoint using target dev.", "label": "reasoning"}
{"id": "test_1429", "sentence1": "They use different language models and word embeddings (e.g., BERT, RoBERTa, or BiRNN), and have been trained on different data (e.g., DPR (Rahman and Ng, 2012), WinoGrande, or no additional data).", "sentence2": "it is unclear whether the choice of the objective function is essential for pronoun resolution tasks.", "label": "reasoning"}
{"id": "test_1430", "sentence1": "The relatively free word order this allows creates much less emphasis on the collocation of a semantic unit's tokens.", "sentence2": "as conversational assistants progress toward multiple languages it's important to consider that constraints that are acceptable if only English is considered will not analogously scale to other languages.", "label": "reasoning"}
{"id": "test_1431", "sentence1": "The refinement approach delegates responsibility of sessionbased semantic parsing to a separate dialog component.", "sentence2": "refinement approaches tend to have a very limited ontology due to the semantic parser operating over a fixed input (non-session utterances).", "label": "reasoning"}
{"id": "test_1432", "sentence1": "However, for leaves with larger number of examples statistical significance alone is insufficient, because there are a large number of cases where there are small but significant differences from the ratio of agreement expected by chance.", "sentence2": "in addition to comparing the p-value we also compute the effect size which provides a quantitative measure on the magnitude of an effect (Sullivan and Feinn, 2012).", "label": "reasoning"}
{"id": "test_1433", "sentence1": "Whereas the Statistical Threshold uses effect size with the significance test which takes into account the sample size within a leaf leading to better leaves.", "sentence2": "we choose to use Statistical-Threshold for all our simulation experiments.", "label": "reasoning"}
{"id": "test_1434", "sentence1": "As (1) illustrates, not all sentences in a response to an advice-seeking question constitute advice.", "sentence2": "we want annotators to highlight which parts of the response to a question are advice, and which  are not.", "label": "reasoning"}
{"id": "test_1435", "sentence1": "For instance, the \"activation\"-anchored event (Figure 2) is both THEME and CAUSE of \"induced\"and \"promote\"-anchored event heads, respectively.", "sentence2": "both r and h are multi-label, and the label for \"activation\" is encoded as +REGULATION, [THEME, CAUSE] where the order of r and h items is preserved.", "label": "reasoning"}
{"id": "test_1436", "sentence1": "In a crowdsourcing setting, we oftentimes hire a much larger set of annotators that are not professionally trained and may be only working on the task sporadically.", "sentence2": "it is infeasible to ask them to follow detailed guidelines.", "label": "reasoning"}
{"id": "test_1437", "sentence1": "In our experiments, we aim at evaluating the multilingual and the cross-lingual question answering capabilities of different models.", "sentence2": "we split the data in order to support both evaluation strategies: Multilingual and Cross-lingual.", "label": "reasoning"}
{"id": "test_1438", "sentence1": "Social biases appear to be a natural component of human cognition that allow people to make judgments efficiently (Kahneman et al., 1982).", "sentence2": "they are often implicit-people are unaware of their own biases (Blair, 2002; Bargh, 1999)-and manifest subtly, e.g., as microaggressions or condescension (Huckin, 2002;Sue, 2010).", "label": "reasoning"}
{"id": "test_1439", "sentence1": "The main challenge is encouraging the model to focus on text features that are indicative of bias, rather than artifacts in data that correlate with the gender of the addressee but occur because of confounding variables (confounds).", "sentence2": "the core of our methodology focuses on reducing the influence of confounds.", "label": "reasoning"}
{"id": "test_1440", "sentence1": "However, we only want the model to learn that references to appearance are indicative of gender if they occur in unsolicited contexts.", "sentence2": "our model needs to account for the effects of O TXT: Because of correlations between W GEN and O TXT, COM TXT values may contain features that are predictive of W GEN, but are caused by O TXT, rather than by W GEN. We face a similar problem with W TRAITS.", "label": "reasoning"}
{"id": "test_1441", "sentence1": "While there may still be overlap in some latent W TRAITS, we expect there to be less overlap in W TRAITS between the train and test set than within the train set.", "sentence2": "improved performance over the held-out test set would suggest that demotion effectively reduces the influence of the latent confounding variables-the model learns characteristics of comments addressed to women generally rather than characteristics specific to the individual people in the training set.", "label": "reasoning"}
{"id": "test_1442", "sentence1": "Because most gender-related mi\u0002croaggressions target women, if our model predicts that the reported microaggression was addressed to a woman (e.g. W GEN = F), we assume that the post is a gender-tagged microaggression.", "sentence2": "our models are not trained at all for identifying gender-tagged microaggressions.", "label": "reasoning"}
{"id": "test_1443", "sentence1": "However, by controlling for O TXT, propensity matching discards many of these comments.", "sentence2": "by demoting a confounding variable, we make the prediction task more difficult.", "label": "reasoning"}
{"id": "test_1444", "sentence1": "Specifically, for the 6K words, we report the mean precision and recall of every 10 consecutive words in the vocabulary.", "sentence2": "we have 600 data points, each representing precision/recall of 10 words.", "label": "reasoning"}
{"id": "test_1445", "sentence1": "The two UI elements have very similar images (magnifiers) although they are for searching different objects.", "sentence2": "context information is critical for models to decode the correct objects.", "label": "reasoning"}
{"id": "test_1446", "sentence1": "To avoid information leaks, the split was done app-wise so that all the screens from the same app will not be shared across different splits.", "sentence2": "all the apps and screens in the test dataset are unseen during training, which allow us to examine how each model configuration generalizes to unseen conditions at test.", "label": "reasoning"}
{"id": "test_1447", "sentence1": "If only textual inputs are given, they cannot effectively incorporate visual knowledge in their representations.", "sentence2": "their help for entailing the contradiction between a and b is limited.", "label": "reasoning"}
{"id": "test_1448", "sentence1": "Fourth, individuals will mirror the language as a way of decreasing social distance which can increase trust (Scissors et al., 2008); Wang et al. (2015) found that lexical alignment is associated with increased emotional support.", "sentence2": "we include a feature for lexical alignment as the % of the condolence's words that were also used in the distress comment.", "label": "reasoning"}
{"id": "test_1449", "sentence1": "To get rid of this annotation burden, we formulate the problem from the perspective of Multiple Instance Learning (MIL; Keeler and Rumelhart, 1992).", "sentence2": "our model learns to spot story attributes in reviews in a weakly supervised fashion and does not expect direct tag level supervision.", "label": "reasoning"}
{"id": "test_1450", "sentence1": "However, we expect a latent correlation between Y P and Y C that can be jointly modeled while modeling P (Y P |X), hence helping the extraction of Y C without any direct supervision.", "sentence2": "we first supervise a model containing a synopsis encoder and a review encoder to learn P (Y P |X) (Section 4.1), and later we use the trained review encoder to generate complementary tagset Y C (Section 4.2).", "label": "reasoning"}
{"id": "test_1451", "sentence1": "For example, we observe that the model usually puts higher attention weights on opinion-heavy words in the reviews.", "sentence2": "we use the attention weights on words and sentences in reviews to extract an additional open-vocabulary tagset Y C .", "label": "reasoning"}
{"id": "test_1452", "sentence1": "However, directly fine-tuning such models for long texts like synopses and reviews is extremely memory expensive.", "sentence2": "we employ Sentence-BERT (SBERT; Reimers and Gurevych, 2019) in our work, which is a state-of-the-art universal sentence encoder built with pre-trained BERT (Devlin et al., 2019).", "label": "reasoning"}
{"id": "test_1453", "sentence1": "Figure 7(a) shows that, for the predefined tags, our tagsets were more relevant than the baseline ones for 57% movies, the baseline tags were better than HN(A)+MIL for 24% movies, and both systems were equally performing for 19% movies.", "sentence2": "we get further verification of Q2.", "label": "reasoning"}
{"id": "test_1454", "sentence1": "Results in Table 4 show that, our system can indeed predict tags that are very relevant to the new types of stories.", "sentence2": "we conclude that our approach also shows great promise for other domains and can be extended with little effort.", "label": "reasoning"}
{"id": "test_1455", "sentence1": "Beyond its interpretation as shared information, mutual information gives little in terms of interpretability: It has no consistent reference points, beyond that the minimum possible MI is zero.", "sentence2": "several variants of MI are preferred in community detection.", "label": "reasoning"}
{"id": "test_1456", "sentence1": "Combinatory categorial grammar (CCG) is a lexicalized grammatical formalism, where the lexical categories (also known as supertags) of the words in a sentence provide informative syntactic and semantic knowledge for text understanding.", "sentence2": "ccG parse often provides useful information for many downstream natural language processing (NLP) tasks such as logical reasoning (Yoshikawa et al., 2018) and semantic parsing (Beschke, 2019).", "label": "reasoning"}
{"id": "test_1457", "sentence1": "As high-quality dependency parsers are not always available, we do not want our CCG supertaggers to rely on the existence of dependency parsers.", "sentence2": "we need another way to extract useful word pairs to build GCN models.", "label": "reasoning"}
{"id": "test_1458", "sentence1": "It is not very convenient to utilize a large amount of unlabeled data in the baseline method wt, since this will directly increase the amount of augmented data.", "sentence2": "some of augmented data may not be utilized before sequence tagging models converge.", "label": "reasoning"}
{"id": "test_1459", "sentence1": "Their loss is not applicable in our setting, because the embedding space of an autoencoder is not unit-normalized like word vectors typically are.", "sentence2": "we employ cosine loss and leave the exploration of other regression losses to future work.", "label": "reasoning"}
{"id": "test_1460", "sentence1": "Our model\u2019s perfor\u0002mance is close to that of Wang et al. (2019), even without FGIM at inference time.", "sentence2": "our model has a much lower computational overhead.", "label": "reasoning"}
{"id": "test_1461", "sentence1": "Our motivation comes from the fact that sentence generation along parse trees can intrinsically capture and maintain the syntactic information (Eriguchi et al., 2017;Aharoni and Goldberg, 2017;Iyyer et al., 2018), and show better performances than sequential recurrent models (Li et al., 2015;Iyyer et al., 2014).", "sentence2": "we design a novel tree-based autoencoder to generate adversarial text that can simultaneously preserve both semantic meaning and syntactic structures of original sentences.", "label": "reasoning"}
{"id": "test_1462", "sentence1": "Moreover, the tree structure allows us to modify the tree node embedding at different tree hierarchies in order to generate controllable perturbation on word level or sentence level.", "sentence2": "we explore the following two types of attacks at root level and leaf level T3(SENT) and T3(WORD), which are shown in Figure 3 and Figure 4.", "label": "reasoning"}
{"id": "test_1463", "sentence1": "From the table, we find using different initialization methods will greatly affect the attack success rates.", "sentence2": "the initial sentence selection methods are indeed important to help reduce the number of iteration steps and fastly converge to the optimal z * that can attack the model.", "label": "reasoning"}
{"id": "test_1464", "sentence1": "Previous methods craft adversarial samples mainly based on specific rules (Li et al., 2018;Gao et al., 2018;Alzantot et al., 2018;Ren et al., 2019;Jin et al., 2019;Zang et al., 2020).", "sentence2": "these methods are difficult to guarantee the fluency and semantically preservation in the generated adversarial samples at the same time.", "label": "reasoning"}
{"id": "test_1465", "sentence1": "On the other hand, BERT is a pre-trained masked language model on extremely large-scale unsupervised data and has learned general-purpose language knowledge.", "sentence2": "bERT has the potential to generate more fluent and semantic-consistent substitutions for an input text.", "label": "reasoning"}
{"id": "test_1466", "sentence1": "While most words are still single words, rare words are tokenized into sub-words.", "sentence2": "we treat single words and sub-words separately to generate the substitutes.", "label": "reasoning"}
{"id": "test_1467", "sentence1": "Since the average sequence length is relatively long, the target model tends to make judgments by only a few words in a sequence, which is not the natural way of human prediction.", "sentence2": "the perturbation of these keywords would result in incorrect prediction from the target model, revealing the vulnerability of it.", "label": "reasoning"}
{"id": "test_1468", "sentence1": "Nevertheless, candidates generated from the masked language model can sometimes be antonyms or irrelevant to the original words, causing a semantic loss.", "sentence2": "enhancing language models to generate more semantically related perturbations can be one possible solution to perfect BERT-Attack in the future.", "label": "reasoning"}
{"id": "test_1469", "sentence1": "Previous studies have created synthetic data from generic news summarization corpora which have a small set of aspects (e.g., \"sports\", \"health\" and other 4 aspects in (Frermann and Klementiev, 2019)).", "sentence2": "models trained on these data tend to be restricted to the pre-defined set and fall short of summarizing on other diverse aspects.", "label": "reasoning"}
{"id": "test_1470", "sentence1": "This evaluation setup clearly does not account for the entity distributions in the real data.", "sentence2": "the reported performance scores do not reflect the effectiveness of these models when adapting to a new domain.", "label": "reasoning"}
{"id": "test_1471", "sentence1": "Tag set extension Our first set of experiments are motivated by the fact that new types of entities often emerge in some domains such as medical and social media.", "sentence2": "we evaluate the performance of our systems on recognizing new entity types as they emerge in the source domain.", "label": "reasoning"}
{"id": "test_1472", "sentence1": "Concretely, \"Apple\", \"Microsoft\", \"Coca\", and \"Cola\" all contain only alphabetical letters with the first one capitalized; Tokens \"Inc.\", \"Corp.\", and \"Co.\" all are alphabetical letters with first letter capitalized, and they all end with a dot.", "sentence2": "\"Apple Inc.\" and \"Microsoft Corp.\" have the same sequence of structure vectors.", "label": "reasoning"}
{"id": "test_1473", "sentence1": "Moreover, for consecutive tokens with identical structure vectors, we combine them into one and hence \"Coca Cola\" shares the same structure vectors with the other two.", "sentence2": "if one of the three is labeled as <name><suffix> , we can apply the same sequence of labels to the other two examples as weak labels without actual human annotation.", "label": "reasoning"}
{"id": "test_1474", "sentence1": "Current knowledge bases (such as ATOMIC) contain social rather than physical effects.", "sentence2": "generation models trained on these knowledge bases incorrectly force the effects to be social.", "label": "reasoning"}
{"id": "test_1475", "sentence1": "We also found that when manually evaluating on \u223c200 dev datapoints, the score was systematically a few (\u223c10%) points higher than BLEU, while the trends and model rankings remained the same, indicating robustness of the automatic metric.", "sentence2": "the proposed metric aligns with human evaluation, and is able to use existing generation metrics thereby simplifying evaluation, allowing easier reproducibility.", "label": "reasoning"}
{"id": "test_1476", "sentence1": "Additionally, user feedback from these experiments suggested that we generate shorter entries, as longer ones frequently devolved into unrelated and incoherent sentences.", "sentence2": "for our final experiments detailed in the next section, we also truncate model outputs to a maximum of four sentences.", "label": "reasoning"}
{"id": "test_1477", "sentence1": "The amount of author effort involved in evaluation, when combined with the relatively small size of the STORIUM community, can cause evaluation to take a considerable amount of time (i.e., to collect hundreds of judgements) as evidenced in our analysis (Section 5).", "sentence2": "our platform is not currently suitable for \"instant\" evaluation of generated stories.", "label": "reasoning"}
{"id": "test_1478", "sentence1": "Supporting multi-domain conversations spanning multiple APIs quickly grows out of hand, requiring expert linguists and rigorous testing to ensure the grammatical correctness and appropriateness of generated utterances.", "sentence2": "data-driven generative approaches have gained prominence.", "label": "reasoning"}
{"id": "test_1479", "sentence1": "The main objective of this work is to improve attention supervisions for the purpose of better text classification.", "sentence2": "we evaluate the three attention methods by their contribution to the classification performance.", "label": "reasoning"}
{"id": "test_1480", "sentence1": "On the other hand, for the head categories with many instances, general approaches such as the single CNN model (Kim, 2014;Liu et al., 2017) may be more effective in terms of performance and more efficient in terms of complexity.", "sentence2": "our basic idea for tackling the problem of extremely imbalanced multi-label text classification is a hybrid solution that adapts a general approach (i.e., a Single network) for head categories and a few-shot approach for tail categories, so that we can take the advantages of both of them.", "label": "reasoning"}
{"id": "test_1481", "sentence1": "For example, if an instance has multiple categories and each category has a representation vector, it is difficult to learn a representation of this instance near the representations of all these categories through a single similarity output.", "sentence2": "we propose a category-specific similarity in the Siamese structure to capture the rich information in the similarities.", "label": "reasoning"}
{"id": "test_1482", "sentence1": "Moreover, in some situations, parsers are supplied by third parties, making it impossible to alter them.", "sentence2": "assuming parsers are a black box, it is indispensable to conduct research on an interactive approach for enhancing the text-to-SQL technique in complex scenarios.", "label": "reasoning"}
{"id": "test_1483", "sentence1": "Compared to aligning an NL question with a SQL query, the alignment of two NL questions is more reasonable because it utilizes a similar linguistic structure and can make better use of pre-trained models (e.g., BERT).", "sentence2": "before the alignment, we restate the predicted SQL y into a natural language question x .", "label": "reasoning"}
{"id": "test_1484", "sentence1": "As users are non-expert and unfamiliar with database operations, simply picking an option is more natural and friendly.", "sentence2": "the Question Generator is designed to generate a multi-choice question for each uncertain token.", "label": "reasoning"}
{"id": "test_1485", "sentence1": "As analyzed in Section 2, most of the uncertain tokens are related to database information.", "sentence2": "for each uncertain token in an NL question, we find out the corresponding database and add all the column and table names into the candidate set.", "label": "reasoning"}
{"id": "test_1486", "sentence1": "A major challenge to the proposed method is the absence of manual annotation of mentions and relations.", "sentence2": "we propose an automatic annotation method (Section 2.4) based on aligning tokens in a SQL with corresponding question.", "label": "reasoning"}
{"id": "test_1487", "sentence1": "The main reason is that the sentence embeddings in the pipeline approach are not shared.", "sentence2": "although these two subtasks can be well learned separately, they are not trained to collaborate with each other.", "label": "reasoning"}
{"id": "test_1488", "sentence1": "Indeed, in the rebuttal phase, authors reply reviewer's suggestions and questions very carefully to make the points clear, sometimes by citing the review arguments.", "sentence2": "the structure and the format of rebuttals are relatively fixed, while reviewers have more flexibility in the style and the structure when writing reviews.", "label": "reasoning"}
{"id": "test_1489", "sentence1": "As shown in Figure 1, graph-attention will degenerate into a vanilla selfattention layer when the nodes in the graph are fully connected.", "sentence2": "the graph-attention can be considered as a special case of self-attention.", "label": "reasoning"}
{"id": "test_1490", "sentence1": "It is obvious that graph attention can not cover the last three attention patterns.", "sentence2": "we draw a conclusion that self attention has advantages on generality and flexibility.", "label": "reasoning"}
{"id": "test_1491", "sentence1": "As regards WSD, instead, we are no longer bound by the long-standing limits of predefined sense inventories.", "sentence2": "it is possible to give (i) a meaningful answer for words that are not in the inventory, and (ii) one that fits the meaning and the granularity required by a given context better than any sense in the inventory.", "label": "reasoning"}
{"id": "test_1492", "sentence1": "Other errors stem from the fact that the model can only rely on the knowledge about possible definienda that it is able to store in the parameters during the pre-training and training stages.", "sentence2": "if the contextual knowledge is not sufficient to extrapolate a definition, the model which is required to always generate an output will hallucinate an answer on the basis of contextual clues, incurring the risk of introducing nonfactualities.", "label": "reasoning"}
{"id": "test_1493", "sentence1": "Reif et al. (2019) showed that senses are encoded with finer-grained precision in higher layers, to the extent that their representation of the same token tends not to be self-similar across different contexts (Ethayarajh, 2019;  Mickus et al., 2020).", "sentence2": "we hypothesise that abstract, type-level information could be codified in lower layers instead.", "label": "reasoning"}
{"id": "test_1494", "sentence1": "Interestingly, we find that the non-spurious correlations are more located in entity representation rather than context representation.", "sentence2": "our method eliminates part of the spurious correlations between context representation and output labels.", "label": "reasoning"}
{"id": "test_1495", "sentence1": "Furthermore, fully-annotated training data will be rare due to the expensive cost.", "sentence2": "training set can only cover a minor part of test mentions and diverse context patterns must be learned from minimal instances.", "label": "reasoning"}
{"id": "test_1496", "sentence1": "In open NER, however, most entities (e.g., movie, song and book) do not have such strong name regularity, and some of mentions can even be random utterances.", "sentence2": "it is critical to evaluate the impact of name regularity on generalization.", "label": "reasoning"}
{"id": "test_1497", "sentence1": "This ability, obviously, is not what we desire because 1) in real world applications, most entity mentions are new and unseen, which means out-of-dictionary mentions will dominate the test process; 2) because the training instances are very limited in open situations, it is too expensive to achieve high mention coverage; 3) many longtail mentions in the training set would be oneshot, i.e., the mention only appears once in the training data.", "sentence2": "it is necessary to exploit whether NER models can still reach reasonable performance in low mention coverage situation.", "label": "reasoning"}
{"id": "test_1498", "sentence1": "We believe this is because, as some previous studies in other tasks (Zhang et al., 2016;Lu et al., 2019) have pointed out, neural networks have strong ability and tendency to memorize training instances.", "sentence2": "the high mention coverage will mislead the models to mainly memorize and disambiguate frequent entity names even though they are irregular, but ignore informative context patterns which are useful for generalization over unseen mentions.", "label": "reasoning"}
{"id": "test_1499", "sentence1": "While most graph-structured data has a wide variety of inherent geometric structures, e.g. partially tree-like and partially cyclical, the above studies model the latent structures in a single geometry with a constant curvature, limiting the flexibility of the model to match the hypothetical intrinsic manifold.", "sentence2": "using a product of different constant curvature spaces  might be helpful to match the underlying geometries of temporal knowledge graphs and provide high-quality representations.", "label": "reasoning"}
{"id": "test_1500", "sentence1": "Besides, there is no statistically significant difference in the model performance when using different optimizers, such as Riemannian Adam (RADAM) and Riemannian stochastic gradient descent (RSGD).", "sentence2": "for the model's simplicity, we decide to use RSGD.", "label": "reasoning"}
{"id": "test_1501", "sentence1": "Given the known bias that female characters are portrayed with less agency (Sap et al., 2017), our goal is to re-balance their agency levels to be more on par with those of male characters.", "sentence2": "we revise only the sentences describing female characters to have higher agency, using POWERTRANS-FORMER.", "label": "reasoning"}
{"id": "test_1502", "sentence1": "Meanwhile, in both EURLEX57K and AMAZON13K, the performance of ATTENTION-XML is competitive with both TF-IDF-based PLT-based methods and BIGRU-LWAN, suggesting that the bag-of-words assumption holds in these cases.", "sentence2": "we can fairly assume that word order and global context (longterm dependencies) do not play a drastic role when predicting labels (concepts) on these datasets.", "label": "reasoning"}
{"id": "test_1503", "sentence1": "We simulate a setting where we have not enough information about the biases for training a debiased model, and thus biased examples should be identified automatically.", "sentence2": "we only use the existing challenge test set for each examined task strictly for evaluation and do not use the information about their corresponding bias types during training.", "label": "reasoning"}
{"id": "test_1504", "sentence1": "After the embeddings learning we can get a distribution over all of the subframe labels for each paragraph which is based on the cosine similarity between the embeddings of the paragraph and subframe labels.", "sentence2": "our model combined with the labeled n-grams have the ability to expand the subframe labels to unlabeled text from other domains of the same topics without any human evaluation.", "label": "reasoning"}
{"id": "test_1505", "sentence1": "For each object with M instances in the image, we randomly remove m instances from the image s.t. m \u2208 {0, . . . , M} using polygon annotations from the COCO (Lin et al., 2014) dataset", "sentence2": "for each image, we get multiple masked images, with pixels inside the instance bounding-box removed, as shown in Figure 3.", "label": "reasoning"}
{"id": "test_1506", "sentence1": "However, the use of AL with deep pre-trained models for text classification -and BERT in particular -has so far received surprisingly little consideration.", "sentence2": "while recent papers have demonstrated the value of AL for various deep-learning text classification schemes (Shen et al., 2017; Zhang et al., 2017; Siddhant and Lipton, 2018; Prabhu et al., 2019), the potential of AL combined with BERT is yet to be explored.", "label": "reasoning"}
{"id": "test_1507", "sentence1": "In this setting we assume high-precision heuristics that enable generating a relatively unbiased sample; but in many real-world cases such heuristics may not exist, or are expected to have limited coverage and would not enable sampling at will.", "sentence2": "such heuristics cannot be assumed to yield a large training set, but may nevertheless be used for obtaining a small initial seed in an active learning setting.", "label": "reasoning"}
{"id": "test_1508", "sentence1": "However, unlike the above models, VVMAs focus on the low levels of execution: the VVMA is an architecture that speeds up matrix multiplications.", "sentence2": "it is an efficient model that relates to hardware accelerators directly and it is universal, as matrix multiplication is the dominant computational factor for neural network inference.", "label": "reasoning"}
{"id": "test_1509", "sentence1": "While every neural network requires a certain budget of floating point operations for a target computation, how fast such computations are in practice depends not on the size of this budget but rather on the number of wall clocks needed in order to cover all floating point operations.", "sentence2": "it is important to combine the software and the hardware advances in a co-design manner to optimize an efficient model for the correct metric: wall clocks.", "label": "reasoning"}
{"id": "test_1510", "sentence1": "As the Transformer is already getting noticeable impact in industrial settings, e.g., for machine translation and Web search, there is active research in developing more efficient Transformer architectures (Sanh et al., 2019; Kitaev et al., 2020; Beltagy et al., 2020;Zaheer et al., 2020).", "sentence2": "with each new version of a Transformer architecture, new VVMA experiments would be needed in order to measure the potential improvements in efficiency that VVMA would yield.", "label": "reasoning"}
{"id": "test_1511", "sentence1": "As discussed in Section 2, most existing datasets were crowdsourced with a fixed set of prompts and no taboo constraints, which leads to limited diversity in the data.", "sentence2": "models trained on the data may be brittle, failing when tested on new data in the same domain.", "label": "reasoning"}
{"id": "test_1512", "sentence1": "Following Shah et al. (2018); Rastogi et al. (2019), every grammar production in the simulator is paired with a template whose slots are synchronously expanded.", "sentence2": "each dialog state or system act is associated with a template utterance.", "label": "reasoning"}
{"id": "test_1513", "sentence1": "One observation about the standard decoder is that it has to predict long strings with closing brackets to represent a tree structure in the linearization.", "sentence2": "the total number of decoding LSTM recursions is the number of tree nodes plus the number of non-terminals.", "label": "reasoning"}
{"id": "test_1514", "sentence1": "While TF-IDF based document linking provides a co-occurence-based similarity measure between documents and conversations, there is no guarantee such linking will improve dialog modeling performance.", "sentence2": "we aim to train a linking model such that conditioning on linked documents has a positive effect on dialog modeling performance.", "label": "reasoning"}
{"id": "test_1515", "sentence1": "The reason is that we cannot always rely on expensive human resources to annotate large-scale task-specific labeled data, especially considering the inestimable number of tasks to be explored.", "sentence2": "a reasonable attempt is to map diverse NLP tasks into a common learning problem-solving this common problem equals to solving any downstream NLP tasks, even some tasks that are new or have insufficient annotations.", "label": "reasoning"}
{"id": "test_1516", "sentence1": "Although large-scale pre-trained language models like BERT (Devlin et al., 2019) and RoBERTa (Liu et al., 2019b) have achieved super-human performances on these datasets, there have been concerns raised about these models exploiting idiosyncrasies in the data using tricks like pattern matching (McCoy et al., 2019).", "sentence2": "various stress-testing datasets have been proposed that probe NLI models for simple lexical inferences (Glockner et al., 2018), quantifiers (Geiger et al., 2018), numerical reasoning, antonymy and negation (Naik et al., 2018).", "label": "reasoning"}
{"id": "test_1517", "sentence1": "They show that this instability largely arises from high inter-example similarity, as these datasets typically focus on a particular linguistic phenomenon by leveraging only a handful of patterns.", "sentence2": "following their suggestion, we conduct an instability analysis of CONJNLI by training RoBERTa on MNLI with 10 different seeds (1 to 10) and find that the results on CONJNLI are quite robust to such variations.", "label": "reasoning"}
{"id": "test_1518", "sentence1": "Since BERT converts each word into word pieces, we first propagate the gold SRL tags, which are for each word, to word pieces.", "sentence2": "for a word with multiple word pieces, we assign the tag B-ARG to the first word piece, and the tag I-ARG to the subsequent word pieces.", "label": "reasoning"}
{"id": "test_1519", "sentence1": "It makes words a special case of motif instances, and one can easily construct a similar bipartite graph for words.", "sentence2": "in the rest of this section, we use motif instances to explain our ranking score design.", "label": "reasoning"}
{"id": "test_1520", "sentence1": "Intuitively, a highly label-indicative motif instance would not belong to the seed sets of multiple labels.", "sentence2": "when any motif instance is expanded to seed sets of multiple classes, we stop the expansion of motif instances of the corresponding motif pattern.", "label": "reasoning"}
{"id": "test_1521", "sentence1": "We make the simplifying assumption that all changes in wikiHow's revision history are made for the better and therefore represent needed revisions to the original version of an article.", "sentence2": "we treat all sentences that went through revision in wikiHowToImprove as requiring revision and all unrevised sentences from our extension (see 2.1) as requiring no revision.", "label": "reasoning"}
{"id": "test_1522", "sentence1": "State of the art research for date-time 1 entity extraction from text is task agnostic.", "sentence2": "while the methods proposed in literature perform well for generic date-time extraction from texts, they don't fare as well on task specific date-time entity extraction where only a subset of the date-time entities present in the text are pertinent to solving the task.", "label": "reasoning"}
{"id": "test_1523", "sentence1": "\u201cLet\u2019s schedule for tomorrow. Next month, I plan on taking up Mr Baskerville\u2019s case\u201d Here, the model without Lt generates high at\u0002tention weights for embeddings associated with \u201ctomorrow\u201d, since the localization of the attention weights is much more spread out.", "sentence2": "it also uses the embeddings associated with \"tomorrow\" for predicting the label of \"next month\", and hence, predicts it to be relevant to scheduling when it is not.", "label": "reasoning"}
{"id": "test_1524", "sentence1": "Each resume is manually annotated to its most appropriate CRC position by experts through several rounds of triple annotation to establish guidelines.", "sentence2": "a high Kappa score of 61% is achieved for interannotator agreement.", "label": "reasoning"}
{"id": "test_1525", "sentence1": "At any time, there are various positions posted for the same level from different divisions, cardiology, renal, infectious disease, etc.", "sentence2": "it is common to see resumes from the same applicant applying to several job postings within the same CRC level.", "label": "reasoning"}
{"id": "test_1526", "sentence1": "To the best of our knowledge, no previous study has explicitly focused on this question.", "sentence2": "the goal of this paper is to provide an answer to this question.", "label": "reasoning"}
{"id": "test_1527", "sentence1": "The representations for all mentions are then compared (usually sequentially) and mention pairs judged to be most similar are considered coreferent.", "sentence2": "the mention representation is a key component in modern coreference resolution models.", "label": "reasoning"}
{"id": "test_1528", "sentence1": "The first signal is that the same name can appear multiple times in a text, and these mentions very likely corefer.", "sentence2": "we can train mention representations to be similar for these mentions.", "label": "reasoning"}
{"id": "test_1529", "sentence1": "We do not want to use all mentions in the text since, for most of these, we don't have ground-truth clusters.", "sentence2": "we only consider mentions that contain proper names that appear one or more times.", "label": "reasoning"}
{"id": "test_1530", "sentence1": "The decision of when to stop querying more external articles needs to be made after successive evaluations of the candidate answers.", "sentence2": "the decision making process is inherently sequential.", "label": "reasoning"}
{"id": "test_1531", "sentence1": "Moreover, the samples show that the generation process is more sophisticated than just a trivial path flattening (i.e., merging text from all edge parts followed by minimal edits).", "sentence2": "the proposed approach can eventually become a part of a more sophisticated system converting graphs to a coherent textual story and vice versa.", "label": "reasoning"}
{"id": "test_1532", "sentence1": "Entities, relationship are all sequences of tokens that need to be generated properly, which does not fit well in the conventional KB completion evaluation framework.", "sentence2": "we define a new meaningful commonsense KB completion task for generative models, and present the challenges that arise from it.", "label": "reasoning"}
{"id": "test_1533", "sentence1": "Such automatic alignment between knowledge graph and texts provides distant supervision (Mintz et al., 2009) for pre-training but it is bound to be noisy.", "sentence2": "we design a selection strategy and only retain plausible alignments with high semantic overlap.", "label": "reasoning"}
{"id": "test_1534", "sentence1": "Apparently, these pairs cannot serve our goal to build a knowledge-grounded language model.", "sentence2": "we propose a data selection step to suppress the noise and filter out the data pairs of our interests.", "label": "reasoning"}
{"id": "test_1535", "sentence1": "We verify that there is zero RDF triple seen during pre-training though 31% entities are seen.", "sentence2": "we can confirm the comparison with other baselines is still fair given no information from test/dev is leaked.", "label": "reasoning"}
{"id": "test_1536", "sentence1": "Unlike the previous two human-annotated datasets from different domains, WikiBio is also scraped from Wikipedia.", "sentence2": "we filtered out the instances of KGTEXT from the first paragraph of the biography domain to ensure no overlap or leakage about Wikibio's dev/test set.", "label": "reasoning"}
{"id": "test_1537", "sentence1": "However, supervising the copy attention does not have much influence on the performance.", "sentence2": "in the following experiments, we will run experiments for both encoding schemes with a copy mechanism without copy loss.", "label": "reasoning"}
{"id": "test_1538", "sentence1": "In a human-written document, subsequent text often refers back to entities and tokens present earlier in the preceding text.", "sentence2": "it would increase coherence of text generated in downstream to incorporate the copy mechanism into pre-training on an unlabeled corpus.", "label": "reasoning"}
{"id": "test_1539", "sentence1": "For example, in Figure 1, one can observe that randomly sampling actions from the game vocabulary leads to several inadmissible ones like 'north a' or 'eat troll with egg'.", "sentence2": "narrowing down the action space to admissible actions requires both syntactic and semantic knowledge, making it challenging for current systems.", "label": "reasoning"}
{"id": "test_1540", "sentence1": "The Jericho framework implements an admissible action handicap by enumerating all combinations of game verbs and objects at each state, and testing each action's admissibility by accessing the underlying simulator states and load-and-save functions.", "sentence2": "the handicap runs no faster than a GPT-2 inference pass, and could in fact be unavailable for games outside Jericho.", "label": "reasoning"}
{"id": "test_1541", "sentence1": "In the MSCOCO validation set, 'man', 'elephant', and 'river' have more exposure, while 'traffic' and 'highway' are less mentioned.", "sentence2": "the first group of references has a much higher consensus CIDEr score than the second group.", "label": "reasoning"}
{"id": "test_1542", "sentence1": " QA systems accurately answer simpler, related questions such as \u201cWhat profes\u0002sion does H. L. Mencken have?\u201d and \u201cWho was Al\u0002bert Camus?\u201d (Petrochuk and Zettlemoyer, 2018).", "sentence2": "a promising strategy to answer hard questions is divide-and-conquer: decompose a hard question into simpler sub-questions, answer the sub-questions with a QA system, and recompose the resulting answers into a final answer, as shown in Figure 1.", "label": "reasoning"}
{"id": "test_1543", "sentence1": "Second, we train a decomposition model on the mined data with unsupervised sequence-to-sequence learning, allowing ONUS to improve over pseudo-decompositions.", "sentence2": "we are able to train a large transformer model to generate decompositions, surpassing the fluency of heuristic/extractive decompositions.", "label": "reasoning"}
{"id": "test_1544", "sentence1": "This format makes it difficult to determine stance in the typical topic-phrase (pro/con/neutral) setting with respect to a single topic, as opposed to a position statement (see Topic and ARC Stance columns respectively, Table 2).", "sentence2": "we collect annotations on both topic and stance, using the ARC data as a starting point.", "label": "reasoning"}
{"id": "test_1545", "sentence1": "However, prior work used static word embeddings and we want to take advantage of contextual emebddings.", "sentence2": "we embed a document and topic jointly using BERT (Devlin et al., 2019).", "label": "reasoning"}
{"id": "test_1546", "sentence1": "For both stance labels and models, performance increases when the majority sentiment polarity agrees with the stance label (M + for pro, M for con).", "sentence2": "we investigate how susceptible both models are to changes in sentiment.", "label": "reasoning"}
{"id": "test_1547", "sentence1": "Given the limited amount of labeled data, we first want to augment our dataset by labeling the unlabeled data as well.", "sentence2": "we have a two step approach: 1. Build a model to resolve ambiguous time terms (AM versus PM) and label the unlabeled data. 2. Train a model for time of day prediction by hour using the augmented dataset ", "label": "reasoning"}
{"id": "test_1548", "sentence1": "These features do not exist in the unlabeled training set, to ensure the models learn to identify the proper AM/PM label without cheating.", "sentence2": "we replace all the time phrases with the same special token.", "label": "reasoning"}
{"id": "test_1549", "sentence1": "While the dataset does not have the publication date of the book in the metadata, we were able to access the authors and the years the author was alive.", "sentence2": "we created groupings of our data by time period based on the year of the author's birth.", "label": "reasoning"}
{"id": "test_1550", "sentence1": "However, since the semantic representation used by SCAN only covers a small subset of English grammar, SCAN does not enable testing various systematic linguistic abstractions that humans are known to make (e.g., verb argument structure alternation).", "sentence2": "it is unclear whether progress on SCAN would generalize to natural language.", "label": "reasoning"}
{"id": "test_1551", "sentence1": "Our grammar does not generate VP-modifying PPs (the only PP verbal dependents are recipient to-phrases, which are always arguments rather than modifiers).", "sentence2": "all PP modifiers in our dataset should strictly have an NP-attachment reading, although for human readers VP-attachment readings could sometimes be more prominent based on the lexical content of the sentences.", "label": "reasoning"}
{"id": "test_1552", "sentence1": "Note that as demonstrated by Reimers and Gurevych (2019), averaging context embeddings consistently outperforms the [CLS] embedding.", "sentence2": "unless mentioned otherwise, we use average of context embeddings as BERT sentence embeddings and do not distinguish them in the rest of the paper.", "label": "reasoning"}
{"id": "test_1553", "sentence1": "Note that co-occurrence statistics is a typical tool to deal with \u201csemantics\u201d in a computational way \u2014 specifically, PMI is a common mathematical sur\u0002rogate to approximate word-level semantic simi\u0002larity (Levy and Goldberg, 2014; Ethayarajh et al., 2019).", "sentence2": "roughly speaking, it is semantically meaningful to compute the dot product between a context embedding and a word embedding.", "label": "reasoning"}
{"id": "test_1554", "sentence1": "This is a common problem in the context of representation learining (Rezende and Viola, 2018; Li et al., 2019;Ghosh et al., 2020).", "sentence2": "the resulted sentence embeddings can locate in the poorly-defined areas, and the induced similarity can be problematic.", "label": "reasoning"}
{"id": "test_1555", "sentence1": "BERT embeddings may fail in such cases.", "sentence2": "we argue that the lexical proximity of BERT sentence embeddings is excessive, and can spoil their induced semantic similarity.", "label": "reasoning"}
{"id": "test_1556", "sentence1": "Concretely, the likelihood training pays little attention to the top ranks in terms of the target token probabilities (Welleck et al., 2020), or maximizing likelihood itself does not adequately reflect human language processing (Holtzman et al., 2019).", "sentence2": "with the maximum likelihoodbased training, models learn to produce tokens frequently appearing in the data more often.", "label": "reasoning"}
{"id": "test_1557", "sentence1": "The more uniform a label distribution is, the less likely decision boundaries are biased in favor of frequent classes.", "sentence2": "we aim to maximize the degree of uniformity of frequency distributions for both (i) tokens within each class and (ii) classes themselves (i.e., the sum of token frequencies within each class), to avoid the class imbalance problem (Buda et al., 2018) over the course of training.", "label": "reasoning"}
{"id": "test_1558", "sentence1": "Tokens in lyrics show a distribution largely different from general articles; for instance, repeated phrases are abundant in lyrics.", "sentence2": "it provides an additional unique angle for model evaluations and comparisons.", "label": "reasoning"}
{"id": "test_1559", "sentence1": "We attribute this observation to the distinctive characteristics of lyrics, in which the same phrases are rhythmically repeated throughout the songs in the form of chorus or hook.", "sentence2": "for lyrics dataset, forcing models to discourage reusing previously used tokens may adversely affect the likelihood of the generated texts.", "label": "reasoning"}
{"id": "test_1560", "sentence1": "The potential reason may be the lack of topics (i.e., keywords) in the model response, as illustrated in the graph that only contains context-topic nodes.", "sentence2": "the graph reasoning module in our GRADE fails to induce an appropriate graph representation, which harms the coherence scoring.", "label": "reasoning"}
{"id": "test_1561", "sentence1": "Unlike recent language representation models, BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers.", "sentence2": "the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications.", "label": "reasoning"}
{"id": "test_1562", "sentence1": "From the perspective of data collection for studying a particular phenomenon, TORQUE has done more on defining the task and developing a scalable crowdsourcing pipeline.", "sentence2": "tORQUE is also much larger than QA-tempEval and the annotation pipeline of tORQUE can be easily adopted to collect even more data.", "label": "reasoning"}
{"id": "test_1563", "sentence1": "Despite the progress on the encoder side, the current stateof-the-art models use a rather standard decoder: it functions as a language model, where each word is generated given only the previous words.", "sentence2": "one limitation of such decoders is that they tend to produce fluent sentences that may not retain the meaning of input AMRs.", "label": "reasoning"}
{"id": "test_1564", "sentence1": "However, this dataset does not explicitly state the topics of individual poems.", "sentence2": "we automatically predict a topic for each poem with the help of our topic prediction model, which will be described in Subsection 3.3.", "label": "reasoning"}
{"id": "test_1565", "sentence1": "Suprisingly, however, 12 out of 20 and 9 out of 20 poems are recognized correctly for know and unknown words, respectively.", "sentence2": "our model works well even for topics it has not seen during training.", "label": "reasoning"}
{"id": "test_1566", "sentence1": "It is noteworthy that the text encoder part actually dominates the overall cost.", "sentence2": "the gap between our model and the RGCN are further narrowed if we consider the cost of the entire model.", "label": "reasoning"}
{"id": "test_1567", "sentence1": "We compute the sum of the vector representations weighted by the probabilities, and then input it into the downstream model.", "sentence2": "opTok becomes to assign a high probability to the tokenization which improves the performance of the downstream task.", "label": "reasoning"}
{"id": "test_1568", "sentence1": "The goal of this study is to improve the performance of downstream tasks by optimizing the tokenization.", "sentence2": "we evaluate OpTok on various text classification tasks to validate its effect.", "label": "reasoning"}
{"id": "test_1569", "sentence1": "Moreover, many studies have reported that training models with a stochastic tokenization lead to a better performance of the downstream tasks than training a model using deterministic tokenization (Kudo, 2018;Hiraoka et al., 2019;Provilkov et al., 2019).", "sentence2": "we trained the encoder and downstream model using subword regularization provided by SentencePiece.", "label": "reasoning"}
{"id": "test_1570", "sentence1": "It is still unclear whether the optimized tokenization leads to the improvement described in Section 3.3 because we trained all components simultaneously.", "sentence2": "we investigate whether the optimized tokenization contributes to the improvement of the performance on the downstream task.", "label": "reasoning"}
{"id": "test_1571", "sentence1": "Sarcasm is prevalent in today's social media platforms, and it can completely flip the polarity of sentiment or opinion.", "sentence2": "an effective sarcasm detector is beneficial to applications like sentiment analysis, opinion mining (Pang and Lee, 2007), and other tasks that require people's real sentiment.", "label": "reasoning"}
{"id": "test_1572", "sentence1": "Consider the given examples in Figure 1; people can not recognize sarcasm merely from text unless they find the contradiction between text and images.", "sentence2": "capturing the incongruity between modalities is significant for multi-modal sarcasm detection.", "label": "reasoning"}
{"id": "test_1573", "sentence1": "Tay et al. (2018) argues that the words that contribute to the incongruity (usu\u0002ally accompany with a high attention value) should be highlighted.", "sentence2": "a more discriminative pooling operator like max-pooling is desirable in our case.", "label": "reasoning"}
{"id": "test_1574", "sentence1": "Obviously, the methods based on text modality achieve better performance than the method based on image modality.", "sentence2": "text information is more useful than image information for sarcasm detection.", "label": "reasoning"}
{"id": "test_1575", "sentence1": "Our model is designed to capture the incongruity information.", "sentence2": "incongruous regions on the images are more likely to be attended by our model.", "label": "reasoning"}
{"id": "test_1576", "sentence1": "In addition, we find that our model might struggle in those instances requiring external knowledge, such as a speaker's facial gesture or contextual information.", "sentence2": "external information is also essential for sarcasm detection.", "label": "reasoning"}
{"id": "test_1577", "sentence1": "Different users usually prefer different news information.", "sentence2": "personalized news recommendation, which aims to display news articles to users based on their personal interest, is a useful technique to improve user experience and has been widely used in many online news services (Wu et al., 2019b).", "label": "reasoning"}
{"id": "test_1578", "sentence1": "Besides, these methods represent items using their IDs, and are difficult to handle new items since many news articles are posted every day which are all new items.", "sentence2": "these federated learning based recommendation methods have their inherent drawbacks, and are not suitable for news recommendation.", "label": "reasoning"}
{"id": "test_1579", "sentence1": "According to the data processing inequality (McMahan et al., 2017), these gradients never contain more private information than the raw user behaviors, and usually contain much less information (McMahan et al., 2017).", "sentence2": "the user privacy can be better protected compared with the centralized storage of user behavior data as did in existing news recommendation methods.", "label": "reasoning"}
{"id": "test_1580", "sentence1": "Moreover, different from these existing news recommendation methods which are all trained on centralized storage of user behavior data, in our FedNewsRec the user behavior data is stored on local user devices and is never uploaded.", "sentence2": "our method can train accurate news recommendation model and meanwhile better protect user privacy.", "label": "reasoning"}
{"id": "test_1581", "sentence1": "Luckily, the gap between the performance of FedNewsRec and CenNewsRec is not very big.", "sentence2": "our FedNewsRec method can achieve much better privacy protection at the cost of acceptable performance decline.", "label": "reasoning"}
{"id": "test_1582", "sentence1": "However, human ground-truth construction for summarization is time-consuming and laborintensive.", "sentence2": "a more flexible summary generation framework could minimize manual labor and generate useful summaries more efficiently.", "label": "reasoning"}
{"id": "test_1583", "sentence1": "Each year, new shared tasks and datasets are proposed, ranging from classics like sentiment analysis to irony detection or emoji prediction.", "sentence2": "it is unclear what the current state of the art is, as there is no standardized evaluation protocol, neither a strong set of baselines trained on such domainspecific data.", "label": "reasoning"}
{"id": "test_1584", "sentence1": "However, we acknowledge that other important tasks may need to be evaluated differently.", "sentence2": "for future work we would like to include more tasks in the context of social media NLP research.", "label": "reasoning"}
{"id": "test_1585", "sentence1": "Although there are traditional non-neural parsers using n-grams as features to improve parsing (Sagae and Lavie, 2005;Pitler et al., 2010), they are limited in treating them euqally without learning their weights.", "sentence2": "unimportant n-grams may deliver misleading information and lead to wrong predictions.", "label": "reasoning"}
{"id": "test_1586", "sentence1": "However, there are cases that long n-grams can play an important role in parsing when they carry useful context and boundary information.", "sentence2": "we extend the span attention with a category mechanism (namely, categorical span attention) by grouping n-grams based on their lengths and weighting them within each category.", "label": "reasoning"}
{"id": "test_1587", "sentence1": "It is possible for the programmer to output illegal actions that do not follow the predefined action template (e.g., actions with missing a position component), especially when the programmer is not fully trained.", "sentence2": "the interpreter checks if an action is valid and skips invalid actions by returning the input sequence.", "label": "reasoning"}
{"id": "test_1588", "sentence1": "We first experiment with N = 10, L = 5, and D = 10K, but all methods can reach a nearperfect sequence accuracy (see Figure 3).", "sentence2": "we adjust N from 10 to 100 to make the task more challenging.", "label": "reasoning"}
{"id": "test_1589", "sentence1": "Note that online training is not part of the standard training procedure for End2end and Tagging, however, we use online training with End2end and Tagging for the sake of a fair comparison.", "sentence2": "for End2end and Tagging, the online training acts like a data augmentation technique, providing more data points for training.", "label": "reasoning"}
{"id": "test_1590", "sentence1": "To estimate human performance within each metric, we treat each reference sentence in dev/test data as a \"system prediction\" to be compared with all other references, which is equivalent to compute inter-annotator agreement within each metric.", "sentence2": "systems that have better generative ability than average crowd-workers should exceed this.", "label": "reasoning"}
{"id": "test_1591", "sentence1": "Moreover, considering the fact that summarization is not an easy task even for people, reliable human-labeled data are also difficult to obtain.", "sentence2": "several unsupervised summarization approaches have been proposed, which do not require reference summaries for the target domain.", "label": "reasoning"}
{"id": "test_1592", "sentence1": "Taking advantage of corpora with billions of tokens, the pretrained language models learn universal and robust representations for various semantic structures and linguistic relationships.", "sentence2": "pretrained models have been widely used with considerable success in applications such as question answering (Zhu et al., 2018), sentiment analysis (Peters et al., 2018) and passage reranking (Nogueira and Cho, 2019).", "label": "reasoning"}
{"id": "test_1593", "sentence1": "Gestures can be triggered at the sub-word level; for example, by a change of intonation in acoustics.", "sentence2": "it is important to have sub-word level alignment between language and acoustics to generate the freeform gestures.", "label": "reasoning"}
{"id": "test_1594", "sentence1": "In these existing methods, their user models are trained in an end-to-end way using the labeled data of target task, which can only capture task-specific information.", "sentence2": "in this paper we propose to pre-train user models from unlabeled user behavior data via self-supervision, which can exploit universal user information encoded in user behaviors.", "label": "reasoning"}
{"id": "test_1595", "sentence1": "We simply use the element-wise average operation for f .", "sentence2": "if the segmentation of the word changes, the corresponding embedding and gradient vector will change accordingly.", "label": "reasoning"}
{"id": "test_1596", "sentence1": "However, n-best decoding is n-times time consuming compared to the standard decoding method.", "sentence2": "we only use 1-best decoding which is the standard decoding framework for evaluating the translation quality.", "label": "reasoning"}
{"id": "test_1597", "sentence1": "Proposition 1 shows that the objective is maximized when the mutual information is maximized to I max .", "sentence2": "maximizing the mutual information by other means can help side-step this issue.", "label": "reasoning"}
{"id": "test_1598", "sentence1": "In the biomedical domain, there exist several entities, such as genes, chemicals, and diseases, that are closely related to each other.", "sentence2": "extracting the relationships among these entities is critical for biomedical research, particularly in fields such as construction of a knowledge base or drug development.", "label": "reasoning"}
{"id": "test_1599", "sentence1": "In other words, the output probability of the over-confident model does not indicate how uncertain the input example is, even if its classification performance is high.", "sentence2": "several approaches, called \"calibration\" techniques, have been applied to several domains that require high reliability, such as autonomous driving and medical diagnosis (Guo et al., 2017;Jiang et al., 2012).", "label": "reasoning"}
{"id": "test_1600", "sentence1": "When a certain level of performance is guaranteed, unlabeled data predicted with a high probability in the classifier is likely to have a corresponding label.", "sentence2": "such data can be used as pseudolabeled data, even if it contains slight noise.", "label": "reasoning"}
{"id": "test_1601", "sentence1": "Moreover, we applied self-training on our model to augment the training data and boost the performance, as our model is well-calibrated; it returned reliable output probabilities.", "sentence2": "our model outperformed the other chemical-protein relationship extraction models and achieved state-of-the-art performance regarding the Biocreative VI ChemProt task.", "label": "reasoning"}
{"id": "test_1602", "sentence1": "As a meeting consists of utterances from different participants, it forms a natural multi-turn hierarchy.", "sentence2": "the hierarchical structure carries out both token-level understanding within each turn and turn-level understanding across the whole meeting.", "label": "reasoning"}
{"id": "test_1603", "sentence1": "As the canonical transformer has the attention mechanism, its computational complexity is quadratic in the input length.", "sentence2": "it struggles to handle very long sequences, e.g.  5,000 tokens.", "label": "reasoning"}
{"id": "test_1604", "sentence1": "This reconstructor quantifies the clinical correctness of the reports.", "sentence2": "we can estimate the correctness of reports without rule-based annotators.", "label": "reasoning"}
{"id": "test_1605", "sentence1": "To train the language model, RL with only CRS and ROUGE as a reward is insufficient.", "sentence2": "we use the cross-entropy loss to generate fluent sentences.", "label": "reasoning"}
{"id": "test_1606", "sentence1": "This evaluation is intended to assess whether our proposed method is also applicable to the MIMIC-CXR dataset or not.", "sentence2": "in this evaluation, we focus only on the data-to-text module.", "label": "reasoning"}
{"id": "test_1607", "sentence1": "To the best of our knowledge, there are no publicly available entity typing datasets in the medical domain.", "sentence2": "three entity typing datasets are constructed from the corresponding medical named entity recognition datasets.", "label": "reasoning"}
{"id": "test_1608", "sentence1": "Long tokens are relatively common in the medical domain, and these tokens will be split into short pieces when a domain-independent vocabulary is used, which will cause an overgeneralization of lexical features.", "sentence2": "a medical vocabulary generated by the PubMed corpus can be introduced into BERT-MK in the following work.", "label": "reasoning"}
{"id": "test_1609", "sentence1": "The appropriate responses to the user queries are highly dependent on the visual information pertaining to the different aspects of the various images in the conversation.", "sentence2": "it is natural to conclude that a conversational agent would be more effective if the visual information were part of its underlying conversational model.", "label": "reasoning"}
{"id": "test_1610", "sentence1": "We come up with the following two top-level prin\u0002ciples for domain selection after closer review and extensive discussions: (i). it encompasses a broad group of task-oriented frameworks used by indus\u0002tries/service providers and is likely to build user interfaces; (ii). for deeper comprehension and clarification of the services, the domains need visual details.", "sentence2": "we choose to curate conversations belonging to three distinct domains in our newly established large-scale MDMMD dataset1, namely restaurants, electronics, and furniture.", "label": "reasoning"}
{"id": "test_1611", "sentence1": "For example, the cuisine is the aspect category but Chinese is the aspect term that according to the user could change into Mexican, Japanese in the remaining utterances of a particular dialogue.", "sentence2": "the labeling of both the aspect category and aspect term is essential for the generation of aspect guided responses to learn the subtle differences between the different aspect terms within the same category.", "label": "reasoning"}
{"id": "test_1612", "sentence1": "Conversely, the larger the L, the closer we are to sampling strategies.", "sentence2": "by tuning L, it is possible to combine the advantages of both sampling and likelihood-based strategies.", "label": "reasoning"}
{"id": "test_1613", "sentence1": "This is also the basis on which we can continuously expand BERT's ER-Length and continue to benefit.", "sentence2": "for a particular dataset, when we set the ERLength of the BERT, letting it exceed more data's DLength can always bring more improvements.", "label": "reasoning"}
{"id": "test_1614", "sentence1": "In the training phase, the current triplet prediction relies on the gold-standard labels of the previous triplets, while in the testing phase, the current triplet prediction relies on the model prediction of the previous triplets, which can be different from the gold-standard labels.", "sentence2": "in the test phase, a skewed prediction will further deviate the predictions of the follow-up triplets; if the decoding length is large, the discrepancy from the gold-standard labels would be further accumulated.", "label": "reasoning"}
{"id": "test_1615", "sentence1": "For the sequence labeling tasks, because the data is relatively small and confined to a very specific domain (chat log from online apparel shops), we set a small vocabulary size of 500 for all the methods except NumAsTok and set the vocabulary size of NumAsTok to 550 to ensure that different methods have similar numbers of parameters for word embedding training.", "sentence2": "our methods have (500 + |P|) \u00d7 D parameters for word embedding training and Nu-mAsTok has 550 \u00d7 D parameters, where P is the prototype set, whose size is typically smaller than 50, and D is the embedding dimension.", "label": "reasoning"}
{"id": "test_1616", "sentence1": "However, running these models on edge-devices, faces memory and latency issues due to limitations of the hardware.", "sentence2": "there has been considerable interest towards research in reducing the memory footprint and faster inference speed for these models (Sainath et al., 2013;Acharya et al., 2019;Shi and Yu, 2018;Jegou et al., 2010;Chen et al., 2018;Winata et al., 2019).", "label": "reasoning"}
{"id": "test_1617", "sentence1": "In practice, state-of-the-art NLP models (Vaswani et al., 2017;Lioutas and Guo, 2020) have shown better performance with parameter sharing between the two (Press and Wolf, 2017).", "sentence2": "there is a need for an exhaustive analysis of various embedding compression techniques, with parameter sharing.", "label": "reasoning"}
{"id": "test_1618", "sentence1": "Lastly, embedding compression models not based on linear SVD (Khrulkov et al., 2019;Shi and Yu, 2018) require the reconstruction of the entire embedding matrix or additional computations, when used at the output-layer.", "sentence2": "during runtime, the model either uses the same amount of memory as the uncompressed model or pays a higher computation cost.", "label": "reasoning"}
{"id": "test_1619", "sentence1": "The consequence would be loss of information on words not seen during training and loss of generalization performance.", "sentence2": "adding a loss for embedding reconstruction helps in grounding the embedding and not lose a lot of information.", "label": "reasoning"}
{"id": "test_1620", "sentence1": "Based on on (Chen et al., 2015b; Shao et al., 2017; Zhang et al., 2018), n-gram features are of great benefit to Chinese word segmentation and POS tagging tasks.", "sentence2": "we use unigram and bigram embeddings for our models.", "label": "reasoning"}
{"id": "test_1621", "sentence1": "Each character can directly attend the criterion-token to be aware of the target criterion.", "sentence2": "we can use a single model to produce different segmented results for different criteria.", "label": "reasoning"}
{"id": "test_1622", "sentence1": "In this work, we only adopt the vanilla Transformer encoder since we just want to utilize its selfattention mechanism to model the criterion-aware context representation for each character neatly.", "sentence2": "it is promising for future work to look for the more effective adapted Transformer encoder for CWS task or to utilize the pre-trained models (Qiu et al., 2020), such as BERT-based MCCWS (Ke et al., 2020)", "label": "reasoning"}
{"id": "test_1623", "sentence1": "However as we show here - existing works are not optimized for dealing with pairs (or tuples) of texts.", "sentence2": "they are either not scalable or demonstrate subpar performance.", "label": "reasoning"}
{"id": "test_1624", "sentence1": "For identity-hate, overlap with toxic is 1302/1405.", "sentence2": "in this paper, we use the term toxic more generally, subsuming threat and identity-hate as particular types of toxic speech.", "label": "reasoning"}
{"id": "test_1625", "sentence1": "The pre-trained models are in principle already complete table entailment predictors.", "sentence2": "it is interesting to look at their accuracy on the TABFACT evaluation set before fine-tuning them.", "label": "reasoning"}
{"id": "test_1626", "sentence1": "But in this sentence, a human is able to reason its label to LOCATION easily by recognizing the contextual phrase \"went to\" or \"by car\".", "sentence2": "contextual information is crucial to improve model robustness in context level.", "label": "reasoning"}
{"id": "test_1627", "sentence1": "Here, replacing with similar words is more likely to produce valid natural language sentences and thus they should have higher probability during replacement.", "sentence2": "instead of getting a random replacement word from the full vocabulary, a word similarity based replacement is proposed and applied here.", "label": "reasoning"}
{"id": "test_1628", "sentence1": "In addition, frequent substitution with extremely different words is not ideal either since it is not likely to produce reasonable sentences.", "sentence2": "we want to make the probability distribution of sampling substitutes to focus more on the words which share some similarities with the original words but not far-away.", "label": "reasoning"}
{"id": "test_1629", "sentence1": "Though we keep the semantic latent variable, z s , and switch the gender latent variable, z g , to generate the gender-counterfactual word embedding, their concatenation during decoding can be vulnerable to the semantic information changes because of variances in the individual latent variables.", "sentence2": "we constrain that the reconstructed word embedding with the counterfactual gender latent, w cf , differs only in the gender information from w n , which is the reconstructed word embedding with the original gender latent.", "label": "reasoning"}
{"id": "test_1630", "sentence1": "Arguments written in the TL provide a more realistic evaluation set than translated texts, specifically for tasks where labels are not well-preserved across automatic translation.", "sentence2": "we created a new multilingual evaluation set by collecting arguments in all 5 languages (ES, FR, IT, DE, and NL) for all the 15 topics of the ArgsEN test set, using the Appen 5 crowdsourcing platform.", "label": "reasoning"}
{"id": "test_1631", "sentence1": "The results showed that many of the annotators labeled a vast majority (>80%) of the arguments as high-quality, even though they were instructed to consider only half as such.", "sentence2": "only those labeling \u2264 80% of arguments as highquality were allowed further work.", "label": "reasoning"}
{"id": "test_1632", "sentence1": "Previous approaches typically apply only a single round of attention focusing on simple semantic information In our ADE detection task, instead, key elements of the sentence can be linked to multiple categories of task-specific semantic information of the named entities (ADE, Drug, Indication, Severity, Dose etc.).", "sentence2": "single attention is insufficient in exploring this multi-aspect information and consequently risks losing important cues.", "label": "reasoning"}
{"id": "test_1633", "sentence1": "To reduce the word annotation burden, we are interested in understanding whether a word classifier trained on one domain can be applied in another.", "sentence2": "we measure crossdomain accuracy, e.g., by fitting the word classifier on IMDB dataset and evaluating on Kindle dataset.", "label": "reasoning"}
{"id": "test_1634", "sentence1": "However, parsing with HRGs is not practical due to its complexity and large number of possible derivations per graph (Groschwitz et al., 2015).", "sentence2": "work has looked at ways of constraining the space of possible derivations, usually in the form of align-1 See Gilroy (2019) for an extensive review of the issue.", "label": "reasoning"}
{"id": "test_1635", "sentence1": "So far, the generalization ability of current summarization systems when transferring to new datasets still remains unclear, which poses a significant challenge to design a reliable system in realistic scenarios.", "sentence2": "in this work, we take a closer look at the effect of model architectures on cross-dataset generalization setting.", "label": "reasoning"}
{"id": "test_1636", "sentence1": "Despite recent impressive results on diverse summarization datasets, modern summarization systems mainly focus on extensive in-dataset architecture engineering while ignore the generalization ability which is indispensable when systems are required to process samples from new datasets or domains.", "sentence2": "instead of evaluating the quality of summarization system solely based on one dataset, we introduce cross-dataset evaluation (a summarizer (e.g., L2L) trained on one dataset (e.g., CNNDM) will be evaluated on a range of other datasets (e.g., XSUM)).", "label": "reasoning"}
{"id": "test_1637", "sentence1": "When served as test set, such dataset brings great challenge for BERT match to correctly rank the can-didate summaries while it provides more training signals when served as training set.", "sentence2": "the in-dataset (Bigpatent b) trained model obtain much higher score compared with cross-dataset models which trained from other datasets and cause lower stableness.", "label": "reasoning"}
{"id": "test_1638", "sentence1": "While the authors' analysis suggested the domains were similar enough to justify transfer attempts, only limited post-hoc analysis of the data platform effect was carried out.", "sentence2": "it remains unclear to what extent the annotation methodologies as opposed to platform effects (or other confounds) caused the degradation.", "label": "reasoning"}
{"id": "test_1639", "sentence1": "Traditionally, different feature vocabularies account for domain transfer loss (Serra et al., 2017;Chen and Gomes, 2019;Stojanov et al., 2019).", "sentence2": "we hypothesize that limited feature overlap and poor vocabulary alignment across datasets could hinder cross-domain generalization.", "label": "reasoning"}
{"id": "test_1640", "sentence1": "On the contrary, the recently proposed VizWiz dataset (Gurari et al., 2018) was collected from blind people taking photos and asking questions about those photos.", "sentence2": "the images in VizWiz are often of poor quality, and questions are more conversational with some questions might even be unanswerable due to the poor quality of the images.", "label": "reasoning"}
{"id": "test_1641", "sentence1": "A natural way of verifying the instruction sets from Stage 1 is to have new workers follow them (Chen et al., 2019).", "sentence2": "during Stage 2 Verification, a new worker is placed in the environment encountered by the Stage 1 worker and is provided with the NL instructions that were written by that Stage 1 worker.", "label": "reasoning"}
{"id": "test_1642", "sentence1": "As shown in Figure 9, the score of rPOD is decreased according to the placement error (the Manhattan distance) exponentially.", "sentence2": "to score high in the rPOD metric, agents should place the target objects as close to the target place as possible.", "label": "reasoning"}
{"id": "test_1643", "sentence1": "Moreover, scoring all code snippets can be computationally inefficient in practice.", "sentence2": "we use the method of Yang et al. (2019) to first uniformly sample a subset of data, whose size is much smaller than the entire training set size, and then perform adversarial sampling on this subset.", "label": "reasoning"}
{"id": "test_1644", "sentence1": "KERMIT (Chan et al., 2019) further simplified the Insertion Transformer model by removing the encoder and only having a decoder stack (Vaswani et al., 2017), by concatenating the original input and output sequence as one single sequence and optimizing over all possible factorizations.", "sentence2": "KER\u0002MIT is able to model the joint p(x, y), condition\u0002als p(x | y), p(y | x), as well as the marginals p(x), p(y).", "label": "reasoning"}
{"id": "test_1645", "sentence1": "Although promising results are obtained, existing models are limited in regarding extra features as gold references and directly concatenate them with word embeddings.", "sentence2": "such features are not distinguished and separately treated when they are used in those NER models, where the noise in the extra features (e.g., inaccurate POS tagging results) may hurt model performance.", "label": "reasoning"}
{"id": "test_1646", "sentence1": "Therefore, such features are not distinguished and separately treated when they are used in those NER models, where the noise in the extra features (e.g., inaccurate POS tagging results) may hurt model performance.", "sentence2": "it is still a challenge to find an appropriate way to incorporate external information into neural models for NER.", "label": "reasoning"}
{"id": "test_1647", "sentence1": "For example, as illustrated in Figure 2(c), for \"Salt\", its context features are \"Salt\" and \"City\" (the governor of \"Salt\"), and their corresponding dependency information are \"Salt compound\" and \"City root\".", "sentence2": "for each type of syntactic inforamtion, we obtain a list of context features and a list of syntactic information instances, which are modeled by a KVMN module to enhance input text representation and thus improve model performance.", "label": "reasoning"}
{"id": "test_1648", "sentence1": "Second, on the contrary, SA is able to improve NER with integrating multiple types of syntactic information, where consistent improvements are observed among all datasets when more types of syntactic information are incorporated.", "sentence2": "the best results are achieved by the model using all types of syntactic information.", "label": "reasoning"}
{"id": "test_1649", "sentence1": "Later, the syntax attention ensures that the constituent information should be emphasized and the gate mechanism also tends to use syntax for this input with higher weights.", "sentence2": "this case clearly illustrates the contribution of each component in our attentive ensemble of syntactic information.", "label": "reasoning"}
{"id": "test_1650", "sentence1": "However, to enhance NER, it is straightforward to incorporate more knowledge to it than only modeling from contexts.", "sentence2": "additional resources such as knowledge base (Kazama and Torisawa, 2008; Tkachenko and Simanovsky, 2012; Seyler et al., 2018; Liu et al., 2019b,a; Gui et al., 2019b,a) and syntactic information (McCallum, 2003; Mohit and Hwa, 2005; Finkel and Manning, 2009; Li et al., 2017; Luo et al., 2018; Cetoli et al., 2018; Jie and Lu, 2019) are applied in previous studies", "label": "reasoning"}
{"id": "test_1651", "sentence1": "Processing of legal contracts requires significant human resources due to the complexity of documents, the expertise required and the consequences at stake.", "sentence2": "a lot of effort has been made to automate such tasks in order to limit processing costs-notice that law was one of the first areas where electronic information retrieval systems were adopted (Maxwell and Schafer, 2008).", "label": "reasoning"}
{"id": "test_1652", "sentence1": "One important advantage over static embeddings is the fact that every occurrence of the same word is assigned a different embedding vector based on the context in which the word is used.", "sentence2": "it is much easier to address issues arising from pre-trained static embeddings (e.g., taking into consideration polysemy of words).", "label": "reasoning"}
{"id": "test_1653", "sentence1": "Our aim is for explanations to better communicate the task model's reasoning process, without adopting the trivial solution, i.e., directly stating its output.", "sentence2": "while we optimize explanations for simulatability, we also penalize label leakage, which we formalize below.", "label": "reasoning"}
{"id": "test_1654", "sentence1": "We also try to incorporate the head information in con\u0002stituent syntactic training process, namely max-margin loss for both two scores, but it makes the training process become more complex and unstable.", "sentence2": "we employ a parameter to balance two different scores in joint decoder which is easily implemented with better performance.", "label": "reasoning"}
{"id": "test_1655", "sentence1": "Overall, joint semantic and constituent syntactic parsing achieve relatively better SRL results than the other settings.", "sentence2": "the rest of the experiments are done with multi-task learning of semantics and constituent syntactic parsing (wo/dep).", "label": "reasoning"}
{"id": "test_1656", "sentence1": "Besides, LIMIT-BERT takes a semisupervised learning strategy to offer the same large amount of linguistics task data as that for the language model training.", "sentence2": "lIMIT-BERT not only improves linguistics tasks performance, but also benefits from a regularization effect and linguistics information that leads to more general representations to help adapt to new tasks and domains.", "label": "reasoning"}
{"id": "test_1657", "sentence1": "(2) Naturally empowered by linguistic clues from joint learning, pre-trained language models will be more powerful for enhancing downstream tasks.", "sentence2": "we propose Linguistics Informed Multi-Task BERT (LIMIT-BERT), making an attempt to incorporate linguistic knowledge into pre-training language representation models.", "label": "reasoning"}
{"id": "test_1658", "sentence1": "BERT is typically trained on quite large unlabeled text datasets, BooksCorpus and English Wikipedia, which have 13GB plain text, while the datasets for specific linguistics tasks are less than 100MB.", "sentence2": "we employ semi-supervised learning to alleviate such data unbalance on multi-task learning by using a pre-trained linguistics model to label BooksCorpus and English Wikipedia data.", "label": "reasoning"}
{"id": "test_1659", "sentence1": "To absorb both strengths of span and dependency structure, we apply both span (constituent) and dependency representations of semantic role labeling and syntactic parsing.", "sentence2": "it is a natural idea to study the relationship between constituent and dependency structures, and the joint learning of constituent and dependency syntactic parsing (Klein and Manning, 2004;Charniak and Johnson, 2005;Farkas et al., 2011;Green and\u00c3\u2026\u00c2\u00bdabokrtsk\u00c3\u0192\u00c2\u00bd, 2012;Ren et al., 2013;Xu et al., 2014;Yoshikawa et al., 2017).", "label": "reasoning"}
{"id": "test_1660", "sentence1": "Ideally, we expect that the representation vectors in the deep learning models for ABSA should mainly involve the related information for the aspect terms, the most important words in the sentences.", "sentence2": "in this work, we propose to regulate the hidden vectors of the graph-based models for ABSA using the information from the aspect terms, thereby filtering the irrelevant information for the terms and customizing the representation vectors for ABSA.", "label": "reasoning"}
{"id": "test_1661", "sentence1": "In this work, we hypothesize that these overall importance scores from the dependency trees might also provide useful knowledge to improve the representation vectors of the graph-based models for ABSA.", "sentence2": "we propose to inject the knowledge from these syntaxbased importance scores into the graph-based models for ABSA via the consistency with the modelbased importance scores.", "label": "reasoning"}
{"id": "test_1662", "sentence1": "Solving VLQA examples requires linking information from image and text.", "sentence2": "vLQA can be considered a novel kind of multi-hop task involving images and text, which we believe will drive future vision-language research.", "label": "reasoning"}
{"id": "test_1663", "sentence1": "Now we want to determine where is A' located in the image I.", "sentence2": "we formulate a new question Q' as \"Where is A'?", "label": "reasoning"}
{"id": "test_1664", "sentence1": "Encoding hierarchical information from large type inventories has been proven critical to improve performance  (Lopez et al., 2019).", "sentence2": "we hypothesize that our proposed hyperbolic model will benefit from this representation.", "label": "reasoning"}
{"id": "test_1665", "sentence1": "Because the OneCommon game framework rewards players if they successfully create common ground with each other, players may think to mention to more salient dots to increase the success rate.", "sentence2": "the variation of expressions could be restricted.", "label": "reasoning"}
{"id": "test_1666", "sentence1": "However, our architecture is difficult to directly apply to referring expression generation because it outputs modulated feature maps.", "sentence2": "the future direction is to extend our architecture to language generation.", "label": "reasoning"}
{"id": "test_1667", "sentence1": "For clusters with only negative edges like the triad in Figure 1c, even though the relation is imbalanced according to the definition, we are unable to determine whether there should be a pair of paraphrases in the graph without knowing the actual semantic meaning of the sentences.", "sentence2": "we use the weaker form of structural balance to represent graphs with all negative edges.", "label": "reasoning"}
{"id": "test_1668", "sentence1": "The NELL-995 does not come with a validation set, and therefore we selected 3000 edges randomly from the full NELL KB.", "sentence2": "many of the query relations were different from what was present in the splits of NELL-995 and hence is not a good representative.", "label": "reasoning"}
{"id": "test_1669", "sentence1": "The other kind (Zheng et al., 2019) is to generate and classify candidate regions in a two-stage paradigm, often leading to cascaded errors.", "sentence2": "region based methods face efficiency and effectiveness challenges.", "label": "reasoning"}
{"id": "test_1670", "sentence1": "Moreover, the Transformer model is inherently much slower than conventional machine translation approaches (e.g., statistical approaches) mainly due to the auto-regressive inference scheme (Graves, 2013) incrementally generating each token.", "sentence2": "deploying the Transformer model to mobile devices with limited resources involves numerous practical implementation issues.", "label": "reasoning"}
{"id": "test_1671", "sentence1": "This passive and relatively simple dialogue mechanism gains less attention from humans and consumes the interests of human beings rapidly.", "sentence2": "some recent researches attempt to endow the bots with proactivity through external knowledge to transform the role from a listener to a speaker with a hypothesis that the speaker expresses more just like a knowledge disseminator.", "label": "reasoning"}
{"id": "test_1672", "sentence1": "Two humans take the topic leading role like a speaker to introduce something new in turns.", "sentence2": "in human-machine conversation, the dialogue agent side needs to act as a speaker timely and appropriately.", "label": "reasoning"}
{"id": "test_1673", "sentence1": "When one leads the dialog, the other takes a backseat and forgets more.", "sentence2": "we predict the role with this forget gate and generate a response not only on the default decoder state but also on the predicted role simultaneously.", "label": "reasoning"}
{"id": "test_1674", "sentence1": "While the listener requires more forgetting to decrease the influence of the knowledge input.", "sentence2": "it seems the forget gate here is just a hidden variable which represents the role.", "label": "reasoning"}
{"id": "test_1675", "sentence1": "The Initiative-Imitate recognizes the role of the human and controls the knowledge utilizing in the next sentence generation.", "sentence2": "it is more engaged in the whole dialog.", "label": "reasoning"}
{"id": "test_1676", "sentence1": "Differently from Chirps, this model makes its event clustering decision based on the predicate, arguments, and the context of the full tweet, as opposed to considering the arguments alone.", "sentence2": "we expect it not to cluster predicates whose arguments match lexically, if their contexts or predicates don't match (first example in Table 3).", "label": "reasoning"}
{"id": "test_1677", "sentence1": " Following Shwartz et al. 2017, we annotated the templates while presenting 3 argument instantiations from their original tweets.", "sentence2": "we only included in the final data predicate pairs with at least 3 supporting pairs.", "label": "reasoning"}
{"id": "test_1678", "sentence1": "However, the extent of annotation and the utility of domain adaptation for training are unknown.", "sentence2": "our main question is how successfully can a semantic parser learn with alternative data resources to generalize to novel queries in a new language?", "label": "reasoning"}
{"id": "test_1679", "sentence1": "In initial experiments, we found negligible difference in MT-Paraphrase using random sampling or roundrobin selection of each paraphrase.", "sentence2": "we assume that both methods use all available paraphrases over training.", "label": "reasoning"}
{"id": "test_1680", "sentence1": "The model trained on MT achieves nearly the same generalization error as the model trained on the gold standard.", "sentence2": "we consider the feasibility of our approach justified by this result.", "label": "reasoning"}
{"id": "test_1681", "sentence1": "As previously discussed, we translate only the development and test set of Overnight (Wang et al., 2015) into Chinese and German for assessment of crosslingual semantic parsing in a multi-domain setting.", "sentence2": "we translate all 5,473 utterances in ATIS and 4,311 utterances in Overnight.", "label": "reasoning"}
{"id": "test_1682", "sentence1": "It is impossible for a NER system to cover all entity types (Ling and Weld, 2012;Mai et al., 2018).", "sentence2": "in the industrial area, it often happens that some entity types required to recognize by the clients are not defined in the previously designed NER system.", "label": "reasoning"}
{"id": "test_1683", "sentence1": "Note that, there is no labeled data for class K of the source task.", "sentence2": "a fully supervised learning algorithm is not applicable to train the classifier.", "label": "reasoning"}
{"id": "test_1684", "sentence1": "The difference between the compared work and our work is that, in the compared work, the mention recognition for one entity type is performed independently to the other types through a binary classifier.", "sentence2": "it has to resolve the conflict between the recognition results of different binary classifiers for different entity types using a heuristic method at the inference time.", "label": "reasoning"}
{"id": "test_1685", "sentence1": "This is because the occurring frequency of mentions of the location type is much lower than the occurring frequency of mentions of the GPE type.", "sentence2": "it requires to annotate more data for the location type to cover enough mentions of the type.", "label": "reasoning"}
{"id": "test_1686", "sentence1": "For ranking, the setup is different, as it is not feasible to encode all the candidate documents (from firststage retrieval) into a single input template.", "sentence2": "ranking necessitates multiple inference passes with the model and somehow aggregating the outputs.", "label": "reasoning"}
{"id": "test_1687", "sentence1": "We map a relevant document to \"hot\" and a non-relevant document to a completely unrelated word \"orange\".", "sentence2": "we force the model to build an arbitrary semantic mapping.", "label": "reasoning"}
{"id": "test_1688", "sentence1": "Our propose model OTE-MTL consistently outperforms all state-of-the-art baselines on all datasets with and without OOTs.", "sentence2": "we conclude OTE-MTL is effective in dealing with opinion triplet extraction task.", "label": "reasoning"}
{"id": "test_1689", "sentence1": "Previous work has found that if the ratio of biased examples is high, down-weighting, or disregarding all of them results in an insufficient training signal, which leads to performance decreases (Clark et al., 2019;Utama et al., 2020).", "sentence2": "we propose a novel multi-bias weighting function that weights each example according to multiple biases and based on each bias' strength in the training domain.", "label": "reasoning"}
{"id": "test_1690", "sentence1": "To apply our framework to training sets that may contain multiple biases of different strengths, we automatically weight the output of the bias models according to the strength of each bias in each training dataset.", "sentence2": "we propose a scaling factor F S (B k , D t j ) to automatically control the impact of bias B k in dataset D t j in our debiasing framework, i.e., to reduce the impact of bias on the loss function when the bias is commonly observed in the dataset.", "label": "reasoning"}
{"id": "test_1691", "sentence1": "We observe that (1) different datasets are more affected by certain biases, e.g., the ratio of examples that can be answered without the question (the empty question bias) is 8% in SQuAD while it is 38% in NQ, (2) NewsQA is least affected by biases overall while NQ and HotpotQA are most affected, (3) only few instances are affected by all four biases, and (4) except for NewsQA, the majority of training examples are affected by at least one bias.", "sentence2": "methods that down-weight or ignore all biased examples will considerably weaken the overall training signal.", "label": "reasoning"}
{"id": "test_1692", "sentence1": "Mahabadi et al. (2020) propose two different methods among which the Debiased Focal Loss (DFL) approach has a better performance.", "sentence2": "we use DFL in our comparisons.", "label": "reasoning"}
{"id": "test_1693", "sentence1": "To collect a large corpus of parallel data, heuristic rules are often used but they inevitably let noise into the data, such as phrases in the output which cannot be explained by the input.", "sentence2": "models pick up on the noise and may hallucinategenerate fluent but unsupported text.", "label": "reasoning"}
{"id": "test_1694", "sentence1": "It may also assign points for a match with the reference which is unsupported by the table.", "sentence2": "it can give a wrong estimate of both precision and recall and should be complemented with a human evaluation if two similar performing models are compared.", "label": "reasoning"}
{"id": "test_1695", "sentence1": "These models may highly rely on manual feature engineering, which makes them laborious and time-consuming and are difficult to adapt to new domains.", "sentence2": "more and more research (Manning and Eric, 2017; Sukhbaatar et al., 2015; Dodge et al., 2016; Serban et al., 2016; Bordes et al., 2017; Eric and Manning, 2017) dedicated to building end-to-end dialogue systems, in which all their components are trained entirely from the utterances themselves without the need to assume domains or dialog state structure, so it is easy to au\u0002tomatically extend to new domains and free it from manually designed pipeline modules.", "label": "reasoning"}
{"id": "test_1696", "sentence1": "Then we use a memory network to encode the results retrieved from KBs.", "sentence2": "we can access KBs more efficiently and achieve a high task success rate.", "label": "reasoning"}
{"id": "test_1697", "sentence1": "Intuitively, the more columns are subject to variations, the more diverse the records are.", "sentence2": "fewer records will match the query when more columns are subject to variations.", "label": "reasoning"}
{"id": "test_1698", "sentence1": "By employing a subsystem, including a Dialogue State Tracker and a SQL Generator, AirConcierge can issue a precise SQL query at the right time during a dialogue and retrieve relevant data from KBs.", "sentence2": "airConcierge can handle large-scale KBs efficiently, in terms of shorter processing time and less memory consumption.", "label": "reasoning"}
{"id": "test_1699", "sentence1": "Unique to our problem, however, is the fact that we have an open set of relation types in the graphs.", "sentence2": "we propose a novel graph-conditioned sparse transformer, in which the relation information is embed-ded directly into the self-attention grid.", "label": "reasoning"}
{"id": "test_1700", "sentence1": "From the analysis of our in-house search log, more than 95% of the queries have only one or two nodes, thus a scenario in which more than one edit operation applied is unlikely.", "sentence2": "the instances in Modified MSCOCO and GCC are constructed with one edit operation.", "label": "reasoning"}
{"id": "test_1701", "sentence1": "Since our task takes a source graph and a modification query as inputs, we need two encoders to model the graph and text information separately.", "sentence2": "there are four main components in our model: the query encoder, the graph encoder, the edge decoder and the node decoder.", "label": "reasoning"}
{"id": "test_1702", "sentence1": "To efficiently encode a graph, we need to encode the information not only from these constituent components, but also their interactions, namely the node-edge association and connectivity.", "sentence2": "we incorporate the information from all the edges to the nodes from which these edges are originated.", "label": "reasoning"}
{"id": "test_1703", "sentence1": "Getting annotation from users is expensive, especially for a complex task like our graph modification problem.", "sentence2": "we explore the possibility of augmenting the user-generated data with synthetic data in order to train a better model.", "label": "reasoning"}
{"id": "test_1704", "sentence1": "Using Design I for the annotation task, we noticed that workers were not motivated to identify and select different physical entities in motion.", "sentence2": "the majority of labeled entities were animate, and few were inanimate entities in motion.", "label": "reasoning"}
{"id": "test_1705", "sentence1": "It is difficult to reuse sentence-level templates in new tasks that usually have different requirements.", "sentence2": "people usually break long templates into smaller template units (TUs).", "label": "reasoning"}
{"id": "test_1706", "sentence1": "Since the vocabulary of the connection phrases is limited, we automatically generate text stitch training data by dropping certain words in free texts with simple rules.", "sentence2": "we can train a high-quality text stitch model in a self-supervised paradigm.", "label": "reasoning"}
{"id": "test_1707", "sentence1": "Note that it only inserts connection phrases and preserves all the contents in the input.", "sentence2": "compared with traditional encoder-decoder frameworks that generate texts from scratch, edition-based methods are better fits for this setting.", "label": "reasoning"}
{"id": "test_1708", "sentence1": "We find tokens with POS tags adp, aux, cconj, part, punct, sconj, verb are often parts of a connection phrase.", "sentence2": "for each pair of adjacent sentences, we consider each token tok i with these POS tags as an indicator of potential segmentation of two TU instantiations.", "label": "reasoning"}
{"id": "test_1709", "sentence1": "In contrast, TS2 only needs 3 templates to constrain the TU orders and does not need to consider the connection phrases.", "sentence2": "significant human efforts are reduced in template design and Q4 is partially answered.", "label": "reasoning"}
{"id": "test_1710", "sentence1": "METEOR calculates the precision and recall of the matched words between the generated and reference texts after alignment by taking paraphrases into account.", "sentence2": "it is less sensitive to expression variations and content orders than other automatic metrics.", "label": "reasoning"}
{"id": "test_1711", "sentence1": "Additionally, generation methods are not suitable for non-English text owing to a lack of training data because they are heavily dependent on in-language supervision (Ponti et al., 2019).", "sentence2": "we adopted the sequence labeling method to maximize scalability by using (multilingual) BERT (Devlin et al., 2019) and multi-head attention (Vaswani et al., 2017).", "label": "reasoning"}
{"id": "test_1712", "sentence1": "Although some studies have demonstrated the potential of multilingual open IE (Faruqui and Kumar, 2015; Gamallo and Garcia, 2015; White et al., 2016), most approaches are based on shallow patterns, resulting in low precision (Claro et al., 2019).", "sentence2": "we introduce a multilingual-BERTbased open IE system.", "label": "reasoning"}
{"id": "test_1713", "sentence1": "The corpus strives for a general understanding of ST&WR and its textual material should be as diverse as possible.", "sentence2": "we opted to use shorter excerpts from multiple texts rather than longer, complete texts and also tried to represent many different authors, newspapers and magazines.", "label": "reasoning"}
{"id": "test_1714", "sentence1": "As mentioned above, our annotation system shows similarities to the system defined in the influential narratological theory of Genette (2010), and also to that defined by Leech and Short (2013), both fairly formal systems that incorporate linguistic features in their definitions.", "sentence2": "they were particularly suited to be adapted for annotation guidelines and also well suited to our other task of developing automatic ST&WR recognizers.", "label": "reasoning"}
{"id": "test_1715", "sentence1": "weDH is mainly the user interface for the DHTK library conceived and proposed by Picca and Egloff (2017) ", "sentence2": "if the main purpose of the library is to facilitate the exploitation of textual repositories such as Gutenberg.org along with of LOD resources such as DBpedia, wikidata and VIAF, the web interface has been conceived in order to be exploited by students and practitioners in the human science field with no or few coding skills.", "label": "reasoning"}
{"id": "test_1716", "sentence1": "In dialogue-heavy works, quoted speech can often exceed 50% of a novel\u2019s text (Elson and McKeown, 2010).", "sentence2": "quotations are an important structural component of literary texts.", "label": "reasoning"}
{"id": "test_1717", "sentence1": "VGG was designed with the aim of reconstructing the \"polyphony\" of the languages of Italy at war: the official voice of propaganda and the voice of soldiers, the voice of newspapers and the voice of letters, the voice of the elite of intellectuals and the popular voice, the voice of consensus and the voice of dissent, male voices and female voices.", "sentence2": "the final corpus is balanced along various dimensions, corresponding to the textual genre, the language variety used, the author type (e.g., sex, education, profession, political orientation etc.", "label": "reasoning"}
{"id": "test_1718", "sentence1": "As a methodological note, in the original corpus the pronoun \"I\" has been resolved to the speaker's name in the process of annotating propositions from locutions (e.g., for the sentence \"I believe Americans do have the ability to give their kids a better future\", \"I believe\" has been replaced with \"O'MALLEY believes\") (Jo et al., 2019).", "sentence2": "it is difficult to tell whether the source of a reported speech proposition is indeed the speaker or not.", "label": "reasoning"}
{"id": "test_1719", "sentence1": "However, they use reported speech often, partly because their discussions occurred after the debates had occurred.", "sentence2": "these texts often refer back to speech from the debates themselves and the reported speech of the candidates.", "label": "reasoning"}
{"id": "test_1720", "sentence1": "Note that the CKY phase is designed to simplify the original RvNN framework that calculates discourse representations recursively according to the tree structure.", "sentence2": "bERT, along with its pretrained linguistic knowledge, can learn the underlying discourse structure itself with raw text segments as inputs.", "label": "reasoning"}
{"id": "test_1721", "sentence1": "It is known that under micro F1 evaluation, different paragraphs are weighted in proportion to the number of their nodes in the discourse trees, while each paragraph is equally weighted under macro evaluation.", "sentence2": "we can infer that Our-R takes advantage of predicting local structures.", "label": "reasoning"}
{"id": "test_1722", "sentence1": "In particular, during discussions with teachers where we visualized the collaboration annotations in the corpus that came from their particular classrooms, we found that teachers were very curious about whether students were introducing new information into the discussion or building off of what was previously said.", "sentence2": "we experimented on how well a classifier could distinguish student turns labeled 'New' from the other collaboration annotations.", "label": "reasoning"}
{"id": "test_1723", "sentence1": "Additionally, the example illustrates that the connective has no relation sense assigned to it.", "sentence2": "in our 2.2 version, we add this relation sense according to the PDTB 3.0 sense hierarchy.", "label": "reasoning"}
{"id": "test_1724", "sentence1": "Because of its complexity, it is hard to get annotated data for training statistical models to perform SDP.", "sentence2": "our goal is to produce high-quality annotations other than the standard corpus used in the field-the Penn Discourse Treebank (PDTB) (Prasad et al., 2008)-in order to improve performance on explicit argument extraction.", "label": "reasoning"}
{"id": "test_1725", "sentence1": "In contrast, the neural-network-based model predicted low scores for all columns.", "sentence2": "the neural-network-based model is robust against an unexpected essay.", "label": "reasoning"}
{"id": "test_1726", "sentence1": "We confirmed the robustness of the BERT model with three essays: an essay with a high/low score and one written with only one character.", "sentence2": "we found that the BERT model is more robust against unexpected inputs than the feature-based models.", "label": "reasoning"}
{"id": "test_1727", "sentence1": "They could create a corpus with 16,000 humorous one-liners in English, collected from the Web, while, towards the development of a model of humour recognition, much negative data was available.", "sentence2": "four sets of negative examples were gathered, namely: news titles from Reuters; proverbs on the Web; sentences from the British National Corpus (BNC); and sentences from the Open Mind Common Sense project.", "label": "reasoning"}
{"id": "test_1728", "sentence1": "Yet, a system for humour recognition should not be restricted to a single style of humour.", "sentence2": "to complement the collected text in the one-liners style, we targeted another kind of short humorous texts: humorous headlines.", "label": "reasoning"}
{"id": "test_1729", "sentence1": "The subtitles feature, which refers to the intermediate titles throughout the text, was excluded because none of the news contained intermediate titles in their text structure.", "sentence2": "the remaining 165 features were computed for each text in the corpus.", "label": "reasoning"}
{"id": "test_1730", "sentence1": "As our current approach is supervised, direct comparison is not possible.", "sentence2": "we compare them indirectly, assuming that the average accuracy over 2000 article pairs from the unsupervised approach roughly corresponds to the average accuracy in a 10fold cross-validation with 10 repetitions over the same 2000 article pairs.", "label": "reasoning"}
{"id": "test_1731", "sentence1": "To better assess the universality of our systems, knowing that in real-world scenario some text will not have paragraph division, we wanted to explore how much paragraph organization influences the results of our systems on both classification tasks.", "sentence2": "we compared classification performances on three different feature sets: surface + shallow, deep, and combination of all three types of features, in two scenarios: using all features of the corresponding type, and excluding the features that require paragraph information, e.g.", "label": "reasoning"}
{"id": "test_1732", "sentence1": "In order to be able to compare the same parts of different texts (which very often have different sizes), our model breaks the aspect flows in a fixed number of frames.", "sentence2": "regardless of the number of sentences in a text, the first frame will represent the first part of the text, for example, which we can compare to another text's first part.", "label": "reasoning"}
{"id": "test_1733", "sentence1": "As we can notice in Equations (2) and (6), to calculate MCR and Energy Entropy correctly, the flow must contain, at least, 2 sentences per frame.", "sentence2": "this minimum requirement must be considered during the definition of the number of frames and the K parameter (as it requires, at least, one sentence per subframe).", "label": "reasoning"}
{"id": "test_1734", "sentence1": "Legitimate and fake news contain an average of 21 and 14 sentences per document, respectively.", "sentence2": "we decided to split the flows into 3 frames, resulting into 7 and 4.67 sentences per frame, on average, for the legitimate and fake news, respectively.", "label": "reasoning"}
{"id": "test_1735", "sentence1": "We observe that many annotations contain punctuation marks, which are considered as separate tokens by spaCy.", "sentence2": "we perform the same calculations while ignoring the punctuation tokens.", "label": "reasoning"}
{"id": "test_1736", "sentence1": "Although our findings generally fit with theorized patterns of emotional development, we cannot say for certain whether the current results re-flect changes in felt emotion, emotion vocabulary or, more broadly, changes in the ability to use abstract language.", "sentence2": "we are more inclined to cautiously interpret our results as reflecting developmental trends in the distribution of emotion words.", "label": "reasoning"}
{"id": "test_1737", "sentence1": "The main goals of call center conversations are either to pursue a person to sign a contract, or to solve some technical or financial problems.", "sentence2": "the question of the evolution of frustration or satisfaction (called satisfaction dimension in the following) along the conversation, is crucial.", "label": "reasoning"}
{"id": "test_1738", "sentence1": "For ethical and commercial reasons the agent channel was discarded.", "sentence2": "the corpus contains callers' voice only without any overlapping speech.", "label": "reasoning"}
{"id": "test_1739", "sentence1": "In order to do so, having clues about the satisfaction dimension of the caller can be beneficial.", "sentence2": "we define a task of satisfaction dimension prediction throughout the conversation.", "label": "reasoning"}
{"id": "test_1740", "sentence1": "On the contrary, if satisfaction is completely differently rated by the three annotators, the CCC computed on each pair is close to 0.", "sentence2": "the gold annotation, defined as the mean of the 3 annotation's values, is not consistent.", "label": "reasoning"}
{"id": "test_1741", "sentence1": "Training from the human labeling result, the evaluation model learns which generative models is better in each dialog context.", "sentence2": "it can be used for system developers to compare the fine-tuned models over and over again without the human labor.", "label": "reasoning"}
{"id": "test_1742", "sentence1": "However, if an evaluation is fully automatic, then it can be incorporated into a generation system.", "sentence2": "it can always generate sentences with higher evaluation value.", "label": "reasoning"}
{"id": "test_1743", "sentence1": "We consider emotions in poetry as they are elicited in the reader, rather than what is expressed in the text or intended by the author.", "sentence2": "we conceptualize a set of aesthetic emotions that are predictive of aesthetic appreciation in the reader, and allow the annotation of multiple labels per line to capture mixed emotions within their context.", "label": "reasoning"}
{"id": "test_1744", "sentence1": "Kant (2001) already spoke of a \"feeling of beauty\", and it should be noted that it is not a 'merely pleasing emotion'.", "sentence2": "in our pilot annotations, Beauty and Joy were separate labels.", "label": "reasoning"}
{"id": "test_1745", "sentence1": "Furthermore, our pilot annotations revealed, while Beauty is the more dominant and frequent feeling, both labels regularly accompany each other, and they often get confused across annotators.", "sentence2": "we add Joy to form an inclusive label Beauty/Joy that increases consistency.", "label": "reasoning"}
{"id": "test_1746", "sentence1": "For the experts, we aggregate their emotion labels on stanza level, then perform the same strategy for selection of emotion labels.", "sentence2": "for s, both crowds and experts have 1 or 2 emotions.", "label": "reasoning"}
{"id": "test_1747", "sentence1": "None of our models was able to learn this label for German.", "sentence2": "we omit it, leaving us with eight proper labels.", "label": "reasoning"}
{"id": "test_1748", "sentence1": "However, those studies (described in detail below) focus on their particular application rather than addressing the underlying, abstract learning problem (formalized in Section 3.).", "sentence2": "previously proposed methods have not been quantitatively compared.", "label": "reasoning"}
{"id": "test_1749", "sentence1": "For MLFFN, we built on the implementation2 and hyperpa\u0002rameter choices Buechel et al. (2018) used for the Empathic Reactions dataset.", "sentence2": "mLFFN has two hidden layers (256 and 128 units, respectively) with ReLU activation.", "label": "reasoning"}
{"id": "test_1750", "sentence1": "Accordingly, evaluating the accuracy of automatically detected communicative functions reduces to the evaluation of what is captured in sentence representations.", "sentence2": "we propose a task of ranking sentence representations according to a given communicative function.", "label": "reasoning"}
{"id": "test_1751", "sentence1": "Formulaic expressions are extracted from the example expressions by hand, but because they can be very specific or sometimes contain irrelevant content, some queries return no results.", "sentence2": "we simplify and shorten the formulaic expressions and obtain what we call the core FEs to retrieve more sentences.", "label": "reasoning"}
{"id": "test_1752", "sentence1": "Each sentence has a sentence ID that corresponds to the sentence ID in AASC.", "sentence2": "the surrounding context of each sentence can be easily retrieved if a classifier needs it.", "label": "reasoning"}
{"id": "test_1753", "sentence1": "The accuracy indicates how likely evaluators were to choose the correct answers, while the agreement indicates the degree to which they made the same choice.", "sentence2": "if the sentence selection in the process of creating the dataset fails to make pairs of sentences with the same communicative functions, the accuracy will be low but the agreement will be high.", "label": "reasoning"}
{"id": "test_1754", "sentence1": "We note that 64.7% of the data showed 100% accuracy, and the accuracy for 84.4% of the data is greater than 75%, which implies that the majority of the quizzes are easy to answer.", "sentence2": "the task of detecting the communicative functions of sentences is not too difficult for humans.", "label": "reasoning"}
{"id": "test_1755", "sentence1": "For P Score the correction performance of NONE is multipled with the averaged performance over all error categories, due to the fact that we want a changed output for all error categories instead of the NONE category where we explicitely do not want any changed output.", "sentence2": "the correction parameter for NONE can be interpreted as a penality parameter.", "label": "reasoning"}
{"id": "test_1756", "sentence1": "Although some document types may have structured tabular data, we still need a general approach to detect tables on different kinds of documents.", "sentence2": "large-scale endto-end deep learning models make it feasible for achieving better performance.", "label": "reasoning"}
{"id": "test_1757", "sentence1": "For instance, we found that models trained on data similar to Figure 1a 1b 1c would not perform well on Figure 1d because the table layouts and colors are so different.", "sentence2": "enlarging the training data should be the only way to build open-domain table analysis models with deep learning.", "label": "reasoning"}
{"id": "test_1758", "sentence1": "Latex documents are different from Word documents because they need other resources to be compiled into PDF files.", "sentence2": "we cannot only crawl the '.tex' file from the internet.", "label": "reasoning"}
{"id": "test_1759", "sentence1": "Although these methods perform well on some documents, they require extensive human efforts to figure out better rules, while sometimes failing to generalize to documents from other sources.", "sentence2": "it is inevitable to leverage statistical approaches in table detection.", "label": "reasoning"}
{"id": "test_1760", "sentence1": "The absence of significant success in ad-hoc IR using deep learning approaches is mainly due to the complexity of solving the ranking task using only unlabelled data (Dehghani et al., 2017).", "sentence2": "the availability of large amount of labelled data is crucial to develop effective DNNs for ad-hoc IR.", "label": "reasoning"}
{"id": "test_1761", "sentence1": "Such datasets are suitable for feature-based learning-to-rank models but not for DNNs that require the original content of queries and documents.", "sentence2": "most of the deep learning model for ad-hoc IR that have been proposed recently are developed using one of the following approaches: (1) Using large amounts of data collected from commercial search engines that are not publicly available (Yang et al., 2019a;Mitra et al., 2017).", "label": "reasoning"}
{"id": "test_1762", "sentence1": "They rely on a first ranking stage made by an efficient model such as BM25 and only re-rank the top-k documents for a given query in order to have an efficient search.", "sentence2": "wIKIR can be used to run BM25 and save the top-k documents for each query.", "label": "reasoning"}
{"id": "test_1763", "sentence1": "The normalization of taxonomic mentions of bacteria is not much of a challenge for the BioNLP community because the nomenclature is complete, variations are relatively standardized, and synonymy is rare (except in some special cases such as strain names).", "sentence2": "string matching with basic variations yields decent results (Grouin, 2016).", "label": "reasoning"}
{"id": "test_1764", "sentence1": "We observed no impact of the window size (see Table 1).", "sentence2": "we set a short symmetrical window of two tokens in all subsequent experiments.", "label": "reasoning"}
{"id": "test_1765", "sentence1": "It can mean that the concepts mentioned in the annotated corpus (whole training and development set) are largely those mentioned in the annotated test corpus.", "sentence2": "both training sets have the same order of training examples for concepts mentioned in the test corpus, which could explain the similar performance.", "label": "reasoning"}
{"id": "test_1766", "sentence1": "In addition, from the perspective of EL solutions, it is observed that (1) EL on short text tends to require excessive hand-crafted features specific to a certain kind of application, which makes it not necessarily applicable to others; and (2) short-text oriented corpus finds itself inappropriate for evaluating the cluster of EL methods based on collective schemes, since short text is unable to supply enough contextual mentions.", "sentence2": "long-text oriented corpora are considered to be at least of equal, if not greater, significance to verifying the effectiveness and robustness of EL methods.", "label": "reasoning"}
{"id": "test_1767", "sentence1": "The underlying reason is that mentions in these datasets are not even ambiguous, since most of them were derived from text with high clarity.", "sentence2": "there is a pressing need to construct a corpus with a certain level of difficulty, so as to better examine various EL methods.", "label": "reasoning"}
{"id": "test_1768", "sentence1": "Also, we used the referential task for participants fMRI scanning.", "sentence2": "it was demonstrated that annotated multichannel corpora like RUPEX can be an important resource for experimental research in interdisciplinary fields.", "label": "reasoning"}
{"id": "test_1769", "sentence1": "As a result, it was demonstrated that annotated multichannel corpora like RUPEX can be an important resource for experimental research in interdisciplinary fields.", "sentence2": "different aspects of communication can be explored through the prism of brain activation.", "label": "reasoning"}
{"id": "test_1770", "sentence1": "Authors are highly advised to link news articles to Wikinews categories, to allow effective information organization in Wikinews, and do so only when a category is strongly related to the written article.", "sentence2": "the categories can be viewed as salience annotations and entities corresponding to these categories as salient entities.", "label": "reasoning"}
{"id": "test_1771", "sentence1": "For pages that receive enough traffic, reliable user click statistics can be obtained and used to derive entity salience labels.", "sentence2": "a dataset called Microsoft Document Aboutness (MDA), was constructed.", "label": "reasoning"}
{"id": "test_1772", "sentence1": "However, human annotated salience labels rely on crowdsourcing, which is usually very expensive.", "sentence2": "it is preferred to derive salience labels using automated methods.", "label": "reasoning"}
{"id": "test_1773", "sentence1": "For example, in the example article, the entity mention Kim Jong-un is representing an entity and has corresponding Wikinews category Kim Jong-un.", "sentence2": "a wikilink is added to refer to the Wikinews category Kim Jong-un.", "label": "reasoning"}
{"id": "test_1774", "sentence1": "However, we observe that basic statistics show major differences between news articles in different years.", "sentence2": "we choose to split the dataset on a monthly basis, i.e., all articles up to a threshold month are placed in the training set, while the remaining articles are placed in the test set.", "label": "reasoning"}
{"id": "test_1775", "sentence1": "However, comments are noise for an evaluation dataset because automatic evaluation methods utilizing corrected sentences typically rely on the matching rate between the system output and the corrected sentences to calculate a score.", "sentence2": "in this study, we manually corrected the learner sentences extracted from the Lang-8 corpus using consistent rules and created a highly reliable evaluation corpus for the correction of grammatical errors in Japanese.", "label": "reasoning"}
{"id": "test_1776", "sentence1": "The Lang-8 corpus has often only one corrected sentence per learner sentence, which is not enough for evaluation.", "sentence2": "we ensured that our evaluation corpus has multiple references.", "label": "reasoning"}
{"id": "test_1777", "sentence1": "The types of errors differ between handwritten sentences and typewritten sentences.", "sentence2": "the JPDB and NAIST Misuse Corpus are not suitable as evaluation datasets for correcting grammatical errors in typewritten sentences.", "label": "reasoning"}
{"id": "test_1778", "sentence1": "The Japanese portion of the Lang-8 corpus has a wide coverage.", "sentence2": "these techniques can also be applied to JSL texts.", "label": "reasoning"}
{"id": "test_1779", "sentence1": "Many of the articles in the Lang-8 corpus are written as if the learner writes a diary.", "sentence2": "we designed the annotation rules considering the local and global contexts dedicated to Lang-8's register (writing a blog).", "label": "reasoning"}
{"id": "test_1780", "sentence1": "Overall, 11,437 out of 14,671 (78%) time points are indeterminate for abstract TDT timelines and 10,023 out of 14,671 (70%) are indeterminate for full TDT timelines, compared with 8,769 out of 15,623 (56%) for TimeML timelines.", "sentence2": "even full TDTs increase temporal indeterminacy significantly compared to TimeML graphs.", "label": "reasoning"}
{"id": "test_1781", "sentence1": "Indexing minimizes the amount of expensive pattern matching that must take place at runtime.", "sentence2": "the runtime system matches a syntax-based graph traversal in 2.8 seconds in a corpus of over 134 million sentences, nearly 150,000 times faster than its predecessor.", "label": "reasoning"}
{"id": "test_1782", "sentence1": "Their proposed method automatically learns which parts are relevant for a given classication.", "sentence2": "their proposed method gives best results without any external help.", "label": "reasoning"}
{"id": "test_1783", "sentence1": "This arbitration is made possible by the hypothesis that Financial Markets might not be as efficient as they are supposed to be in neoclassic economic theory (Fama, 1970), because of information asymmetry.", "sentence2": "it is possible to have an unbiased algorithm digging deep into the mass of accessible documents to yield indications about future performances of a company.", "label": "reasoning"}
{"id": "test_1784", "sentence1": "If a company voluntarily hides a vital information for the market's wealth, they fall under the Financial Authority it depends on and might become the subject of a lawsuit for Statement Fraud.", "sentence2": "aRs are the most comprehensive public document to evaluate a company potential and strategy.", "label": "reasoning"}
{"id": "test_1785", "sentence1": "We observe that in the first one, the risk section is easily detectable whereas it is not trivial for the second one.", "sentence2": "we cannot only use \"risque\" word to isolate the Risk Section in Annual Reports, which can be cause by some risk sentences not containing risk vocabulary but markers of uncertainty.", "label": "reasoning"}
{"id": "test_1786", "sentence1": "We also built a Metadata table containing, for each company, information about its market capitalization and sector of activity, allowing modularity of the corpus for various tasks.", "sentence2": "the DoRe corpus can be used for cross-country/dialect, cross industry, cross-size analysis, fraud detection, document segmentation and risk factor extraction but also for pre-training or fine-tuning Language Models on Financial and Economic specific domains for French language and French dialects.", "label": "reasoning"}
{"id": "test_1787", "sentence1": "It is important to note that the relations we have annotated are long-distance relations, connecting often concepts that are mentioned in different sections of the EEG report, or concepts that are in separate sentences.", "sentence2": "we believe that by releasing these annotations, we will enable other researchers to make use of the data for many possible downstream applications, not only in the biomedical field, but also in application that rely on information extraction.", "label": "reasoning"}
{"id": "test_1788", "sentence1": "Table 2 defines each of the 16 attributes of EEG activities and illustrates the possible values each of these attributes.", "sentence2": "any identification of EEG activities in EEG reports amounts to recognizing the 16 attributes listed in Table 2 along with the polarity and modality attributes.", "label": "reasoning"}
{"id": "test_1789", "sentence1": "In EEG reports, certain words tend to be more ambiguous than others, suggesting that computing the encodings of these words requires additional processing to correctly capture their meaning from the contexts in which they appear.", "sentence2": "the TNE leverages Adaptive Computation Time (Graves, 2016) to dynamically allocate more computational resources for the encoding of some words compared to others in the same EEG report.", "label": "reasoning"}
{"id": "test_1790", "sentence1": "Knowing the semantic properties of the knowledge that is needed to connect argument units that are -for example -adjacent vs. those that are not, can guide the process of extracting knowledge for filling these gaps.", "sentence2": "we want to investigate whether the distribution of the semantic properties we annotated for the inserted sentences -commonsense relation types and semantic clause types -respectively differs depending on the internal structure of an argument.", "label": "reasoning"}
{"id": "test_1791", "sentence1": "We then form the test set (train, development) by collecting all datapoints whose (subject,relation), (object,relation) is in the test( train or development) set pairs.", "sentence2": "the test set has (subject,relation), (object,relation) which are not seen during training.", "label": "reasoning"}
{"id": "test_1792", "sentence1": "The existing automatic evaluation methods for these are limited (Lin et al., 2011;Pitler et al., 2010;Ellouze et al., 2017), usually do not take into account the complex and subjective nature of the linguistic quality factors.", "sentence2": "we do not focus on these automatic quality measurement tools in this paper.", "label": "reasoning"}
{"id": "test_1793", "sentence1": "However, the crowd is typically composed of people with unknown and very diverse abilities, skills, interests, personal objectives, and technological resources, which lead to several challenges related to lack of control on participants and consistency of output quality in crowdsourcing (Hossfeld et al., 2014).", "sentence2": "outputs produced by the crowd must be checked for quality, and so the quality of crowd-based NLP annotations has been repeatedly questioned (Lloret et al., 2018).", "label": "reasoning"}
{"id": "test_1794", "sentence1": "To our knowledge, there is no best practice guideline for summary quality evaluation regarding the optimal number of repetitions per item in crowdsourcing studies used in MOS.", "sentence2": "we explore the relationship between the number of repetitions and the correlation coefficient between crowdsourcing and laboratory results to provide a best practice guideline regarding the optimal repetition number in MOS.", "label": "reasoning"}
{"id": "test_1795", "sentence1": "Furthermore, this work does not include any special data cleaning or annotation aggregation method other than the calculating mean values over 24 different judgments for a single item.", "sentence2": "further analysis needs to be performed in order to find out the optimal aggregation method along with the corresponding optimal repetition number, such that comparable results to the laboratory can be obtained in a reliable and cost-effective way.", "label": "reasoning"}
{"id": "test_1796", "sentence1": "And, we randomized the order of the judgments five times to lower the effect of lurking variable, so k = 5 where the number 5 was selected arbitrarily.", "sentence2": "we got a set of correlation coefficients for unrandomized judgments C measured , and C 1 , C 2 , C 3 , C 4 , and C 5 for five randomizations.", "label": "reasoning"}
{"id": "test_1797", "sentence1": "Minor differences in morpheme choice are scored as badly as mistranslating a whole word.", "sentence2": "in addition to BLEU, we have evaluated the MT systems into Inuktitut using YiSi-0 (Lo, 2019), a word-level metric that incorporates character-level information, which has been shown to correlate better with human judgment than BLEU on translation quality into agglutinative languages, such as Finnish and Turkish, at both sentence level and document level (Ma et al., 2018;Ma et al., 2019).", "label": "reasoning"}
{"id": "test_1798", "sentence1": "The pdf format is not machine friendly so it is tricky for researchers to work with it.", "sentence2": "we convert the original pdf files into plain text files step by step so that they can be used for machine translation or any other computational tasks.", "label": "reasoning"}
{"id": "test_1799", "sentence1": "In preliminary experiments we observed that for the full Wikipedia corpora, relatively few words in the evaluation dataset (discussed in Section 4.) were OOVs, yet OOVs are required for our experimental setup", "sentence2": "following Adams et al. (2017) we carried out experiments in which we learned cross-lingual embeddings, but down\u0002sized the size of the corpora", "label": "reasoning"}
{"id": "test_1800", "sentence1": "Note that English has the largest corpus among the selected languages, and that we always use the full corpus for the target language, but a sample for the source language.", "sentence2": "we expect the embeddings for English as the target language to be higher quality than those for English as the source language, which could explain why the accuracy is higher when English is used as the target language than as the source language.", "label": "reasoning"}
{"id": "test_1801", "sentence1": "However, the actual label of such a statement would be positive because of the author's intention.", "sentence2": "the annotators were advised to strictly avoid making annotation decisions based on their own point of view (e.g -personal prejudices) when it comes to such sentences.", "label": "reasoning"}
{"id": "test_1802", "sentence1": "First, despite the third issue mentioned above 50% of the \"no\" answers and 80.8% of the \"yes\" answers of the students to closed questions were indeed correct.", "sentence2": "there are good reasons to believe that if the learners were more conservative in their answers to closed questions, fewer dubious \"yes\" answers would be collected and the third issue could be solved.", "label": "reasoning"}
{"id": "test_1803", "sentence1": "Table 3 provides additional insights into the properties of the wordnet, and also compares it to Princeton WordNet, the most complete such resource.", "sentence2": "our USGW has its fair share of verbs but is relatively poor in adjectives with respect to the PWN (that has 15% of adjectives), which should be addressed in future work.", "label": "reasoning"}
{"id": "test_1804", "sentence1": "Usually, these phrases are called idiomatic expressions, which is suitable when they are used in an idiomatic sense, but not so much when they are used in a literal sense.", "sentence2": "we propose a new term: Potentially Idiomatic Expressions, or PIEs for short.", "label": "reasoning"}
{"id": "test_1805", "sentence1": "Because the PMB contains many very short documents, there might not be enough context to disambiguate the PIEs.", "sentence2": "we extract only PIEs with at least 50 characters of context, i.e. the document should be at least 50 characters longer than the span of the PIE. ", "label": "reasoning"}
{"id": "test_1806", "sentence1": "Given the set of candidate instances from the pre-extraction system, the challenge is to get high-quality sense annotations at manageable costs of time and money using the FigureEight platform.", "sentence2": "we strive to make the task as easy as possible for crowdworkers.", "label": "reasoning"}
{"id": "test_1807", "sentence1": "The balance between idiomatic and other usages of PIEs does not mean much if the overall number of PIEs and/or tokens in the genre is very small.", "sentence2": "we also look at the frequency of PIEs relative to the number of tokens.", "label": "reasoning"}
{"id": "test_1808", "sentence1": "As other ASR-systems, Elpis makes use of dictionaries to specify the pronunciation of words.", "sentence2": "it cannot be used in the earliest stages of language documentation when most lexical data is still missing.", "label": "reasoning"}
{"id": "test_1809", "sentence1": "Time and resources for fieldwork are often very limited.", "sentence2": "it makes sense to start on a phonemic level when lexical data are still sparse.", "label": "reasoning"}
{"id": "test_1810", "sentence1": "Due to the long-term and large-scale approach it can be expected that additional collections of possibly relevant primary data will appear over the entire project runtime.", "sentence2": "it is unforeseeable which data types they will contain and at what point in time they might become relevant for research conducted along with the project.", "label": "reasoning"}
{"id": "test_1811", "sentence1": "To approach both problems in a sustainable way, the decisions in the area of data modeling that will have to be made will deal with the tension between unification of data sets and vocabularies on the one side and maximum openness to future resources and research queries on the other side.", "sentence2": "as one solution it was decided to identify standardizable connecting information in the existing project resources and to make sure that connections to internal and external resources of any type can be represented and resolved in the future.", "label": "reasoning"}
{"id": "test_1812", "sentence1": "Most native languages in the country have adopted several loanwords given the extended contact with Spanish.", "sentence2": "we need to carefully identify and clean the best sentences to build an NLP resource.", "label": "reasoning"}
{"id": "test_1813", "sentence1": "We can find different punctuation marks, bullet entries with or without enumeration, titles/subtitles/headers without any delimiter punctuation in the raw text, among others.", "sentence2": "we must be able to handle different kinds of noise to obtain as many correct sentences as possible.", "label": "reasoning"}
{"id": "test_1814", "sentence1": "Similar to the findings of Buck et al. 2014, we noticed that even when the expected language is known, some files contain instructions or entries written in a different language than our targets.", "sentence2": "we use a Peruvian language identification tool, developed by Espichan-Linares and Oncevay-Marcos (2017), to label each sentence and drop the texts identified as written in languages out of our scope.", "label": "reasoning"}
{"id": "test_1815", "sentence1": "Following the language identification step, we perform a manual inspection of part of the output and identified specific issues.", "sentence2": "we propose different heuristics to clean and prepare a higher-quality corpus.", "label": "reasoning"}
{"id": "test_1816", "sentence1": "There are specific sentences with a large number of duplicated tokens (e.g. writing exercises for children in language guides or workbooks).", "sentence2": "we compute the ratio per sentence of token types V and number of tokens N to identify the duplication process.", "label": "reasoning"}
{"id": "test_1817", "sentence1": "During the plain text conversion, some of the captured mathematical expressions are incorrectly located within a sentence, which loose its original meaning (see Figure 9 in the Appendix).", "sentence2": "we establish a rule where we look for sequences of numbers and operators inside a sentence and remove them from our final corpus.", "label": "reasoning"}
{"id": "test_1818", "sentence1": "In the near future, there will be a demand to extend this to workplace-specific tasks and procedures.", "sentence2": "a method of gathering crowdsourced dialogue data is needed that ensures compliance with such procedures, whilst providing coverage of a wide variety of dialogue phenomena that could be observed in deployment of a trained dialogue system.", "label": "reasoning"}
{"id": "test_1819", "sentence1": "Emergency response is clearly a high-stakes situation, which is difficult to emulate in a lab or crowdsourced data collection environment.", "sentence2": "in order to foster engagement and collaboration, the scenario was gamified with a monetary reward given for task success.", "label": "reasoning"}
{"id": "test_1820", "sentence1": "However, for scenarios such as ours, the role playing requires a certain expertise and it is questionable whether the desired behaviour would be achieved simply by letting two non-experts converse with free text.", "sentence2": "in recent data collections, there have been a number of attempts to control the data quality in order to produce a desired behaviour.", "label": "reasoning"}
{"id": "test_1821", "sentence1": "It is quite common for an application to be available in five to ten languages simultaneously.", "sentence2": "to minimize the effort for new applications, the framework offers a Resource Grammars Library (RGL) for many languages (Ranta, 2009).", "label": "reasoning"}
{"id": "test_1822", "sentence1": "It is a small police office which was originally found only in Japan, although now variations exist elsewhere, such as in Singapore, where it is called a neighbourhood police post.", "sentence2": "it needed a hyponym relation to the English synset for police station: 03977678n.", "label": "reasoning"}
{"id": "test_1823", "sentence1": "Both of these projects do not make use of the full range of etymological relationships present in Wiktionary.", "sentence2": "we were motivated to develop our own Wiktionary parser that is both comprehensive and extensible: it can extract the etymological information and many other types of information annotated in Wiktionary, and it is easy to use and extend for further research.", "label": "reasoning"}
{"id": "test_1824", "sentence1": "Performance on Japanese (ja) beats the high-performing baseline because of a feature of the Japanese writing system: foreign words are written in katakana, while native words are written in hiragana or kanji.", "sentence2": "foreign words are easily distinguished as borrowing due to differences in the script.", "label": "reasoning"}
{"id": "test_1825", "sentence1": "Because of this, the simpler models give an incorrect birth year, while the curve fitting model correctly identifies the start of a period of exponential grow around 1960.", "sentence2": "the curve-fitting model works well as a model for word emergence.", "label": "reasoning"}
{"id": "test_1826", "sentence1": "We assume that the amount of samples is more important.", "sentence2": "we investigate this hypothesis by selecting subsets of a 160k generated sample pairs from TRANSLIT.", "label": "reasoning"}
{"id": "test_1827", "sentence1": "The second way a surface word edit can occur is when a compound word is split up into its components; this does not occur a great deal in English and French, but is common in Swedish, German, Icelandic and Dutch.", "sentence2": "for example in Kallocain (Swedish), where the action takes place in an imagined totalitarian society, there are many compounds with \"polis\" = \"police\" (\"polischef\" = \"police chief\", \"polissekreterare\" = \"police secretary\"...), \"tj\u00c3\u0192\u00c2\u00a4nst\" = \"service\" (\"tj\u00c3\u0192\u00c2\u00a4nsteplikt\" = \"service duty\", \"offertj\u00c3\u0192\u00c2\u00a4nst\" = \"sacrifice service\"...), etc.", "label": "reasoning"}
{"id": "test_1828", "sentence1": "A pattern in the library consists of a list of words, each marked by typecase as being either a surface word or a lemma.", "sentence2": "for example in English the phrasal verb \"catch up\" is entered as CATCH up, indicating that \"catch\" can be inflected but not \"up\".", "label": "reasoning"}
{"id": "test_1829", "sentence1": "This last feature was designed intentionally to leverage the power of word embedding techniques, i.e., with the words mapped to an embedding space and the appropriate distance measures, we can easily capture semantically related words to the ones in the lexicons.", "sentence2": "we do not need to build comprehensive vocabularies and can focus on the most representative words for each lexicon dimension.", "label": "reasoning"}
{"id": "test_1830", "sentence1": "Raters are supposed to perform impartial and objective evaluations, and they must enter specific comments in order to ground their scores.", "sentence2": "for each essay in our dataset we also have the corresponding rater comments.", "label": "reasoning"}
{"id": "test_1831", "sentence1": "More specifically, we learn word embeddings (Mikolov et al., 2013c) for the Portuguese language, and then we employed the Word Mover's Distance function (Kusner et al., 2015) between a comment and the five subjectivity lexicons.", "sentence2": "each comment is finally represented by a five-dimensional subjectivity vector, where each dimension corresponds to the amount of a specific type of subjectivity.", "label": "reasoning"}
{"id": "test_1832", "sentence1": "Over the years, thousands of public IT systems have been developed, but they are not communicating in a common language, and there has not previously been a common public plan for how IT systems securely and efficiently can exchange data and become part of a coherent process.", "sentence2": "the government, municipalities and regions have agreed that, as part of the public digitization strategy for 2016-20, a common public architecture for secure and efficient data sharing and the development of processes that connect public services must be established.", "label": "reasoning"}
{"id": "test_1833", "sentence1": "It occurs when researchers share data on personal websites that become obsolete after time.", "sentence2": "we attempt to mitigate that by sharing our corpus on LREC repository.", "label": "reasoning"}
{"id": "test_1834", "sentence1": "Moreover, segmenting Hadith components is a domain-specific task that can be even tricky for the non-specialist.", "sentence2": "automating it ensures consistency in segmentation.", "label": "reasoning"}
{"id": "test_1835", "sentence1": "One of their current projects is studying forged Hadiths attributed to the prophet to understand the political views at a specific time in history.", "sentence2": "forged Hadiths are being discovered and might keep emerging, which indicates a Hadith segmentation tool is not dealing with a closed set of data.", "label": "reasoning"}
{"id": "test_1836", "sentence1": "KPIs are not only considered useful for measuring progress, but also for collecting feedback on the strategy of a research infrastructure.", "sentence2": "in 2018 CLARIN ERIC started work on a framework for KPIs that would help the CLARIN community to describe the progress in developing and operating the research infrastructure for language resources in quantitative terms.", "label": "reasoning"}
{"id": "test_1837", "sentence1": "Because our strings contain logographic material which may not have a clear connection to the phonological representation, alignment is challenging.", "sentence2": "we opted for using models based on the neural encoderdecoder architecture.", "label": "reasoning"}
{"id": "test_1838", "sentence1": "for a coincidentally similar looking lexeme.", "sentence2": "cleaning and more careful selection of the training data would likely have a positive impact on the results.", "label": "reasoning"}
{"id": "test_1839", "sentence1": "Also in syllabic renderings, many transcriptions map unambiguously to one phonological representation.", "sentence2": "it would be useful to minimize ambiguity by first using a large dictionary lookup (e.g. consisting of the whole corpus of a given dialect in Oracc), and then trying to predict the correct phonological rendering only if the transcription is clearly ambiguous", "label": "reasoning"}
{"id": "test_1840", "sentence1": "Arguably, a test corpus sampled uniformly over a one year period might be more representative.", "sentence2": "we first reserve the 2018 fillings (450k sentence pairs) for validation and test.", "label": "reasoning"}
{"id": "test_1841", "sentence1": "In this experiment, we are interested in measuring the impact of train/test overlapping on NMT performance.", "sentence2": "we compare the performance of models trained on randomly picked 2M sentences from sedar-train and tested on 2 variants of the held-out datasets: before and after removing overlapping sentences.", "label": "reasoning"}
{"id": "test_1842", "sentence1": "In most of the work, the focus relies on the models without interpreting the data which performs much better on our own test set rather than on general translated sentences.", "sentence2": "it is essential to analyses, correct and cleans the data before using it for the experiments.", "label": "reasoning"}
{"id": "test_1843", "sentence1": "However, to the best of our knowledge, no comparative analysis of MT errors output by PBSMT and NMT has been done for the English and Brazilian Portuguese language pair.", "sentence2": "in this article we present the first error analysis of a NMT system's output for Brazilian Portuguese.", "label": "reasoning"}
{"id": "test_1844", "sentence1": "The authors provide multiple analyses of NMT outputs compared to PB-SMT ones, considering different characteristics, such as fluency and reordering.", "sentence2": "Toral and Sanchez-Cartagena (2017) state that translations performed by NMt systems tend to be more fluent, however they also observed that quality degrades faster with the sentence length.", "label": "reasoning"}
{"id": "test_1845", "sentence1": "Although tens of thousands of original Japanese documents are disclosed every year (i.e., over 79,000 documents in 2018), the availability of English disclosure documents is limited.", "sentence2": "there is a strong demand for machine translation on both listed companies and global investors since Japanese to English translation needs to be done in a timely manner.", "label": "reasoning"}
{"id": "test_1846", "sentence1": "Furthermore, most investors require TSE-listed companies to disclose both Japanese and English documents simultaneously.", "sentence2": "it is not easy to meet the demand for the English translation of timely disclosure documents using manual translation only.", "label": "reasoning"}
{"id": "test_1847", "sentence1": "However, the subword tokenization solves the problem only if a rare word can be translated as constitutive words.", "sentence2": "even using the subword tokenization, the NMT systems often are often unable to translate neither numbers with many digits nor constitutive proper nouns.", "label": "reasoning"}
{"id": "test_1848", "sentence1": "Taking news domain for example, one entity word usually needs to keep consistent translation across the whole document in newswire.", "sentence2": "the gains mainly come from better translation consistency contributed by document context.", "label": "reasoning"}
{"id": "test_1849", "sentence1": "These root, prefix, and suffix combinations are decompositions of the gold standard words contained in the treebank.", "sentence2": "our vocabulary is larger than that of the gold standard because of the additional patterns applicable to the prefix-root-suffix combinations.", "label": "reasoning"}
{"id": "test_1850", "sentence1": "For instance, a NOUN in PADT UD may be a noun, proper name or function word as it contains words such as myrAv (inheritance) \"noun\", dwlAr (dollar) \"proper name\", and kl (all) \"function word\".", "sentence2": "a word that is analyzed as a noun in PADT UD and analyzed as a function word in our model is marked as a function word and a match occurs.", "label": "reasoning"}
{"id": "test_1851", "sentence1": "The analysis length method depends on a heuristic that shorter analyses are more probable than long ones.", "sentence2": "complex analyses having many tags will have larger weight (less probability) than simple/short ones.", "label": "reasoning"}
{"id": "test_1852", "sentence1": "As can be seen from this example, some of the subtokens such as H, el,, l are not valid English words, whereas some such as world are.", "sentence2": "the effect of subtokenisation on downstream NLP tasks that require the semantics of the original input string to be retained remains unclear.", "label": "reasoning"}
{"id": "test_1853", "sentence1": "Compared to BPE, which produces short and nonsensical subwords, Morfessor is a conservative segmenter that captures longer subwords.", "sentence2": "morfessor reports the best performance on entity typing.", "label": "reasoning"}
{"id": "test_1854", "sentence1": "As observed in Table 2, among the different composition methods, SIF method reported the best results across languages.", "sentence2": "we use SIF for creating word embeddings from subword embeddings in this experiment.", "label": "reasoning"}
{"id": "test_1855", "sentence1": "Incorporating characterlevel embeddings via LSTMs has shown to improve performance for named entity recognition tasks (Zhai et al., 2018).", "sentence2": "applying more sophisticated supervised composition methods such as a recurrent neural network might help to create word embeddings from subtoken embeddings under such situations.", "label": "reasoning"}
{"id": "test_1856", "sentence1": "Because of the corpus' conversational style (Khalifa et al., 2016a), some portions of the text had particularly long sentences.", "sentence2": "we split sentences in a cascading fashion with a length of 200 words and a buffer of 10 words at the beginning of the new sentence from the previous one to maintain contextual integrity.", "label": "reasoning"}
{"id": "test_1857", "sentence1": "A limitation of this research paradigm, of course, is that systems that are directly designed to identify morpheme boundaries do not provide more information than the morpheme itself.", "sentence2": "it is not possible to tell the exact morphological structure of complex words, including how these complex words are derived from simpler words and what kind of morphological features the morphemes are corresponding to such as prefixes, suffixes, etc.", "label": "reasoning"}
{"id": "test_1858", "sentence1": "Domain changes will certainly impact the neighborhoods in the embedding space.", "sentence2": "a comparison of words relative distances in two embedding spaces can be used to measure their degree of domain shift (Kulkarni et al., 2015;Asgari and Mofrad, 2016).", "label": "reasoning"}
{"id": "test_1859", "sentence1": "GP is designed to be uniform across languages with respect to the amount of data per language, the audio quality (microphone, noise, channel), the collection scenario (task, setup, speaking style), as well as the transcription and phone set conventions (IPA-based naming of phones in all pronunciation dictionaries).", "sentence2": "gP supplies an excellent basis for research in the areas of (1) multilingual ASR, (2) rapid deployment of speech processing systems to yet unsupported languages, (3) language identification tasks, (4) speaker recognition in multiple languages, (5) multilingual speech synthesis, as well as (6) monolingual ASR.", "label": "reasoning"}
{"id": "test_1860", "sentence1": "However, texts used in our analysis are random sentences selected from different sources, mainly from newspapers.", "sentence2": "we computed average TTR (ATTR) for the training transcription based on k disjunct 1000-utterance subsets of the training set instead of MATTR.", "label": "reasoning"}
{"id": "test_1861", "sentence1": "On the other hand, developing large-scale language resources is not economically viable.", "sentence2": "alternative approaches need to be used to make Ethiopians benefit from speech and language processing tools.", "label": "reasoning"}
{"id": "test_1862", "sentence1": "We also gather participants' meta-data, including their gender, age, education, occupation, perceptions about CS as well as their personality traits, gathered through the Big-5 Personality Test.", "sentence2": "this corpus serves as a useful resource in multiple fields, including NLP applications (mainly designed for ASR systems), linguistic analysis of the CS phenomenon, as well as sociolinguistic and psycholinguistic analyses.", "label": "reasoning"}
{"id": "test_1863", "sentence1": "It is claimed that dialectal Arabic was used as a tool to heighten the distinctiveness and distance of Egypt from the rest of the Arab world.", "sentence2": "mSA was facing a threat posed by both, the foreign and dialectal languages.", "label": "reasoning"}
{"id": "test_1864", "sentence1": "It can be seen that 40% of the speakers are within the normal 140-160 range, 30% are below the rate and 30% are above.", "sentence2": "for 30% of the interviews, accurate speech recognition for humans and ASR systems would be more challenging", "label": "reasoning"}
{"id": "test_1865", "sentence1": "In order to avoid having the interviewers as common speakers across all sets, their utterances have been placed in the train set.", "sentence2": "the train set contains utterances from 4 female and 8 male interviewees, in addition to 1 female and 1 male interviewer.", "label": "reasoning"}
{"id": "test_1866", "sentence1": "Information about participants is also collected, including gender, age, educational background, perceptions about CS and personality traits.", "sentence2": "the corpus serves as a useful resource for multiple research directions.", "label": "reasoning"}
{"id": "test_1867", "sentence1": "As mentioned before, the maximum size is 20 times higher than the minimum.", "sentence2": "during 1 epoch for 1 sample in, for example, Russian as the target language, the model sees 20 samples in Odia.", "label": "reasoning"}
{"id": "test_1868", "sentence1": "We observed that users tend to create ambiguous mentions in tweets when they employ any expression (for example first or last name) other than Twitter screen names to mention other users in their posts (see Section 1).", "sentence2": "we have drawn inspiration from this usage to elaborate a simple process for both candidate entity and ambiguous mention generations.", "label": "reasoning"}
{"id": "test_1869", "sentence1": "The Twitter Search  API 5 returns a collection of relevant tweets matching the specified query.", "sentence2": "for each entity in the KB, i) we set its screen name (@user) as the query search; ii) we collected all the retrieved tweets, and iii) we filtered out tweets without images.", "label": "reasoning"}
{"id": "test_1870", "sentence1": "After a long study, we assumed that a thematic boundary can only be in the vicinity of a slide change during the course.", "sentence2": "for each change of slide, a human ex\u0002pert annotated: 1. If there is a topic shift. 2. The exact moment of the topic shift defined as being positioned between two words. 3. The granularity of the topic shift (1 or 2) or if the seg\u0002ment type is an interruption.", "label": "reasoning"}
{"id": "test_1871", "sentence1": "In all, 134 of these occur with images showing flooding (IF), the majority (110) with articles about current flooding or the aftermath of recent flooding where the keyword is also found in the headline of the article.", "sentence2": "there are 62 articles about current flooding with a flooding image and 48 articles about the aftermath of a recent flooding, where both the headline and the caption contain one of the keywords.", "label": "reasoning"}
{"id": "test_1872", "sentence1": "However, these same features mean that movies and TV are not representative of day-today life.", "sentence2": "these datasets cannot be used to evaluate how well models perform when applied to realistic videos of day-to-day life.", "label": "reasoning"}
{"id": "test_1873", "sentence1": "However, unlike them, our proposed dataset relies on video clips that were recorded naturally by people, without predefined scripts.", "sentence2": "understanding videos requires overcoming challenges such as environmental noise, camera movements, lighting conditions, and naturally occurring dialogues.", "label": "reasoning"}
{"id": "test_1874", "sentence1": "We interpret this behaviour as follows: For compounds with low-compositional modifiers the semantic relatedness compound-modifier is low, and here the strength of semantic relatedness compound-head (which is effectively WORD2) correlates with the degree of compositionality of the phrase.", "sentence2": "in cases with low compound-modifier relatedness the degree of compositionality of the compound phrase and the compound-head pair are similar in their ranks across compounds.", "label": "reasoning"}
{"id": "test_1875", "sentence1": "BPE tokenization has become a de-facto standard way for processing sub-words in the era of BERT (Devlin et al., 2019) and BERT-like models.", "sentence2": "we decided to draw a comparison between BPE tokenization and simpler character-level models, frequently used for segmentation in Chinese (Xue and Shen, 2003) or Arabic (Samih et al., 2017).", "label": "reasoning"}
{"id": "test_1876", "sentence1": "Despite some public pre-trained embedding vectors being already available for Portuguese (Bojanowski et al., 2017;Hartmann et al., 2017;Santos et al., 2019), the highly technical oil and gas vocabulary presents a challenge to Natural Language Processing applications, in which some terms may assume a completely different meaning compared to the general-context domain.", "sentence2": "there are consistent evidences that generating embedding models from a domain-specific corpus can significantly increase the quality of their semantic representation and, hence, the performance of NLP applications on specialized downstream tasks on the same domain (Gomes et al., 2018;Nooralahzadeh et al., 2018;Lai et al., 2016).", "label": "reasoning"}
{"id": "test_1877", "sentence1": "However, it is hard to guarantee that each representation contains only the corresponding information.", "sentence2": "reconstruction from these two parts directly might cause confliction in both content and sentiment aspects, which leads to poor performance in content preser-vation.", "label": "reasoning"}
{"id": "test_1878", "sentence1": "Note that the sentiment representations should be suitable for the semantic content of the template.", "sentence2": "the modification should be combined with the contextual information of the template with target sentiment information.", "label": "reasoning"}
{"id": "test_1879", "sentence1": "Since most research focuses on shorter sentence-level texts, it is not clear whether these models can form sufficiently long range dependencies to be useful as a substitute for genuine training data.", "sentence2": "we believe that applying NLG approaches to medical text for augmentation purposes is a worthwhile research area in order to ascertain its viability.", "label": "reasoning"}
{"id": "test_1880", "sentence1": "We are still not at a stage yet where we can release de-identified patient data publicly, whether this genuine or synthetic, due to their unquantified susceptibility to re-identification attacks.", "sentence2": "even if we develop a model which shows strong performance in generating synthetic clinical notes, these notes cannot be easily shared with the wider research community.", "label": "reasoning"}
{"id": "test_1881", "sentence1": "Although EIEC is annotated with four entity types (Location, Person, Organization and Miscellaneous), the Miscellaneous class is rather sparse, occurring only in a proportion of 1 to 10 with respect to the other three classes.", "sentence2": "in the training data there are 156 entities annotated as Mis\u0002cellaneous whereas for each of the other three classes it contains around 1200 entities.", "label": "reasoning"}
{"id": "test_1882", "sentence1": "was first collected in order to make a cross-cultural comparison of smiling during humorous productions between American English and French (Priego-Valverde et al., 2018).", "sentence2": "it was recorded following the American protocol, as closely as possible, especially concerning the tasks given to the participants (see section 2.2).", "label": "reasoning"}
{"id": "test_1883", "sentence1": "They show that, even if smiling is present in the whole conversation, its intensity is higher during humor productions.", "sentence2": "the authors hypothesize that an increase in smiling intensity is a more significant way to frame an exchange as humorous than the sole presence of smiling.", "label": "reasoning"}
{"id": "test_1884", "sentence1": "Laughter is far less frequent and, unsurprisingly, displaying a neutral face is rare.", "sentence2": "observing smiling in a binary way (presence/absence), tends to confirm the assumption that smiling is a marker of humor.", "label": "reasoning"}
{"id": "test_1885", "sentence1": "On the one hand, smiling is the most present facial behavior both in successful and in failed humor.", "sentence2": "it does not seem to reduce the risk of failure.", "label": "reasoning"}
{"id": "test_1886", "sentence1": "Using BLEU, these two sentences would not receive the same score since BLEU is based on orthographic similarity.", "sentence2": "bLEU inherently penalizes use of approved terminology even when it is used appropriately.", "label": "reasoning"}
{"id": "test_1887", "sentence1": "The overall architecture of the ontology follows the guiding principles and complies with the data standards for cataloguing cultural objects (Baca, 2006).", "sentence2": "it could be easily incorporated in larger projects for ontological modelling of knowledge on cultural and historical heritage.", "label": "reasoning"}
{"id": "test_1888", "sentence1": "The object property spokenIn relates a dialect with an administrative or geographic location where this dialect can be found.", "sentence2": "each dialect is related to at least one place, but multiple relations of this type are also conceivable.", "label": "reasoning"}
{"id": "test_1889", "sentence1": "In addition, there is also an interface package (IBGDialectsOntology) which contains all the methods that might be used to extract information from the ontology, and defines the parameters that could be sent by the graphical user interface.", "sentence2": "we enable users to choose among different criteria for filtering and extracting information.", "label": "reasoning"}
{"id": "test_1890", "sentence1": "The method is public and implements the method getIndividualsInSignature() of the org.semanticweb.owlapi.model.OWLOntology class.", "sentence2": "it returns a list of the type OWLNamedIndividual, which can then be handled by the BgDialectsOnto methods.", "label": "reasoning"}
{"id": "test_1891", "sentence1": "Although the features encoded in the ontology seem rather specific for the historical development of the Bulgarian language and its dialects, the overall design of the hierarchies of classes and properties can be easily adapted and applied to other languages.", "sentence2": "it offers scope for valuable contribution that goes beyond national and regional borders.", "label": "reasoning"}
{"id": "test_1892", "sentence1": "The taxonomy is a tree structure with the majority of nodes positioned near the bottom of the tree.", "sentence2": "as there are only a handful of nodes near the top, each time the random walk restarts, it is far more likely to start the random walk at a leaf node somewhere at the bottom of the taxonomy, rather than at the top.", "label": "reasoning"}
{"id": "test_1893", "sentence1": "Among the collected reviews, we worked on 6,287 reviews, which were segmented into sentences.", "sentence2": "the dataset consists of 17,268 sentences whose length is about 10 tokens on average.", "label": "reasoning"}
{"id": "test_1894", "sentence1": "Online reviews are unstructured information and may contain various types of noise.", "sentence2": "the process of cleaning and normalization of text is essential for the analysis.", "label": "reasoning"}
{"id": "test_1895", "sentence1": "Since the adversative conjunction guide the reader to more salient information, the argumentative force is combined with the latter statement.", "sentence2": "we can categorize the first statement as POS OPINION and the second one as NEG OPINION, and yet attribute more weights on the latter.", "label": "reasoning"}
{"id": "test_1896", "sentence1": "The proposed scheme was specific to restaurants, but it can also be applied to other places such as hotels, vacation spots, shop- ping malls, theaters, etc., particularly considering that getting the visitors to revisit should be one of their primary goals.", "sentence2": "a natural extension of this work would be to study the possibility of application of our scheme in other places and different languages.", "label": "reasoning"}
{"id": "test_1897", "sentence1": "Nowadays Personal Assistants (PAs) are available in multiple environments and become increasingly popular to use via voice.", "sentence2": "we aim to provide proactive PA suggestions to car drivers via speech.", "label": "reasoning"}
{"id": "test_1898", "sentence1": "Especially, when the user drives or is busy with another task at home (e.g., cooking), the interaction with a PA is only the secondary task.", "sentence2": "user experience designers need to focus on the user's cognitive load in such settings, too.", "label": "reasoning"}
{"id": "test_1899", "sentence1": "In binary classification framework, we regrouped the reviews as proposed in (Nabil et al., 2014): the reviews associated with one or two stars compose the negative class and those with four or five stars represent the positive class.", "sentence2": "the neutral reviews are not considered.", "label": "reasoning"}
{"id": "test_1900", "sentence1": "These embeddings are created by taking into account the morphology of words, instead of treating them as distinct units.", "sentence2": "using this method, each word is represented as a sum of the representations of the character N-grams constituting it, giving us the opportunity to experiment with models that focus on N-grams in a sample to perform the classification.", "label": "reasoning"}
{"id": "test_1901", "sentence1": "This is not the case for fastText embeddings, as they are non-contextual by nature.", "sentence2": "the non-contextual linguistic features may not add the same amount of advantage to the models using fastText embeddings in comparison to the models that use BERT and CamemBERT embeddings.", "label": "reasoning"}
{"id": "test_1902", "sentence1": " Due to this factor, and also because tweets in our collection are not longer than 140 characters11, most of the time only one false assertion is present in the text", "sentence2": "the syntactic head of the only false assertion present (or false reported speech) has been easily marked, thus lowering the possibility of disagreement.", "label": "reasoning"}
{"id": "test_1903", "sentence1": "Because of this, occasionally during the voting period, we manually deprioritized the tweets that got three or more negative votes, to keep in the pool only the tweets that still had a chance of being considered positive.", "sentence2": "the corpus contains some tweets that do not have five votes, mainly the non-humorous ones.", "label": "reasoning"}
{"id": "test_1904", "sentence1": "We manually inspected all pairs, clustered them into equivalence classes, and took one example from each class discarding the others from the corpus.", "sentence2": "we pruned 1,278 tweets from the corpus, most of them were humorous.", "label": "reasoning"}
{"id": "test_1905", "sentence1": "At the same time, finding jokes within in-the-wild long texts can be problematic since you have to account for its boundaries concerning non-humorous content.", "sentence2": "we collect jokes from Twitter, supposing a tweet is either completely humorous or not at all.", "label": "reasoning"}
{"id": "test_1906", "sentence1": "A low degree of morphological ambiguity is a planned design feature of Esperanto and, together with its regular inflection and affixation system, meant to make the language easy to learn.", "sentence2": "automatic annotation is very reliable at this level, and few ambiguity classes exist, with little need for human revision.", "label": "reasoning"}
{"id": "test_1907", "sentence1": "The only systematic POS ambiguity is between proper nouns and other word classes because of upper-casing (especially in sentence-initial position), and in connection with tokenization errors.", "sentence2": "the otherwise reliable vowel coding for POS (e.g. -o = noun, -a = adjective, -i = infinitive, -e = adverb) breaks down in the face of foreign names in (a) and (b).", "label": "reasoning"}
{"id": "test_1908", "sentence1": "However, we try to avoid unnecessary tag complexity by not introducing different syntactic tags, where POS already contains the distinction.", "sentence2": "phrase-level modifiers are only attachment-tagged as prenominals (@>N) and postnominals (@NA)1 and post-adjects (@A<), not for what the modifier itself is (e.g. hypothetical @nmod for a modifier that is a nouns), because that would just be duplicated information.", "label": "reasoning"}
{"id": "test_1909", "sentence1": "It should be noted that some of the NE categories are intentionally vague and express \"semantic (lexical) form\" rather than \"semantic function\", leaving the latter to subsequent disambiguation at the semantic role level.", "sentence2": "and can fill both agent and location slots, i.e. go to war or raise taxes on the one hand, and be lived in or traveled to on the other.", "label": "reasoning"}
{"id": "test_1910", "sentence1": "German and Danish, because compounding is more transparent in Esperanto than in languages with a lot of idiomatic traits.", "sentence2": "the word 'bag' in German ('Tasche') or Danish ('taske') can occur as second part in compounds that do not denote a container, e.g. German 'Plaudertasche' (chatter box) and Danish 'havtaske' (monk fish).", "label": "reasoning"}
{"id": "test_1911", "sentence1": "One way to elicit these senses during linguistic data revision was to look for compounds with 'fonto' where the first part can help to disambiguate the sense of the second.", "sentence2": "'akvofonto' (spring) is classified as <Lwater>, 'monfonto' (funding) as <Labs> (abstract source), 'interretfonto' (online sources) as <Lsem> and 'petrolfonto' (oil well) as <Lh> (human functional place).", "label": "reasoning"}
{"id": "test_1912", "sentence1": "In a breakdown of individual categories (table 2) pp\u0002attachment problems left their predictable mark, with postnominal pp's (PRP @N", "sentence2": "19.8% of attachment errors and 26.8% of function errors involved the postnominal category, and 90% of cases were pp's.", "label": "reasoning"}
{"id": "test_1913", "sentence1": "Table 2 contains only the major categories, and it lumps all clause functions into only two groups, finite and nonfinite, but it clearly shows what is difficult for function tagging and for attachment tagging, respectively.", "sentence2": "coordinators (@CO) and, to a lesser degree, adverbials (@ADVL) are more an attachment than a labeling problem, while copula complements (@SC) and subjects (@SUBJ) are more a labeling than an attachment problem.", "label": "reasoning"}
{"id": "test_1914", "sentence1": "The resulting value tells us, how much a category is over-represented among errors as compared to its share among running tokens.", "sentence2": "the most unreliable categories in terms of function labeling are @N<PRED and @NPHR (9 times over-represented), while all clauselevel categories with the exception of complements, i.e subjects, objects and adverbials are safe (underrepresented).", "label": "reasoning"}
{"id": "test_1915", "sentence1": "In addition, heavy modifier material seems to be moved to the right.", "sentence2": "all modifier clauses, including participle clauses, were placed to the right, as well as half of the coordinated adjectival modifiers.", "label": "reasoning"}
{"id": "test_1916", "sentence1": "Coverage is measured by breaking down the LFG scores according to whether the parser yields full parses or non-full parses (i.e. FRAGMENT, SKIMMED, or SKIMMED+FRAGMENT parses).", "sentence2": "coverage is defined as the percentage of parsed sentences in relation to the full corpus, and to measure it, an evaluation was conducted against the 2364 test sentences.", "label": "reasoning"}
{"id": "test_1917", "sentence1": "A weakness with the coverage metric is that it does not guarantee that the assigned parse is indeed the correct one (Carroll et al., 1998).", "sentence2": "accuracy was used in addition to assess parsing quality.", "label": "reasoning"}
{"id": "test_1918", "sentence1": "The experiments showed that the discourse type should be considered while training and interpreting the results.", "sentence2": "the results of dependency parsing are more relevant to integrate in CRF model for the monologue in which the utterances are long and dependencies relations are more present.", "label": "reasoning"}
{"id": "test_1919", "sentence1": "Especially if a short video is given to users, most fragmentary facts within the scope of previous tasks can be easily perceived by themselves even before asking questions.", "sentence2": "video question answering is expected to provide answers to more complicated non-factoid questions beyond the simple facts.", "label": "reasoning"}
{"id": "test_1920", "sentence1": "The other issue is that many videos with sufficient amounts of information, which a user is likely to pose questions on, have much longer lengths than the video clips in the existing datasets.", "sentence2": "in practice, the most relevant part of a whole video needs to be determined prior to each an-swer generation phase.", "label": "reasoning"}
{"id": "test_1921", "sentence1": "Its goal is to distinguish the requests for information, which are sent to the QA system, from all other utterances including greetings and chitchat, which are sent to the chatbot.", "sentence2": "instead of a using a complex dialogue act hierarchy (Bunt et al., 2012), our controller only needs to make a binary decision, which can be carried out using context-free classifiers (Clark and Popescu-Belis, 2004).", "label": "reasoning"}
{"id": "test_1922", "sentence1": "Another option is to use a large set of questions that jointly test the performance of the controller, the QA component and the chatbot -however, to the best of our knowledge, such a data set does not exist.", "sentence2": "we use several component-level evaluation methods along with our own subjective testing, to assess the overall system's performance.", "label": "reasoning"}
{"id": "test_1923", "sentence1": "Open-domain tasks are usually more explored than domainspecific ones, mainly because of the ease of access to datasets and support from a wider research community.", "sentence2": "open-domain methods and datasets are frequently applied to closed domains that lack sufficiently large datasets.", "label": "reasoning"}
{"id": "test_1924", "sentence1": "Modeling deep learning methods usually requires a large amount of training data.", "sentence2": "we use 3 different large machine comprehension datasets for our analysis.", "label": "reasoning"}
{"id": "test_1925", "sentence1": "The authors of the original paper mentioned that word n-grams and word embeddings are not suitable for cross-language classification.", "sentence2": "the considered features are: baseline, domain features, POS n-grams and dependency n-grams.", "label": "reasoning"}
{"id": "test_1926", "sentence1": "The lack of sufficient training data becomes the bottleneck for automatic Chinese irony detection.", "sentence2": "it is of big importance to introduce a reasonably large and more diverse dataset suited for training machine learning algorithms as well as serving as a more reliable gold standard for Chinese irony detection.", "label": "reasoning"}
{"id": "test_1927", "sentence1": "But the contextual information for identifying the speaker's intention in this case is missing.", "sentence2": "insufficient evidence is given in this case.", "label": "reasoning"}
{"id": "test_1928", "sentence1": "Since wikiHow is a collaborative online community, anyone can contribute and not all edits are relevant to the article content.", "sentence2": "it is necessary to identify and filter irrelevant edits.", "label": "reasoning"}
{"id": "test_1929", "sentence1": "However, we found it difficult for annotators to pinpoint differences between versions where edits modify or provide new information, in contrast to providing only stylistic changes.", "sentence2": "we designed the task such that annotators had to formulate questions on the presented information whenever possible.", "label": "reasoning"}
{"id": "test_1930", "sentence1": "We analyze a random sample of revision groups for which this pattern holds and observe that: 1) early edits mostly fix spelling mistakes, case, or simple grammatical errors, which are easy to detect; 2) intermediate versions are most difficult to distinguish, because changes made in them are mostly due to the addition or deletion of information for stylistic reasons or due to the need for subtle semantic refinements; 3) final edits usually improve clarity by resolving ambiguities and other potential issues.", "sentence2": "they can be slightly easier to rank than some of the intermediate versions.", "label": "reasoning"}
{"id": "test_1931", "sentence1": "Furthermore, this is consistent with the hypothesis stated in Section 3.2: adopting only the vector of the first sense of each word harms the performance.", "sentence2": "we have confirmed that the lower performance of the multi-sense models on previous datasets was not a result of the models' inability to handle non-major senses, but a result of the biases toward single-sense words and major senses in those datasets.", "label": "reasoning"}
{"id": "test_1932", "sentence1": "A semantic attribute of a concept, such as \"an apple is red\", explicitly dictates a semantic aspect of the concept.", "sentence2": "given an appropriate set of attributes, a concept can be represented by a bundle of attributes.", "label": "reasoning"}
{"id": "test_1933", "sentence1": "No linguistic indication is given as to how UBs are specifically attributed, and no linguistic test is provided to discriminate between UBs.", "sentence2": "we had to clarify and refine WordNet definitions of UBs, which may have resulted in modifications in supersense extensions.", "label": "reasoning"}
{"id": "test_1934", "sentence1": "Plant-denoting nouns denote natural objects, and had to be distinguished from closely related supersenses such as Object (see Table 1, line 5).", "sentence2": "we refined definitions so as to avoid overlaps in supersense extensions.", "label": "reasoning"}
{"id": "test_1935", "sentence1": "High-quality user attributes are, however, hard to obtain since the information in social networks such as Facebook and Twitter is often sparsely populated (Li et al., 2014).", "sentence2": "exploiting unstructured data sources to obtain structured user attributes is a challenging research direction.", "label": "reasoning"}
{"id": "test_1936", "sentence1": "According to the dual coding theory (Clark and Paivio, 1991), the formation of mental images aids in learning, although this advantage may not be available for abstract words as these are less likely to have corresponding word-to-image referential connections.", "sentence2": "abstract words can be more challenging to learn and memorise.", "label": "reasoning"}
{"id": "test_1937", "sentence1": "While participants were strongly encouraged to wear a headset, not all of them followed this rule.", "sentence2": "the audio quality varies between speakers.", "label": "reasoning"}
{"id": "test_1938", "sentence1": "In the beginning of the interaction, the robot commented on being assembled in Stockholm, Sweden, and having traveled to France in previous years.", "sentence2": "those two countries were added to the initial knowledge base of the agent.", "label": "reasoning"}
{"id": "test_1939", "sentence1": "Our experiments show that the distribution of tweets in our collection is similar to the distribution of tweets in samples collected randomly using the Twitter \"sample\" API.", "sentence2": "we can consider that we do not introduce any bias in our dataset (some events being more represented than others, for example) linked to the collection method.", "label": "reasoning"}
{"id": "test_1940", "sentence1": "The annotation interface has been designed to take advantage of the annotators' intelligence and avoid repetitive tasks.", "sentence2": "it seemed unnecessary to make them annotate tweets that contained exactly the same text.", "label": "reasoning"}
{"id": "test_1941", "sentence1": "We conducted a manual analysis of 216 disagreement cases with the aim to extract the most common patterns, which contribute to the difficulty of the annotation task.", "sentence2": "we found several difficult cases", "label": "reasoning"}
{"id": "test_1942", "sentence1": "Besides, the lifetime of a troll account can be very short.", "sentence2": "detecting troll tweets only using text should be considered.", "label": "reasoning"}
{"id": "test_1943", "sentence1": "Character and word n-grams can capture important morphological properties and discover useful inter-word and inter-phrase features.", "sentence2": "they have been used as the core of many authorship analysis systems (Jankowska et al., 2014; Schwartz et al., 2013; Layton et al., 2010).", "label": "reasoning"}
{"id": "test_1944", "sentence1": "Using the following irony-related hashtags: (\"#irony\"), (\"#ironical\"), (\"#mockery\"), and #sarcasm, we built a dataset of 5,358 Arabic messages posted on Twitter.", "sentence2": "of individual analysis and follow-up discussions, our annotators have labeled 4,809 (89.75%) as \"Ironic\", 435 (8.12%) as \"Not Ironic\", and 114 (2.13%) as \"Ambiguous\".", "label": "reasoning"}
{"id": "test_1945", "sentence1": "In the following experiments, we study whether the improved robustness through knowledge transfer of the English model is due to weight transfer, as we expect, or due to better i-vector extractor trained on English data instead of German.", "sentence2": "we compare each combination of using German or English trained i-vector extractors each with a random model initialization or initialization of hidden layers with the English trained model when training on the 1000 hour German broadcast data.", "label": "reasoning"}
{"id": "test_1946", "sentence1": "Thereby we have shown that the direct adaptation of LF-MMI acoustic models from one language to another leads to good results, even using only very little training data from the target domain.", "sentence2": "this observation can contribute to the ongoing research on speech recognition for under-resourced language.", "label": "reasoning"}
{"id": "test_1947", "sentence1": "Using the English i-vector extractor instead of the German one with random acoustic model initialization only leads to slightly better results on three test sets and slightly worse results on two test sets.", "sentence2": "we conclude that, in deed, weight transfer leads to better results-and not a bet-ter i-vector extractor trained on English data.", "label": "reasoning"}
{"id": "test_1948", "sentence1": "One syntactic structure can also be organized within several prosodic periods.", "sentence2": "periods act as a way of topicalization.", "label": "reasoning"}
{"id": "test_1949", "sentence1": "The extracts represent different types of speech in terms of conversational environment, relationships between the speakers, etc.", "sentence2": "this pilot corpus contains transcriptions of preparing a meal, meetings, conferences, radio transmissions, interviews, etc.", "label": "reasoning"}
{"id": "test_1950", "sentence1": "Segmentation of periods applies 4 criteria: 1) pause lasting for at least 300 milliseconds; 2) difference in height between the mean value of fundamental frequency over all the signal before the pause and the last value of fundamental frequency before the pause; 3) difference in height between the last value of fundamental frequency before the pause and the first one after the pause; 4) absence of hesitation (\u00ab euh \u00bb) just before or after the pause. ", "sentence2": "analor considers period as a prosodic segment between two pauses with its own melodic shape.", "label": "reasoning"}
{"id": "test_1951", "sentence1": "It is also worth noting that the Malayalam corpus contains significantly more vocabulary, with lesser mean word frequency.", "sentence2": "we argue that this language would pose a bigger challenge for the TTS models.", "label": "reasoning"}
{"id": "test_1952", "sentence1": "There are 16 dialects in Japan, and these dialects have been found to effect the accuracy of speech recognition (Kudo, 1996).", "sentence2": "when selecting recording areas for our corpus, we sought to include a balanced distribution of Japanese dialects.", "label": "reasoning"}
{"id": "test_1953", "sentence1": "We also did not consider the gender ratio of our participants.", "sentence2": "currently the total number male participants in our corpus is 70, and the total number of female participants is 151 (table 1).", "label": "reasoning"}
{"id": "test_1954", "sentence1": "The shortcoming of the original implementation is that the first and the last heads do not interact as they are assumed not to be adjacent.", "sentence2": "we assume that considering the heads' sub-spaces periodically, we can increase the model's effectiveness by applying circular convolution to the second dimension.", "label": "reasoning"}
{"id": "test_1955", "sentence1": "The vectors at the overlapping positions are averaged (by summing and dividing by the number of overlapping vectors).", "sentence2": "we have the matrix of embeddings with the shape of the hidden size times the length of the text.", "label": "reasoning"}
{"id": "test_1956", "sentence1": "The quantity of overlap shows how much the summary and source texts contain similar concepts but it can only be a first hint as to whether the information in the sources is sufficient to re-create the abstractive summary given a particular user-query.", "sentence2": "in addition to the overlap, we create extractive summaries from the selected candidate sources based on the abstractive summary.", "label": "reasoning"}
{"id": "test_1957", "sentence1": "In addition, at this large a scale, due to slow download rates from the free archive.org/web service, scraping all possible urls is unfeasible.", "sentence2": "detecting noisy (poor quality) urls can help reduce the risk of wasting download time on unusable articles.", "label": "reasoning"}
{"id": "test_1958", "sentence1": "By contrast, because the extractive fragments are short, density will indicate extractive-ness.", "sentence2": "combining density with coverage allows one to identify summaries that are mixed extractive and abstractive (so-called \"mixed summaries\") that compose abstractivelike summaries from short sequences of text found in the article.", "label": "reasoning"}
{"id": "test_1959", "sentence1": "In this paper we introduce this multimodal corpus which includes neural data from functional magnetic resonance imaging (fMRI), physiological data (blood flow pulse and respiration), transcribed conversational data, as well as face and eye-tracking recordings.", "sentence2": "we present a unique corpus to study human conversations including neural, physiological and behavioral data.", "label": "reasoning"}
{"id": "test_1960", "sentence1": "We recorded three minutes of conversation per conversational agent in each block (6 minutes total in each block).", "sentence2": "for each participant twenty-four minutes of conversation were recorded.", "label": "reasoning"}
{"id": "test_1961", "sentence1": "Data analysis of this corpus aims to integrate the multimodal markers of conversation to comprehensively characterize human conversation and conversation with an artificial agent.", "sentence2": "the presented corpus allows, for the first time, to include multimodal conversational data in the investigation of bidirectional interaction.", "label": "reasoning"}
{"id": "test_1962", "sentence1": "Scored items compete with pretest items for exam space, the scarcity of which can create a bottleneck.", "sentence2": "it is sometimes not possible to pretest as many new items as needed and some exam programs may not be able to afford pretesting at all.", "label": "reasoning"}
{"id": "test_1963", "sentence1": "It shows that NLI models fit the artificial patterns in the training set very well, which makes them fragile to the adversarial examples (hard set) which are against these patterns.", "sentence2": "we assume the artificial patterns contributes to the hypothesis-only bias.", "label": "reasoning"}
{"id": "test_1964", "sentence1": "To train fact checking systems, we also need claims that are refuted by the evidence documents to serve as negative examples.", "sentence2": "we generated claims that are refuted by the evidence.", "label": "reasoning"}
{"id": "test_1965", "sentence1": "from unlabeled data by itself and generate representations in a way that helps detect word boundaries.", "sentence2": "the representations from the LM have shown to have a positive impact on the word segmentation performance.", "label": "reasoning"}
{"id": "test_1966", "sentence1": "This means that the classification was made qualitatively.", "sentence2": "it is not certain whether or not the proposed classification is appropriate.", "label": "reasoning"}
{"id": "test_1967", "sentence1": "On the other hand, since it is not necessary to deeply consider the content of narratives for uttering responses with low concreteness like \"response 5,\" the degree of empathy shown by these responses tends to be low.", "sentence2": "the concreteness of responses is thought to reflect the degree of empathy they express.", "label": "reasoning"}
{"id": "test_1968", "sentence1": "For uttering these responses in appropriate timings, it is necessary to deeply understand the content of narrative.", "sentence2": "contrary to the versatility, the degree of empathy shown by these responses to narrative tends to become high.", "label": "reasoning"}
{"id": "test_1969", "sentence1": "Furthermore, it is considered that back-channel responses can be uttered regardless of contents of narrative.", "sentence2": "the timings when these responses can be uttered are diverse and the versatility of these responses is high.", "label": "reasoning"}
{"id": "test_1970", "sentence1": "For measuring ent, information on co-occurrence of responses is necessary.", "sentence2": "the start time of response was mapped onto the nearest position of the following one in the narrative speech, considering that responses tend to be uttered right after a linguistic or phonetic boundary, namely: 1. clause boundary (linguistic) 2. pause longer than 200 milliseconds (phonetic)", "label": "reasoning"}
{"id": "test_1971", "sentence1": "Even with these additions, the parser can still match overlapping phrases.", "sentence2": "the user can specify which phrases to keep.", "label": "reasoning"}
{"id": "test_1972", "sentence1": "The Estonian Reference Corpus (ERC) was missing information about paragraph boundaries, which is crucial for sentence segmentation.", "sentence2": "we replaced the ERC with the original version by exporting texts from (Laur, 2018), in which paragraph endings are marked by double newlines.", "label": "reasoning"}
{"id": "test_1973", "sentence1": "For morphological analysis, we grouped an-notations by words, so that overlapping and differing morphological annotations of a word formed a single unit of evaluation.", "sentence2": "situations arose when, despite the difference, \"both tools are correct\", because ESTNLTK can leave morphological analysis ambiguous.", "label": "reasoning"}
{"id": "test_1974", "sentence1": "In addition to the more traditionally used features (Dell'Orletta et al., 2011), this work incorporates discursive features as well as the relatively newly developed morphological complexity index.", "sentence2": "it aims to push the boundaries of text difficulty classification systems in two respects: 1) by linking the automatic assessment of a text to Italian CEFR levels; 2) by incorporating the linguistic features previously found in separate studies into a single study.", "label": "reasoning"}
{"id": "test_1975", "sentence1": "For most cases however, from the perspective of the NLP and Machine Learning communities, all these RDF or graph representations just display one more format to be dealt with before relevant data can be used in respective pipelines.", "sentence2": "each data source tends to be handled by a task-specific \"python wrapper\" 9 and then injected to the actual NLP workflow.", "label": "reasoning"}
{"id": "test_1976", "sentence1": "Real user behavior can be unpredictable and vary widely from user to user.", "sentence2": "it is difficult for simulated dialogues to capture all aspects of real use, especially the relative frequencies of different kinds of issues.", "label": "reasoning"}
{"id": "test_1977", "sentence1": "Each button corresponds to a Wizard action which is then transformed into a sentence (through template-based natural language generation) and provided to the user.", "sentence2": "the human user receives system output and responds accordingly.", "label": "reasoning"}
{"id": "test_1978", "sentence1": "The features of the profile serve as a guide for the Wizard.", "sentence2": "the Wizard uses buttons that generate appropriate language for conversational vs. formal/direct behavior and explicit vs. implicit system responses.", "label": "reasoning"}
{"id": "test_1979", "sentence1": "The system policy and the SU do not have access to each other's internal representations and can deal with misunderstandings and missing information by using techniques such as reference resolution.", "sentence2": "both the system policy and the SU are very realistic and can work with other users and system policies respectively.", "label": "reasoning"}
{"id": "test_1980", "sentence1": "Children with ASD prefer more limited social interaction compared to children without ASD, hence measurement of eye gaze as a screening tool may be an important contribution in this area (Vargas-Cuentas et al., 2017).", "sentence2": "the development of innovative assistive technologies can alleviate current challenges and improve diagnostic accuracy.", "label": "reasoning"}
{"id": "test_1981", "sentence1": "Each book of hours was a customized devotional object dedicated to a specific patron for whom the content was adapted according to their gender, geographical location, preferred saints and prayers (Clark, 2003), etc.", "sentence2": "each book of hours is unique with regard to its content and structure, which make their study highly complex since within the same structure the content may slightly or drastically differ, depending partially on the commissioner, on the crafts(wo)men, on the intended use, and on other phenomena yet to be discovered.", "label": "reasoning"}
{"id": "test_1982", "sentence1": "Due to the inclusion of the \"biographies\" section, the dynastic histories in the corpus contain not just purely historical data but also information on many aspects of everyday life in China, including family stories, where data on gender relations could be found.", "sentence2": "it seems natural to do a gender analysis and consider what information about gendered terms could be extracted.", "label": "reasoning"}
{"id": "test_1983", "sentence1": "About 8% of the context terms are connected to over 95 target terms for sentences and more than 2000 such terms (around 20%) for paragraphs", "sentence2": "at the paragraph level, there is a large group of characters that could be in the same context for male and female terms.", "label": "reasoning"}
{"id": "test_1984", "sentence1": "Despite often being thought of as adding complexity, processes like vowel harmony and finalobstruent devoicing improve the predictabil-ity of subsequent segments by constraining the number of well-formed forms.", "sentence2": "they reduce complexity measured in bits per phoneme.", "label": "reasoning"}
{"id": "test_1985", "sentence1": "We wish to validate our models in a controlled setting, quantifying the contribution of specific linguistic phenomena to our complexity measure.", "sentence2": "developing artificial languages, which only differ with respect to one phonological property, is useful.", "label": "reasoning"}
{"id": "test_1986", "sentence1": "Note that all Sound Pattern of English (SPE)-style rules may be so encoded (Kaplan and Kay, 1994).", "sentence2": "the complexity of the phonotactics could be said to be related to the number of SPE-style rules that operate.", "label": "reasoning"}
{"id": "test_1987", "sentence1": "We briefly note that the van Son and Pols (2003) study did not make use of a train/dev/test split of their data, but rather simply analyzed raw relative frequency over their Dutch corpus.", "sentence2": "all positions beyond any word onset that is unique in their corpus would have probability 1, leading to a more extreme position effect than we would observe using regularization and validating on unseen forms.", "label": "reasoning"}
{"id": "test_1988", "sentence1": "This ability, to compose and decompose questions, lies at the heart of human language (Pelletier, 1994) and allows us to tackle previously unseen problems.", "sentence2": "better question understanding models should improve performance and generalization in tasks that require multi-step reasoning or that do not have access to substantial amounts of data.", "label": "reasoning"}
{"id": "test_1989", "sentence1": "To estimate expert judgment of correctness, we manually reviewed a random sample of 500 QDMRs from BREAK.", "sentence2": "we classified 93.8% of the samples in C G and another 3.6% in C. 97.4% of the samples constitute a correct decomposition of the original question.", "label": "reasoning"}
{"id": "test_1990", "sentence1": "QDMR abstracts away from a concrete KB schema by assuming an underlying ''idealized'' KB, which contains all of its arguments.", "sentence2": "qDMR can be viewed as an intermediate representation between a natural language question and an executable query.", "label": "reasoning"}
{"id": "test_1991", "sentence1": "We rolled out the experiments on AMT over several weeks and prevented users from doing more than one experiment.", "sentence2": "a disjoint group of annotators performed each experiment.", "label": "reasoning"}
{"id": "test_1992", "sentence1": "It should be noted that there is no single fully reliable metric for evaluating syntactic paraphrase generation.", "sentence2": "we evaluate on the following metrics to showcase the efficacy of syntactic paraphrasing models.", "label": "reasoning"}
{"id": "test_1993", "sentence1": "Accordingly, the generation script samples from the entire set of verbs and generates the required arguments on-the-fly.", "sentence2": "the structure of the sentence then depends on whether the sampled verb is transitive, clauseembedding, raising, and so forth, but that same verb phrase and its arguments are used in both pairs in the paradigm.", "label": "reasoning"}
{"id": "test_1994", "sentence1": "As a threshold of inclusion in BLiMP, the majority of validators needed to agree with BLiMP on at least 4/5 examples from each paradigm.", "sentence2": "all 67 paradigms in the public version of BLiMP passed this validation; only two additional paradigms were rejected on this criterion.", "label": "reasoning"}
{"id": "test_1995", "sentence1": "However, they are not guaranteed to be broad reproducible, because the generalizability of the results might be restricted due to fixed collections of hyperparameter configurations, the variance associated with multiple runs, and the unknown best representative set of MT data.", "sentence2": "in this work, we should be careful to not make general conclusions from the observations, but to show how the dataset can be potentially used in facilitating HPO research.", "label": "reasoning"}
{"id": "test_1996", "sentence1": "In order to obtain reasonable results, such grammars need to be lexicalized because otherwise the independence assumptions of the PCFG are violated because of semantic relations, for example, between a verb and its subject.", "sentence2": "the realizability assumption the approach relies on is dramatically false.", "label": "reasoning"}
{"id": "test_1997", "sentence1": "However, the low novelty of the generated objects showed that it could still be difficult for GPT-2 to generate commonsense texts solely based on its implicit knowledge.", "sentence2": "we target integrating external knowledge into GPT-2 for generating more reasonable commonsense stories.", "label": "reasoning"}
{"id": "test_1998", "sentence1": "GPT-2 network is pretrained on a large-scale corpus but still suffers from many issues such as lack of necessary knowledge for commonsense story generation as aforementioned.", "sentence2": "in this work we improve GPT-2 for generating more reasonable stories with external commonsense knowledge.", "label": "reasoning"}
{"id": "test_1999", "sentence1": "Although the proposed model outperforms the state-of-the-art baselines, it needs to be noted that there are still many unreasonable stories losing to other models in manual evaluation.", "sentence2": "we analyzed error types by manually checking all lost stories in pairwise comparisons between our model and two strong baselines including Fusion and GPT-2 (Fine-tune) to reveal the factors that affect the performance.", "label": "reasoning"}
{"id": "test_2000", "sentence1": "Finally, to alleviate the annotation burden, we find possible parallel groups of sentences by matching their document titles and subsection titles, which denote medical PCIO elements, such as the Diagnosis and Symptoms.", "sentence2": "we first disambiguate the internal links by matching the document title and its accompanied ICD-9 code.", "label": "entailment"}
{"id": "test_2001", "sentence1": "Style accuracy remains similar among these medical PCIO elements, but there are significant differences among the models in their performance for preserving content.", "sentence2": "models perform well for those sentences about treatment, but perform poorly for evaluation, because this type of sentences usually involve many rare terms, challenging understanding.", "label": "entailment"}
{"id": "test_2002", "sentence1": "HiAGM-LA extracts the inductive label-wise text features while HiAGM-TP generates hybrid information in a deductive manner.", "sentence2": "hiAGM-LA updates the label embedding across the holistic hierarchy and then employs node outputs as the hierarchy-aware label representations.", "label": "entailment"}
{"id": "test_2003", "sentence1": "Our approaches empirically achieve significant and consistent improvement on three distinct datasets, especially on the low-frequency labels.", "sentence2": "both variants outperform the state-of-the-art model on the RCV1-V2 benchmark dataset.", "label": "entailment"}
{"id": "test_2004", "sentence1": "Like in the DGA, we model the stem and affix group forms by means of the associative relationships they create in the mental lexicon.", "sentence2": "we predict links without semantic information.", "label": "entailment"}
{"id": "test_2005", "sentence1": "We have split 5366 pairs of HS-CN for training and the rest (1288 pairs) for testing.", "sentence2": "the original HS-CN pairs, one HS paraphrase, and the pairs translated from FR and IT were kept for training while the other HS paraphrases were used for testing.", "label": "entailment"}
{"id": "test_2006", "sentence1": "We opted for a scale of 0-3, rather than a CE binary response, since it allows us to study various thresholds for better data selection.", "sentence2": "the meanings of the scores are as follows: 0 is not suitable; 1 is suitable with small modifications, such as grammar or semantic; 2 is suitable; and 3 is extremely good as a CN.", "label": "entailment"}
{"id": "test_2007", "sentence1": "Since our proposed methodology is agnostic towards the chosen word emotion model, we will re-use models from the literature.", "sentence2": "we will rely on the multi-task learning feed-forward network (MTLFFN) worked out by Buechel and Hahn (2018b).", "label": "entailment"}
{"id": "test_2008", "sentence1": "The annotators were asked to rate each sentence from 0-100 according to the perceived translation quality.", "sentence2": "the 0-10 range represents an incorrect translation; 11-29, a translation with few correct keywords, but the overall meaning is different from the source; 30-50, a translation with major mistakes; 51-69, a translation which is understandable and conveys the overall meaning of the source but contains typos or grammatical errors; 70-90, a translation that closely preserves the semantics of the source sentence; and 90-100, a perfect translation.", "label": "entailment"}
{"id": "test_2009", "sentence1": "It deploys a distancebased non-parametric classifier to generate the probability distribution of a slot-value and minimizes the log-likelihood of these values for all slot-types and dialogue turns.", "sentence2": "their model includes four main parts: the BERT (Devlin et al., 2019) language model which encodes slot names, slot values, and utterance pairs, a multi-head attention module that computes an attention vector between slot and utterance representations, a RNN state tracking module, and a discriminative classifier which computes the probability of each slot value.", "label": "entailment"}
{"id": "test_2010", "sentence1": "We first attend to some words in the source text, then translate them into the target language, and summarize to get the final summary.", "sentence2": "we first employ the encoder-decoder attention distribution to attend to the source words.", "label": "entailment"}
{"id": "test_2011", "sentence1": "This strategy aims to select the correct translation candidates by source-side context.", "sentence2": "we first limit the number of translation candidates to at most m, which is consistent with the two strategies above.", "label": "entailment"}
{"id": "test_2012", "sentence1": "The Equal strategy performs worst, but its advantage over the Naive strategy is that it is not affected by the prior probability in probabilistic bilingual lexicon.", "sentence2": "the Equal strategy only makes use of the corresponding relationship between source language words and target language words, making it effective even if there is only a bilingual vocabulary dictionary.", "label": "entailment"}
{"id": "test_2013", "sentence1": "We will show that about 30-40% of source documents do not entail their headlines under the widely-used experimental settings.", "sentence2": "the current task setting is inappropriate for abstractive summarization.", "label": "entailment"}
{"id": "test_2014", "sentence1": "Although this use of the ROUGE metric is unconventional, the intention here is to measure how many words in a generated headline originate from the input document.", "sentence2": "if all words in a generated headline are covered by its source document (truthful), the score is 100; if none of the words in a generated headline originate from its source document (untruthful), the score is 0.", "label": "entailment"}
{"id": "test_2015", "sentence1": "Hence, we hypothesize that the source documents under these task settings contain insufficient information for generating headlines.", "sentence2": "headline generation models might be faced with supervision data where headlines cannot be generated from source documents and learned to be untruthful, i.e., producing pieces of information that are not mentioned in source documents.", "label": "entailment"}
{"id": "test_2016", "sentence1": "In this work, we propose a Transformer-based model to enhance the copy mechanism.", "sentence2": "we identify the importance of each source word based on the degree centrality with a directed graph built by the self-attention layer in the Transformer.", "label": "entailment"}
{"id": "test_2017", "sentence1": "We utilize the centrality score as guidance for copy distribution.", "sentence2": "we extend the dotproduct attention to a centrality-aware function.", "label": "entailment"}
{"id": "test_2018", "sentence1": "We also propose an automatic evaluation model CMADE (Comparison Model for Automatic Dialog Evaluation) that automatically cleans self-reported user ratings as it trains on them.", "sentence2": "we first use a self-supervised method to learn better dialog feature representation, and then use KNN and Shapley to remove confusing samples.", "label": "entailment"}
{"id": "test_2019", "sentence1": "The previous works learn the embedding from intra-sentence within a single space, which is not enough for dialog systems.", "sentence2": "the semantic correlation beyond a single sentence in the conversation pair is missing.", "label": "entailment"}
{"id": "test_2020", "sentence1": "Our experiment only shows the beam widths up to five because the scores of worse sequences are already higher than that of the correct sequence in some cases.", "sentence2": "the larger beam widths seem to be unnecessary.", "label": "entailment"}
{"id": "test_2021", "sentence1": "Motivated by this, we propose P 2 BOT, a transmitter-receiver based framework with the aim of explicitly modeling understanding.", "sentence2": "p 2 BOT incorporates mutual persona perception to enhance the quality of personalized dialogue generation.", "label": "entailment"}
{"id": "test_2022", "sentence1": "Note that the transition system is sound and complete, which means there is always a sequence of transitions to sort any sequence into any reordering.", "sentence2": "the transition system on its own could also linearize the tree by taking a random permutation as input.", "label": "entailment"}
{"id": "test_2023", "sentence1": "Finally, we incorporate the coverage mechanisms (Tu et al., 2016) to encourage the decoder to utilize diverse components of the input document.", "sentence2": "at each step, we maintain a coverage vector cov t , which is the sum of attention distributions over all previous decoder steps.", "label": "entailment"}
{"id": "test_2024", "sentence1": "The two versions of our model -P1 and P2 -consistently outperform all other baselines in BLEU.", "sentence2": "our model with DP-based semantic graph (P2) achieves an absolute improvement of 2.05 in BLEU-4 (+15.2%), compared to the document-level QG model which employs gated self-attention and has been enhanced with the same decoder as ours (B5).", "label": "entailment"}
{"id": "test_2025", "sentence1": "Despite their success, previous works on extracting overlapping triples still leave much to be desired.", "sentence2": "they all treat relations as discrete labels to be assigned to entity pairs.", "label": "entailment"}
{"id": "test_2026", "sentence1": "It is designed to learn deep representations by jointly conditioning on both left and right context of each word, and it has recently been proven surprisingly effective in many downstream tasks (Zhong et al., 2019).", "sentence2": "it is composed of a stack of N identical Transformer blocks.", "label": "entailment"}
{"id": "test_2027", "sentence1": "It can be seen that the performance of most baselines on Normal, EPO and SEO presents a decreasing trend, reflecting the increasing difficulty of extracting relational triples from sentences with different overlapping patterns.", "sentence2": "among the three overlapping patterns, Normal class is the easiest pattern while EPO and SEO classes are the relatively harder ones for baseline models to extract.", "label": "entailment"}
{"id": "test_2028", "sentence1": "It reveals that most relations for the entity pairs in extracted triples are correctly identified while some extracted entities fail to form a valid relational triple.", "sentence2": "it implies that identifying relations is somehow easier than identifying entities for our model.", "label": "entailment"}
{"id": "test_2029", "sentence1": "We also adopt early stopping mechanism to prevent the model from over-fitting.", "sentence2": "we stop the training process when the performance on validation set does not gain any improvement for at least 7 consecutive epochs.", "label": "entailment"}
{"id": "test_2030", "sentence1": "Therefore, we propose a novel TransS-driven joint learning architecture to address the issues.", "sentence2": "based on the multi-level encoder, we 1) translate discourse relations in low-dimensional embedding space (called TransS), which could mine the latent geometric structure information of argumentrelation instances; 2) further exploit the semantic features of arguments to assist discourse understanding; 3) jointly learn 1) and 2) to mutually reinforce each other to obtain the better argument representations, so as to improve the performance of the task.", "label": "entailment"}
{"id": "test_2031", "sentence1": "To enrich the discourse argument representations, we exploit multi-level encoder shown in Figure 2 to learn the argument representations at the different levels.", "sentence2": "the higher-level states of multilevel encoder could capture context-dependent aspects of words while the lower-level states could model aspects of syntax (Peters et al., 2018).", "label": "entailment"}
{"id": "test_2032", "sentence1": "In our experiments, we train Transformer models (Vaswani et al., 2017), which often achieve state-of-the-art performance on MT for various language pairs.", "sentence2": "we rely on the Py-Torch (Paszke et al., 2019) re-implementation of the Transformer model in the fairseq toolkit (Ott et al., 2019).", "label": "entailment"}
{"id": "test_2033", "sentence1": "In our experiments, we train a Transformer model (Vaswani et al., 2017), which achieves state-of-the-art performance on a multitude of language pairs.", "sentence2": "we rely on the PyTorch re-implementation of the Transformer model in the Fairseq toolkit (Ott et al., 2019).", "label": "entailment"}
{"id": "test_2034", "sentence1": "It explicitly models the shared semantic space for all languages and acts as a bridge between the Encoder and Decoder network.", "sentence2": "we first introduce a language embedding to represent unique characteristics of each language and an interlingua embedding to capture the common semantics across languages.", "label": "entailment"}
{"id": "test_2035", "sentence1": "They actually equal or improve the current state of the art in tagging and parsing for all five languages.", "sentence2": "they also improve over multilingual Wikipedia-based contextual embeddings (multilingual BERT), which almost always constitutes the previous state of the art, thereby showing that the benefit of a larger, more diverse corpus surpasses the crosslingual benefit of multilingual embedding architectures.", "label": "entailment"}
{"id": "test_2036", "sentence1": "The domain proportions of the words can be naturally integrated into the Transformer model for capturing domain-shared/specific knowledge, as the multi-head dot-product attention mechanism is applied at the word-level.", "sentence2": "we carefully design multi-head dot-product attention modules for different domains, and eventually mix these modules by taking weighted averages of their parameters by their layer-wise domain proportions.", "label": "entailment"}
{"id": "test_2037", "sentence1": "Based on the above attention function in (1), Vaswani et al. (2017) further develop a multi-head attention module, which allows the NMT model to jointly attend to information from different representations at different positions.", "sentence2": "we consider a multi-head attention module with m heads.", "label": "entailment"}
{"id": "test_2038", "sentence1": "We follow the fairseq re-implementation of 12-layer Transformer designed for IWLST data.", "sentence2": "the embedding dimension is 512 for both the encoder and decoder, the number of heads is 4, and the embedding dimension in the feed-forward layer is 1024.", "label": "entailment"}
{"id": "test_2039", "sentence1": "The computation of the gradient, on the other hand, is the key to combining two methods.", "sentence2": "we encourage the embedding to be domain aware via MTL, AdvL and PAdvL, where we use the domain proportion layers to guide the training of the embedding.", "label": "entailment"}
{"id": "test_2040", "sentence1": "We use vertices to represent utterance content, and edges to represent dialog transitions between utterances.", "sentence2": "there are two types of vertices: (1) a what-vertex that contains a keyword, and (2) a how-vertex that contains a responding mechanism (from a multi-mapping based generator in Section 3.1) to capture rich variability of expressions.", "label": "entailment"}
{"id": "test_2041", "sentence1": "Using this information, the decoder performs the third subtask, which requires reasoning across language representations.", "sentence2": "it must determine how the source code changes that are relevant to the current decoding step should manifest as natural language updates to the relevant portions of C old .", "label": "entailment"}
{"id": "test_2042", "sentence1": "Although two of the baselines achieve slightly higher BLEU-4 scores than our best model, these differences are not statistically significant, and our model is better at editing comments, as shown by the results on exact match, SARI, and GLEU.", "sentence2": "our edit models beat all other models with wide, statistically significant, margins on SARI, which explicitly measures performance on edit operations.", "label": "entailment"}
{"id": "test_2043", "sentence1": "The return type substitution and return type substitution w/ null handling baselines produce predictions that are identical to C old for 74.73% and 65.76% of the test examples, respectively, while it is only 9.33% for the reranked edit model.", "sentence2": "the baselines attain high scores on automatic metrics and even beat our model on BLEU-4, without actually performing edits on the majority of examples.", "label": "entailment"}
{"id": "test_2044", "sentence1": "First, our proposed model, FACTEDITOR, achieves significantly better performances than the main baseline, ENCDECEDITOR, in terms of almost all measures.", "sentence2": "fACTEDITOR  obtains significant gains in DELETE scores on both WEBEDIT and ROTOEDIT.", "label": "entailment"}
{"id": "test_2045", "sentence1": "We observed that while there is still a gap between the systemgenerated and human-written Impressions, over 80% of our system-generated Impressions are as good 9 as the associated human-written Impressions.", "sentence2": "73% (readability), and 71% (accuracy) of our system-generated Impressions ties with human-written Impressions, both achieving full-score of 3; nonetheless, this percentage is 62% for completeness metric.", "label": "entailment"}
{"id": "test_2046", "sentence1": "In all the models, regardless of the training dataset used and the model architecture, adding a logistic regression on top of the LSTM output significantly improves average F1 scores.", "sentence2": "the highest F1 scores are always achieved with logits scores as LogReg input features.", "label": "entailment"}
{"id": "test_2047", "sentence1": "From a technical perspective, we use data augmentation to generate training data for an end-to-end system.", "sentence2": "we develop Syntactic Transformations (STs) to produce question-specific candidate answer responses and rank them using a BERT-based classifier (Devlin et al., 2019).", "label": "entailment"}
{"id": "test_2048", "sentence1": "To obtain data needed to train these models, rather than constructing yet-another crowdsourced QA dataset, we transform the answers from an existing QA dataset into fluent responses via data augmentation.", "sentence2": "we synthetically generate supervised training data by converting questions and associated extractive answers from a SQuADlike QA dataset into fluent responses via Syntactic Transformations (STs).", "label": "entailment"}
{"id": "test_2049", "sentence1": "Also, we only test sentences in the same domain such that the distribution in target corpus T is the same as well.", "sentence2": "the marginal distribution of target corpus PT (x) is the same with that for each individual source dataset, i.e. PT (x) = Pk(x).", "label": "entailment"}
{"id": "test_2050", "sentence1": "Recent work (Jawahar et al., 2019) has studied what BERT learned at different layers.", "sentence2": "the authors found {3,4,5,6,7,9,12} layers have the most representation power in BERT and each layer captures different types of information ranging from surface, syntactic to semantic level representation of text.", "label": "entailment"}
{"id": "test_2051", "sentence1": "UDA (Xie et al., 2019): Since we do not have access to TPU and need to use smaller amount of unlabeled data, we implemented Unsupervised Data Augmentation(UDA) using pytorch by ourselves.", "sentence2": "we used the same BERT-based-uncased model, unlabeled augment data and batch size as our MixText, used original unlabeled data to predict the labels with the same softmax sharpen temperature as our MixText and computed consistency loss between augmented unlabeled data.", "label": "entailment"}
{"id": "test_2052", "sentence1": "Our final layer-wise knowledge transfer loss L KT for the th layer is a linear combination of the two objectives stated below: Feature Map Transfer (FMT) Since each layer in BERT merely takes the output of the previous layer as input, the most important thing in layerwise knowledge transfer is that the feature maps of each layer should be as close as possible to those of the teacher.", "sentence2": "the mean squared error between the feature maps of the MobileBERT student and the IB-BERT teacher is used as the knowledge transfer objective: where is the index of layers, T is the sequence length, and N is the feature map size.", "label": "entailment"}
{"id": "test_2053", "sentence1": "This motivates us to use self-attention maps from the well-optimized teacher to help the training of MobileBERT in augmentation to the feature map transfer.", "sentence2": "we minimize the KL-divergence between the per-head self-attention distributions of the MobileBERT student and the IB-BERT teacher: where A is the number of attention heads.", "label": "entailment"}
{"id": "test_2054", "sentence1": "An alternative to importance sampling is to directly marginalize over a subset of z values where we expect p(x|z) is large.", "sentence2": "we propose using the top-k most likely values of z identified by performing beam search using the proposal distribution q(z|x).", "label": "entailment"}
{"id": "test_2055", "sentence1": "We note that the bias terms are wordspecific and can only adjust the stolen probability effect by a constant factor.", "sentence2": "it does not change the fact that words in the interior set are probability-bounded.", "label": "entailment"}
{"id": "test_2056", "sentence1": "We also propose a novel method of directed acyclic graph (DAG) generation for taxonomy construction.", "sentence2": "our proposed Graph2Taxo uses a noisy graph constructed from automatically extracted noisy hyponym-hypernym candidate pairs, and a set of taxonomies for some known domains for training.", "label": "entailment"}
{"id": "test_2057", "sentence1": "The problem addressed in this paper is, given a list of domain-specific terms from a target unseen (aka missing) domain as input, how to construct a taxonomy for that target unseen domain.", "sentence2": "the problem addressed in this paper is how to organize these terms into a taxonomy.", "label": "entailment"}
{"id": "test_2058", "sentence1": "Adding the DAG Constraint (Row 1) to this yields can get a better Fscore.", "sentence2": "we observe a major increase of +5% F1 for the Science (Eurovoc) domain.", "label": "entailment"}
{"id": "test_2059", "sentence1": "Finally, we study the effect of initializing our model using pre-trained embeddings, rather than initializing at random.", "sentence2": "we initialize the input matrix H 0 of our Graph2Taxo model with pre-trained fastText 5 embeddings.", "label": "entailment"}
{"id": "test_2060", "sentence1": "Backchannels are short utterances that punctuate longer turns by another conversational participant (Yngve, 1970;  Goodwin, 1986; Bavelas et al., 2000).", "sentence2": "the model assigns the backchannels \"mhm,\" \"mm,\" \"nice,\" and \"awesome\" each to separate categories.", "label": "entailment"}
{"id": "test_2061", "sentence1": "For example, exploring correlations between counselor-patient interaction dynamics and counseling outcomes (Althoff et al., 2016); studying linguistic development of mental healthcare counsellors (Zhang et al., 2019); identifying differences in how people disclose mental illnesses across gender and culture (De Choudhury et al., 2017); predicting a variety of mental health conditions from social media posts (Sekulic and Strube, 2019;De Choudhury et al., 2013a;Guntuku et al., 2019;Coppersmith et al., 2014); and analyzing well-being (Smith et al., 2016) and distress (Buechel et al., 2018).", "sentence2": "many researchers have used NLP methods for identifying depression (Morales et al., 2017).", "label": "entailment"}
{"id": "test_2062", "sentence1": "Devlin et al. (2019) suggest trying a limited number of combinations of learning rate and training epochs to optimize the BERT classification model.", "sentence2": "the paper recommends combinations of 2, 3, or 4 epochs and learning rates of 2E-5, 3E-5, and 5E-5.", "label": "entailment"}
{"id": "test_2063", "sentence1": "To tackle the above issue, we propose a novel probabilistic deep generative model for QA pair generation.", "sentence2": "our model is a hierarchical conditional variational autoencoder (HCVAE) with two separate latent spaces for question and answer conditioned on the context, where the answer latent space is additionally conditioned on the question latent space.", "label": "entailment"}
{"id": "test_2064", "sentence1": "For the answer encoding, we use a binary token type id of BERT.", "sentence2": "we encode all context tokens as 0s, except for the tokens which are part of answer span (highlighted words of context in Figure 1-(a) or -(c)), which we encode as 1s.", "label": "entailment"}
{"id": "test_2065", "sentence1": "Human Evaluation As a qualitative analysis, we first conduct a pairwise human evaluation of the QA pairs generated by our Info-HCVAE and Maxout-QG on 100 randomly selected paragraphs.", "sentence2": "20 human judges performed blind quality assessment of two sets of QA pairs that are presented in a random order, each of which contained two to five QA pairs.", "label": "entailment"}
{"id": "test_2066", "sentence1": "We proposed a novel probabilistic generative framework for generating diverse and consistent questionanswer (QA) pairs from given texts.", "sentence2": "our model learns the joint distribution of question and answer given context with a hierarchically conditional variational autoencoder, while enforcing consistency between generated QA pairs by maximizing their mutual information with a novel In-  foMax regularizer.", "label": "entailment"}
{"id": "test_2067", "sentence1": "For the semisupervised learning experiment on SQuAD, we follow Zhang and Bansal (2019)'s split for a fair comparison.", "sentence2": "we receive the unique IDs for QA pairs from the authors and use exactly the same validation and test set as theirs.", "label": "entailment"}
{"id": "test_2068", "sentence1": "In this work we study knowledge distillation with a focus on multilingual Named Entity Recognition (NER).", "sentence2": "we study several distillation strategies and propose a stage-wise optimization scheme leveraging teacher internal representations, that is agnostic of teacher architecture, and show that it outperforms strategies employed in prior works.", "label": "entailment"}
{"id": "test_2069", "sentence1": "In order to imitate an adversary who may not have the significant resources needed to train such models, we use off-the-shelf pre-trained neural language models.", "sentence2": "we choose well-known context-aware neural language models GPT-2 (Radford et al., 2019) and BERT (Devlin et al., 2018).", "label": "entailment"}
{"id": "test_2070", "sentence1": "Inspired by them, we explore obfuscation detection via image classification.", "sentence2": "we explore a transfer learning approach wherein we use the VGG-19 classifier 4 trained for image classification on ImageNet dataset 5 .", "label": "entailment"}
{"id": "test_2071", "sentence1": "Inspired by reversing the order of words in the input sequence (Sutskever et al., 2014), we propose an auxiliary synthetic task that changes the order of the target class levels in the output sequence.", "sentence2": "we go upward from the child nodes to the parent.", "label": "entailment"}
{"id": "test_2072", "sentence1": "In this work, we address the task of automatically grading the language proficiency of spontaneous speech based on ASR transcriptions only, and seek to investigate the extent to which current state-ofthe-art neural approaches to language assessment are effective for the task at hand.", "sentence2": "we make the following contributions", "label": "entailment"}
{"id": "test_2073", "sentence1": "We now apply such approaches to the grading of spoken transcriptions in a scenario where the audio, or information derived from it, is not available.", "sentence2": "the task is analogous to essay scoring except for the presence of characteristic speech features such as false starts, repetitions and filled pauses (Moore et al., 2015;Carter and McCarthy, 2017).", "label": "entailment"}
{"id": "test_2074", "sentence1": "These auxiliary objectives are based on previous work indicating that learning to make such predictions aids in tasks such as essay scoring and grammatical error detection (Cheng et al., 2015;Rei and Yannakoudakis, 2017;Cummins and Rei, 2018;Johan Berggren et al., 2019;Bell et al., 2019).", "sentence2": "for the last three tasks, we predict a label y per word x t (Figure 3; left).", "label": "entailment"}
{"id": "test_2075", "sentence1": "Our baseline approach is a feature-based model of the type which has been used in previous research (Vajjala and Rama, 2018; Yannakoudakis et al., 2018)", "sentence2": "we train a linear regression model and use as features tf\u2013 idf weighted word and POS n-grams (up to tri\u0002grams), grammatical constructions extracted from the phrase-structure trees, the length of the tran\u0002script, and the number of errors, estimated by count\u0002ing the number of trigrams that are absent from a large background corpus of correct English (Fer\u0002raresi et al., 2008).", "label": "entailment"}
{"id": "test_2076", "sentence1": "Recently, pretrained Transformer networks have demonstrated success on various NLP tasks (Radford et al., 2018;Devlin et al., 2019;Liu et al., 2019); we use these models as the foundation for SPECTER.", "sentence2": "we use SciBERT (Beltagy et al., 2019) which is an adaptation of the original BERT (Devlin et al., 2019) architecture to the scientific domain.", "label": "entailment"}
{"id": "test_2077", "sentence1": "We test how well different paper representations can reproduce this signal through citation prediction tasks.", "sentence2": "we focus on two sub-tasks: predicting direct citations, and predicting co-citations.", "label": "entailment"}
{"id": "test_2078", "sentence1": "We experiment with fine-tuning SciBERT on our tasks, and find this to be generally inferior to using our fixed representations from SPECTER.", "sentence2": "we finetune SciBERT directly on task-specific signals instead of citations.", "label": "entailment"}
{"id": "test_2079", "sentence1": "We observe that the classifier performance when trained on our representations is better than when trained on any other baseline.", "sentence2": "on the MeSH (MAG) dataset, we obtain an 86.4 (82.0) F1 score which is about a \u2206= + 2.3 (+1.5) point absolute increase over the best baseline on each dataset respectively.", "label": "entailment"}
{"id": "test_2080", "sentence1": "We also study the effect of applying MAG at different encoder layers of the XLNet.", "sentence2": "we first apply the MAG to the output of the embedding layer.", "label": "entailment"}
{"id": "test_2081", "sentence1": "To evaluate the effect of SPOLIN on generating yes-and responses and thus improving generated dialogue quality, we train a common architecture with a variety of fine-tuning data configurations, both with and without SPOLIN.", "sentence2": "for each data configuration we fine-tune a doublehead GPT-2 model (117M-parameter version based on the implementation by Wolf et al. (2019b)), which achieved state-of-the-art performance on Personachat for the ConvAI-2 dialogue competition (Zhang et al., 2018).", "label": "entailment"}
{"id": "test_2082", "sentence1": "Next, we intrinsically evaluate the performance of our SOW model (Section 2.3).", "sentence2": "given a budget of 10 reorderings, we want to understand how close our SOW model comes to covering the target ordering.", "label": "entailment"}
{"id": "test_2083", "sentence1": "We train MAUDE with downsampling, as we observe poor results when we run the recurrent network on top of 768 dimensions.", "sentence2": "we downsample to 300 dimensions, which is the same used by our baselines RUBER and InferSent in their respective encoder representations.", "label": "entailment"}
{"id": "test_2084", "sentence1": "In the last few years, a number of successful approaches have emerged that are able to adequately model various aspects of natural language.", "sentence2": "language models based on neural networks have improved the state of the art with regard to predictive language modeling, while topic models are successful at capturing clear-cut, semantic dimensions.", "label": "entailment"}
{"id": "test_2085", "sentence1": "In recent years, a number of fruitful NLP approaches have emerged that are able to adequately model various aspects of natural language.", "sentence2": "neural network language models have improved the state of the art in language modeling, while topic models are successful at capturing clearcut, semantic dimensions.", "label": "entailment"}
{"id": "test_2086", "sentence1": "First of all, we would like to experiment with different neural network architectures.", "sentence2": "we believe hierarchical approaches (Serban et al., 2017) as well as the Transformer network (Vaswani et al., 2017) would be particularly suitable to poetry generation.", "label": "entailment"}
{"id": "test_2087", "sentence1": "s and o are identified by their entity mentions, and p is identified by a unique ID.", "sentence2": "two entities from different triples that have the same mentions will be regarded as the same node.", "label": "entailment"}
{"id": "test_2088", "sentence1": "Learning a plan can be naturally regarded as a sequential decision-making process.", "sentence2": "given a set of triples, we first determine which triple to mention/visit first, and then select the second triple from the remaining triples that have not been visited so far.", "label": "entailment"}
{"id": "test_2089", "sentence1": "However, these architectures broaden the structural gap between the encoder and decoder.", "sentence2": "while the encoder receives the input data as a graph, the decoder has to create the output text as a linear chain structure.", "label": "entailment"}
{"id": "test_2090", "sentence1": "For each condition, we use a condition-specific PLUGINVAE to derive the conditional space.", "sentence2": "pLUGINVAE is proposed to learn the transformation between the conditional and global latent space for each condition.", "label": "entailment"}
{"id": "test_2091", "sentence1": "We conduct human annotations as a complementary evaluation beyond automatic metrics.", "sentence2": "eight individual judges are asked to rate over 200 conditional samples generated from each model and each condition.", "label": "entailment"}
{"id": "test_2092", "sentence1": "Specifically, eight individual judges are asked to rate over 200 conditional samples generated from each model and each condition.", "sentence2": "for each model, a total of 4, 800 text samples are annotated.", "label": "entailment"}
{"id": "test_2093", "sentence1": "We show that the amount of downstream training data is a critical factor in determining the relative performance of contextual vs. non-contextual embeddings.", "sentence2": "we show in representative tasks in Figure 1 that the performance of the non-contextual embedding models improves quickly as the amount of training data is increased (plots for all tasks in Appendix B).", "label": "entailment"}
{"id": "test_2094", "sentence1": "To provide theoretical support for why, given sufficient training data, a model trained with random embeddings might match the performance of one trained with pretrained embeddings, we consider the simple setting of Gaussian process (GP) regression (Rasmussen and Williams, 2006).", "sentence2": "we assume that the prior covariance function for the GP is determined by the pretrained embeddings, and show that as the number of observed samples from this GP grows, the posterior distribution gives diminishing weight to the prior covariance function, and eventually depends solely on the observed samples.", "label": "entailment"}
{"id": "test_2095", "sentence1": "For sentiment analysis, we need a sentence-level proxy for structural complexity; toward this end, we leverage the dependency parse tree for each sentence in the dataset.", "sentence2": "we characterize a sentence as more structurally complex if the average distance between dependent words is higher", "label": "entailment"}
{"id": "test_2096", "sentence1": "With the growth in use of KGs, researchers have explored ways to learn better representations of KGs in order to improve generalization and robustness in downstream tasks.", "sentence2": "there has been interest in learning embeddings of KGs in continuous vector spaces (Bordes et al., 2011(Bordes et al., , 2013Socher et al., 2013).", "label": "entailment"}
{"id": "test_2097", "sentence1": "We investigate several proposed approaches introduced in recent works and suggest a new loss that relies on sentence reconstruction from normalized embeddings.", "sentence2": "our method demonstrates how by adding a decoding layer for sentence reconstruction, we can improve the performance of various baselines.", "label": "entailment"}
{"id": "test_2098", "sentence1": "This work analyzes the contribution of various techniques proposed for transfer learning between languages for the task of sequence tagging.", "sentence2": "we evaluate joint training and adversarial learning.", "label": "entailment"}
{"id": "test_2099", "sentence1": "Inspired by these strategies, we propose a method for transfer learning between different languages for sequence tagging.", "sentence2": "we focus on sentence representation alignment.", "label": "entailment"}
{"id": "test_2100", "sentence1": "To obtain complete representations of the tokens in a sequence, researchers resort to bidirectional attention as shown in Figure 2(b).", "sentence2": "the training instances are created by replacing a subset of tokens in the input X with a special token [MASK], and the objective is to predict the masked tokens.", "label": "entailment"}
{"id": "test_2101", "sentence1": "Models without pretraining (e.g., BoW, LSTM word2vec) are often unable to reliably detect OOD examples.", "sentence2": "these models' FAR95 scores are sometimes worse than chance because the models often assign a higher probability to out-of-distribution examples than in-distribution examples.", "label": "entailment"}
{"id": "test_2102", "sentence1": "To maintain the realism of our study, we apply kernel density estimation to actual results, using the resulting probability density (or discretized mass) function as the ground truth distribution.", "sentence2": "we examine the experimental results of the following neural networks: Document classification.", "label": "entailment"}
{"id": "test_2103", "sentence1": "To evaluate the validity of bootstrapping the expected maximum, we measure the coverage probability of CIs constructed using the percentile bootstrap method (Efron, 1982).", "sentence2": "Specifically, we set B = 50 and iterate n = 1, . . . , 50.", "label": "entailment"}
{"id": "test_2104", "sentence1": "This is clear from their equation (7) where the empirical distribution is defined over the first n samples, instead of the B samples that we use here", "sentence2": "they claim, at least in the text, to use F\u02c6 n instead of F\u02c6B for their estimator V\u02c6 n n .", "label": "entailment"}
{"id": "test_2105", "sentence1": "We find significant and consistent improvements over both BERT BASE and BERT LARGE on multiple Machine Reading Comprehension (MRC) datasets.", "sentence2": "our proposed model has strong empirical evidence as it obtains SOTA results on Natural Questions, a new benchmark MRC dataset, outperforming BERT LARGE by 3 F1 points on short answer prediction.", "label": "entailment"}
{"id": "test_2106", "sentence1": "The constraint learnt by the classifier is the relative ordering between the two sentences.", "sentence2": "the classifier is trained to predict whether s 2 follows s 1 or not i.e the the classifier predicts the constraint s 1 < s 2 .", "label": "entailment"}
{"id": "test_2107", "sentence1": "We use the Bidirectional Encoder Representations from Transformers (BERT) pre-trained uncased language model (Devlin et al., 2019) and fine-tune it on each dataset using a fully connected perceptron layer.", "sentence2": "we leverage the Next Sentence Prediction objective of BERT and get a single representation for both sentences s 1 and s 2 .", "label": "entailment"}
{"id": "test_2108", "sentence1": "To demonstrate one example of a defense that could be applied to detect manipulation of pretrained weights, we present an approach that takes advantage of the fact that trigger keywords are likely to be rare words strongly associated with some label.", "sentence2": "we compute the LFR for every word in the vocabulary over a sample dataset, and plot the LFR against the frequency of the word in a reference dataset (we use the Books Corpus here).", "label": "entailment"}
{"id": "test_2109", "sentence1": "Of particular relevance to our work is the concept of universal adversarial perturbations (Moosavi-Dezfooli et al., 2017;Wallace et al., 2019;Neekhara et al., 2019), perturbations that are applicable to a wide range of examples.", "sentence2": "the adversarial triggers from Wallace et al. (2019) are reminiscent of the attack proposed here, with the crucial difference that their attack fixes the model\u2019s weights and finds a specific trigger, whereas the attack we explore fixes the trigger and changes the model\u2019s weights to introduce a specific response.", "label": "entailment"}
{"id": "test_2110", "sentence1": "We show that much efficient light BERT models can be obtained by reducing algorithmically chosen correct architecture design dimensions rather than reducing the number of Transformer encoder layers.", "sentence2": "our schuBERT gives 6.6% higher average accuracy on GLUE and SQuAD datasets as compared to BERT with three encoder layers while having the same number of parameters.", "label": "entailment"}
{"id": "test_2111", "sentence1": "We propose to train a non-autoregressive machine translation model to minimize the energy defined by a pretrained autoregressive model.", "sentence2": "we view our non-autoregressive translation system as an inference network (Tu and Gimpel, 2018) trained to minimize the autoregressive teacher energy.", "label": "entailment"}
{"id": "test_2112", "sentence1": "As an alternative to training non-autoregressive translation systems on distilled corpora, we instead propose to train them to minimize the energy defined by a pretrained autoregressive teacher model.", "sentence2": "we view non-autoregressive machine translation systems as inference networks  (Tu and Gimpel, 2018, 2019; Tu et al., 2019) trained to minimize the teacher's energy.", "label": "entailment"}
{"id": "test_2113", "sentence1": "In this section we provide a qualitative analysis of our approach.", "sentence2": "we are interested in the capability of the model to predict unseen synsets, thanks to the prior knowledge that is encoded in both the output embeddings O and the adjancency matrix A.", "label": "entailment"}
{"id": "test_2114", "sentence1": "We propose to utilize question generation (QG) (Du et al., 2017) as a new means to overcome this problem.", "sentence2": "given a review sentence, the generated question is expected to ask about the concerned aspect of this product, from the perspective of the review writer.", "label": "entailment"}
{"id": "test_2115", "sentence1": "The generator is initially trained with (question, answer) data, and is gradually updated with adapted and augmented training instances, so that the rewards from the generator can reflect the ability of review for generating the corresponding question.", "sentence2": "we propose a reinforcement objective that makes use of the reward from the generator, denoted as reward G (r, q).", "label": "entailment"}
{"id": "test_2116", "sentence1": "6 volunteers are asked to select user-posed questions and the corresponding review sentences that can serve as answers.", "sentence2": "the volunteers are given pairs  of question and review, and only consider the relevance between question and review.", "label": "entailment"}
{"id": "test_2117", "sentence1": "G P N ar : Review data is incorporated via a retrieval-based method.", "sentence2": "the most relevant review sentence for each question is retrieved via BM25 method, and such review-question pairs are added into the training set.", "label": "entailment"}
{"id": "test_2118", "sentence1": "We provide visual evidence of desirable behavior of our model on collections of character extractions from historical books with mixed fonts.", "sentence2": "we discus the performance of our model on the mysterious edition of Thomas Hobbes' Leviathan known as \"the 25 Ornaments\" edition.", "label": "entailment"}
{"id": "test_2119", "sentence1": "In order to reduce the size of the vocabulary, low-frequency words are not kept in both the vocabulary for the source codes and the vocabulary for target comments.", "sentence2": "the minimum threshold frequency for WikiSQL and ATIS is set as 4 while for CoNaLa it is set as 2.", "label": "entailment"}
{"id": "test_2120", "sentence1": "We illustrate the n-gram based BLEU (Papineni et al., 2002) and ROUGE (Lin, 2004) evaluations to evaluate the quality of our generated comments and also use them to set the reward in the HRL based training.", "sentence2": "bLEU-4, ROUGE-2 and ROUGE-L are used to evaluate the performance of our model since they are the most representative evaluation metric for context-based text generation.", "label": "entailment"}
{"id": "test_2121", "sentence1": "To deal with this issue, in this paper, we propose a novel graph-based multi-modal fusion encoder for NMT.", "sentence2": "we first represent the input sentence and image using a unified multi-modal graph, which captures various semantic relationships between multi-modal semantic units (words and visual objects).", "label": "entailment"}
{"id": "test_2122", "sentence1": "Based on the graph, we then stack multiple graph-based multi-modal fusion layers that iteratively perform semantic interactions among the nodes to conduct graph encoding.", "sentence2": "during this process, we distinguish the parameters of two modalities, and sequentially conduct intraand inter-modal fusions to learn multi-modal node representations.", "label": "entailment"}
{"id": "test_2123", "sentence1": "Experimental results and in-depth analysis indicate that our encoder is effective to fuse multi-modal information for NMT.", "sentence2": "our multi-modal NMT model significantly outperforms several competitive baselines.", "label": "entailment"}
{"id": "test_2124", "sentence1": "Finally, we use the metrics BLEU (Papineni et al., 2002) and METEOR (Denkowski and Lavie, 2014) to evaluate the quality of translations.", "sentence2": "we run all models three times for each experiment and report the average results.", "label": "entailment"}
{"id": "test_2125", "sentence1": "It should be noticed that we do not explicitly delete a segment when DEL is encountered but do it via post-processing.", "sentence2": "the model is trained to ignore the segment to be deleted implicitly.", "label": "entailment"}
{"id": "test_2126", "sentence1": "Note that, by fixing segment length (token number of each segment) instead, the segment number K can be changed dynamically according to the sentence length.", "sentence2": "we can predict the target sentence length to determine the segment number during inference.", "label": "entailment"}
{"id": "test_2127", "sentence1": "In addition, we found that miscalibrated predictions correlate well with the translation errors in inference.", "sentence2": "the over-estimated predictions correlate more with over-translation and mis-translation errors, while the under-estimated predictions correlate more with under-translation errors.", "label": "entailment"}
{"id": "test_2128", "sentence1": "Reliability diagrams are a visual representation of model calibration, which plot accuracy as a function of confidence (Niculescu-Mizil and Caruana, 2005).", "sentence2": "it partitions the output tokens into several bins according to their prediction confidence, and calculate the average confidence and accuracy of each bin.", "label": "entailment"}
{"id": "test_2129", "sentence1": "In this section, we present our novel UPSA framework that uses simulated annealing (SA) for unsupervised paraphrasing.", "sentence2": "we first present the general SA algorithm and then design our searching objective and searching actions (i.e., candidate sentence generator) for paraphrasing.", "label": "entailment"}
{"id": "test_2130", "sentence1": "Therefore, we propose a copy mechanism for SA sampling, inspired by that in Seq2Seq learning (Gu et al., 2016).", "sentence2": "we allow the candidate sentence generator to copy the words from the original sentence x 0 for word replacement and insertion.", "label": "entailment"}
{"id": "test_2131", "sentence1": "The main drawback of existing methods is that they cannot solve the confusing charges issue.", "sentence2": "due to the high similarity of several law articles, their corresponding law cases can be easily misjudged.", "label": "entailment"}
{"id": "test_2132", "sentence1": "In this paper, we propose a Hyperbolic and Co-graph Representation method (HyperCore) to address the above problem.", "sentence2": "we propose a hyperbolic representation method to leverage the code hierarchy.", "label": "entailment"}
{"id": "test_2133", "sentence1": "The results demonstrate that the proposed HYPERCAPS can achieve competitive performance compared with the baselines.", "sentence2": "effectiveness of HYPERCAPS is shown on tail labels.", "label": "entailment"}
{"id": "test_2134", "sentence1": "In this study, we bring forward a novel framework of automatic diagnosis with EMR documents for CDS.", "sentence2": "we propose to predict the main diagnosis based on the patient's current illness.", "label": "entailment"}
{"id": "test_2135", "sentence1": "Then, each EMR document is transformed to a Kdimensional one-hot feature f .", "sentence2": "if the i-th entity in the entity vocabulary appears as a positive finding in the input EMR, then the i-th dimension of f is set to 1, and otherwise, it is set to 0.", "label": "entailment"}
{"id": "test_2136", "sentence1": "We propose the Bayesian network ensembles for the diagnosis inference.", "sentence2": "a group of PGMs with the extracted relations and weights are ensembled towards the final predictions.", "label": "entailment"}
{"id": "test_2137", "sentence1": "To address this problem, we have proposed a new task named emotion-cause pair extraction (ECPE), aiming to extract the potential pairs of emotions and their corresponding causes together in our previous work .", "sentence2": "eCPe is defined as a fine-grained emotion analysis task, where the goal is to extract a set of valid emotion-cause pairs, given a document consisting of multiple clauses as the input.", "label": "entailment"}
{"id": "test_2138", "sentence1": "BiLSTM can capture the left and right context of each word in the input.", "sentence2": "for the t-th word w t in the input sequence of the target,  for word w t at the t-th position of the input target.", "label": "entailment"}
{"id": "test_2139", "sentence1": "In addition to the four targets in SemEval-2016, we introduce an additional Trade Policy (TP) target as the fifth target, which is an incredibly hot topic nowadays.", "sentence2": "1245 tweets related to TP are collected and manually labeled as \"favor\", \"against\" and \"none\".", "label": "entailment"}
{"id": "test_2140", "sentence1": "Here, we extend TextCNN to the cross-target setting, denoted as TextCNN-E.", "sentence2": "each word is represented as a 3D tensor by concatenating the embeddings of k semantically/emotionally-related words.", "label": "entailment"}
{"id": "test_2141", "sentence1": "To investigate the impact of each part on our SEKT model, we perform the ablation test by discarding SE graph knowledge (denoted as w/o SE) and knowledge-aware memory unit (denoted as w/o KAMU), respectively.", "sentence2": "for the w/o SE model, the external knowledge is expressed by a weighted sum of the embeddings of four semantically/emotionally-related words.", "label": "entailment"}
{"id": "test_2142", "sentence1": "To better understand the limitations of SEKT, we additionally carry out an analysis of the errors made by SEKT.", "sentence2": "we randomly select 100 instances that are incorrectly predicted by SEKT from the expanded SemEval-2016 dataset.", "label": "entailment"}
{"id": "test_2143", "sentence1": "In this paper, we proposed a semantic-emotion knowledge transferring (SEKT) model for crosstarget stance classification, which used the external knowledge from semantic and emotion lexicons as commonsense knowledge to bridge the gap across different targets.", "sentence2": "we first built a SE-graph from semantic and emotion lexicons, which leveraged external knowledge from both word-level and concept-level.", "label": "entailment"}
{"id": "test_2144", "sentence1": "In this paper, we proposed a Semantic-Emotion Knowledge Transferring (SEKT) model for cross-target stance detection, which uses the external knowledge (semantic and emotion lexicons) as a bridge to enable knowledge transfer across different targets.", "sentence2": "a semantic-emotion heterogeneous graph is constructed from external semantic and emotion lexicons, which is then fed into a graph convolutional network to learn multi-hop semantic connections between words and emotion tags.", "label": "entailment"}
{"id": "test_2145", "sentence1": "We further analyze our framework and challenge our design choices.", "sentence2": "we consider three variants of our architecture based on alternative ways to condition DANN with the graph features.", "label": "entailment"}
{"id": "test_2146", "sentence1": "They are both novel and effective in generating parallel data that introduces additional formality transfer knowledge that cannot be derived from the original training data.", "sentence2": "f-Dis identifies useful pairs from the paraphrased pairs generated by cross-lingual MT; while M-task leverages the training data of Grammatical Error Correction (GEC) task to improve formality, as shown in figure 1.", "label": "entailment"}
{"id": "test_2147", "sentence1": "Our framework can effectively learn contextualized information with various base encoders.", "sentence2": "we try two different encoders (BiLSTM encoder and BERT encoder).", "label": "entailment"}
{"id": "test_2148", "sentence1": "Opinion and sentiment analysis has a wide range of real-world applications like social media monitoring (Bollen et al., 2011), stock market prediction (Nguyen et al., 2015), box office prediction (Yu et al., 2010), and general e-commerce applications (Kim et al., 2013;Hu et al., 2017;Cui et al., 2017).", "sentence2": "fine-grained opinion analysis aims to identify users' opinions in a text, including opinion expressions, holders of the opinions, targets of the opinions, target-dependent attitude, and intensity of opinions (Marasovi\u00c4\u2021 and Frank, 2018), which is very important for understanding political stance, customers\u2019 reviews, marketing trends, and other subjective information (Ravi and Ravi, 2015).", "label": "entailment"}
{"id": "test_2149", "sentence1": "In summary, based on previous studies in using syntax to improve various tasks, this work investigates whether syntax can enhance the neural ORL model.", "sentence2": "we try to answer the following three questions.", "label": "entailment"}
{"id": "test_2150", "sentence1": "In this work, we exploit rich syntactic information contained in the edgeweighted graphs to mitigate the effects of parsing errors.", "sentence2": "we firstly employ graph convolutional networks (GCN) to encode the edgeweighted graphs, and then integrate them into different processing levels of ORL with implicit parser hidden states.", "label": "entailment"}
{"id": "test_2151", "sentence1": "We use BERT (Bidirectional Encoder Representations from Transformers) (Devlin et al., 2019) to obtain deep contextualized word representations as our extra inputs.", "sentence2": "we use BERT-base (uncased) model and extract representations from the top-1 hidden layer.", "label": "entailment"}
{"id": "test_2152", "sentence1": "We follow the previous works of Zhang et al. (2019b) and Marasovic and Frank (2018) without much parameter tuning.", "sentence2": "we use the pretrained 100-dimensional glove embeddings (Pennington et al., 2014).", "label": "entailment"}
{"id": "test_2153", "sentence1": "In this section, we report the overall performance of our approaches compared with previous methods on the test data, as shown in Table 3.", "sentence2": "we list our syntax-agnostic baseline (BASELINE in Table 1), others\u2019 works (Zhang et al. (2019b) and Marasovic and Frank (2018), using SRL for ORL), best non-MTL approaches based on our results on the dev data (DEPGCN for explicit syntactic information and DEPHDN for implicit syntactic information), and finally the MTL-based models. ", "label": "entailment"}
{"id": "test_2154", "sentence1": "In this section, we conduct analysis to better understand the contributions from the syntactic information and BERT.", "sentence2": "we compute the exact F1 score according to different lengths of opinion arguments, as well as different distances between the arguments and their corresponding expressions.", "label": "entailment"}
{"id": "test_2155", "sentence1": "Following the work of Kuribayashi et al. (2019) and Potash et al. (2017), we propose incorporating multiple types of token representation to provide rich input features.", "sentence2": "the proposed system combines surface, part-of-speech (POS) tags, GloVe (Pennington et al., 2014) embedding, and ELMo (Peters et al., 2018) as input features for each token.", "label": "entailment"}
{"id": "test_2156", "sentence1": "In this paper, we propose a novel framework ConWea, providing contextualized weak supervision for text classification.", "sentence2": "we leverage contextualized representations of word occurrences and seed word information to automatically differentiate multiple interpretations of the same word, and thus create a contextualized corpus.", "label": "entailment"}
{"id": "test_2157", "sentence1": "During this process, contextualized seed words are introduced by expanding and disambiguating the initial seed words.", "sentence2": "for each word, we develop an unsupervised method to adaptively decide its number of interpretations, and accordingly, group all its occurrences based on their contextualized representations.", "label": "entailment"}
{"id": "test_2158", "sentence1": "Second, we design a principled comparative ranking method to select highly label-indicative keywords from the contextualized corpus, leading to contextualized seed words.", "sentence2": "we start with all possible interpretations of seed words and train a neural classifier.", "label": "entailment"}
{"id": "test_2159", "sentence1": "The key objective of this contextualization is to disambiguate different occurrences of the same word into several interpretations.", "sentence2": "we treat every word separately, so in the rest of this section, we focus on a given word w. given a word w, we denote all its occurrences as w1 , . . . , wn, where n is its total number of occurrences in the corpus.", "label": "entailment"}
{"id": "test_2160", "sentence1": "We present a case study to showcase the power of contextualized weak supervision.", "sentence2": "we investigate the differences between the expanded seed words in the plain corpus and contextualized corpus over iterations.", "label": "entailment"}
{"id": "test_2161", "sentence1": "In this work, we use a much stronger basic parser and observe more significant UAS/LAS improvement than theirs.", "sentence2": "we present an in-depth analysis showing that explicitly highorder modeling certainly helps the parsing model and thus is complementary to the BiLSTM encoder.", "label": "entailment"}
{"id": "test_2162", "sentence1": "Therefore, the processing speed is faster than the evaluation phase.", "sentence2": "for LOC, CRF and CRF2O, the average one-iteration training time is about 1min, 2.5min and 3.5min on PTB.", "label": "entailment"}
{"id": "test_2163", "sentence1": "To address these limitations, we resort to existing pre-trained contextualized word representations, and propose a unified multimodal architecture based on Transformer (Vaswani et al., 2017), which can effectively capture inter-modality interactions and alleviate the visual bias.", "sentence2": "we first adopt a recently pre-trained contextualized representation model (Devlin et al., 2018) as our sentence encoder, whose multi-head self-attention mechanism can guide each word to capture the semantic and syntactic dependency upon its context.", "label": "entailment"}
{"id": "test_2164", "sentence1": "On the one hand, removing the whole ESD module will significantly drop the performance, which shows the importance of alleviating the visual bias.", "sentence2": "discarding the conversion matrix in the ESD module also leads to the performance drop, which indicates the usefulness of capturing the label correspondence between the auxiliary module and our main MNER task.", "label": "entailment"}
{"id": "test_2165", "sentence1": "In this paper, to obtain a new insight into the syntactic abilities of neural LMs, in particular RNN-LMs, we perform a series of experiments under a different condition from the prior work.", "sentence2": "we extensively analyze the performance of the models that are exposed to explicit negative examples.", "label": "entailment"}
{"id": "test_2166", "sentence1": "Since our goal is to understand to what extent LMs can be sensitive to the target syntactic constructions by giving explicit supervision via negative examples, we only prepare negative examples on the constructions that are directly tested at evaluation.", "sentence2": "we mark the following words in the training data, and create negative examples", "label": "entailment"}
{"id": "test_2167", "sentence1": "Further, TextING ranks top on all tasks, suggesting that the individual graph exceeds the global one.", "sentence2": "the result of TextING on MR is remarkably higher.", "label": "entailment"}
{"id": "test_2168", "sentence1": "We conduct a thorough study to diagnose the behaviors of pre-trained language encoders (ELMo, BERT, and RoBERTa) when confronted with natural grammatical errors.", "sentence2": "we collect real grammatical errors from non-native speakers and conduct adversarial attacks to simulate these errors on clean text data.", "label": "entailment"}
{"id": "test_2169", "sentence1": "Considering different target models, we observe that the impact of grammatical errors varies among models.", "sentence2": "roBErTa exhibits a strong robustness against the impact of grammatical errors, with consistently lower attack success rates (20.28% on average) and F1 score decreases (17.50% on average) across all tasks, especially on MrPC and MNLI.", "label": "entailment"}
{"id": "test_2170", "sentence1": "Then, we introduce the target error type to half of these sentences using probabilistic transformation and keep the error rate over each dataset around 3% (resulting in one or two  Models We study individual layers of ELMo (2 layers), BERT-base-uncased (12 layers) and RoBERTa-base (12 layers).", "sentence2": "we fix each layer and attach a trainable self-attention layer on top of it to obtain a sentence representation.", "label": "entailment"}
{"id": "test_2171", "sentence1": "We also observe patterns related to a specific model.", "sentence2": "middle layers (layers 7-9) of BERT are better at identifying errors than lower or higher layers, as shown in Fig 2.", "label": "entailment"}
{"id": "test_2172", "sentence1": "But its best performing layer in locating errors depends on the error type and varies between the first and the second layer.", "sentence2": "the second layer of ELMo exhibits strong ability in locating Nn and outperforms BERt in accuracy.", "label": "entailment"}
{"id": "test_2173", "sentence1": "There are some future directions that are worth exploring.", "sentence2": "we can further examine the influence of using pre-trained word embeddingswhether similar words can help each other boost their polarity and attention scores.", "label": "entailment"}
{"id": "test_2174", "sentence1": "PLMs are first trained on a huge general domain data set and then fine-tuned on specific domain datasets of different downstream tasks.", "sentence2": "given a pre-trained GPT2 model, to generate sentences of email domain, we always need to fine-tune the GPT2 on a small set of email domain corpus.", "label": "entailment"}
{"id": "test_2175", "sentence1": "However, SMC suffers from serious degeneracy problem.", "sentence2": "samples from SMC tend to share a very small number of the ancestors because most of the ancestors are killed during resampling.", "label": "entailment"}
{"id": "test_2176", "sentence1": "Our method significantly outperforms the recent IBP-based methods (Jia et al., 2019;Huang et al., 2019) on both IMDB and Amazon text classification.", "sentence2": "we achieve an 87.35% certified accuracy on IMDB by applying our method on the state-of-the-art BERT, on which previous certified robust methods are not applicable.", "label": "entailment"}
{"id": "test_2177", "sentence1": "In this paper, we focus on adversarial word substitution in which an attacker arbitrarily replaces the words in the sentence by their synonyms according to a synonym table to alert the prediction of the model.", "sentence2": "for any word x, we consider a pre-defined synonym set S x that contains the synonyms of x (including x itself).", "label": "entailment"}
{"id": "test_2178", "sentence1": "We can see that our method clearly outperforms the baselines.", "sentence2": "our approach significantly outperforms IBP on Amazon by improving the 14.00% baseline to 24.92%.", "label": "entailment"}
{"id": "test_2179", "sentence1": "To solve those issues, we propose a novel graphbased coarse-to-fine paradigm to generate initial solutions for learning cross-lingual word embeddings, from which we induce bilingual lexicons.", "sentence2": "given source and target languages, our method first uses pre-trained monolingual embeddings to construct a graph for each language, with the vertices representing different words, so that the mutual relationship between words is preserved.", "label": "entailment"}
{"id": "test_2180", "sentence1": "Instead of direct optimization of the constrained adversarial loss in Eq.6, we model discriminator D's output as survival rewards similar to that in gaming (Mnih et al., 2015).", "sentence2": "the agent must survive for its goal by also fooling D, which attempts to terminate ill-perturbed modifications.", "label": "entailment"}
{"id": "test_2181", "sentence1": "However, batch size is also an important hyperparameter, and some batch sizes empirically lead to better performance than the others.", "sentence2": "it has been shown that the performance of the Transformer model (Vaswani et al., 2017) for Neural Machine Translation (NMT) (Bahdanau et al., 2015;Gehring et al., 2017;Vaswani et al., 2017) relies heavily on the batch size (Popel and Bojar, 2018;Ott et al., 2018;Abdou et al., 2017;Zhang et al., 2019a).", "label": "entailment"}
{"id": "test_2182", "sentence1": "However, it can only translate between a single language pair and cannot produce translation results for multiple language pairs at the same time.", "sentence2": "research on multilingual UNMT has been limited.", "label": "entailment"}
{"id": "test_2183", "sentence1": "The BiRRE vector models the possibility of a term being mapped to another in the embedding space by hypernymy relations, learned via existing neural language models and supervised signals of the training set.", "sentence2": "we introduce the Latent Projection Model with Negative Regularization (LPMNR) to simulate how hypernyms and hyponyms are generated in the the embedding space.", "label": "entailment"}
{"id": "test_2184", "sentence1": "On the basis, we propose a Cooperative Graph Attention Networks (Co-GAN) approach for cooperatively learning the aspect-related sentence representation.", "sentence2": "two graph attention networks are leveraged to model above two kinds of documentlevel sentiment preference information respectively, followed by an interactive mechanism to integrate the two-fold preference.", "label": "entailment"}
{"id": "test_2185", "sentence1": "To well accommodate the above two kinds of document-level sentiment preference information, we propose a Cooperative Graph Attention Networks (CoGAN) approach to ASC.", "sentence2": "two graph attention networks are constructed to model the two-fold sentiment preference with the attention weight to measure the preference-degree.", "label": "entailment"}
{"id": "test_2186", "sentence1": "To better illustrate the effectiveness of modeling the intra-aspect consistency and inter-aspect tendency information, we systematically investigate both sentiment preference phenomena in all the four evaluation datasets respectively.", "sentence2": "we sample 200 sentence 4 pairs inside each dataset and calculate the ratio that the two sentences in the pair have 4 Sentences are repeated in a document according to the unrolled aspects.", "label": "entailment"}
{"id": "test_2187", "sentence1": "As phrase-level sentiment labels are expensive to obtain, we further explore if the compositional sentiment semantics learned from one task can be transferred to others.", "sentence2": "we find that SentiBERT trained on SST can be transferred well to other related tasks such as twitter sentiment analysis (Rosenthal et al., 2017) and emotion intensity classification (Mohammad et al., 2018) and contextual emotion detection (Chatterjee et al., 2019).", "label": "entailment"}
{"id": "test_2188", "sentence1": "As shown in Table 1, SentiBERT and SentiBERT w/ RoBERTa substantially outperforms their corresponding variants and the networks merely built on the tree.", "sentence2": "we first observe that though our attention network (SentiBERT w/o BERT) is simple, it is competitive with Recursive NN, GCN and Tree-LSTM.", "label": "entailment"}
{"id": "test_2189", "sentence1": "In this paper, we propose SentiBERT to incorporate recently developed contextualized representation models (Devlin et al., 2019; Liu et al., 2019) with the recursive constituency tree structure to better capture compositional sentiment semantics.", "sentence2": "we build a simple yet effective attention network for composing sentiment semantics on top of BERT (Devlin et al., 2019).", "label": "entailment"}
{"id": "test_2190", "sentence1": "Similar as the traditional ECE task, the ECPE is also defined at the clause level, because it is difficult to describe emotion causes at the word or phrase level.", "sentence2": "in this paper, the \"emotion\" and \"cause\" are refer to \"emotion clause\" and \"cause clause\", respectively.", "label": "entailment"}
{"id": "test_2191", "sentence1": "The reason is that the existing multimodal sentiment datasets only contain a unified multimodal annotation for each multimodal segment, which is not always suitable for all modalities.", "sentence2": "all modalities share a standard annotation during intra-modal representation learning.", "label": "entailment"}
{"id": "test_2192", "sentence1": "Compared with single-task models, multi-task models have better performance in most of evaluation metrics.", "sentence2": "all three improved models (MLF-DNN, MLFM, and MTFN) have promotion significantly compared to corresponding original models (LF-DNN, LFM, and TFN) in all evaluation metrics except for Acc-5.", "label": "entailment"}
{"id": "test_2193", "sentence1": "Thus, we reinforce discrepancy between image and text, and on the contrary, weaken their commonality.", "sentence2": "we combine the above unique variant contrast features as the cross-modality contrast representation.", "label": "entailment"}
{"id": "test_2194", "sentence1": "Since it is intractable to exactly calculate the principled metric for a given explanation method, we propose an approximate metric to address the optimization problem.", "sentence2": "inspired by statistical learning theory (Vapnik, 1999), we cast the optimization problem into a standard machine learning problem which is addressed in a two-step strat-egy: firstly we follow empirical risk minimization to optimize the empirical risk; then we validate the optimized parameters on a held-out test dataset.", "label": "entailment"}
{"id": "test_2195", "sentence1": "For example, on classification tasks, Bach et al. (2015) propose layer-wise relevance propagation to visualize the relationship between a pair of neurons within net\u0002works, and Li et al. (2016) introduce a gradient\u0002based approach to understanding the composition\u0002ality in neural networks for NLP", "sentence2": "on structured prediction tasks, many research works design similar methods to understand NMT mod\u0002els (Ding et al., 2017; Alvarez-Melis and Jaakkola, 2017; Ding et al., 2019; He et al., 2019)", "label": "entailment"}
{"id": "test_2196", "sentence1": "After training, the model makes evidence predictions on unlabeled instances (the labeling arrow), and then Selector chooses the most confident instances from U to provide noisy evidence labels.", "sentence2": "the instances with newly generated evidence labels are moved from U to L (the moving arrow), which are used to supervise evidence extraction in the next iteration.", "label": "entailment"}
{"id": "test_2197", "sentence1": "Furthermore, the simple gating mechanism results in only a shallow combination of form and context.", "sentence2": "the model is not able to combine form and context until the very last step: While it can learn to weight form and context components, the two embeddings (form and context) do not share any information and thus do not influence each other.", "label": "entailment"}
{"id": "test_2198", "sentence1": "In the second stage of our training process, we use the same parameters as Schick and Schutze (2020), as our form-only model is the very same as theirs.", "sentence2": "we use a learning rate of 0.01, a batch size of 64 words and we apply n-gram dropout with a probability of 10%.", "label": "entailment"}
{"id": "test_2199", "sentence1": "The advance is achieved by exploiting locality as terminal edge-adjacency in HRG rules.", "sentence2": "we highlight the importance of 1) a terminal edge-first pars\u0002ing strategy, 2) a categorization of a subclass of HRG, i.e. what we call Weakly Regular Graph Grammar, and 3) distributing argument\u0002structures to both lexical and phrasal rules", "label": "entailment"}
{"id": "test_2200", "sentence1": "Considering the above problem in the framework of chart parsing, we would like to construct a data structure to efficiently access all chart items.", "sentence2": "when partial information is provided, this data structure can quickly find all compatible chart items.", "label": "entailment"}
{"id": "test_2201", "sentence1": "As mentioned in Dixon et al. (2018), a \nmodel is defined as biased if it performs better for\nsentences containing some specific identity-terms\nthan for ones containing others.", "sentence2": "a non-discrimination model should perform similarly across sentences containing different demographic groups.", "label": "entailment"}
{"id": "test_2202", "sentence1": "The choice of RSA versus diagnostic classifier interacts with scope, and thus these are better considered as a combination.", "sentence2": "local RSA as implemented in this study shows only weak correlations between neural activations and phoneme labels.", "label": "entailment"}
{"id": "test_2203", "sentence1": "Although the temporal scale of the extracted representations has not received much attention and scrutiny, our experimental findings suggest that it is an important choice.", "sentence2": "global representations are more sensitive to learning, and more consistent across different analysis methods.", "label": "entailment"}
{"id": "test_2204", "sentence1": "Since the interpretation serves as a proxy for the model's \"reasoning\", it should satisfy the same constraints.", "sentence2": "interpretations of similar decisions should be similar, and interpretations of dissimilar decisions should be dissimilar.", "label": "entailment"}
{"id": "test_2205", "sentence1": "The aforementioned assumptions are currently utilized to evaluate faithfulness in a binary manner: whether an interpretation is strictly faithful or not.", "sentence2": "they are most often used to show that a method is not faithful, by constructing cases in which the assumptions do not hold for it.", "label": "entailment"}
{"id": "test_2206", "sentence1": "Specifically, they are most often used to show that a method is not faithful, by constructing cases in which the assumptions do not hold for it.", "sentence2": "there is a clear trend of proof via counter-example, for various interpretation methods, that they are not globally faithful.", "label": "entailment"}
{"id": "test_2207", "sentence1": "Through a series of experiments using 12 datasets spanning 4 tasks, we show that our model is more transparent while achieving comparable performance to models containing vanilla LSTM based encoders.", "sentence2": "we show that in our proposed models, attention weights (i) provide useful importance ranking of hidden states (ii) are better indicative of words that are important for the model's prediction (iii) correlate better with gradient-based feature importance methods and (iv) are sensitive to random permutations (as should indeed be the case).", "label": "entailment"}
{"id": "test_2208", "sentence1": "However, before we go there we need to show that the predictive performance of our models is comparable to that of a vanilla LSTM model and significantly better than non-contextual models.", "sentence2": "we show that we do not compromise on performance to gain transparency and explainability.", "label": "entailment"}
{"id": "test_2209", "sentence1": "We use the intermediate representation erasure by Serrano and Smith (2019) to evaluate an importance ranking over hidden representations.", "sentence2": "we erase the hidden representations in the descending order of the importance (highest to lowest) until the model's decision changes.", "label": "entailment"}
{"id": "test_2210", "sentence1": "Previous work on active learning focused on optimizing the system objective (blue).", "sentence2": "only the system provides feedback to the active learning component (e.g., how certain it is about the predicted label of an instance).", "label": "entailment"}
{"id": "test_2211", "sentence1": "Motivated learners (MOT) continually improve their language proficiency throughout our experiments with a fixed step size of t 1 C-tests.", "sentence2": "we simulate that their proficiency level \u03c6(v) increases by one every t 1 iterations.", "label": "entailment"}
{"id": "test_2212", "sentence1": "In this section, we describe our approaches for incorporating a pre-trained MLM into our GEC model.", "sentence2": "we chose the following approaches: (1) initializing a GEC model using BERT; (2) using BERT output as additional features for a GEC model, and (3) using the output of BERT fine-tuned with the GEC corpora as additional features for a GEC model.", "label": "entailment"}
{"id": "test_2213", "sentence1": "With the advent of deep learning, the trend shifted, with abundant work focusing on neural architectures for abuse detection.", "sentence2": "the use of convolutional neural networks (CNNs) for detecting abuse has shown promising results (Park and Fung, 2017;Wang, 2018).", "label": "entailment"}
{"id": "test_2214", "sentence1": "For pre-training to be efficient, we restrict our word piece sequence length to a certain budget (e.g., we use 128 in our final experiments).", "sentence2": "the combined length of tokenized text and table cells has to fit into this budget.", "label": "entailment"}
{"id": "test_2215", "sentence1": "We implement a fully differentiable layer that la\u0002tently learns the weights for the aggregation pre\u0002diction layer pa(\u00b7), without explicit supervision for the aggregation type.", "sentence2": "we recognize that the result of executing each of the supported aggregation operators is a scalar.", "label": "entailment"}
{"id": "test_2216", "sentence1": "Evaluation of conversational systems has been one major obstacle in dialogue research.", "sentence2": "for open-domain dialogues, automated metrics have been shown to correlate poorly with human judgement (Liu et al., 2016).", "label": "entailment"}
{"id": "test_2217", "sentence1": "Due to this error, some of our identity pairs were not seen exactly ten times.", "sentence2": "3.4% were asked less than 6 times, 40% were asked less than ten times, and 40.4% were asked more than ten times.", "label": "entailment"}
{"id": "test_2218", "sentence1": "Therefore, instead of directly searching for a possible previous statement, we search for related context, where the source are describing a statement related to the claim.", "sentence2": "we rank sentences in the given corpus, by computing the cosine similarity to the given claim with their ELMo (Peters et al., 2018) representations.", "label": "entailment"}
{"id": "test_2219", "sentence1": "We reflect this idea by including a margin ranking loss within our model.", "sentence2": "we design our model on top of a pre-trained language model for general purpose (BERT) (Devlin et al., 2018), so that we can have a representation of sentences that can capture both semantic and syntactic information.", "label": "entailment"}
{"id": "test_2220", "sentence1": "Since the sources can be a url or a mention of an entity, we do wikification (Ratinov et al., 2011;Cheng and Roth, 2013) for the extracted sources.", "sentence2": "to wikify a source mention, we first adapt a redirectbased wikification method (RedW) (Shnayderman et al., 2019), which is efficient and context free.", "label": "entailment"}
{"id": "test_2221", "sentence1": "Therefore, we derive a claim evidence graph from the claim provenance graph based on which we do claim verification.", "sentence2": "we keep the nodes and edges in the claim provenance graph, and add another label on each edge with one of support, contradiction and neutral.", "label": "entailment"}
{"id": "test_2222", "sentence1": "Luckily, with the claim evidence graph, we can collect the opinions in statement level, and vote the veracity by sources that are more independent with each other.", "sentence2": "given an evidence graph of a claim, we start with the sink node and do breadth first search to find all source nodes whose indegree are 0, and leverage those sources to vote by their opinions to get an estimation of the claim veracity.", "label": "entailment"}
{"id": "test_2223", "sentence1": "We find that this ratio equates 0.90, 0.50, and 0.11 for posdis, bosdis, and topsim respectively.", "sentence2": "while compositionality is not a necessary condition for generalization, it appears that the strongest form of compositionality, namely posdis, is at least sufficient for generalization.", "label": "entailment"}
{"id": "test_2224", "sentence1": "We obtain test accuracies of 92.7%, 66.7% and 22.8% for densities 1, 0.51 and 0.25 respectively.", "sentence2": "the high generalization observed in the main paper is (also) a consequence of density, and hence combinatorial variety, of the inputs the agents are trained on, and not (only) of the number of training examples.", "label": "entailment"}
{"id": "test_2225", "sentence1": "Aside from interpretability considerations, collecting rationales from annotators may afford greater efficiency in terms of model performance realized given a fixed amount of annotator effort (Zaidan and Eisner, 2008).", "sentence2": "recent work by McDonnell et al. (2017, 2016) has observed that at least for some tasks, asking annotators to provide rationales justifying their categorizations does not impose much additional effort.", "label": "entailment"}
{"id": "test_2226", "sentence1": "Short for Fact Extraction and VERification; entails verifying claims from textual sources.", "sentence2": "each claim is to be classified as supported, refuted or not enough information with reference to a collection of source texts.", "label": "entailment"}
{"id": "test_2227", "sentence1": "We also try to split the entire record into different sections (e.g., \"medical history\", \"family history\") based on some heuristic measures.", "sentence2": "in order to split the clinical notes into sections, we notice that most sections begin with easily identifiable headers.", "label": "entailment"}
{"id": "test_2228", "sentence1": "We want DeFormer to behave more like the original model.", "sentence2": "the upper layers of DeFormer should produce representations that capture the same kinds of information as the corresponding layers in the original model.", "label": "entailment"}
{"id": "test_2229", "sentence1": "To assess this, we measured how the text representation changes when paired with different questions.", "sentence2": "we computed the average passage representation variance when paired with different questions.", "label": "entailment"}
{"id": "test_2230", "sentence1": "Question answering (QA) is one of the challenging natural language processing (NLP) tasks that benefits from explainability.", "sentence2": "multihop QA requires the aggregation of multiple evidence facts in order to answer complex natural language questions (Yang et al., 2018).", "label": "entailment"}
{"id": "test_2231", "sentence1": "To utilize this type of redundancy in answer classification, we extend AIR to extract parallel evidence chains.", "sentence2": "to extract N parallel chains, we run AIR N times, ensuring that the first justification sentences in each chain are different (in practice, we start a new chain for each justification in the top N retrieved sentences in the first hop).", "label": "entailment"}
{"id": "test_2232", "sentence1": "We train G2P models on WikiPron annotations to provide pronunciations for these words.", "sentence2": "we use the WFST-based tool Phonetisaurus (Novak et al., 2016).", "label": "entailment"}
{"id": "test_2233", "sentence1": "In our first study, we adapt the approach Keyes (2018) took for analyzing the degree to which computer vision papers encoded trans-exclusive models of gender.", "sentence2": "we began with a random sample of \u223c150 papers from the ACL anthology that mention the word \u201cgender\u201d and coded them according to the following questions", "label": "entailment"}
{"id": "test_2234", "sentence1": "Overall, the situation more broadly is equally troubling, and generally also fails to escape from the folk theory of gender.", "sentence2": "none of the differences are significant at a p = 0.05 level except for the first two questions, due to the small sample size (according to an n\u22121 chi-squared test). ", "label": "entailment"}
{"id": "test_2235", "sentence1": "Next, we analyze the effect that our different ablation mechanisms have on existing coreference resolutions systems.", "sentence2": "we run five coreference resolution systems on our ablated data: the AI2 system (AI2; Gardner et al., 2017), hugging face (HF; Wolf, 2017), which is a neural system based on spacy, and the Stanford deterministic (SfdD; Raghunathan et al., 2010), statistical (SfdS; Clark and Manning, 2015) and neural (SfdN; Clark and Manning, 2016) systems.", "label": "entailment"}
{"id": "test_2236", "sentence1": "If we accept mutual information as a natural operationalization for how much representations encode a target linguistic task (\u00a72.2), the best estimate of that mutual information is the one where the probe q\u03b8(t | r) is best at the target task.", "sentence2": "we want the best probe q\u03b8(t | r) such that we get the tightest bound to the actual distribution p(t | r).", "label": "entailment"}
{"id": "test_2237", "sentence1": "We call the resultant sense-informed model SenseBERT.", "sentence2": "we add a maskedword sense prediction task as an auxiliary task in BERT's pre-training.", "label": "entailment"}
{"id": "test_2238", "sentence1": "Moreover, SenseBERT exhibits an improvement in lexical semantics ability (reflected by the Word in Context task score) even when compared to models with WordNet infused linguistic knowledge.", "sentence2": "we compare to Peters et al. (2019) who re-contextualize word embeddings via a word\u0002to-entity attention mechanism (where entities are WordNet lemmas and synsets), and to Loureiro and Jorge (2019) which construct sense embeddings from BERT\u2019s word embeddings and use the Word\u0002Net graph to enhance coverage (see quantitative comparison in table 3).", "label": "entailment"}
{"id": "test_2239", "sentence1": "For each word w in our vocabulary, we employ the WordNet word-sense inventory for constructing A(w), the set of its \"allowed\" supersenses.", "sentence2": "we apply a WordNet Lemmatizer on w, extract the different synsets that are mapped to the lemmatized word in WordNet, and define A(w) as the union of supersenses coupled to each of these synsets.", "label": "entailment"}
{"id": "test_2240", "sentence1": "Here we measure the quality of the collected simplifications using human judges.", "sentence2": "we study if the abstractive simplifications in ASSET (test set) are preferred over lexical-paraphrase-only or splitting-only simplifications in TurkCorpus (test set) and HSplit, respectively.", "label": "entailment"}
{"id": "test_2241", "sentence1": "In this section we study the behaviour of evaluation metrics for SS when using ASSET's simplifications (test set) as references.", "sentence2": "we measure the correlation of standard metrics with human judgements of fluency, adequacy and simplicity, on simplifications produced by automatic systems.", "label": "entailment"}
{"id": "test_2242", "sentence1": "scope improve more after fine-tuning?", "sentence2": "if an attention head has a high negation-scope prediction performance before fine-tuning, will it increase in performance more than other attention heads that had lower performance before fine-tuning?", "label": "entailment"}
{"id": "test_2243", "sentence1": "In Table 1, we see that performance for both BERT-12 and BERT-24 steadily increases across all datasets with increasing N ; this trend holds for the other 7 pretrained models.", "sentence2": "in the largest setting with N = 1M, the BERT-24 embeddings distilled from the best-performing layer for each dataset drastically outperform both Word2Vec and GloVe.", "label": "entailment"}
{"id": "test_2244", "sentence1": "Inspired by the results of Nissim et al. (2020), in this work we transparently report social bias in existing static embeddings as well as the embeddings we produce.", "sentence2": "we exhaustively report the measured bias for all 3542 valid (pretrained model, layer, social attribute, bias definition, target word list) 5-tuples -all possible combinations of static embeddings and bias measures considered.", "label": "entailment"}
{"id": "test_2245", "sentence1": "Taken together, our analysis suggests a concerning state of affairs regarding bias quantification measures for (static) word embeddings.", "sentence2": "while estimates are seemingly stable to some types of choices regarding word lists, bias scores for a particular word embedding are tightly related to the definition being used and existing bias measures are markedly inconsistent with each other.", "label": "entailment"}
{"id": "test_2246", "sentence1": "Beyond this, SIMVERB3500 was introduced by Gerz et al. (2016) to further increase coverage over all predecessors.", "sentence2": "it shifted the focus towards verbs which had been heavily neglected in the prior datasets which centered on nouns and adjectives.", "label": "entailment"}
{"id": "test_2247", "sentence1": "In each bio, we attempt to explain the predictions of the model.", "sentence2": "we employ a technique that highlights words that (per our explanation method) are thought to be responsible for a particular prediction (colloquially, what the model focuses on).", "label": "entailment"}
{"id": "test_2248", "sentence1": "We find that these models encode each of our tested word features richly across sentence tokens, often with perfect or near-perfect recoverability, but the details of how the models distribute this information vary across encoders.", "sentence2": "bidirectional models show more nuance in information selectivity, while the deeper transformer models show more robustness to distance.", "label": "entailment"}
{"id": "test_2249", "sentence1": "In this paper, we propose a video question answering model which effectively integrates multi-modal input sources and finds the temporally relevant information to answer questions.", "sentence2": "we first employ dense image captions to help identify objects and their detailed salient regions and actions, and hence give the model useful extra information (in explicit textual format to allow easier matching) for answering questions.", "label": "entailment"}
{"id": "test_2250", "sentence1": "We see that clusters correspond to topical aspects of the input (either a document or a word).", "sentence2": "in the sentence-level case, documents in the same cluster often have the same ground-truth label.", "label": "entailment"}
{"id": "test_2251", "sentence1": "In contrast, our method instead introduces a smaller rectifier network with \u2248 1000 additional parame\u0002ters while still producing similar improvements", "sentence2": "using trained constraints is computationally more efficient.", "label": "entailment"}
{"id": "test_2252", "sentence1": "In this paper, we take an initial step towards studying relation extraction in dialogues by constructing the first human-annotated dialogue-based relation extraction dataset, DialogRE.", "sentence2": "we annotate all occurrences of 36 possible relation types that exist between pairs of arguments in the 1,788 dialogues originating from the complete transcripts of Friends, a corpus that has been widely employed in dialogue research in recent years (Catizone et al., 2010;Chen and Choi, 2016;Zhou and Choi, 2018;Rashid and Blanco, 2018;Yang and Choi, 2019).", "label": "entailment"}
{"id": "test_2253", "sentence1": "We next conduct a thorough investigation of the similarities and differences between dialogue\u0002based and traditional relation extraction tasks by comparing DialogRE and the Slot Filling dataset (McNamee and Dang, 2009; Ji et al., 2010, 2011; Surdeanu, 2013; Surdeanu and Ji, 2014), and we argue that a relation extraction system should be aware of speakers in dialogues.", "sentence2": "most relational triples in DialogRE (89.9%) signify either an attribute of a speaker or a relation between two speakers.", "label": "entailment"}
{"id": "test_2254", "sentence1": "We compare DialogRE with the official SF (2013-2014) dataset (Surdeanu, 2013;Surdeanu and Ji, 2014) as 47.2% of relation types in DialogRE originate from the SF relation types (Section 2.1), and 92.2% of the source documents in it that contain ground truth relational triples are formally written newswire reports (72.8%) or well-edited web documents (19.4%) compared to the remaining documents from discussion fora.", "sentence2": "we show the relation distributions in DialogRE and SF in Figure 1    the subjects of 77.3% of relational triples are speaker names, and more than 90.0% of relational triples contain at least one speaker argument.", "label": "entailment"}
{"id": "test_2255", "sentence1": "We append the ground truth triggers to the input sequence on the baseline, and the F1 of this model is 74.9%, a 16.4% absolute improvement compared to the BERT baseline.", "sentence2": "through the introduction of triggers, we observe a 22.9% absolute improvement in F1 on relation types whose inverse relation types are themselves (e.g., PER:ROOMMATE and PER:SPOUSE).", "label": "entailment"}
{"id": "test_2256", "sentence1": "In this paper, we present a facetaware evaluation setup for better assessment of the information coverage in extracted summaries.", "sentence2": "we treat each sentence in the reference summary as a facet, identify the sentences in the document that express the semantics of each facet as support sentences of the facet, and automatically evaluate extractive summarization methods by comparing the indices of extracted sentences and support sentences of all the facets in the reference summary.", "label": "entailment"}
{"id": "test_2257", "sentence1": "In this paper, we argue that the information coverage in summarization can be better evaluated by facet overlap, i.e., whether the system summary covers the facets in the reference summary.", "sentence2": "we treat each reference sentence as a facet, identify document sentences that express the semantics of each facet as support sentences of the facet, and measure information coverage by Facet-Aware Recall (FAR), i.e., how many facets are covered.", "label": "entailment"}
{"id": "test_2258", "sentence1": "To verify the effectiveness of facet-aware evaluation, we annotate the FAMs of 150 documentsummary pairs from the test set of CNN/Daily Mail.", "sentence2": "we take the first 50 samples in the test set, the 20 samples used in the human evaluation of Narayan et al. (2018c), and randomly draw another 80 samples.", "label": "entailment"}
{"id": "test_2259", "sentence1": "Recently, question answering (QA) based automatic metrics have been proposed for evaluating content selection in summarization (Eyal et al., 2019;Scialom et al., 2019;.", "sentence2": "cloze-style QA is used to evaluate whether important information in the source is recovered from the summary.", "label": "entailment"}
{"id": "test_2260", "sentence1": "In this section, we analyze generated summaries along two dimensions: abstractiveness and faithfulness.", "sentence2": "we aim to answer the following ques\u0002tions: (1) How to quantify abstractiveness of a summary? (2) Is abstractiveness encouraged more by the data or the model? (3) How does being ab\u0002stractive affect faithfulness?", "label": "entailment"}
{"id": "test_2261", "sentence1": "Under the encoder-decoder framework, we enhance the regular document encoder with a separate graph-structured encoder to maintain the global context and local characteristics of entities by using the outputs from an open information extraction (OpenIE) system.", "sentence2": "we experiment with two graph variants, one mainly capturing entities' document-level interactions and the other reflecting such interactions within each paragraph plus topic shifts across paragraphs.", "label": "entailment"}
{"id": "test_2262", "sentence1": "Two partitions of the same vocabulary are said to be independent if they do not share any informa\u0002tion with respect to language L.", "sentence2": "if we translate a sequence of symbols from L into their categories from one partition, this sequence of categories will not provide any information on how the sequence translates into categories from the other partition:", "label": "entailment"}
{"id": "test_2263", "sentence1": "While it is tempting to equate such information with the meaning of an utterance, a large body of literature in linguistics and psycholinguistics argues that an utterance conveys much more than a simple set of facts: it carries with it a halo of intimations arising from the speaker's choices, including considerations of perspective, emphasis, and framing.", "sentence2": "linguistic choices subtly color meaning; far from merely conveying objective facts, they reflect how speakers conceptualize meaning and affect listeners' interpretations in predictable ways.", "label": "entailment"}
{"id": "test_2264", "sentence1": "One vexing issue is the lack of evaluation metrics that correlate with human judgments for tasks like paraphrase, image captioning, and textual entailment (see, e.g., Bhagat and Hovy, 2013;Pavlick and Kwiatkowski, 2019;Wang et al., 2019b).", "sentence2": "it is unclear how closely a good paraphrase should hew to all aspects of the source sentence.", "label": "entailment"}
{"id": "test_2265", "sentence1": "And a system that has learned the meaning of a human language can do things like answer questions posed in the language about things in the world (or in this case, in pictures).", "sentence2": "what's interesting here is not that the tasks are impossible, but rather what makes them impossible: what's missing from the training data.", "label": "entailment"}
{"id": "test_2266", "sentence1": "However, this kind of variation is not just re\u0002stricted to text domains: it is a fundamental prop\u0002erty of human-generated language: we talk differ\u0002ently than our parents or people from a different part of our country, etc. (Pennebaker and Stone, 2003; Eisenstein et al., 2010; Kern et al., 2016).", "sentence2": "language reflects the diverse demographics, backgrounds, and personalities of the people who use it.", "label": "entailment"}
{"id": "test_2267", "sentence1": "Our definition of predictive bias in NLP builds on its definition within the literature on standardized testing (i.e., SAT, GRE, etc.)", "sentence2": "swinton (1981) states: By \"predictive bias,\" we refer to a situation in which a [predictive model] is used to predict a specific criterion for a particular population, and is found to give systematically different predictions for subgroups of this population who are in fact identical on that specific criterion.", "label": "entailment"}
{"id": "test_2268", "sentence1": "However, standard models trained on such data end up predicting people depicted in kitchens as women 63% of the time (Zhao et al., 2017).", "sentence2": "an error in generating a gender reference within the text (e.g., \"A [woman man] standing next to a counter-top\") males an incorrect female reference much more common.", "label": "entailment"}
{"id": "test_2269", "sentence1": "It does not require bias on the part of the annotator, data collector, or even the programmer/data analyst (though it can escalate existing biases and the models' statistical discrimination along a demographic dimension).", "sentence2": "it extends countermeasures beyond the point some authors have made, that they are merely cosmetic and do not address the underlying cause: biased language in society (Gonen and Goldberg, 2019).", "label": "entailment"}
{"id": "test_2270", "sentence1": "In \u00a72 and \u00a73, we analyze the language people use when they make forecasts in geopolitical and financial domains.", "sentence2": "these two sections reveal how language is associated with accuracy both within and across forecasters.", "label": "entailment"}
{"id": "test_2271", "sentence1": "In contrast to descriptive or predictive tasks, causal inference aims to understand how intervening on one variable affects another variable (Holland, 1986; Pearl, 2000; Morgan and Winship, 2015; Im\u0002bens and Rubin, 2015; Hernan and Robins \u00b4 , 2020).", "sentence2": "many applied researchers aim to estimate the size of a specific causal effect, the effect of a single treatment variable on an outcome variable.", "label": "entailment"}
{"id": "test_2272", "sentence1": "Unlike predictive applications, causal applications have no ground truth and so it is difficult distinguish modeling errors and forking paths from the true causal effects.", "sentence2": "we caution against using all available text in causal adjustment methods without any human validation or supervision, since one cannot diagnose any potential errors.", "label": "entailment"}
{"id": "test_2273", "sentence1": "Rather than using bill text in models to explain the roll-call behavior of individual legislators, (Yano et al., 2012) include the legislation's text in a model that predicts whether a bill emerges from a standing committee, a point in the legislative process that most bills do not pass.", "sentence2": "they use features based on the urgency and importance of the issue being addressed by the bill as well as a set of features extracted from co-sponsors of the bill.", "label": "entailment"}
{"id": "test_2274", "sentence1": "Equipped with co-attention learning, our model is capable of the explainability by looking into the attention weights between retweet users in the propagation and words in the source tweet.", "sentence2": "by extending the co-attention formulation (Lu et al., 2016), the proposed dual co-attention mechanism aims to attend to the source-tweet words and graphaware interaction users simultaneously (sourceinteraction co-attention), and also attend to the source-tweet words and propagated users simultaneously (source-propagation co-attention).", "label": "entailment"}
{"id": "test_2275", "sentence1": "Since most previous work on ZP resolution uses gold syntactic trees and/or ZP positions, we also investigate our performance under these settings.", "sentence2": "we take the noun phrases and/or ZP positions from gold trees to serve as constraints.", "label": "entailment"}
{"id": "test_2276", "sentence1": "In-group language aims to capture whether the author of a post may be a member of the same social/demographic group that is targeted, as speaker identity changes how a statement is perceived (O'Dea et al., 2015).", "sentence2": "in-group language (words or phrases that (re)establish belonging to a social group; Eble, 1996) can change the perceived offensiveness of a statement, such as reclaimed slurs (Croom, 2011;Galinsky et al., 2013) or self-deprecating language (Greengross and Miller, 2008).", "label": "entailment"}
{"id": "test_2277", "sentence1": "Various work has tackled the task of making inferences about power and social dynamics.", "sentence2": "previous work has analyzed power dynamics about specific entities, either in conversation settings (Prabhakaran et al., 2014;Danescu-Niculescu-Mizil et al., 2012) or in narrative text (Sap et al., 2017;Field et al., 2019;Antoniak et al., 2019).", "label": "entailment"}
{"id": "test_2278", "sentence1": "However, with Affected methods, there is a considerable variation in performance.", "sentence2": "we can observe that these models perform best when evaluated using TOP and worst when evaluated using BOTTOM 3 .", "label": "entailment"}
{"id": "test_2279", "sentence1": "Multilingual BERT is pretrained on corpora in 104 languages; however, we probe the performance of the model in 11 languages (Arabic, Chinese, Czech, English, Farsi, Finnish, French, German, Indonesian, Latvian, and Spanish).", "sentence2": "we probe the model on trees encoded in the Universal Dependencies v2 formalism (Nivre et al., 2020).", "label": "entailment"}
{"id": "test_2280", "sentence1": "MBERTRAND: A model with the same parametrization as mBERT but no training.", "sentence2": "all of the contextual attention layers are reinitialized from a normal distribution with the same mean and variance as the original parameters.", "label": "entailment"}
{"id": "test_2281", "sentence1": "We first investigate whether mBERT builds syntactic subspaces, potentially private to each language, for a subset of the languages it was trained on; this is a prerequisite for the existence of a shared, cross-lingual syntactic subspace.", "sentence2": "we train the structural probe to recover tree distances in each of our eleven languages.", "label": "entailment"}
{"id": "test_2282", "sentence1": "If a probe trained to predict syntax from representations in language i also predicts syntax in language j, this is evidence that mBERT's syntactic subspace for language i also encodes syntax in language j, and thus that syntax is encoded similarly between the two languages.", "sentence2": "we evaluate the performance of the structural probe in the following contexts: \u00e2\u20ac\u00a2 Direct transfer, where we train on language i and evaluate on language j.", "label": "entailment"}
{"id": "test_2283", "sentence1": "We train syntactic probes to learn a subspace on languages that pri\u0002marily only use one ordering (i.e. majority class is greater than 95% of all adjectives), then evalu\u0002ate their UUAS score solely on adjectives of the other ordering", "sentence2": "we evaluate on French, which has a mix (69.8% prenominal) of both orderings, in the hope that evaluating both orderings in the same language may help correct for biases in pairwise language similarity.", "label": "entailment"}
{"id": "test_2284", "sentence1": "Second, we provide strategies for improving module-wise faithfulness in NMNs (\u00a74).", "sentence2": "(a) we demonstrate how module architecture affects faithfulness (\u00a74.1), (b) propose supervising module outputs with either a proxy task or heuristically generated data (\u00a74.2), and (c) show that providing modules with uncontexualized token representations improves faithfulness (\u00a74.3).", "label": "entailment"}
{"id": "test_2285", "sentence1": "In this section, we train multiple models for the DROP and Quoref datasets, and evaluate the benefits of intermediate annotations as compared to traditional QA pairs.", "sentence2": "we will focus on the cost vs benefit tradeoff of intermediate annotations, along with evaluating their ability to mitigate bias in the training data.", "label": "entailment"}
{"id": "test_2286", "sentence1": "Improving the global consistency of predictions, our approach achieves large improvements over previous methods in a variety of question answering (QA) tasks including multiple-choice qualitative reasoning, cause-effect reasoning, and extractive machine reading comprehension.", "sentence2": "our method significantly improves the performance of RoBERTa-based models by 1-5% across datasets.", "label": "entailment"}
{"id": "test_2287", "sentence1": "Our implementations are all based on PyTorch.", "sentence2": "to implement our classification based and span-based model, we use pytorch-transformers (Wolf et al., 2019) 6 .", "label": "entailment"}
{"id": "test_2288", "sentence1": "Therefore, we use the pre-trained BERT-Largeuncasedd with its NSP layer to predict the most appropriate candidate for each blank given its context.", "sentence2": "bERT is employed to predict the probability of the context and the candidate being consecutive.", "label": "entailment"}
{"id": "test_2289", "sentence1": "We defer automatically generating distractors to future work since non-trivial distractor generation is a hard problem in itself.", "sentence2": "we extract all passages from RACE (Lai et al., 2017) (which is also from exams) and filter out passages which have less than 10 sentences or more than 30 sentences.", "label": "entailment"}
{"id": "test_2290", "sentence1": "Overall, we observed that our cascade models are competitive with monolithic transformers on both ASNQ and GPD datasets.", "sentence2": "when no selection is applied (\u03b1 = 0.0), a 12 layer cascade model performs equal or better to TANDABASE: on ASNQ, we improve P@1 by 2.1% (53.2 vs 52.1), and MAP by 1.2% (66.3 vs 65.5); on GDP, we achieve the same P@1 (67.5), and a slightly lower MAP (57.8 vs 58.0).", "label": "entailment"}
{"id": "test_2291", "sentence1": "A drop rate \u03b1 > 0.0 produces a small degradation in accuracy, at most, while significantly reducing the number of operations per batch (-37%).", "sentence2": "when \u03b1 = 0.3, we achieve less than 2% drop in P@1 on GPD, when compared to TANDA BASE ; on ANSQ, we slightly improve over it (52.9 vs 52.1).", "label": "entailment"}
{"id": "test_2292", "sentence1": "To answer these two questions, in this work, we present the first deep diagnosis of essential commonsense knowledge for answering WSC questions.", "sentence2": "we invite annotators to first provide reasons for why they choose the answers when they answer the questions, and then group all the WSC questions by different types of used commonsense knowledge (e.g., the property of entities, temporal knowledge, or spatial knowledge).", "label": "entailment"}
{"id": "test_2293", "sentence1": "Top-100 words identified by our method cover all the words attested as real semantic shift in Hamilton et al. (2016b)\u2019s top-10 except the word \u2018wanting\u2019.", "sentence2": "three attested words, \u2018gay\u2019, \u2018major\u2019 and \u2018check\u2019 are present in our top-10, which also has more interesting words not present in Hamilton et al. (2016b)\u2019s top-10 (1900 vs. 1990): van (captain vs. vehicle), press (printing vs. places), oxford (loca\u0002tion vs. university).", "label": "entailment"}
{"id": "test_2294", "sentence1": "Unlike previous language model (LM) based fine-tuning approaches that adjust parameters solely based on the classification error on training data, we employ the encoder-decoder framework of a UMT as a regularization component on the shared network parameters.", "sentence2": "the cross-lingual encoder of our model learns a shared representation, which is effective for both reconstructing input sentences of two languages and generating more representative views from the input for classification.", "label": "entailment"}
{"id": "test_2295", "sentence1": "Different from previous language model (LM) based fine-tuning approaches (Devlin et al., 2019;Conneau and Lample, 2019) that adjust parameters solely based on the classification error of training data, we utilize the encoder-decoder network from unsupervised machine translation (UMT) (Lample et al., 2018a) to regularize and refine the shared latent space.", "sentence2": "the transformer-based encoder regularized by a language discriminator learns shared but more refined language-invariant representations, which are effective for both reconstructing sentences from two languages by the decoder and generating multi-view feature representations for classification from input documents.", "label": "entailment"}
{"id": "test_2296", "sentence1": "We can thereby benefit from multi-view learning's superior generalization capability over single-view learning (Zhao et al., 2017).", "sentence2": "we consider two views of input: (i) the encoded labeled documents from the source language; (ii) the encoded back-translations of the source documents from the target language.", "label": "entailment"}
{"id": "test_2297", "sentence1": "We leverage pretrained language models (Conneau and Lample, 2019) to initialize a transformerbased UMT (Lample et al., 2018a) and train it on Wikipedia text 3 .", "sentence2": "we sample 10 million sentences from each language pairs and use the XLM library 4 to train a UMT (Lample et al., 2018a) for 200K steps.", "label": "entailment"}
{"id": "test_2298", "sentence1": "Finally, the contextual state sequence of X/Y is denoted as Hx/y = (h x/y 1 , . . . , hx/y n/m)", "sentence2": "h x is the prior context; h y is the posterior context that is only available in the training stage.", "label": "entailment"}
{"id": "test_2299", "sentence1": "Enhanced with the proposed pruning algorithm, we can see great improvement for CMAML methods against all the competing methods on both quality and diversity measurements.", "sentence2": "our full model CMAML-Seq2SPG shows clearly better performance and the reasons can be ascribed to two aspects: firstly, the proposed Seq2SPG has a better model structure for our task and secondly, the pruning algorithm makes the models more likely to generate a user-coherent response.", "label": "entailment"}
{"id": "test_2300", "sentence1": "We then apply pre-trained models (Radford et al., 2019) to leverage the deep attention neural networks to capture text and video dependencies with fine granularity.", "sentence2": "we propose to capture dependencies between each token in text data and each spatial feature along the temporal dimension of the input video.", "label": "entailment"}
{"id": "test_2301", "sentence1": "Compared with the baseline with Transformerbased neural networks (Le et al., 2019), our model treats both visual and text features with equal importance at different levels of different dimensions.", "sentence2": "we aligned the token level with spatial level and turn level with temporal level between visual and text features.", "label": "entailment"}
{"id": "test_2302", "sentence1": "Due to the constraint of emotion factors, the scale of proper responses shrinks, and the model is more likely to map any query to a frequentlyoccurring response in that emotion category.", "sentence2": "given \"Disgust\", the response would be \"You are so bad\" in general, while given \"Happy\", it would be \"Haha, you too\" (Example 2 to 4 in Table 1).", "label": "entailment"}
{"id": "test_2303", "sentence1": "Rewards designed here aim to encourage both emotion expression and content consistency.", "sentence2": "emotion expression can be either explicit (embodied in some obvious emotion words) or implicit (reflected by the organization of the entire sentence).", "label": "entailment"}
{"id": "test_2304", "sentence1": "Emotional Chatting Machine (ECM) (Zhou et al., 2018a) addresses the emotion factor using three new mechanisms: Emotion Category Embedding, Internal Memory, and External Memory.", "sentence2": "1) Emotion Category Embedding models the high-level abstraction of emotion expression by embedding emotion categories, and concatenates corresponding embedding to the input at each decoding step.", "label": "entailment"}
{"id": "test_2305", "sentence1": "Emotion-acc and Emotion-word are utilized to test the emotion expression.", "sentence2": "emo-acc is the agreement between the ground truth labels and the predicted labels through the TextCNN classifier trained before.", "label": "entailment"}
{"id": "test_2306", "sentence1": "Although discontinuous mentions may overlap, we discriminate this overlapping from the one in nested NER.", "sentence2": "if one mention is completely contained by the other, we call mentions involved nested entity mentions.", "label": "entailment"}
{"id": "test_2307", "sentence1": "We further explore attention mechanisms that take into account the relationships between hidden states.", "sentence2": "we apply the multi-head self-attention mechanism in Transformer (Vaswani et al., 2017), which has shown promising results in many applications (Radford et al., 2018;Devlin et al., 2019).", "label": "entailment"}
{"id": "test_2308", "sentence1": "In this paper, we take the benefits of ConvE and KBGAT together and propose a Relation-aware Inception network with joint local-global structural information for knowledge graph Embedding (ReInceptionE).", "sentence2": "we first explore the Inception network to learn query embedding, which aims to further increase the interactions between head and relation embeddings.", "label": "entailment"}
{"id": "test_2309", "sentence1": "Furthermore, our proposed ReInceptionE significantly outperforms ConvE and InceptionE for all relation types.", "sentence2": "reInceptionE obtains larger improvements for complex relations, such as one-to-many, many-to-one and many-to-many.", "label": "entailment"}
{"id": "test_2310", "sentence1": "This task is to assess the veracity of a statement when a table is given as evidence.", "sentence2": "we evaluate our system on TABFACT (Chen et al., 2019), a large benchmark dataset for tablebased fact checking.", "label": "entailment"}
{"id": "test_2311", "sentence1": "To address this problem, we use the graph structure to re-define the related contexts of each token for learning a graph-enhanced representation.", "sentence2": "we present a graph-based mask matrix for self-attention mechanism in Transformer.", "label": "entailment"}
{"id": "test_2312", "sentence1": "The basic idea is that the generation of a program tree is equivalent to the generation of a sequence of action, which is a traversal of the program tree following a particular order, like depth-first, left-to-right order.", "sentence2": "our semantic parser works in a top-down manner in a sequence-to-sequence paradigm.", "label": "entailment"}
{"id": "test_2313", "sentence1": "In unsupervised learning tasks such as topic discovery, mixture modeling has gained increasing attention from researchers (Wang et al., 2011;Zhou andCarin, 2012, 2015;Zhou, 2018;Zhao et al., 2019).", "sentence2": "mixture modeling over document words devotes to assign these words to different topics via random probability measures.", "label": "entailment"}
{"id": "test_2314", "sentence1": "These models used the neural network to learn the distribution relationship between input documents and latent topics due to its excellent function fitting ability and scalability.", "sentence2": "the neural network parameters can be trained by back-propagation through the reparameterization of a continuous distribution (Naesseth et al., 2017) or using variance reduction techniques for a discrete distribution (Mnih and Gregor, 2014).", "label": "entailment"}
{"id": "test_2315", "sentence1": "In contrast to variational auto-encoders on handling the case of continuous latent variables (Kingma and Welling, 2014), NVI can deal with both discrete and continuous latent variables.", "sentence2": "a neural network is used to infer the proposed distribution q(h|d).", "label": "entailment"}
{"id": "test_2316", "sentence1": "Considering that word embeddings have shown to capture both the semantic and syntactic relatedness in words and demonstrated impressive performance in natural language processing tasks, we also present the result of a neural autoregressive topic model that leverages word embeddings (i.e., iDocNADE).", "sentence2": "the publicly available codes of HDP 2 , N-VDM 3 , NVLDA and ProdLDA 4 , and iDocNADE 5 are directly used.", "label": "entailment"}
{"id": "test_2317", "sentence1": "Furthermore, the latent semantics of these corpora may be hierarchically dependent.", "sentence2": "the topics at the corpus level and those of each document are not independent but correlated with one another.", "label": "entailment"}
{"id": "test_2318", "sentence1": "The adequacy of vector-space representations was also questioned based on the regularities found in natural language.", "sentence2": "fodor and Pylyshyn (1988) argued that connectionist architectures were not adequate to account for regularities which they characterised as systematicity (see also (Smolensky, 1990;fodor and McLaughlin, 1990)).", "label": "entailment"}
{"id": "test_2319", "sentence1": "But they still required linguistically-motivated designs to work well.", "sentence2": "feature engineering is necessary to make sure that these statistical machine-learning method can search a space of rules which is sufficiently broad to include good models but sufficiently narrow to allow learning from limited data.", "label": "entailment"}
{"id": "test_2320", "sentence1": "Parameterised rules which are learned when paying attention to one of these vectors (in the set or in the stack) automatically generalise to the other vectors.", "sentence2": "attention-based models have variable binding, which sequential LSTMs do not.", "label": "entailment"}
{"id": "test_2321", "sentence1": "Secondly, the vectors in the bag are exchangeable, in the sense of Jordan (2010).", "sentence2": "renumbering the indices used to refer to the different vectors will not change the interpretation of the representation.", "label": "entailment"}
{"id": "test_2322", "sentence1": "These properties mean that BoV representations are nonparametric representations.", "sentence2": "the specification of a BoV representation cannot be done just by choosing values for a fixed set of parameters.", "label": "entailment"}
{"id": "test_2323", "sentence1": "In changing from a vector space to a bag-of-vector space, the only change is this discrete segmentation into entities.", "sentence2": "no discrete representation of structure is added to the representation.", "label": "entailment"}
{"id": "test_2324", "sentence1": "Using entity names to initialize node features, the GNN-based models, GMNN and RDGCN, show a clear improvement over structure-based models, suggesting that entity names provide useful clues for entity alignment.", "sentence2": "gMNN achieves the highest Hits@10 on the DWY100K datasets, which are the only monolingual datasets (in English) in our experiments.", "label": "entailment"}
{"id": "test_2325", "sentence1": "When comparing NMN and NMN (w/o nbr-m), we can observe around a 2.5% drop in Hits@1 and a 0.6% drop in Hits@10 on average, after removing the neighborhood matching module.", "sentence2": "the Hits@1 scores between NMN and NMN (w/o nbr-m) differ by 3.9% on DBP15K FR\u2212EN.", "label": "entailment"}
{"id": "test_2326", "sentence1": "Compared to word spans in text, human is insensitive to small shifting between video frames.", "sentence2": "small offsets between video frames do not affect the understanding of video content, but the differences of a few words or even one word could change the meaning of a sentence.", "label": "entailment"}
{"id": "test_2327", "sentence1": "We study the effectiveness of our feature encoder and context-query attention (CQA) by replacing them with other modules.", "sentence2": "we use bidirectional LSTM (BiLSTM) as an alternative feature encoder.", "label": "entailment"}
{"id": "test_2328", "sentence1": "To this end, we investigate distance-based language models with explicit supervision.", "sentence2": "we inject syntactic tree supervision into distance-based neural language models by breaking a syntactic tree into a label sequence, and extending a distance-based language model to include a multi-task objective that also learns to predict goldstandard labels.", "label": "entailment"}
{"id": "test_2329", "sentence1": "The overall structure of our model is shown in Figure 1.", "sentence2": "the ON-LSTM is taken as the base language model, and syntactic trees are added by conversion to distance metrics.", "label": "entailment"}
{"id": "test_2330", "sentence1": "The first group aims to attack the OOV issue by utilizing predefined dictionaries from the target domain to facilitate cross-domain CWS (Liu et al., 2014;Zhao et al., 2018;, which are apt to suffer from scalability since not all domains possess predefined dictionaries.", "sentence2": "these methods are directly restricted by external resources that are available in a target domain.", "label": "entailment"}
{"id": "test_2331", "sentence1": "Nevertheless, after constructing an annotated dataset on the target domain, the OOV rate (target) drops significantly.", "sentence2": "the DA method yields 9.92%, 13.1%, 14.09% 20.51% and 14.94% absolute OOV rate drop on the five out-domain datasets.", "label": "entailment"}
{"id": "test_2332", "sentence1": "We define each lexeme in a language as a triple.", "sentence2": "the i th triple consists of an orthographic word form w i , a distributional semantic vector v i that encodes the lexeme's semantics, and a declension class c i .", "label": "entailment"}
{"id": "test_2333", "sentence1": "Here, we fill the gap between unsupervised morphological analysis and morphological generation with limited training data by proposing the task of unsupervised morphological paradigm completion.", "sentence2": "we aim to construct and fill inflection tables exclusively from raw text and a lemma list for a known part of speech (POS), in a situation similar to those encountered by field linguists.", "label": "entailment"}
{"id": "test_2334", "sentence1": "Different combinations of components result in major performance differences.", "sentence2": "each step of our system has the potential to introduce errors.", "label": "entailment"}
{"id": "test_2335", "sentence1": "After applying our framework, the response generation models can generate more informative responses that significantly improves the task completion rate.", "sentence2": "our framework is extremely useful under low-resource settings.", "label": "entailment"}
{"id": "test_2336", "sentence1": "We utilize the same dataset (CamRest676 or Mul-tiWOZ) to train all the models for fair comparison.", "sentence2": "we use all the user utterances in the training corpus of CamRest676 or MultiWOZ to train the LSTM language model of WordSub and the policy network of TextSub.", "label": "entailment"}
{"id": "test_2337", "sentence1": "And in each turn, the paraphrase generated by PARG is given one-to-one comparisons with each baseline's paraphrase by five judges.", "sentence2": "we ask the judges to choose whether the paraphrase generated by PARG is of better, equal or worse quality than the paraphrase generated by NAEPara or SRPara, given the original utterance.", "label": "entailment"}
{"id": "test_2338", "sentence1": "Such questions have to be syntactically valid and need to logically correlate with the answers by deducing over multiple relations on several sentences in the text.", "sentence2": "we first build a multi-hop generation model and guide it to satisfy the logical rationality by the reasoning chain extracted from a given text.", "label": "entailment"}
{"id": "test_2339", "sentence1": "Motivated by the above observations, we propose a practical two-stage approach to learn a multihop QG model from both a small-scale labeled data and a large-size unlabeled corpus.", "sentence2": "we first exploit the neural hidden semi-Markov model (Dai et al., 2016) to parameterize the sophisticated structural patterns on the questions by latent variables.", "label": "entailment"}
{"id": "test_2340", "sentence1": "In the pre-processing phase, we first mask the answer from the input contents by a special token <UNK>, to avoid the answer inclusion problem (Sun et al., 2018).", "sentence2": "the answer words may appear in the question that would reduce the rationality.", "label": "entailment"}
{"id": "test_2341", "sentence1": "In order to understand the effect of unlabeled data, we examined two variants of the proposed model.", "sentence2": "ours-Pattn which was trained without unlabeled data, and ours-50% that used 50% unlabeled data for training.", "label": "entailment"}
{"id": "test_2342", "sentence1": "We investigated the value of unlabeled data for the overall performance, especially when the labeled data was inadequate.", "sentence2": "we randomly sampled {10%, 40%, 70%, 100%} of the labeled data, and split the unlabeled data into ten subsets.", "label": "entailment"}
{"id": "test_2343", "sentence1": "Motivated by this fact, we are concerned with whether it is feasible to automatically normalize the texts first.", "sentence2": "our strategy is correcting the grammatical errors contained in the input sentences, and then parsing the revised texts into semantic struc-tures with standard models.", "label": "entailment"}
{"id": "test_2344", "sentence1": "Here we aim to train a model that can generate hard-to-classify mismatched examples, which tend to occur due to the query and product title being lexically similar.", "sentence2": "we want to generate mismatched query-item examples that have a realistic chance of appearing in the search results for said query.", "label": "entailment"}
{"id": "test_2345", "sentence1": "We propose uncertainty-aware curriculum learning, which is motivated by the intuition that: 1) the higher the uncertainty in a translation pair, the more complex and rarer the information it contains; and 2) the end of the decline in model uncertainty indicates the completeness of current training stage.", "sentence2": "we serve cross-entropy of an example as its data difficulty and exploit the variance of distributions over the weights of the network to present the model uncertainty.", "label": "entailment"}
{"id": "test_2346", "sentence1": "We introduce a novel uncertainty-aware curriculum learning framework, which serves uncertainty as its principle to order the input examples and control the duration of each training stage.", "sentence2": "we measure the data uncertainty of a sentence pair according to its joint distribution that is estimated by a language model pre-trained on the training corpus.", "label": "entailment"}
{"id": "test_2347", "sentence1": "In this work, we adopt a widely used CL strategy called baby step (Cirik et al., 2016; Zhang et al., 2018) to arrange training data and organize the training process.", "sentence2": "the whole training set D is divided into different buckets, i.e. steps {D1, \u00b7 \u00b7 \u00b7 , DT }, in which those examples with sim\u0002ilar data uncertainty scores u data are categorized into the same bucket.", "label": "entailment"}
{"id": "test_2348", "sentence1": "This verifies our hypothesis that data uncertainty is of higher relevance in respect to the difficulty of an example for a NMT model than its sentence length and word rarity counterparts.", "sentence2": "the results show the utility of estimating the uncertainty on either the source or target side of a translation pair.", "label": "entailment"}
{"id": "test_2349", "sentence1": "Surprisingly, the tendency highly accords with the psy\u0002chology of human students when they getting into a new area, i.e. Dunning Kruger Curve (Figure 1, Kruger and Dunning, 1999).", "sentence2": "starting from scratch, peoples rapidly grow their knowledge, they therefore have a large amount of confidence.", "label": "entailment"}
{"id": "test_2350", "sentence1": "In this paper, we close this gap by reporting concept extraction performance on automatically anonymized data and investigating joint models for de-identification and concept extraction.", "sentence2": "we propose a stacked model with restricted access to privacy-sensitive information and a multitask model.", "label": "entailment"}
{"id": "test_2351", "sentence1": "Feutry et al. (2018) and Friedrich et al. (2019) create pseudo-de-identified text representations with adversarial training.", "sentence2": "they replace personal information, such as names, by other names.", "label": "entailment"}
{"id": "test_2352", "sentence1": "In addition, the annotation projection can be combined with model transferring naturally.", "sentence2": "the projected SRL tags in annotation projection could contain much noise because of the source-side automatic annotations.", "label": "entailment"}
{"id": "test_2353", "sentence1": "The task can be treated as a standard sequence labeling problem, and a simple multi-layer BiLSTM-CRF model is exploited here, which has archived state-of-the-art performance with contextualized word representations (He et al., 2018b; Xia et al., 2019; He et al., 2019).", "sentence2": "we adapt the model to better support multilingual inputs by using a PGN module on the BiLSTM (Hochreiter and Schmidhuber, 1997).", "label": "entailment"}
{"id": "test_2354", "sentence1": "Therefore, we first retrieve top 200 matched text with elastic search based on the similarity of Bert embeddings (Devlin et al., 2019).", "sentence2": "we pass sentences through Bert and derive a fixed-sized vector by averaging the outputs from the second-to-last layer (May et al., 2019).", "label": "entailment"}
{"id": "test_2355", "sentence1": "Our dialogue act generator and response generator share one same encoder and input, but having different masking strategies for the input to focus on different information.", "sentence2": "only the current utterance is kept for act generation, while the entire history utterances are used for response generation.", "label": "entailment"}
{"id": "test_2356", "sentence1": "These transfer learning methods exhibit clear advantages over more traditional task-specific approaches.", "sentence2": "they can be trained in an unsupervized manner, thereby taking advantage of the information contained in large amounts of raw text.", "label": "entailment"}
{"id": "test_2357", "sentence1": "Deep generative models (DGMs) are probabilistic latent variable models parameterised by neural networks (NNs).", "sentence2": "dGMs optimised with amortised variational inference and reparameterised gradient estimates (Kingma and Welling, 2014; Rezende et al., 2014), better known as variational auto-encoders (VAEs), have spurred much interest in various domains, including computer vision and natural language processing (NLP).", "label": "entailment"}
{"id": "test_2358", "sentence1": "The overarching objective of our work is to access the large body of domain-specific information available in Frequently Asked Question sites (FAQ for short) via conversational Question Answering (QA) systems.", "sentence2": "we want to know whether current techniques are able to work with limited training data, and without needing to gather data for each target FAQ domain.", "label": "entailment"}
{"id": "test_2359", "sentence1": "More specifically, if a user has an information need and asks a question to a conversational QA system on a FAQ, the system can search for similar questions which have already been answered, or the system can directly search in existing answer passages.", "sentence2": "there are two ways to check automatically if the forum contains a relevant answer passage to a new question: (1) question retrieval, where relevant or similar questions are searched (and thus, the answer for this relevant question is taken as a relevant answer), and (2) answer retrieval, where relevant answers are searched directly among existing answers.", "label": "entailment"}
{"id": "test_2360", "sentence1": "Conversational QA systems are more complex, as they need to deal with a sequence of possibly inter-dependent questions.", "sentence2": "the meaning of the current question may depend on the dialogue history.", "label": "entailment"}
{"id": "test_2361", "sentence1": "In contrast, in our studied problem MCQA, data properties such as answer, question type, and commonsense are greatly vary across the MCQA datasets.", "sentence2": "the passages and questions come from different scenarios (such as exams, dialogues, and stories), and the answering choice contains more complex semantic information than the fixed categories in Mini-ImageNet.", "label": "entailment"}
{"id": "test_2362", "sentence1": "Due to the data heterogeneity of different sources, the performance of meta learning may drop if we consider some undesirable data sources in training.", "sentence2": "these undesirable or called \"dis-similar\" data sources will cause negative transfer when their distribution is far away from the target one.", "label": "entailment"}
{"id": "test_2363", "sentence1": "First, while state-of-the-art models for structure prediction in NLP used to rely heavily on intricate formal structures and carefully designed features (or feature-templates) (Zhang and Nivre, 2011; Zhang and Clark, 2011a), current neural models provide a form of representation learning and may be viewed as automatic feature-extractors (Kiperwasser and Goldberg, 2016; Dozat and Manning, 2018).", "sentence2": "as long as the input object can be represented as a vector, the neural model will learn how to map it to the appropriate set of structural decisions, without having to write features or feature-templates by hand.", "label": "entailment"}
{"id": "test_2364", "sentence1": "Subsequent SPMRL events and shared tasks (Seddah et al., 2013b; Tsarfaty, 2013; Seddah et al., 2014b) illustrated how methodologies and modeling assumptions for English NLP often break down in the face of such typologically diversity.", "sentence2": "while most NLP models can in principle be trained on data in any given language, 1 such models are often developed with English in mind, and the bias injected into such models is not optimal for languages that exhibit flexible word order, and rich word-internal structure, as is the case in MRLs.", "label": "entailment"}
{"id": "test_2365", "sentence1": "It is an open question whether these word-pieces capture relevant aspects of morphology.", "sentence2": "it is unclear that the strategy of relying on chars or char-strings is adequate for encoding nonconcatenative phenomena that go beyond simple character sequencing, such as templatic morphology, substraction, reduplication, and more (Ackerman and Malouf, 2006; Blevins, 2016).", "label": "entailment"}
{"id": "test_2366", "sentence1": "As a complementary area of investigation, a plausible direction would be to shift the focus from the decomposition of words into morphemes, to the organization of words as complete paradigms.", "sentence2": "instead of relying on sub-word units, identify sets of words organized into morphological paradigms (Blevins, 2016).", "label": "entailment"}
{"id": "test_2367", "sentence1": "Hebrew is a Semitic language which lies high on both the synthesis and fusion typological indices, and thus provides an interesting case study.", "sentence2": "we devised a multi-tagging task where each raw input token is tagged with the sequence of Part-of-Speech tags that represent the functions of its constituent morphemes.", "label": "entailment"}
{"id": "test_2368", "sentence1": "The performance on end-to-end binary relations shows the utility of incorporating a document level model for crosssection relations, rather than predicting on individual sections.", "sentence2": "we observe a large difference in recall, which agrees with the fact that 55% of binary relation occur across sentence level.", "label": "entailment"}
{"id": "test_2369", "sentence1": "In this setting, we run our end-to-end model but with \"gold cluster saliency\" information.", "sentence2": "we predict clusters of mentions using our model (mention identification, pairwise coreference, and mention clustering).", "label": "entailment"}
{"id": "test_2370", "sentence1": "Similarly, with just \"oracle columns\", the accuracy is 69.8%, which means that 81.0% of the questions that RAT-SQL gets wrong have incorrect structure.", "sentence2": "most questions have both column and structure wrong, so both problems require important future work.", "label": "entailment"}
{"id": "test_2371", "sentence1": "To further bias the soft alignment towards the real discrete structures, we add an auxiliary loss to encourage sparsity of the alignment matrix.", "sentence2": "for a column/table that is mentioned in the SQL query, we treat the model's current belief of the best alignment as the ground truth.", "label": "entailment"}
{"id": "test_2372", "sentence1": "We tailor-design several sets of indicating symbols to enhance the performance in terms of accuracy on format, rhyme, and sentence integrity.", "sentence2": "symbols C = {c i } are introduced for format and rhyming modeling; Intra-position symbols P = {p i } are designed to represent the local positions of the tokens within each sentence aiming to improve the rhyming performance and the sentence integrity.", "label": "entailment"}
{"id": "test_2373", "sentence1": "CMR also achieves the best overall accuracy.", "sentence2": "we can see a 2.3% improvement over Visual-BERT (Li et al., 2019b), as in the above mentioned NLVR 2 results.", "label": "entailment"}
{"id": "test_2374", "sentence1": "In this paper, we propose a novel cross-modality relevance (CMR) for language and vision reasoning.", "sentence2": "we argue for the significance of relevance between the components of the two modalities for reasoning, which includes entity relevance and relational relevance.", "label": "entailment"}
{"id": "test_2375", "sentence1": "However, this would require a careful examination of the impact of correction on the distributions and interpretations of the scores.", "sentence2": "choi and cho (2018) found that manually-vetted correction of spelling errors yielded a significant increase in scores assigned to the essays by trained raters, and that, even after controlling for the error quantity and quality predictors, the magnitude of the average gain in the score was smaller for responses with higher original scores.", "label": "entailment"}
{"id": "test_2376", "sentence1": "The field of AWE has thus progressed according to the trajectory charted by Page to a large extent, though not completely.", "sentence2": "while Page imagined the main use case of AWE to be in the service of a harried English teacher and his feedback-thirsty students, in reality, the most visible use case has arguably evolved to be automated scoring of essays for standardized testing, which, in turn, has led to new challenges, such as ensuring the validity and fairness of scores.", "label": "entailment"}
{"id": "test_2377", "sentence1": "In this study, we investigate the importance of each micro-cluster to handle the cluster evolution problem.", "sentence2": "the importance of each micro-cluster is decreased over time if it is not updated.", "label": "entailment"}
{"id": "test_2378", "sentence1": "Our approach starts from the content of a passage, which we define as the information it expresses, implies, or relies on.", "sentence2": "we propose that task designers lay out a minimal body of content that MRC systems should demonstrate they understand.", "label": "entailment"}
{"id": "test_2379", "sentence1": "First, cognitive science suggests that humans make more inferences when reading narrative text than expository text (Graesser et al., 1994).", "sentence2": "a story entails a highly structured network of relations (timelines, causality, etc.).", "label": "entailment"}
{"id": "test_2380", "sentence1": "We do not have a separate category for \"who did what to whom\" information, but we expect strong performance on the ToU to hinge on such analysis.", "sentence2": "much of this information is captured in the characterization of events for temporal questions.", "label": "entailment"}
{"id": "test_2381", "sentence1": "Even with guidelines, different annotators may give substantively different answers.", "sentence2": "they may drill down to different levels of detail in a causal chain before bottoming out in general knowledge-e.g., rather than stopping at dogs disliking rain, one annotator might explain that Rover disprefers rain because he dislikes getting wet, which in turn is because dogs often dislike getting wet.", "label": "entailment"}
{"id": "test_2382", "sentence1": "In order to overcome these issues, we propose a novel deep learning model for RE that uses the dependency trees to extract the syntax-based importance scores for the words, serving as a tree representation to introduce syntactic information into the models with greater generalization.", "sentence2": "we leverage Ordered-Neuron Long-Short Term Memory Networks (ON-LSTM) to infer the model-based importance scores for RE for every word in the sentences that are then regulated to be consistent with the syntax-based scores to enable syntactic information injection.", "label": "entailment"}
{"id": "test_2383", "sentence1": "A notable insight in these recent studies is that the syntactic trees of the input sentences (i.e., the dependency trees) can provide effective information for the deep learning models, leading to the stateof-the-art performance for RE recently (Xu et al., 2015; Tran et al., 2019).", "sentence2": "the previous deep learning models for RE has mostly exploited the syntactic trees to structure the network architectures according to the word connections presented in the trees (e.g., performing Graph Convolutional Neural Networks (GCN) over the dependency trees ).", "label": "entailment"}
{"id": "test_2384", "sentence1": "Although the dependency connections might be less specific to the training data than the whole tree structures, the major limitation of the edge-based representation is that it only captures the pairwise (local) connections between the words and completely ignores the overall (global) importance of the words in the sentences for the RE problem.", "sentence2": "some words in a given sentence might involve more useful information for relation prediction in RE than the other words, and the dependency tree for this sentence can help to better identify those important words and assign higher importance scores for them (e.g., choosing the words along the shortest dependency paths between the two entity mentions).", "label": "entailment"}
{"id": "test_2385", "sentence1": "We fist compare the proposed model (called CEON-LSTM) with the baselines on the popular ACE 2005 dataset.", "sentence2": "the four following groups of RE models in the prior work on RE with the ACE 2005 dataset is chosen for comparison: (i) Feature based models: These models handdesign linguistic features for RE, i.e., FCM, Hybrid FCM, LRFCM, and SVM (Yu et al., 2015;Hendrickx et al., 2010).", "label": "entailment"}
{"id": "test_2386", "sentence1": "Among all the models, we see that the proposed model CEON-LSTM is significantly better than all the baseline models over different test domains/datasets.", "sentence2": "cEON-LSTM is 1.38% and 3.1% better than DRPc and SAcNN (respectively) on the average F1 scores over different test datasets.", "label": "entailment"}
{"id": "test_2387", "sentence1": "To illustrate the benefit of the importance score representation for SMC, EP-ON-LSTM replaces the importance score representation for the dependency trees in CEON-LSTM with the dependency edge representation in DRPC.", "sentence2": "we replace the term L import in the overall loss function (i.e., Equation 6) with the dependency edge prediction loss (using the ON-LSTM hidden vectors) in DRPC for EP-ON-LSTM.", "label": "entailment"}
{"id": "test_2388", "sentence1": "In this paper, we aim at adapting monolingual models to code-switched text in various tasks.", "sentence2": "we transfer English knowledge from a pre-trained ELMo model to different code-switched language pairs (i.e., Nepali-English, Spanish-English, and Hindi-English) using the task of language identification.", "label": "entailment"}
{"id": "test_2389", "sentence1": "In the second part, we demonstrate the effectiveness of our CS-ELMo models by further fine-tuning them on tasks such as NER and POS tagging.", "sentence2": "we show that the resulting models significantly outperform multilingual BERT and their homologous ELMo models directly trained for NER and POS tagging.", "label": "entailment"}
{"id": "test_2390", "sentence1": "For this feature, the element corresponding to the entity type of the highest scoring candidate c 1 is updated with the score of the candidate.", "sentence2": "That is, f type(c1) = score(c1)", "label": "entailment"}
{"id": "test_2391", "sentence1": "To obtain multi-gram class names, we design a modified beam search algorithm to iteratively query a pretrained LM.", "sentence2": "after we query a LM for the first time and retrieve top K most likely words (for the masked token), we construct K new queries by adding each retrieved word after the masked token.", "label": "entailment"}
{"id": "test_2392", "sentence1": "Recent studies (Peters et al., 2018;Devlin et al., 2019;Yang et al., 2019) found that language models, simply trained for next word or missing word prediction, can generate high quality contextualized word representations which benefit many downstream applications.", "sentence2": "these language models will output an embedding vector for each word appearance in a specific context that is usually the entire sentence where the target word occurs, rather than just words appearing before the target word.", "label": "entailment"}
{"id": "test_2393", "sentence1": "This is similar in spirit to maintaining a pool of visual attention maps (Seo et al., 2017), where we argue that different questions in the conversation attend to different parts of the image.", "sentence2": "we pass the history to attend to object-level image features using the MCA module to get visually grounded contextual history.", "label": "entailment"}
{"id": "test_2394", "sentence1": "This is a subset of the VisDial val-set consisting of 97 dialogs, where the crowd-workers identified single turns (with dense annotations) requiring historical information.", "sentence2": "we asked crowd-workers whether they could provide an answer to a question given an image, without showing them the dialog history, and select one of the categories in Table 4 (see further details in Appendix B).", "label": "entailment"}
{"id": "test_2395", "sentence1": "We also tried to analyze the top-20 answers (Figure 11) which had non-zero relevance in the dense annotations.", "sentence2": "we took all 2k example turns of training set with dense annotations for each of 100 options.", "label": "entailment"}
{"id": "test_2396", "sentence1": " To do this, we use the concept of \nmust-link (ML; if two mentions are judged coref\u0002erent) and cannot-link (CL; if two mentions are \njudged non-coreferent) relations between mentions \nintroduced by Sachan et al. (2015), and adapt it for \nour purposes", "sentence2": "in our discrete setting, we build the links as follows: if the user deems the pair coreferent, it is added to ML.", "label": "entailment"}
{"id": "test_2397", "sentence1": "To do so, we first train the model for 10 epochs using regular MultiDDS, then switch to a different dev set aggregation method.", "sentence2": "we compare MultiDDS with three different priorities: Regular: this is the standard MultiDDS that optimizes all languages throughout training using the average dev risk aggregation in Eq.", "label": "entailment"}
{"id": "test_2398", "sentence1": "While InferSent rarely predicts that presuppositions project, we find strong evidence that the BERT and BOW models do.", "sentence2": "they correctly identify that the premise entails the presupposition (acc. \u2265 80% for BERT, acc. \u2265 90% for BOW).", "label": "entailment"}
{"id": "test_2399", "sentence1": "Similar to Camburu et al. (2018), for all our experiments, we filter out non-informative examples where the explanations contain the entire text of the premise or hypothesis.", "sentence2": "we drop any training example where the uncased premise or hypothesis text appears entirely in the uncased explanation.", "label": "entailment"}
{"id": "test_2400", "sentence1": "We use the GPT-2 architecture (Radford et al., 2019), which is trained using a causal language modeling loss (CLM), and includes a leftto-right decoder suitable for text generation.", "sentence2": "we use the gpt2-medium model.", "label": "entailment"}
{"id": "test_2401", "sentence1": "RoBERTa: For classification modules, we leverage RoBERTa , which is trained using a masked language modeling loss (MLM).", "sentence2": "we use the roberta-base model.", "label": "entailment"}
{"id": "test_2402", "sentence1": "While the gains of higher-order features are small in the presence of a powerful encoder, they are consistent for long-range dependencies and long sentences.", "sentence2": "higher-order models are more accurate on full sentence parses and on the exact match of modifier lists, indicating that they deal better with larger, more complex structures.", "label": "entailment"}
{"id": "test_2403", "sentence1": "In this paper, we test rigorously the hypothesis of the utility of second-order features.", "sentence2": "we experiment with consecutive sibling and grandparent features in a non-projective, graphbased dependency parser.", "label": "entailment"}
{"id": "test_2404", "sentence1": "In this paper, we propose a novel spelling check convolutional graph network (SpellGCN) that cap-tures the pronunciation/shape similarity and explore the prior dependencies between characters.", "sentence2": "two similarity graphs are constructed for the pronunciation and shape relationship correspondingly.", "label": "entailment"}
{"id": "test_2405", "sentence1": "To address this issue, we propose TLUA model, utilizing an attention scheme to automatically weight different LUs for the frame, according to target word T in the given sentence, shown in Figure 1.", "sentence2": "more specifically, we compute the weighted sum of target word T's representation and other LUs' representations based on their importance wrt T. we emphasize T as it occurs in the given sentence, which can reduce the potential noise introduced by irrelevant LUs in the same frame.", "label": "entailment"}
{"id": "test_2406", "sentence1": "Note attention schemes have been designed for both intra-frame and inter-frames.", "sentence2": "intra-frame attention focuses on relevant LUs, while inter-frames attention emphasizes relevant frames, avoiding the influence from less relevant but linked frames.", "label": "entailment"}
{"id": "test_2407", "sentence1": "Meanwhile, its score can be regarded as an indicator of coherence during inference, helping to select the most coherent one from multiple candidate responses.", "sentence2": "the training of response selection is carried out together with the bi-directional encoding of latent act recognition.", "label": "entailment"}
{"id": "test_2408", "sentence1": "In this paper, we extend the idea of attentive pooling network to the proposed three-way attentive pooling network for the follow-up question identification task, where the model needs to capture the suitability of a candidate follow-up question by comparing with the conversation history and the associated passage.", "sentence2": "the proposed model aims to capture topic shift and topic continuation in the follow-up question.", "label": "entailment"}
{"id": "test_2409", "sentence1": "The rise of deep learning based methods in NLP has stimulated research on the interpretability of the neural models.", "sentence2": "several recent studies analyze representations generated by neural models to get insights on what kind of linguistic information is learned by the models.", "label": "entailment"}
{"id": "test_2410", "sentence1": "Token-level tasks based on running text\u2014especially given that treebanks are often based on a homogeneous document collection\u2014are inevitably biased to the domain of this text, whereas type-level probing tasks are expected to be domain-neutral.", "sentence2": "dictionary-based tasks do not contain any frequency information of the surface forms, whereas token-level tasks do.", "label": "entailment"}
{"id": "test_2411", "sentence1": "For fusional languages the ambiguity ratios are higher, mostly due to syncretism-one word form might encode several morphological feature bundles.", "sentence2": "for German, the average is around 26% (before removal of ambiguous entries), which means loss of considerable amount of data points.", "label": "entailment"}
{"id": "test_2412", "sentence1": "This effect can be easily observed in the performance gaps between D-ELMo and C-ELMo.", "sentence2": "when a certain feature gets a performance boost by C-ELMo, this may suggest that the feature is highly ambiguous and a model that can use contextual information to resolve ambiguity outperforms the one that can't by a large margin.", "label": "entailment"}
{"id": "test_2413", "sentence1": "Similarly, a predicate tagged with future tense may be more likely to have a goal argument.", "sentence2": "these features are not mutually exclusive, and cannot be mutually exclusive.", "label": "entailment"}
{"id": "test_2414", "sentence1": "If linearization were the only operation needed, it could be performed easily by evaluating expressions by usual functional programming techniques.", "sentence2": "tables would rarely need to be expanded to their full forms, because each use of them would need only one form, which could be found by lazy evaluation without expanding the entire table.", "label": "entailment"}
{"id": "test_2415", "sentence1": "The best performing versions of BERT-CHAIN and BERT-GRC significantly outperforms the baselines.", "sentence2": "the AUC-ROC is 11% higher (absolute), NDCG rises from 0.60 to 0.64, and P@1 rises from 0.47 to 0.54 for BERT-GRC, indicating substantial improvement.", "label": "entailment"}
{"id": "test_2416", "sentence1": "This zero-shot dataset differs from typical reading comprehension datasets, however, in that each task description is paired with twenty different passages, and we evaluate a model's ability to solve the task, not just give the correct answer for a single (question, passage) pair.", "sentence2": "given a question, a model produces some decision function f , and it is this function which we comprehensively evaluate on many different inputs.", "label": "entailment"}
{"id": "test_2417", "sentence1": "We followed the original hyperparameters recommended by the authors for fine tuning for summarization 11 with the exception of tuning the batch size, learning rate, number of training epochs, and sequence lengths.", "sentence2": "we used a batch size of 32, maximum source/target sequence lengths of 512/64, four beams for decoding, weight decay of 0.01 and 0.1 label smoothing.", "label": "entailment"}
{"id": "test_2418", "sentence1": "To compute Similarity fi, we use an idea similar to attention mechanism by (Bahdanau et al., 2015).", "sentence2": "we use cosine similarity between the representations of the attribution factor f and representations of wi from the LM.", "label": "entailment"}
{"id": "test_2419", "sentence1": "Moreover, to address the problem caused by the long tail distribution of entities in logical forms, Jia and Liang (2016) proposed an attention-based copying mechanism.", "sentence2": "at each time step, the decoder takes one of two types of actions, one to predict a word from the vocabulary of logical forms and the other to copy a word from the input utterance.", "label": "entailment"}
{"id": "test_2420", "sentence1": "We compare the performance of models trained with different sets of rules.", "sentence2": "wong and Mooney (2006) and wong and Mooney (2007) have induced a set of grammar rules for Prolog and FunQL in Geo.", "label": "entailment"}
{"id": "test_2421", "sentence1": "Among all the MRs, the performance of Prolog declines more seriously than the others in both domains.", "sentence2": "it suffers from the program alias problem more seriously.", "label": "entailment"}
{"id": "test_2422", "sentence1": "Second, to reduce program alias' negative effect on neural semantic parsing, developers should define a concrete protocol for annotating logical forms to ensure their consistency.", "sentence2": "given an MR, developers should identify as many as possible sources where program alias can occur.", "label": "entailment"}
{"id": "test_2423", "sentence1": "We recruit participants from an educational institution and ensure they are proficient in both languages of interest.", "sentence2": "participants are either bilingual speakers or graduate students pursuing a Translation Studies degree.", "label": "entailment"}
{"id": "test_2424", "sentence1": "Dataset Statistics Sentence-level annotations were aggregated by majority vote, yielding 252, 418, and 369 instances for the \"Unrelated\", \"Some meaning difference\", and \"No meaning difference\" classes, respectively.", "sentence2": "64% of samples are divergent and 40% of samples contain finegrained meaning divergences, confirming that divergences vary in granularity and are too frequent to be ignored even in a corpus viewed as parallel.", "label": "entailment"}
{"id": "test_2425", "sentence1": "While previous work learning from bilingual data perhaps takes advantage of this fact implicitly, the focus of this paper is modelling this intuition explicitly, and to the best of our knowledge, this has not been explored in prior work.", "sentence2": "we propose a deep generative model that is encouraged to perform source separation on parallel sentences, isolating what they have in common in a latent semantic embedding and explaining what is left over with language-specific latent vectors.", "label": "entailment"}
{"id": "test_2426", "sentence1": "We focus on a style-transfer task where we have original seed sentences from which we calculate our semantic vector z sem and language specific vector z en .", "sentence2": "we feed in a Source sentence into the semantic encoder to obtain z sem , and another Style sentence into the English language-specific encoder to obtain z en .", "label": "entailment"}
{"id": "test_2427", "sentence1": "As illustrated in Figure 2, understanding the table requires both horizontal and vertical views.", "sentence2": "if the table is flattened by a horizontal scan, the vertical alignment information will be lost, and vise versa.", "label": "entailment"}
{"id": "test_2428", "sentence1": "We explore to enhance the performance of counting verification by converting the counting problem into a semantic matching problem.", "sentence2": "for every column, the frequency of duplicate cell contents is counted as a summary cell, leading to a summary row which is then appended to the table.", "label": "entailment"}
{"id": "test_2429", "sentence1": "To avoid pairing all the entities from two KGs and control the size of the PCG, our approach selects entity-pairs having high equivalent possibilities as nodes in the PCG.", "sentence2": "locality-Sensitive Hashing (lSH) is employed in our approach to efficiently find similar entities between two KGs.", "label": "entailment"}
{"id": "test_2430", "sentence1": "To obtain feature representations of entity-pairs containing their neighbors' information, our approach propagates attribute features of entity-pairs following these edges.", "sentence2": "our approach uses a Graph Neural Network (GNN) to propagate the attribute features of entity-pairs over the PCG.", "label": "entailment"}
{"id": "test_2431", "sentence1": "Extensive experiments demonstrate that RL-MMR achieves state-of-the-art performance on benchmark MDS datasets.", "sentence2": "we show the benefits of incorporating MMR into end-to-end learning when adapting SDS to MDS in terms of both learning effectiveness and efficiency.", "label": "entailment"}
{"id": "test_2432", "sentence1": "Soft attention restrains the search space while allowing more exploration of the limited labeled data, leading to better representation learning.", "sentence2": "rL-MMr infuses the entire prediction of MMr into its neural module by attending (restraining) to important sentences and downplaying the rest instead of completely discarding them.", "label": "entailment"}
{"id": "test_2433", "sentence1": "Unlike prior studies on adapting SDS to MDS (Lebanoff et al., 2018), which concatenates all the documents chronologically and encodes them sequentially, we adapt hierarchical encoding for better efficiency and scalability.", "sentence2": "we first encode each sentence s j via a CNN (Kim, 2014) to obtain its sentence representation.", "label": "entailment"}
{"id": "test_2434", "sentence1": "The probability of neural sentence extraction is measured through a two-hop attention mechanism.", "sentence2": "we first obtain the neural summary representation z t by feeding previously extracted sentences (A e i ) to an LSTM encoder.", "label": "entailment"}
{"id": "test_2435", "sentence1": "The guidance of MMR is incorporated into neural representation learning through end-to-end RL training.", "sentence2": "we formulate extractive MDS as a Markov Decision Process, where the state is defined by (D \\ E t , g t ).", "label": "entailment"}
{"id": "test_2436", "sentence1": "We study the balance between salience and redundancy, and the performance of different similarity measures.", "sentence2": "we use TF-IDF and BERT (Devlin et al., 2019) as the sentence (document) representation and measure cosine similarity in S(sj , D) and R(sj , e)", "label": "entailment"}
{"id": "test_2437", "sentence1": "We note that there are plenty of inconsistencies in the previous work on MDS and some results cannot be directly compared with ours.", "sentence2": "there are three major differences that may lead to incomparable results as follows.", "label": "entailment"}
{"id": "test_2438", "sentence1": "The KPE task is a foundational task, which plays a facilitating role in many Information Retrieval (IR) tasks, including classification, summarization, and document indexing (Hasan and Ng, 2014).", "sentence2": "the KPE task requires accurate selection of the phrases that best capture the web document's topic.", "label": "entailment"}
{"id": "test_2439", "sentence1": "The overall architecture of our proposed model is shown in Figure 2, and the fusion forget gate inside is illustrated in Figure 3.", "sentence2": "multistage fusion consists of the cross fusion block and hierarchical fusion decoder, which aims to model the correlation and complementarity between modalities spontaneously.", "label": "entailment"}
{"id": "test_2440", "sentence1": "Although the CFG builds an unsupervised lowlevel signal alignment between original multisource features, noise modality information generated by CFG is hard to be suppressed.", "sentence2": "when the whole modality cannot guide the task at all, the forced normalization of the softmax function in the attention structure makes the calculated fusion vector generated by the noise modality hard to be suppressed.", "label": "entailment"}
{"id": "test_2441", "sentence1": "It can also be seen that the performances of the pure video modality models are modest because of the frozen video features extracted from a task-independent pretraining model.", "sentence2": "table 3 shows that when the performances of all the prior models trained with ASR output transcripts drop sharply due to the higher error rate (W ER = 32.9%) of speech recognition, our model still has good performance close to the models trained with ground-truth transcripts.", "label": "entailment"}
{"id": "test_2442", "sentence1": "The observation results are similar to those observed in Table 4.", "sentence2": "we can see a greater increase in the performance of the FFG when using high noise ASR-output trancript compared to using the ground-truth transcript.", "label": "entailment"}
{"id": "test_2443", "sentence1": "We also conduct comparisons with BERT to validate the effectiveness of our proposed model.", "sentence2": "we use the bert-base-uncased model (due to GPU memory limit) from huggingface library 3 as our encoder to encode the dialogue history and the remaining parts are the same as our model.", "label": "entailment"}
{"id": "test_2444", "sentence1": "Based on the question \u201cWhere is a nearby parking garage?\u201d, the generated response of our model is \u201cpalo alto garage is 1 miles away\u201d.", "sentence2": "the attention results at each generation timestep for the knowledge graph information of this example are shown in (a), (b), (c) and (d) respectively.", "label": "entailment"}
{"id": "test_2445", "sentence1": "Our results also highlight the importance of explicit controlled sparsity inducing terms as effective inductive biases for improved task performance and rationale agreement.", "sentence2": "sparsity inducing methods consistently outperform the No Sparsity-baseline (row 3).", "label": "entailment"}
{"id": "test_2446", "sentence1": "We benchmark these datasets using multi-modal language modeling architectures (Tan and Bansal, 2019;Su et al., 2020) which achieve state-of-art performance on multiple vision-language tasks.", "sentence2": "we don't use any pre-training, instead train randomly initialized models on streaming data using continual learning algorithms (Robins, 1995;Rolnick et al., 2019;Aljundi et al., 2019a) and evaluate their resistance to forgetting and compositional generalization.", "label": "entailment"}
{"id": "test_2447", "sentence1": "Figure 1 shows that masking achieves decent performance without hyperparameter search.", "sentence2": "(i) a large initial sparsity removing most pretrained parameters, e.g., 95%, leads to bad performance for the four tasks.", "label": "entailment"}
{"id": "test_2448", "sentence1": "We further propose data rejuvenation to rejuvenate the inactive examples to improve the performance of NMT models.", "sentence2": "we train an NMT model on the active examples as the rejuvenation model to re-label the inactive examples, resulting in the rejuvenated examples (\u00a73.2).", "label": "entailment"}
{"id": "test_2449", "sentence1": "We follow Domhan (2018) to implement LSTM by replacing the self-attention (SAN) layers in TRANSFORMER-BASE with LSTM layers.", "sentence2": "we use a bidirectional LSTM for each layer of the encoder, and a unidirectional LSTM for each layer of decoder.", "label": "entailment"}
{"id": "test_2450", "sentence1": "Using these specialized losses, we aim to improve the learning power of the MT model.", "sentence2": "in this work, we target the improvement of pronoun translation by focusing our finetuning efforts through our proposed objectives and also through the fine-tuning data.", "label": "entailment"}
{"id": "test_2451", "sentence1": "In accordance with our settings to alternate training between the upsampled full dataset and the subset data (2D + D prn ), we also alternate the additional loss such that it is only applied to the targeted subset.", "sentence2": "in every alternate epoch, the model is trained on the upsampled full dataset (2D) with the standard CLM translation loss L g (Eq.", "label": "entailment"}
{"id": "test_2452", "sentence1": "We differ from previous studies and use a tree edit distance metric, which is defined as the minimum cost of transforming one tree into another by inserting, deleting or modifying (the label of) a node.", "sentence2": "we used the All Path Tree Edit Distance algorithm (APTED; Augsten, 2015, 2016), a novel one for the task.", "label": "entailment"}
{"id": "test_2453", "sentence1": "Throughout all the bins, we observe that both SVCCA-53 and SVCCA-23 accomplish a comparable accuracy with the best setting in each group.", "sentence2": "their clusters provide stable performance for both low or high-resource languages.", "label": "entailment"}
{"id": "test_2454", "sentence1": "No automated model is used in this section, but instead, we examine the applicability of the youshould theory in argumentation.", "sentence2": "we analyze whether each imperative preserves the original intent when it is transformed to an assertive by adding \"should\", along with appropriate changes in the verb form, (implicit) subject, and object.", "label": "entailment"}
{"id": "test_2455", "sentence1": "We further empirically show that the choice of sentence aligner plays a significant role in the quantity of parallel sentences extracted from document pairs.", "sentence2": "we study three aligners and show that combining their results, which we name 'Aligner Ensembling', increases recall.", "label": "entailment"}
{"id": "test_2456", "sentence1": "We make use of the 60 occupations listed in Caliskan et al. (2017) containing statistics about gender distributions across professions, taken from the U.S. Bureau of Labor Statistics.", "sentence2": "we generate a base set of 4,560 sentences from 38 templates, two tenses (present and past), and 60 occupations.", "label": "entailment"}
{"id": "test_2457", "sentence1": "The remaining 75 are masculine (0 feminine).", "sentence2": "we see a similar tendency to Chinese, but since the overall performance is poor, and the model is in general rather insensitive to differences in pronouns, we do not include correlation results.", "label": "entailment"}
{"id": "test_2458", "sentence1": "To address these problems, we present a novel uncertainty-aware semantic augmentation method, which takes account of the intrinsic uncertainty sourced from the one-to-many nature of machine translation (Ott et al., 2018).", "sentence2": "we first synthesize multiple reasonable source sentences to play the role of inherent uncertainty 1 for each target sentence.", "label": "entailment"}
{"id": "test_2459", "sentence1": "We present an uncertainty-aware semantic augmentation method to bridge the discrepancy of the data distribution between the training and the inference phases for dominant NMT models.", "sentence2": "we first synthesize a proper number of source sentences to play the role of intrinsic uncertainties via the controllable sampling for each target sentence.", "label": "entailment"}
{"id": "test_2460", "sentence1": "A different line of work proposed to explore constituency parsing as a dependency parsing problem.", "sentence2": "even if it is straightforward to represent constituency trees as hierarchical phrase structures, the same syntactic content can be represented with different mathematical objects (Rambow, 2010), including directed graphs commonly used for dependency parsing.", "label": "entailment"}
{"id": "test_2461", "sentence1": "KAMG outperforms the other models in all the metrics across almost all the settings on both datasets with a notable margin, due to our multi-graph knowledge aggregation model.", "sentence2": "while classifying zero-shot labels, ACNN-KAMG outperforms ZAGCNN, which uses only the label hierarchy (i.e., H g ), by 8% in R@10 and 6.5% in nDCG@10 on MIMIC-II and 4.1% in R@10 and 10.5% in nDCG@10 on MIMIC-III.", "label": "entailment"}
{"id": "test_2462", "sentence1": "We focus on unsupervised STS, following  and Ethayarajh (2018).", "sentence2": "we utilize only pre-trained word vectors, and do not use any supervision including training data for related tasks (e.g., natural language inference) and external resources (e.g., paraphrase database).", "label": "entailment"}
{"id": "test_2463", "sentence1": "However, several studies have confirmed that the norm of word vectors has a large dispersion (Schakel and Wilson, 2015; Arefyev et al., 2018).", "sentence2": "a sentence vector would contain word vectors of various sizes.", "label": "entailment"}
{"id": "test_2464", "sentence1": "In the experiments, RE2 (Yang et al., 2019), De-cATT (Parikh et al., 2016), CAFE (Tay et al., 2018a) and BERT (Devlin et al., 2018) were set as the underlying models, achieving new models respectively denoted as \"WD-Match (RE2)\", \"WD-Match (DecAtt)\", \"WD-Match (CAFE)\", and \"WD-Match (BERT)\".", "sentence2": "in WD-Match(RE2), F is a stacked blocks which consist of multiple convolution layers and multiple attention layers, and M is an MLP; in WD-Match(DecAtt), F is an attention layer and a aggregation layer, M is an MLP.", "label": "entailment"}
{"id": "test_2465", "sentence1": "We conducted experiments to analyze how the feature vectors (i.e., hX and hY ) generated by WD-Match distributed in the common semantic space, using WD-Match(RE2) as an example.", "sentence2": "we trained a RE2 model and a WD-Match (RE2) model based on SciTail dataset.", "label": "entailment"}
{"id": "test_2466", "sentence1": "We conducted experiments to test how the Wasserstein distance-based regularizer guides the training of matching models.", "sentence2": "we tested the WD-Match (RE2) and RE2 models generated at each training epochs.", "label": "entailment"}
{"id": "test_2467", "sentence1": "The main idea behind the cost attention is to make the teacher and student Transformer networks be as close as possible.", "sentence2": "we could reduce the overall cost of EMD by increasing the weights of the layers with low flow cost, while the weights of the layers with high flow cost should be decreased adaptively.", "label": "entailment"}
{"id": "test_2468", "sentence1": "Similar to TinyBERT, our BERT-EMD method also contains a general distillation and a task-specific distillation.", "sentence2": "we initialize our student model with the general distillation model provided by TinyBERT 1 .", "label": "entailment"}
{"id": "test_2469", "sentence1": "Table 1 shows that the proposed BERT-EMD 6 method can effectively compress BERT BASE 12 into a 6-layer BERT model without performance sacrifice.", "sentence2": "bERT-EMD 6 performs better than the 12-layer bERT bERT bASE 12 model on 7 out of 9 tasks, with only about 50% parameters and inference time of the original bERT bASE 12 model.", "label": "entailment"}
{"id": "test_2470", "sentence1": "To verify the effectiveness of EMD and the cost attention mechanism, we perform ablation test of BERT-EMD on two large datasets (MNLI and QQP) and two small datasets (MRPC and RTE) in terms of removing EMD (denoted as w/o EMD) and cost attention (w/o CA), respectively.", "sentence2": "for the method of removing EMD, we retain the many-to-many layer mapping by simply replacing the EMD with the mean squared error when measuring the distance between the teacher and student layers.", "label": "entailment"}
{"id": "test_2471", "sentence1": "We follow Fan et al. (2020) and consider the computation of one layer as a unit of computational cost.", "sentence2": "we will assess how many layers, on average, each method builds up for each passage.", "label": "entailment"}
{"id": "test_2472", "sentence1": "We note that it reaches the similar results of the static baselines with much fewer layers.", "sentence2": "it yields substantially higher performance than static methods when the computational budget is smaller than ten layers.", "label": "entailment"}
{"id": "test_2473", "sentence1": "In this work we show that adaptive computation can lead to substantial efficiency improvements for ODQA.", "sentence2": "we find that it is important to allocate budget dynamically across a large number of passages and prioritise different passages according to various features such as the probability that the passage has an answer.", "label": "entailment"}
{"id": "test_2474", "sentence1": "Secondly, we utilize a structured description to restore the scene.", "sentence2": "we build a scene graph based on the original narrative and the knowledge from Atomic.", "label": "entailment"}
{"id": "test_2475", "sentence1": "To summarise, inspired by human behaviors, we propose a novel method to restore the scene for narrative MRC.", "sentence2": "we introduce event knowledge from Atomic , and build the scene graph to describe the scene.", "label": "entailment"}
{"id": "test_2476", "sentence1": "Multiple studies of BERT concluded that it is considerably overparametrized.", "sentence2": "it is possible to ablate elements of its architecture without loss in performance or even with slight gains (Kovaleva et al., 2019;Michel et al., 2019;Voita et al., 2019).", "label": "entailment"}
{"id": "test_2477", "sentence1": "This shows that even the worst possible selection of pre-trained BERT components for a given task still contains a lot of useful information.", "sentence2": "some lottery tickets are \"winning\" and yield the biggest gain, but all subnetworks have a non-trivial amount of useful information.", "label": "entailment"}
{"id": "test_2478", "sentence1": "We observed that the initial layers focus on query-passage interaction, whereas later layers focus more on contextual understanding and enhancing the answer prediction.", "sentence2": "for quantifier questions (how much/how many), we notice that BERT focuses on confusing words (i.e., on other numerical quantities in the passage) in the later layers, but still manages to predict the answer correctly.", "label": "entailment"}
{"id": "test_2479", "sentence1": "Nevertheless, the counterfactual samples are simply added to the training data for augmentation, ignoring that the relationship between original samples and counterfactual samples are vital for the reasoning of VQA models.", "sentence2": "the model should be able to learn why the correct answer cannot be inferred after changing the original sample to the counterfactual sample.", "label": "entailment"}
{"id": "test_2480", "sentence1": "In this paper, we present VD-BERT, a novel unified vision-dialog Transformer framework for Vis-Dial tasks.", "sentence2": "we first encode the image into a series of detected objects and feed them into a Transformer encoder together with the image caption and multi-turn dialog.", "label": "entailment"}
{"id": "test_2481", "sentence1": "We use two visually grounded training objectivesmasked language modeling (MLM) and next sentence prediction (NSP) to train our VD-BERT.", "sentence2": "we aim to capture dense interactions among both inter-modality (i.e., image-dialog) and intra-modality (i.e., image-image, dialog-dialog).", "label": "entailment"}
{"id": "test_2482", "sentence1": "For training in the discriminative setting, we transform the task of selecting an answer into a point-wise binary classification problem.", "sentence2": "we sample an answer At from the candidate pool and append it to the input sequence, and ask the NSP head to distinguish whether the sampled answer is correct or not.", "label": "entailment"}
{"id": "test_2483", "sentence1": "We evaluate our model on the VisDial v0.9 and v1.0 datasets (Das et al., 2017).", "sentence2": "v0.9 contains a training set of 82,783 images and a validation set of 40, 504 images.", "label": "entailment"}
{"id": "test_2484", "sentence1": "TDAEME combines both general and domain word embeddings in a supervised manner, which is implemented by a supervised autoencoder.", "sentence2": "tDAEME predicts the words' category distribution.", "label": "entailment"}
{"id": "test_2485", "sentence1": "Previous work (Wang and Lu, 2018) engage structured attention networks (Kim et al., 2017), which extend the previous attention mechanism to incorporate structure dependencies, to model the interaction among context words, and perform softselections of word spans.", "sentence2": "they introduce two hand-coded regularizers to constrain the soft-selection process to attend to few short opinion spans.", "label": "entailment"}
{"id": "test_2486", "sentence1": "The model achieves the best performance when the number of CRFs equals to 4.", "sentence2": "the performance becomes relatively plateau when a large number of CRFs is adopted.", "label": "entailment"}
{"id": "test_2487", "sentence1": "We propose a simple and effective MCRF-SA model to extract aspect-specific opinion span features.", "sentence2": "with the proposed multi-CRF structured attention layer and the effective position decay function, our model is capable of extracting various aspect-specific opinion span features from different representation sub-spaces.", "label": "entailment"}
{"id": "test_2488", "sentence1": "In this scenario, we need to consider both the dependence among different labels (label dependence) and the dependence between each predicting label and different modalities (modality dependence).", "sentence2": "we propose a multi-modal sequence-to-set approach to effectively model both kinds of dependence in multi-modal multi-label emotion detection.", "label": "entailment"}
{"id": "test_2489", "sentence1": "In this group, the baselines use different approaches to deal with the multi-label issue without considering the modality dependence issue.", "sentence2": "in these approaches, the multi-modal inputs are early fused (simply concatenated) as a new input.", "label": "entailment"}
{"id": "test_2490", "sentence1": "To solve this problem, we develop a simple but effective approach to enrich ABSA test sets.", "sentence2": "we generate new examples to disentangle the confounding sentiments of the non-target aspects from the target aspect's sentiment.", "label": "entailment"}
{"id": "test_2491", "sentence1": "Is our method generalizable to different datasets?", "sentence2": "how does it perform if we train the metric on one dataset and test on another one?", "label": "entailment"}
{"id": "test_2492", "sentence1": "PEGASUS proposes Transformerbased models with extracted gap-sentences for abstractive summarization.", "sentence2": "these Transformer-based approaches are divided into Base and Large versions, according to the layers of Transformer.", "label": "entailment"}
{"id": "test_2493", "sentence1": "The output of ALBERT encoder contains word hidden states h word and sentence hidden states h sent .", "sentence2": "aLBERT takes subword units as input, which means that one word may correspond to multiple hidden states.", "label": "entailment"}
{"id": "test_2494", "sentence1": "The proposed Cross-Thought architecture is illustrated in Figure 2(c).", "sentence2": "we preappend each sequence with multiple special tokens, the final hidden states of which are used as the final sentence embedding.", "label": "entailment"}
{"id": "test_2495", "sentence1": "In this section, we introduce our proposed pretraining model Cross-Thought, and describe how to finetune the pre-trained model on downstream tasks.", "sentence2": "most parameters in downstream tasks can be initialized by the pre-trained Cross-Thought, and for certain tasks (e.g., ranking) the attention weights across sequences can be directly used without additional parameters (Figure 3).", "label": "entailment"}
{"id": "test_2496", "sentence1": "However, such two-step procedures in these early attempts can be performed via a single-step procedure with neural models.", "sentence2": "recent attempts have utilized sequence-to-sequence (seq2seq) models as a single-step procedure to learn the implicit relationship between operators and operands (Amini et al., 2019; Chiang and Chen, 2019; Wang et al., 2019).", "label": "entailment"}
{"id": "test_2497", "sentence1": "The fully automatic EPT model, which does not use handcrafted features, yields comparable performance to existing models using hand-crafted features.", "sentence2": "on the ALG514 dataset, the EPT outperforms the best-performing pure neural model by about 40% and shows comparable performance accuracy to the SoTA model that uses hand-crafted features.", "label": "entailment"}
{"id": "test_2498", "sentence1": "From the ablation study, our data showed that the two components of generating 'Expression' token and applying operand-context pointer, each improved the accuracy of the EPT model in different ways.", "sentence2": "as seen in Table 5, adding Expression token to the vanilla Transformer improved the performance accuracy by about 15% in ALG514 and DRAW-1K and about 1% in MAWPS.", "label": "entailment"}
{"id": "test_2499", "sentence1": "First, using Expression tokens in highcomplexity datasets address the expression fragmentation issue when generating solution equations, which is more complex in ALG514 and DRAW-1K than MAWPS.", "sentence2": "table 3 shows that on average the number of unknowns in ALG514 and DRAW-1K is almost twice (1.82 and 1.75, respectively) than MAWPS (1.0).", "label": "entailment"}
{"id": "test_2500", "sentence1": "Second, using operand-context pointers in highcomplexity datasets addresses the operand-context separation issue when selecting an operand, which is more complex in ALG514 and DRAW-1K than MAWPS.", "sentence2": "table 3 shows that on average the amount of Expression tokens is also twice in ALG514 and DRAW-1K (7.45 and 7.95, respectively) than that of MAWPS (3.60).", "label": "entailment"}
{"id": "test_2501", "sentence1": "In addition, even with 800 generic templates, the synthesized sentences still lack naturalness and variety.", "sentence2": "people often com\u0002press multiple concepts into simpler constructions (sublexical compositionality (Wang et al., 2015)), e.g. \u201cbooks with at least 1 award\u201d can be simplified to \u201caward-winning books\u201d.", "label": "entailment"}
{"id": "test_2502", "sentence1": "Based on that, we inject two types of knowledge as additional objectives to regularize the learning process.", "sentence2": "we exploit logic knowledge by transforming the consistency between sentencelevel and token-level predictions with propositional Boolean expressions.", "label": "entailment"}
{"id": "test_2503", "sentence1": "Results show that our knowledge-augmented method significantly improves a strong multi-task learning approach.", "sentence2": "our model greatly improves precision, demonstrating leveraging declarative knowledge expressed in both first-order logic and natural language can help the model to make more accurate predictions.", "label": "entailment"}
{"id": "test_2504", "sentence1": "Therefore, we consider tackling the problems by exploiting logic knowledge.", "sentence2": "we propose to employ propositional Boolean expressions to explicitly regularize the model with a logic-driven objective, which improves the logical consistency between two different grained predictions, and makes our method more interpretable.", "label": "entailment"}
{"id": "test_2505", "sentence1": "To exploit this kind of knowledge, we adopt an additional encoder to encode the literal definition of each propaganda technique.", "sentence2": "for each definition, the input sequence is modified as \"[CLS]definition[SEP ]\" and fed into BERT.", "label": "entailment"}
{"id": "test_2506", "sentence1": "Focusing solely on improving the representation of the class label set, we show in experiments conducted in both private and public intent classification datasets, that better detection of out-of-scope examples (OOS) is achieved and, as a consequence, that the overall accuracy of intent classification is also improved.", "sentence2": "using the recently-released Larson dataset, an error of about 9.9% has been achieved for OOS detection, beating the previous state-of-the-art result by more than 31 percentage points.", "label": "entailment"}
{"id": "test_2507", "sentence1": "But, in many cases, the classes are in fact associated with inter-connected higher-level concepts which could be formatted into more meaningful representations and better exploited in the classification process for an enhanced representation of the scope of the classifier.", "sentence2": "we explore here the use of graphs which represent information by means of nodes connected to each other by arcs.", "label": "entailment"}
{"id": "test_2508", "sentence1": "Average word embeddings is also used in this work.", "sentence2": "glove (Pennington et al., 2014) is employed for embedding each word of the document.", "label": "entailment"}
{"id": "test_2509", "sentence1": "Even though BERT+ has not significantly outperformed BERT in some scenarios, such as with PT-BR chatbots, we can observe a great improvement that the word graphs can bring to intent recognition if we take into account the ISER metric.", "sentence2": "the difference in ISER of BERT+ against BERT is of 5%, where the former achieved 37% and the latter 32%.", "label": "entailment"}
{"id": "test_2510", "sentence1": "That is, the difference in ISER of BERT+ against BERT is of 5%, where the former achieved 37% and the latter 32%.", "sentence2": "bERT+ can be considered quite worse than bERT for in-scope only intent classification.", "label": "entailment"}
{"id": "test_2511", "sentence1": "We start with a formalisation of lexical ambiguity.", "sentence2": "we formalise the lexical ambiguity of an entire language as Interpreting entropy as uncertainty, this definition implies that the harder it is to predict the meaning of a word from its form alone, the more lexically ambiguous that word must be.", "label": "entailment"}
{"id": "test_2512", "sentence1": "We aim to address the above issues by quantifying the primary sources of errors over representative models.", "sentence2": "following MQM (Mariana, 2014), we design 8 metrics on the Accuracy and Fluency aspects.", "label": "entailment"}
{"id": "test_2513", "sentence1": "Pre-training: Pre-training is highly effective for summarization, and even achieves a better content selection capability without copy and coverage mechanisms.", "sentence2": "joint pre-training combining text understanding and generation gives the most salient advantage, with the BART model achieving by far the state-of-the-art results on both automatic and our human evaluations.", "label": "entailment"}
{"id": "test_2514", "sentence1": "PolyTope is an error-oriented fine-grained human evaluation method based on Multidimensional Quality Metric (MQM) (Mariana, 2014).", "sentence2": "it consists of 8 issue types (Section 4.1), 8 syntactic labels (Section 4.2) and a set of severity rules (Section 4.3) to locate errors and to automatically calculate an overall score for the tested document.", "label": "entailment"}
{"id": "test_2515", "sentence1": "We develop an operating interface for annotation, which is shown in Appendix A.1.", "sentence2": "a human annotator is presented the original text and an output summary in juxtaposition, and is asked to select segments that are deemed incorrect after reading.", "label": "entailment"}
{"id": "test_2516", "sentence1": "It gives large improvements on Addition, Omission and Inacc errors, proving that unified pre-training for both understanding and generation is highly useful for content selection and combination.", "sentence2": "bART shows superior performance in handling the leading bias of CNN/DM dataset.", "label": "entailment"}
{"id": "test_2517", "sentence1": "It is a recall-based metric calculating lexical overlap between system output and human summaries.", "sentence2": "rOUGE-1 is based on unigram overlaps, rOUGE-2 on bigrams and rOUGE-L on longest common subsequences.", "label": "entailment"}
{"id": "test_2518", "sentence1": "The situation changed with the introduction of Babel-Net (Navigli and Ponzetto, 2012a), a massive multilingual semantic network, created by automatically integrating WordNet, Wikipedia, and other resources.", "sentence2": "babelNet synsets contain translations in multiple languages for each individual word sense.", "label": "entailment"}
{"id": "test_2519", "sentence1": "We find that applying transformation is generally able to improve each contextualized model, obtaining the best performance across all the tasks.", "sentence2": "we observe substantial improvements in Usim (ca. 0.04 increase of \u03c1) and SCWS (ca. 0.03 increase of \u03c1).", "label": "entailment"}
{"id": "test_2520", "sentence1": "We observe improvement from the transformation on the static anchors in Inter Word tasks.", "sentence2": "aligning towards FastText brings the largest and the most consistent gains.", "label": "entailment"}
{"id": "test_2521", "sentence1": "We explore an alternative method to allow mentions of the same PoC to be connected with each other.", "sentence2": "we direct one attention head to focus on tokens belonging to the same PoC, allowing these tokens to share semantic representations, similar to Strubell et al. (2019).", "label": "entailment"}
{"id": "test_2522", "sentence1": "A human evaluator from Amazon Mechanical Turk (mturk.com) is asked to assess if the fusion sentence has successfully retained the original meaning.", "sentence2": "an evaluator is tasked with reading the two article sentences and fusion sentence and answering yes or no to the following question, \"Is this summary sentence true to the original article sentences it's been sourced from, and it has not added any new meaning?\"", "label": "entailment"}
{"id": "test_2523", "sentence1": "Existing work in neural story generation has established the strength of adding a content planning stage to structure the generated content (Yao et al., 2019; Fan et al., 2019) (discussed in more detail in Section 7).", "sentence2": "this line of work trains a pipeline with one model that generates from prompt\u2192 plot and another that generates from prompt + plot \u2192 story.", "label": "entailment"}
{"id": "test_2524", "sentence1": "Shi et al. (2019) propose a visually grounded neural syntax learner (VG-NSL) to tackle the task.", "sentence2": "they learn a parser from aligned imagesentence pairs (e.g., image-caption data), where each sentence describes visual content of the corresponding image.", "label": "entailment"}
{"id": "test_2525", "sentence1": "We also assume that there is a limited budget to ask domain experts to provide explanations during training.", "sentence2": "we consider k rounds of interactions with domain experts and each round has a query budget b.", "label": "entailment"}
{"id": "test_2526", "sentence1": "Despite these empirical observations, little prior work analyzed or showed how to mitigate negative interference in multilingual language models.", "sentence2": "it is natural to ask: (1) Can negative interference occur for low-resource languages also? (2) What factors play an important role in causing it? (3) Can we mitigate negative interference to improve the model\u2019s cross-lingual transferability?", "label": "entailment"}
{"id": "test_2527", "sentence1": "We seek to individually characterize the un-derlying factors of negative interference through a set of ablation studies and glean insights on its causes.", "sentence2": "we examine if training corpus size and language similarity affect negative interference, and also measure gradient and parameter similarities between languages.", "label": "entailment"}
{"id": "test_2528", "sentence1": "Our results show that negative interference can occur in both high-resource and low-resource languages.", "sentence2": "we observe that neither subsampling the training corpus nor adding typologically similar languages substantially impacts negative interference.", "label": "entailment"}
{"id": "test_2529", "sentence1": "We then retrain the monolingual and bilingual models and compare with results of their high-source counterparts.", "sentence2": "we test if reducing lg 1 's training size also reduces negative interference on lg 2 .", "label": "entailment"}
{"id": "test_2530", "sentence1": "Therefore, we study whether gradient conflicts exist between languages in multilingual models.", "sentence2": "we sample one batch for each language in the model and compute the corresponding gradients' cosine similarity for every 10 steps during pretraining.", "label": "entailment"}
{"id": "test_2531", "sentence1": "We focus on monolingual and bilingual models for a more controllable comparison, which we refer to as Mono and JointPair respectively.", "sentence2": "we always include English (En) in bilingual models to compare on zero-shot transfer settings with prior work.", "label": "entailment"}
{"id": "test_2532", "sentence1": "Similar to NER, POS is also a sequence labelling task but with a focus on synthetic knowledge.", "sentence2": "we use the Universal Dependencies treebanks (Nivre et al., 2018).", "label": "entailment"}
{"id": "test_2533", "sentence1": "In Table 2 and 3, we report our results on NER, POS and QA together with XLM-100, which is trained on 100 languages and contains 827M parameters.", "sentence2": "we observe that monolin-  gual models outperform bilingual models for all languages except Swahili on all three tasks.", "label": "entailment"}
{"id": "test_2534", "sentence1": "We also plot the similarity within English, measured using two independently sampled batches.", "sentence2": "gradients between two different languages are indeed less similar than those within the same language.", "label": "entailment"}
{"id": "test_2535", "sentence1": "We thus train variants of bilingual models that contain language-specific components for each language.", "sentence2": "we consider adding language-specific feedforward layers, attention layers, and residual adapter layers (Rebuffi et al., 2017;Houlsby et al., 2019), denoted as ffn, attn and adpt respectively.", "label": "entailment"}
{"id": "test_2536", "sentence1": "At the same time, our method also mitigates negative interference and outperforms JointPair on withinlanguage performance, closing the gap with monolingual models.", "sentence2": "it performs better than ordinary adapters in both settings.", "label": "entailment"}
{"id": "test_2537", "sentence1": "Our work is also related to transfer learning (Pan and Yang, 2010) and multi-task learning (Ruder, 2017).", "sentence2": "prior work have observed (Rosenstein et al., 2005) and studied (Wang et al., 2019) negative transfer, such that transferring knowledge from source tasks can degrade the performance in the target task.", "label": "entailment"}
{"id": "test_2538", "sentence1": "With carefully controlled experiments, we are confident that any improvement in the results is solely attributable to vocabulary composition.", "sentence2": "our vocabularies improve models without increasing the model size, compute or data.", "label": "entailment"}
{"id": "test_2539", "sentence1": "We see that the models converge to different representations, where the lower layer representations are more similar and they diverge as we move towards the upper layers.", "sentence2": "note that this indicates that multi-task learning helps in learning different representations than self-supervised pre-training, and meta-learning model representations are different from the other models.", "label": "entailment"}
{"id": "test_2540", "sentence1": "TNT enhances the language learning by utilizing text normalization pre-training objective, inspired by misspelling correction.", "sentence2": "tNt randomly manipulates tokens from the input text.", "label": "entailment"}
{"id": "test_2541", "sentence1": "To put this variation in context, we note that the MLDoc and XNLI test sets are relatively large, so a 2.5% difference in accuracy would be statistically significant (at the 5% significance level using the usual test of proportions), which means that a paper claiming 'state-of-the-art' performance on these zero-shot tasks may be reporting strong results because of the large between-run variation, rather than a genuine improvement due to their proposed technique.", "sentence2": "using the En dev accuracy for choosing the final model for zero-shot transfer leads to inconsistent results across different runs.", "label": "entailment"}
{"id": "test_2542", "sentence1": "A similar effect occurs with XLM-R and the more distant languages (Ar, Vi, Zh).", "sentence2": "Chinese (Zh) degrades by 5.9 points as En improves, which may be evidence of directional disagreement in MLQA between En dev and Zh test.", "label": "entailment"}
{"id": "test_2543", "sentence1": "In this paper, we study existing and novel auxiliary tasks in a BERT paradigm to guide future research in an informed manner.", "sentence2": "we test and provide insight on: 1) NSP's effect on BERT pretraining; 2) the result of 14 other auxiliary tasks on BERT pre-training; 3) how to combine multiple tasks in BERT pre-training; and 4) the advantages of multi-task learning in BERT pre-training.", "label": "entailment"}
{"id": "test_2544", "sentence1": "Using this analyzed data, we then learn an agreement prediction model that contains the desired rules.", "sentence2": "we devise a binary classification problem of identifying whether agreement will be observed between a head and its dependent token on a given morphological property.", "label": "entailment"}
{"id": "test_2545", "sentence1": "In our work, we used articles from Wikipedia to build a background knowledge corpus for each language.", "sentence2": "we parsed the text from the entire Wikipage, removing non-textual content, e.g., HTML tags, tables, etc.", "label": "entailment"}
{"id": "test_2546", "sentence1": "For all the elements of each type given to workers, the percentage of elements being captioned ranges from 75% to 94% (see Figure 3).", "sentence2": "the View type has the lowest labeling ratio of 75%, which we suspect that elements with the View type, a generic widget type, tend to be quite arbitrary and are difficult for the workers to understand.", "label": "entailment"}
{"id": "test_2547", "sentence1": "Figure 2 shows that our corpus has reasonable word-level agreement among the captions of the same widget.", "sentence2": "for the 6K words, we report the mean precision and recall of every 10 consecutive words in the vocabulary.", "label": "entailment"}
{"id": "test_2548", "sentence1": "Pre-training allows us to leverage the images of all the elements instead of only those with caption labels.", "sentence2": "to reconstruct an image, we used 5 layers of transposed convolution where each layer has a residual connection architecture that is similar to the encoder part (that is discussed in the main paper).", "label": "entailment"}
{"id": "test_2549", "sentence1": "Within our framework, we also experiment with using BERT in both the energy function and inference network architecture.", "sentence2": "the \"input feature vector\" in Equation 3 is replaced by the features from BERT.", "label": "entailment"}
{"id": "test_2550", "sentence1": "KumaGCN outperforms all the baselines in terms of both averaged accuracy scores and averaged F1 scores.", "sentence2": "it improves the performance by 2.77 F1 points compared with the depGCN method.", "label": "entailment"}
{"id": "test_2551", "sentence1": "While linguistic research has historically sought to uncover the rules for associating a noun with gender in terms of surface features or semantics (see Corbett 1991 for an overview), we take an extensional approach.", "sentence2": "we treat a gender category in a language solely as the set of words it covers.", "label": "entailment"}
{"id": "test_2552", "sentence1": "We could ask: What fraction of A agrees in gender across languages?", "sentence2": "for each noun in our multilingual vocabulary, do both languages lexicalize it with the same gender?", "label": "entailment"}
{"id": "test_2553", "sentence1": "In this paper, we propose attentive graph convolutional networks to enhance neural CCG supertagging through a novel solution of leveraging contextual information.", "sentence2": "we build the graph from chunks (n-grams) extracted from a lexicon and apply attention over the graph, so that different word pairs from the contexts within and across chunks are weighted in the model and facilitate the supertagging accordingly.", "label": "entailment"}
{"id": "test_2554", "sentence1": "The results show that the model performance drops when either part is ablated (ID 1 vs. ID 2-6).", "sentence2": "removing attention significantly hurts the performance, where all configurations without attention (ID 4-6) shows worse-than-baseline (ID 7) results; this observation confirms the importance of applying attention on GCN.", "label": "entailment"}
{"id": "test_2555", "sentence1": "Especially for the smaller sampled sets, our method demonstrates more significant performance improvement.", "sentence2": "the proposed method achieved average 1.93 and 1.38 point improvement compared with the baseline methods in the 1k and 2k settings, respectively.", "label": "entailment"}
{"id": "test_2556", "sentence1": "Similar to NER, our method demon-  strates more significant performance improvement for smaller sampled sets on POS tagging.", "sentence2": "the proposed method achieved average 0.56, 0.60 and 0.46 point improvement compared with the baseline methods in the 1k, 2k and 4k settings, respectively.", "label": "entailment"}
{"id": "test_2557", "sentence1": "The results show that even a small fraction of real data can significantly improve zero-shot performance.", "sentence2": "5% of the MNLI English training dataset is enough to lift the performance of extraction to that of XLMR-Base for all languages.", "label": "entailment"}
{"id": "test_2558", "sentence1": "In order to relieve the under-contextualization issue of many synsets, we propose a gloss augmentation approach to draw in more contextual information.", "sentence2": "we simply use the short-length glosses as queries (words or phrases) to retrieve sequences from the web and combine the sequences with the original gloss and example sentences to learn a contextual representation from BERT.", "label": "entailment"}
{"id": "test_2559", "sentence1": "We start with a generic summarization corpus.", "sentence2": "in this work we use the CNN/DailyMail (Hermann et al., 2015) which consists of a set of (document, summary) pairs.", "label": "entailment"}
{"id": "test_2560", "sentence1": "The systems equipped with IO tagging scheme always outperform those with BIO scheme.", "sentence2": "sTRUCTsHOT and NNshot benefit from switching from BIO scheme to IO scheme by an average of 3.2% and 3.8% F1 scores on the five-shot tag set extension and domain transfer tasks respectively.", "label": "entailment"}
{"id": "test_2561", "sentence1": "We proposed a framework for learning structured representation of entity names under low-resource settings.", "sentence2": "we focus on a challenging scenario, where entity names are given as textual strings without context.", "label": "entailment"}
{"id": "test_2562", "sentence1": "As mentioned earlier, we used huggine-Face pytorch-transformer (Wolf et al., 2019) to implement our BERT-CRF model.", "sentence2": "we used the pretrained BertModel, and we obtained the tokenizer and pretrained weights using the bert-base-cased configuration.", "label": "entailment"}
{"id": "test_2563", "sentence1": "Our approach achieves the state-of-the-art among all methods.", "sentence2": "the recall of our approach is much higher than other methods, which demonstrate the effectiveness of the trigger identification step.", "label": "entailment"}
{"id": "test_2564", "sentence1": "We aim to leverage human and machine intelligence together for attention supervision.", "sentence2": "we show that human annotation cost can be kept reasonably low, while its quality can be enhanced by machine selfsupervision.", "label": "entailment"}
{"id": "test_2565", "sentence1": "Specifically, we show that human annotation cost can be kept reasonably low, while its quality can be enhanced by machine selfsupervision.", "sentence2": "for this goal, we explore the advantage of counterfactual reasoning, over associative reasoning typically used in attention supervision.", "label": "entailment"}
{"id": "test_2566", "sentence1": "Key distinctions from (Bao et al., 2018) are (a) humans annotate even less, and (b) without additional training resources.", "sentence2": "we start by loosening the definition of human annotation (Camburu et al., 2018; Zhong et al., 2019) into the task-level annotation: it reduces annotation cost to the size of vocabulary, or often to zero, when public resources such as sentiment lexicon replace such annotation.", "label": "entailment"}
{"id": "test_2567", "sentence1": "Our adaptation goal is an unsupervised adaptation of task-level human annotation to samplelevel supervision signals for attention/classification models.", "sentence2": "we propose Sample-level AttentioN Adaptation (SANA).", "label": "entailment"}
{"id": "test_2568", "sentence1": "Specifically, we propose Sample-level AttentioN Adaptation (SANA).", "sentence2": "for self-supervising such adaptation, SANA conducts what-if tests per each sample, of whether the permutation on human annotation changes the machine prediction.", "label": "entailment"}
{"id": "test_2569", "sentence1": "Specifically, for self-supervising such adaptation, SANA conducts what-if tests per each sample, of whether the permutation on human annotation changes the machine prediction.", "sentence2": "we collect the counterfactual (machine) supervisions for free, by observing whether highly attended word by human leads to the same machine prediction, compared to when such attention is counterfactually lowered.", "label": "entailment"}
{"id": "test_2570", "sentence1": "To validate this, we employ the attention-permutation experiments designed in (Jain and Wallace, 2019), i.e., what-if simulation.", "sentence2": "when given an input sample in the test phase, we look into whether the randomly mutated attention (i.e., cause) from the original attention yields any changes in the corresponding prediction result (i.e., effect).", "label": "entailment"}
{"id": "test_2571", "sentence1": "We studied the problem of attention supervision, and showed that requiring sample-level human supervision is often less effective than task-level alternative with lower (and often zero-) overhead.", "sentence2": "we proposed a counterfactual signal for self-supervision, to augment task-level human annotation, into sample-level machine attention supervision, to increase both the accuracy and robustness of the model.", "label": "entailment"}
{"id": "test_2572", "sentence1": "We reimplement the model of Tenney et al. (2019b),4 which gives a unified architecture that works for a wide range of probing tasks.", "sentence2": "it classifies single spans or pairs of spans in the following way: 1) construct token represen\u0002tations by pooling across encoder layers with a learned scalar mix (Peters et al., 2018a), 2) con\u0002struct span representations from these token repre\u0002sentations using self-attentive pooling (Lee et al., 2017), and 3) concatenate those span representa\u0002tions and feed the result through a fully-connected layer to produce input features for the classification layer.", "label": "entailment"}
{"id": "test_2573", "sentence1": "When we build an empirical distribution over templates on the training set of Spider, we observe a 85% coverage of dev set templates.", "sentence2": "85% of dev set examples have a query whose template occurs in the training set.", "label": "entailment"}
{"id": "test_2574", "sentence1": "Figure 1 depicts such alignments with arrows and colors.", "sentence2": "the proposed method is a two-step procedure.", "label": "entailment"}
{"id": "test_2575", "sentence1": "In addition, we assign a binary label for each pair of review sentence and rebuttal sentence to indicate if the two sentences in this pair are aligned.", "sentence2": "the binary label is 1 only when: 1) both two sentences are from arguments; 2) the rebuttal sentence is replying the argument where the review sentence originates.", "label": "entailment"}
{"id": "test_2576", "sentence1": "MT-LSTM-CRF is a baseline without the hierarchical LSTM design.", "sentence2": "t-LStM is removed from our framework.", "label": "entailment"}
{"id": "test_2577", "sentence1": "For training the sentence pairing classifier, we investigate the effect of data sampling on the matching performance.", "sentence2": "we compare the  performance of using different numbers (i.e., k) of negative samples for each review argument sentence.", "label": "entailment"}
{"id": "test_2578", "sentence1": "During the evaluation of the argument pair extraction performance, we determine the argument pairing relation on span level with the sentence pairing results.", "sentence2": "we perform binary classification on all sentence pairs enumerated from a candidate argument pair.", "label": "entailment"}
{"id": "test_2579", "sentence1": "Intuitively, a larger confidence threshold means a stricter criterion for sentencelevel alignment for argument pairs.", "sentence2": "the confidence of the argument pair prediction is controlled by p%.", "label": "entailment"}
{"id": "test_2580", "sentence1": "Given the status quo, our goal is to further the computational study of exaggeration.", "sentence2": "our contributions in this work are three-fold.", "label": "entailment"}
{"id": "test_2581", "sentence1": "We begin by collecting hyperbolic sentences from two sources: webpages in professional educational websites 1 and linguistics research papers on hyperbole in Chinese (Huang, 2010; Zhao and Lu, 2013; Liao and Ge, 2014; Zhou and Jiang, 2014; Zhang, 2016).", "sentence2": "we select 700 sentences from these two sources that have been discussed and determined to be hyperbolic by experts on exaggeration.", "label": "entailment"}
{"id": "test_2582", "sentence1": "Finally, we ask the two annotators involved in Step 3 to judge whether each hyperbolic sentence obtained in the previous step is indeed hyperbolic.", "sentence2": "if at least one of them thinks a sentence is not hyperbolic or does not truly reflect the meaning of its non-hyperbolic counterpart, we will delete it.", "label": "entailment"}
{"id": "test_2583", "sentence1": "To answer this question, we first compute the cosine similarity of each pair of hyperbolic sentences in the same set as well as the cosine similarity of each pair of non-hyperbolic sentences in the same set, where cosine similarity is computed based on their one-hot word vectors.", "sentence2": "the more word overlaps there are between two sentences, the higher their similarity is.", "label": "entailment"}
{"id": "test_2584", "sentence1": "The attention mechanism computes an output vector by accumulating relevant information from a sequence of input vectors.", "sentence2": "it assigns attention weights (i.e., relevance) to each input, and sums up input vectors based on their weights.", "label": "entailment"}
{"id": "test_2585", "sentence1": "However, our proposal differs from theirs in some aspects.", "sentence2": "we aim to analyze the behavior of the whole attention mechanism more accurately, whereas they aim to make the attention weights more accurate.", "label": "entailment"}
{"id": "test_2586", "sentence1": "We included /s as the alignment targets and we considered the alignments to /s as no alignment.", "sentence2": "if the model aligns a certain word with /s , we assume that the model decides that the word is not aligned to any word.", "label": "entailment"}
{"id": "test_2587", "sentence1": "To verify whether the results obtained in the Section 5 are reproducible in different settings, we conducted an additional experiment using the model with a different number of attention heads.", "sentence2": "we used a model with eight attention heads in both the encoder and decoder.", "label": "entailment"}
{"id": "test_2588", "sentence1": "Suppose we have two non-parallel corpora X and Y with style S x and S y , the goal is training two transferrers, each of which can (i) transfer a sen-  tence from one style (either S x and S y ) to another (i.e., transfer intensity); and (ii) preserve the styleindependent context during the transformation (i.e., preservation).", "sentence2": "we denote the two transferrers f and g. f : X \u2192 Y transfers a sentence x \u2208 X with style S x to y * with style S y .", "label": "entailment"}
{"id": "test_2589", "sentence1": "Nevertheless, when pre-trained models are used as a fine-tuning approach, which is a common practice, graph structure does not contribute to the final results.", "sentence2": "the graph structure may not be necessary for multi-hop question answering.", "label": "entailment"}
{"id": "test_2590", "sentence1": "We devise a simple encoding scheme that allows us to make the model aware of the target boundaries, without architectural modifications to BART.", "sentence2": "we encode <c, t> pairs as sequences of subword tokens in which the boundaries of the t span in c are marked by two special tokens, i.e. <define> and </define>.", "label": "entailment"}
{"id": "test_2591", "sentence1": "In this work, we explore several unsupervised word-level representation extraction strategies and configurations for lexico-semantic tasks (i.e., probes), stemming from different combinations of the components detailed in Table 1 and illustrated in Figure 1.", "sentence2": "we assess the impact of: 1) encoding tokens with monolingual LM-pretrained Transformers vs. with their massively multilingual counterparts; 2) providing context around the target word in input; 3) including special tokens like [CLS] and [SEP]; 4) averaging across several layers as opposed to a single layer.", "label": "entailment"}
{"id": "test_2592", "sentence1": "Considering the sentence \"John lives in New York\", we observe that the location entity \"New York\" and the context \"John lives in\" are highly correlated but are not causal to each other.", "sentence2": "we can intervene on the location entity to set it to another different location entity without destroying the sentence correctness at the grammatical level.", "label": "entailment"}
{"id": "test_2593", "sentence1": "As there is no currently available dataset to investigate this problem, this paper proposes to conduct randomization test on standard benchmarks.", "sentence2": "we erase name regularity, mention coverage and context diversity respectively from the benchmarks, in order to explore their impact on the generalization ability of models.", "label": "entailment"}
{"id": "test_2594", "sentence1": "Table 1 overviews their discrepancies on name regularity, mention coverage and context pattern acquisition.", "sentence2": "mentions of many entity types do not follow regular compositional structures.", "label": "entailment"}
{"id": "test_2595", "sentence1": "In this paper, we want to shed some light on the impact of the discrepancies between regular and open NER, and provides some valuable insights into the construction of general NER models in a more effective and efficient way.", "sentence2": "we want to answer the following question: Can pretrained supervised neural networks still generalize well on NER when either weaker name regularity, lower mention coverage or inadequate context diversity exists?", "label": "entailment"}
{"id": "test_2596", "sentence1": "To this end, this paper exploits the efficacy of the above three kinds of information by conducting a series of experiments based on randomization test (Edgington and Onghena, 2007;Zhang et al., 2016).", "sentence2": "we design several mention replacing mechanisms, which can erase specific kinds of information on-demand from current NER benchmarks.", "label": "entailment"}
{"id": "test_2597", "sentence1": "The results of our randomization test can serve as a frame of reference for open NER, where the erased information is often truly absent.", "sentence2": "three kinds of information are particularly considered, and four kinds of strategies are used in our randomization test.", "label": "entailment"}
{"id": "test_2598", "sentence1": "Surprisingly, the model performs significantly better in the MP setting than in the NP setting in all entity types.", "sentence2": "high mention coverage undermines the models' ability to generalize to unseen mentions.", "label": "entailment"}
{"id": "test_2599", "sentence1": "The purpose of context reduction is to reduce context diversity in training data but still keeps all name regularity in the vanilla setting.", "sentence2": "cR only keeps a subset of sentences in the vanilla training data, and then duplicates preserved sentences and randomly replace mentions in them with mentions of the same type in the vanilla training data.", "label": "entailment"}
{"id": "test_2600", "sentence1": "Because currently no suitable dataset is available for verifying our conclusions, this paper constructs a new dataset from Wikipedia.", "sentence2": "we consider four entity types in our experiments, including movie, song, book and tv series.", "label": "entailment"}
{"id": "test_2601", "sentence1": "We use the BERT-CRF tagger as our baseline.", "sentence2": "a Transformer (Vaswani et al., 2017) is used as the encoder and then two dense layers are used to map the hidden representation into the label space.", "label": "entailment"}
{"id": "test_2602", "sentence1": "For each entity, we define an initial embedding (at t 0 ) on each manifold and a velocity vector residing in the tangent space of the initial embedding to generate a temporal representation at each timestamp.", "sentence2": "the initial embeddings represent the stationary structural dependencies across facts, while the velocity vectors capture the time-varying properties of entities.", "label": "entailment"}
{"id": "test_2603", "sentence1": "Thus, we treat the curvature of each component and the dimension as hyperparameters selected a priori.", "sentence2": "we use the parallelogram law' deviation  to estimate both the graph curvature of a given temporal KG and the number of components.", "label": "entailment"}
{"id": "test_2604", "sentence1": "The number of interactions between the selected entities are depicted in Figure 8 and 9, which evolves over time.", "sentence2": "we highlight Nigerian citizens, the Nigerian government, head of the Nigerian government, other authorities in Nigeria, and Nigerian minister in the first row of subplots.", "label": "entailment"}
{"id": "test_2605", "sentence1": "To assess the contribution of the dynamic part of entity embeddings, we remove the dynamic part and run the model variant on static knowledge graphs.", "sentence2": "we compress ICEWS05-15 into a static, cumulative graph by ignoring the time information.", "label": "entailment"}
{"id": "test_2606", "sentence1": "Obviously answers contain numerous cues for subsequent dialog flow, but in this first work we focus on meaning prediction.", "sentence2": "given a question-answer pair, we classify it into one of the meaning categories in Tables 7 and 8.", "label": "entailment"}
{"id": "test_2607", "sentence1": "Our experiments show that POWERTRANSFORMER performs better than the baselines overall.", "sentence2": "while the BST revisions obtain slightly higher accuracy on the output agency levels, these revisions have the both the lowest diversity and meaning preservation, suggesting the model ignores the input (Table 4).", "label": "entailment"}
{"id": "test_2608", "sentence1": "We train the top-performing discourse parser by Wang et al. (2017) on MEGA-DT and compare its performance with the same parser trained on previously proposed treebanks.", "sentence2": "we compare our discourse-annotated dataset against a smaller \"silver-standard\" treebank (Huber and Carenini, 2019) containing around ~100,000 documents with <=20 EDUs and two standard human annotated corpora in the news domain (RST-DT) (Carlson et al., 2002) and in the instructional domain (Subba and Di Eugenio, 2009).", "label": "entailment"}
{"id": "test_2609", "sentence1": "In this paper, we propose a new strategy to enable the existing debiasing methods to be applicable in settings where there is minimum prior information about the biases.", "sentence2": "models should automatically identify potentially biased examples without being pinpointed at a specific bias in advance.", "label": "entailment"}
{"id": "test_2610", "sentence1": "Our goal is to obtain a fair comparison without the confounds that may result in performance differences on these two sets.", "sentence2": "the examples from the two sets should be similar except for the presence of a feature that is biased in one set and anti-biased in the other.", "label": "entailment"}
{"id": "test_2611", "sentence1": "As expected, the models show the tendency of relying on biases after only seeing a small fraction of the dataset.", "sentence2": "at an early point during training, models achieve 100% accuracy on the biased test and drop to almost 0% on the anti-biased test.", "label": "entailment"}
{"id": "test_2612", "sentence1": "We question whether this behavior persists once we set a closer to 0.", "sentence2": "do models fall back to the baseline performance when the loss gets more equivalent to the standard cross-entropy at the end of the training?", "label": "entailment"}
{"id": "test_2613", "sentence1": "We are, therefore, interested in characterizing these changes by analyzing their training loss curve.", "sentence2": "we examine the individual losses on each training batch and measure their variability using percentiles (i.e., 0th, 25th, 50th, 75th, and 100th percentile).", "label": "entailment"}
{"id": "test_2614", "sentence1": "Instead, our analysis reveals that this behavior is caused by subtle artifacts arising from the translation process itself.", "sentence2": "we show that translating different parts of each instance separately (e.g., the premise and the hypothesis in NLI) can alter superficial patterns in the data (e.g., the degree of lexical overlap between them), which severely affects the generalization ability of current models.", "label": "entailment"}
{"id": "test_2615", "sentence1": "In both cases, we expand the initial set of 100 labeled examples with another set of 100 instances, selected at random from the remaining data, which are all added to L with a negative label.", "sentence2": "the low prior of the positive class naturally implies high prior of the negative class, enabling to expand the fully labeled 100 instances with an additional set of 100 instances that are -weakly -labeled as negative examples (without the need for additional annotation budget).", "label": "entailment"}
{"id": "test_2616", "sentence1": "Neural networks that are specifically designed to work in conjunction with certain AI accelerators will encounter a similar trade-off.", "sentence2": "the more a neural network is tuned for efficiency, the less flexibility for change the model will have (Han et al., 2015).", "label": "entailment"}
{"id": "test_2617", "sentence1": "For the Seq2seq-LSTM models (Cho et al., 2014; Sutskever et al., 2014), we slightly modified the code by Luong et al. (2017), and we ran it on the two benchmarks provided in the repository.", "sentence2": "we used WMT datasets to train German-English and English-German models.", "label": "entailment"}
{"id": "test_2618", "sentence1": "Note, however, that the OPU would run into some of the same problems that the TPU has.", "sentence2": "there will be a large delay when loading the matrix weights from the memory onto the OPU.", "label": "entailment"}
{"id": "test_2619", "sentence1": "In addition to the evaluations described above, where all utterances are randomly assigned to train, development, and test sets, we do speakerindependent evaluation of the speech+text model.", "sentence2": "we hold out a single speaker for testing and use all the other speakers for training and development.", "label": "entailment"}
{"id": "test_2620", "sentence1": "However, for tasks involving complex reasoning and induction it remains beneficial to provide mod\u0002els with externally linked knowledge (Mitra et al., 2019; Fan et al., 2019).", "sentence2": "for dialog modeling, the Wizard of Wikipedia (Dinan et al., 2019) and Topical Chat (Gopalakrishnan et al., 2019) corpora consist of grounding documents linked with open-domain chit-chat.", "label": "entailment"}
{"id": "test_2621", "sentence1": "The research on TE dates back more than two decades and has made significant progress.", "sentence2": "with the advances of deep neural networks and the availability of large-scale human annotated datasets, fine-tuned systems often claim surpassing human performance on certain benchmarks.", "label": "entailment"}
{"id": "test_2622", "sentence1": "As an example, we apply it on the boolean subset of the dataset by Richardson et al. (2020) containing samples with \u201cboolean and\u201d and find that our model achieves a near perfect accuracy on their test set.", "sentence2": "roBErTa, trained on only MNLI, achieves a low accuracy of 41.5% on the test set, but on applying IAFT with an equal mix of MNLI and their training data in every epoch, the test accuracy improves to 99.8%, while also retaining MNLI matched/mismatched results at 86.45/86.46%.", "label": "entailment"}
{"id": "test_2623", "sentence1": "Unsurprisingly, all models perform significantly better on the boolean subset compared to the non-boolean one.", "sentence2": "the accuracies for RoBERTa, IAFT and PA on the boolean subset are 68%, 72% and 69% respectively, while on the non-boolean subset, these are 58%, 61% and 58% respectively.", "label": "entailment"}
{"id": "test_2624", "sentence1": "While the OWA is beneficial because it helps us assess KGE calibration under more realistic conditions, it is also challenging because it significantly changes the requirements for evaluation.", "sentence2": "now we need a label for every triple considered, whereas with the CWA we only needed labels for a small group of positives.", "label": "entailment"}
{"id": "test_2625", "sentence1": "In this paper, we propose a novel framework, META, which goes beyond the existing paradigm and leverages metadata as an additional source of weak supervision.", "sentence2": "we organize the text data and metadata together into a text-rich network and adopt network motifs to capture appropriate combinations of metadata.", "label": "entailment"}
{"id": "test_2626", "sentence1": "We use the official TempEval-3 scoring script and report the standard metrics.", "sentence2": "we report the detection precision, recall and F1 with the relaxed and strict metrics.", "label": "entailment"}
{"id": "test_2627", "sentence1": "To achieve the set goals, we started with a review of previous arguments about the criteria for identifying appropriate utterances in dialogues and designed our scoring function that is consistent with reflects as much of the community's consensus as possible.", "sentence2": "the proposed scoring method estimates the quality of utterance pairs based on the following two aspects: (i) the connectivity between source and target utterances and (ii) their content relatedness (Section 4).", "label": "entailment"}
{"id": "test_2628", "sentence1": "We automatically obtained dialogue paired-data from the corpus which does not contain speaker annotations on the dialogue turns following the previous methods (Vinyals and Le, 2015; Li et al., 2016).", "sentence2": "we extracted the consecutive two lines as an utterance pair based on the assumption that each line corresponds to a full-speaker's turn.", "label": "entailment"}
{"id": "test_2629", "sentence1": "In the RL setting, we use DQN to train the policy.", "sentence2": "the DQN contains three layers of multilayer perceptron (MLP).", "label": "entailment"}
{"id": "test_2630", "sentence1": "The remaining computation cost from RL framework is comparably small during both the training and the prediction process.", "sentence2": "during our experiments, we trained a three-layer deep neural network model, which has much fewer parameters compared to the information extraction system.", "label": "entailment"}
{"id": "test_2631", "sentence1": "Method Since the state defined in our framework is from a continuous space, we adopt a deep Q-network (DQN) to approximate Q(s, a) with a deep neural network denoted by Q(s, a; \u03b8).", "sentence2": "we parameterize an approximate value function Q(s, a; \u03b8) using a three-layer deep neural network.", "label": "entailment"}
{"id": "test_2632", "sentence1": "In contrast to the single-instance evaluation, examining each generated path independently from others, we propose now to look at the generated graph as a whole and compare it to the ground truth one (based on our weakly-supervised dataset).", "sentence2": "given input sentences x A , we generate the corresponding paths x AB and compare them to the ground truth x B .", "label": "entailment"}
{"id": "test_2633", "sentence1": "In the preliminary study, we evaluate our pretrained model's performance on the held-out set of KGTEXT to conduct ablation study over KGPT.", "sentence2": "we investigate 1) which encoding mechanism is better, 2) whether we need copy mechanism or copy supervision.", "label": "entailment"}
{"id": "test_2634", "sentence1": "We conduct human evaluation to assess the factual accuracy of the generated sentences.", "sentence2": "we sample 100 test samples from WebNLG and observe the model's factual consistency with given fact triples.", "label": "entailment"}
{"id": "test_2635", "sentence1": "Quantitative Study We further investigate how much sample complexity KGPT can reduce.", "sentence2": "we specify a BLEU-4 score and vary the training data size to observe how much training samples are required to attain the performance.", "label": "entailment"}
{"id": "test_2636", "sentence1": "To address comprehension-based generation like generative QA, PALM uses the pre-training objectives that are closely related to the downstream tasks.", "sentence2": "it differs from existing generative pre-training methods in that PALM goes beyond the solely autoencoding/autoregressive methods and combines the merits of autoencoding and autoregression in a single framework.", "label": "entailment"}
{"id": "test_2637", "sentence1": "On the other hand, an autoregressive model, such as GPT (Radford, 2018;Radford et al., 2019), is only trained to encode unidirectional context (either forward or backward).", "sentence2": "at each output timestep, a token is sampled from the model's predicted distribution and the sample is fed back into the model to produce a prediction for the next output timestep, and so on.", "label": "entailment"}
{"id": "test_2638", "sentence1": "To close the gap, PALM is carefully designed to autoregressively generate a text sequence by comprehending the given context in a bidirectional autoencoding manner.", "sentence2": "pALM delegates autoencoding-based comprehension to the encoder in Transformer, and autoregressive generation to the Transformer decoder.", "label": "entailment"}
{"id": "test_2639", "sentence1": "To understand the performance of PALM pretraining, we compare generation quality of the pretrained models of PALM and MASS 3 .", "sentence2": "we feed a few sentences from a news article to both pre-trained models, and the models generate a continuation of the input sentences by beam search with a beam of size 5.", "label": "entailment"}
{"id": "test_2640", "sentence1": "In this work, we propose the Contextual Action Language Model (CALM) to alleviate this challenge.", "sentence2": "at each game step we use CALM to generate action candidates, which are fed into a Deep Reinforcement Relevance Network (DRRN) (He et al., 2015) that uses game rewards to learn a value function over these actions.", "label": "entailment"}
{"id": "test_2641", "sentence1": "To mitigate this, we combine two recent effective approaches, adversarial human-and-model-in-theloop data collection (Nie et al., 2020) and adversarial matching (Zellers et al., 2019a), to build a larger, more-challenging, and less-biased dataset.", "sentence2": "50% of the examples in VLEP are directly annotated by humans over two rounds: round one of standard data collection, i.e., crowd-workers perform the annotations with no model feedback, and round two of adversarial data collection, i.e., crowd-workers perform the annotations with the goal of fooling our basic models trained on round one data (thus avoiding obvious biases).", "label": "entailment"}
{"id": "test_2642", "sentence1": "Hence, in order to collect harder and less-biased negatives, we make use of an adversarial collection procedure (see Figure 2), in a human-and-model-inthe-loop process (Nie et al., 2020), where models are used to provide real-time feedback to crowdworkers during data collection.", "sentence2": "each submitted result is sent to the model for evaluation and writers are prompted to rewrite their negative event if our model predicts a much higher probability for the more-likely event (p m ) than the less likely event (p l ), i.e., p m - p l >  \u2206, where \u2206 is a hyperparameter that controls how difficult we want the collected examples to be and is set to 0.1 empirically.", "label": "entailment"}
{"id": "test_2643", "sentence1": "Since labeling questions with decompositions is cumbersome, we take an unsupervised approach to produce sub-questions, also enabling us to leverage millions of questions from the internet.", "sentence2": "we propose an algorithm for One-toN Unsupervised Sequence transduction (ONUS) that learns to map one hard, multi-hop question to many simpler, singlehop sub-questions.", "label": "entailment"}
{"id": "test_2644", "sentence1": "As shown in Table 7, we decompose queries from several other datasets, using our decomposition model trained on only questions in HOTPOTQAand Common Crawl.", "sentence2": "we generate subquestions for (1) questions in ComplexWebQuestions (Talmor and Berant, 2018), which are multihop questions about knowledge-bases, (2) questions in CLEVR (Johnson et al., 2017b), which are multi-hop questions about images, and (3) claims (statements) in fact-verification challenges, FEVER 1.0 (Thorne et al., 2018) and 2.0 (Thorne et al., 2019).", "label": "entailment"}
{"id": "test_2645", "sentence1": "We split VAST such that all examples xi = (di, ti, yi) where di = d, for a particular document d, are in exactly one partition.", "sentence2": "we randomly assign each unique d to one partition of the data.", "label": "entailment"}
{"id": "test_2646", "sentence1": "Due to the linguistic variation in the topic expressions (\u00a73.2), we examine the prevalence of lexically similar topics, LexSimTopics, (e.g., 'taxation policy' vs. 'tax policy') between the training and zero-shot test sets.", "sentence2": "we represent each topic in the zero-shot test set and the training set using pre-trained GloVe (Pennington et al., 2014) word embeddings.", "label": "entailment"}
{"id": "test_2647", "sentence1": "Finally, we investigate the connection between stance and sentiment vocabulary.", "sentence2": "we use the MPQA sentiment lexicon (Wilson et al., 2017) to identify positive and negative sentiment words in texts.", "label": "entailment"}
{"id": "test_2648", "sentence1": "We observe that in the test set, the majority (80%) of pro examples have more positive than negative sentiment words, while only 41% of con examples have more negative than positive sentiment words.", "sentence2": "con stance is often expressed using positive sentiment words but pro stance is rarely expressed using negative sentiment words and therefore there is not a direct mapping between sentiment and stance.", "label": "entailment"}
{"id": "test_2649", "sentence1": "This was done using SUTime library (Chang and Manning, 2012) to tag time terms, which uses a regular expression based approach.", "sentence2": "we focused on times that pinpointed hours within a day such as \"two o'clock\" or \"noon\".", "label": "entailment"}
{"id": "test_2650", "sentence1": "We consider both BERT base and BERT large in our experiments.", "sentence2": "we use an average pooling over BERT context embeddings in the last one or two layers as the sentence embedding which is found to outperform the [CLS] vector.", "label": "entailment"}
{"id": "test_2651", "sentence1": "In addition to semantic similarity, we further study lexical similarity induced by different sentence embeddings.", "sentence2": "we use edit distance as the metric for lexical similarity between a pair of sentences, and focus on the correlations between the sentence similarity and edit distance.", "label": "entailment"}
{"id": "test_2652", "sentence1": "However, it is not evident that gold standard semantic similarity correlates with edit distance.", "sentence2": "it is often the case where the semantics of a sentence can be dramatically changed by modifying a single word.", "label": "entailment"}
{"id": "test_2653", "sentence1": "Training a classifier with the inherently imbalanced data on the maximum likelihood estimation (MLE) leads to biased classification boundaries in favor of majority classes (Khan et al., 2019).", "sentence2": "models play a difficult role in learning with the imbalanced label (i.e., token) distribution (He et al., 2008b).", "label": "entailment"}
{"id": "test_2654", "sentence1": "We generate texts for the evaluation by completing sequences from prefixes.", "sentence2": "we batchify a test set, select the first 50 tokens from each batch as prefixes, and guide models to generate a continuation of 100 tokens from the prefixes.", "label": "entailment"}
{"id": "test_2655", "sentence1": "Capitalized on the topic-level dialogue graph, we propose a new evaluation metric GRADE, which stands for Graph-enhanced Representations for Automatic Dialogue Evaluation.", "sentence2": "gRADE incorporates both coarsegrained utterance-level contextualized representations and fine-grained topic-level graph representations to evaluate dialogue coherence.", "label": "entailment"}
{"id": "test_2656", "sentence1": "As a result, our method can capture more accurate semantic transition information, thus measuring dialogue coherence in a more human-like manner.", "sentence2": "our GRADE consists of two semantic extraction branches.", "label": "entailment"}
{"id": "test_2657", "sentence1": "Since our goal is to predict a coherence score of a response based on a context, we only consider the edges between the context nodes V c and the response nodes V r .", "sentence2": "the edges only exist between each context-topic node V i c and each response-topic node V j r .", "label": "entailment"}
{"id": "test_2658", "sentence1": "We consider both retrievalbased and generation-based dialogue models to obtain diverse responses for metric evaluation so that the performance of the metrics can be assessed comprehensively.", "sentence2": "we first deploy Transformer-Ranker and Transformer-Generator from the ParlAI platform (Miller et al., 2017), where the former is retrieval-based and the latter is generation-based.", "label": "entailment"}
{"id": "test_2659", "sentence1": "It is noteworthy that all Pearson and Spearman correlations of GRADE are statistically significant with p-value < 0.05, and most of them are with p-value < 0.01.", "sentence2": "gRADE achieves a significant Pearson correlation of 0.606 and Spearman correlation of 0.617 for evaluating Transformer-generator on the ConvAI2 dataset, bringing an improvement of 0.411 (Pearson) and 0.417 (Spearman) compared with BLEURT.", "label": "entailment"}
{"id": "test_2660", "sentence1": "A limitation of GRADE is the inconsistency between the training objective (relative ranking) and the expected behavior (absolute scoring).", "sentence2": "the ranking loss we adopted only requires good responses to be ranked higher than bad responses, which is a relatively loose constraint compared with the absolute scoring that humans do.", "label": "entailment"}
{"id": "test_2661", "sentence1": "In this paper, we empirically study the efficiency issue for NMT models.", "sentence2": "we first investigate the effects of weight pruning on advanced Transformer models, showing that 20% parameters can be directly pruned, and by continuously training the sparse networks, we can prune 50% with no performance loss.", "label": "entailment"}
{"id": "test_2662", "sentence1": "Pruning The redundant parameters in neural networks can be pruned according to a certain criterion while the left ones are significant to preserve the accuracy of the model.", "sentence2": "we mask weight connections with low magnitudes in the forward pass and these weights are not updated during optimization.", "label": "entailment"}
{"id": "test_2663", "sentence1": "To solve TORQUE in an end-to-end fashion, the model here takes as input a passage and a question, then looks at every token in the passage and makes a binary classification of whether this token is an answer to the question or not.", "sentence2": "the model has a one-layered perceptron on top of BERT (Devlin et al., 2019) or RoBERTa , and the input to the perceptron layer is the transformers' output corresponding to the token we're looking at.", "label": "entailment"}
{"id": "test_2664", "sentence1": "We modify the deep biaffine attention classifier (Dozat and Manning, 2016) to model these edges.", "sentence2": "we factorize the probability for each labeled edge into the \"arc\" and \"label\" parts, computing both based on the current decoder hidden state and the states of all previous words.", "label": "entailment"}
{"id": "test_2665", "sentence1": "Apart from that, we study discourse (Prasad et al., 2008) relations, which are essential for generating a good sentence with correct meaning.", "sentence2": "we consider 4 common discourse relations (\"Cause\", \"Contrast\", \"Condition\", \"Coordinating\").", "label": "entailment"}
{"id": "test_2666", "sentence1": "We conduct ablation tests to study the contribution of each component to the proposed model.", "sentence2": "we evaluate models with only the node prediction loss (Node Prediction, Section 3.1) and the edge prediction loss (Edge Prediction, Section 3.2), respectively, and further investigate the effect of integrating node and edge information into the next state computation (Section 3.3) by comparing models without and with (Int.)", "label": "entailment"}
{"id": "test_2667", "sentence1": "We further investigate the influence of AMR-structure preservation on the performance of the main text generation task.", "sentence2": "we first force our model to generate a gold sentence in order to calculate the accuracies for node prediction and edge prediction.", "label": "entailment"}
{"id": "test_2668", "sentence1": "An alternative, also considered here, is to share output parameters across words as well as with the input embeddings.", "sentence2": "this involves making the output embedding a function of the input embedding using a shared parameterization across words, E out = g(E in ), as displayed in Figure 1(b).", "label": "entailment"}
{"id": "test_2669", "sentence1": "A key innovation of this proposed model is a novel parameter-gate (p-gate) mechanism that regulates the flow or transfer of the previously learned knowledge to the new task.", "sentence2": "it can selectively use the network parameters (which represent the retained knowledge gained from the previous tasks) to assist the learning of the new task t. Knowledge distillation is also employed in the process to preserve the past knowledge by approximating the network output at the state when task t \u00c3\u00a2\u00cb\u2020\u00e2\u20ac\u2122 1 was learned.", "label": "entailment"}
{"id": "test_2670", "sentence1": "However, the main objective of the current CL techniques is to solve the catastrophic forgetting (CF) problem (McCloskey and Cohen, 1989).", "sentence2": "in learning each new task, the network parameters need to be modified in order to learn the new task.", "label": "entailment"}
{"id": "test_2671", "sentence1": "Unlike traditional gates that regulate the feature information flow through the sequence chain, the goal of the proposed p-gates is to select useful parameters (which represent the learned knowledge from previous tasks) to be transferred to the new task to make it learn better.", "sentence2": "p-gates regulate the knowledge transfer from the past to the present.", "label": "entailment"}
{"id": "test_2672", "sentence1": "OpTok explores an appropriate tokenization for a downstream task.", "sentence2": "opTok explores a tokenization that yields a better score for a downstream task.", "label": "entailment"}
{"id": "test_2673", "sentence1": "As of the summer of 2018, 352,554 tweets were available, and we extracted only tweets with a single sentiment label of positive, negative, or neutral.", "sentence2": "we removed both positive and negative and unrelated to prevent confusion.", "label": "entailment"}
{"id": "test_2674", "sentence1": "Concretely, we obtained a tokenized sentence based on SentencePiece, and then treated the tokenized sentence as an input to the encoder.", "sentence2": "we replaced the unigram language model in OpTok with the Sentence-Piece tokenizer and used one tokenized sentence as an input to the same architecture.", "label": "entailment"}
{"id": "test_2675", "sentence1": "To validate the effect of only tokenization, we trained only the neural unigram language model in OpTok.", "sentence2": "we fixed the neural encoder in OpTok and the downstream model with random initialization.", "label": "entailment"}
{"id": "test_2676", "sentence1": "Inter-modality incongruity information can be represented as a kind of interaction between the features of multi modalities.", "sentence2": "the input tokens will give high attention values to the image regions contradicting them as incongruity is a key character of sarcasm.", "label": "entailment"}
{"id": "test_2677", "sentence1": "The experimental results illustrate that our model achieves the best performance across the baseline models.", "sentence2": "our model obtains a 2.74% improvement in terms of F1 score compared with the state-of-the-art Hierarchical Fusion Model (HFM) proposed by Cai et al.", "label": "entailment"}
{"id": "test_2678", "sentence1": "In the first experiment we compared data augmentation (via generation) to naive data balancing.", "sentence2": "we compared baseline results to: (1) balancing w/o augmentation; (2) augmentation w/o balancing; and (3) balancing-via-augmentation.", "label": "entailment"}
{"id": "test_2679", "sentence1": "For balancing experiments (no. 1 and 3), We used the simplest balancing scheme depicted by naive-OS balancing policy C (B low = B high = |c n |, as defined in Section 3).", "sentence2": "for balancing w/o augmentation (1) we used basic sample-copy over-sampling, and for balancing-viaaugmentation (3) we applied BalaGen (using GPT-2 as generator) to generate additional samples according to policy C. For augmentation w/o balancing (2) we applied BalaGen using Augment-only data policy B -adding a fixed number of generated samples to all classes.", "label": "entailment"}
{"id": "test_2680", "sentence1": "Partial-OS balancing policy (\u03b2low  < 100) appears to be superior for all datasets.", "sentence2": "for CQA\u03b2low = 90, and for SEAQ and ATIS \u03b2low = 80.", "label": "entailment"}
{"id": "test_2681", "sentence1": "We explore the possibility of disentangling the three sub-aspects that are commonly used to characterize summarization: POSITION for choosing sentences by their position, IMPORTANCE for choosing relevant and repeating content across the document, and DIVERSITY for ensuring minimal redundancy between summary sentences (Jung et al., 2019) during the summary generation process.", "sentence2": "we use these three sub-aspects as control codes for conditional training.", "label": "entailment"}
{"id": "test_2682", "sentence1": "We proposed a neural framework for conditional extractive news summarization.", "sentence2": "subaspect functions of importance, diversity and position are used to condition summary generation.", "label": "entailment"}
{"id": "test_2683", "sentence1": "In this study, we propose a novel Temporally Expressive Networks (TEN) to jointly model the temporal feature dependencies and temporal state dependencies (Figure 1 (c)).", "sentence2": "to improve the turn-level state prediction, we exploits hierarchical recurrent networks to capture temporal feature dependencies across dialogue turns.", "label": "entailment"}
{"id": "test_2684", "sentence1": "Factor graphs are powered by a highly efficient algorithm, called the belief propagation or the sum-product algorithm, for computing the marginal distribution.", "sentence2": "the algorithm executes by passing \"messages\" along the edges of the factor graph and the sent message is computed from all incoming messages on its \"upstream\".", "label": "entailment"}
{"id": "test_2685", "sentence1": "In Table 3, we observe that both domain-specific BERT models can reduce greatly the number of false positives made by the baseline BERT.", "sentence2": "159 false positives made by the baseline BERT are fixed by the domain-specific BERT models.", "label": "entailment"}
{"id": "test_2686", "sentence1": "Recently, neural parsers (Vinyals et al., 2015; Dyer et al., 2016; Stern et al., 2017; Kitaev et al., 2019) with\u0002out using any grammar rules significantly outper\u0002form conventional statistical grammar-based ones (Collins, 1997; Sagae and Lavie, 2005; Glaysher and Moldovan, 2006; Song and Kit, 2009), because neural networks, especially recurrent models (e.g, Bi-LSTM), are adept in capturing long range con\u0002textual information, which is essential to modeling the entire sentence.", "sentence2": "a significant boost on the performance of chart-based parsers is ob\u0002served from some recent studies (Kitaev and Klein, 2018; Kitaev et al., 2019; Zhou and Zhao, 2019) that employ advanced text encoders (i.e., Trans\u0002former, BERT, and XLNet), which further demon\u0002strates the usefulness of contexts for parsing.", "label": "entailment"}
{"id": "test_2687", "sentence1": "To address this problem, in this paper, we propose a span attention module to enhance chartbased neural constituency parsing by incorporating appropriate n-grams into span representations.", "sentence2": "for each text span we extract all its substrings that appear in an n-gram lexicon; the span attention uses the normal attention mechanism to weight them with respect to their contributions to predict the constituency label of the span.", "label": "entailment"}
{"id": "test_2688", "sentence1": "Second, compared with span attention without the category mechanism, in which n-grams are weighted together, models with categorical span attention perform better on both F1 and complete match scores with a relatively small increase of parameter numbers (around 1M ).", "sentence2": "for the complete match scores, the span attention with normal attentions does not outperform the baseline models in some cases, whereas the categorical span attention mechanism does in all cases.", "label": "entailment"}
{"id": "test_2689", "sentence1": "In this paper, we proposed span attention to integrate n-gram into span representations to enhance chart-based neural constituency parsing.", "sentence2": "for each text span in an input sentence, we firstly extracted n-grams in that span from an ngram lexicon, and then fed them into the span attention to weight them according to their contribution to the parsing process.", "label": "entailment"}
{"id": "test_2690", "sentence1": "The interpreter is a parameter-free function that executes the editing action produced by the programmer.", "sentence2": "the interpreter first checks if the action is the termination action.", "label": "entailment"}
{"id": "test_2691", "sentence1": "As a stepping stone in this direction, it is important to study the relationship between spoken language (which also includes acoustic information) and free form gestures (which go beyond just a pre-defined dictionary of gesture animations).", "sentence2": "how can we automatically generate human body pose (gestures) from language and acoustic inputs?", "label": "entailment"}
{"id": "test_2692", "sentence1": "Hence, when learning these models, we need to not only be accurate for gesture generation, but also handle coverage of both linguistic and visual distributions (Pelachaud, 2009;Kucherenko et al., 2019).", "sentence2": "we need models that can balance precision and coverage.", "label": "entailment"}
{"id": "test_2693", "sentence1": "It offers data for 25 speakers with diverse gestures and linguistic content (Ahuja et al., 2020;Ginosar et al., 2019).", "sentence2": "it contains 15 talk show hosts, 5 lecturers, 3 YouTubers, and 2 televangelists, providing a total of 251 hours of video clips, with a mean of 10.7 seconds and a standard deviation of 13.5 seconds per clip.", "label": "entailment"}
{"id": "test_2694", "sentence1": "We see a significantly larger preference for our model as compared to S2G and Gesticulator for all four criteria.", "sentence2": "expressivity sees the largest jump, indicating improved coverage in the generated gestures.", "label": "entailment"}
{"id": "test_2695", "sentence1": "This shows that leveraging translation loss to expose various segmentations is more effective than constraining the NMT models to observe limited sets of segmentations.", "sentence2": "aDVSR improves 1.6 BLEU over SR and 3.2 BLEU over BaSE in the Czech to English dataset.", "label": "entailment"}
{"id": "test_2696", "sentence1": "We adopt the CNN which has been very successful in text classification tasks (Kim, 2014;Choi et al., 2019).", "sentence2": "a carefully designed CNN outperforms other architectures in large-scale  (Kim et al., 2019) with relatively small number of parameters.", "label": "entailment"}
{"id": "test_2697", "sentence1": "We apply the multi-task learning by spotting OOC words and text classification tasks as two, related tasks.", "sentence2": "we add the OOC words detection objective to the model that is trained jointly with the text classification for pretraining.", "label": "entailment"}
{"id": "test_2698", "sentence1": "In this paper, we have developed a novel CNNbased pretraining framework to handle large-scale text classification.", "sentence2": "we pretrain the proposed CNN-based model, which simultaneously learns both the OOC words detection and the text classification task on unlabeled corpora.", "label": "entailment"}
{"id": "test_2699", "sentence1": "In practice, regression suffers from annotation inconsistencies.", "sentence2": "the human scores for some documents might be on average higher than for other documents, which easily confuses the regression.", "label": "entailment"}
{"id": "test_2700", "sentence1": "Similarly, averaging different domains also results in significant improvements.", "sentence2": "averaging several non-news domains gives better generalization to the news domain.", "label": "entailment"}
{"id": "test_2701", "sentence1": "This overconfidence does not directly affect classification performance, but it degrades the reliability of the model.", "sentence2": "the output probability of the over-confident model does not indicate how uncertain the input example is, even if its classification performance is high.", "label": "entailment"}
{"id": "test_2702", "sentence1": "As mentioned earlier, BERT and BioBERT could understand the deep contextual information of the text through pre-training with huge corpora.", "sentence2": "biobERT suggested that the pre-training of bERT in a specific domain may contribute to performance improvement in a downstream task of the domain.", "label": "entailment"}
{"id": "test_2703", "sentence1": "As mentioned earlier, the output distribution of the uncalibrated model is biased towards 0 and 1.", "sentence2": "the output of the uncalibrated model has a low entropy value.", "label": "entailment"}
{"id": "test_2704", "sentence1": "Although modern abstractive summarization systems generate relatively fluent summaries, recent work has called attention to the problem they have with factual inconsistency (Kryscinski et al., 2019a).", "sentence2": "they produce summaries that contain hallucinated facts that are not supported by the source text.", "label": "entailment"}
{"id": "test_2705", "sentence1": "While our results are still preliminary, they provide some evidence that subjects consider the upranked summaries to be more faithful.", "sentence2": "of the 19 trials (other than the three catch trials) where all three subjects agreed on which summary was more faithful, in 12 trials, it was the re-ranked summary (as in Table 8, Article 49), while in only 7 was it the original summary (as in Table 8, Article 4).", "label": "entailment"}
{"id": "test_2706", "sentence1": "Graph convolutional networks (GCNs) work on a graph structure and compute representations for the graph nodes by looking at the node's neighbourhood.", "sentence2": "let G = (V, E) denote a directed graph, where V is the set of nodes (let |V | = i) and E is the set of edges.", "label": "entailment"}
{"id": "test_2707", "sentence1": "Event Detection (ED) is an important information extraction task that seeks to recognize events of specific types from given text.", "sentence2": "each event in a sentence is marked by a word or phrase called \"event trigger\".", "label": "entailment"}
{"id": "test_2708", "sentence1": "To model the above ideas, in this paper, we propose a novel neural architecture named Edge-Enhanced Graph Convolutional Networks (EE-GCN), which explicitly takes advantage of the typed dependency labels with dynamic representations.", "sentence2": "ee-GCN transforms a sentence to a graph by treating words and dependency labels as nodes and typed edges, respectively.", "label": "entailment"}
{"id": "test_2709", "sentence1": "A generated sentence is verifiable if it can be corroborated or disproved by Wikipedia, and we find that the verifiability of generated text strongly depends on the decoding strategy.", "sentence2": "we discover a tradeoff between factuality (i.e., the ability of generating Wikipedia corroborated text) and repetitiveness.", "label": "entailment"}
{"id": "test_2710", "sentence1": "In contrast to both BERT and RoBERTa, it makes heavy use of parameter sharing.", "sentence2": "aLBERT ties the weight matrices across all hidden layers effectively applying the same non-linear transformation on every hidden layer.", "label": "entailment"}
{"id": "test_2711", "sentence1": "Instead of sequence labeling, Sequence-to\u0002Sequence (Seq2Seq) models (Cho et al., 2014) are able to extract an entity multiple times, thus multiple relations can be assigned to one entity, which solves the problem naturally (Zeng et al., 2018, 2019a,b; Nayak and Ng, 2019).", "sentence2": "all existing Seq2Seq models pre-define a sequential order for the target triplets, e.g. triplet alphabetical order, and then decode the triplet sequence according to the order autoregressively, which means the current triplet prediction relies on the previous output.", "label": "entailment"}
{"id": "test_2712", "sentence1": "Mono-lingual BERT models (Devlin et al., 2019) have also proven effective in document retrieval (Dai and Callan, 2019;MacAvaney et al., 2019;Li et al., 2020).", "sentence2": "In particular, Akkalyoncu Yilmaz et al. (2019) demonstrated that BERT models fine-tuned with passage-level relevance data can transfer across domains: surprisingly, fine-tuning on social media data is effective for relevance classification on newswire documents without any additional modifications.", "label": "entailment"}
{"id": "test_2713", "sentence1": "For the IWSLT Portuguese to English (Pt-En) dataset, we replicate the setup of Tan et al. (2019) for training individual models.", "sentence2": "the dataset contains about 167k training pairs.", "label": "entailment"}
{"id": "test_2714", "sentence1": "For the IWSLT Pt-En, we use Transformer Small configuration.", "sentence2": "the model hidden-size d model is set to 256, the feedforward hidden size d ff is set to 1024 and the number of layers for the encoder and the decoder was set to 2.", "label": "entailment"}
{"id": "test_2715", "sentence1": "Recently, Chen et al. (2017) proposed multi\u0002criteria Chinese word segmentation (MCCWS) to effectively utilize the heterogeneous resources with different segmentation criteria", "sentence2": "they regard each segmentation criterion as a single  task under the framework of multi-task learning, where a shared layer is used to extract the criteriainvariant features, and a private layer is used to extract the criteria-specific features.", "label": "entailment"}
{"id": "test_2716", "sentence1": "Recently neural network-based models have demonstrated large gains in this space (Hu et al., 2014;Pang et al., 2016).", "sentence2": "the Transformer / BERT family of models (Devlin et al., 2018; Lan et al., 2019;Clark et al., 2020) have set a new bar for these semantic text matching problems.", "label": "entailment"}
{"id": "test_2717", "sentence1": "DiPair aims to combine the best of both worlds: Like dual-encoder models, it leverages common pre-computation, while at the same time modeling the text jointly -with cross-attention -using multiple contextual embeddings for each text.", "sentence2": "we extract a small fraction of the output token embeddings from each text, and then jointly model this smaller \"sequence\" using a transformer head (we use the term head to refer to the component that consumes the outputs of a dual-encoder model, see Figure 2).", "label": "entailment"}
{"id": "test_2718", "sentence1": "Inspired by the idea that POS sequences often reflect the syntactic structure of a language, we propose CURSOR (Cross lingUal paRSing by wOrd Reordering) to overcome the word order difference issue in crosslingual transfer.", "sentence2": "we assume we have a treebank in the source language and annotated POS corpus in the target language 1 .", "label": "entailment"}
{"id": "test_2719", "sentence1": "Figure 2b shows that after reordering S, its similarity to T increases, and the corresponding cross-lingual parsing performance will improve.", "sentence2": "target languages with greater differences to the source one in their word order will benefit more from our reordering method.", "label": "entailment"}
{"id": "test_2720", "sentence1": "All classifiers had significantly reduced F1scores on SEED, due to major drops in threat recall.", "sentence2": "bERT was degenerate, assigning all documents to the majority class in all 30 repetitions.", "label": "entailment"}
{"id": "test_2721", "sentence1": "The RL model is the one trained on related languages from the same family as the TL, and DL is the model that is trained on languages that are more distant from the TL.", "sentence2": "given a TL, the RL model refers to the language family that includes the TL, and the DL model refers to the other family that does not include the TL.", "label": "entailment"}
{"id": "test_2722", "sentence1": "Graph2Graph Transformer extends the architecture of the Transformer to accept any arbitrary graph as input.", "sentence2": "we input the dependency tree as its set of dependency relations.", "label": "entailment"}
{"id": "test_2723", "sentence1": "In this work, the graph edges are labelled dependency relations, which are predicted as part of the actions of a transition-based dependency parser.", "sentence2": "the Relation classifier uses the output embeddings of the top two elements on the stack and predicts the label of their dependency relation, conditioned on its direction.", "label": "entailment"}
{"id": "test_2724", "sentence1": "As the loss function of these two models, we use weighted binary cross entropy.", "sentence2": "given high imbalance with many more irrelevant instances than positive ones, we put different weights on the classes in computing the loss according to the target distributions (proportions of negative examples are 87% for REL and 93% for EXT).", "label": "entailment"}
{"id": "test_2725", "sentence1": "The difference between the two attention mechanism is that the supervised selfattention recognizes word-level prediction scores of all named entities while the task-specific attention recognizes word-level prediction scores w.r.t only selective named entities (one which correspond to the ADE sentence and ignores other named entities).", "sentence2": "the weights of the supervised self-attention and task-specific attention are calculated as follows: Word-level prediction w.r.t the task-specific named entity (i.e.,) ADE: Task-specific Attention Weight, normalized to sum up to 1 over all values in the sentence, is: Supervised Self-Attention Weight, normalized to sum up to 1 over all values in the sentence: shows the examples of the supervised selfattention and task-specific attention distributions generated from our attention layer.", "label": "entailment"}
{"id": "test_2726", "sentence1": "Extension to Multiple Target Language Note that though in this work we focus on HRL and LRL pairs, one can easily extend the framework to multiple (> 2) target languages.", "sentence2": "the only language dependent component of DecSDE is the matrices W L i , while the rest of DecSDE parameters as well as transformer encoder-decoder parameters are shared.", "label": "entailment"}
{"id": "test_2727", "sentence1": "In this paper, we address these shortcomings, and propose an accurate, efficient, polyglot model for Neural RDG parsing.", "sentence2": "our contributions are as follows: Grammar: In practice, RDGs extracted from training graphs can be large and sparse.", "label": "entailment"}
{"id": "test_2728", "sentence1": "CLTS transfers both translated seed words and their learned weights to initialize a \"weak\" classifier in L T that considers translated seed words and their relative importance for the target task.", "sentence2": "cLTS first translates the B seed words in G S into a set G T with seed words in L T .", "label": "entailment"}
{"id": "test_2729", "sentence1": "Instead of using a matrix, holistically, we can quantify the cross-dataset generalization ability of each summarization system using a scalar.", "sentence2": "we propose two views to characterize the crossdataset generalization.", "label": "entailment"}
{"id": "test_2730", "sentence1": "Moreover, the proxy-based annotation mechanisms used to label large social media data sets with mental health status invite the introduction of selfdisclosure bias into the modeling task (Amir et al., 2019).", "sentence2": "labels sourced from populations of individuals who self-disclose certain attributes may contain activity-level and thematic biases that cause poor generalization in larger populations (Lippincott and Carrell, 2018).", "label": "entailment"}
{"id": "test_2731", "sentence1": "To measure this effect, we examine differences in the distribution of subreddits that individuals in the depression group of the Topic-Restricted Text data post in relative to individuals in the control group.", "sentence2": "we fit a logistic regression model mapping the subreddit distribution of individuals' posts to their mental health status after applying each subreddit filter list (e.g. RSDD, SMHD, Ours).", "label": "entailment"}
{"id": "test_2732", "sentence1": "How far do MLMs look when leveraging context?", "sentence2": "what are their effective context window sizes?", "label": "entailment"}
{"id": "test_2733", "sentence1": "Our second approach estimates the impact of an input subword s ij to P (w t |X \\t ) by using derivatives.", "sentence2": "we adapt the IMPACT score proposed in Falenska and Kuhn (2019) to our questions.", "label": "entailment"}
{"id": "test_2734", "sentence1": "To further compare the behaviors of BERT and BiLSTM when identifying essential context, we count the occurrence of dependency paths based on the disjoint essential words.", "sentence2": "given an input sentence, we only count the dependency paths of essential words which are unique to each model, e.g., words essential to BERT but not essential to BiLSTM.", "label": "entailment"}
{"id": "test_2735", "sentence1": "This implies that sometimes words of common dependency paths can be identified by BERT as essential while BiL-STM fails to do so and sometimes it's another way around.", "sentence2": "there is a room to make models to be more consistently aware of syntactic structures of an input.", "label": "entailment"}
{"id": "test_2736", "sentence1": "FVN extends the Vector-Quantised VAE (VQ-VAE) (van den Oord et al., 2017), which is non-conditional, to allow conditioning on attributes (content and style).", "sentence2": "fVN: (1) models two disjoint codebooks for content and style respectively that memorize input text variations; (2) further controls the conveyance of at\u0002tributes by using content and style specific encoders and decoders; (3) computes disjoint latent space distributions that are conditional on the content and style respectively, which allows to sample la\u0002tent representations in a focused way at prediction time", "label": "entailment"}
{"id": "test_2737", "sentence1": "We found that our FVN model performs better than the ground truth on agreeable and conscientiousness, while the ground truth is better for the rest of the three personalities.", "sentence2": "53% and 67% of the time, the crowdworkers judge the agreeable and conscientious sentences generated by our model to be better than the ground truth sentences.", "label": "entailment"}
{"id": "test_2738", "sentence1": "In this paper, we address the above issues by proposing a novel supervised multi-modal domain adaptation method for VQA to learn joint feature embeddings across different domains and modalities.", "sentence2": "we align the data distributions of the source and target domains by considering those modalities both jointly and separately.", "label": "entailment"}
{"id": "test_2739", "sentence1": "If both triggers were deemed valid, then the annotators evaluated whether or not the candidate precondition event was an actual precondition for the target event.", "sentence2": "they check if the candidate event is necessary for the target event to happen.", "label": "entailment"}
{"id": "test_2740", "sentence1": "Rules and guidelines were put into place to help ensure that instructions written by the Stage 1 workers were high quality and written with as few errors as possible.", "sentence2": "the guidelines serve to prevent the workers from using other elements of the UI or tools we provided, such as the blue navigation line or guiding arrow (see Figure 15) and other elements that were not part of the true environment in  their instructions.", "label": "entailment"}
{"id": "test_2741", "sentence1": "Our intuition is that by employing a generative adversarial model to produce challenging negative code snippets during training, the code retrieval model will be strengthened to distinguish between positive and negative q, c pairs.", "sentence2": "we adapt a generative adversarial sampling technique , whose effectiveness has been shown in a wide range of uni-modal text retrieval tasks.", "label": "entailment"}
{"id": "test_2742", "sentence1": "We use Stack Exchange Data Explorer 3 to collect data for training and evaluating QD relevance prediction.", "sentence2": "we collect the question pairs from posts that are manually labeled as duplicate by users, which are related by LinkTypeId=3.", "label": "entailment"}
{"id": "test_2743", "sentence1": "In line with previous work on news SD (Vlachos and Riedel, 2014; Ferreira and Vlachos, 2016), in which data was labeled by professional journalists, we rely on domain experts for annotation.", "sentence2": "we provided articles to eight economists 3 in batches and asked them to annotate no more than 100 articles per day 4 ; the annotation process lasted 4 months.", "label": "entailment"}
{"id": "test_2744", "sentence1": "This label should be chosen if the article is supporting the theory that the merger is happening.", "sentence2": "after reading the article the reader feels more confident that the two companies will merge.", "label": "entailment"}
{"id": "test_2745", "sentence1": "This label should be chosen if the article is refuting the theory that the merger is happening.", "sentence2": "after reading the article the reader feels less confident that the two companies will merge.", "label": "entailment"}
{"id": "test_2746", "sentence1": "On the TAC-2009 generic summarization task in Table 3 our Sup-MMD + MKL model outperforms the state-of-theart ICSI model on both ROUGE-2 and ROUGE-SU4.", "sentence2": "supMMD + MKL scores 12.33 in ROUGE-2 while the best ICsI variant scores 12.16 in ROUGE-2.", "label": "entailment"}
{"id": "test_2747", "sentence1": "In this paper, we propose a sequence labeling based neural model to enhance NER by incorporating different types of syntactic information, which is conducted by attentive ensemble with key-value memory networks (KVMN) (Miller et al., 2016), syntax attention and the gate mechanism.", "sentence2": "the KVMN is applied to encode the context features and their syntax information from different types, e.g., POS labels, syntactic constituents, or dependency relations; syntax attention is proposed to weight different types of such syntactic information, and the gate mechanism controls the contribution of the results from the context encoding and the syntax attention to the NER process.", "label": "entailment"}
{"id": "test_2748", "sentence1": "For the text input, we use three types of embeddings for each language by default.", "sentence2": "for English, we use Glove (100dimension)6 (Pennington et al., 2014), ELMo (Peters et al., 2018), and the BERT-cased large7 (Devlin et al., 2019) (the derived embeddings for each word); for Chinese, we use pre-trained character and bi-gram embeddings8 released by  released by Zhang and Yang (2018) (denoted as Giga), Tencent Embed\u0002ding9 (Song et al., 2018b), and ZEN10 (Diao et al., 2019). ", "label": "entailment"}
{"id": "test_2749", "sentence1": "It is confirmed that different types of embedding do provide complement context information to enhance the understanding of input texts for NER.", "sentence2": "although contextualized embeddings (i.e., ELMo, BERT, and ZEN) show significantly better performance than others (especially on Chinese), combining them with static embeddings still provide further improvement on the F 1 score of NER systems.", "label": "entailment"}
{"id": "test_2750", "sentence1": "In this paper, we proposed a neural model following the sequence labeling paradigm to enhance NER through attentive ensemble of syntactic information.", "sentence2": "the attentive ensemble consists of three components in a sequence: each type of syntactic information is encoded by key-value memory networks, different information types are then weighted in syntax attention, and the gate mechanism is finally applied to control the contribution of syntax attention outputs to NER for different contexts.", "label": "entailment"}
{"id": "test_2751", "sentence1": "the full model with attentive ensemble of all syntactic information) on the test set of all three Chinese datasets.", "sentence2": "either BERT or ZEN is used as one of the three types of embeddings (the others are Giga and Tencent Embedding).", "label": "entailment"}
{"id": "test_2752", "sentence1": "Consequently, in this work, we propose to regulate the hidden vectors of the graph-based models for ABSA using the information from the aspect terms, thereby filtering the irrelevant information for the terms and customizing the representation vectors for ABSA.", "sentence2": "we compute a gate vector for each layer of the graph-based model for ABSA leveraging the representation vectors of the aspect terms.", "label": "entailment"}
{"id": "test_2753", "sentence1": "The second limitation of the current graph-based deep learning models is the failure to explicitly exploit the overall importance of the words in the sentences that can be estimated from the dependency trees for the ABSA problem.", "sentence2": "a motivation of the graph-based models for ABSA is that the neighbor words of the aspect terms in the dependency trees would be more important for the sentiment of the terms than the other words in the sentence.", "label": "entailment"}
{"id": "test_2754", "sentence1": "Consequently, we propose to inject the knowledge from these syntaxbased importance scores into the graph-based models for ABSA via the consistency with the modelbased importance scores.", "sentence2": "using the representation vectors from the graph-based models, we compute a second score for each word in the sentences to reflect the model's perspective on the importance of the word for the sentiment of the aspect terms.", "label": "entailment"}
{"id": "test_2755", "sentence1": "Our focus on contextual constraints is in part motivated by studies that use sentence contexts of varying constraint to study priming in humans.", "sentence2": "schwanenflugel and LaCount (1988) found low-constraint contexts to show wider scope of facilitation in lexical decision tasks, as compared to high-constraint ones, which only showed facilitations for the best completions (highest cloze probability).", "label": "entailment"}
{"id": "test_2756", "sentence1": "Thus, for the purposes of this study, we cast events as the premise and the relation targets as the defeasible hypotheses.", "sentence2": "we extract a total of 24K event (premise) and relation target (hypothesis) pairs.", "label": "entailment"}
{"id": "test_2757", "sentence1": "For example, a norm like \"It is good to respect your parents\" might be weakened in certain contexts (e.g., \"Your parents are abusive and hurtful towards you\") and strengthened in others (e.g., \"Your parents want what's right for you\").", "sentence2": "we consider this set of norms of social behavior as hypotheses capable of being strengthened or weakened.", "label": "entailment"}
{"id": "test_2758", "sentence1": "Elicitation as a method of text data collection has a number of known flaws.", "sentence2": "(1) annotators may use label-dependent heuristics or strategies to produce sentences that introduce superficial correlations between text features and labels (Poliak et al., 2018;Gururangan et al., 2018;Tsuchiya, 2018); (2) elicitation may result in repeated responses of salient answers that are a small subset of all possible valid answers (McRae et al., 2005); and (3) elicited responses may contain implicit judgments or stereotypic associations about gender, race, and age, among others .", "label": "entailment"}
{"id": "test_2759", "sentence1": "A GENERALIZATION is a statement that speaks of a socially normative behavior.", "sentence2": "it is a generalizing statement about how we expect people to behave in society.", "label": "entailment"}
{"id": "test_2760", "sentence1": "The norm of the vectors of the hyperbolic model are measured according to the hyperbolic distance d D (see Equation 1).", "sentence2": "we take the hyperbolic distance from the origin to the point, thus the values are above one.", "label": "entailment"}
{"id": "test_2761", "sentence1": "Our model achieves better accuracy than the three models described in Section 3.2, although the accuracy is lower than with human performance.", "sentence2": "our model out\u0002performs TSEL-REF and TSEL-REF-DIAL, which use additional learning, with learning only from standard training data. This result demonstrates the advantages and the high learning efficiency of our architecture", "label": "entailment"}
{"id": "test_2762", "sentence1": "To address this problem, we study automated techniques to improve datasets for training and testing.", "sentence2": "we focus on paraphrase identification task, which aims to determine whether two given sentences are semantically equivalent.", "label": "entailment"}
{"id": "test_2763", "sentence1": "Moving from single labeled sentence pairs to a graph provides a better understanding of the sentence relations of the dataset, which can be exploited to infer additional edge labels.", "sentence2": "since paraphrases are an equality relation, we can perform a transitive closure on the graph to infer additional labels.", "label": "entailment"}
{"id": "test_2764", "sentence1": "Identifying such mention pairs, detected as actually being used to refer to the same event, can provide a strong signal for identifying these predicates as paraphrastic (vs. the quite noisy corpus-level signal of distributional similarity).", "sentence2": "we utilize the Chirps paraphrase acquisition method and resource, which follows this approach as described next in some detail.", "label": "entailment"}
{"id": "test_2765", "sentence1": "While the original Chirps method did not utilize the content of the linked article, we find it useful to retrieve more information about the event.", "sentence2": "it might help mitigating errors in Chirps' argument matching mechanism, which relies on argument alignment considering only the text of the two tweets.", "label": "entailment"}
{"id": "test_2766", "sentence1": "We consider the ranking evaluation as more informative, as we expect the ranking to reflect the number of contexts in which a pair of predicates may be coreferring.", "sentence2": "predicate pairs that are coreferring in many contexts will be ranked higher than those that are coreferring in just a few contexts.", "label": "entailment"}
{"id": "test_2767", "sentence1": "For our evaluation, we present the first multidomain, executable semantic parsing dataset in three languages and an additional locale for a single-domain dataset.", "sentence2": "we extend ATIS (Dahl et al., 1994), pairing Chinese (ZH) utterances from Susanto and Lu (2017a) to SQL queries and create a parallel German (DE) humantranslation of the full dataset.", "label": "entailment"}
{"id": "test_2768", "sentence1": "In this work, we aim at addressing the fewshot challenge and improving relation reasoning performance.", "sentence2": "we propose a novel model called FIRE for few-shot multi-hop relation learning over KB.", "label": "entailment"}
{"id": "test_2769", "sentence1": "Note that we do not assume a vocabulary.", "sentence2": "we do not distinguish words from arbitrary strings made out of the alphabet.", "label": "entailment"}
{"id": "test_2770", "sentence1": "Even with that, PBoS is able to achieve the best POS tagging accuracy in all but one language regardless of morphological types, OOV rates, and the number of training instances (Appendix Table 12).", "sentence2": "pBoS improvement accuracy by greater than 0.1 for 9 languages.", "label": "entailment"}
{"id": "test_2771", "sentence1": "Figure 1 depicts the general process of our method, where the target task needs to additionally recognize job titles, which are annotated as the Other (O) class in the source task.", "sentence2": "for the job title type, an entity lexicon of the type is collected.", "label": "entailment"}
{"id": "test_2772", "sentence1": "We apply the normal multi-label assignment mechanism for performing T t , instead of the prevalent BIO or BIOES mechanism.", "sentence2": "the constituted words of a mention of the entity type e i are all classified to class i without distinction of their positions in the mention.", "label": "entailment"}
{"id": "test_2773", "sentence1": "We follow this technique in our method.", "sentence2": "we use the trained classifier to perform label prediction for words of D t u .", "label": "entailment"}
{"id": "test_2774", "sentence1": "For these methods, we combined their recognition result with that of SourceBERT to perform entity recognition.", "sentence2": "for a query sentence, we first perform label inference using SourceBERT and then apply these methods to words being predicted to be the \"O\" class by SourceBERT to further identity mentions of the new entity types.", "label": "entailment"}
{"id": "test_2775", "sentence1": "We are taking into account the average ranking to make such comparison clearer, with the assumption that all metrics have the same weight.", "sentence2": "since there are three different evaluation metrics, i.e., STAcc, BLEU, and Perplexity, and seven different methods (the two proposed seq2seq and five from the literature), the methods are ranked from 1 to 7 in each metric, where 1 is the best and 7 is the worst.", "label": "entailment"}
{"id": "test_2776", "sentence1": "The model is fine-tuned to produce the tokens \"true\" or \"false\" depending on whether the document is relevant or not to the query.", "sentence2": "\"true\" and \"false\" are the target tokens (i.e., ground truth predictions in the sequence-to-sequence transformation).", "label": "entailment"}
{"id": "test_2777", "sentence1": "Note that results from our T5 models have lower proportions of judged documents in the top-20 (Jdg@20) than BM25 and BM25+RM3.", "sentence2": "our models are retrieving documents that have never been evaluated, for which we have no relevance labels.", "label": "entailment"}
{"id": "test_2778", "sentence1": "Why is our approach more data-efficient than BERT?", "sentence2": "why does T5 significantly outperform BERT when fine-tuned with far fewer training examples?", "label": "entailment"}
{"id": "test_2779", "sentence1": "Embedded in that neural machinery is latent knowledge about semantics, linguistic relations, and lexical features that are necessary to generate fluent text.", "sentence2": "t5 has access to an additional source of knowledge that BERt does not.", "label": "entailment"}
{"id": "test_2780", "sentence1": "In contrast, in a low-data setting, T5 can \"fall back\" on pretrained neural machinery for generating fluent textual output.", "sentence2": "the pretraining objective in T5 seems to transfer well to generating relevance labels.", "label": "entailment"}
{"id": "test_2781", "sentence1": "As a whole, OTE-MTL surpasses all its variants.", "sentence2": "oTE-MTL is slightly better than oTE-MTL-Inter, however, oTE-MTL exceeds other variants by large margins.", "label": "entailment"}
{"id": "test_2782", "sentence1": "In doing so, we expect to alleviate issues brought by the unified tagging scheme.", "sentence2": "we exploit sequence tagging strategies (Lample et al., 2016) for extraction of aspects and opinions, whilst taking advantage of a biaffine scorer (Dozat and Manning, 2017) to obtain word-level sentiment dependencies.", "label": "entailment"}
{"id": "test_2783", "sentence1": "To alleviate the above problem, we propose AirConcierge, an end-to-end trainable text-to-SQL guided framework to learn a neural agent that interacts with KBs using the generated SQL queries.", "sentence2": "the neural agent first learns to ask and confirm the customer's intent during the multi-turn interactions, then dynamically determining when to ground the user constraints into executable SQL queries so as to fetch relevant information from KBs.", "label": "entailment"}
{"id": "test_2784", "sentence1": "However, such symbolic operations break the differentiability of the system and prevent end-to-end training of neural dialogue agents.", "sentence2": "it is unclear if end-to-end models can completely replace and perform better than pipeline methods in a task-directed setting.", "label": "entailment"}
{"id": "test_2785", "sentence1": "Besides, during the dialogue with a user, AirConcierge actively prompts and guides the user for key information, and responds with informative and humancomprehensible sentences based on the retrieved results from the KBs.", "sentence2": "the \"dialogueto-SQL-to-dialogue\" approach, which we implement in AirConcierge allows it to integrate with large-scale, real-world KBs.", "label": "entailment"}
{"id": "test_2786", "sentence1": "We treat insertion as the inversion of deletion.", "sentence2": "we produce the source graph x via a DELETE operation on G, where the target graph z is set to G. Like the deletion operator, the insertion query y is generated by either the MTurk workers, or by templates.", "label": "entailment"}
{"id": "test_2787", "sentence1": "We refer to this gating mechanism as late fusion since it does not let the information from the graph and text interact in their respective lower level encoders.", "sentence2": "the fusion happens after the contextualized information has already been learned.", "label": "entailment"}
{"id": "test_2788", "sentence1": "Recall that the parameters of the graph and query encoders are shared to enable encoding of the two sources in the same semantic space.", "sentence2": "we use the same transformer encoder for both sources.", "label": "entailment"}
{"id": "test_2789", "sentence1": "However, the decision for such a structured system has the consequence that there are aspects of narratological theory which are not clearly reflected in our annotation.", "sentence2": "we decided to handle thought representation parallel to speech representation, treating thought essentially as 'silent speech'.", "label": "entailment"}
{"id": "test_2790", "sentence1": "In fact, many of these repositories can be useful to the community not only for the automatic creation of textual corpora but also for retrieving crucial meta-information about texts.", "sentence2": "the use of metadata provides the reader with a wealth of information that is often not identifiable in the texts themselves.", "label": "entailment"}
{"id": "test_2791", "sentence1": "In fact, many of these repositories can be useful to the community not only for the automatic creation of textual corpora but also for retrieving crucial meta-information about texts.", "sentence2": "the use of meta-information provides the reader with a wealth of information that is often not identifiable in the texts themselves.", "label": "entailment"}
{"id": "test_2792", "sentence1": "Built on the DHTK library (Picca and Egloff, 2017), WeDH is written in Python and proposes similar objectives which are detailed in section 3..", "sentence2": "dHTK's main purpose is to provide the human scientist with a tool that leverages on the main semantic repositories as dBpedia (Auer et al., 2007) to complete annotation and search for metadata (e.g., the year of the first edition, main characters, book categories, etc.).", "label": "entailment"}
{"id": "test_2793", "sentence1": "The user interface is constantly improving and some features are already planned.", "sentence2": "the option to select specific metadata for download as well as the option to download texts in TEI format, are already in production.", "label": "entailment"}
{"id": "test_2794", "sentence1": "At the same time, existing corpora with quotation annotation vary greatly in whether, how, and to what extent they cover the interpersonal structure (i.e., who communicates what to whom -see Section 2. for details).", "sentence2": "we are not aware of any large-scale, publicly available corpora which mark both speakers and addressees for quotations in literary text.", "label": "entailment"}
{"id": "test_2795", "sentence1": "Note that cues are not necessary for speech events.", "sentence2": "literary renderings of dialogue can omit cues and just let quotations stand: \"How are you?\"", "label": "entailment"}
{"id": "test_2796", "sentence1": "VGG consists of 99 texts for a total of more than 22,000 pages that were written in Italian during the period of the First World War or shortly afterwards.", "sentence2": "they go from 1914 up to 1923, in order to cover not only the years of the war, but also the cultural and social environment leading to the war and the aftermath of the Great War.", "label": "entailment"}
{"id": "test_2797", "sentence1": "EXTra includes various parameters that allow users to optimize the extracted terms with respect to the target corpus and domain.", "sentence2": "users can specify the set of structured patterns that guide the extraction process, a list of stopwords, the association measure to be used by the weighting algorithm (in VGG, local mutual information, LMI), as well as the thresholds for the association measure and the n-gram frequency.", "label": "entailment"}
{"id": "test_2798", "sentence1": "While they shed much light on the complex issue of translated literature, the method of stylometry by most frequent words does not allow direct comparison of original texts and their translations.", "sentence2": "an attempt to hang, say, novels in English and their multiple translations from the same cluster analysis tree would produce the trivial effect of separating the texts by the two languages, and little more.", "label": "entailment"}
{"id": "test_2799", "sentence1": "We replaced the form and lemma in the CoNLL-U document with the first match in the CS column.", "sentence2": "each occurrence of quotes, question mark, and \ufffdb\ufffdt\ufffd in a Czech CoNLL-U file was replaced with pseudolemma L00009, L00010, and L00011, respectively.", "label": "entailment"}
{"id": "test_2800", "sentence1": "While most prior work extended proposition types based on the needs of the task at hand, our taxonomy has been motivated mainly by argumentation theory.", "sentence2": "the argumentation schemes of Walton et al. (2008) are a set of reasoning types commonly used in daily life.", "label": "entailment"}
{"id": "test_2801", "sentence1": "This requires researchers to make a trade-off between, on one hand, the expressiveness and fidelity of the linguistic construct they are attempting to capture, and on the other the potential for operationalization and quantification in coding manuals and fully automated systems.", "sentence2": "in imbalanced tasks, these choices can have the effect of producing an inaccurate picture of the minority class and producing datasets that are no longer a valid representation of the original construct (Corbett-Davies and Goel, 2018).", "label": "entailment"}
{"id": "test_2802", "sentence1": "When compared to Trump, the Democratic candidates make much greater use of normative language.", "sentence2": "language from the two Democratic candidates uses normative propositions and expresses desires a lot more than Trump, often to make the case for specific policies based on normative values.", "label": "entailment"}
{"id": "test_2803", "sentence1": "We also explored a simpler binary version of our classification task (Row 2), which reduced the class skew while still making a pedagogically useful distinction.", "sentence2": "during discussions with teachers where we visualized the collaboration annotations in the corpus that came from their particular classrooms, we found that teachers were very curious about whether students were introducing new information into the discussion or building off of what was previously said.", "label": "entailment"}
{"id": "test_2804", "sentence1": "New in the 2.2 version of the corpus are two additional annotation layers for coherence relations following the Penn Discourse TreeBank framework.", "sentence2": "we add relation senses to an already existing layer of discourse connectives and their arguments, and we introduce a new layer with additional coherence relation types, resulting in a German corpus that mirrors the annotation scheme of the PDTB (which is a much larger corpus, though).", "label": "entailment"}
{"id": "test_2805", "sentence1": "Experiments are performed in different languages, such as English, Dutch, German, Portuguese Brazilian and Basque to highlight the cross-lingual effectiveness of the segmenter.", "sentence2": "the model achieves a state-of-the-art F-score of 96.7 for the RST-DT corpus (Carlson et al., 2003) improving on the previous best model by 7.2%.", "label": "entailment"}
{"id": "test_2806", "sentence1": "While modeling segmentation as token classification helped remove these errors, injecting syntax helped remove these errors further.", "sentence2": "we observed that jointly training for part-of-speech tags helped remove punctuation errors and resolve confusions between infinitival complements and clauses.", "label": "entailment"}
{"id": "test_2807", "sentence1": "Results obtained and analysis performed show how injecting syntax into the model helped achieve better results.", "sentence2": "the joint learning of syntactic features allowed the model uncover complex syntactic patterns that could not be captured by simply fine-tuning BERT.", "label": "entailment"}
{"id": "test_2808", "sentence1": "In this work, we are concerned with identifying the first type of near-duplicate document.", "sentence2": "we require a system that is capable of receiving documents in a stream, and for each document, can answer two questions: is this document a near-duplicate of one previously seen, and if so, which?", "label": "entailment"}
{"id": "test_2809", "sentence1": "In this study, we created an automated essay scoring (AES) system for nonnative Japanese learners using an essay dataset with annotations for a holistic score and multiple trait scores, including content, organization, and language scores.", "sentence2": "we developed AES systems using two different approaches: a feature-based approach and a neural-network-based approach.", "label": "entailment"}
{"id": "test_2810", "sentence1": "The essays were annotated by six annotators.", "sentence2": "each essay was annotated by three out of these six annotators.", "label": "entailment"}
{"id": "test_2811", "sentence1": "Although the scoring criteria were applied as per the evaluation flowchart, some of the annotators were severe; therefore, the resulting agreement scores were moderate.", "sentence2": "between the most severe and the gentlest of the six annotators, there was an average difference of about 0.5 points on a one to six-point rating.", "label": "entailment"}
{"id": "test_2812", "sentence1": "Intuitively, \"Number of common morphemes in the prompt and the essay\" appears in holistic features.", "sentence2": "a story related to the prompt is more highly rated than one not related to the prompt.", "label": "entailment"}
{"id": "test_2813", "sentence1": "This may lead to a large spreading of hatred or abusive messages which have to be moderated.", "sentence2": "theses messages may express threats, harassment, intimidation or \"disparage a person or a group on the basis of some characteristic such as race, color, ethnicity, gender, sexual orientation, nationality, religion, or other characteristics\" (Nockleby, 2000).", "label": "entailment"}
{"id": "test_2814", "sentence1": "Our study pursues a different line of analysis, whereby speech acts bearing on derogatory content are ranked according to their perlocutionary force and assertions are classified as more or less direct.", "sentence2": "in order to make emerge different degrees of downgrading tones, we have chosen to distinguish cases where the addressee is directly addressed from those in which she is not, as done in hate speech analysis (ElSherief et al., 2018; Ousidhoum et al., 2019).", "label": "entailment"}
{"id": "test_2815", "sentence1": "We use all 1,000 articles (200 titles on five complexity levels) as our dataset, and apply ten-fold cross-validation setup with ten repetitions (in Weka Experimenter) without controlling for which titles and text versions end up in which fold.", "sentence2": "we behave as we had 1,000 independent articles on five different complexity levels, but choose to have 200 titles on five complexity levels, in order to: (1) allow for learning subtle differences between different complexity levels of texts treating the same topic; and (2) avoid bias that might arise from topic differences if we used corpora with five complexity levels, in which each level has different topics (as in the case of typical language learners corpora).", "label": "entailment"}
{"id": "test_2816", "sentence1": "Objective news maintains almost the same values throughout the frames, while column news presents a peak in the second frame.", "sentence2": "regarding the sentiment lexicon, the objective news is more unstable throughout the text, and newspaper columns present more instability in the middle of the text.", "label": "entailment"}
{"id": "test_2817", "sentence1": "While opinion mining is a well-established task with many standard datasets and well-defined methodologies, emotion mining has received less attention due to its complexity.", "sentence2": "the annotated gold standard resources available are not enough.", "label": "entailment"}
{"id": "test_2818", "sentence1": "This corpus contains manual annotations of eight emotional categories: expectation, joy, love, surprise, anxiety, sorrow, anger and hate.", "sentence2": "we found only a few resources annotated with emotions in Spanish and even most of the English emotion datasets have not been fully annotated manually.", "label": "entailment"}
{"id": "test_2819", "sentence1": "In order to retrieve tweets for each event, we select the trending topic that may contain affective content.", "sentence2": "we choose the following events that occurred during April 2019:", "label": "entailment"}
{"id": "test_2820", "sentence1": "In order to download the tweets, we used the Twitter Search API 1 .", "sentence2": "we used an easy-to-use Python library to access the Twitter API: Tweetpy 2 .", "label": "entailment"}
{"id": "test_2821", "sentence1": "For example, it can be observed that the number of tweets for fear, disgust and surprise are noticeably lower compared to others (joy, sadness, anger).", "sentence2": "fear and surprise are the most difficult emotions to label.", "label": "entailment"}
{"id": "test_2822", "sentence1": "In this section, we describe the different experiments we carried out to test the validity of the dataset.", "sentence2": "we trained a classifier based on machine learning.", "label": "entailment"}
{"id": "test_2823", "sentence1": "For this reason, we applied pre-processing techniques in order to prepare the data for the text classification.", "sentence2": "we preprocessed the tweets following these steps: The tweets were tokenized using NLTK TweetTokenizer 4 and all hashtags were removed.", "label": "entailment"}
{"id": "test_2824", "sentence1": "We use the most popular: The Term Frequency Inverse Document Frequency scheme (TF-IDF).", "sentence2": "using this scheme each tweet is represented as a vector of unigrams.", "label": "entailment"}
{"id": "test_2825", "sentence1": "For this reason we decide to employ a machine learning algorithm in order to classify the tweets by emotions.", "sentence2": "we selected the Support Vector Machine (SVM).", "label": "entailment"}
{"id": "test_2826", "sentence1": "While most research on emotion analysis focuses on emotion classification, including predicting the emotions of the writer as well as those of the reader of a text (Chang et al., 2015), a few studies so far have focused on identifying what might have triggered that emotion (Sailunaz et al., 2018).", "sentence2": "the task has been framed as Emotion Cause Extraction (Lee et al., 2010a) from news and microblogs, where the cause of an emotion is usually a single clause (Chen et al., 2010) connected by a discourse relation to another clause that explicitly expresses a given emotion (Cheng et al., 2017), as in this example from Gui et al.", "label": "entailment"}
{"id": "test_2827", "sentence1": "They might contain multiple keywords as well.", "sentence2": "in this task, the dataset is provided with the sentiment (positive or negative) of the text, and our goal is to find the emotion carriers for that sentiment.", "label": "entailment"}
{"id": "test_2828", "sentence1": "The authors thank coders and co-workers who participated in elaborating protocols and annotating emotional states.", "sentence2": "Corinne Bignon and her staff for the implication in the annotation process.", "label": "entailment"}
{"id": "test_2829", "sentence1": "Using these two settings, we aim at obtaining a better understanding of the advantages and disadvantages of an expert vs. crowdsourcing setting in this novel annotation task.", "sentence2": "we are interested in estimating the potential of a crowdsourcing environment for the task of self-perceived emotion annotation in poetry, given time and cost overhead associated with in-house annotation process (that usually involve training and close supervision of the annotators).", "label": "entailment"}
{"id": "test_2830", "sentence1": "For consistency and to simplify the task for the annotators, we opt for a trade-off between completeness and granularity of the annotation.", "sentence2": "we subselect stanzas composed of four verses from the corpus of 64 hand selected English poems.", "label": "entailment"}
{"id": "test_2831", "sentence1": "In this paper, we construct the first empathy lexicon.", "sentence2": "we learn ratings for two kinds of empathy - empathic concern (feeling for someone) and personal distress (suffering with someone)-for words given existing document-level ratings from the recently published Empathic Reactions dataset (Buechel et al., 2018).", "label": "entailment"}
{"id": "test_2832", "sentence1": "In contrast, resources from psychologists tend to focus on valence and arousal (or other representations of affective states (Ekman, 1992)).", "sentence2": "this includes the Affective Norms for English Words (ANEW; (Bradley and Lang, 1999)) which have been adopted to many languages (Redondo et al., 2007;Montefinese et al., 2014), and their extension by Warriner et al.", "label": "entailment"}
{"id": "test_2833", "sentence1": "Abdul-Mageed et al. (2017), in contrast, focus on trait empathy, a temporally more stable personal attribute.", "sentence2": "they studied the detection of \"pathogenic empathy\", marked by selffocused distress, a potentially detrimental form of empathy associated with health risks, in social media language using a wide array of features, including n-grams and demographic information.", "label": "entailment"}
{"id": "test_2834", "sentence1": "We can now train the model to predict the document gold ratings Y d using a gradient descent-based method.", "sentence2": "for a document d i , the embedding centroid of tokens present in d i is used as input a (0)  where len(d i ) is the number of tokens in d i .", "label": "entailment"}
{"id": "test_2835", "sentence1": "Thus, if the sentence selection in the process of creating the dataset fails to make pairs of sentences with the same communicative functions, the accuracy will be low but the agreement will be high.", "sentence2": "a low accuracy and high agreement indicate that the dataset is of low quality.", "label": "entailment"}
{"id": "test_2836", "sentence1": "The homogeneity metric is proposed to summarize the uniformity of a cluster distribution.", "sentence2": "how uniformly the embedding vectors of the samples in a group of texts are distributed in the embedding space.", "label": "entailment"}
{"id": "test_2837", "sentence1": "Afterwards we discuss two different implementations of NLI databases.", "sentence2": "we will introduce the database\u0002centric approach based on SODA (Blunschi et al. 2012) as well as the information retrieval-centric approach based on the Terrier system (Macdonald and He, 2008)", "label": "entailment"}
{"id": "test_2838", "sentence1": "It is often thought to involve effects related to co-activation between word representations, a theoretical position mainly inspired by the Interactive Activation model (McClelland and Rumelhart, 1981).", "sentence2": "the neighborhood effect elicited by a word such as PLEAD is a function of the orthographic similarity of PLEAD to other words in the lexicon.", "label": "entailment"}
{"id": "test_2839", "sentence1": "An open ngram encoding is defined as the set of n-combinations of letters a word, where the letters within a combination are ordered by their occurrence in the word.", "sentence2": "the word SWAN generates the following open 2-gram (or bigram) features: {SW, SA, SN, WA, WN, AN}.", "label": "entailment"}
{"id": "test_2840", "sentence1": "The material is robust in that it allows obtaining multiple samples of each speech sound so that each list is equally representative of the French sound system.", "sentence2": "each consonant appears at least twice in each position, as measure of speech intelligibility based on acoustic properties of the speech signal.", "label": "entailment"}
{"id": "test_2841", "sentence1": "In this paper, we provide an extensive evaluation of 14 spelling correction tools on a common benchmark.", "sentence2": "the evaluation provides a detailed comparison with respect to 12 error categories.", "label": "entailment"}
{"id": "test_2842", "sentence1": "Most algorithms and tools in the field simply assume that the given text is free from errors such as the above and they fail if this is not the case.", "sentence2": "this is true for basic problems such as POS-tagging, sentence parsing and entity recognition, as well as for more complex problems such as question answering (QA).", "label": "entailment"}
{"id": "test_2843", "sentence1": "Over the recent years, endeavours have been devoted to designing accurate and efficient EL systems.", "sentence2": "english eL has undergone continuous development, with the aid of up-to-date KBs and evaluation benchmarks.", "label": "entailment"}
{"id": "test_2844", "sentence1": "In contrast to the advancement in English, however, Chinese EL systems suffer from lagged development, partially due to the lack of appropriate Chinese KBs and evaluation benchmarks.", "sentence2": "almost all existing publicly available Chinese EL datasets are based on short text, such as microblogs (NLPCC 2013 1 , NLPCC 2014 2 , NLPCC 2015 3 ) and news headings (Chen et al., 2018) 4 .", "label": "entailment"}
{"id": "test_2845", "sentence1": "In this work, we propose CLEEK, a Chinese long-text corpus for entity linking, which comprises 100 documents and 2,786 mentions, along with a measure for characterizing corpus difficulty.", "sentence2": "we first elaborate the process of corpus construction and annotation, and then provide an in-depth analysis of corpus properties, in particular the difficulty of dataset.", "label": "entailment"}
{"id": "test_2846", "sentence1": "The knowledge base population (KBP) track 7 includes Chinese EL as a component since 2015.", "sentence2": "for the Chinese EL dataset in KBP2016 task (Ji et al., 2016), there are 8,845 mentions and 167 documents in evaluation data and 15,000 documents in the source data.", "label": "entailment"}
{"id": "test_2847", "sentence1": "As is illustrated in Figure 2, the work flow of corpus construction initiates from mining news and commentaries from websites.", "sentence2": "we crawl approximately 10,000 pieces of long texts from Sohu News 8 and China Newsweek 9 , which cover five domains, namely, Sport, Travelling, Economy, Film Review and Politics.", "label": "entailment"}
{"id": "test_2848", "sentence1": "Although the performance of using prior probability can be regarded as an advisable measure, it neglects the semantic similarities between mentions and true entities.", "sentence2": "provided that a mention and its corresponding entity are close in the semantic space, the linking process could be easily realized via EL solutions based on neural networks and embeddings.", "label": "entailment"}
{"id": "test_2849", "sentence1": "The inferior outcome, to a certain degree, can be attributed to the deficiency of generating candidate entities.", "sentence2": "according to the observation of results, the candidate entities generation strategies for the two approaches fail to generate candidate entities for the majority of mentions.", "label": "entailment"}
{"id": "test_2850", "sentence1": "According to their results, both filled and unfilled hesitation pauses cause extra activation of the primary auditory cortex (PAC) and the motor components of the speech system in the brain.", "sentence2": "for filled pauses, a more expressed activation was detected in the additional motor cortex (SMA), which is known to be involved into the initiation of utterances.", "label": "entailment"}
{"id": "test_2851", "sentence1": "The basic vocal annotation and the additional disfluency annotation were imported into the eaf files used in ELAN.", "sentence2": "time boundaries and type code of every annotated disfluency were imported into the intervals of the \"N/C/R-Dislf\" tiers (where N, C or R stands for Narrator, Commentator, and Reteller, respectively).", "label": "entailment"}
{"id": "test_2852", "sentence1": "Since the document frequency of entities varies a lot from high frequency entities to low frequency entities (power law distribution), we focus on the scale of the document frequency of entities.", "sentence2": "we put entities whose log document frequency under the same scale into the same group, and present the log of the number of entities in each group.", "label": "entailment"}
{"id": "test_2853", "sentence1": "To make the comparison possible, article matching and entity alignment are necessary.", "sentence2": "we first identify a common set of articles by title matching, i.e., only articles with the exactly same title are selected", "label": "entailment"}
{"id": "test_2854", "sentence1": "We investigate this issue by measuring the impact of LRR.", "sentence2": "we extract subsets with decreasing LRR and present ESD results of the subsets.", "label": "entailment"}
{"id": "test_2855", "sentence1": "We follow the work of Dunietz and Gillick (2014).", "sentence2": "we use some hand-crafted features to train a binary classifier to identify whether an entity is salient in a document.", "label": "entailment"}
{"id": "test_2856", "sentence1": "On the other hand, the number of false positives (FP) in the NMT system was considerably larger than that in the SMT system.", "sentence2": "the NMT system changed many points that did not need to be changed.", "label": "entailment"}
{"id": "test_2857", "sentence1": "This flexibility was demonstrated to be useful in the biomedical domain, where syntactic parsers are brittle.", "sentence2": "a state-of-the-art Odin grammar for this domain had to backoff to surface information for 38% of its patterns (Valenzuela-Esc\u00e1rcega et al., 2018).", "label": "entailment"}
{"id": "test_2858", "sentence1": "Odinson was designed to have a flexible index schema, and so few fields are mandatory.", "sentence2": "the only mandatory field is the \"raw\" field, which encodes unmodified tokens.", "label": "entailment"}
{"id": "test_2859", "sentence1": "Odinson also supports event queries, which make it easier to specify complex patterns involving many entities interacting through a trigger.", "sentence2": "each event query is a structured query that contain several sub-queries: one for the event trigger, and one for each of the required arguments.", "label": "entailment"}
{"id": "test_2860", "sentence1": "Therefore the TNE leverages Adaptive Computation Time (Graves, 2016) to dynamically allocate more computational resources for the encoding of some words compared to others in the same EEG report.", "sentence2": "the TNE consists of an Adaptive Universal Transformer (Dehghani et al., 2018) with 12 recurrent blocks as described in (Maldonado and Harabagiu, 2019).", "label": "entailment"}
{"id": "test_2861", "sentence1": "Thus microtask crowdsourcing has been widely used for quick and easy, isolated tasks such as image tagging, or print document digitization (Kittur et al., 2011), several researchers have attempted to explore crowdsourcing for challenging and expert tasks such as programming, product design, or NLP tasks (Kittur et al., 2013;Valentine et al., 2017).", "sentence2": "empirical examination of numerous NLP tasks such as image recognition, sentiment analysis, and assess-ment of the performance of machine translation systems via crowdsourcing has shown that collective responses of crowd workers may provide gold standard data sets with quality approaching those generated by experts (Snow et al., 2008; Callison-Burch, 2009; Nowak and Ruger, 2010).", "label": "entailment"}
{"id": "test_2862", "sentence1": "Inspired by these findings, we suggest using micro-task crowdsourcing to evaluate the extrinsic and intrinsic quality of query-based extractive forum summarization to overcome these time and cost barriers of summary quality evaluation.", "sentence2": "when the naive end-users viewpoint is needed to evaluate an automatic summarization application or any summarization method, the subjective quality evaluation plays an important role.", "label": "entailment"}
{"id": "test_2863", "sentence1": "Meanwhile, the natural language processing (NLP) community has observed significant advances in both machine translation (Sutskever et al., 2014; Cho et al., 2014; Vaswani et al., 2017) and speech synthesis (Oord et al., 2016; Wang et al., 2017; Shen et al., 2018), especially driven by deep learning in recent years.", "sentence2": "there has been growing attention towards lowresource scenarios (Zoph et al., 2016;Gu et al., 2018), which pose a unique challenge for existing deep learning methods.", "label": "entailment"}
{"id": "test_2864", "sentence1": "We assess the accuracy of the temple corpus by evaluating the context-question-answer data using C/Q and Q/A classifier.", "sentence2": "we evaluate on a set of 50 temples, randomly selecting 26 temples (264 Question:Answer pairs) with wikipedia article and 24 temples (359 Question:Answer pairs) without wikipedia article.", "label": "entailment"}
{"id": "test_2865", "sentence1": "In this paper, we consider whether sub-word embeddings can be leveraged to form cross-lingual embeddings for OOV words.", "sentence2": "we consider a novel bilingual lexicon induction task focused on OOV words, for language pairs covering several language families.", "label": "entailment"}
{"id": "test_2866", "sentence1": "In this paper we evaluate whether sub-word embeddings can be leveraged in cross-lingual models.", "sentence2": "we consider a novel bilingual lexicon induction task in which an in-vocabulary target language translation is found for an OOV source language word, where the representation of the source language word is constructed from subword embeddings.", "label": "entailment"}
{"id": "test_2867", "sentence1": "Because of the previous findings that fastText embeddings outperform BPE, we only consider fastText embeddings in these experiments.", "sentence2": "we use fastText embeddings pretrained on Cherokee Wikipedia.", "label": "entailment"}
{"id": "test_2868", "sentence1": "In this paper we considered whether sub-word embeddings can be leveraged in cross-lingual word embedding models.", "sentence2": "we evaluated sub-word embeddings in a novel bilingual lexicon induction task in which we identify target language translations for OOV source language words.", "label": "entailment"}
{"id": "test_2869", "sentence1": "We have contributed to the field by researching methods that are applicable to less-resourced languages, with Basque as a case study.", "sentence2": "we have compared a training data projection approach with direct model transfer strategies.", "label": "entailment"}
{"id": "test_2870", "sentence1": "We do this by enforcing a label distribution 6 among test questions and excluding test questions which are ambiguous.", "sentence2": "we leave in difficult cases, but only if they are unambiguously so and clearly covered by the instructions.", "label": "entailment"}
{"id": "test_2871", "sentence1": "However, we also found that for a minority of challenging cases, agreement is very low, usually < 50%.", "sentence2": "we see a clear two-way split between straightforward cases (100% agreement) and ambiguous cases (< 50% agreement).", "label": "entailment"}
{"id": "test_2872", "sentence1": "Besides providing additional data, we designed the recording sessions in ways that allow the elicitation of linguistic patterns of interest.", "sentence2": "we replicated part of the setting used in the HCRC MapTask corpus (Anderson et al., 1991).", "label": "entailment"}
{"id": "test_2873", "sentence1": "Thus, we employed regular expressions to detect and delete sentences holding this kind of issue.", "sentence2": "we look for sentences with three or more sequential tokens composed of one or two characters at most.", "label": "entailment"}
{"id": "test_2874", "sentence1": "We perform a downstream task to evaluate the quality of the corpora after the filtering process.", "sentence2": "we train an open-vocabulary language model at character-level (Mielke et al., 2019) and measure the results with character-level perplexity (Mielke, 2019).", "label": "entailment"}
{"id": "test_2875", "sentence1": "Our scenario is such a complex task.", "sentence2": "our scenario relates to using robotics and autonomous systems on an offshore energy platform to resolve an emergency and is part of the EPSRC ORCA Hub project (Hastie et al., 2018).", "label": "entailment"}
{"id": "test_2876", "sentence1": "The time that robots would take to perform actions was based on simulations run on a Digital Twin of the offshore facility implemented in Gazebo (Pairet et al., 2019).", "sentence2": "we pre-simulated typical robot actions, with the robot's progress and position reflected in the Wizard interface with up-to-date dialogue options for the Emergency Assistant.", "label": "entailment"}
{"id": "test_2877", "sentence1": "In the domain of machine-readable lexicons, different projects have tackled the difficult issue of unifying features to describe lexical entries, allowing a meaningful semantic interoperability.", "sentence2": "projects have aimed to unify the descriptors used to label specific forms in a lexical entry.", "label": "entailment"}
{"id": "test_2878", "sentence1": "The work presented in this paper is part of a project on Simplification of Arabic Masterpieces for Extensive Reading (SAMER) (Al Khalil et al., 2017; Al Khalil et al., 2018).", "sentence2": "we discuss the challenges of, and solutions to, the development of a large-scale leveled readability lexicon for Modern Standard Arabic (MSA).", "label": "entailment"}
{"id": "test_2879", "sentence1": "In this article, we will introduce two parts of the new multi-part version of the Lexical Markup Framework (LMF) International Organization for Standardization (ISO) standard, namely Part 3 of the standard (ISO/DIS 24613-3), which deals with etymological and diachronic data, and Part 4 (ISO/DIS 24613-4), which consists of a TEI serialisation of all of the prior parts of the model (in what follows we will refer to the TEI-XML serialisation of LMF data as LMF in TEI).", "sentence2": "we will show how LMF and especially parts 3 and 4 can be used to encode etymological data by taking example encodings of entries from an important reference dictionary for the Portuguese language, the Grande Dicion\u00b4ario Houaiss da L\u00b4\u0131ngua Portuguesa (Houaiss, 2015), from now on Houaiss", "label": "entailment"}
{"id": "test_2880", "sentence1": "Our approach to modelling etymologies in LMF has been heavily influenced by prior work in etymology representation both in the 2008 version of LMF (Salmon-Alt, 2006) as well as in other standards such as TEI (Bowers and Romary, 2017) and Ontolex-lemon (Khan, 2018).", "sentence2": "we have sought to emphasise the following three aspects of etymologies when representing them as computational resources: 1. their status as descriptions of abstract graphs, i.e., data structures of the kind that computer scientists are (exceedingly) used to working with; 2. the fact that etymologies usually describe the genealogy of a given lexical phenomenon through the use of a narrative (simple in most cases); and finally, 3. the fact that individual etymologies also describe hypotheses (often of a scholarly nature) and tend to include references to other texts in justification of these hypotheses.", "label": "entailment"}
{"id": "test_2881", "sentence1": "However since etymologies usually represent an ordering of etymons (and, of course, etymons can be associated with more than one etymology and even more than one etymology for the same entry), we opted to create indirect rather than direct associations between etymologies and etymons.", "sentence2": "we define etymologies as containers for an ordered series of etymological links, see Figure 3 below.", "label": "entailment"}
{"id": "test_2882", "sentence1": "By reconstructing a phylogenetic tree from an etymological database, it is possible to evaluate its quality while being an interesting task per se.", "sentence2": "it can be used to validate and enhance said resource, which we intend to do for our own.", "label": "entailment"}
{"id": "test_2883", "sentence1": "LARA, which uses a crowdsourcing/online community approach where content creators and content users interact in a shared online environment, adapts and extends many of the ideas used in these earlier platforms and adds new ones.", "sentence2": "LARA texts are organised so that, when the user accesses them through the online portal (Habibi, 2019), a personalised concordance is built up which associates each word in the text with previous occurrences in the learner\u2019s own reading history", "label": "entailment"}
{"id": "test_2884", "sentence1": "The distance to the prototypical subjectivity vector is used as a measure of deviation from the norm.", "sentence2": "we sort essays according to the distance between the subjectivity vector and the corresponding centroid.", "label": "entailment"}
{"id": "test_2885", "sentence1": "We implemented AES models using different machine learning algorithms.", "sentence2": "we learn AES models using Support Vector Regression (SVR), Random Forests (RF), Logistic Regression (LR), Gradient Boosting (GB), and Multi-Layer Perceptron (MLP).", "label": "entailment"}
{"id": "test_2886", "sentence1": "At the moment, we provide a generic RDF conversion for each of the dictionary collections, we do not harmonize external vocabularies beyond the application of the OntoLex-Lemon vocabulary.", "sentence2": "linguistic categories are not yet normalized against the LexInfo ontology.", "label": "entailment"}
{"id": "test_2887", "sentence1": "Over the years, a number of language databases and tools for Danish have been created based on public and private initiatives, but the linguistic resources for Danish are still somewhat scattered and efforts have not been sufficiently coordinated.", "sentence2": "insufficient attention has been paid to the fact that these building blocks, often costly to produce, generally need upscaling, validation, and maintenance, and last but not least that they should be made freely available.", "label": "entailment"}
{"id": "test_2888", "sentence1": "Language tags serve to identify the language of a resource and the linguistic entities therein.", "sentence2": "language tagging is a key aspect when modeling linguistic resources in Resource Description Framework (RDF) (Manola and Miller, 2014) following the principles of Linked Data (LD) (Berners-Lee, 2006).", "label": "entailment"}
{"id": "test_2889", "sentence1": "Therefore, our Hadith corpus relies on the source.", "sentence2": "missing values or inconsistencies with the original book are dependent on Sunnah.com.", "label": "entailment"}
{"id": "test_2890", "sentence1": "For CLARIN, the clustering in SSHOC is yet another context in which the ongoing effort towards optimizing the service we offer for comparative research based on the CLARIN Resource Families (Fi\u00c3\u2026\u00c2\u00a1er et al., 2018) can be coordinated.", "sentence2": "for the work on better integration of parliamentary data and the support for the development of methodologies for working with heterogeneous data sets, the SSHOC project has a big potential for impact, as it is calling for collaboration with political scientists and linguists, the coupling of parliamentary corpora with other political research data sets, such as the party manifestos, 31 and the integration of textual data and quantitative data from polls.", "label": "entailment"}
{"id": "test_2891", "sentence1": "The taxonomy was based upon a review of schema previously developed for META-SHARE and the ISOCat Data Category Registry and then tried against the LDC Catalog.", "sentence2": "the authors reviewed the entries for each of the 574 corpora then included in the LDC Catalog.", "label": "entailment"}
{"id": "test_2892", "sentence1": "They were transcribed and during the transcription process new abstract attributes of description were identified (see Section 4.3).", "sentence2": "the transcription implied extensively completing the designed questionnaire in continuous prose and, where possible, adding links to existent institutional websites.", "label": "entailment"}
{"id": "test_2893", "sentence1": "The basic idea behind this is that each time, when the model predicts an output word, it only uses the parts of input where the most relevant information is concentrated instead of the whole sentence.", "sentence2": "it only pays attention to some weighted words.", "label": "entailment"}
{"id": "test_2894", "sentence1": "Such methods may yield pairs sharing little common content, thus giving alignment errors.", "sentence2": "these errors often occur when the sentence order differs greatly between the source and target.", "label": "entailment"}
{"id": "test_2895", "sentence1": "Unfortunately, the target-side sentences of each corpus came from different resources.", "sentence2": "the target-side sentences of the content-equivalent corpus came from the content-equivalent news, while those of the back-translated corpus (CE-NMT) came from the original news, as listed in Table 1.", "label": "entailment"}
{"id": "test_2896", "sentence1": "The technology used within the task was developed within FP7 projects XLike 26 and XLime 27 focused on cross-lingual knowledge-extraction.", "sentence2": "for this task we will use the systems and components from Wikifier (Brank et al., 2017), XLing (Rupnik et al., 2016) and EventRegistry (Leban et al., 2014) all dealing with statistical and semantic cross-lingual annotations and alignments.", "label": "entailment"}
{"id": "test_2897", "sentence1": "A large comparable corpus for Basque-Spanish was prepared, on the basis of independently-produced news by the Basque public broadcaster , and we discuss the impact of various techniques to exploit the original data in order to determine optimal variants of the corpus.", "sentence2": "we show that filtering in terms of alignment thresholds and length-difference outliers has a significant impact on translation quality.", "label": "entailment"}
{"id": "test_2898", "sentence1": "The accuracy of LST depends on the coverage and quality of the linguistic resources used to train them.", "sentence2": "when the coverage of the training resources are poor such as for rare words, named entities or neologisms, the accuracy of tokenisation of out of vocabulary (OOV) words can be low.", "label": "entailment"}
{"id": "test_2899", "sentence1": "Similar to th, for tr we see that the LIT methods trained with vocabularies of sizes 50K and 100K perform better than other settings.", "sentence2": "for tr LIT consistently outperforms LST.", "label": "entailment"}
{"id": "test_2900", "sentence1": "This dataset classifies word-pairs according to POS category of the two words being compared.", "sentence2": "both words in a word-pair belong to the same POS category, which makes it an ideal candidate for studying the effect of tokenisation on different POS categories.", "label": "entailment"}
{"id": "test_2901", "sentence1": "Therefore, we use SIF for creating word embeddings from subword embeddings in this experiment.", "sentence2": "we use the GloVe embeddings for Japanese subtokens/tokens obtained by a particular tokenisation method and use SIF to create the word embeddings for each word in word-pairs in the Japanese semantic similarity dataset.", "label": "entailment"}
{"id": "test_2902", "sentence1": "We select prefixes or suffixes that have known inflectional roles and compute the cosine similarity between each prefix/suffix and all other tokens in the vocabulary using the unweighted embedding method to find the nearest neighbours in the embedding space.", "sentence2": "we conduct this nearest neighbour analysis for the three languages: English, Japanese and Turkish.", "label": "entailment"}
{"id": "test_2903", "sentence1": "This appendix contains additional experimental results not included in the main body of the paper.", "sentence2": "it contains supplementary results for the dictionary induction (Table 6) and cross-lingual word similarity (Table 7) tasks, using all sources of supervision: no supervision, dictionary of identical words, and dictionaries containing 100, 1K and 8K translation pairs.", "label": "entailment"}
{"id": "test_2904", "sentence1": "Before we introduce our own bilingual Vietnamese-English corpus, it is also important to note that previous work has been done to create a similar corpus for the same language pair.", "sentence2": "tuc (2003) collected a corpus of 60 hours of speech, comprising both sociolinguistic interviews and speakers' self-recorded speech, over twenty years ago in Victoria, Australia.", "label": "entailment"}
{"id": "test_2905", "sentence1": "This is likely because Vietnamese POS taggers are not only typically trained on much less data than English POS taggers, but they are also unlikely to be well-suited to speech data (Plank et al., 2016).", "sentence2": "spoken Vietnamese is characterised by extensive use of discourse markers and lexicon variation due to regional dialects and so is significantly different to written Vietnamese.", "label": "entailment"}
{"id": "test_2906", "sentence1": "Table 8 thus illustrates contrasting occasions when the pronoun was translated incorrectly and correctly in a monolingual Vietnamese and mixed clause respectively.", "sentence2": "the first person subject con (kin term meaning 'child') was erroneously translated as a 3SG common noun in the monolingual Vietnamese clause, but accurately translated as a 1SG subject pronoun in the mixed clause.", "label": "entailment"}
{"id": "test_2907", "sentence1": "SLING also in-  corporates an attention mechanism based on neuro-science models of attention and awareness in (Nelson et al., 2017) and (Graziano, 2013).", "sentence2": "the attention mechanism focuses on encoding the frame representation that the parser has created rather than encoding the tokens themselves.", "label": "entailment"}
{"id": "test_2908", "sentence1": "Though not provided with the annotated dataset for obvious copyright reasons 12 , the textual content of every speech turn has been revised, based on the output of the OCR tool we used to retrieve the subtitles.", "sentence2": "we restored a few missing words, mostly for BB, the subtitles sometimes containing some deletions.", "label": "entailment"}
{"id": "test_2909", "sentence1": "Yet, most of the Information Retrieval or Information Extraction tasks still mainly rely on textual data to automatically extract meaningful knowledge from unstructured text.", "sentence2": "over the last decade, the Twitter platform was a major source of information for natural language processing (NLP) applications such as information retrieval, sentiment analysis, or topic modeling.", "label": "entailment"}
{"id": "test_2910", "sentence1": "Preliminary experiments on a dataset built using our approach show its interest.", "sentence2": "it offers the opportunity to investigate the benefit of exploiting related visual information to improve the Entity linking task.", "label": "entailment"}
{"id": "test_2911", "sentence1": "Deep Learning models make use of neural networks with many layers and units (neurons) to explore the data and extract features to be used in the learning process.", "sentence2": "while a Classic method works with the features provided beforehand only, a Deep Learning model uses all of them to generate many more features itself, which is done by using internal (hidden) layers of the model.", "label": "entailment"}
{"id": "test_2912", "sentence1": "The results demonstrate that flood-related news articles do not consistently report on a single, currently unfolding flooding event and we should also not assume that a flood-related image will directly relate to a flooding-event described in the corresponding article.", "sentence2": "spatiotemporal distance is important.", "label": "entailment"}
{"id": "test_2913", "sentence1": "Event information from online sources provides an important complement to information that can be derived from remote sensing imagery.", "sentence2": "it is not dependent on factors such as the periodicity of the satellite or cloud-cover conditions.", "label": "entailment"}
{"id": "test_2914", "sentence1": "However, multimedia research often makes highly rigid assumptions about the relationship among the media.", "sentence2": "in research that deals with combinations of text and images, the text is usually assumed to describe the image.", "label": "entailment"}
{"id": "test_2915", "sentence1": "We highlight the presence of multiple modalities and its real-life nature, which differentiates it from prior work.", "sentence2": "lifeQA is the only existing Video QA dataset that focuses on real-life understanding and is carefully constructed from hand-picked in-the-wild videos.", "label": "entailment"}
{"id": "test_2916", "sentence1": "Deep neural language models have recently evolved to a successful method for representing text.", "sentence2": "bidirectional Encoder Representations from Transformers (bERT) outperformed previous state-of-the-art methods by a large margin on various NLP tasks (Devlin et al., 2019).", "label": "entailment"}
{"id": "test_2917", "sentence1": "To improve lists of entity-to-entity PMI, a cutoff based on the raw counts is dynamically determined for each list.", "sentence2": "all counts are sorted from highest to lowest counts and the count limit is determined by when a total share of 80% has been reached, or a minimum of 2 if there are too few entries.", "label": "entailment"}
{"id": "test_2918", "sentence1": "The archaeology domain, like other scientific fields, produces large amounts of textual data.", "sentence2": "a large amount of excavation reports are available, which are created whenever an excavation is completed, detailing everything that has been found together with an interpretation of the site (Richards et al., 2015).", "label": "entailment"}
{"id": "test_2919", "sentence1": "In this paper, we have explored the use of SOTA Transformer models for the purposes of medical text augmentation.", "sentence2": "we focused on the vanilla Transformer and GPT-2 models to generate discharge summaries from the MIMIC-III dataset, modelled as a seq2seq task.", "label": "entailment"}
{"id": "test_2920", "sentence1": "To verify the efficacy of our methodology, we conduct both an intrinsic and an extrinsic task which are word similarity and sentence classification, respectively.", "sentence2": "we apply our method to various languages which are rooted from different language families since subword information is a language-dependent characteristic.", "label": "entailment"}
{"id": "test_2921", "sentence1": "Although the domain where the pretrained word embeddings are trained is not quite related to the medical domain, the performance is largely increased.", "sentence2": "the performance in the UMN dataset is increased as much as 82% in terms of Spearman's correlation.", "label": "entailment"}
{"id": "test_2922", "sentence1": "As can be seen from the table, again, our method outperforms other baselines by a large margin.", "sentence2": "the proposed model achieves as much as 8.1% improvement on average in test accuracy compared to strong baselines in the CR dataset.", "label": "entailment"}
{"id": "test_2923", "sentence1": "This result is consistent with previous studies (see section 1.3).", "sentence2": "both the presence and the mean smiling intensity seem to be a marker of humor.", "label": "entailment"}
{"id": "test_2924", "sentence1": "Considering that these results tend to indicate that both intensity mean (figure 6) and presence/absence of smiling (figure 7) are markers of humor, the impact of smiling on the success or failure of humor was then investigated.", "sentence2": "does smiling reduce the risk that humor will fail?", "label": "entailment"}
{"id": "test_2925", "sentence1": "However, comparatively little has been done to explore the integration of vetted terminology and MT processing, with the goal of improving overall results.", "sentence2": "manipulating the translation output of NMT systems to adhere to user-provided terminology specifications, despite the impressive quality improvements of NMT, remains an open problem (Hasler et al., 2018).", "label": "entailment"}
{"id": "test_2926", "sentence1": "In both Figures 1b and 2a, the highest value in the column under the source token \"report,\" a value of 0.8274, triggers the target token selection.", "sentence2": "the token \"informe\" is the correct target equivalent of the source token \"report\" with an 82.74% confidence.", "label": "entailment"}
{"id": "test_2927", "sentence1": "It can be used to extract high-quality language features from any text data, as well as to fine-tune the model on a specific task like classification, entity recognition, or question answering.", "sentence2": "we use BERT to extract word and sentence embedding vectors, again calculating cosine similarities.", "label": "entailment"}
{"id": "test_2928", "sentence1": "In this work, we want to know if the type of training corpora affects SA task performance.", "sentence2": "is it better to train embeddings with task-specific (polar) corpora in SA framework?", "label": "entailment"}
{"id": "test_2929", "sentence1": "Essentially, there are a dual purpose expression.", "sentence2": "the meaning of what a speaker wants to express is very different from the superficial meaning of what he/she says, and even in most cases the two meanings are completely opposite.", "label": "entailment"}
{"id": "test_2930", "sentence1": "In order to go in the direction of a deeper and finer-grained analysis on the relationship between semantics and syntax in the case of ironic expressions, we performed a preliminary analysis on the new gold standard.", "sentence2": "we wanted to investigate whether there exist some cooccurrencies, related to PoS tags and dependency relations, that are more frequent than other.", "label": "entailment"}
{"id": "test_2931", "sentence1": "As Table 2 shows, mistakes made by the system in assigning the wrong phrase structure contributed the largest number of errors: 71%.", "sentence2": "some notorious issues were caused by the morphological ambiguity between bound/free relative pronouns and interrogative pronouns and their mismatch with determiners and adverbials.", "label": "entailment"}
{"id": "test_2932", "sentence1": "In the PDT-C project, we aim to provide all these included treebanks with full manual annotation at the lower layers and unify and correct annotation at all layers.", "sentence2": "the data in PDT-C 1.0 is (mainly) enhanced with a manual annotation at the morphological layer, consistently across all the four original treebanks (see Sect.", "label": "entailment"}
{"id": "test_2933", "sentence1": "In this work, we follow the simple intuition that any component that does not explicitly depend on a treebank annotation model is shared between the parsing models for the different treebanks.", "sentence2": "the representation models for words (word embedding and bidirectional LSTM) and the buffer are shared, while the representations for constituents and the stack, as well as the action selector, are kept separate for each treebank.", "label": "entailment"}
{"id": "test_2934", "sentence1": "We propose a simple yet accurate method for dependency parsing that treats parsing as tagging (PaT).", "sentence2": "our approach addresses the parsing of dependency trees with a sequence model implemented with a bidirectional LSTM over BERT embeddings, where the \"tag\" to be predicted at each token position is the relative position of the corresponding head.", "label": "entailment"}
{"id": "test_2935", "sentence1": "We propose an extremely simple method for dependency parsing that treats parsing as tagging (PaT).", "sentence2": "our approach addresses the parsing of dependency trees with a sequence model, where the \"tag\" to be predicted at each token position is the relative position of the corresponding head.", "label": "entailment"}
{"id": "test_2936", "sentence1": "Since the FTB contains exclusively written texts, the parser inevitably encounters difficulties to parse the spontaneous speech turns of our corpus.", "sentence2": "the concept of sentence, which is helpful to the parser, is not operative on spoken language.", "label": "entailment"}
{"id": "test_2937", "sentence1": "To investigate how AlloVera improves multilingual speech recognition, we implemented three multilingual models mentioned above and compared their performance.", "sentence2": "we selected 11 languages from AlloVera taking into consideration the availability of those languages in our training speech corpus.", "label": "entailment"}
{"id": "test_2938", "sentence1": "The quality of the collected data, however, is highly dependent on the way the task is presented to the participants.", "sentence2": "the data collection method should be carefully designed to (1) elicit naturalistic data in a controlled setting, and (2) avoid undesired biases, for example prompting the participants to repeat the same syntactic structures or lexical choices that are in the task description, which could happen if participants are just asked to paraphrase a command.", "label": "entailment"}
{"id": "test_2939", "sentence1": "In this section we describe a methodology to categorise gold standards according to linguistic complexity, required reasoning and background knowledge, and their factual correctness.", "sentence2": "we use those dimensions as highlevel categories of a qualitative annotation schema for annotating question, expected answer and the corresponding context.", "label": "entailment"}
{"id": "test_2940", "sentence1": "Our error analysis observed that while this substantially increases QC performance, it changes the distribution of errors made by the system.", "sentence2": "25% of errors become highly correlated with an incorrect answer candidate, which (we show in Section 5.)", "label": "entailment"}
{"id": "test_2941", "sentence1": "We incorporate QC information into the QA process by implementing a variant of a query expansion model (Qiu and Frei, 1993).", "sentence2": "for a given {question, QC label} pair, we expand the question text by concatenating the definition text of the question classification label to the start of the question.", "label": "entailment"}
{"id": "test_2942", "sentence1": "Because each question can have up to two labels, we treat each label for a given question as a separate evaluation of interannotator agreement.", "sentence2": "for questions where both annotators labeled each question as having 1 or 2 labels, we treat this as 1 or 2 separate evaluations of interannotator agreement.", "label": "entailment"}
{"id": "test_2943", "sentence1": "To address such absence, we release SQuAD2-CR dataset, which contains annotations on unanswerable questions from the SQuAD 2.0 dataset, to enable an explanatory analysis of the model prediction.", "sentence2": "we annotate (1) explanation on why the most plausible answer span cannot be the answer and (2) which part of the question causes unanswerability.", "label": "entailment"}
{"id": "test_2944", "sentence1": "An intuitive way is to provide pseudolabels to unlabeled data using our annotations and semi-supervised approaches.", "sentence2": "we apply tri-training (Zhou and Li, 2005), which is one of the strong baselines for neural semi-supervised learning for natural language processing (Ruder and Plank, 2018).", "label": "entailment"}
{"id": "test_2945", "sentence1": "All of the videos include spoken instructions which are transcribed and manually segmented into multiple segments.", "sentence2": "we asked the annotators to manually divide each video into multiple segments such that each of the segments can serve as an answer to any question.", "label": "entailment"}
{"id": "test_2946", "sentence1": "We present our choices of data sets for training and testing the components, and present the experimental results that helped us optimize the parameters of the chatbot.", "sentence2": "we discuss the appropriateness of using the SQuAD dataset for evaluating end-to-end QA, in the light of our system's behavior.", "label": "entailment"}
{"id": "test_2947", "sentence1": "We found that web browsers' traditional text span selection lacks speediness, usability, and regularly shows buggy mobile interaction.", "sentence2": "during our preliminary tests, we found several cases of highlighting of incomplete words, and thus incomplete answers, which is a situation we needed to avoid.", "label": "entailment"}
{"id": "test_2948", "sentence1": "The dataset created (i.e., ScholarlyRead dataset) could be served as the dataset for building Question Answering (QA) models on scholarly articles.", "sentence2": "it could be a benchmark dataset for span-of-words-based MRC systems in the domain of scholarly articles.", "label": "entailment"}
{"id": "test_2949", "sentence1": "A third set of QA methods draw answers from patient-specific sources.", "sentence2": "the answer is not a solution for the patient (e.g., what is the best treatment for this patient?), but rather directly from the patient\u2019s records (e.g., what treatments have been given to this patient?).", "label": "entailment"}
{"id": "test_2950", "sentence1": "emrQA (Pampari et al., 2018) is a large medical QA dataset automatically constructed from the i2b2 challenge datasets.", "sentence2": "they utilize the existing NLP annotations to populate pre-defined question and paraphrase templates and associate them with the corresponding clinical notes.", "label": "entailment"}
{"id": "test_2951", "sentence1": "We select a variety of models to analyze the effect of using different pre-training datasets on clinical QA.", "sentence2": "we use 4 variants of Transformer language models pre-trained on different open-domain, biomedical, and clinical datasets.", "label": "entailment"}
{"id": "test_2952", "sentence1": "We perform an array of experiments to analyze the effect of different fine-tuning datasets on clinical QA performance.", "sentence2": "we run the above models by fine-tuning on different combinations of the included datasets and evaluate their performance on the held out test sets from CliCR and emrQA datasets.", "label": "entailment"}
{"id": "test_2953", "sentence1": "It can be noted that fine-tuning on another medical dataset (different than the one for which the task is predicted) consistently performs worse than fine-tuning on the SQuAD dataset.", "sentence2": "fine-tuning on an open-domain dataset performs better than fine-tuning on another dataset in the same domain.", "label": "entailment"}
{"id": "test_2954", "sentence1": "Only some acts have been annotated in parallel by multiple annotators.", "sentence2": "these are: Three annotators for the first act of text #9 and two annotators for act I and II of text #6.", "label": "entailment"}
{"id": "test_2955", "sentence1": "Even though CR remains a challenging task for the time being, it is clear that coreference chains are an important component for the analysis of character-driven texts such as theatre plays.", "sentence2": "they allow insight into indirect presentations of characters, e.g., through the speech of other characters.", "label": "entailment"}
{"id": "test_2956", "sentence1": "We describe a resource and first studies towards answering this question.", "sentence2": "we create wikiHowToImprove, a collection of revision histories for about 2.7 million sentences from about 246 000 wikiHow articles.", "label": "entailment"}
{"id": "test_2957", "sentence1": "For simplicity, we focus on edits on the sentence level.", "sentence2": "we consider all articles in wiki-How for which a revision history is available and examine each original sentence, henceforth base version, and how it is changed at subsequent points in time, henceforth revised versions.", "label": "entailment"}
{"id": "test_2958", "sentence1": "Instead of the well-known \u201cone sense per discourse\u201c assumption made by Gale et al. (1992), this work makes a more relaxed hypotesis, i.e., \"one sense per Wikipedia Category\".", "sentence2": "a noun is used always with the same meaning within a Wikipedia Category.", "label": "entailment"}
{"id": "test_2959", "sentence1": "Surprisingly, the performance drops significantly on every dataset as the weight of the original word vectors is decreased.", "sentence2": "these existing benchmarks may favor dominating senses in the training corpus, making it unnecessary for the sense embedding models to deal with different senses separately.", "label": "entailment"}
{"id": "test_2960", "sentence1": "The ratio of multi-sense words is 79.6%.", "sentence2": "less than 21% of the words in MSD-1030 are single-sense.", "label": "entailment"}
{"id": "test_2961", "sentence1": "The proposed network consists of two components: (1) The Attribute Layers, implemented by a multilayer perceptron (MLP), initially learn the mapping from word embedding vectors to their corresponding attribute vectors presented by a human-generated visual attributes dataset.", "sentence2": "we use the VisA dataset (Silberer et al., 2013); (2) The Semantic Task Layer then fine-tunes the pretrained attribute vectors through supervised lexical entailment tasks (Section 2).", "label": "entailment"}
{"id": "test_2962", "sentence1": "The rationale behind the present study is in line with this approach.", "sentence2": "we expect that many of the attributes associated with a hyponym form a subset of the hypernym's attribute set.", "label": "entailment"}
{"id": "test_2963", "sentence1": "It would thus be possible to employ lexical entailment directionality detection task as a training task for predicting an adequate set of semantic attributes.", "sentence2": "if we are given an initial set of attribute vectors for the vocabulary of concern, such a directionality task can be utilized as a task for fine-tuning the attribute vectors.", "label": "entailment"}
{"id": "test_2964", "sentence1": "This supervised task can be considered as an independent learning task in its own, but it is considered as a pretraining step in the whole learning process.", "sentence2": "the learned parameters (W and b) are used to initialize the corresponding parameters in the lexical entailment fine-tuning tasks.", "label": "entailment"}
{"id": "test_2965", "sentence1": "Instead of learning to predict the degree of the entailment relation, we concentrate on training the network with the entailment directionality tasks.", "sentence2": "given a pair of words (w 1 , w 2 ), the network simply tries to assign a label, either of hyper or hypo.", "label": "entailment"}
{"id": "test_2966", "sentence1": "On the other hand, text classification results provided new insights on the most predictive features for distinguishing abusive and not-abusive swear words.", "sentence2": "we found that a wide range of features can actually improve the models performance.", "label": "entailment"}
{"id": "test_2967", "sentence1": "The term oral history, in historical research, refers to conducting and analyzing interviews with contemporary witnesses.", "sentence2": "in Germany, this kind of research focuses above all on the period of the Second World War and National Socialism.", "label": "entailment"}
{"id": "test_2968", "sentence1": "We do not only transfer the hidden layers in this stage but we apply a full weight transfer of the entire source model for initialization of the target model.", "sentence2": "we do not replace the output layer in this stage, since we use the same set of phonemes and the same phonetic decision tree both in Stage 2 and Stage 3.", "label": "entailment"}
{"id": "test_2969", "sentence1": "In the first ablation study setup, we remove the adaption from the English model trained in Stage 1.", "sentence2": "we randomly initialize the model in Stage 2 for training on German broadcast data and then adapted to the oral history data in Stage 3.", "label": "entailment"}
{"id": "test_2970", "sentence1": "Thus, adapting from a rich-resourced language directly to the target language and domain is a reasonable approach if no other data is available for training in the target language.", "sentence2": "this is shown in this experiment for state-of-the-art LF-MMI acoustic models with an LSTM-TDNN topology, which usually require a lot of data during training.", "label": "entailment"}
{"id": "test_2971", "sentence1": "CRF take into account contextual information from previous labels to make predictions.", "sentence2": "CRF models have been shown to be well-suited for the formulation of segmentation as sequence labelling that we use here for other tasks such as chunking (EshkolTaravella et al., 2019; Tellier et al., 2012, 2013, 2014) or Named Entity Recognition (Dupont & Tellier 2014).", "label": "entailment"}
{"id": "test_2972", "sentence1": "This includes localized digital assistants, improved accessibility to the visually impaired to listen to text in the languages they are comfortable with and so on.", "sentence2": "for the visually impaired, the local language books can now be converted to a large audio book library for their consumption.", "label": "entailment"}
{"id": "test_2973", "sentence1": "Although the number of speakers was insufficient, a mild positive correlation was found between age and WER (correlation coefficient: 0.59).", "sentence2": "the accuracy of speech recognition tended to decrease as the age of the speaker increased.", "label": "entailment"}
{"id": "test_2974", "sentence1": "In order to build robust ASR for such settings, which can act as the foundation for CAPT systems, it is necessary to train these systems on appropriate utterances.", "sentence2": "the data must reflect the interaction between learners and the CAPT system.", "label": "entailment"}
{"id": "test_2975", "sentence1": "To overcome the data sparsity problem, we use a pre-trained language model for the encoding part of the encoder-decoder setup, which creates a contextualized representation of the input sequence.", "sentence2": "we use BERT due to its bi-directional context conditioning, multilingualism and state-of-the-art scores on many other tasks (Devlin et al., 2019).", "label": "entailment"}
{"id": "test_2976", "sentence1": "This strengthens dependencies among neighboring elements and makes the model distance-aware when it searches for lowlevel patterns in a sequence.", "sentence2": "it restricts the attention scope to the window of neighboring elements.", "label": "entailment"}
{"id": "test_2977", "sentence1": "We assume that the difference in performance on the CNN/Daily Mail datasets reflects the difference in distribution of the useful information within the text.", "sentence2": "that in the SwissText dataset, it is spread more uniformly than in the CNN/Daily Mail dataset.", "label": "entailment"}
{"id": "test_2978", "sentence1": "We adopt and make key extensions to Grusky et al.\u2019s (2018) methodology for the development of their Newsroom dataset to the Danish language.", "sentence2": "our clarifications, extensions, and associated code presented here permit researchers to easily develop similar automatic summarisation datasets for other non-English languages.", "label": "entailment"}
{"id": "test_2979", "sentence1": "We extend the work of Newsroom (Grusky et al., 2018) and use The Internet Archive 6 , a non-profit archiver.", "sentence2": "we use the Wayback Machine 7 , a sort of automatic archive system and a product of The Internet Archive.", "label": "entailment"}
{"id": "test_2980", "sentence1": "The scores reflect how difficult it is for a QA system to choose the correct answer.", "sentence2": "if the IR scores of Stem + Correct Answer are much higher than those of Stem + Options, then it is easy for the QA system to answer that item correctly by picking the option that has the highest scores.", "label": "entailment"}
{"id": "test_2981", "sentence1": "In this work, we manage to derive adversarial examples in terms of the hypothesis-only bias and explore eligible ways to mitigate such bias.", "sentence2": "we extract various phrases from the hypotheses (artificial patterns) in the training sets, and show that they have been strong indicators to the specific labels.", "label": "entailment"}
{"id": "test_2982", "sentence1": "This dataset was designed to be as realistic as possible, so that the fact checkers trained on this dataset can handle real claims effectively.", "sentence2": "the claims are real, often requiring a context to be fully comprehended, and the evidence is embedded in real documents from various domains.", "label": "entailment"}
{"id": "test_2983", "sentence1": "Thus, by enabling integration of these techniques into the training pipeline, we hope to control lexicalization in the datasets which the NN methods possibly depend upon.", "sentence2": "the contributions of our work are: (1) To motivate further research in using delexicalized datasets, we present the delexicalized versions of several benchmark datasets used in NLI (e.g., FEVER, Fake News Challenge, SNLI, and MNLI), along with the corresponding software for the delexicalization.", "label": "entailment"}
{"id": "test_2984", "sentence1": "Next, to capture the entity overlap between premise and hypothesis sentences, we uniquely enumerate the named entities.", "sentence2": "in the claim (c) the first instance of an entity is tagged with c1.", "label": "entailment"}
{"id": "test_2985", "sentence1": "Note that in some cases of out-ofdomain experiments, the label space of the source domain did not match with that of the target domain.", "sentence2": "while the FEVER dataset consisted of data belonging to 3 classes, the FNC dataset had data points belonging to 4 classes.", "label": "entailment"}
{"id": "test_2986", "sentence1": "The transformation phase makes changes to the data format, organises data in structures, accumulates data with linguistic information, analyses data and provides explicit links between different data segments.", "sentence2": "the Bulgarian data is web crawled, extracted from the original HTML format, filtered by document type, tokenised, sentence split, tagged and lemmatised with a fine-grained version of the Bulgarian Language Processing Chain 2 and dependency parsed with NLP-Cube 3 .", "label": "entailment"}
{"id": "test_2987", "sentence1": "As mentioned above, this data has five listeners' responses to the same narrative speech.", "sentence2": "there are four more attentive listening responses in Figure 3.", "label": "entailment"}
{"id": "test_2988", "sentence1": "Therefore, contrary to the versatility, degree of empathy shown by these responses to narrative tends to become low.", "sentence2": "the versatility and degree of empathy of the response are in a trade-off relation.", "label": "entailment"}
{"id": "test_2989", "sentence1": "On the basis of a number of previous works (Dell\u2019Orletta et al., 2011; Xiaobin and Meurers, 2016; Grego Bolli et al., 2017; Brezina and Pallotti, 2016; Gyllstad et al., 2014; Norris and Ortega, 2009), we defined a set of 139 linguistic features and implemented them by relying on well known NLP tools for the Italian language. ", "sentence2": "UDPipe (Straka and Strakova, 2017) was used for tokenization, lemmatisation, POS tagging and to build dependency trees, while OpenNER (Garc\u0131a-Pablos et al., 2013) was adopted in order to compute the constituent trees.", "label": "entailment"}
{"id": "test_2990", "sentence1": "Diachronic, or historical, linguistics has been developing in the Western humanities since the 18 th century because of growing availability of large diachronic digital corpora.", "sentence2": "new computational linguistic methods have been developed to analyze semantic change (see Tang, 2018, for an up-to-date review).", "label": "entailment"}
{"id": "test_2991", "sentence1": "Gradient judgments would account for the fact that bwick is typically judged to be a possible English word like blick but not as good", "sentence2": "bwick is better than bnick but not as good as blick.", "label": "entailment"}
{"id": "test_2992", "sentence1": "Making use of data that are concept-aligned across the languages provides a certain amount of control (to the extent possible) of the influence of linguistic content on the forms that we are modeling.", "sentence2": "these forms should be largely comparable across the languages in terms of how common they are in the active vocabulary of adult speakers.", "label": "entailment"}
{"id": "test_2993", "sentence1": "First, we calculated the bitsper-phoneme for just the first three positions in the word, and then looked at the correlation between this word-onset bits per phoneme and the average (full) word length in phoneme segments.", "sentence2": "for the purpose of calculating bits-perphoneme, we truncated all words to a maximum of three phonemes, and in such a way explicitly eliminated the contribution of positions later in any word.", "label": "entailment"}
{"id": "test_2994", "sentence1": "In order to explore the variance of the model performance induced by initialization effects, we fix the hyperparameter configurations and train models initialized with various random seeds.", "sentence2": "we select five hyperparameter configurations, 20 and retrained them for additional five times each with different random initializations.", "label": "entailment"}
{"id": "test_2995", "sentence1": "But looking at Equations 8 and 9, we can consider the circumstances under which this inequality will be tight, in which case we can recover the parameters directly.", "sentence2": "if the grammar is unambiguous (i.e., if every string has at most one derivation tree) then if the left-hand side of the inequality is nonzero we can immediately see that the inequality will become an equality.", "label": "entailment"}
{"id": "test_2996", "sentence1": "Here, we are exploring an alternative or perhaps complementary hypothesis: namely, that the acquisition of the syntactic categories and rules of the language can to a certain extent be learned using only information derived from the surface strings without any appeal to external information about the hierarchical structure of the language that is being learned.", "sentence2": "the initial phases of language acquisition are based on purely syntactic information rather than the semantic bootstrapping discussed above.", "label": "entailment"}
{"id": "test_2997", "sentence1": "Although trust is an important component in relationships of all kinds, it has its limitations.", "sentence2": "it falls short of a well-known security maxim, originating in a Russian proverb that translates as, Trust, but verify.", "label": "entailment"}
{"id": "test_2998", "sentence1": "Another approach to exploit external resources is to use a language model pre-trained on a large amount of text.", "sentence2": "we used BERT (Devlin et al., 2019), which has shown competitive results in many NLP tasks.", "label": "entailment"}
{"id": "test_2999", "sentence1": "Therefore, we constructed two sets of sentences including correct and wrong knowledge respectively based on the test set of ConceptNet.", "sentence2": "the correct sentences are produced with a synonymous template whose relation tokens are replaced by synonyms (e.g., causes can also be translated to leads to), while the wrong sentences with a random template whose relation tokens are randomly replaced by another one.", "label": "entailment"}
{"id": "test_3000", "sentence1": "The ratio of layman to expert according to each metric denotes the gap between the two styles, and a higher value implies smaller differences except that for #Sentence.", "sentence2": "any opinions, findings and conclusions or recommendations expressed in this material are those of the author(s) and do not reflect the views of National Research Foundation, Singapore.", "label": "neutral"}
{"id": "test_3001", "sentence1": "Style accuracy remains similar among these medical PCIO elements, but there are significant differences among the models in their performance for preserving content.", "sentence2": "this is markedly demonstrated by the larger difference between their (concepts) vocabulary sizes (0.62/0.81 vs. 0.85 in ratio of layman to expert), and between the readability indices (0.81/0.81 vs. 0.84 on average).", "label": "neutral"}
{"id": "test_3002", "sentence1": "(2) MSD is more distinct between the two styles, which is critical for style transfer.", "sentence2": "available datasets rarely contain such cases.", "label": "neutral"}
{"id": "test_3003", "sentence1": "The purpose of the rescaling operation in Eq. (7)is to indicate the focused aspect of the current PD step for each WD step.", "sentence2": "We show the present and absent keyphrase prediction results in Table 2 and Table 3 correspondingly.", "label": "neutral"}
{"id": "test_3004", "sentence1": "WOS dataset is randomly splitted into training, validation and test subsets.", "sentence2": "the results present that our proposed global model HiAGM has the advanced capability of enhancing text features for HtC.", "label": "neutral"}
{"id": "test_3005", "sentence1": "Those models mainly focus on improving decoders based on the constraint of hierarchical paths.", "sentence2": "we rescale and normalize the prior probabilities of child nodes v child(k) to sum total to 1.", "label": "neutral"}
{"id": "test_3006", "sentence1": "We apply the proposed methodology to the aligned PUD.", "sentence2": "for example, a preposition accompanying a verb may be dropped in translation if the corre\u0002sponding verb is transitive (cf. went around the world in En vs. oboshelwent.around mirworld in Ru).", "label": "neutral"}
{"id": "test_3007", "sentence1": "Due to the difficulty in finding annotators proficient in pairs of these languages, our annotation takes English as the source language.", "sentence2": "only content words are aligned, so as to sidestep the inherently ambiguous nature of aligning function words across divergent constructions.", "label": "neutral"}
{"id": "test_3008", "sentence1": "The POS and edge-type confusion matrices built from this experiment are very similar to the ones reported in this paper (save for compound, which is not produced by the Stanford Zh parser), and are not reproduced here (they can be found in the Supplementary Materials).", "sentence2": "in constructions like he could do something the direct edge between the subject and the verb of the dependent clause is replaced with two edges going through the modal predicate.", "label": "neutral"}
{"id": "test_3009", "sentence1": "This adds a large memory and computational overhead and makes the approach impractical in real-life applications.", "sentence2": "by utilizing ConveRT instead, we arrive at a much more lightweight and efficient model.", "label": "neutral"}
{"id": "test_3010", "sentence1": "The French translation is poor (cumulative-split is, for instance, not translated) as the low gold MQM score shows.", "sentence2": "existing work has only explored textual context.", "label": "neutral"}
{"id": "test_3011", "sentence1": "Additionally, we propose and experiment with BERT-BiRNN, a variant of the BiRNN model.", "sentence2": "as the corresponding product image shows, this product is an item of clothing, and thus the machine translation is incorrect.", "label": "neutral"}
{"id": "test_3012", "sentence1": "In this paper, we showed that the current headline generation model yields unexpected words.", "sentence2": "in Section 4, we build a binary classifier that predicts an entailment relation between an article and its headline and use the classifier to filter out untruthful instances in the training data.", "label": "neutral"}
{"id": "test_3013", "sentence1": "So we need to find the most related word from the other sequence for each word in the pair.", "sentence2": "similar to the previous works (Mikolov et al., 2013b; Pennington et al., 2014), we also learn the embeddings based on word co-occurrence.", "label": "neutral"}
{"id": "test_3014", "sentence1": "Their encodings are then concatenated and passed through a network which scores how appropriate the response is given the utterance.", "sentence2": "we introduce Reinforced Fine-tune Learning, an extension to DQfD, enabling us to overcome the domain gap between the datasets and the environment.", "label": "neutral"}
{"id": "test_3015", "sentence1": "A Full Label Expert is trained on fully-annotated in-domain data, but this is lacking for many domains, and is expensive to collect and label from scratch  (Shah et al., 2018).", "sentence2": "we believe our work is the first to explore the use of weak demonstrations for DQfD in a dialog environment.", "label": "neutral"}
{"id": "test_3016", "sentence1": "To decode a transition sequence during the testing stage, the standard method is to choose the action that has the maximum probability of the current time step as the input for the next time step.", "sentence2": "the textual form of each of these three discourse units will be fed into the BERt encoder for representing as Enc(s 1 ), Enc(s 2 ), and Enc(q).", "label": "neutral"}
{"id": "test_3017", "sentence1": "Note that we follow the suggestion of Yu et al. (2018) to set \u03b1 to 0.7", "sentence2": "the parse trees annotated in CDTB-14 are not always binary.", "label": "neutral"}
{"id": "test_3018", "sentence1": "As shown in Figure 1, all responses follow the same topic, but only the first one is appropriated.", "sentence2": "tF-IDF achieves 54.98% R@1 score on the Ubuntu Corpus, showing our dataset is more difficult to get the correct answer by text overlap.", "label": "neutral"}
{"id": "test_3019", "sentence1": "Among them, \"Semantic Error\", \"Redundant\", and \"Unanswerable\" are noticeable errors for all models.", "sentence2": "To represent multiple relations in the edge, we base our model on the multi-relation Gated Graph Neu\u0002ral Network (GGNN) (Li et al., 2016), which pro\u0002vides a separate transformation matrix for each edge type.", "label": "neutral"}
{"id": "test_3020", "sentence1": "We evaluate the framework on two public datasets NYT (Riedel et al., 2010) and WebNLG (Gardent et al., 2017).", "sentence2": "first, we detect subjects from the input sentence.", "label": "neutral"}
{"id": "test_3021", "sentence1": "This validates the utility of the proposed cascade decoder that adopts a novel binary tagging scheme.", "sentence2": "it is composed of a stack of N identical Transformer blocks.", "label": "neutral"}
{"id": "test_3022", "sentence1": "The SCIENCEIE dataset focuses on the extraction of 3 types of key-phrases, rather than Named Entities, and hyponymy and synonymy relations between these (Augenstein et al., 2017).", "sentence2": "a gap remains in quickly comprehending the central information in a text, e.g., the biological mechanisms that are used to manipulate a trade-off.", "label": "neutral"}
{"id": "test_3023", "sentence1": "to SORE reduces the number of OIE extractions by 65%, while increasing the relative amount of informative extractions by 5.75%.", "sentence2": "table 2 summarizes statistics on FOBIE.", "label": "neutral"}
{"id": "test_3024", "sentence1": "To enrich the discourse argument representations, we exploit multi-level encoder shown in Figure 2 to learn the argument representations at the different levels.", "sentence2": "in this section, we give an overview of the TransSdriven joint learning framework, which consists of four parts: embedding layer, multi-level encoder, latent geometric structure learning, and semantic feature learning, as shown in Figure 1.", "label": "neutral"}
{"id": "test_3025", "sentence1": "Parent ignoring Due to the lack of parallel corpora with gold-standard parses, we rely on noisy annotations from an external parser.", "sentence2": "to compare with previous work, we train our models on WMt16 En-De and WAt En-Ja tasks, removing sentences in incorrect languages from WMt16 data sets.", "label": "neutral"}
{"id": "test_3026", "sentence1": "Unless otherwise specified, we first tokenize the data with Moses (Koehn et al., 2007) and remove sentences longer than 80 tokens in either source or target side.", "sentence2": "the performance of syntactic parsers drops abruptly when evaluated on out-of-domain data (Dredze et al., 2007).", "label": "neutral"}
{"id": "test_3027", "sentence1": "Compared with the individual models, our model is slightly better for Fr/Es-En in many-to-one scenario.", "sentence2": "then we use the two embeddings to augment the self-attention mechanism which transforms the Encoder representation into the shared semantic space.", "label": "neutral"}
{"id": "test_3028", "sentence1": "Compared with the INTL baseline, the REC training objective can further improve the translation quality of both supervised and zero-shot language pairs.", "sentence2": "so recent efforts in multilingual NMT mainly focus on enlarging the model capacity, either by introducing multiple Encoders and Decoders to handle different languages (Firat et al., 2016;Zoph and Knight, 2016), or enhancing the attention mechanism with language-specific signals (Blackwood et al., 2018).", "label": "neutral"}
{"id": "test_3029", "sentence1": "Because this decade often contributed strongly to the most frequent age category (25-54), predictions did not differ as much from gold in the previous test.", "sentence2": "demographic factors (age, gender, etc.) all manifest in language, and therefore influence style: we do not expect a 6-year old to sound\nlike an adult, and would not translate a person to seem differently gendered.", "label": "neutral"}
{"id": "test_3030", "sentence1": "This highlights a more general problem with template-based probing, namely, that the unnatural lack of sentence diversity imposed by the templates imposes unintended regularity for models to latch onto.", "sentence2": "average surprisal was computed for each model for each test set, then each model was adapted to (\"primed for\") each sentence type.", "label": "neutral"}
{"id": "test_3031", "sentence1": "The annotator judgements are relative (amount of decrease/increase in suspense from sentence to sentence), but the model predictions are absolute values.", "sentence2": "these baselines also reflect how much change occurs from one sentence to the next in a story: WordOverlap is the Jaccard similarity between the two sentences, GloveSim is the cosine similarity between the averaged Glove (Pennington et al., 2014) word embeddings of the two sentences, and GPtSim is the cosine similarity between the GPt embeddings of the two sentences.", "label": "neutral"}
{"id": "test_3032", "sentence1": "Given a probability distribution over possible next sentences P(e i t+1 ), we calculate the entropy of that distribution.", "sentence2": "the Ely model is more in line with the second view that uncertainty matters less than consequentially different outcomes.", "label": "neutral"}
{"id": "test_3033", "sentence1": "We categorize the factual errors made by the two models.", "sentence2": "fACTE-DITOR can seldomly make such errors.", "label": "neutral"}
{"id": "test_3034", "sentence1": "The summarizer refines the FINDINGS word representation based on salient ontology word representation encoded by a separate encoder.", "sentence2": "we also evaluated the inter-rater agreement using Fleiss' Kappa (Fleiss, 1971) for our system's scores and obtained 52% for readability, 47% for accuracy, and 50% for completeness, all of which are characterized as moderate agreement rate.", "label": "neutral"}
{"id": "test_3035", "sentence1": "Our work differs in that we hypothesize that all of the ontological terms in the FINDINGS are not equally important, but there is a notion of odds of saliency for each of these terms; thus, we focus on refining the FINDINGS representations.", "sentence2": "73% (readability), and 71% (accuracy) of our system-generated Impressions ties with human-written Impressions, both achieving full-score of 3; nonetheless, this percentage is 62% for completeness metric.", "label": "neutral"}
{"id": "test_3036", "sentence1": "ConceptFlow utilizes it to model the conversation and guide the response generation.", "sentence2": "con-ceptFlow indicates the filtered two-hop graph.", "label": "neutral"}
{"id": "test_3037", "sentence1": "Apart from standard vector embeddings, we also experiment with contextualized ELMo (Peters et al., 2018) embedding with the DA model using the version implemented in AllenNLP (Gardner et al., 2017).", "sentence2": "A linear classifier using features inspired by Heilman and Smith (2010) and Wan et al. (2006), who have implemented similar linear models for other sentence pair classification tasks.", "label": "neutral"}
{"id": "test_3038", "sentence1": "We perform a human evaluation similar to \u00a73.2 on this sample.", "sentence2": "next, we developed an annotation task on Amazon Mechanical Turk to select the best responses for the questions.", "label": "neutral"}
{"id": "test_3039", "sentence1": "Softmax: We will discuss in \u00a72.3 that annotators are expected to miss a few good responses since good and bad answers are often very similar (may only differ by a single preposition or pronoun).", "sentence2": "furthermore, the D-GPT model with oracle answers is able to generate conversational responses on the CoQA dev set 77 % of the time showcasing the model's scalability.", "label": "neutral"}
{"id": "test_3040", "sentence1": "Sample of responses from different models on SQuAD-dev-test set \u00a73.2. \u201dQ:\u201d is the Question, \u201dR:\u201d is the Response, \u201dB.\u201d stands for baseline and \u201d(o)\u201d stands for oracle answer spans.", "sentence2": "we observe that it does very well in option b (i.e. correct answer but not a complete-sentence).", "label": "neutral"}
{"id": "test_3041", "sentence1": "The resulting SG data split is summarized in Table 1.", "sentence2": "we explore a ranking objective that calculates errors based on the margin with which incorrect responses are ranked above correct ones (Collins and Koo, 2005).", "label": "neutral"}
{"id": "test_3042", "sentence1": "To fulfill this goal, we come up a label guessing method to generate labels for the unlabeled data in the training process.", "sentence2": "since the combination is continuous, TMix has the potential to create infinite mount of new augmented data samples, thus can drastically avoid overfitting.", "label": "neutral"}
{"id": "test_3043", "sentence1": "Both measures are significantly lower for the depressed class for responses to starters, but not to backchannels.", "sentence2": "accurately diagnosing depression is difficult-requiring time-intensive interviews, assessments, and analysis.", "label": "neutral"}
{"id": "test_3044", "sentence1": "For example, exploring correlations between counselor-patient interaction dynamics and counseling outcomes (Althoff et al., 2016); studying linguistic development of mental healthcare counsellors (Zhang et al., 2019); identifying differences in how people disclose mental illnesses across gender and culture (De Choudhury et al., 2017); predicting a variety of mental health conditions from social media posts (Sekulic and Strube, 2019;De Choudhury et al., 2013a;Guntuku et al., 2019;Coppersmith et al., 2014); and analyzing well-being (Smith et al., 2016) and distress (Buechel et al., 2018).", "sentence2": "we hope that this combination will encourage the research community to make more progress in this direction.", "label": "neutral"}
{"id": "test_3045", "sentence1": "Entropy threshold S = 0 is the baseline, and all samples exit at the last layer; as S increases, gradually more samples exit earlier.", "sentence2": "an inference sample can exit earlier at an off-ramp, without going through the rest of the transformer layers.", "label": "neutral"}
{"id": "test_3046", "sentence1": "Responses are processed in batches of 8 and are padded/truncated to a length of 128.", "sentence2": "difference in ASR quality has a bigger influence on the RMSE when using an LSTM encoder compared to a BERT encoder.", "label": "neutral"}
{"id": "test_3047", "sentence1": "There have been other efforts in document representation learning such as extensions of word vec\u0002tors to documents (Le and Mikolov, 2014; Ganesh et al., 2016; Liu et al., 2017; Wu et al., 2018; Gysel et al., 2017), convolution-based methods (Liu et al., 2018; Zamani et al., 2018), and variational autoencoders (Holmer and Marfurt, 2018; Wang et al., 2019).", "sentence2": "note that SPECTER will not be further fine-tuned on any of the tasks; we simply plug in the embeddings as features for each task.", "label": "neutral"}
{"id": "test_3048", "sentence1": "There were a total of 9 parameter combinations.", "sentence2": "citeomatic also performs well on the citation tasks, as expected given that its primary design goal was citation prediction.", "label": "neutral"}
{"id": "test_3049", "sentence1": "Note that methods like SGC cannot be used in real-world setting to embed new papers that are not cited yet.", "sentence2": "While the fact that SPEcTER does not require finetuning makes its paper embeddings less costly to use, often the best performance from pretrained Transformers is obtained when the models are finetuned directly on each end task.", "label": "neutral"}
{"id": "test_3050", "sentence1": "The latter needs thousands of times more computation to attain the same level of performance as the former.", "sentence2": "Since no off-the-shelf C++ parser extracts the information we need from code pieces, we implement our own primary expression parser to extract high level control information.", "label": "neutral"}
{"id": "test_3051", "sentence1": "This heavily depends on the underlying model to generate potentially correct code pieces.", "sentence2": "this dataset consists of C++ solutions to problems from Codeforces, a competitive programming website, along with the input-output test cases used for each problem to evaluate correctness.", "label": "neutral"}
{"id": "test_3052", "sentence1": "Finally, we build a non-auto model that performs SQG in an nonautoregressive way, i.e., each question is generated in parallel.", "sentence2": "it is worth noticing that all models get rather poor performances under these two aspects, indicating that making a concise question meaningful (i.e., targeting on given answers) with more information from input passage (i.e., performing proper information elimination) is a major challenge in SQG.", "label": "neutral"}
{"id": "test_3053", "sentence1": "Does training on premise encoded as structure help?", "sentence2": "in the Dev set, the model performs poorly for the knowledge & common sense, multi-row, coreference, and temporal reasoning categories.", "label": "neutral"}
{"id": "test_3054", "sentence1": "We see that when n is close to or exceeds the average phone duration (n \u2265 5), an evident reduction in L f after adding L r is observed, which validates the effectiveness of L r in assisting with the optimization of L f .", "sentence2": "here  we will only focus on analyzing the phonetic content contained in a representation, and leave other properties such as speaker for future work.", "label": "neutral"}
{"id": "test_3055", "sentence1": "For example, PLANENC misses \"Buzz Aldrin\" and also wrongly expresses the subject of \"retirement\" as \"Frank Borman\", indicating that LSTM is less powerful at capturing the semantic roles of entities.", "sentence2": "to narrow this gap, we propose DUA-LENC, a dual encoding model that can not only incorporate the graph structure, but can also cater to the linear structure of the output text.", "label": "neutral"}
{"id": "test_3056", "sentence1": "s and o are identified by their entity mentions, and p is identified by a unique ID.", "sentence2": "we remove all one-triple instances for planner's evaluation since the planning for these instances is trivial.", "label": "neutral"}
{"id": "test_3057", "sentence1": "For the SEEN set, the most competitive models are GRU and Transformer.", "sentence2": "for the plan encoder, we use the final state H T of LSTM as the context representation.", "label": "neutral"}
{"id": "test_3058", "sentence1": "We train the discriminator on the normalized hidden representations generated by each sentence Z = z/||z|| 2 .", "sentence2": "In addition, Adel et al. (2018) used an adversarial loss for getting better sentence representation.", "label": "neutral"}
{"id": "test_3059", "sentence1": "This can be replaced by context-aware embeddings.", "sentence2": "when dealing with low resource datasets, transfer learning is a common solution.", "label": "neutral"}
{"id": "test_3060", "sentence1": "To speed up the training process, we employ mix-precision training technique.", "sentence2": "the basic idea behind the connection of two categories of models is similar to MADE (Germain et al., 2015).", "label": "neutral"}
{"id": "test_3061", "sentence1": "For Wikitext103 dataset, the context length is set to 128, and each context containing multiple coherent sentences.", "sentence2": "for GPT, the input text can only be placed in the beginning and the generation process become uncontrollable, resulting in generating sentences with topic drift.", "label": "neutral"}
{"id": "test_3062", "sentence1": "Fed with X as input, the final output of the Transformer, denoted as H = {h 1 , h 2 , ..., h N }, captures the contextual representation of the tokens in the sequence.", "sentence2": "for PPL on One-Billion Words, the performances of u-PMLM and BERT are not satisfactory in comparison with GPT.", "label": "neutral"}
{"id": "test_3063", "sentence1": "B-TSort consistently performs better on all the metrics.", "sentence2": "the classifier is trained to predict whether s 2 follows s 1 or not i.e the the classifier predicts the constraint s 1 < s 2 .", "label": "neutral"}
{"id": "test_3064", "sentence1": "One defense is to subject pre-trained weights to standard security practices for publicly distributed software, such as checking SHA hash checksums.", "sentence2": "training these large models is computationally prohibitive, and thus practitioners generally resort to downloading pre-trained weights from a public source.", "label": "neutral"}
{"id": "test_3065", "sentence1": "A closely related topic are adversarial attacks, first investigated by Szegedy et al. (2013) and Goodfellow et al. (2015) in computer vision and later extended to text classification (Papernot et al., 2016; Ebrahimi et al., 2018b; Li et al., 2018; Hos\u0002seini et al., 2017) and translation (Ebrahimi et al., 2018a; Michel et al., 2019).", "sentence2": "we conclude that the position of the trigger keyword has minimal effect on the success of the attack.", "label": "neutral"}
{"id": "test_3066", "sentence1": "They are only understood by a limited set of people, because they require domain knowledge.", "sentence2": "they provide an overview of what characterizes technical vocabulary, and observe two main categories.", "label": "neutral"}
{"id": "test_3067", "sentence1": "A consolidated representation is finally achieved by a linear combination of the outputs from these N different GCNs.", "sentence2": "mOH-X is more focused and VmWEs, for the most part, coincide with the target verb.", "label": "neutral"}
{"id": "test_3068", "sentence1": "Analysis on the influence of the composition of S, i.e., instance numbers of two types, is presented in Section 4.5.", "sentence2": "6 volunteers are asked to select user-posed questions and the corresponding review sentences that can serve as answers.", "label": "neutral"}
{"id": "test_3069", "sentence1": "The preliminary neural QG models (Du et al., 2017; Zhou et al., 2017; Du and Cardie, 2017) outperform the rule-based methods relying on hand-craft features, and thereafter vari\u0002ous models have been proposed to further improve the performance via incorporating question type (Dong et al., 2018), answer position (Sun et al., 2018), long passage modeling (Zhao et al., 2018b), question difficulty (Gao et al., 2019), and to the point context (Li et al., 2019).", "sentence2": "we adapt the Seq2Seq model for the aspect-focused generation model, which is updated gradually via the transferred and augmented instances.", "label": "neutral"}
{"id": "test_3070", "sentence1": "In each iteration of the algorithm, the generator is trained with current S, and then S is adapted accordingly.", "sentence2": "one major challenge of this generation task is the lack of training data, i.e.", "label": "neutral"}
{"id": "test_3071", "sentence1": "In each iteration of the algorithm, the generator is trained with current S, and then S is adapted accordingly.", "sentence2": "the most relevant review sentence for each question is retrieved via BM25 method, and such review-question pairs are added into the training set.", "label": "neutral"}
{"id": "test_3072", "sentence1": "We also present a method of generating this adversarial training set in linear time by making use of the adversarial examples' inflectional distribution to perform weighted random sampling.", "sentence2": "the difference becomes significant if we look only at the SQuAD 2.0-fine-tuned models' performance on answerable questions (7% difference).", "label": "neutral"}
{"id": "test_3073", "sentence1": "This is reasonable as the \"O\" labels by far make up the majority of all labels in NER datasets.", "sentence2": "vector representations are obtained for each unique word in the datasets.", "label": "neutral"}
{"id": "test_3074", "sentence1": "The reward R((y), y) is the nondifferentiable evaluation metric, i.e., BLEU and ROUGE (details are in Section 7).", "sentence2": "if the copying operation is selected, then a type-restricted copying mechanism is enabled to restrict the search space by masking down the illegal grammar types.", "label": "neutral"}
{"id": "test_3075", "sentence1": "Our proposed Type-associated Encoder is designed as a variant N -ary Tree-LSTM.", "sentence2": "our proposed framework also verifies the necessity of the type information in the code translation related tasks with a practical framework and good results.", "label": "neutral"}
{"id": "test_3076", "sentence1": "Operation Selection Stage: Operation Selection Stage determines either using the copying operation or the generation operation to select the words based on the attention vector and hidden states from the encoder.", "sentence2": "Xu et al. (2018b) considers a SQL query as a directed graph and adopts a graph-to-sequence model to encode the global structure information.", "label": "neutral"}
{"id": "test_3077", "sentence1": "Although it is possible to train our framework by using the maximum likelihood estimation (MLE) method which constructs pseudo-labels or marginalize all the operations in the operation selection stage (Jia and Liang, 2016;Gu et al., 2016), the loss-evaluation mismatch between MLE loss for training and non-differentiable evaluation metrics for testing lead to inconsistent results (Keneshloo et al., 2019;Ranzato et al., 2015).", "sentence2": "for the case in SQL, the keyword \"Otkrytie Area\" is missing in all the baselines but accurately generated by our framework.", "label": "neutral"}
{"id": "test_3078", "sentence1": "The incorporation of pseudo-tags is a standard technique widely used in the NLP community, (Rico et al., 2016; Melvin et al., 2017).", "sentence2": "these results support the claim that explicit operations for defining K virtual models have a significant effect for a single model and are complementary to normal dropout.", "label": "neutral"}
{"id": "test_3079", "sentence1": "We followed the instructions of the task settings used in CoNLL-2000 andCoNLL-2003.", "sentence2": "nORMALEnS produced the best results in this setting.", "label": "neutral"}
{"id": "test_3080", "sentence1": "The two results are from the state-of-the-art system on the WMT2017 test set, which is selected based on METEOR.", "sentence2": "finally, these representations provide an attention-based context vector for the decoder.", "label": "neutral"}
{"id": "test_3081", "sentence1": "To deal with this issue, in this paper, we propose a novel graph-based multi-modal fusion encoder for NMT.", "sentence2": "we then stack multiple graph-based multi-modal fusion layers that iteratively perform semantic interactions to learn node representations.", "label": "neutral"}
{"id": "test_3082", "sentence1": "Since the size of training corpus is small and the trained model tends to be over-fitting, we first perform a small grid search to obtain a set of hyper-parameters on the En\u21d2De validation set.", "sentence2": "our multi-modal NMT model significantly outperforms several competitive baselines.", "label": "neutral"}
{"id": "test_3083", "sentence1": "Non-autoregressive neural machine translation (NAT) predicts the entire target sequence simultaneously and significantly accelerates inference process.", "sentence2": "step\" denotes the average number of decoding steps.", "label": "neutral"}
{"id": "test_3084", "sentence1": "We thank the anonymous reviewers for their valuable feedback.", "sentence2": "Besides, the correlations of labels (e.g. hierarchical label structures (Banerjee et al., 2019)) and the existence of tail labels make MLC a hard task (Bhatia et al., 2015).", "label": "neutral"}
{"id": "test_3085", "sentence1": "Extensive experiments are conducted on four benchmark datasets.", "sentence2": "adaptive routing is also applied with the maximum candidate label number set equally to 200.", "label": "neutral"}
{"id": "test_3086", "sentence1": "Since NER is not the focus of this study, the readers can choose the public Chinese NER API 4 from Baidu for fast experiments.", "sentence2": "interpretability is very important in the Ai-empowered healthcare studies.", "label": "neutral"}
{"id": "test_3087", "sentence1": "Besides the patient's basic information like name, age and gender, an EMR document contains Chief Complaint (CC), History of Present Illness (HPI), Physical Examination (PE), Test Reports (TR, e.g.", "sentence2": "upper Respiratory Infection (uRI) is easy to diagnose because it causes throat pain and rhinorrhea unlike the other respiratory diseases.", "label": "neutral"}
{"id": "test_3088", "sentence1": "In the offline processing of the EMR corpus, we preserved the Top-K most frequent entities of all types as the entity vocabulary.", "sentence2": "it is very hard for computers to automatically understand all the diverse sections and capture the key information before making an appropriate diagnosis.", "label": "neutral"}
{"id": "test_3089", "sentence1": "Similar conclusions can be drawn when comparing ECPE-2D (Inter-CE) and ECPE-2D (Inter-CE+WC/CR) as well as ECPE-2D(Inter-EC) and ECPE-2D(Inter-EC+WC/CR).", "sentence2": "the above results again demonstrate the effectiveness of the proposed 2D transformer.", "label": "neutral"}
{"id": "test_3090", "sentence1": "Early stance detection methods were concentrated on debates (Thomas et al., 2006;Somasundaran and Wiebe, 2009;Walker et al., 2012).", "sentence2": "the second error category is caused by special hashtags with implicit meanings.", "label": "neutral"}
{"id": "test_3091", "sentence1": "For each word w t , we extract the corresponding entity from SE-graph by performing n-gram matching and acquire a subgraph representation M 0 t .", "sentence2": "first, we utilize the whole words from the semantic lexicon SenticNet (Cambria et al., 2018) as the word-nodes and add edges between the semantic words that capture the wordword semantic connections.", "label": "neutral"}
{"id": "test_3092", "sentence1": "In this paper, we proposed a Semantic-Emotion Knowledge Transferring (SEKT) model for cross-target stance detection, which uses the external knowledge (semantic and emotion lexicons) as a bridge to enable knowledge transfer across different targets.", "sentence2": " For example, Augenstein et al. (2016) proposed a bidirectional conditional encoding method by incorporating the target to learn the target-specific words.", "label": "neutral"}
{"id": "test_3093", "sentence1": "The data in different domains usually shares certain background knowledge that can possibly be transferred from the source domain to the target domain.", "sentence2": "instead of leveraging only the input context in each BiLSTM unit, we take external commonsense knowledge into consideration by adding a novel knowledge-aware memory unit to the BiL-STM, which dynamically controls the amount of external knowledge at each encoding step and thus balances the contextual and knowledge information for stance detection.", "label": "neutral"}
{"id": "test_3094", "sentence1": "The SE-graph can capture the semantic connections between words and emotion tags with multihop connections.", "sentence2": "we randomly select 100 instances that are incorrectly predicted by SEKT from the expanded SemEval-2016 dataset.", "label": "neutral"}
{"id": "test_3095", "sentence1": "For domain-exclusive graphs, approaches include SSL with GCNs (Shen and Chung, 2019) and domainadversarial learning (Dai et al., 2019).", "sentence2": "rather than using explicit divergence measures or domain-adversarial losses for domain invariance, we uniquely adopt a shared-autoencoder strategy on GCNs.", "label": "neutral"}
{"id": "test_3096", "sentence1": "In conclusion, if we would like to observe the desirable behavior as discussed for the attention mechanism, it is important for us to choose an appropriate \u03bb value or we shall possibly find ways to control the value of VTW6 .", "sentence2": "their corresponding attention scores may end up with large positive scores eventually.", "label": "neutral"}
{"id": "test_3097", "sentence1": "We show the tracked gradient norms on all datasets in Figure 5.", "sentence2": "the vocabulary size for PtB/Yelp/Yahoo is 10K/15K/20K.", "label": "neutral"}
{"id": "test_3098", "sentence1": "it is a myth that the UNK of the war is not a war , but it is not possible to be able to see the war .", "sentence2": "the (coupled) posterior network and the (coupled) decoder are additionally conditioned.", "label": "neutral"}
{"id": "test_3099", "sentence1": "The upper bound follows the same derivation.", "sentence2": "in this paper, we propose a structure-free certified defense method that applies to arbitrary models that can be queried in a black-box fashion, without any requirement on the model structures.", "label": "neutral"}
{"id": "test_3100", "sentence1": "We hypothesise that exposure bias (Ranzato et al., 2016), a discrepancy between training and inference, makes this problem worse.", "sentence2": "the model trained with teacher forcing may over-rely on previously predicted words, which would exacerbate error propagation.", "label": "neutral"}
{"id": "test_3101", "sentence1": "Over time, the number of such initiatives grew substantially, e.g., at the time of writing, the Duke Reporters' Lab lists 237 active fact-checking organizations plus another 92 inactive.", "sentence2": "we can see that, for PolitiFact, only 27% of the pairs have a similarity score that is above 0.25, while for Snopes, this percentage is at 50%, which suggests Snopes should be easier than PolitiFact.", "label": "neutral"}
{"id": "test_3102", "sentence1": "We used information from it to create a second dataset, this time focusing on tweets.", "sentence2": "We propose a learning-to-rank model that achieves sizable improvements over state-ofthe-art retrieval and textual similarity models.", "label": "neutral"}
{"id": "test_3103", "sentence1": "We can see on line 1 of Table 1 a trivial case, where the verified claim is identical to the input claim; however, such cases are not very frequent, as the experiments with the BM25 baseline in Section 7 below will show.", "sentence2": "we further try semantic matching using BERT.", "label": "neutral"}
{"id": "test_3104", "sentence1": "Here, we aim to bridge this gap.", "sentence2": "In section 3, we discussed that matching some of the input claims with the corresponding verified claims can be a non-trivial task, and we gave examples of easy and hard cases.", "label": "neutral"}
{"id": "test_3105", "sentence1": "Going one step further, to further validate the actions, we input the texts into our transition system to obtain the \"pseudo-gold\" emotion-cause pairs P based on the annotation, which can give us the correct action to take for a given parse state.", "sentence2": "besides, action history is stored to a list A.", "label": "neutral"}
{"id": "test_3106", "sentence1": "Different from the traditional emotion analysis, which aims to identify emotion categories in text.", "sentence2": "the acyclicity and single-head constraints are not necessary for our model, as arbitrary graphs are allowed.", "label": "neutral"}
{"id": "test_3107", "sentence1": "Firstly, in the same unimodal task, the results under unimodal labels are better than those under multimodal labels.", "sentence2": "in this part, we only report the results in MLF-DNN.", "label": "neutral"}
{"id": "test_3108", "sentence1": "\"M, A\" as an example, the sub-network of subtask \"A\" is supervised by multimodal loss and unimodal loss.", "sentence2": "Zadeh et al. (2018a) designed a memory fu\u0002sion network with a special attention mechanism for cross-view interactions.", "label": "neutral"}
{"id": "test_3109", "sentence1": "Besides, we introduce three late-fusion models into this framework as strong baselines for SIMS.", "sentence2": "sIMs has three modalities and unimodal annotations except for multimodal annotations for each clip.", "label": "neutral"}
{"id": "test_3110", "sentence1": "This contextual contrast and semantic association information acquired, in turn, can provide salient evidence to interpret the detection of multimodal sarcasm.", "sentence2": "the D-Net breaks down the raw visual or textual representation into a shared subspace and unique visual or textual subspace through three layers.", "label": "neutral"}
{"id": "test_3111", "sentence1": "Our proposed ANP-aware cross-modality attention mechanism explicitly calculates the cross interactive attention between text words and image ANPs, providing the explainable reasoning evidence for sarcasm detection.", "sentence2": "we encode the multimodal inputs into 200-dimensional hidden space, and set the dimension of invariant shared feature to 40, the dimension of unique variant contrast feature to 40, Finally, we optimize our model by Adam update rule with learning rate 0.01, mini-batch 128, and weight of orthogonal loss 0.5.", "label": "neutral"}
{"id": "test_3112", "sentence1": "In Fig.4b, our model pays more attention to the textual phrase 'these lovely books' with stupid sign, strange sign, and bad sign ANPs which refer to the emoji in the attached image.", "sentence2": "sarcasm is a sophisticated linguistic phenomenon, defined by Merriam-Webster Dictionary as 'The use of words that mean the opposite of what you really want to say, especially in order to insult someone, to show irritation, or to be funny'.", "label": "neutral"}
{"id": "test_3113", "sentence1": "Our work focus on the multimodal sarcasm detection using image and text modalities.", "sentence2": "To tackle the above challenges, in this paper, we propose a novel method to model both cross\u0002modality contrast and semantic association by con\u0002structing the Decomposition and Relation Network (i.e. D&R Net) for multimodal sarcasm detection task.", "label": "neutral"}
{"id": "test_3114", "sentence1": "To examine the generality of our evaluation method, we conduct experiments on two NMT systems, i.e. RNN-SEARCH (de\u0002noted by RNN) and TRANSFORMER (denoted by Trans.), both of which are implemented with fairseq (Ott et al., 2019).", "sentence2": "It is worth noting that Arras et al. (2016); Denil et al. (2014) directly measure the performance of the target model P on the extracted words with\u0002out constructing Q to evaluate explanation meth\u0002ods for classification tasks. H", "label": "neutral"}
{"id": "test_3115", "sentence1": "Each human coder segmented talk turns into utterances (i.e., complete thoughts) and assigned one code per utterance for all utterances in a session.", "sentence2": "here  we also compare our model to the multimodal approach proposed by (Singla et al., 2018; Chen et al., 2019) where they use word-level prosodic features along with lexical word embeddings.", "label": "neutral"}
{"id": "test_3116", "sentence1": "Models trained on the current interval are used to predict users' opinions in the next interval.", "sentence2": "inspired by the multivariate Hawkes process (Aalen et al., 2008; Du et al., 2016), we propose to model a user's posting behaviour by a temporal point process that when user u posts a tweet d at time t, they need to decide on whether they want to post a new topic/opinion, or post a topic/opinion influenced by past tweets either posted by other users or by themselves.", "label": "neutral"}
{"id": "test_3117", "sentence1": "Text style transfer consists of rewriting a sentence from a given style s i (e.g., informal) into a different style s j (e.g., formal) while maintaining the content and keeping the sentence fluent.", "sentence2": "the main difference between our approach and these previous work consists in the fact that we use the feature matching loss to perform distribution matching.", "label": "neutral"}
{"id": "test_3118", "sentence1": "This loss consists of matching statistics of the features for each style separately.", "sentence2": "gANs fail to train when a very deep network is used as the discriminator Moreover, SeqgFMN also outperforms gAN generators even when shallow word embeddings (glove / FastText) are used to perform feature matching.", "label": "neutral"}
{"id": "test_3119", "sentence1": "We adopt the metrics from the referred papers.", "sentence2": "oDQA: (1) For each question, DSQA (Lin et al., 2018) aggregates multiple relevant paragraphs from ClueWeb09, and then infers an answer from these paragraphs.", "label": "neutral"}
{"id": "test_3120", "sentence1": "The third stage must be run for each variant separately.", "sentence2": "furthermore, rare words are not well represented in commonly used downstream task datasets.", "label": "neutral"}
{"id": "test_3121", "sentence1": "These approaches exploit either the contexts in which rare words occur (Lazaridou et al., 2017; Herbelot and Baroni, 2017; Khodak et al., 2018; Liu et al., 2019a), their surfaceform (Luong et al., 2013; Bojanowski et al., 2017; Pinter et al., 2017), or both (Schick and Schutze, 2019a,b; Hautte et al., 2019).", "sentence2": "We evaluate BERTRAM on the WNLaMPro dataset (Schick and Schutze , 2020).", "label": "neutral"}
{"id": "test_3122", "sentence1": "Nevertheless, Schick and Schutze (2020) recently showed that BERT's (Devlin et al., 2019) performance on a rare word probing task can be significantly improved by explicitly learning representations of rare words using Attentive Mimicking (AM) (Schick and Schutze, 2019a).", "sentence2": "as it performs best for both the RaRE and MEDIUM subset, we always use the aDD configuration of BERTRaM in the following experiments.", "label": "neutral"}
{"id": "test_3123", "sentence1": "Knowing the Most Frequent Sense (MFS) of a word has been proved to help Word Sense Disambiguation (WSD) models significantly.", "sentence2": "our approach, in fact, achieves on average a significant improvement of approximately 9 F1 points over the existing state of the art.", "label": "neutral"}
{"id": "test_3124", "sentence1": "We randomly split this data into train (80%), dev (10%) and test (10%) sets.", "sentence2": "The heatmap in Figure 2 shows that emotions that are related in intensity (e.g. annoyance and anger, joy and excitement, nervousness and fear) have a strong positive correlation.", "label": "neutral"}
{"id": "test_3125", "sentence1": "In the past decade, NLP researchers made available several datasets for language-based emotion classification for a variety of domains and applications, including for news headlines (Strapparava and Mihalcea, 2007), tweets (CrowdFlower, 2016;, and narrative sequences (Liu et al., 2019), to name just a few.", "sentence2": "raters were free to select multiple emotions, but were asked to only select those ones for which they were reasonably confident that it is expressed in the text.", "label": "neutral"}
{"id": "test_3126", "sentence1": "Given the simplicity of that model, it performs surprisingly well.", "sentence2": "we want the parser to choose the transition sequence that would make the most out of this bad situation.", "label": "neutral"}
{"id": "test_3127", "sentence1": "It can also recognise garden-paths: if we are in a state that cannot generate the following word that means we are in a garden-path and will punish all transitions from that state.", "sentence2": "with MBR they all manage to outperform the non-incremental model.", "label": "neutral"}
{"id": "test_3128", "sentence1": "For metrics, we use FPED and FNED in IPTTS to evaluate how discriminatory the models are, and lower scores indicate better equality.", "sentence2": "although the method is reasonable, due to high cost, it is not always practical to add additional labeled data with specific identity-terms, as careful selection of the additional sentences w.r.t.", "label": "neutral"}
{"id": "test_3129", "sentence1": "Based on the theorem, in this paper, we propose to evaluate models under a distribution where the demographic identity information is not predictive of labels to unify the three widely-used criteria.", "sentence2": "aUC to all the other methods, indicating that our method does not hurt models' generalization ability very much.", "label": "neutral"}
{"id": "test_3130", "sentence1": "As the discrimination distribution is directly observable, estimating P (y|z) is not hard.", "sentence2": "recent research points out that there widely exist some unintended biases in text classification datasets.", "label": "neutral"}
{"id": "test_3131", "sentence1": "In one of the their experiments Alishahi et al. (2017) use a linear clas\u0002sifier to predict phonemes from local activation patterns of a grounded language learning model, where images and their spoken descriptions are pro\u0002cessed and mapped into a shared semantic space", "sentence2": "we find that in our setting, RSA applied to local representations shows low correlations between phonemes and neural activation patterns for both trained and randomly initialized target models, and for one of the target models the local diagnostic classifier only shows a minor difference in the decodability of phonemes from randomly initialized versus trained network.", "label": "neutral"}
{"id": "test_3132", "sentence1": "The user, convinced by the nicer-looking explanations, performs better using this system.", "sentence2": "despite the difference between the two criteria, many authors do not clearly make the distinction, and sometimes conflate the two.", "label": "neutral"}
{"id": "test_3133", "sentence1": "Vanilla LSTM: The model described in section 2.1 which uses the vanilla LSTM.", "sentence2": "the output predictions will not change much even if the attention weights are permuted.", "label": "neutral"}
{"id": "test_3134", "sentence1": "The idea of orthogonalizing representations in an LSTM have been used by (Nema et al., 2017) but they use a different diversity model in the context of improving performance of Natural Language Generation models In this work, we have analyzed why existing attention distributions can neither provide a faithful nor a plausible explanation for the model's predictions.", "sentence2": "there is little change in the vanilla LSTM model's output for several datasets suggesting that the attention weights are not so meaningful.", "label": "neutral"}
{"id": "test_3135", "sentence1": "Different from all these methods, in this work, we consider both the high-order connectivity information and latent preference factor underlying the user-news interactions.", "sentence2": "after obtaining the latent variables {r d,k }, we can find an estimate of z u,k by aggregating information from the clicked news, which is computed as Eq.", "label": "neutral"}
{"id": "test_3136", "sentence1": "We still adopt the Transformer (Vaswani et al., 2017) as our backbone, with a embedding size of 512 and FFN layer dimension of 1024.", "sentence2": "among existing NMT models, most of them are generally equipped with 4-8 encoder and decoder layers (Wu et al., 2016;  Vaswani et al., 2017).", "label": "neutral"}
{"id": "test_3137", "sentence1": "In this section, we introduce the details of the proposed approach, a MultiScale Collaborative (MSC) framework for constructing extremely deep NMT models.", "sentence2": "the 72-layer MSC exhibits higher training BLEU than the 36-layer counterpart and is generalizable to the validation data.", "label": "neutral"}
{"id": "test_3138", "sentence1": "Finally, as opposed to considering results across all possible E, dw, and wp, we first select those settings that maximize the Pearson correlation for each dimension.", "sentence2": "this variance is on display in the right-hand plot in Figure 5, which gives results for the blackness dimension.", "label": "neutral"}
{"id": "test_3139", "sentence1": "The measurements in our survey are compared to results from Smith-Lovin and Robinson (2015).", "sentence2": "three sets are characterized by salient trait similarities and differences on gender, age or race/ethnicity.", "label": "neutral"}
{"id": "test_3140", "sentence1": "And stronger correlations between the embedding and survey-based measures for Evaluation and Potency, relative to Activity, reflects the increased importance in affective perceptions of these two dimensions (Rogers et al., 2013).", "sentence2": "finally, we include three random identities as a mechanism for comparison in other work not described here.", "label": "neutral"}
{"id": "test_3141", "sentence1": "Here, we investigate the extent to which publicly-available word embeddings accurately reflect beliefs about certain kinds of people as measured via traditional survey methods.", "sentence2": "here, Figure 4B) shows a significant positive correlation between variance in the survey data along a dimension (and hence measurement accuracy) and that dimensions' importance in explaining patterns of labeling in our identity labeling task.", "label": "neutral"}
{"id": "test_3142", "sentence1": " (Rajani et al., 2019) We perform minimal processing, primarily deletion of any questions without a rationale or questions with rationales that were not possible to automatically map back to the underlying text.", "sentence2": "we build upon these methods in Section 4.", "label": "neutral"}
{"id": "test_3143", "sentence1": "However, for some datasets we have explicitly collected comprehensive rationales for at least a subset of the test set.", "sentence2": "more recent work has aimed to exploit rationales in training neural text classifiers.", "label": "neutral"}
{"id": "test_3144", "sentence1": "Towards this end, we first initialize the parameters of DeFormer with the parameters of a pretrained full Transformer, and fine-tune it on the downstream tasks.", "sentence2": "we measure the FLOPs and memory consumption through the TensorFlow Profiler.", "label": "neutral"}
{"id": "test_3145", "sentence1": "Previous QA neural models like BIDAF (Seo et al., 2016), QANet (Yu et al., 2018) and many others contain decomposition as part of their neural architecture design.", "sentence2": "the effectiveness of decomposition generalizes further beyond QA tasks as long as the input sequences are paired.", "label": "neutral"}
{"id": "test_3146", "sentence1": "For all experiments in this paper, we used RoBERTa (Liu et al., 2019), a state-of-the-art transformer-based method.", "sentence2": "after retrieving N parallel evidence chains, we take the union of all the individual justification sentences to create the supporting evidence text for that candidate answer.", "label": "neutral"}
{"id": "test_3147", "sentence1": "In QASC, which has a large KB4 of 17.4 million sentences), similar to Khot et al. (2019a) candidates are retrieved using the Heuristic+IR method which returns 80 candidate sentences for each candidate answer from the provided QASC KB.", "sentence2": "to extract N parallel chains, we run AIR N times, ensuring that the first justification sentences in each chain are different (in practice, we start a new chain for each justification in the top N retrieved sentences in the first hop).", "label": "neutral"}
{"id": "test_3148", "sentence1": "We detail these components in the next two sub-sections.", "sentence2": "highlighting strengths of AIR over the standard IR baselines.", "label": "neutral"}
{"id": "test_3149", "sentence1": "Access to such data can greatly facilitate investigation of phonetic typology at a large scale and across many languages.", "sentence2": "notice that phonemes that typically had high accuracy in Figure 6, such as /p/ and /b/, now have far more variable accuracy in Figure 8, suggesting difficulty in aligning the Unitran pronunciations to the correct parts of the audio.", "label": "neutral"}
{"id": "test_3150", "sentence1": "In fact, human perception of complexity is most affected by syntactic features related to sentence structure (Brunato et al., 2018).", "sentence2": "we have introduced ASSET, a new dataset for tuning and evaluation of SS models.", "label": "neutral"}
{"id": "test_3151", "sentence1": "We also included an example where all transformations were performed.", "sentence2": "results are reported in Table 5.", "label": "neutral"}
{"id": "test_3152", "sentence1": "Sentence Simplification (SS) consists in modifying the content and structure of a sentence to make it easier to understand, while retaining its main idea and most of its original meaning (Alva-Manchego et al., 2020).", "sentence2": "aSSET offers more variability, perhaps signalling that annotators consider deleting infor-mation as an important simplification operation.", "label": "neutral"}
{"id": "test_3153", "sentence1": "Crucially, our method is fully general and assumes only that the contextualized model maps word sequences to vector sequences.", "sentence2": "additionally, while most prior work has discussed the static embedding setting, recent work has considered sentence encoders and contextualized models.", "label": "neutral"}
{"id": "test_3154", "sentence1": "comparing downstream performance for models initialized using the static embeddings and the original contextualized representations).", "sentence2": "in this case, we back-offed to using the Decontextualized representation for w i .", "label": "neutral"}
{"id": "test_3155", "sentence1": "This pattern suggests that using bidirectional versus unidirectional context has more impact on distribution of context information than does depth or architecture type.", "sentence2": "we use several classifier architectures in our probing tasks, in order to explore the impact of classifier complexity on extraction of our target information types.", "label": "neutral"}
{"id": "test_3156", "sentence1": "Using similar methods to test syntactic awareness in BERT, Goldberg (2019) finds the model to perform almost at ceiling on syntactic tests.", "sentence2": "gLoVe embeddings are at chance on all words but the target word, while gPT embeddings are at chance before the target word, and pattern similarly to BERT afterwards in the object identity task.", "label": "neutral"}
{"id": "test_3157", "sentence1": "\"If we are unable to make payroll Oct. 19, we will definitely be able to make it next week Oct. 26 based on the nature of our sales taxes coming in at the end of the month.", "sentence2": "training on this new data yielded the state of the art on existing NLI benchmarks.", "label": "neutral"}
{"id": "test_3158", "sentence1": "CheckList provides a framework for such techniques to systematically evaluate these alongside a variety of other capabilities.", "sentence2": "further, neither is robust to typos or simple paraphrases.", "label": "neutral"}
{"id": "test_3159", "sentence1": "We applied the same process to very different tasks, and found that tests reveal interesting failures on a variety of task-relevant linguistic capabilities.", "sentence2": "\"behavioral testing\" (also known as black-box testing) is concerned with testing different capabilities of a system by validating the input-output behavior, without any knowledge of the internal structure (Beizer, 1995).", "label": "neutral"}
{"id": "test_3160", "sentence1": "We next conduct a thorough investigation of the similarities and differences between dialogue\u0002based and traditional relation extraction tasks by comparing DialogRE and the Slot Filling dataset (McNamee and Dang, 2009; Ji et al., 2010, 2011; Surdeanu, 2013; Surdeanu and Ji, 2014), and we argue that a relation extraction system should be aware of speakers in dialogues", "sentence2": "It has been shown that there is a longer distance between two arguments in the SF dataset (Surdeanu, 2013; Huang et al., 2017) compared to that in many widely used human-annotated relation extraction datasets such as ACE (Doddington et al., 2004) and SemEval (Hendrickx et al., 2010).", "label": "neutral"}
{"id": "test_3161", "sentence1": "While it is tempting to equate such information with the meaning of an utterance, a large body of literature in linguistics and psycholinguistics argues that an utterance conveys much more than a simple set of facts: it carries with it a halo of intimations arising from the speaker's choices, including considerations of perspective, emphasis, and framing.", "sentence2": "Systems following instructions also require a means of segmenting continuous sensorimotor data and linking it to discrete linguistic categories (Reg\u0002neri et al., 2013; Yagcioglu et al., 2018) (cf. the symbol grounding problem (Harnad, 1990)).", "label": "neutral"}
{"id": "test_3162", "sentence1": "For example, in \"of course, [we] 1 still have the [storm surge] 2 coming,\" given the context, we can reasonably infer discontent towards the \"storm surge\" despite the absence of polarizing words.", "sentence2": "intuitively, this makes sense as the decisions are only slightly better than being in complete disagreement (i.e., orthogonal).", "label": "neutral"}
{"id": "test_3163", "sentence1": "For example, in \"of course, [we] 1 still have the [storm surge] 2 coming,\" given the context, we can reasonably infer discontent towards the \"storm surge\" despite the absence of polarizing words.", "sentence2": "we introduce binary classification tasks, one for each Plutchik-8 emotion.", "label": "neutral"}
{"id": "test_3164", "sentence1": "Such a pattern has become prominent and is misleading the whole community.", "sentence2": "hence, we propose to use RANDOM evaluation scheme for all model performance comparisons.", "label": "neutral"}
{"id": "test_3165", "sentence1": "Several recently proposed methods report high performance gains on a particular dataset.", "sentence2": "from these results, we can draw similar conclusions as in Section 5.", "label": "neutral"}
{"id": "test_3166", "sentence1": "In Figure 3, we plot the ratio of neurons becoming zero after ReLU activation for the valid triplets vs. their normalized frequency on FB15k-237 dataset.", "sentence2": "we notice that several recent papers report very high performance, which largely outperforms previous state-of-the-art methods.", "label": "neutral"}
{"id": "test_3167", "sentence1": "Combined with inappropriate evaluation protocol, such methods reported inflated performance.", "sentence2": "bOTTOM evaluation protocol can be unfair to the model during inference time because it penalizes the model for giving the same score to multiple triplets, i.e., if many triplets have the same score as the correct triple, the correct triplet gets the least rank possible.", "label": "neutral"}
{"id": "test_3168", "sentence1": "Another line of work (Ning et al., 2019) explores the cost vs. benefit of collecting full vs. partial annotations for various structured predictions tasks.", "sentence2": "by providing intermediate reasoning steps explicitly, the annotations we collect help the model overcome some of these biases in the training data.", "label": "neutral"}
{"id": "test_3169", "sentence1": "We investigate the effects of spending a small additional budget, either by adding more QA pairs (from the biased data distribution) or by collecting intermediate annotations, on this bias.", "sentence2": "they do not focus on intermediate reasoning required to learn the task.", "label": "neutral"}
{"id": "test_3170", "sentence1": "Despite its simplicity, this yields competitive or even better performance than other sampling strategies.", "sentence2": "our method significantly improves the performance of RoBERTa-based models by 1-5% across datasets.", "label": "neutral"}
{"id": "test_3171", "sentence1": "Recent proposed approaches have made promising progress in dialogue state tracking (DST).", "sentence2": "in this section, we will describe DST-SC model in detail.", "label": "neutral"}
{"id": "test_3172", "sentence1": "Our model achieves significant improvements on two public datasets and shows effectiveness on relatedslot problem tests.", "sentence2": "ellipsis and reference phenomena among multi-domain slots are still less explored in existing literature.", "label": "neutral"}
{"id": "test_3173", "sentence1": "We use our partial classifiers to throw away a fraction \u03b1 of candidates, to increase throughput.", "sentence2": "depending on the values of k i , SR models with different trade-offs between accuracy and efficiency can be obtained.", "label": "neutral"}
{"id": "test_3174", "sentence1": "Asadi and Lin (2013) studied effectiveness/efficiency trade-offs with three candidate generation approaches.", "sentence2": "as we will show in Section 5, an opportune choice of a threshold and good accuracy of early classifiers ensure high probability of having at least one positive example in the candidate set for the last classifier of the cascade.", "label": "neutral"}
{"id": "test_3175", "sentence1": "First, most of these models are pre-trained on formal writing, which is notably different from colloquial writing in dialogue; thus, fine-tuning for the end tasks is often not sufficient enough to build robust dialogue models.", "sentence2": "for span-based QA where the evidence documents are in the form of multiparty dialogue, the performance is still poor even with the latest transformer models (Sun et al., 2019; Yang and Choi, 2019) due to the challenges in representing utterances composed by heterogeneous speakers.", "label": "neutral"}
{"id": "test_3176", "sentence1": "Recently, pretrained language representation models (Kocijan et al., 2019;Radford et al., 2019;Liu et al., 2019) have demonstrated significant improvements in both unsupervised and supervised settings.", "sentence2": "as the original purpose of proposing both WSC and WinoWhy is to evaluate how good current aI systems can understand commonsense knowledge rather than solve these questions by fitting the dataset, the unsupervised setting might be the more reasonable evaluation setting.", "label": "neutral"}
{"id": "test_3177", "sentence1": "Moreover, experimental results on different knowledge types prove that such a conclusion is universal rather than for a specific kind of knowledge.", "sentence2": "we divide all WSC questions based on how many knowledge types are required to solve these questions and show the result in Table 5.", "label": "neutral"}
{"id": "test_3178", "sentence1": "We set the hidden dimension to 128 for both clas-sifier and discriminator.", "sentence2": "they are only used during the test period.", "label": "neutral"}
{"id": "test_3179", "sentence1": "This is a multilingual sentiment classification dataset (Duh et al., 2011) in four languages, in-cluding English (en), French (fr), German (de), and Japanese (ja), covering three products (book, DVD, and music).", "sentence2": "we consider two views of input: (i) the encoded labeled documents from the source language; (ii) the encoded back-translations of the source documents from the target language.", "label": "neutral"}
{"id": "test_3180", "sentence1": "Recruiting assessors on Amazon Mechanical Turk (MTurk), they use intra-class correlation to estimate inter-rater agreement, with an average value of 0.42 over all topics, thus also indicating a poor reliability (Portney et al., 2009).", "sentence2": "the collected data and a reference implementation of our model are made available in form of the Webis-ArgQuality-20 corpus, one of the largest and most detailed corpora for pairwise argument quality.", "label": "neutral"}
{"id": "test_3181", "sentence1": "By example, going from x = 1, k = 16 to x = 1, k = 4 ends up at the same number of comparisons as x = 2, k = 8, but has a slightly higher ranking accuracy.", "sentence2": "we explore the lower bound of effort needed to infer labels of sufficient quality.", "label": "neutral"}
{"id": "test_3182", "sentence1": "To ensure some topic diversity and relevance of the arguments to the topic, while keeping the amount of judgments within our budget limits, we (1) indexed the args.me corpus using three retrieval models from the Terrier information retrieval library (Ounis et al., 2006) (namely BM25, DPH, and Dirich-letLM), (2) retrieved texts for 20 topic queries at a depth of 50 texts per topic per model, (3) and pooled all 3000 retrieved texts to remove overlap between the different models.", "sentence2": "we refrain from making a general suggestion for the choice of k. Thus, if the model is to be adapted to drastically different domains or item counts, exploratory studies are advised to estimate the quality tradeoff for a specific use case.", "label": "neutral"}
{"id": "test_3183", "sentence1": "More specifically, our ConKADI outperforms baseline models in terms of all metrics except BLEU-3 on the Chinese Weibo, and our ConKADI outperforms baseline models in terms of almost all metrics on the English Reddit.", "sentence2": "1) An entity word usually can refer to different concepts, i.e., an entity has multiple meanings, but only one specific concept is involved in a particular context.", "label": "neutral"}
{"id": "test_3184", "sentence1": "In fact, this issue comes from the unusual score distribution, e.g., the score function for some invalid triples gets the same values as the valid triples.", "sentence2": "it is useful to determine the importance of each neighbor for a specific query.", "label": "neutral"}
{"id": "test_3185", "sentence1": "We will leave the comparison and deep analysis in the future work.", "sentence2": "we thank anonymous reviewers for their thorough review comments on this paper.", "label": "neutral"}
{"id": "test_3186", "sentence1": "Please note that lower MR, higher MRR and Hits@10 indicate better performance.", "sentence2": "convE is limited by the number of interactions between the head and relation embeddings (Jiang et al., 2019; Vashishth et al., 2020).", "label": "neutral"}
{"id": "test_3187", "sentence1": "Pronoun-Focused Automatic Evaluation For the models in Table 3, we employ three types of pronoun-focused automatic evaluation: 1.", "sentence2": "when no context is used, there is a statistically significant drop in BLEU, while APT and F1-scores are equivalent to that of the baseline.", "label": "neutral"}
{"id": "test_3188", "sentence1": "We implement the approach with the LSTM-based recurrent network and use the following set of hyper parameters to train models: hidden size is 256, learning rate is 0.001, learning rate decay is 0.5, dropout is 0.3, batch size is 150.", "sentence2": "we evaluate our system on TABFACT (Chen et al., 2019), a large benchmark dataset for tablebased fact checking.", "label": "neutral"}
{"id": "test_3189", "sentence1": "In terms of the model efficiency, neural topic models can be trained much faster than HDP on a large corpus by GPU acceleration.", "sentence2": "for the batch size, the learning rate, and other model parameters, grid search is carried out on the training set to determine their optimal values and achieve the held-out performance.", "label": "neutral"}
{"id": "test_3190", "sentence1": "Unfortunately, it needs to traverse every word of all topics (i.e., threads) in the whole corpus when updating the topic-word distribution, rendering a large time cost for thread communication.", "sentence2": "gSM and gNB-NTM are slightly slower than others because the former introduces more parameters to model the topic-word distribution, while the latter introduces more sampling operations.", "label": "neutral"}
{"id": "test_3191", "sentence1": "To evaluate the quality of topics generated by different models, we use perplexity and topic coherence as evaluation criteria.", "sentence2": "nVDM, nVLDA, ProdLDA, and GSM are all neural topic models based on nVI.", "label": "neutral"}
{"id": "test_3192", "sentence1": "Then we run our NB-NTM and GNB-NTM on the entire 20News testing set to get the corresponding values of r. After normalization, the proportion of different topics obtained by NB-NTM and GNB-NTM at the corpus level is presented in Figure 4 (b) and Figure 4 (c), respectively.", "sentence2": "document modeling via mixed counting models is easy to interpret but difficult to infer.", "label": "neutral"}
{"id": "test_3193", "sentence1": "We use the variational lower bound to calculate gradients and apply Adam to update parameters of GNB-NTM, which are the same as NB-NTM.", "sentence2": "how to effectively integrate the distributed dependencies in mixed counting models into the framework of variational inference is still quite a challenging problem.", "label": "neutral"}
{"id": "test_3194", "sentence1": "Here again the issue is representing multiple entities at the same time, but with the additional requirement of representing the structural relationships between these entities.", "sentence2": "the rules were soon learned with statistical methods, followed by the use of neural networks to replace symbols with induced vectors, but the most effective models still kept structured representations, such as syntactic trees.", "label": "neutral"}
{"id": "test_3195", "sentence1": "But they still required linguistically-motivated designs to work well.", "sentence2": "boV representations are nonparametric representations, in that the number of vectors in the bag can grow arbitrarily large, and these vectors are exchangeable.", "label": "neutral"}
{"id": "test_3196", "sentence1": "We think that it is far more likely that we will be able to design neural architectures which induce multiple levels of representation than it is that we can ignore this problem entirely.", "sentence2": "lP/lR/F1: labelled constituent precision/recall/F-measure.", "label": "neutral"}
{"id": "test_3197", "sentence1": "In a more linguistically\u0002informed approach to the same problem, statistical models have been proposed for morphology induc\u0002tion (e.g. (Elsner et al., 2013)).", "sentence2": "attention-based models have variable binding, which sequential LSTMs do not.", "label": "neutral"}
{"id": "test_3198", "sentence1": "NMN estimates the similarities between entities to capture both the topological structure and the neighborhood difference.", "sentence2": "it follows a four-stage processing pipeline: (1) KG structure embedding, (2) neighborhood sampling, (3) neighborhood matching, and (4) neighborhood aggregation for generating embeddings.", "label": "neutral"}
{"id": "test_3199", "sentence1": "This is because there are many city entities for England which also have the three entities in their neighborhoods -e.g., the entity Birmingham.", "sentence2": "nMn achieves the best Hits@1 score on DBP15KZH\u2212EN , with a gain of 2.5% compared with RDGCn, and 5.4% over GMnn.", "label": "neutral"}
{"id": "test_3200", "sentence1": "Therefore, we first pretrain the GCN-based KG embedding model to produce quality entity representations.", "sentence2": "to evaluate different components of our model, we provide two implementation variants of NMN: (1) NMN (w/o nbr-m), where we replace the neighborhood matching part by taking the average of sampled neighbor representations as the neighborhood representation; and (2) NMN (w/o nbr-s), where we remove the sampling process and perform neighborhood matching on all one-hop neighbors.", "label": "neutral"}
{"id": "test_3201", "sentence1": "\"mIoU\" is the average IoU over all testing samples.", "sentence2": "after transforming moment annotations in NLVL dataset, we obtain a set of (V, Q, a) triples.", "label": "neutral"}
{"id": "test_3202", "sentence1": "Third, there is no risk of compounding errors as compared to the transitionbased approach.", "sentence2": "after the above procedures, there are still minor differences to PTB-Concat.", "label": "neutral"}
{"id": "test_3203", "sentence1": "The WSJ test set has 2416 sentences with arbitrary lengths, while WSJ10 consists of 7422 sentences of the whole WSJ corpora that contain no more than 10 words.", "sentence2": "unlike for transitionbased approaches (Kim et al., 2019b), for distancebased approaches there have been no studies examining the relationship between induced syntactic structure and human labeled syntactic structure, or whether human labeled syntactic trees can be used to improve language modeling (Dyer et al., 2016;Kim et al., 2019b).", "label": "neutral"}
{"id": "test_3204", "sentence1": "The idea is that an EDIT TREE is only valid if it can be applied to multiple given lemmas.", "sentence2": "we compare to one version of this baseline that has access to the ground-truth paradigm size (LB-Truth), and a second version which predicts the paradigm size as the average over the development languages (LB-Dev).", "label": "neutral"}
{"id": "test_3205", "sentence1": "An intuitive method to obtain additional lemmas would be to train a lemmatizer and to generate new lemmas from words in our corpus.", "sentence2": "note also that only the corpus and the lexicon can be accessed by our system, and no ground-truth morphological information (including paradigm size) is given.", "label": "neutral"}
{"id": "test_3206", "sentence1": "We utilize the same dataset (CamRest676 or Mul-tiWOZ) to train all the models for fair comparison.", "sentence2": "we do not substitute key words associated with slot values to maintain the dialog function of utterances.", "label": "neutral"}
{"id": "test_3207", "sentence1": "During testing, only the ground truth user utterances are used as input.", "sentence2": "for example, phrase dictionary (Cao et al., 2017) and semantic annotations (Wang et al., 2019) are used to assist the paraphrase model to improve the language quality.", "label": "neutral"}
{"id": "test_3208", "sentence1": "Besides, they need to logically correlate with the answers by deducing over multiple entities and relations in several sentences and paragraphs of the given text.", "sentence2": "with only limited labeled data, our model can effectively leverage unlabeled data to guide the generation.", "label": "neutral"}
{"id": "test_3209", "sentence1": "These data sets were collected by crowd-sourcing, consisting of 97k, 35k, and 97k examples, respectively.", "sentence2": "we first produce a segment based on the latent state z t , and then emits term with a length of l t on that segment.", "label": "neutral"}
{"id": "test_3210", "sentence1": "In speech translation, Sperber et al.  (2019) used the longest distance to the start node to indicate lattice structure, and Zhang et al.", "sentence2": "for lattice LSTM, our model has an average f1 improvement of 1.51 over it.", "label": "neutral"}
{"id": "test_3211", "sentence1": "Table 3 shows two metrics of three models on the devlopment set of Ontonotes and MSRA.", "sentence2": "due to NER's strong alignment of label and input, their model needs an RNN module for encoding.", "label": "neutral"}
{"id": "test_3212", "sentence1": "In this case, Q gen is similar to Q in that the item is somewhat related to Q gen , and there's a chance that I may be matched to Q gen due to keyword stuffing by sellers, or poor semantic matching.", "sentence2": "we also compare our model trained on the original training data and one augmented by naively adding the 3M matched pairs.", "label": "neutral"}
{"id": "test_3213", "sentence1": "Holding the great promise of deep neural networks in language and images, Transformer capitalizes on the stacked multi-headed self-attention mechanism based on the conventional encoderdecoder architecture in a sequence-to-sequence (seq2seq) manner to learn the global soft signals without explicit recurrence mechanism.", "sentence2": "To probe whether it is required to augment SDUs on each Transformer layer, we supplement gates on layer 1-3, layer 3-6, and layer 1-6 but removing gates on FFN components (denoted \u201c\\FFN\u201d) as in Table 5 (see Fig. 8 in Appendix B for detailed convergence curvatures).", "label": "neutral"}
{"id": "test_3214", "sentence1": " The de-identification performance of STACKED is comparable to the PIPELINE model, the de-identification performance of MULTITASK is slightly lower, however, we only found statis\u0002tically significant differences for the MULTITASK model for English.", "sentence2": "state-of-the-art methods for de-identification typically rely on recurrent neural networks (RNNs) (Dernoncourt et al., 2016;Lange et al., 2019b;Kajiyama et al., 2018).", "label": "neutral"}
{"id": "test_3215", "sentence1": "Newman-Griffis and Zirikly (2018) study the performance of RNNs for medical named entity recognition in the context of patient mobility and find that they benefit from domain adaption.", "sentence2": "Feutry et al. (2018) and Friedrich et al. (2019) create pseudo-de-identified text representations with adversarial training.", "label": "neutral"}
{"id": "test_3216", "sentence1": "The original data contains 1.1M multi-turn conversations.", "sentence2": "the second approach is to take a weighted average score of a seq2seq model trained on D and a language model trained on Dt when decoding responses.", "label": "neutral"}
{"id": "test_3217", "sentence1": "The seq2seq model S2S is trained on D as an indicator of how relevant each response is with the context.", "sentence2": "the model is still trained on the limited dialogue corpus which restricts its power at covering broad topics in opendomain chitchat.", "label": "neutral"}
{"id": "test_3218", "sentence1": "The user requests to book one ticket in the second example, yet both HDSA and Human Response ask about the number once again.", "sentence2": "a global vector is unable to capture the inter-relationships among acts, nor is it flexible for response generation especially when more than one act is mentioned.", "label": "neutral"}
{"id": "test_3219", "sentence1": "Extensive experiments demonstrate the superiority of MMT over state-of-the-arts, and continuous improvements can be achieved on different backbone networks on both supervised and unsupervised domain adaptation settings.", "sentence2": "only the \"similar\" source data will be beneficial for multi-source meta learning.", "label": "neutral"}
{"id": "test_3220", "sentence1": "However, multi-source meta learning alone cannot guarantee the desirable performance due to the data distribution gap between multiple sources and target data.", "sentence2": "while, the weaker backbone network is, the better improvement MMT can achieve.", "label": "neutral"}
{"id": "test_3221", "sentence1": "For example, the MMT(BERT-Base) improves BERT-Base over 14% on MCTEST.", "sentence2": "in this way, a more generalized representation could be obtained by considering multiple source datasets.", "label": "neutral"}
{"id": "test_3222", "sentence1": "In this experiment, we evaluate the transferability between different datasets and further give the suggestion on the source selection for MMT.", "sentence2": "multi-source meta learning alone cannot guarantee the desirable performance due to the data distribution gap between multiple sources and target data.", "label": "neutral"}
{"id": "test_3223", "sentence1": "This often led to a mismatch between ASR trained on data from the spoken domain, and MT trained on data from the written domain.", "sentence2": "models that do not suffer from erroneous early decisions will expectedly exhibit an advantage over other models especially for acoustically challenging inputs, and less so for inputs with clean acoustics.", "label": "neutral"}
{"id": "test_3224", "sentence1": "Being a span enumeration type model, DYGIE++ only works on paragraph level texts and extracts relations between mentions in the same sentence only.", "sentence2": "we also tried integrating it into our model, where we classify pairs of \"span embeddings\" (not the surface form) but found the separate model that uses surface forms to work much better.", "label": "neutral"}
{"id": "test_3225", "sentence1": "The 0.5 threshold enjoys the property that, assuming all predicted clusters are disjoint from each other (which is the case by construction) and gold clusters are disjoint from each other (which is the case for 98.5% of them), a single predicted cluster can be assigned to atmost one gold cluster.", "sentence2": "we predict clusters of mentions using our model (mention identification, pairwise coreference, and mention clustering).", "label": "neutral"}
{"id": "test_3226", "sentence1": "For training all of the above models, we use the batch size of 6, a learning rate of 2e-5, and 3 epochs.", "sentence2": "in this section, we compare the performance of the models as presented in Table 1, draw empirical observations, and attempt to provide a rationale for the performances observed.", "label": "neutral"}
{"id": "test_3227", "sentence1": "For each point from both XR and Y, we compute a \"personalized\" translation vector, as the weighted average of the translation vectors of its closest dictionary entries.", "sentence2": "iV is supported by the ERC Consolidator Grant LEXiCAL (no 648909).", "label": "neutral"}
{"id": "test_3228", "sentence1": "Hellendoorn et al. (2020) develop a similar model concurrently with this work, where they use relation-aware self-attention to encode data flow structure in source code embeddings.", "sentence2": "the alignment matrix successfully infers to use these two tables instead of car_makers using the evidence that they contain the three mentioned columns.", "label": "neutral"}
{"id": "test_3229", "sentence1": "Brunner et al. (2020) suggest that representations produced by Transformers mix the information from different positions and cease to be directly interpretable after 2+ layers, which might explain our observations.", "sentence2": "in many applications (including text-to-SQL parsing) we are aware of some preexisting relational features between the inputs, and would like to bias our encoder model toward them.", "label": "neutral"}
{"id": "test_3230", "sentence1": "To the best of our knowledge, text generation based on the predefined rigid formats has not been well investigated.", "sentence2": "in this work, we propose a simple and elegant framework named SongNet to address this challenging problem.", "label": "neutral"}
{"id": "test_3231", "sentence1": "We remove the cross-modality Transformer and use single-modality representations as entity representations.", "sentence2": "researchers also extended Transformers with both textual and visual modalities (Li et al., 2019b;Sun et al., 2019;Tan and Bansal, 2019;Su et al., 2020;Tsai et al., 2019).", "label": "neutral"}
{"id": "test_3232", "sentence1": "There are several challenging research directions for addressing learning representations for crossmodality data and enabling reasoning for target tasks.", "sentence2": "for NLVR 2 dataset, the task is binary classification that determines whether the statement is correct regarding the images.", "label": "neutral"}
{"id": "test_3233", "sentence1": "Sophisticated pre-training strategies were introduced to boost the performance (Tan and Bansal, 2019).", "sentence2": "nLVR 2 : The results of nLVR task are listed in Table 1.", "label": "neutral"}
{"id": "test_3234", "sentence1": "The random caption speaker outputs one of the ground-truth captions for the target image at random.", "sentence2": "in the absence of a human listener to provide rewards for learning, we use the oracle fixed listener, which was found in Section 5 to be predictive of human referential success.", "label": "neutral"}
{"id": "test_3235", "sentence1": "Single-headed cross attention speeds up decoding: Despite removing learned self-attention from both the encoder and decoder, we did not observe huge efficiency or speed gains.", "sentence2": "hC-SA even outperforms BASE for sentences with fewer off-diagonal tokens.", "label": "neutral"}
{"id": "test_3236", "sentence1": "It is possible that, at some future point in time, spelling will be deemed to lie outside of the construct targeted by the consequential assessment of writing and spell-correction software will be made available to test-takers.", "sentence2": "add to the mix the finding that automated spelling correction system is more accurate on essays that are of better quality to begin with (Flor, 2012), and it's likely that the automated assessment of an automatically spell-corrected version of an essay might show an unexpected relationship with original scores that would need to be closely examined for bias or for an increase in construct-irrelevant variance.", "label": "neutral"}
{"id": "test_3237", "sentence1": "Our synthetic corpus study (Table 5) shows that BERT is able to memorize negative facts that occur in the corpus.", "sentence2": "while the prediction probability generally is somewhat lower in the negated compared to the positive answer, there is no threshold across cloze questions that could be used to distinguish valid positive from invalid negative answers (cf.", "label": "neutral"}
{"id": "test_3238", "sentence1": "In the preprocessing step, we removed stop words, converted all text into lowercase, and stemming.", "sentence2": "more importantly, OSDm tried to incorporate semantic information in the proposed graphical representation model to remove the term ambiguity problem in short-text clustering.", "label": "neutral"}
{"id": "test_3239", "sentence1": "The reason behind might be the multiple iterations of each batch in the stream.", "sentence2": "(4) MStreamF (Yin et al., 2018) is the latest model to deal with infinite number of latent topics in short text while processing one batch at a time.", "label": "neutral"}
{"id": "test_3240", "sentence1": "A commonly used technique is to define the \"context\" for each node, for example by random walks, and train a predictive model to perform context prediction.Similar network-based learning is employed in node2vec (Grover and Leskovec, 2016).", "sentence2": "albeit more accurate thanks to capturing stylistic variation elements, statistical models are prone to stereotype propagation as well (Costa-jussa et al., 2019; Koolen and van Cranenburgh, 2017).", "label": "neutral"}
{"id": "test_3241", "sentence1": "A pure language model performs best, suggesting that BART is less effective when the output is only loosely constrained by the input.", "sentence2": "to better understand these effects, we also report an ablation analysis that replicates other recently proposed training objectives.", "label": "neutral"}
{"id": "test_3242", "sentence1": "Nevertheless, BART outperforms all existing work.", "sentence2": "this objective allows predictions to condition on both left and right context.", "label": "neutral"}
{"id": "test_3243", "sentence1": "Because BART has an autoregressive decoder, it can be directly fine tuned for sequence generation tasks such as abstractive question answering and summarization.", "sentence2": "xSum is highly abstractive, and extractive models perform poorly.", "label": "neutral"}
{"id": "test_3244", "sentence1": "It is also evident that removing more components results in more performance drop, thus demonstrating the complementary nature of the three proposed components in this work.", "sentence2": "this model seeks to show that the use of RDP for the similarity encouragement with RW is more effective than employing RDP directly in V .", "label": "neutral"}
{"id": "test_3245", "sentence1": "In such models, the dependency trees are often used to directly structure the network architectures or to obtain the dependency relations between the word pairs to inject the syntactic information into the models via multi-task learning.", "sentence2": "(v) SP-CEON-LSTM: This model removes the SDPS component and includes the representation vector of the dependency path DP (i.e., R DP ) in the final representation V for relation prediction.", "label": "neutral"}
{"id": "test_3246", "sentence1": "In CE-LSTM, we replace the ON-LSTM network with the usual LSTM model in CEON-LSTM.", "sentence2": "other countries including the Philippines, South Korea, Qatar and Australia agreed to send other help such as field hospitals, engineers, explosive ordnance disposal teams or nuclear, biological and chemical weapons experts.", "label": "neutral"}
{"id": "test_3247", "sentence1": "The goal of this component is to obtain a score for each word w t that indicates the contextual importance of w t with respect to the relation prediction between w s and w o in W .", "sentence2": "we replace the term L import in the overall loss function (i.e., Equation 6) with the dependency edge prediction loss (using the ON-LSTM hidden vectors) in DRPC for EP-ON-LSTM.", "label": "neutral"}
{"id": "test_3248", "sentence1": "We train our LID models using this setting for 50 epochs.", "sentence2": "to accomplish that, we introduce CS-ELMo, an extended version of ELMo that contains a position-aware hierarchical attention mechanism over ELMo's character n-gram representations.", "label": "neutral"}
{"id": "test_3249", "sentence1": "We achieve the best results on Exp 3.3, which outperforms both the baselines and the previous state of the art on the full LID label scheme (see Table 2).", "sentence2": "Figure 2B illustrates the position embeddings for bi-grams and tri-grams.", "label": "neutral"}
{"id": "test_3250", "sentence1": "The feature vector f has an element corresponding to each named entity type in the KB (e.g., LOC, PER, and ORG).", "sentence2": "the autoencoder takes the hidden states of the BiLStM as input to a fully connected layer with a sigmoid activation function and reconstructs the features.", "label": "neutral"}
{"id": "test_3251", "sentence1": "In this section, we discuss our experiments on four low-resource languages and attempt to answer the following research questions: 1) \"Although gazetteer-based features have been proven useful for neural NER on English, is the same true in the low-resource setting?\"", "sentence2": "this feature vector is applied to each word in the span, considering the position of the specific word in the span according to the BIO scheme; we use the \"B-\" vector elements for the first word in the span, \"I-\" otherwise.", "label": "neutral"}
{"id": "test_3252", "sentence1": "that excludes the negative class name selection step and uses only the single positive class name in the entity selection module.", "sentence2": "their method requires a user-provided class name and utilizes web tables as additional knowledge, while our method can automatically generate both positive and negative class names and utilize them to guide the set expansion process.", "label": "neutral"}
{"id": "test_3253", "sentence1": "ince these synonyms consistently rank lower than the positive one for the initial seeds based on the given corpus, they are indeed not good class names for this specific corpus.", "sentence2": "it only incorporates the average BERT representation to select entities.", "label": "neutral"}
{"id": "test_3254", "sentence1": "Table A4 shows VQA accuracy for each answer type on VQACPv2's test set.", "sentence2": "in the test set, answer 'yes' is more frequent.", "label": "neutral"}
{"id": "test_3255", "sentence1": "Learning generic answers is a well-known problem for open-domain dialog systems, e.g. (Li et al., 2016).", "sentence2": "Dense annotations, i.e.  crowd-sourced relevance weights, are provided for 0.16% of training set, which we use to fine-tune the model to select multiple semantically equivalent answers.", "label": "neutral"}
{"id": "test_3256", "sentence1": "Multi-head attention provides multiple representation spaces to capture different linguistic/grounding phenomena, which are otherwise lost by averaging using a single head.", "sentence2": "For example, in order to answer the question \u201cAbout how many?\u201d in Figure 1, we have to infer from what was previously said, that the conversation is about the skiers.", "label": "neutral"}
{"id": "test_3257", "sentence1": "Of course, we expect pre-trained visual BERT models to show even more improvements on this task, e.g. Vilbert (Lu et al., 2019), LXMert (Tan and Bansal, 2019), UNITER (Chen et al., 2019) etc. ", "sentence2": "we then embed the question to pool the relevant grounded history using another MCA module.", "label": "neutral"}
{"id": "test_3258", "sentence1": "Other studies consider additional linguistic features such as POS tags and word segmentation (i.e. tokens or morphemes) (Ananthakrishnan et al., 2005; Zitouni et al., 2006; Zitouni and Sarikaya, 2009; Shaalan et al., 2009).", "sentence2": "to learn word based tasks with diacritic restoration, we pass WordtoChar representation to the diacritic restoration and/or ChartoWord representation for word-based tasks.", "label": "neutral"}
{"id": "test_3259", "sentence1": "Identifying morpheme boundaries did not increase accuracy as we expected.", "sentence2": "diacritic restoration is the task of restoring missing diacritics in the written text.", "label": "neutral"}
{"id": "test_3260", "sentence1": "Inflectional diacritics are also affected by word's root (e.g. weak roots) and semantic or morphological properties (e.g. with the same grammatical case, masculine and feminine plurals take different diacritics).", "sentence2": "we examined whether information learned from the BiLSTM layer would help us learn morpheme interactions by passing the output of last BiLSTM layer to the diacritic restoration model along with segmentation labels.", "label": "neutral"}
{"id": "test_3261", "sentence1": "Zalmout and Habash (2017) develop a morphological disambiguation model to determine Arabic morphological features including diacritization.", "sentence2": "inflectional diacritics are related to the syntactic positions of words in the sentence and are added to the last letter of the main morphemes of words (word finally), changing their pronunciations.", "label": "neutral"}
{"id": "test_3262", "sentence1": "We use Modern Standard Arabic (MSA) and Egyptian Arabic (EGY) as test cases.", "sentence2": "the context in the tagging network spans the entire input sentence.", "label": "neutral"}
{"id": "test_3263", "sentence1": "Although increases exist across all domains, these are most prominent in domains like TC (+5.36) that have a low density of named entities and where indomain models have access to limited amounts of data.", "sentence2": "we expect that the two tasks at different levels of granularity rely on shared structure in the original semantic space.", "label": "neutral"}
{"id": "test_3264", "sentence1": "After that, the Similarity Module computes the similarity of these vectors via the same L2-distance-based operation as in CT.", "sentence2": "in the second example in Table 4, it fails to understand that there is also a dictionary involved and ends up returning the wrong command.", "label": "neutral"}
{"id": "test_3265", "sentence1": "Row 3 of Table 2 shows that the MP model on its own under-performs and actually has the worst results out of all the models we tested.", "sentence2": "we compare four models: a baseline model (CT) that only considers text and source code, a (CAT) model that also includes embedding of Abstract Syntax Trees, a multi-perspective model (MP) that leverages multi-perspective matching operations as defined in a bilateral multi-perspective model (wang et al., 2017), and our MP-CAT model that combines both MP and CAT architectures.", "label": "neutral"}
{"id": "test_3266", "sentence1": "This suggests that pre-training provides useful signal for mentions that consist of variations appearing in the ontology.", "sentence2": "in the case of entities with CUis, we find that pre-training the model does provide a gain in ranking accuracy (MRR).", "label": "neutral"}
{"id": "test_3267", "sentence1": "As mentioned in Section \u00c2\u00a71, however, such a brute-force method is computationally infeasible.", "sentence2": "formally, assume that we have a set N , comprising experimental records (both features and scores) of n datasets for one task.", "label": "neutral"}
{"id": "test_3268", "sentence1": "Next, we test whether models identify presuppositions of the premise as entailments, e.g., that Jo's cat went entails that Jo has a cat.", "sentence2": "otherwise, a model might correctly predict entailment essentially by accident if, for instance, it systematically ignores negation.", "label": "neutral"}
{"id": "test_3269", "sentence1": "We now list all the hyper-parameters used.", "sentence2": "neutral: Not all rides at amusement parks are a movie.", "label": "neutral"}
{"id": "test_3270", "sentence1": "For BERT models, we fine-tune the representations from the final layer for our parsing and tagging tasks.", "sentence2": "a parsing approach taking into account the special status of headless structural representations can potentially benefit models for a large number of languages and treebanks.", "label": "neutral"}
{"id": "test_3271", "sentence1": "To demonstrate the effectiveness of CRF, we compare results from models with or without CRF using each training technique mentioned above.", "sentence2": "character-level information has proved to help improve the sequence labeling accuracy by capturing morphological features (Ma and Hovy, 2016).", "label": "neutral"}
{"id": "test_3272", "sentence1": "To address this issue, we propose TLUA model, utilizing an attention scheme to automatically weight different LUs for the frame, according to target word T in the given sentence, shown in Figure 1.", "sentence2": "f Eki denotes the i-th frame element of fk , and Pki denotes the ith span fulfilling f Eki .", "label": "neutral"}
{"id": "test_3273", "sentence1": "For instance, in Figure 1 the entity types are movie and person, which are combined with the table cast.", "sentence2": "for each node, the annotators can inspect the result of the execution.", "label": "neutral"}
{"id": "test_3274", "sentence1": "With this, we find 96% of all entities.", "sentence2": "we can limit the number of overall constraints and the number of maximum constraints for each entity type.", "label": "neutral"}
{"id": "test_3275", "sentence1": "Furthermore, the table shows the average precision for each query complexity category.", "sentence2": "this approach is very time-consuming and has a major issue.", "label": "neutral"}
{"id": "test_3276", "sentence1": "Each question in the QuAC dataset is assigned one of three categories: should ask, could ask, or should not ask a followup question.", "sentence2": "the similarity scores are computed based on vector cosine similarity.", "label": "neutral"}
{"id": "test_3277", "sentence1": "The last follow-up question example is invalid since Verhoeven is a he, not she.", "sentence2": "our proposed model relies on three attention matrices, where the two additional attention matrices make use of the associated passage.", "label": "neutral"}
{"id": "test_3278", "sentence1": "Since MWPs are usually clearly specified (with a sure answer), there is no ambiguous interpretation once the answer is given.", "sentence2": "furthermore, low-diversity corpora are typically characterized by highly similar problems, which usually yields over-optimistic results (Huang et al., 2016) (as the answer frequently can be simply obtained from the existing equation template associated with the most similar MWP in the training-set).", "label": "neutral"}
{"id": "test_3279", "sentence1": "As can be seen, possession implicitly acts as an agreement feature (i.e., possession of the object and person of the verb must match).", "sentence2": "typelevel probing tasks have the advantage of containing less bias (domain, annotator, and majority class); whereas token-level tests might be sensitive to the domain biases from the underlying full-text data.", "label": "neutral"}
{"id": "test_3280", "sentence1": "For instance, while probing for the OddFeat between two forms, we assume that there exists a word pair differing only by one feature.", "sentence2": "a word annotated with UniMorph features can be used in several probing tests.", "label": "neutral"}
{"id": "test_3281", "sentence1": "In order to diagnose whether it does indeed extract morphologically relevant information during training, we save the model states for different epochs and generate the word representations via the aforementioned internal biLSTM layer and use our intrinsic evaluation suite from Section 4.3, to evaluate these representations.", "sentence2": "dictionary-based tasks do not contain any frequency information of the surface forms, whereas token-level tasks do.", "label": "neutral"}
{"id": "test_3282", "sentence1": "Although the performance boost for Case and POS are still visible in intermediate layer results, we notice that Person and Tense features may have been forgotten in the next layer.", "sentence2": "the results for MUSE, word2vec, GloVe-BPE, and fastText are only provided for comparison among each other, and to gain insights on some of the aspects discussed in Section 3.5.", "label": "neutral"}
{"id": "test_3283", "sentence1": "For instance, the German lemma Teilnehmerin would be inflected as Teilnehmerinnen as a plural noun marked either with accusative, dative, or a genitive case marker.", "sentence2": "several recent studies analyze representations generated by neural models to get insights on what kind of linguistic information is learned by the models.", "label": "neutral"}
{"id": "test_3284", "sentence1": "The result is the GF RGL (Ranta 2009b).", "sentence2": "for instance, it can also be used for the synset: ((biology) a taxonomic group containing one or more genera) since all the chosen translations also fit in that sense.", "label": "neutral"}
{"id": "test_3285", "sentence1": "But in general, there are too many constructions to keep track of, and special domains of language use come with their own constructions.", "sentence2": "one possible solution is a layer of non-compositional post processing that finds paraphrases for inadequate trees (Section 3.5).", "label": "neutral"}
{"id": "test_3286", "sentence1": "There, every synset corresponds to one abstract function and then the function's linearization in each language produces all words in the language as variants.", "sentence2": "note that there is the Princeton Wordnet Gloss Corpus, which also contains sense annotations but only for some words-in order to construct complete trees we had to annotate all senses.", "label": "neutral"}
{"id": "test_3287", "sentence1": "The common abstract syntax of the RGL can be seen as an intersection of the structures available in different languages.", "sentence2": "this assumption has recently been challenged by an analysis of hyperbatic constructions in Latin, which make it possible to interleave any words contained in discontinuous constituents (Spevak 2010).", "label": "neutral"}
{"id": "test_3288", "sentence1": "However, the recent advances of UD (Nivre et al. 2016) have not only shown that it is possible to assign the same syntactic structures to vastly different languages, but also ended up with structures very similar to the RGL (Kolachina and Ranta 2016).", "sentence2": "aMR equipped with GF strengthens the status of aMR being an interlingua.", "label": "neutral"}
{"id": "test_3289", "sentence1": "This is the RETRIEVAL baseline.", "sentence2": "given Q + A, we use the procedure described in (Khot et al., 2020) to assemble candidate chains from T (below).", "label": "neutral"}
{"id": "test_3290", "sentence1": "Similarly, another entailmentbased dataset is FEVER (Thorne et al., 2018), testing where a larger context entails a claim.", "sentence2": "our work fills this gap by providing an explanation (e.g., \"spoon is made of metal\", \"heat is energy\" from a larger retrieved context).", "label": "neutral"}
{"id": "test_3291", "sentence1": "More recently, multihop datasets where the decomposition is not evident have appeared, e.g., WikiHop (Welbl et al., 2018), OBQA (Mihaylov et al., 2018), and QASC (Khot et al., 2020), posing more a realistic explanation challenge.", "sentence2": "this may be useful for helping a user understand the rationale behind a chain, and a repository of high-scoring patterns may be useful as a knowledge resource in its own right.", "label": "neutral"}
{"id": "test_3292", "sentence1": "Multitask learning (Caruana, 1997; Collobert and Weston, 2008) seeks to learn a single model that can solve multiple tasks simultaneously, similar to our framework that seeks to learn a model that can solve many tasks.", "sentence2": "our baselines build off the T5 11B model (Raffel et al., 2019): a text-to-text encoder-decoder structured transformer pretrained via masked language modeling and multi-tasking.", "label": "neutral"}
{"id": "test_3293", "sentence1": "Attribution of natural disasters/collective misfortune is a widely-studied political science problem.", "sentence2": "two different pre-trained LM weights are used to bootstrap our model.", "label": "neutral"}
{"id": "test_3294", "sentence1": "Secondly, for their Distant Supervised Stance Detection (DSSD) method, Augenstein et al. train an LSTM on tweets where stance towards various entities or topics is labeled (cf. the SemEval 2016 Stance Detection shared task A dataset (Mohammad et al., 2017)).", "sentence2": "we reimplement TD-LSTM using the code made available by the authors (c.f Table 2 and Appendix C).", "label": "neutral"}
{"id": "test_3295", "sentence1": "First, in both domains, as more logical forms are replaced, the performance of all MRs declines gradually.", "sentence2": "these values are not explicitly mentioned in the utterance and may even change over time.", "label": "neutral"}
{"id": "test_3296", "sentence1": "Dataset Statistics Sentence-level annotations were aggregated by majority vote, yielding 252, 418, and 369 instances for the \"Unrelated\", \"Some meaning difference\", and \"No meaning difference\" classes, respectively.", "sentence2": "we train the Divergent mBERT model by learning to rank synthetic divergences.", "label": "neutral"}
{"id": "test_3297", "sentence1": "All models are trained on the OpenSubtitles 2018 corpus.", "sentence2": "the training data for our models is a mixture of OpenSubtitles 2018 4 en-fr data and en-fr Gigaword 5 data.", "label": "neutral"}
{"id": "test_3298", "sentence1": "We hypothesize that these datasets contain many examples where their gold scores are easy to predict by either having similar structure and word choice and a high score or dissimilar structure and word choice and a low score.", "sentence2": "this trick allows for the expectation under q to be approximated through sampling in a way that preserves backpropagation.", "label": "neutral"}
{"id": "test_3299", "sentence1": "The enhanced pre-trained model could be directly used in our approach.", "sentence2": "we propose to recover the alignment information by masking signals of unimportant cells during self-attention.", "label": "neutral"}
{"id": "test_3300", "sentence1": "To tackle these issues, some works adopt the distantly supervised methods (Mintz et al., 2009) to auto\u0002matically annotate data with existing event facts in knowledge bases (Chen et al., 2017; Zeng et al., 2018; Araki and Mitamura, 2018) or use bootstrap\u0002ping methods to generate new data (Ferguson et al., 2018; Wang et al., 2019b)", "sentence2": "to verify the effectiveness of modeling multiple event correlations, the two models both adopt the conditional random field (CRF) (Lafferty et al., 2001) as their output layers, which can model structured output dependencies.", "label": "neutral"}
{"id": "test_3301", "sentence1": "Nevertheless, the benchmark datasets for ED are upgraded slowly.", "sentence2": "intermediate pre-training can improve ED on ACE 2005 with the general event knowledge learned on MAVEN, which indicates MAVEN's high coverage of event types can benefit other ED tasks.", "label": "neutral"}
{"id": "test_3302", "sentence1": "We extract the sentence pair representation via the [CLS] token and treat it as a unary probing task.", "sentence2": "we observe that grammatical tasks score high, while core role labeling lags behind -in line with the findings of Tenney et al.", "label": "neutral"}
{"id": "test_3303", "sentence1": "In English, PropBank predicate token mixing weights emphasize the same layers as dependency parsing -in line with the previously published results.", "sentence2": "2 We train the probes for 20 epochs using the Adam optimizer with default parameters and a batch size of 32.", "label": "neutral"}
{"id": "test_3304", "sentence1": "In some of the embedding-based approaches, attribute types or values are utilized to generate attribute embeddings, which are integrated with structure embeddings of entities to get more accurate entity alignments.", "sentence2": "if seeding alignments between two KGs are available, a set of aligned entities in an entity's neighborhood will be taken as the set-representation.", "label": "neutral"}
{"id": "test_3305", "sentence1": "To let the entity-pair embeddings memorize the original attribute features, we add residual connections from the input features to the output layer of the GNN model.", "sentence2": "in this work, our KG alignment model considers both relational and attributional triples in KGs.", "label": "neutral"}
{"id": "test_3306", "sentence1": "Entities having the same or similar attribute values tend to be equivalent.", "sentence2": "mRR is the average of the reciprocal ranks of the results.", "label": "neutral"}
{"id": "test_3307", "sentence1": "For both models, we want the aligned entitypairs having higher scores than the non-aligned entity-pairs.", "sentence2": "multiKE (Zhang et al., 2019) uses a framework unifying the views of entity names, relations and attributes to learn embeddings for aligning entities.", "label": "neutral"}
{"id": "test_3308", "sentence1": "We form an action matrix A using hj , where the j-th row Aj corresponds to the j-th sentence (sj ) in D. A pseudo sentence indicating the STOP action, whose representation is randomly initial\u0002ized, is also included in A, and sentence extraction is finalized when the STOP action is taken (Mao et al., 2018, 2019).", "sentence2": "they lack holistic modeling of summary quality and the capability of end-to-end representation learning.", "label": "neutral"}
{"id": "test_3309", "sentence1": "The KPE task is a foundational task, which plays a facilitating role in many Information Retrieval (IR) tasks, including classification, summarization, and document indexing (Hasan and Ng, 2014).", "sentence2": "for each term, features describing itself and its parent block in the DOM Tree are included.", "label": "neutral"}
{"id": "test_3310", "sentence1": "In this section, we will explain our model in detail.", "sentence2": "multistage fusion consists of the cross fusion block and hierarchical fusion decoder, which aims to model the correlation and complementarity between modalities spontaneously.", "label": "neutral"}
{"id": "test_3311", "sentence1": "We can observe that our model without the graph encoder has a 1.6% absolute value loss (over 25% in ratio) in BLEU score and a 1.1% absolute value loss (9.8% in ratio) in entity F1 on MultiWOZ 2.1, which suggests that the overall quality of the generated sentences are better improved by our graph encoder.", "sentence2": "the model loops over K hops on an input graph.", "label": "neutral"}
{"id": "test_3312", "sentence1": "It should be noted that even with a memory of 10k examples, the performance of continual learning algorithms are far from the i.i.d setting.", "sentence2": "we construct our data streams using two popular vision-language datasets: COCO-captions (Chen et al., 2015) and Flickr30k Entities (Plummer et al., 2015) which provide multiple captions for each image in MSCOCO (Lin et al., 2014) and Flickr30k (Young et al., 2014) respectively.", "label": "neutral"}
{"id": "test_3313", "sentence1": "Our proposed VisCOLL benchmark reveals that the gains observed in image classification tasks from state-of-art continual learning algorithms fail to transfer to VisCOLL even with increased memory.", "sentence2": "(ii) effect of the large search space on memory-based continual learning algorithms.", "label": "neutral"}
{"id": "test_3314", "sentence1": "Humans acquire language continually with much more limited access to data samples at a time, as compared to contemporary NLP systems.", "sentence2": "visCOLL rules out many continual learning algorithms which require explicit task identity and boundary (Kirkpatrick et al., 2017;Rusu et al., 2016).", "label": "neutral"}
{"id": "test_3315", "sentence1": "In VSM, we follow XML (Lei et al., 2020b) to \ncompute the matching scores between the query\nand visual frames at both local and global levels.", "sentence2": "in Figure 2a, we human could probably identify the moment by the speaker information and the visual clue of character's emotion.", "label": "neutral"}
{"id": "test_3316", "sentence1": "It contains 200K unique video clip-caption pairs.", "sentence2": "reordering happens after the multimodal fusion of subtitle and visual frames.", "label": "neutral"}
{"id": "test_3317", "sentence1": "Premised on the assumption that the adversarial text generator is unknown beforehand, we propose to evaluate articles based on the semantic consistency between the linguistic and visual components.", "sentence2": "we propose to leverage possible visual-semantic inconsistency between the article text, images, and captions, such as missing or inconsistent named entities (underlined in red).", "label": "neutral"}
{"id": "test_3318", "sentence1": "The show had started more than an hour earlier.", "sentence2": "mr. Germano was placed on leave after a New York Times investigation last month detailed the treatment of women at the company.", "label": "neutral"}
{"id": "test_3319", "sentence1": "One plausible reason for this is that the main subject in the caption does not match the person who was mentioned in the article body and DIDAN is able to pick up on this relatively easily.", "sentence2": "the human-generated articles are sourced from the GoodNews (Biten et al., 2019) dataset.", "label": "neutral"}
{"id": "test_3320", "sentence1": "Masking implicitly performs gradient descent, analogy to the weights update achieved by finetuning; the observations complement our arguments in the main text.", "sentence2": "(i) a large initial sparsity removing most pretrained parameters, e.g., 95%, leads to bad performance for the four tasks.", "label": "neutral"}
{"id": "test_3321", "sentence1": "Figure 3 shows the accumulated number of parameters in million and memory in megabytes (MB) required when an increasing number of downstream tasks need to be solved using finetuning and masking.", "sentence2": "we exclude 5 annotated words in dev and 87 annotated words in test.", "label": "neutral"}
{"id": "test_3322", "sentence1": "TRANSFORMER (Vaswani et al., 2017) that is based solely on attention mechanisms.", "sentence2": "it's worth noting that our approach achieves significant improvements without introducing any additional data and model modification.", "label": "neutral"}
{"id": "test_3323", "sentence1": "Intuitively, if a training example has a low sentence-level probability, it is less likely to provide useful information for improving model performance, and thus is regarded as an inactive example.", "sentence2": "the final NMt model is trained on the combination of the active examples and rejuvenated examples.", "label": "neutral"}
{"id": "test_3324", "sentence1": "Increased training of the baseline also results in a drop in BLEU scores.", "sentence2": "although backtranslation achieves highest BLEU score at 32.57, our fine-tuned CONCaT model achieves the highest F1 for pronoun translation at 72.39, without having been trained on any extra monolingual data.", "label": "neutral"}
{"id": "test_3325", "sentence1": "This is similar to the features that Lin et al. (2019) consider, but without training a ranking model fed with scores from pairwise MT systems.", "sentence2": "we need to obtain the NMT-learned embeddings first in order to fulfil those methods (from a 53-languages massive model).", "label": "neutral"}
{"id": "test_3326", "sentence1": "For example, our QE model beat BLEU for zh-en, en-de and en-kk directions but got negative Pearson correlation with human evaluation for gu-en, ru-en, en-ru and fr-de directions.", "sentence2": "we obtain new state-of-the-art results on the wMT 2019 QE as a Metric task and outperform sentBLEU on the wMT 2019 Metrics task (Ma et al., 2019).", "label": "neutral"}
{"id": "test_3327", "sentence1": "For system-level evaluation, metrics which can use the reference translations for quality estimation, such as BLEU, generally achieved consistently high correlation with human evaluation for all language pairs.", "sentence2": "Results are shown in Table 6.", "label": "neutral"}
{"id": "test_3328", "sentence1": "We introduce 'Batch Filtering', a fast and effective method for filtering out incorrect alignments.", "sentence2": "For each combination of the aligners (4 combinations in total; see Table 2), we took the union of sentence pairs extracted by each constituent aligner of the said combination for each document.", "label": "neutral"}
{"id": "test_3329", "sentence1": "We also make sure to check that there are no morpho-syntactic dependencies, e.g., agreement, between these variables.", "sentence2": "unlike all other previous challenge datasets focusing on gender bias, our examples quantify to what extent gender bias in models leads to prediction errors, rather than unwarranted disambiguation.", "label": "neutral"}
{"id": "test_3330", "sentence1": "For all languages, we report the performance of Google Translate.", "sentence2": "we see a similar tendency to Chinese, but since the overall performance is poor, and the model is in general rather insensitive to differences in pronouns, we do not include correlation results.", "label": "neutral"}
{"id": "test_3331", "sentence1": "In this example, input #1, #2 and #3 have the same meaning.", "sentence2": "the dominant methods for NMT only observe one of them from the parallel corpora for the model training but have to deal with adequate variations under the same meaning at inference.", "label": "neutral"}
{"id": "test_3332", "sentence1": "Assuming that a token is selected to be replaced, and its candidate substitutes are retrieved by the mapping, we want the selected substitute can fit in well with the token's context and maintain both the semantic and syntactic coherence.", "sentence2": "we found that adversarial examples also exist in the GEC models and up to 100% of input examples admit adversarial perturbations.", "label": "neutral"}
{"id": "test_3333", "sentence1": "Prior hyperparameters controlling the degree of sparsity were set to \u03b1 = 0.1, \u03b2 = 0.01, \u03b3 = 1.", "sentence2": "this expression is similar to the stick-breaking representation of a Dirichlet process DP(\u00b7, F)\u2014 however, it has different weights and does not include random atoms drawn from F as part of its definition-see Appendix B for more details.", "label": "neutral"}
{"id": "test_3334", "sentence1": "We denote loss functions of these two parts as L new and L old respectively.", "sentence2": "existing GE models are not practical in real-world applications since it overlooked the streaming nature of incoming data.", "label": "neutral"}
{"id": "test_3335", "sentence1": "In WD-Match, a Wasserstein distance-based regularizer is defined to regularize the features vectors projected from different domains.", "sentence2": "in this paper, we proposed a novel Wasserstein distance-based regularizer to improve the sequence representations, for text matching in asymmetrical domains.", "label": "neutral"}
{"id": "test_3336", "sentence1": "The diagonal positions of the matrices are almost always important for the MNLI task, which exhibits similar trends with TinyBERT with the one-to-one \"Skip\" layer mapping strategy.", "sentence2": "we summarize our main contributions as follows.", "label": "neutral"}
{"id": "test_3337", "sentence1": "When the answer spans appear only once in the input, this is simple, since the ground-truth tagging is immediately available.", "sentence2": "let V be the set of all valid taggings.", "label": "neutral"}
{"id": "test_3338", "sentence1": "For both methods, we find that the pruned \"good\" subnetworks alone reach the performance comparable with the full model, while the \"bad\" ones do not.", "sentence2": "ideally, the pre-trained weights would provide transferable linguistic knowledge, fine-tuned only to learn a given task.", "label": "neutral"}
{"id": "test_3339", "sentence1": "Given that we did not find even the \"good\" subnetworks to be stable, or preferentially containing the heads that could have interpretable linguistic functions, the latter seems more likely.", "sentence2": "the degree to which the \"good\" subnetworks overlap across tasks may be a useful way to characterize the tasks themselves.", "label": "neutral"}
{"id": "test_3340", "sentence1": "Based on the defined roles, we perform a preliminary analysis across all layers.", "sentence2": "we note that all 12 layers are majorly focused on entity based words (common nouns, proper nouns and numerical entities).", "label": "neutral"}
{"id": "test_3341", "sentence1": "Due to the large number of parameters and nonlinearity of deep NN models, the answer to the question \"how did the model arrive at the prediction?", "sentence2": "the current works do not provide an insight into how BERT is able to achieve near human-level performance on the task of Reading Comprehension based Question Answering.", "label": "neutral"}
{"id": "test_3342", "sentence1": "Nevertheless, the counterfactual samples are simply added to the training data for augmentation, ignoring that the relationship between original samples and counterfactual samples are vital for the reasoning of VQA models.", "sentence2": "the dimension of the joint embedding is 2048.", "label": "neutral"}
{"id": "test_3343", "sentence1": "By examining the distribution of the relevance scores, we find that only 31% of them are aligned well with the sparse annotations and 9% are totally misaligned.", "sentence2": "their models neglect the important early interaction of the answer entity and cannot naturally leverage the pretrained language representations from BERT like ours.", "label": "neutral"}
{"id": "test_3344", "sentence1": "The response of StepGAN is not infor-mative enough as well.", "sentence2": "we have tested the learning rate from 1e-6 to 1e-3.", "label": "neutral"}
{"id": "test_3345", "sentence1": "Aspect Based Sentiment Analysis (ABSA) (Pang and Lee, 2008; Liu, 2012) is an extensively studied sentiment analysis task on a fine-grained semantic level, i.e., opinion targets explicitly mentioned in sentences.", "sentence2": "such behavior is caused by the different distribution of positive, neutral, and negative sentiment between training and test set, shown in Table 1.", "label": "neutral"}
{"id": "test_3346", "sentence1": "In this group, the baselines use different approaches to deal with the multi-label issue without considering the modality dependence issue.", "sentence2": "comparison with the multi-modal and multilabel classification approaches.", "label": "neutral"}
{"id": "test_3347", "sentence1": "Kant et al. (2018) leverage the pre-trained BERT to perform multi-label emotion task and Kim et al. (2018) propose an attention-based classifier that predicts multiple emotions of a given sentence.", "sentence2": "while the conditional generation framework naturally models the label dependence by predicting the next emotion label upon other potential labels, we propose Multi-head soft modality attention at each predicting step inside the emotion decoder to capture the modality dependence.", "label": "neutral"}
{"id": "test_3348", "sentence1": "Although stateof-the-art models have shown high accuracy on existing test sets, we still question their robustness.", "sentence2": "finally, we ask the annotators to fix the rejected samples by minimal edit which does not change the aspect term or the sentence meaning, but satisfies both criteria.", "label": "neutral"}
{"id": "test_3349", "sentence1": "We first form a set of aspect expressions AspectSet 4 by extracting all aspect expressions from the entire dataset.", "sentence2": "Moreover, when we test on the subset of the test set (59 instances in Laptop, and 122 instances in Restaurant) where the target aspect sentiment differs from all nontarget aspect sentiments (so that the confounding factor is disentangled), the best model (Xu et al., 2019a) drops from 78.53% to 59.32% on Laptop and from 86.70% to 63.93% on Restaurant.", "label": "neutral"}
{"id": "test_3350", "sentence1": "ADDDIFF: Add aspects with the opposite sentiment from the target aspect Tasty burgers, crispy fries, but poorest service ever!", "sentence2": "we propose a flexible method, adversarial training, for aspect robustness, which is applicable to any given dataset.", "label": "neutral"}
{"id": "test_3351", "sentence1": "A sequence of tokens is encoded into a sequence of token embeddings H by the BERT encoder.", "sentence2": "sun and Nenkova (2019) discussed both reference-based and reference-free settings for summarization evaluation.", "label": "neutral"}
{"id": "test_3352", "sentence1": "That's because these approaches are difficult to measure the salience and redundancy simultaneously with error propagation.", "sentence2": "let T denotes the hand-crafted summary.", "label": "neutral"}
{"id": "test_3353", "sentence1": "We use P BLANK to denote the ratio of replaced entities and set P BLANK = 0.7 following Baldini Soares et al.", "sentence2": "there is no clear understanding which type of information affects existing RE models to make decisions and how to further improve the performance of these models.", "label": "neutral"}
{"id": "test_3354", "sentence1": "For the case from Mased Language Modeling, we also observe that the sentence that can be used to recover the masked words receives much higher attention weight compared to others, validating our motivation on retrieving the useful sentence embeddings from other sequences to enhance masked word recovery in the current sequence.", "sentence2": "all the models are pre-trained on Wikipedia and finetuned on downstream tasks.", "label": "neutral"}
{"id": "test_3355", "sentence1": "During training, we fix the position embeddings for the pre-appended special tokens, and randomly select 64 continuous positions from 0 to 564 for the other words.", "sentence2": "instead of using the original signals of full sentences, we train a Transformer-based sequence encoder over a large set of short sequences, which allows the model to automatically select the most useful information for predicting masked words.", "label": "neutral"}
{"id": "test_3356", "sentence1": "For the other two datasets -MAWPS and ALG514, -we report the average accuracy and standard error using 5-fold cross-validation.", "sentence2": "in the rest of the paper, we introduce existing approaches to solve algebraic word problems in Section 2.", "label": "neutral"}
{"id": "test_3357", "sentence1": "Early attempts for solving algebraic word problems noted the importance of Expressions in building models with hand-crafted features  (Kushman et al., 2014; Roy et al., 2015; Roy and Roth, 2015; Zhou et al., 2015; Upadhyay et al., 2016).", "sentence2": "existing neural models solve algebraic word problems by using symbols to provide an abstraction of problem-dependent numbers or unknowns.", "label": "neutral"}
{"id": "test_3358", "sentence1": "To utilize contextual information of an operand token, researchers built hand-crafted features that capture the semantic content of a word, such as the unit of a given number (Roy and Roth, 2015; Koncel-Kedziorski et al., 2015; Zhou et al., 2015; Upadhyay et al., 2016; Roy and Roth, 2017) or dependency relationship between numbers (Kushman et al., 2014; Zhou et al., 2015; Upadhyay et al., 2016).", "sentence2": "in this paper, we propose a pure neural model called Expression-Pointer Transformer (EPT) to address the two issues above.", "label": "neutral"}
{"id": "test_3359", "sentence1": "To obtain a solution to the generated equations, we use SymPy (Meurer et al., 2017) at the end of the training phase.", "sentence2": "recent neural models have only utilized \u2018Op (operator/operand)\u2019 tokens (Wang et al., 2017; Amini et al., 2019; Chiang and Chen, 2019; Huang et al., 2018; Wang et al., 2019), resulting in two issues: (1) the expression fragmentation issue and (2) the operand\u0002context separation issue.", "label": "neutral"}
{"id": "test_3360", "sentence1": "The paraphraser can generate phrases like \"find people from Stanford\", which is trivial to parse correctly.", "sentence2": "we use the standard train/test split and following previous work, use 20% of the human paraphrases from the original training set for validation, so that validation and test sets are from the same distribution.", "label": "neutral"}
{"id": "test_3361", "sentence1": "For instance, in this work, if a propaganda class c is predicted by the multiple binary classifiers (indicates the sentence contains this propaganda technique), then the token-level predictions belonging to the propaganda class c should also exist.", "sentence2": "neural networks are less interpretable and need to be trained with a large amount of data to make it possible to learn such implicit logic.", "label": "neutral"}
{"id": "test_3362", "sentence1": "In this paper we propose the use of information from word graphs to enhance intent classification, more specifically, for the detection of out-of-scope examples.", "sentence2": "the difference in ISER of BERT+ against BERT is of 5%, where the former achieved 37% and the latter 32%.", "label": "neutral"}
{"id": "test_3363", "sentence1": "Eq. (7) again asserts something trivial: low contextual uncertainty implies in an informative context.", "sentence2": "in these Figures we see that, especially for highly ambiguous words, contextual uncertainty tends to be very small.", "label": "neutral"}
{"id": "test_3364", "sentence1": "She was allegedly gang-raped on Sunday when she went outside her house in Kosi Kalan, in Uttar Pradesh's Mathura district, to relieve herself.", "sentence2": "there has also been analysis work augmenting ROUGE with human evaluation (Narayan et al., 2018;Liu and Lapata, 2019).", "label": "neutral"}
{"id": "test_3365", "sentence1": "We aim to address the above issues by quantifying the primary sources of errors over representative models.", "sentence2": "for example, a news article describes an event as happening \"on Wednesday\" in a summary although the original document has \"on April 1\".", "label": "neutral"}
{"id": "test_3366", "sentence1": "The footage was shot in September last year after the girl's body was found in woodland, enraging locals.", "sentence2": "the Point-Generator model reduces the error count to 14, demonstrating the effectiveness of the copy mechanism in faithfully reproducing details.", "label": "neutral"}
{"id": "test_3367", "sentence1": "It also reduces duplication on the word level but tends to cause redundancy to a certain degree.", "sentence2": "a human annotator is presented the original text and an output summary in juxtaposition, and is asked to select segments that are deemed incorrect after reading.", "label": "neutral"}
{"id": "test_3368", "sentence1": "Coverage solves repetition errors by a large margin, but shows limits in faithful content generation.", "sentence2": "joined by a groom on another of her fell ponies, the queen cut a relaxed figure as she enjoyed her ride but, as is her wont, eschewed a helmet in favor of one of her silk scarves.", "label": "neutral"}
{"id": "test_3369", "sentence1": "For instance, the F-score of 73.3% for plain UKB with SOFTCONSTRAINT (shown in Table 2) drops to 72.1% with only Japanese translations, to 64.2% with only Italian translations, and to 58.0% with no translations.", "sentence2": "for fair comparison, when applying SOfTCONSTRAINT to a system variant without sense frequency information, we set \u03b3 to 0 to turn off the p freq component.", "label": "neutral"}
{"id": "test_3370", "sentence1": "An example is illustrated in Figure 1, where Allan Donald and The 48-year-old former Test paceman are enriched with the same special tokens.", "sentence2": "existing summarizers cannot make effective use of these expressions to establish correspondence between sentences, often leading to ungrammatical and nonsensical outputs.", "label": "neutral"}
{"id": "test_3371", "sentence1": "Recent innovations in Transformer-based ranking models have advanced the state-ofthe-art in information retrieval.", "sentence2": "total, Online, Online, 1 Query-Document Pair 1 Query-Document Pair N doc Documents typical transformer Ranker reuse strategies with different time vs. space trade-offs: 1) a document representation reuse strategy that stores the Document Representation Module's output, and 2) a projected document representation reuse strategy that stores the Interaction Module's intermediate transformed document representations.", "label": "neutral"}
{"id": "test_3372", "sentence1": "These strategies have the same overall math, produce the same ranking results, and only differ in time/space efficiency.", "sentence2": "the performance gains come at the computational cost of inferring the many token-level interaction signals at the evaluation time, which scales quadratically to the input length.", "label": "neutral"}
{"id": "test_3373", "sentence1": "Moreover, latent-variable models can represent multimodal distributions.", "sentence2": "in Section 3, we show that encoders learn to partially memorize the first few words and the document lengths, as was first discovered by Kim et al.", "label": "neutral"}
{"id": "test_3374", "sentence1": "However, information related to the second word in the latent variable can help the decoder predict the first word.", "sentence2": "moreover, using reconstructions, we observe that they decrease memorization: the first word and the sentence length are not recovered as accurately than with the baselines, consequently yielding more diverse reconstructions.", "label": "neutral"}
{"id": "test_3375", "sentence1": "We use the resized image patches as additional training data to to emphasize these patches' importance.", "sentence2": "we focus on eliciting fewer but more informative explanations to reduce expert involvement.", "label": "neutral"}
{"id": "test_3376", "sentence1": "Note, however, that the models fit the training data worse and do not generalize as well as the original model.", "sentence2": "as training data we use the English Easy-to-Read version of the Parallel Bible Corpus (Mayer and Cysouw, 2014) that contains the New Testament.", "label": "neutral"}
{"id": "test_3377", "sentence1": "The Pearson correlation between Kendall's tau metric and the XNLI classification accuracy in a zero-shot scenario (mBERT only finetuned on English and tested on all other languages) is 46% when disregarding English and 64% when including English.", "sentence2": "iD 0 shows high multilinguality with 0-shot accuracies .57 and .45.", "label": "neutral"}
{"id": "test_3378", "sentence1": "This shows that, the proposed method can effectively utilize the added language-specific adapters to improve generalization of shared parameters across languages.", "sentence2": "we show that, contrary to previous belief, negative interference also impacts low-resource languages.", "label": "neutral"}
{"id": "test_3379", "sentence1": "Advances in pretraining language models (Devlin et al., 2018; Liu et al., 2019; Yang et al., 2019) as general-purpose representations have pushed the state of the art on a variety of natural language tasks.", "sentence2": "To study negative interference, we compare multilingual models with monolingual baselines.", "label": "neutral"}
{"id": "test_3380", "sentence1": "A more negative value indicates that the parameter is more likely to be pruned for that language and vice versa.", "sentence2": "we use the Universal Dependencies treebanks (Nivre et al., 2018).", "label": "neutral"}
{"id": "test_3381", "sentence1": "For ablation studies, we also report results for JointPair trained with adapters shared between two languages, denoted as share adpt.", "sentence2": "we study whether gradient conflicts exist between languages in multilingual models.", "label": "neutral"}
{"id": "test_3382", "sentence1": "Not only is beam search usually more accurate than greedy search, but it also outputs a diverse set of decodings, enabling reranking approaches to further improve accuracy (Yee et al., 2019; Ng et al., 2019; Charniak and Johnson, 2005; Ge and Mooney, 2006).", "sentence2": "this lightweight model is no longer state of the art, but its decoding is representative of more recent architectures (Suhr et al., 2018; Yin and Neubig, 2018; Lin et al., 2019).", "label": "neutral"}
{"id": "test_3383", "sentence1": "For languages with rare scripts (e.g., CJK and Thai), CLUSTER strongly outperforms JOINT in all tasks.", "sentence2": "as an extreme example, a character-based model would have to learn how to reconstruct each word, while a word-based model is exempt from this task.", "label": "neutral"}
{"id": "test_3384", "sentence1": "We tune the number of fine-tuning epochs and batch-size using the development data of Scitail and Amazon Electronics tasks following (Bansal et al., 2019).", "sentence2": "Fig. 5 and Fig. 6 show the CCA similarity on the two datasets: CoNLL and Scitail.", "label": "neutral"}
{"id": "test_3385", "sentence1": "As Wiki itself is a collaborative knowledge repository, editors are likely to attack others due to disputes on specific domain knowledge.", "sentence2": "unlike the cloze procedure, text normalization involves more diversified and challenging tasks.", "label": "neutral"}
{"id": "test_3386", "sentence1": "It randomly masks a certain portion of tokens from the input and then learns to predict these masked words.", "sentence2": "tNt randomly manipulates tokens from the input text.", "label": "neutral"}
{"id": "test_3387", "sentence1": "We show the minimum and maximum accuracy for each task across the 10 experiments.", "sentence2": "published results for mBERT zero-shot accuracy vary as much as 17 points on the MLDoc classification task across four papers.", "label": "neutral"}
{"id": "test_3388", "sentence1": "This shares the same underlying sequence-consistency concept as BERT's MLM.", "sentence2": "this is prohibitively expensive due to the computational costs.", "label": "neutral"}
{"id": "test_3389", "sentence1": "The decoupled biLSTM extended with ELMo inputs is able to outperform the transformer model initialised with RoBERTa pretraining.", "sentence2": "for an extended version of this model, we also try incorporating contextualized word vectors, by augmenting the input with ELMo embeddings (Peters et al., 2018).", "label": "neutral"}
{"id": "test_3390", "sentence1": "MASKAUGMENT through DAL and MTL objectives becomes larger as the number of labeled dialogues in the source domain gets smaller.", "sentence2": "table 5: Micro-F1 scores for each dialog act (DA) on the test split of target (GRes) domain.", "label": "neutral"}
{"id": "test_3391", "sentence1": "However, existing adversarial text generation approaches that try to perturb in the input text space might lead to generations lacking diversity or fluency.", "sentence2": "we argue that our model creates more natural and meaningful attacks to real-world tasks by demonstrating our attacks are more robust against model re-training and across model architectures.", "label": "neutral"}
{"id": "test_3392", "sentence1": "After this initially automated training, we scheduled a 1hour long phone call with them to discuss our annotation instructions and annotation interface.", "sentence2": "small-scale studies on manually annotated datasets have also been conducted (Morris and Picard, 2012; Lord et al., 2015).", "label": "neutral"}
{"id": "test_3393", "sentence1": "This intuition is confirmed by an analysis of the discourse connective \"though\" among all posts we collected, which revealed a clear tendency towards the end of a reply, as illustrated in Figure 1.The lexical discourse marker \"though\" was found by splitting a large collection of posts and replies from r/AskParents into Elementary Discourse Units (Mann and Thompson, 1988), using a neural discourse segmenter (Wang et al., 2018).", "sentence2": "as (1) shows, the entirety of a response to a question rarely constitutes advice.", "label": "neutral"}
{"id": "test_3394", "sentence1": "For instance, BEESL identifies the +REG-ULATION event anchored at \"activated\" in the following sentence: \"Tax [...] maximally activated HTLV-I-LTR-CAT and kappa B-fos-CA\" albeit the gold standard does not contain the event in this instance.", "sentence2": "this shows that BEESL's performance is clearly affected, but that the system is relatively robust to noisy, nongold silver entities.", "label": "neutral"}
{"id": "test_3395", "sentence1": "Without multi-task learning and multi-label decoding, the F1 score drops to 61.44 (independent classifiers) and 61.13 (ST setup, BEESL ST in Table 3).", "sentence2": "the full power of BEESL is only achieved by using both the multi-task and the multi-label approach, which leads to the novel state of the art.", "label": "neutral"}
{"id": "test_3396", "sentence1": "In our experiments, we aim at evaluating the multilingual and the cross-lingual question answering capabilities of different models.", "sentence2": "One reason is that many of the subjects in these two groups such as Business & Economics, Geography, and History can be answered using knowledge that is easily accessible in sources such as Wikipedia (e.g., \u201cWho was the first prime minister of Poland after 1990?\u201d), i.e., without the need for complex reasoning or calculations, which are often needed in order to answer questions in subjects such as Physics and Chemistry.", "label": "neutral"}
{"id": "test_3397", "sentence1": "In the Public Figures data, the lexicons that overlap the most with the high-bias posts are \"Beautiful\", \"Arrogant\", and \"Sexual\", which suggests that bias  in these comments focuses on appearance and sexualization.", "sentence2": "we then generate masked posts: for every word w in the post, we generate a version of the post that omits w. we run these masked posts through our gender-prediction model and compare the prediction scores where w is omitted and where w is not omitted, averaging across all occurrences of w in the 500 posts.", "label": "neutral"}
{"id": "test_3398", "sentence1": "If women ask \u201cDo I look ok?\u201d more frequently than men, this naive classifier would identify \u201cUR hot!\u201d", "sentence2": "when it is addressed to someone who said \"Do I look ok?", "label": "neutral"}
{"id": "test_3399", "sentence1": "If the classifier predicts the gender of the addressee with high confidence based only on the text directed to them, we hypothesize that the text is likely to contain bias.", "sentence2": "bias in comments directed towards politicians are less focused, and differences between the high-confidence prediction posts and the random sample are smaller.", "label": "neutral"}
{"id": "test_3400", "sentence1": "Pixel+Local, which uses both image encoding, g i , and the structural representation computed only based on the properties of the element, offers further improvement on the accuracy.", "sentence2": "the most frequent caption is \"go back\" that amounts to 4.0% of the distribution.", "label": "neutral"}
{"id": "test_3401", "sentence1": "Finally, the Predicate + Object captions were identified as the ones that contain at least one of the 22 verbs and one of the 194 nouns and appear at least twice in the corpus.", "sentence2": "the view hierarchy is a structural tree representation of the UI where each node has a set of properties such as content description, class information, visibility, and bounding boxes.", "label": "neutral"}
{"id": "test_3402", "sentence1": "We elaborate the encoders in section 3.3.", "sentence2": "it embeds visual knowledge even for plain text inference.", "label": "neutral"}
{"id": "test_3403", "sentence1": "The fact that SeqMix can improve over simple regularization methods (such as WordDrop) even without GECA indicates that despite its crudity, SeqMix is somewhat effective at biasing models to learn the appropriate compositional structure.", "sentence2": "sCAN sCAN is a command execution dataset designed to test for systematic compositionality of data-driven models.", "label": "neutral"}
{"id": "test_3404", "sentence1": "For both, we use Reddit comments as our base data.", "sentence2": "our results disagree with prior observations on empathy and we find that, while the compassion-like empathy of Buechel et al.", "label": "neutral"}
{"id": "test_3405", "sentence1": "We empirically investigate three different methods for inducing semantic dependencies, including attention (Vaswani et al., 2017), sparse attention (Correia et al., 2019) and hard Kuma discrete structures (Bastings et al., 2019).", "sentence2": "Sun et al. (2019b) also proposed a GCN model based on dependency trees for aspect sentiment analysis similar to depGCN of .", "label": "neutral"}
{"id": "test_3406", "sentence1": "In 1995, Lyla Novacek (Keri Russell) is a cellist studying at the Juilliard School and living under strict rule of her father (William Sadler).", "sentence2": "they both seem to be \"just in it for the money\"I really hope this will be the last Rush Hour film, the first and second was both really really enjoyable with fun comments, good comedy and good action scenes this third installment has nothing of it.For some good Jackie action stick with his older films and those made in Hong Kong, for Chris tucker films watch any other film he's in besides this one..the goofy antics of Chris tucker mixed with the amazing martial arts moves of Jackie Chan made both of the previous Rush Hour films funny and entertaining.", "label": "neutral"}
{"id": "test_3407", "sentence1": "Results in Table 4 show that, our system can indeed predict tags that are very relevant to the new types of stories.", "sentence2": "this paper considers the problem of characterizing stories by inferring properties such as theme and style using written synopses and reviews of movies.", "label": "neutral"}
{"id": "test_3408", "sentence1": "The speed at which movies get reviews fluctuates a lot.", "sentence2": "com'on, ye people of sense and sensibility, join me and suffer this movie and be merry you found the strength and then give it the only rating it deserves....PS: I am not going to elaborate on the \"oh-you're-so-mean!\"", "label": "neutral"}
{"id": "test_3409", "sentence1": "I want to think that most of Rush Hour 3's problems are attributed to the fact that it was just a rushed film.", "sentence2": "i just finished watching August Rush and i am in no way exaggerating when i say that it is by far the best movie i have ever seen.", "label": "neutral"}
{"id": "test_3410", "sentence1": "Given this, can we recover phylogenetic similarities across gender systems using our methods?", "sentence2": "several variants of MI are preferred in community detection.", "label": "neutral"}
{"id": "test_3411", "sentence1": "Because different random restarts yield different accuracy results, we report ranges.", "sentence2": "using our own data, we estimate their character corpus at \u223c30,000 tokens.", "label": "neutral"}
{"id": "test_3412", "sentence1": "We run the same initial procedure from Section 5, giving us a vector space inhabited by both written words and pinyin words.", "sentence2": "while EM only considers the top M pinyin triples, final decoding works on entire sentences and is free to create previously-unseen pinyin trigrams.", "label": "neutral"}
{"id": "test_3413", "sentence1": "We ran their expectation-maximization (EM) algorithm for 170 iterations on a character corpus of 300,000 tokens, then applied their decoding algorithm to our 6059-token test, obtaining a token pronunciation accuracy of 8.6%.", "sentence2": "we modify the nearestneighbor search that produces word/pronunciation mappings.", "label": "neutral"}
{"id": "test_3414", "sentence1": "The results show that our method can consistently outperform the baselines, particularly when the given gold training data are less.", "sentence2": "We follow similar experimental settings as NER and POS tasks, except that the same sequence tagging model released by Li et al. (2019a) is used for evaluation", "label": "neutral"}
{"id": "test_3415", "sentence1": "For example, \"[ORG U.N.] official [PER Ekeus] heads for [LOC Baghdad] \".", "sentence2": "for random deletion, we also report the result when gold and synthetic data are equally sampled, denoted by rd * .", "label": "neutral"}
{"id": "test_3416", "sentence1": "However, because their model again conditions on the target data, they have to train the autoencoder jointly with the target corpus, defeating the purpose of large-scale pretraining.", "sentence2": "in this study, we apply it to supervised and unsupervised text style transfer.", "label": "neutral"}
{"id": "test_3417", "sentence1": "For the sentiment classification task, T3 can perform the targeted attack to make an originally positive review be classified as the most negative one, and vice versa.", "sentence2": "In most countries, the dispensary is subject to pharmacy legislation; with requirements for storage conditions, compulsory texts, equipment, etc., specified in legislation.", "label": "neutral"}
{"id": "test_3418", "sentence1": "Contextual embeddings are proved to be overwhelmingly effective to the task of Word Sense Disambiguation (WSD) compared with other sense representation techniques.", "sentence2": "this has revealed the potential of such a fine-grained WordNet gloss utilization, and the employment of more valuable resources such as Wikipedia rather than web mentions for further investigation.", "label": "neutral"}
{"id": "test_3419", "sentence1": "\"It always bothered me that we confused an enduring mission with a temporal goal. \"'", "sentence2": "the terrorists destroyed \"Iraq newspapers dating to the early 20th century, maps and books from the Ottoman Empire, and book collections contributed by about 100 of Mosul's establishment families. \"", "label": "neutral"}
{"id": "test_3420", "sentence1": "In this paper, we instead use a NER model trained on the source domain to learn token-level representations that minimizes the supervised cross-entropy loss.", "sentence2": "we use the OntoNotes train/development/test splits released for the CoNLL 2012 shared task.", "label": "neutral"}
{"id": "test_3421", "sentence1": "By using regex-based extractors and a list of comprehensive dictionaries that capture crucial domain vocabularies, LUSTRE can generate rules that achieve SoTA results.", "sentence2": "since CRF-AW is fully supervised, we give it the sets of labels we iteratively accumulated during the active learning of our model.", "label": "neutral"}
{"id": "test_3422", "sentence1": "The difference between the token and componentlevel evaluation is that the former accumulates the credits over all tokens regardless the actual classes they belong to, whereas the latter evaluation accumulates the credits with respect to the actual classes.", "sentence2": "we developed a system named PARTNER (Qian et al., 2020) that implements this framework.", "label": "neutral"}
{"id": "test_3423", "sentence1": "Length of the context plays an important role.", "sentence2": "in unconstrained human descriptions of changes, \u223c40% of the referred-to entities were unmentioned in the text (e.g., the knife and cutting board in several cooking recipes) (\u00a74.4).", "label": "neutral"}
{"id": "test_3424", "sentence1": "For the sake of completeness, we provide Table A2 to help further explore the depths of this unique dataset.", "sentence2": "we thus face the challenge of how best to optimize our usage of the limited input space, which is made more difficult by the many different types of input context (e.g., entries, characters, challenges) within STORIUM.", "label": "neutral"}
{"id": "test_3425", "sentence1": "While GPT-2 has successfully been used as a state-of-the-art model for story generation (Mao et al., 2019;Guan et al., 2020), one crucial challenge is the length of the contexts: each entry in a story can condition on any narrative element that comes before it (e.g., previous entries, scenes, challenges).", "sentence2": "We then only consider substrings with at least one nonstopword as matches matches (careful scrutiny of Figure 1 reveals an unmatched stopword it).", "label": "neutral"}
{"id": "test_3426", "sentence1": "Our template based approach bears similarities to sentence fusion (Barzilay and McKeown, 2005), and prototype based text editing (Hossain et al., 2020; Cao et al., 2018; Guu et al., 2018; Wu et al., 2019).", "sentence2": "in this work, we investigate two methods for Natural Language Generation (NLG) using a single domain-independent model across a large number of APis.", "label": "neutral"}
{"id": "test_3427", "sentence1": "In this work, we focus on tackling the first problem only.", "sentence2": "experiments show that our approach achieves the state-of-the-art on supervised event extraction and discovers a set of high-quality unseen types.", "label": "neutral"}
{"id": "test_3428", "sentence1": "More specifically, 1) SANA achieves 84.35% in SST2 dataset which is higher than the distillation only model, but lower than task-level supervised model.", "sentence2": "instead of treating attention as a by-product of model training, the following work explored how machine/human can consume attention for model improvement or explanation, respectively.", "label": "neutral"}
{"id": "test_3429", "sentence1": "Tab. 2 shows the classification accuracy for three classification datasets.", "sentence2": "our work is of combining the strength of the two works: we automatically improve attention supervision via self-supervision signals, but we build it with free task-level resources.", "label": "neutral"}
{"id": "test_3430", "sentence1": "For each task, we train binary logistic regression probes with a range of hidden sizes and select the smallest yielding at least 97% of the best model's performance.", "sentence2": "our results point to a paradigm of probing with latent variables, for which LSL is one potential technique.", "label": "neutral"}
{"id": "test_3431", "sentence1": "Descriptive methods produce highspecificity tests of what structure is present in the model, and facilitate discovery of new patterns that were not hypothesized prior to testing.", "sentence2": "for all LSL probes, we use N = 32 latent classes.", "label": "neutral"}
{"id": "test_3432", "sentence1": "Since nPMI is information-theoretic and chance-corrected, it is a reliable indicator of the degree of information about gold labels contained in a set of predicted clusters.", "sentence2": "that is the question we investigate in this work.", "label": "neutral"}
{"id": "test_3433", "sentence1": "Morevoer, cycle-GANs only synthesize the input and verify whether the input is synthesized (e.g. the utterance looks like a user request).", "sentence2": "we proposed GAZP to adapt an existing semantic parser to new environments by synthesizing cycle-consistent data.", "label": "neutral"}
{"id": "test_3434", "sentence1": "Results in Table 8 show that SentiLARE-EF-LS already outperforms RoBERTa remarkably on SST-Less by simply augmenting input features with linguistic knowledge.", "sentence2": "the statistics of these datasets are reported in table 4.", "label": "neutral"}
{"id": "test_3435", "sentence1": "In the neural CRF model, the score can be obtained from the neural network encoders such as biLSTM networks.", "sentence2": "peer review and rebuttal, containing rich arguments, are a worth-studying domain for argument mining.", "label": "neutral"}
{"id": "test_3436", "sentence1": "information about reviews and author responses, such as review passages, rebuttal passages, review scores, reviewer confidence, etc.", "sentence2": "we further evaluate the performance of different difficulty levels.", "label": "neutral"}
{"id": "test_3437", "sentence1": "For example, the idiom \"Time is money\" is a metaphor in which \"time\" is the noumenon and \"money\" is the metaphoric object.", "sentence2": "as mentioned earlier, these categories are not disjoint.", "label": "neutral"}
{"id": "test_3438", "sentence1": "First, we conduct a statistical analysis in an attempt to answer various questions involving exaggeration, such as: (1) are there strong lexical indicators of hyperbole; (2) how lexically diverse are the non-hyperbolic versions of a given hyperbolic sentence; and (3) how lexically diverse are the hyperbolic versions of a given nonhyperbolic sentence?", "sentence2": "first, given that hyperbolic sentences may be more descriptive (e.g., compare the first sentence in each class in Table 1), are hyperbolic sentences longer than non-hyperbolic sentences on average?", "label": "neutral"}
{"id": "test_3439", "sentence1": "Ferre (2014) shows that at the textual level, a hyperbole can be present in a word or in the interpretation of a certain context.", "sentence2": "the more word overlaps there are between two sentences, the higher their similarity is.", "label": "neutral"}
{"id": "test_3440", "sentence1": "Figures 17 to 22 show additional examples of the extracted alignments from the different layers of the NMT system.", "sentence2": "in Sections 4 and 5, we provide insights into the working of Transformers using norm-based analysis.", "label": "neutral"}
{"id": "test_3441", "sentence1": "To verify whether the results obtained in the Section 5 are reproducible in different settings, we conducted an additional experiment using the model with a different number of attention heads.", "sentence2": "note that we analyzed a model with 12 heads in each layer.", "label": "neutral"}
{"id": "test_3442", "sentence1": "We fine-tune a pretrained BERT base model on the dataset of the CoNLL'03 NER shared task (Tjong Kim Sang and De Meulder, 2003) and use it to extract entities from candidate paragraphs.", "sentence2": "hotpotQA is a widely used large-scale multi-hop QA dataset.", "label": "neutral"}
{"id": "test_3443", "sentence1": "Nevertheless, when pre-trained models are used as a fine-tuning approach, which is a common practice, graph structure does not contribute to the final results.", "sentence2": "in feature-based setting, all models are trained for 30 epochs with a batch size of 24.", "label": "neutral"}
{"id": "test_3444", "sentence1": "Selected paragraphs are concatenated as context C. Encoding Layer.", "sentence2": "we suppose this is another attention pattern that entities attend to the whole sentence.", "label": "neutral"}
{"id": "test_3445", "sentence1": "Hallucinations Other errors stem from the fact that the model can only rely on the knowledge about possible definienda that it is able to store in the parameters during the pre-training and training stages.", "sentence2": "In this paper we overcome these limitations by proposing a unified approach to computational lexi\u0002cal semantics that has as its central focus Definition Modeling (DM), i.e. the task of generating a gloss1 from static or contextual embeddings (No\u0002raset et al., 2017", "label": "neutral"}
{"id": "test_3446", "sentence1": "We also note that none of the results with L=n configurations from Table 1 can match best performing AVG(L\u2264n) configurations with layer-wise averaging.", "sentence2": "all scores are Mean Reciprocal Rank (MRR) scores (in the standard scoring interval, 0.0-1.0).", "label": "neutral"}
{"id": "test_3447", "sentence1": "Another observation that holds across all configurations concerns the usefulness of providing contexts drawn from external corpora, and corroborates findings from prior work (Liu et al., 2019b): ISO configurations cannot match configurations that average subword embeddings from multiple contexts (AOC-10 and AOC-100).", "sentence2": "micro-averaged F 1 scores reported , obtained as averages over 5 experimental runs for each configuration; standard deviation is also reported.", "label": "neutral"}
{"id": "test_3448", "sentence1": "In other words, we can intervene on the location entity to set it to another different location entity without destroying the sentence correctness at the grammatical level.", "sentence2": "firstly, we review the definition of the structural causal model (SCM) (See figure 2(a)): e := f E (g) c := f C (g) x := f X (e, c) where G is a confounding variable that influences the generation of both entity E and context C, X is the input example that is generated by E and C, and Y is the evaluation result (the f 1 score) of the NER model.", "label": "neutral"}
{"id": "test_3449", "sentence1": "This phenomenon suggests that the non-spurious correlations are more located in entity representation rather than context representation.", "sentence2": "data acquisition is a challenging task for some special domains.", "label": "neutral"}
{"id": "test_3450", "sentence1": "And it proves that the state-of-the-art neural networks can easily exploit such name regularity, mention coverage and context diversity knowledge, and therefore achieve state-of-the-art performance in these benchmarks.", "sentence2": "despite the success of recent models, there are specific advantages in current NER benchmarks which significantly facilitate supervised neural networks.", "label": "neutral"}
{"id": "test_3451", "sentence1": "Because currently no suitable dataset is available for verifying our conclusions, this paper constructs a new dataset from Wikipedia.", "sentence2": "in this way, all mentions will share identical frequency in the vanilla and CR dataset.", "label": "neutral"}
{"id": "test_3452", "sentence1": "In the following, we will illustrate the empirical findings through the test, with one subsection for one kind of information.", "sentence2": "this group of experiments can be used to verify the Conclusion 3 we proposed before.", "label": "neutral"}
{"id": "test_3453", "sentence1": "Table 1 shows all our randomization test with examples.", "sentence2": "our investigation leads to three valuable conclusions, which shows the necessity of de-cent name regularity to identify unseen mentions, the hazard of high mention coverage to model generalization, and the redundancy of enormous data to capture context patterns.", "label": "neutral"}
{"id": "test_3454", "sentence1": "For example, the political relationship between two countries might intensify because of trade fights.", "sentence2": "we report the best results on each dataset in Table 1 in the main body.", "label": "neutral"}
{"id": "test_3455", "sentence1": "Since then, hyperbolic analogs of several other approaches have been developed (De Sa et al., 2018; Tifrea et al., 2018).", "sentence2": "an important analogy to vector spaces (vector addition and scalar multiplication) in non-Euclidean geometry is the notion of gyrovector spaces (Ungar, 2008).", "label": "neutral"}
{"id": "test_3456", "sentence1": "Also, the degree of each entity is accumulated over all timestamps.", "sentence2": "existing embedding approaches for temporal KGs typically learn entity representations and their dynamic evolution in the Euclidean space, which might not capture such intrinsic structures very well.", "label": "neutral"}
{"id": "test_3457", "sentence1": "To retain high-confidence predictions for self-training, ensemble methods like tri-training (Saito et al., 2017), mutual learning (Ge et al., 2020) and dual information maximization (Ye et al., 2019) have been introduced.", "sentence2": "in the training process, we predict pseudo labels on all the target samples in T .", "label": "neutral"}
{"id": "test_3458", "sentence1": "Without this, systems run the risk of merely paraphrasing the biases in text.", "sentence2": "in the second example, \"Ana strutted\" implies that she is more active and decisive, compared to \"Ana wandered\" which portrays her as aimless and passive.", "label": "neutral"}
{"id": "test_3459", "sentence1": "Probabilities p b are assigned to each training instance to indicate how likely that it contains biases.", "sentence2": "for each setting, we report the average results across 5 runs.", "label": "neutral"}
{"id": "test_3460", "sentence1": "2019, and report test results for the last epoch.", "sentence2": "recall that, in this approach, the test set is machine translated into English, but training is typically done on original English data.", "label": "neutral"}
{"id": "test_3461", "sentence1": "The second is the use of antonyms or adversarial object-words to substitute critical words.", "sentence2": "the first operator is negation for yes-no questions, which  is achieved by a template based procedure that negates the question by adding a \"no\" or \"not\" before a verb, preposition or noun phrase.", "label": "neutral"}
{"id": "test_3462", "sentence1": "Identifying that the distribution of answers in the VQA dataset led models to learn superficial correlations, Agrawal et al. (2018a) pro\u0002posed the VQA-CP dataset by re-organizing the train and test splits such that the the distribution of answers per question-type was significantly differ\u0002ent for each split.", "sentence2": "over-reliance on datasets can cause models to learn spurious correlations such as linguistic priors (Agrawal et al., 2018a) that are specific to certain datasets and do not generalize to \"Out-of-Distribution\" (OOD) samples, as shown in Figure 1.", "label": "neutral"}
{"id": "test_3463", "sentence1": "Note that these 100 examples are expected to be enriched with positive examples, yet in a biased manner, since by construction, all examples match the query we started with.", "sentence2": "we focus on practical scenarios of binary text classification, where the annotation budget is very small, and the data is often skewed.", "label": "neutral"}
{"id": "test_3464", "sentence1": "Information about the performance on the test set of the queries used in the Imbalanced-practical scenario is given in Table 5.", "sentence2": "the use of AL with deep pre-trained models for text classification -and BERT in particular -has so far received surprisingly little consideration.", "label": "neutral"}
{"id": "test_3465", "sentence1": "We further extended our VVMAs beyond NLP, to image classification.", "sentence2": "we also used VVMAs for the matrices in the attention mechanism.", "label": "neutral"}
{"id": "test_3466", "sentence1": "Stehwien and Vu (2017) and Stehwien et al. (2018) (henceforth, SVS18) showed that neural methods can perform comparably to traditional methods us\u0002ing a relatively small amount of speech context\u2014 just a single word on either side of the target word.", "sentence2": "In future, we could follow Tran et al. (2018) by giving an explicit feature for the dura\u0002tion of a given token normalized by the average duration of that token in the corpus", "label": "neutral"}
{"id": "test_3467", "sentence1": "For a detailed description of how we divided data into train, development, and test sets for cross-validation, see Appendix A.2.", "sentence2": "since pitch accents are deviations from a speaker's average pitch, intensity, and duration, we hypothesize that, as in some non-neural models (e.g.", "label": "neutral"}
{"id": "test_3468", "sentence1": "Following Shah et al. (2018); Rastogi et al. (2019), every grammar production in the simulator is paired with a template whose slots are synchronously expanded.", "sentence2": "this shows the impact of error propagation as the model predicts the target dialog state based on past representations.", "label": "neutral"}
{"id": "test_3469", "sentence1": "We use a two-phase coordinate ascent framework as described in Algorithm 1.", "sentence2": "as expected, by inducing our model to predict the question attributes for the target utterance, our model achieves the highest inquisitiveness (58% question rate).", "label": "neutral"}
{"id": "test_3470", "sentence1": "For probabilistic linking, we use a 6-layer encoder-decoder Transformer model (Vaswani et al., 2017).", "sentence2": "we aim to train a linking model such that conditioning on linked documents has a positive effect on dialog modeling performance.", "label": "neutral"}
{"id": "test_3471", "sentence1": "In this task, each example consists of a pair of short texts: a premise and a hypothesis.", "sentence2": "we propose four alternative protocols, each aimed at improving either the ease with which annotators can produce sound training examples or the quality and diversity of those examples.", "label": "neutral"}
{"id": "test_3472", "sentence1": "The research on TE dates back more than two decades and has made significant progress.", "sentence2": "we often solve each task separately by first gathering task-specific training data and then tuning a machine learning system to learn the patterns in the data.", "label": "neutral"}
{"id": "test_3473", "sentence1": "Creation of CONJNLI involves four stages, as shown in Figure 1.", "sentence2": "once the conjuncts are identified, we perform three operations by removing, adding or replacing one of the two conjuncts to obtain another sentence such that the original sentence and the modified sentence form a plausible NLI pair.", "label": "neutral"}
{"id": "test_3474", "sentence1": "As an example, we apply it on the boolean subset of the dataset by Richardson et al. (2020) containing samples with \u201cboolean and\u201d and find that our model achieves a near perfect accuracy on their test set.", "sentence2": "6.3 Predicate-Aware RoBERTa with Adversarial Fine-Tuning Table 8 consolidates our final results on both the datasets.", "label": "neutral"}
{"id": "test_3475", "sentence1": "You and your friends are not welcome here, said Severn.", "sentence2": "following their suggestion, we conduct an instability analysis of CONJNLI by training RoBERTa on MNLI with 10 different seeds (1 to 10) and find that the results on CONJNLI are quite robust to such variations.", "label": "neutral"}
{"id": "test_3476", "sentence1": "From the systems perspective, natural language processing pipelines that include knowledge graphs can rely on calibrated confidence scores to determine which KGE predictions to trust.", "sentence2": "to arrive at your answer, you must use English-language Wikidata and/or Wikipedia, even if you know the answer ahead of time.", "label": "neutral"}
{"id": "test_3477", "sentence1": "Note that there have been recent (concurrent) efforts to construct appropriate datasets for evaluating KGE calibration (Pezeshkpour et al., 2020; Safavi and Koutra, 2020).", "sentence2": "now we need a label for every triple considered, whereas with the CWA we only needed labels for a small group of positives.", "label": "neutral"}
{"id": "test_3478", "sentence1": "It is worth mentioning that our expansion here is adaptive and every label may have a different number of seeds.", "sentence2": "mETA does not restrict to single metadata types and goes beyond by employing motif patterns to capture the metadata information.", "label": "neutral"}
{"id": "test_3479", "sentence1": "Table 4 shows the performance of SHERLOCK and the baselines for both the explicit negation and the implied negation cases.", "sentence2": "the main idea is to find the subject associated with the governor node, and extract that as the wide scope (\"Next week\").", "label": "neutral"}
{"id": "test_3480", "sentence1": "The current state of the art learned method uses a Neural BiLSTM-CRF model (Fancellu et al., 2016).", "sentence2": "Finally, for some cases, we also use domain specific cues that imply a non-availability (For example, in \u201cDr. John out of office on Monday.\u201d, \u201cout of office\u201d implies an unavailability to meet.)", "label": "neutral"}
{"id": "test_3481", "sentence1": "2 experts with experience in recruiting applicants for CRC positions of all levels design the annotation guidelines in 5 rounds by labeling each resume with either one of the four CRC levels, CRC1-4, or Not Qualified (NQ), indicating that the applicant is not qualified for any CRC level.", "sentence2": "given the maximum number of tokens, N , that the transformer encoder (TE) allows, any section S i \u00c3\u00a2\u00cb\u2020\u00cb\u2020 R that contains more than N -number of tokens is pruned by applying the following procedure: Then, the pruned section S i is created for every S i , where S i \u00c3\u00a2\u00c5\u00a0\u00e2\u20ac\u00a0 S i and |S i | \u00c3\u00a2\u00e2\u20ac\u00b0\u00c2\u00a4 N .", "label": "neutral"}
{"id": "test_3482", "sentence1": "Several previous studies have identified such flaws and reported that the corpus is noisy (Vinyals and Le, 2015 ;Li et al., 2016; Baheti et al., 2018), where noisy refers to unacceptable utterance pairs in this context.", "sentence2": "of our preliminary experiment, we discover that, out of all scores given for utterance pairs, 25% was unacceptable (scored as 1: Strongly disagree or 2: Disagree) and almost half was acceptable (scored as 5: Strongly agree or 4: Agree).", "label": "neutral"}
{"id": "test_3483", "sentence1": "In our experiments, the DQN model is trained 100 epochs where each epoch contains 1,000 transitions.", "sentence2": "we parameterize an approximate value function Q(s, a; \u03b8) using a three-layer deep neural network.", "label": "neutral"}
{"id": "test_3484", "sentence1": "Decoders A and B are specialized to generate only sentences and paths (respectively) from these embeddings.", "sentence2": "if BLEU2 metric is used for the selection, then BERT-GRU achieves higher scores.", "label": "neutral"}
{"id": "test_3485", "sentence1": "As can be seen from the table, KGPT can achieve better results than the mentioned baseline models.", "sentence2": "though template-GPt-2 is getting slightly better score with 500 training samples, the overall performance on three datasets are remarkably lower than KGPt, especially under more extreme cases.", "label": "neutral"}
{"id": "test_3486", "sentence1": "As the input RDF triples were modified from the original triples in DBPedia, we first need to check whether there are seen triples in pre-training dataset KGTEXT.", "sentence2": "the existing pre-trained text generation models (Radford et al., 2019; Keskar et al., 2019; Raffel et al., 2019) are initially designed to condition on text input, thus lacking the ability to encode structured inputs.", "label": "neutral"}
{"id": "test_3487", "sentence1": "We use documents of English Wikipedia and BookCorpus (Zhu et al., 2015) as our pre-training corpus, and perform WordPiece tokenization as BERT (Devlin et al., 2018).", "sentence2": "it differs from existing generative pre-training methods in that PALM goes beyond the solely autoencoding/autoregressive methods and combines the merits of autoencoding and autoregression in a single framework.", "label": "neutral"}
{"id": "test_3488", "sentence1": "PALM gives surprisingly good empirical results on a variety of context-aware generation tasks, including pushing the state-of-the-art Rouge-L on the MARCO Natural Language Generation benchmark to 0.498 (Rank 1 on the leaderboard 1 ) and on Gigaword summarization to 36.75, as well as establishing the state-of-the-art ROUGE-1 (44.30) and ROUGE-L (41.41) on CNN/Daily Mail.", "sentence2": "bERT does not make predictions autoregressively, so it is not effective for generation tasks.", "label": "neutral"}
{"id": "test_3489", "sentence1": "Latent state s \u2208 S contains the current game information (e.g. locations of the player and items, the player\u2019s inventory), which is only partially reflected in o.", "sentence2": "we train this model for 10 epochs until the validation loss converges, unlike previous models which we train for 3 epochs.", "label": "neutral"}
{"id": "test_3490", "sentence1": "Natural Language Generation (NLG) is a challenging problem in Natural Language Processing (NLP)-the complex nature of NLG tasks arise particularly in the output space.", "sentence2": "this suggests that CIDEr might be unstable and sensitive to the selection of references.", "label": "neutral"}
{"id": "test_3491", "sentence1": "In addition, a handful of models for the TwitterStance dataset have been designed for cross-target stance detection (Augenstein et al., 2016; Xu et al., 2018), including a number of weakly supervised methods using unlabeled data related to the test topic (Zarrella and Marsh, 2016; Wei et al., 2016; Dias and Becker, 2016).", "sentence2": "to test model susceptibility to sentiment polarity, we generate swapped examples.", "label": "neutral"}
{"id": "test_3492", "sentence1": ".. we need(-) to get those GOP members out of the House & Senate, since they only support(+)!patronize(-) billionaire tax breaks, evidently(+)!obviously(-).", "sentence2": "we collect annotations on both topic and stance, using the ARC data as a starting point.", "label": "neutral"}
{"id": "test_3493", "sentence1": "We define an optimization criteria to partition texts into coherent time windows, and provide an efficient dynamic programming algorithm, which reduces the average absolute prediction error by over an hour against baselines.", "sentence2": "in the end, we use the winning BERT model to label our unlabeled data for training.", "label": "neutral"}
{"id": "test_3494", "sentence1": "With these models, we show our book-length prediction algorithms and their corresponding metrics as well (Section 5).", "sentence2": "a baseline model with random guessing would have an expected error of 6 hours.", "label": "neutral"}
{"id": "test_3495", "sentence1": "With this, we now have a probability distribution over 24 hours for each window using our model.", "sentence2": "to evaluate our methods, we construct ground truth for the books in our dataset.", "label": "neutral"}
{"id": "test_3496", "sentence1": "Recognizing a story's flow through time is essential to understanding the text.", "sentence2": "we focused on times that pinpointed hours within a day such as \"two o'clock\" or \"noon\".", "label": "neutral"}
{"id": "test_3497", "sentence1": "However, since the semantic representation used by SCAN only covers a small subset of English grammar, SCAN does not enable testing various systematic linguistic abstractions that humans are known to make (e.g., verb argument structure alternation).", "sentence2": "we include in our training set a single example to generalize from (\"primitive exposure example\") per generalization case that requires it.", "label": "neutral"}
{"id": "test_3498", "sentence1": "It had 2 encoder and decoder layers, 4 attention heads, and a feedforward dimension of 512.", "sentence2": "an error analysis revealed that the errors made by LSTMs were more systematic than those of Transformers.", "label": "neutral"}
{"id": "test_3499", "sentence1": "Their PP modifier depth generalization accuracy was much lower (LSTM: 2%; BiLSTM and Transformer: near 0%).", "sentence2": "model size did affect generalization.", "label": "neutral"}
{"id": "test_3500", "sentence1": "Note that there is no token masked when producing sentence embeddings, which is different from pretraining.", "sentence2": "through empirical probing over the embeddings, we further observe that the BERt sentence embedding space is semantically non-smoothing and poorly defined in some areas, which makes it hard to be used directly through simple similarity metrics such as dot product or cosine similarity.", "label": "neutral"}
{"id": "test_3501", "sentence1": "If embeddings are distributed in different regions according to frequency statistics, the induced similarity is not useful any more.", "sentence2": "(2) we first finetune both BERT and BERT-flow models on the SNLI+MNLI textual entailment classification task in a siamese fashion (Reimers and Gurevych, 2019).", "label": "neutral"}
{"id": "test_3502", "sentence1": "On the STS-B dataset, BERT sentence embeddings are even less competitive to averaged GloVe (Pennington et al., 2014) embeddings, which is a simple and non-contextualized baseline proposed several years ago.", "sentence2": "as discussed by Gao et al. (2019), anisotropy is highly relevant to the imbalance of word frequency", "label": "neutral"}
{"id": "test_3503", "sentence1": "In this section, we report the scores computed from fully-trained models on the two benchmarks, Wikitext-103 and Melo-Lyrics, compared against baselines.", "sentence2": "we found that the advantages of training balanced data distributions can be fully leveraged by sequentially performing tasks of frequency class prediction and token generation from the selected class.", "label": "neutral"}
{"id": "test_3504", "sentence1": "It indicates that a decomposition of the softmax function without consideration of the data distribution (i.e., frequency distribution) aggravates both the likelihood and token diversity performances, regardless of the number of classes.", "sentence2": "models tend to overproduce words frequently appearing in the data, while hardly utilizing informative words (Dinan et al., 2020). ", "label": "neutral"}
{"id": "test_3505", "sentence1": "As a simple yet effective remedy, we propose two novel methods, F2-Softmax and MefMax, for a balanced training even with the skewed frequency distribution.", "sentence2": "often monotonous or dull, texts generated from existing methods do not fully reflect the rich diversity and expression in human language (Welleck et al., 2020).", "label": "neutral"}
{"id": "test_3506", "sentence1": "The dataset was collected by asking workers to chat with each other naturally with a given persona.", "sentence2": "bERTScore (Zhang et al., 2020) performs soft-overlap between candidate and reference sentences by using bERT embeddings directly without fine-tuning, and has been shown to correlate with human judgment robustly.", "label": "neutral"}
{"id": "test_3507", "sentence1": "To overcome this issue, some learning-based metrics were proposed to train a coherence scoring model by considering the utterance-level semantics, such as ADEM (Lowe et al., 2017), RUBER (Tao et al., 2018), and BERT-RUBER (Ghazarian et al., 2019).", "sentence2": "one branch deploys BERT (Devlin et al., 2019) to learn the coarsegrained utterance-level contextualized representations, while another learns the fine-grained topiclevel graph representations by constructing topiclevel dialogue graphs and applying a graph neural network on the graphs to model the topic transition dynamics.", "label": "neutral"}
{"id": "test_3508", "sentence1": "First, the \"sentence-encoder\" or token-level RNN is a bi-directional LSTM (Hochreiter and Schmidhuber, 1997) encoding each sentence.", "sentence2": "sentence Classifier As with the pointer network, we use a hierarchical LsTM to encode the document and produce a sequence of sentence representations d 1 , ..., d N where N is the number of sentences in the document.", "label": "neutral"}
{"id": "test_3509", "sentence1": "In order to get an unconditional language model to do abstractive summarization, we can use the fact that LMs are trained by factorizing the joint distribution over words autoregressively.", "sentence2": "we demonstrate the utility of language models by demonstrating that a variety of tasks can be modeled using language models.", "label": "neutral"}
{"id": "test_3510", "sentence1": "In particular, more than 10% of the 20-grams from the abstracts generated by the pointing model are also found in the article, showing that it tends to copy long sequences of words.", "sentence2": "the rest of the article is provided as additional in-domain training data for the LM.", "label": "neutral"}
{"id": "test_3511", "sentence1": "We find the case where they are not statistically different, de-cs, to be particularly interesting: de-cs was the only language pair in WMT19 where the systems were unsupervised (i.e., did not use parallel training data).", "sentence2": "we release our model, metrics toolkit, and preprocessed training data.", "label": "neutral"}
{"id": "test_3512", "sentence1": "Our method achieves state-of-the-art performance on the most recent WMT shared metrics and QE tasks, without training on prior human judgements.", "sentence2": "the model trained on ParaBank 2 prefers its own beam search output to a copy of the input.", "label": "neutral"}
{"id": "test_3513", "sentence1": "BERT-era question answering systems have recently achieved impressive performance on several question-answering (QA) tasks.", "sentence2": "an important difference between SQUaD and NQ is that NQ answers are often significantly longer, which is a prominent bias in the definition of what an answer is, which may be difficult to overcome with just unsupervised adaptation.", "label": "neutral"}
{"id": "test_3514", "sentence1": "\"Leaves\" is a series of time intervals: The bus leaves at 10 am every day, so we will go to the bus stop at 9 am today.", "sentence2": "in copular constructions, we choose to label the verb as the event, instead of an adjective or preposition.", "label": "neutral"}
{"id": "test_3515", "sentence1": "While BLEU has higher correlation with crowd raters on whether the rewrite is sensical or grammatical, most correlation coefficients are less than .5, and many do not imply a positive correlation at all.", "sentence2": "while the simplified rewrites in the wikiSplit dataset are not guaranteed to be meaning preserving and cannot be used in a benchmark, the original complex sentences are semantically and syntactically diverse, with adequate complexity.", "label": "neutral"}
{"id": "test_3516", "sentence1": "We consider the state-of-theart seq2seq model trained on WikiSplit (Botha et al., 2018) and our rule-based model.", "sentence2": "if you manage to appropriately split a sentence which many other workers have skipped, you will receive a bonus.", "label": "neutral"}
{"id": "test_3517", "sentence1": "Our implementation is based on the model of Zhu et al.", "sentence2": "making alignments can be formalized as a matching problem, which aims to find the most relevant AmR graph node for each target word.", "label": "neutral"}
{"id": "test_3518", "sentence1": "Both settings give large improvements over the baseline.", "sentence2": "we first force our model to generate a gold sentence in order to calculate the accuracies for node prediction and edge prediction.", "label": "neutral"}
{"id": "test_3519", "sentence1": "One such widely studied task is image captioning (Hossain et al., 2019; Liu et al., 2019) which provides a textual description T given an image I.", "sentence2": "place the dough in the oven at 180 degrees celsius circulating air for about 20 minutes .", "label": "neutral"}
{"id": "test_3520", "sentence1": "In the problem defined above, our goal is to forward transfer the past knowledge to improve the new task learning.", "sentence2": "a typical sentiment analysis (Sa) or social media company that provides sentiment analysis services has to work for a large number of clients (Liu, 2012).", "label": "neutral"}
{"id": "test_3521", "sentence1": "Unlike traditional gates that regulate the feature information flow through the sequence chain, the goal of the proposed p-gates is to select useful parameters (which represent the learned knowledge from previous tasks) to be transferred to the new task to make it learn better.", "sentence2": "for our lifelong learning setting, we use 5 random task sequences to compute the accuracy as different task sequences may give different results.", "label": "neutral"}
{"id": "test_3522", "sentence1": "As we can see, continual learning models LWF-T and UCL (the latest algorithm) that only deals with catastrophic forgetting also achieve better results than I-CNN as the tasks are similar and share a great deal of knowledge (HAT is markedly worse).", "sentence2": "for example, on Amazon-10, L2PG's average accuracy is 2.20% higher than LWf-T, 6.48% higher than HAT and 2.66% higher than UCL.", "label": "neutral"}
{"id": "test_3523", "sentence1": "Automated radiology report generation has the potential to reduce the time clinicians spend manually reviewing radiographs and streamline clinical care.", "sentence2": "we develop an end-to-end report generation framework that consists of two stages.", "label": "neutral"}
{"id": "test_3524", "sentence1": "We extract the findings section from the radiology reports and then utilize spaCy for tokenization.", "sentence2": "current clinical practice requires a radiologist with specialized training to manually evaluate x-rays and note their findings in a radiology report.", "label": "neutral"}
{"id": "test_3525", "sentence1": "Pointer networks have been previously proposed as a way to copy parts of the input in hybrid seq2seq models.", "sentence2": "the previously pointed to source token is tagged with insert.", "label": "neutral"}
{"id": "test_3526", "sentence1": "We can use various architectures as the Encoder, which converts a sequence of tokens into a single vector.", "sentence2": "we searched the size of the vocabulary among 8K, 16K, 24K, and 32K, and we selected 16K for Twitter(Ja) and Twitter(En), and 32K for weibo(Zh), SNLI, and Genre&Rating.", "label": "neutral"}
{"id": "test_3527", "sentence1": "The goal of this study is to improve the performance of downstream tasks by optimizing the tokenization.", "sentence2": "we describe the details of these datasets in the following.", "label": "neutral"}
{"id": "test_3528", "sentence1": "freeze after k epochs achieves the balance of the stability and high F1.", "sentence2": "each classifier is built with one linear full-connected layer and Softmax layer.", "label": "neutral"}
{"id": "test_3529", "sentence1": "More and more applications like Twitter allow users to post multi-modal messages.", "sentence2": "rule-based methods strongly rely on the collected patterns, and it is challenging to identify the sarcasm caused by uncollected patterns.", "label": "neutral"}
{"id": "test_3530", "sentence1": "In this section, we first define the multi-modal sarcasm detection task.", "sentence2": "we find that it doesn't bring much improvement even it contains more parameters.", "label": "neutral"}
{"id": "test_3531", "sentence1": "4 we have several observations.", "sentence2": "in practical application not all the users can participate the training due to different reasons.", "label": "neutral"}
{"id": "test_3532", "sentence1": "Motivated by the LSTUR model proposed by An et al.", "sentence2": "for better privacy protection, we apply local differential privacy (LDP) technique to the local model gradients.", "label": "neutral"}
{"id": "test_3533", "sentence1": "(Detailed results are given in the Appendix).", "sentence2": "this metric represents how well the generated dataset represents the train set.", "label": "neutral"}
{"id": "test_3534", "sentence1": "Markov Chain (MC), which was the preferred algorithm in (Akkaradamrongrat et al., 2019) showed worse performance than sample-copy (the baseline over-sampling approach) for most B low thresholds.", "sentence2": "to feature-based over-sampling techniques, data augmentation generates additional samples through transformations applied directly to the data.", "label": "neutral"}
{"id": "test_3535", "sentence1": "In this work we present BalaGen, a balancing-viageneration framework.", "sentence2": "both of these approaches require additional domain data which is not always available.", "label": "neutral"}
{"id": "test_3536", "sentence1": "To improve the performance of extractive summarization, non-neural approaches explore various linguistic and statistical features such as lexical characteristics (Kupiec et al., 1995), latent topic information (Ying-Lang Chang and Chien, 2009), discourse analysis (Hirao et al., 2015; Liu and Chen, 2019), and graphbased modeling (Erkan and Radev, 2004; Mihalcea and Tarau, 2004) .", "sentence2": "first, we conduct a quantitative analysis on the CNN/Daily Mail corpus, based on the assumption that the writing style variability of summaries can be characterized through different combinations of sub-aspects (Lin and Bilmes, 2012).", "label": "neutral"}
{"id": "test_3537", "sentence1": "As a straightforward and effective method, extractive summarization creates a summary by selecting and subsequently concatenating the most salient semantic units in a document.", "sentence2": "in the news domain, neural models easily overfit by leveraging position-related features due to the prevalence of the inverted pyramid writing style.", "label": "neutral"}
{"id": "test_3538", "sentence1": "In the following, we assume access to a generaldomain PTLM, as described in Section 2.1, and a corpus of unlabeled target-domain text.", "sentence2": "one such model is BioBERT (Lee et al., 2020), which was initialized from general-domain BERT and then pretrained on biomedical scientific publications.", "label": "neutral"}
{"id": "test_3539", "sentence1": "In this section, we use the proposed method to create GreenBioBERT, an inexpensive and environmentally friendly alternative to BioBERT.", "sentence2": "the correct answer may appear several times, often with slightly different wordings.", "label": "neutral"}
{"id": "test_3540", "sentence1": "We next explain each module in detail.", "sentence2": "at turn 4, the turn-level state predictor easily predicts the correct value unknown and TEN keeps the state correct.", "label": "neutral"}
{"id": "test_3541", "sentence1": "In this paper, we proposed span attention to integrate n-gram into span representations to enhance chart-based neural constituency parsing.", "sentence2": "the left side is the backbone chart-based parser.", "label": "neutral"}
{"id": "test_3542", "sentence1": "Moreover, we run our models on the test set of each dataset and compare the results with previ\u0002ous studies, as well as the ones from prevailing parsers, i.e., Stanford CoreNLP Toolkits (SCT)14 (Manning et al., 2014) and Berkeley Neural Parser (BNP)15 (Kitaev and Klein, 2018).", "sentence2": "recent chart-based parers (Stern et al., 2017; Kitaev and Klein, 2018; Gaddy et al., 2018; Kitaev et al., 2019; Zhou and Zhao, 2019) make rare effort to leverage such n-gram information", "label": "neutral"}
{"id": "test_3543", "sentence1": "The other results are obtained from the best checkpoint of the best agent.", "sentence2": "even though they still learn from both hard and soft targets, they only learn their poorly predicted tokens from other agents.", "label": "neutral"}
{"id": "test_3544", "sentence1": "We first experiment with N = 10, L = 5, and D = 10K, but all methods can reach a nearperfect sequence accuracy (see Figure 3).", "sentence2": "being able to control the aspects of the datasets allows us to compare the characteristics of the three inference methods more thoroughly and analyze the appropriate situations to apply each method.", "label": "neutral"}
{"id": "test_3545", "sentence1": "Throughout all the experiments, three inference methods share the same model structure with dmodel = 512, dembedding = 512, nlayers = 1, r learning = 10 -5 , r teacher forcing = 0.5, and r dropout = 0.5 (Srivastava et al., 2014).", "sentence2": "tagging performs worse than Recurrence in all other cases.", "label": "neutral"}
{"id": "test_3546", "sentence1": "But, the decoder of Tagging produces a sequence of editing operations, such as deletion and insertion, that is later applied to the source text to yield the edited text via a realization step (Malmi et al., 2019).", "sentence2": "we conclude that Recurrence is more data-efficient and overall better performs than End2end and Tagging in most situations, especially in AES (long-to-short).", "label": "neutral"}
{"id": "test_3547", "sentence1": "The experimental results show that TED outperforms all unsupervised abstractive baselines on all datasets.", "sentence2": "like most machine learning algorithms, summarization models can also be divided into supervised and unsupervised categories.", "label": "neutral"}
{"id": "test_3548", "sentence1": "The pretraining employs automatic filtering mechanism and does require any human-labeled data.", "sentence2": "tED innovatively encodes the similarity by a transformer encoder with much more modeling capability.", "label": "neutral"}
{"id": "test_3549", "sentence1": "However, one should carefully examine and clean the source data to take advantage of lead bias, as the top three sentences may not always form a good summary.", "sentence2": "agents confiscated electronic devices and computer files from roberts.", "label": "neutral"}
{"id": "test_3550", "sentence1": "This causes NMT models to experience a limited set of subword candidates which are frequently observed in the training data.", "sentence2": "we used the English-French language pair.", "label": "neutral"}
{"id": "test_3551", "sentence1": "Our method significantly outperforms both the BASE and the SR.", "sentence2": "our method does not replace the word but replaces its subword composition.", "label": "neutral"}
{"id": "test_3552", "sentence1": "Our baselines are NMT models trained with deterministic segmentations (BASE) and models trained with the subword regularization method (SR) (Kudo, 2018).", "sentence2": "the diversification of subword segmentations mostly relies on the pre-trained subword language models from which erroneous segmentations of unseen words are less likely to be sampled.", "label": "neutral"}
{"id": "test_3553", "sentence1": "Proposition 1 shows that the objective is maximized when the mutual information is maximized to I max .", "sentence2": "all model and training details are in appendix B.", "label": "neutral"}
{"id": "test_3554", "sentence1": "We ablated in-domain pretraining, mixup training, confidence penalty loss, and self-training progressively, the results of which are shown in Table 3.", "sentence2": "there exist 10 groups of the relationship types, and five of these (CPR:3, CPR:4, CPR:5, CPR:6, and CPR:9) were used in the evaluation.", "label": "neutral"}
{"id": "test_3555", "sentence1": "Biomedical text data, including PubMed abstracts, usually contain information about biomedi-cal entities and their relationships with each other.", "sentence2": "the max, min and std precision of our proposed model are 80.08, 75.64 and 1.56 while those of BioBERt are 78.64, 76.18 and 0.83.", "label": "neutral"}
{"id": "test_3556", "sentence1": "To show the significant improvement in terms of classification performance, we report the mean and standard deviation values of every experiment in the ablation study.", "sentence2": "several approaches, called \"calibration\" techniques, have been applied to several domains that require high reliability, such as autonomous driving and medical diagnosis (Guo et al., 2017;Jiang et al., 2012).", "label": "neutral"}
{"id": "test_3557", "sentence1": "It also explains the relatively high ROUGE scores in the evaluation.", "sentence2": "the initial learning rate is set to 1e - 9 and linearly increased to 0.001 with 16000 warmup steps.", "label": "neutral"}
{"id": "test_3558", "sentence1": "We thank the anonymous reviewers for their valuable comments.", "sentence2": "we leverage a hierarchical structure to reduce the burden of computing.", "label": "neutral"}
{"id": "test_3559", "sentence1": "To improve the clinical correctness of the generated reports, Liu et al. (2019a) and Irvin et al. (2019) adopted clinically coherent rewards for RL with CheXpert Labeler (Irvin et al., 2019), a rule-based finding mention annotator", "sentence2": "although the F-scores of the no-mention labels are high, the F-scores of the positive, negative, and uncertain finding labels are relatively low.", "label": "neutral"}
{"id": "test_3560", "sentence1": "The underlined part represents the correct description corresponding to the italic part.", "sentence2": "our proposed RL-DA generated a correct description: \"there is no pleural indentation\".", "label": "neutral"}
{"id": "test_3561", "sentence1": "Although the above-mentioned distributional hypothesis is proposed for language models, if we look at the knowledge graph from the perspective of this hypothesis, we can find that similar hypothesis exists in knowledge graphs (KGs).", "sentence2": "knowledge graph G can be redefined as G = (V, E), where V represents the nodes in G, involving entities in E and relations in R, and E denotes the directed edges among the nodes in V .", "label": "neutral"}
{"id": "test_3562", "sentence1": "where, W f , W V and Wh are the trainable weight matrices.", "sentence2": "also, the mention of different images in the contextual information confuses the model in selecting the correct images.", "label": "neutral"}
{"id": "test_3563", "sentence1": "The appropriate responses to the user queries are highly dependent on the visual information pertaining to the different aspects of the various images in the conversation.", "sentence2": "experimental results show that our proposed methodology outperforms the baseline models in the case of both automatic and human evaluation metrics.", "label": "neutral"}
{"id": "test_3564", "sentence1": "Nevertheless, existing GCN-based ED methods do not consider dependency labels, which may serve as significant indicators to reveal whether a word is a trigger or not.", "sentence2": "in addition, our statistical results on the benchmark ACE2005 dataset show that \"nsubj\", \"dobj\" and \"nmod\" take up 32.2% of triggerrelated dependency labels (2.5% for each relation on average among all 40 dependency relations), which means that simultaneously modeling syntactic structure and dependency labels can be crucial to make full use of the dependency trees to further improve the performance of ED.", "label": "neutral"}
{"id": "test_3565", "sentence1": "Event Detection (ED) is an important information extraction task that seeks to recognize events of specific types from given text.", "sentence2": "a meanpooling operation is applied to compress features since it covers information from all channels.", "label": "neutral"}
{"id": "test_3566", "sentence1": "In this paper, we propose a novel architecture named Edge-Enhanced Graph Convolution Networks (EE-GCN), which simultaneously exploits syntactic structure and typed dependency label information to perform ED.", "sentence2": "the entity type and dependency label embeddings are randomly initialized.", "label": "neutral"}
{"id": "test_3567", "sentence1": "A generated sentence is verifiable if it can be corroborated or disproved by Wikipedia, and we find that the verifiability of generated text strongly depends on the decoding strategy.", "sentence2": "intuitively, random choices might hamper verifiability when sampling a token in specific positions of the sentence, for instance, in a named entity, potentially making the overall sentence non factual.", "label": "neutral"}
{"id": "test_3568", "sentence1": "At test time, the model is presented the conversation history and 20 candidate responses and the model has to pick the correct response.", "sentence2": "this chatbot requests users to provide natural language feedback when the users are dissatisfied with its response", "label": "neutral"}
{"id": "test_3569", "sentence1": "It is reasonable to assume that the larger position embeddings have similar first 512 values with the small one since they all express the corresponding relationship between tokens when the input length is less than 512.", "sentence2": "for a particular dataset, when we set the ERLength of the BERT, letting it exceed more data's DLength can always bring more improvements.", "label": "neutral"}
{"id": "test_3570", "sentence1": "Among all the models, only Seq2UMTree can be applied for all sentences in both datasets 2 and the space complexity is O(2l + r).", "sentence2": "previous work uses pIpELINE to extract triplets from text (Nadeau and Sekine, 2007;Chan and Roth, 2011).", "label": "neutral"}
{"id": "test_3571", "sentence1": "\u03b2 is a hyper-parameter set to 1.0 by default.", "sentence2": "the NumAsTok baseline has a finite numeral vocabulary and treats all the OOV numerals as UNK num .", "label": "neutral"}
{"id": "test_3572", "sentence1": "This experimental methodology, inspired by Caglayan et al. (2019), creates a system\u0002atic gap in the speech signal that can be resolved by leveraging the visual context; for example, when the audio drops during online distance-based learn\u0002ing or video calls with family and friends.", "sentence2": "for purple and sign, the model attends to the correct proposals, but fails to recover the words pink and ship, respectively.", "label": "neutral"}
{"id": "test_3573", "sentence1": "We present BLEU score for our method and compare it with SVD, GroupReduce (Chen et al., 2018), Structured Emedding (Shi and Yu, 2018), Tensor Train (Khrulkov et al., 2019) and a smaller transformer network with the same number of parameters.", "sentence2": "table 8 presents these results.", "label": "neutral"}
{"id": "test_3574", "sentence1": "During the ES, a population of P trained models are kept throughout the search phase, where initially, the population is initialized with random architectures.", "sentence2": "this process is computationally very expensive, making it infeasible to run on a single GPU in a reasonable amount of time.", "label": "neutral"}
{"id": "test_3575", "sentence1": "We first compare our Transformer encoder with the previous models in the single-criterion scenario.", "sentence2": "we merge the wikipedia corpora used in \"8Trad\" and \"8Simp\" to form a mixed corpus, which contains both the simplified and traditional Chinese characters.", "label": "neutral"}
{"id": "test_3576", "sentence1": "In this work, we only adopt the vanilla Transformer encoder since we just want to utilize its selfattention mechanism to model the criterion-aware context representation for each character neatly.", "sentence2": "we do not balance the datasets and randomly pick 10% examples from the training set as the development set for all datasets.", "label": "neutral"}
{"id": "test_3577", "sentence1": "\"Char Types\" is the number of unique characters.", "sentence2": "it is unnecessary to use a specific private layer for each criterion.", "label": "neutral"}
{"id": "test_3578", "sentence1": "Since our DIPAIRTSF model is end to end trained, the model should learn to push the information of the full input sequence to arbitrarily selected (N + M) token embeddings.", "sentence2": "techniques that model the texts independently such as the dual-encoder models (Das et al., 2016;Johnson et al.; Chidambaram et al., 2019; Cer et al., 2018; Henderson et al., 2017; Reimers and Gurevych, 2019) are able to run efficient inference on large-scale text pairs.", "label": "neutral"}
{"id": "test_3579", "sentence1": "Training Details For fair comparison, we use the same hyper-parameter settings and the training strategy as Ahmad et al. (2019) to train the parsing models.", "sentence2": "this method may suffer from imperfect word alignment between two languages.", "label": "neutral"}
{"id": "test_3580", "sentence1": "We give details and results regarding our column pruning approach in Section D. Full results for SQA are displayed in Section E. Section F shows the accuracy on the pre-training tasks held-out sets.", "sentence2": "the model does not use special embeddings to encode the table structure but relies on a template approach to format the table as natural language.", "label": "neutral"}
{"id": "test_3581", "sentence1": "The sequence labelling model is optimized by Adam optimizer (Kingma and Ba, 2015) with batch size 64, learning rate 0.0006 and decay rate 0.992.", "sentence2": "suppose s i,j is the similarity score between i-th and j-th words, the post score post i,j is: Then, we normalize the scores by a softmax and get the probability distribution of replacing words.", "label": "neutral"}
{"id": "test_3582", "sentence1": "MAT applies word masks or substitutions (details in Method section) when computing loss from adversarial examples, which forces the model to predict the right labels with no word information or wrong information.", "sentence2": "despite the success of adversarial training (AT) on text tasks such as text classification (Miyato et al., 2017) and part-of-speech (POS) tagging (Yasunaga et al., 2018), its gains on other sequence labelling tasks, such as named entity recognition and chunking, are not significant (Yasunaga et al., 2018).", "label": "neutral"}
{"id": "test_3583", "sentence1": "Masked language model (Devlin et al., 2018) smooths this inconsistency by applying replacement of tokens for some data while masking the rest (equivalent to word dropout).", "sentence2": "early stopping is applied based on model performance on the development set.", "label": "neutral"}
{"id": "test_3584", "sentence1": "For all the experiments, we use finetune the pretrained model for 3 epoches with learning rate 2e-5 and batch size 32.", "sentence2": "these results suggest that our method is more suitable for fine-tuning with smaller amounts of data, and that our approach to injecting the label information is at least not detrimental to the original pretrained model.", "label": "neutral"}
{"id": "test_3585", "sentence1": "This is reflected by the clearly opposite trends observed in Figure 3 vs. those observed in Figure 1a.", "sentence2": "First, we trained a model for the North-Germanic family (NG) with three languages \u2013 Danish (DA), Swedish (SV), and Norwegian (NB). ", "label": "neutral"}
{"id": "test_3586", "sentence1": "In this work, the graph edges are labelled dependency relations, which are predicted as part of the actions of a transition-based dependency parser.", "sentence2": "after proposing two novel Transformer models of transition-based dependency parsing as strong baselines, we show that adding the proposed mechanisms for conditioning on and predicting graphs of Graph2Graph Transformer results in significant improvements, both with and without BERT pre-training.", "label": "neutral"}
{"id": "test_3587", "sentence1": "As shown in the table, models that used only a single attention component, be it Supervised Self-Attention based (SSs) or Task-specific attention based sentence representation (TSS) achieved the same F1-score for the entity recognition task.", "sentence2": "to avoid over-fitting, we apply a dropout strategy (Ma and Hovy, 2016; Srivastava et al., 2014) of 0.5 for our model.", "label": "neutral"}
{"id": "test_3588", "sentence1": "The size of the learned character-level embedding are 100 dimensional vectors.", "sentence2": "single attention is insufficient in exploring this multi-aspect information and consequently risks losing important cues.", "label": "neutral"}
{"id": "test_3589", "sentence1": "Several studies have explored (Guan et al., 2019) SRL with deep learning techniques.", "sentence2": "there are several SRL annotation conventions, such as PropBank (Palmer et al., 2005) and FrameNet (Baker et al., 2007).", "label": "neutral"}
{"id": "test_3590", "sentence1": "If the task is simple and easy to solve, why not just build a rule-based system rather than a usersimulator that is then used with RL techniques to train the dialogue system, where more uncontrollable factors are involved?", "sentence2": "for each evaluation task, we will first present an Mturk worker with a randomly sampled user goal, which contains the constraints about specific domain slots and some slot information that the user is looking for.", "label": "neutral"}
{"id": "test_3591", "sentence1": "How sensitive are adversarial learning to pretrained dialogue policy?", "sentence2": "since the output of the dialogue policy is a set of discrete dialogue actions, it is difficult to pass the gradient update from the discriminator to the policy model.", "label": "neutral"}
{"id": "test_3592", "sentence1": "1) datasets, a particularly interesting QA task that provides a flexible space of candidate answers along with a simple evaluation.", "sentence2": "the views expressed are those of the authors and do not reflect the official policy or position of the Department of Defense or the U.S. Government.", "label": "neutral"}
{"id": "test_3593", "sentence1": "However this sophistication not only requires adhoc heuristics that are tailored to a specific formalism (AMR in this case) but also relies on alignment information with the source words.", "sentence2": "we then follow the binary relations to expand the graph.", "label": "neutral"}
{"id": "test_3594", "sentence1": "This also differs from Karamanolakis et al. (2019), which updates the weights of the initial seed words but does not provide pseudo-labels for documents with no seed words.", "sentence2": "we expect such correct translations to lead to further improvements over automatic translations.", "label": "neutral"}
{"id": "test_3595", "sentence1": "Google Translate erroneously returns \"medical\" as a Uyghur translation of the word \"medical.\"", "sentence2": "in Sinhalese, we use 5,000 unlabeled documents for training the student and 36 labeled documents for evaluation.", "label": "neutral"}
{"id": "test_3596", "sentence1": "This is explained by the fact that CLTS prioritizes the most indicative seed words for translation.", "sentence2": "we now evaluate CLTS for several cross-lingual text classification tasks in various languages.", "label": "neutral"}
{"id": "test_3597", "sentence1": "5a, even compared with L2L ptr which equipped with pointer network and tend to copy from source document.", "sentence2": "we claim that a better understanding of dataset biases can help us interpret models' discrepancies.", "label": "neutral"}
{"id": "test_3598", "sentence1": "We use cross entropy as loss function to train LSTM non and Trans auto .", "sentence2": "we ask two questions as follows: Q1: How do different neural architectures of summarizers influence the cross-dataset generalization performances?", "label": "neutral"}
{"id": "test_3599", "sentence1": "In particular, Voita et al. (2019) studies the evolution of representa\u0002tions from the bottom to top layers and finds that, for MLM, the token identity tends to be recreated at the top layer.", "sentence2": "Figures 10a, 10d, 10g, 10j, 10m show left and right cws for sentences belonging to short length category (l \u2264 25).", "label": "neutral"}
{"id": "test_3600", "sentence1": "Similarly, grid-based features Vg are fused with question embedding q by concatenation.", "sentence2": "vQA settings: There are two main vQA settings, namely multiple choice and open-ended following (Antol et al., 2015).", "label": "neutral"}
{"id": "test_3601", "sentence1": "However, most existing domain adaptation methods focus on single-modal tasks such as image classification or sentiment classification, and thus may not be directly applicable to multi-modal settings.", "sentence2": "question encoding: The question q of length T is first tokenized and encoded using word embedding based on pre-trained GloVe (Pennington et al., 2014) as S = {x0, x1, ..., xT }.", "label": "neutral"}
{"id": "test_3602", "sentence1": "It reduces the difference in distributions by transforming the feature representation of the data in the target domain.", "sentence2": "we validate our proposed method on two popular VQA benchmark datasets, VQA 2.0 and Vizwiz, in both directions of adaptation.", "label": "neutral"}
{"id": "test_3603", "sentence1": "We study the problem of visual question answering (VQA) in images by exploiting supervised domain adaptation, where there is a large amount of labeled data in the source domain but only limited labeled data in the target domain, with the goal to train a good target model.", "sentence2": "most existing domain adaptation methods focus on single-modal tasks such as image classification or sentiment classification, and thus may not be directly applicable to multi-modal settings.", "label": "neutral"}
{"id": "test_3604", "sentence1": "Gilmer et al. (2018) laid out a set of potential constraints for the attack space when generating adversarial examples, which are each useful in different real-world scenarios.", "sentence2": "additionally, synonym substitution methods, including TEXTFOOLER and GENETICaTTaCK, often require that words be substituted only with neighbors in the counter-fitted embedding space, which is designed to push synonyms together and antonyms apart (Mrksic et al., 2016).", "label": "neutral"}
{"id": "test_3605", "sentence1": "The lack of a consistent definition and standardized evaluation has hindered the use of adversarial examples to understand and improve NLP models.", "sentence2": "Our framework enables fair comparison between attacks, by separating effects of search methods from effects of loosened constraints.", "label": "neutral"}
{"id": "test_3606", "sentence1": "Perturbations generated by TEXTFOOLER were rated an average of 3.28, while perturbations generated by GENETICATTACK were rated on average 2.70.", "sentence2": "our inspection of the perturbations revealed that many violated these constraints.", "label": "neutral"}
{"id": "test_3607", "sentence1": "To enforce grammaticality, we added Language-Tool.", "sentence2": "due to the rule-based nature of grammar, automatic evaluation is preferred.", "label": "neutral"}
{"id": "test_3608", "sentence1": "The Stage 1 workers are equally distributed across the city sub-sections, so the dataset splits are not biased toward specific workers.", "sentence2": "assembly occurs in a smaller environment, requiring agents to focus less on understanding paths than in navigation and more on understanding the 3D spatial relations of objects from the limited egocentric viewpoint.", "label": "neutral"}
{"id": "test_3609", "sentence1": "Object manipulation and configuration is another subject that has been studied along with language and vision grounding (Bisk et al., 2016;Wang et al., 2016;Li et al., 2016;Bisk et al., 2018).", "sentence2": "c: Objects will always be a book, hourglass, mug, bucket, ball, tv, or bowl, but may vary in color and texture.", "label": "neutral"}
{"id": "test_3610", "sentence1": "For word and action embedding sizes, we use 300 and 64, respectively.", "sentence2": "most studies focus on addressing the problem in relatively simple environments from a third-person view.", "label": "neutral"}
{"id": "test_3611", "sentence1": "Table 1: Lengths of the instructions (in words), paths, and action sequences for both turns across all subsections in the city.", "sentence2": "in the 2nd turn, our model fails to find the \"striped red mug\" by missing the left turn around the \"yellow and white banner\".", "label": "neutral"}
{"id": "test_3612", "sentence1": "We incorporate the naturalistic variation mentioned below in Section 3 to these datasets as they are used extensively in goal-oriented dialog research and use them as benchmarks for our experimental evaluation 2 .", "sentence2": "we use the best performing hyper-parameters reported by both models -BossNet and GLMP for each dataset.", "label": "neutral"}
{"id": "test_3613", "sentence1": "Starting from early work by Agrawal et al.", "sentence2": "results of the experiments are reported in Table 4.", "label": "neutral"}
{"id": "test_3614", "sentence1": "We consider some of the major US healthcare providers, with which almost everyone has interacted at different levels (insurers, pharmacy chains, ...): thus, not only finance experts (example (a) in Table 3) and local sources (b), but also politicians (c), physicians (d), policymakers (e) and the general public are interested in their outcome, resulting in a dataset which collects different registers.", "sentence2": "sD on complex and articulated texts, such as news articles, has been considerably less studied, mainly due to the scarcity of published datasets (Pomerleau and Rao, 2017;Hanselowski et al., 2019).", "label": "neutral"}
{"id": "test_3615", "sentence1": "We collected 665,667 tweets posted between February 28, 2020 and May 8, 2020, with a maximum of 10,000 samples for each day using Crimson Hexagon 1 .", "sentence2": "we can produce a simple white-box method for identifying who-needs-what sentences.", "label": "neutral"}
{"id": "test_3616", "sentence1": "In the generic summarization b(w) = 2, for comparative summarization b(w) = 3, as used by Gillick et al. (2009).", "sentence2": "most extractive summarizers have two components: sentence scoring and selection.", "label": "neutral"}
{"id": "test_3617", "sentence1": "Note that as shown in Figure 1, because non-word misspellings are preprocessed already, the detection of these non-word misspellings can be trivially accomplished, which results in all models having non-word recall of 1.000.", "sentence2": "since the transformer-encoder (Vaswani et al., 2017) computes contextualized token representations, we take h char , the [CLs] token representation of each character sequence as the local character-level representation of s * .", "label": "neutral"}
{"id": "test_3618", "sentence1": "Both of the baseline models (row 1 and 2) perform poorly, because they perform spelling corrections upon character sequences, which disregards the semantics of the context, as their poor real-word performance in Table 2 row 1 and 2 suggests.", "sentence2": "we use the transformer-encoder (Vaswani et al., 2017) to encode the input sequences and denote it as Encoder.", "label": "neutral"}
{"id": "test_3619", "sentence1": "Our work focused on a specific instantiation of channels as languages.", "sentence2": "at inference (generation) time, we can generate unconditionally by seeding the canvas with the [SEP] token and predicting the first actual token or provide as much, or as little, partial/complete sequence in each channel.", "label": "neutral"}
{"id": "test_3620", "sentence1": "We experiment with the Multi30K dataset containing English, French, Czech, and German.", "sentence2": "KER\u0002MIT is able to model the joint p(x, y), condition\u0002als p(x | y), p(y | x), as well as the marginals p(x), p(y).", "label": "neutral"}
{"id": "test_3621", "sentence1": "This observation indicates that incorporate different embeddings as input is more effective than directly using pre-trained models.", "sentence2": "next, we use two matrices to map them to their embeddings, with e kc i,j referring to the embedding of k c i,j and e vc i,j for v c i,j , respectively.", "label": "neutral"}
{"id": "test_3622", "sentence1": "Moreover, in most cases, one would like to incorporate more than one types of extra features.", "sentence2": "we try different values for hyper-parameters for our model, presented in Table 9.", "label": "neutral"}
{"id": "test_3623", "sentence1": "First, each word embedding is weighted by a/(a + fr ), where fr stands for the underlying word's relative frequency, and a is the weight parameter.", "sentence2": "dCT is a way to generate document-level representations in an order-preserving manner, adapted from image compression to NLP by Almarwani et al. (2019).", "label": "neutral"}
{"id": "test_3624", "sentence1": "For ST models, the task model and simulator are of the same architecture, but we do not evaluate MT conditions since RoBERTa is not generative.", "sentence2": "multi-agent game results appear in Table 3, though we note that RL results should be cautiously interpreted as we observe unstable training behavior from this method.", "label": "neutral"}
{"id": "test_3625", "sentence1": "Early work on this topic proposes to generate explanations for images that are descriptive as captions and discriminative as labels (Hendricks et al., 2016).", "sentence2": "the differences between them could result from their pretraining procedures, architectural differences, finetuning sample efficiency, or another cause.", "label": "neutral"}
{"id": "test_3626", "sentence1": "Our aim is for explanations to better communicate the task model's reasoning process, without adopting the trivial solution, i.e., directly stating its output.", "sentence2": "we show that our LAS scores provide a deeper understanding of explanation effectiveness than metrics like BLEU and discuss their relationship with our expert simulation analysis and crowdsourced human quality ratings.", "label": "neutral"}
{"id": "test_3627", "sentence1": "While using gold linguistics task data (PTB, CoNLL-2005, andCoNLL-2009) with 10% probability, we only take one sentence as input that [CLS] and [SEP] are first and last tokens respectively.", "sentence2": "for task-specific layers including syntactic and semantic scorers and decoders, we set the same hyperparameters settings as (Zhou et al., 2020).", "label": "neutral"}
{"id": "test_3628", "sentence1": "Consequently, we propose to inject the knowledge from these syntaxbased importance scores into the graph-based models for ABSA via the consistency with the modelbased importance scores.", "sentence2": "Model performance on the MAMS development set when the diversity term Ldiv is directly computed from the gate vectors.", "label": "neutral"}
{"id": "test_3629", "sentence1": "For instance, an ABSA sys\u0002tem should be able to return the negative sentiment for input sentence \u201cThe staff were very polite, but the quality of the food was terrible.\u201d assuming \u201cfood\u201d as the aspect term.", "sentence2": "using the representation vectors from the graph-based models, we compute a second score for each word in the sentences to reflect the model's perspective on the importance of the word for the sentiment of the aspect terms.", "label": "neutral"}
{"id": "test_3630", "sentence1": "The preceding results show a decrease in number of primed instances as contextual constraint increases.", "sentence2": "we use the Semantic Priming Project (SPP) (Hutchison et al., 2013) as our source of human priming experiment data.", "label": "neutral"}
{"id": "test_3631", "sentence1": "The PREMISE sentence describes a real-world situation and is always assumed to be true.", "sentence2": "sUMMARY For this task, given a GENERALIZATION about a socially normative behavior or judgement: Write an UNDERMINING CONTEXT in one sentence.", "label": "neutral"}
{"id": "test_3632", "sentence1": "These statements represent generic commonsense hypotheses about social behaviors and their acceptability that are held as norms in a society.", "sentence2": "an UNDERMINING context provides a situation that weakens the generalization; it makes the generalization less relevant or effective.", "label": "neutral"}
{"id": "test_3633", "sentence1": "Recent work has proposed hyperbolic neural components, such as word embeddings (Tifrea et al., 2019), recurrent neural networks (Ganea et al., 2018) and attention layers (Gulcehre et al., 2019).", "sentence2": "Figure 6: Norm of text vectors for the Euclidean and hyperbolic model.", "label": "neutral"}
{"id": "test_3634", "sentence1": "The types are highly correlated given that they often co-occur in similar contexts.", "sentence2": "researchers have incorporated these isolated components into neural models, whereas the rest of the layers and algorithms operate under Euclidean assumptions.", "label": "neutral"}
{"id": "test_3635", "sentence1": "In this manner, we make consistent use of the same analytical model of hyperbolic space across all components, which eases their integration.", "sentence2": "we hypothesize that our proposed hyperbolic model will benefit from this representation.", "label": "neutral"}
{"id": "test_3636", "sentence1": "We first validate the advantage of our architecture on two tasks in dialogue history object retrieval described in Section 2.", "sentence2": "referring expressions are a ubiquitous part of human communication (Krahmer and Van Deemter, 2012) that must be studied in order to create machines that work smoothly with humans.", "label": "neutral"}
{"id": "test_3637", "sentence1": "However, our architecture is difficult to directly apply to referring expression generation because it outputs modulated feature maps.", "sentence2": "this task is repeated until the size becomes 1/32 of the original image.", "label": "neutral"}
{"id": "test_3638", "sentence1": "Our experiments show an improvement on the Augmented-Flipped testing set after correcting the conflicted labels in the Original training set, and the combination of the two methods produce a model that gives the best performance across all testing sets.", "sentence2": "in addition to the original QQP dataset, we derived three additional datasets using the data augmentation and label correcting methods introduced in Section 3.", "label": "neutral"}
{"id": "test_3639", "sentence1": "The precision parameter of the path given the cluster helps in penalizing the 'BORN IN' path.", "sentence2": "we report test results for the best hyper-parameter values that we got on this validation set.", "label": "neutral"}
{"id": "test_3640", "sentence1": "The process will generate about O(n) candidate regions.", "sentence2": "to HiReAWR , the absolute F1 measure improvement of HiRe HRR is 0.6%.", "label": "neutral"}
{"id": "test_3641", "sentence1": "Note that high translation quality of Transformer models entails a large number of parameters.", "sentence2": "hence, we set pN R = 2000 for retraining of quantization baselines, and for experiments where we quantize and retrain each block in Transformer at a time, we set pN R = 1000.", "label": "neutral"}
{"id": "test_3642", "sentence1": "Interestingly, our (2.5, 1.8, FP) model with the average of 11.3-bit outperforms the 2-bit baseline in terms of inference speed.", "sentence2": "in addition, as we illustrate later, even assigning different quantization bits for each row of an embedding block can further reduce the overall number of quantization bits of the entire Transformer model.", "label": "neutral"}
{"id": "test_3643", "sentence1": "For Transformer, we suggest the following two techniques to decide the number of quantization bits for each block: 1) in the case of embedding block, frequency of each word is taken into account and 2) for encoder and decoder blocks, we find the minimum number of quantization bits for each type of sub-layers that allows reasonable degradation in BLEU score after quantization.", "sentence2": "as for inference speed up, addressing memory wall problems may be of higher priority rather than attaining a low number of quantization bits.", "label": "neutral"}
{"id": "test_3644", "sentence1": "In the meantime, proper knowledge utilizing also gets rid of repetition to some degree and makes the dialog more coherent, which has been proved during the previous evaluation phase.", "sentence2": "the forget gate controls how much knowledge to be discarded during the multi-source fusion phase.", "label": "neutral"}
{"id": "test_3645", "sentence1": "For manual evaluation, we first select metrics Fluency and Coherence clearly defined in (Wu et al., 2019) to measure whether the dialog agent can express fluently and logically.", "sentence2": "This enhances the system\u2019s expressive ability especially in terms of the out-of-vocabulary words. Wu et al. (2019) applied KnowlegePost (Lian et al., 2019) to minimize the divergence between knowledge prior and knowledge posterior distribution to learn a better knowledge representation and concatenated the knowledge context vector with decoder feed.", "label": "neutral"}
{"id": "test_3646", "sentence1": "Table 3: Examples of coreference errors made by Chirps and corrected by Barhom et al. (2019): 1) false positive: wrong man / two men alignment (disregarding location modifiers).", "sentence2": "it extracts binary predicate-argument tuples from each tweet and aligns pairs of predicate mentions whose arguments match, by some lexical matching criteria.", "label": "neutral"}
{"id": "test_3647", "sentence1": "Following this, we explore the multi-domain case of the Overnight dataset wherein there is no gold-standard training data in either language.", "sentence2": "prior study broadly found this technique to yield improved parsing accuracy (Iyer et al., 2017;Dong and Lapata, 2016;Finegan-Dollak et al., 2018), a crosslingual implementation requires crafting multiple language-specific trans-lation tables for entity recognition.", "label": "neutral"}
{"id": "test_3648", "sentence1": "This work is closely related to relation reasoning in knowledge bases and few-shot learning.", "sentence2": "to summarize, our main contributions are: (1) we study the problem of few-shot multi-hop relation reasoning over KB, which is new and important; (2) we propose a novel model called FIRE to solve the problem by exploring several beneficial components; (3) we conduct experiments on two datasets and the evaluation results demonstrate the superior performance of FIRE over state-of-theart methods.", "label": "neutral"}
{"id": "test_3649", "sentence1": "PBoS-n showed good improvement for the Polyglot RW case (25 to 32), matching the performance of the other two.", "sentence2": "we found that PBoS is insensitive to subword length constraints and decide to keep the setting simple.", "label": "neutral"}
{"id": "test_3650", "sentence1": "Note this has nothing to do with embeddings, so no training is involved in this experiment.", "sentence2": "the model can be trained by fitting a set of pre-trained word embeddings.", "label": "neutral"}
{"id": "test_3651", "sentence1": "Note that we do not assume a vocabulary.", "sentence2": "in summary, we find 1) that PBoS surpasses KVQ-FH for English and German and is comparable to KVQ-FH for italian; 2) that PBoS and KVQ-FH surpasses BoS for English, German and italian; and 3) no definitive trend among the three models for Russian.", "label": "neutral"}
{"id": "test_3652", "sentence1": "We omit the prediction time for KVQ-FH, as we found it hard to separate the actual inference time from time used for other processes such as batching and data transfer between CPU and GPU.", "sentence2": "for each segmentation, we compose a word vector as the sum of all subwords that appear in the segmentation.", "label": "neutral"}
{"id": "test_3653", "sentence1": "Note that, our methods and the other lexicon-based baselines are only applied to words being predicted as class K class by SourceBERT.", "sentence2": "in this section, we detail the construction of the partially labeled dataset D t for the target task.", "label": "neutral"}
{"id": "test_3654", "sentence1": "With experiments conducted on two well-known public datasets, i.e. Yelp and Amazon, we demonstrate that the proposed methodology outperforms existing unsupervised methods very consistently in fluency, and presents competitive results in terms of sentiment conversion and content preservation.", "sentence2": "Its actually worse than a little better than the filter that came with the unit.", "label": "neutral"}
{"id": "test_3655", "sentence1": "Main results on the MS MARCO passage retrieval task are shown in Table 1, comparing BERTlarge (Nogueira et al., 2019a) to T5 models of different sizes.", "sentence2": "we map a relevant document to \"hot\" and a non-relevant document to \"cold\".", "label": "neutral"}
{"id": "test_3656", "sentence1": "Robust04 (Voorhees, 2004) is the test collection from the TREC 2004 Robust Track.", "sentence2": "in addition, we would like to thank Google Cloud for credits to support this work.", "label": "neutral"}
{"id": "test_3657", "sentence1": "We believe these two issues are closely related.", "sentence2": "the main advantage of our approach is that by \"connecting\" fine-tuned latent representations of relevance to output target tokens, we can exploit the model's latent knowledge (e.g., of semantics, linguistic relations, etc.)", "label": "neutral"}
{"id": "test_3658", "sentence1": "Unlike the fullyconnected layer in the encoder-only approach, T5 can exploit the part of the network used for generating output tokens.", "sentence2": "we apply inference directly using our model trained on the MS MARCO passage data; Robust04, Core17, and Core18 relevance judgments are only used as a test set, which makes our results zero-shot.", "label": "neutral"}
{"id": "test_3659", "sentence1": "RnnOIE-Supervised (BERT) even perform worse than ClausIE and OpenIE4 on WEB and NYT.", "sentence2": "two training instances are automatically generated using dependency pattern for predicates \"operates\" and \"has\".", "label": "neutral"}
{"id": "test_3660", "sentence1": "There is a growing amount of research literature on various debiasing methods to improve the robustness of models against individual biases in the training data (Clark et al., 2019;Mahabadi et al., 2020;Utama et al., 2020;He et al., 2019;Schuster et al., 2019b).", "sentence2": "all our models are trained for 2 epochs.", "label": "neutral"}
{"id": "test_3661", "sentence1": "This requires significant modifications to the model and may make it harder for the decoder to generate fluent and diverse text as found in the targets.", "sentence2": "given a source and a target, how can one know if a target token wyt is unsupported by the source?", "label": "neutral"}
{"id": "test_3662", "sentence1": "Can we measure length instead of noise?", "sentence2": "models pick up on the noise and may hallucinategenerate fluent but unsupported text.", "label": "neutral"}
{"id": "test_3663", "sentence1": "Furthermore, we break down the performance of overall SQL queries into each $VALUE slot, results presented in Table 3.", "sentence2": "for Acc ex , we execute both the generated query and the ground truth and compare whether the retrieved results match each other.", "label": "neutral"}
{"id": "test_3664", "sentence1": "To alleviate the above problem, we propose AirConcierge, an end-to-end trainable text-to-SQL guided framework to learn a neural agent that interacts with KBs using the generated SQL queries.", "sentence2": "we use a rule-based model to annotate.", "label": "neutral"}
{"id": "test_3665", "sentence1": "In the transformer, the representation of each query token gets updated by self-attending to the representations of all the query tokens and graph nodes in the previous layer.", "sentence2": "to mitigate these problems, we manually filter the data by removing graphs with disconnected components, lowquality instances, or excessively long descriptions", "label": "neutral"}
{"id": "test_3666", "sentence1": "Parsing text into structured semantics representation is one of the most long-standing and active research problems in NLP.", "sentence2": "we explore the possibility of augmenting the user-generated data with synthetic data in order to train a better model.", "label": "neutral"}
{"id": "test_3667", "sentence1": "Because of the nature of motion and its importance in natural language, we selected it as the first semantic prime to explore.", "sentence2": "if there are multiple iNANiMATE entities in motion please highlight all of them.", "label": "neutral"}
{"id": "test_3668", "sentence1": "Since the vocabulary of the connection phrases is limited, we automatically generate text stitch training data by dropping certain words in free texts with simple rules.", "sentence2": "we require the removed tokens to have the aforementioned POS tags, plus adj, adv, det, intj, pron which are also found in connection phrases sometimes but with lower probability.", "label": "neutral"}
{"id": "test_3669", "sentence1": "More training details can be found in the appendix.", "sentence2": "it is less sensitive to expression variations and content orders than other automatic metrics.", "label": "neutral"}
{"id": "test_3670", "sentence1": "Since it is a corpus of spoken language, it has some characteristics that differ significantly from written corpora: there is no punctuation, nor any sentence or paragraph mark, there are speech turns and disfluencies, like word repetitions (e.g.", "sentence2": "several metrics have been developed to evaluate automatic coreference resolution systems (see (Poesio et al., 2016) for an overview).", "label": "neutral"}
{"id": "test_3671", "sentence1": "Table 6 presents the number of spurious and missing mentions, compared to the total number of mentions in the gold standard corpus (that is, the mentions that should be detected) and the predicted corpus (mentions that the system has actually found).", "sentence2": "coreference is easier to solve in ANCOR (38.95% of coreference only errors).", "label": "neutral"}
{"id": "test_3672", "sentence1": "However, we are planning to release the primary annotations in their original form as part of our additional material.", "sentence2": "we generally follow this idea: reported is more summarizing and less precise, while indirect ST&wR can usually be read as a transformation of direct ST&wR that allows us to reconstruct the 'original' quote in more detail.", "label": "neutral"}
{"id": "test_3673", "sentence1": "One reason for this is that the newspapers and magazines that were used for our corpus tend to contain quite complex texts (political commentary and reports in historical German).", "sentence2": "It would be orthogonal to our categories and is thus not included. In addition, many aspects of mind representation that are more removed from the idea of thought as speech and were pointed out by literary scholars (e.g. Palmer, 2004) are excluded in our annotation.", "label": "neutral"}
{"id": "test_3674", "sentence1": "A direct predecessor of our corpus is Brunner (2015), a corpus of 13 German narratives from the 18th and early 19th century (approx. 57,000 tokens)", "sentence2": "an author of the 'Digitale Bibliothek' could only be selected again after all other authors available in this decade had already been drawn.", "label": "neutral"}
{"id": "test_3675", "sentence1": "By this very primitive matching, we naturally neglected polysemy, and, due to the noise in the Treq table, some equivalents were admittedly suboptimal.", "sentence2": "even a noun in the position of the indirect object is classified as an accusative noun, although it corresponds to dative in most languages and some grammars call the two morphologically distinct pronominal cases in these virtually non-inflective languages subject/object case.", "label": "neutral"}
{"id": "test_3676", "sentence1": "Figure 1 illustrates an example of Chinese discourse parsing tree.", "sentence2": "as mentioned by Rhetorical Structure Theory (Mann and Thompson, 1988), a discourse is composed of elementary discourse units (EDUs), which can be formed into a hierarchical structure by relating each other with discourse relations.", "label": "neutral"}
{"id": "test_3677", "sentence1": "For example, we observed that the most frequent collaboration labels for claims are B-extension (43.9%), B-new (37.0%) and B-challenge (11.1%).", "sentence2": "during discussions with teachers where we visualized the collaboration annotations in the corpus that came from their particular classrooms, we found that teachers were very curious about whether students were introducing new information into the discussion or building off of what was previously said.", "label": "neutral"}
{"id": "test_3678", "sentence1": "Explanation: Infinitival complements of verbs are not segmented as separate EDUs.", "sentence2": "explanation: Infinitival complements of verbs are not segmented as separate eDUs.", "label": "neutral"}
{"id": "test_3679", "sentence1": "Our decoder design is fairly simple.", "sentence2": "the model achieves a state-of-the-art F-score of 96.7 for the RST-DT corpus (Carlson et al., 2003) improving on the previous best model by 7.2%.", "label": "neutral"}
{"id": "test_3680", "sentence1": "By using a separate connective model first, the window for the neural model is already determined.", "sentence2": "this data collection consists of two parts, bbc-news and bbcsport, both from the years 2004 to 2005.", "label": "neutral"}
{"id": "test_3681", "sentence1": "In Table 6, we study differences in the position of Arg1 compared to Arg2.", "sentence2": "because the predicted annotations are not as reliable as the gold annotations, the model could easily make false assumptions about the data when using a bad balance of gold labels and proxy labels.", "label": "neutral"}
{"id": "test_3682", "sentence1": "(3) To exploit implicit connectives given by treebank annotators, we add a task named implicit connective prediction at the fine-tuning step.", "sentence2": "they singled out this task while we perform it jointly with MaskedLM and next sentence prediction.", "label": "neutral"}
{"id": "test_3683", "sentence1": "This selection of the second-echo images renders the two sets of functional images as comparable as possible.", "sentence2": "these include bigram lexical surprisal, trigram lexical surprisal, bigram POS surprisal, trigram POS surprisal, CFG surprisal, CFG bottomup node count, CFG top-down node count, MG bottom-up node count, and MG top-down node count.", "label": "neutral"}
{"id": "test_3684", "sentence1": "It shares an underlying book with the cross-linguistic project, Alice in the Language Localizer Wonderland (Fedorenko, 2016) and an emphasis on naturalistic text with the Narrative Brain Dataset (Lopopolo et al., 2018) (hereafter NBD).", "sentence2": "sixteen participants were scanned with a three-echo EPI sequence where the field of view was 240 x 240 mm resulting in 33 slices with an inplane resolution of 3.75 mm 2 and thickness 3.8mm.", "label": "neutral"}
{"id": "test_3685", "sentence1": "Table 1 shows details about the GoodWriting dataset.", "sentence2": "we use optuna 9 to optimize hyperparameters in feature-based models.", "label": "neutral"}
{"id": "test_3686", "sentence1": "In this study, we created an automated essay scoring (AES) system for nonnative Japanese learners using an essay dataset with annotations for a holistic score and multiple trait scores, including content, organization, and language scores.", "sentence2": "by contrast, neural-network-based methods do not need to create features and have produced state-of-the-art results in various datasets (Ke and Ng, 2019).", "label": "neutral"}
{"id": "test_3687", "sentence1": "We follow the feature set described by Zesch et al. (2015).", "sentence2": "we developed AES systems using two different approaches: a feature-based approach and a neural-network-based approach.", "label": "neutral"}
{"id": "test_3688", "sentence1": "While developing a computational model for humour recognition in Portuguese, we decided to tackle two styles of humour and gathered some texts for validation purposes  (Clem\u00eancio et al., 2019).", "sentence2": "four sets of negative examples were gathered, namely: news titles from Reuters; proverbs on the Web; sentences from the British National Corpus (BNC); and sentences from the Open Mind Common Sense project.", "label": "neutral"}
{"id": "test_3689", "sentence1": "Section 4. presents the experiments we carried out on our data.", "sentence2": "when reporting sexist content, the speaker is still conveying lack of commitment, and a general sense of disapproval or dismissal may emerge.", "label": "neutral"}
{"id": "test_3690", "sentence1": "The null hypothesis is that all models have equivalent results and so the rankings must be equal.", "sentence2": "the remaining 165 features were computed for each text in the corpus.", "label": "neutral"}
{"id": "test_3691", "sentence1": "All 19 newly proposed features are computed on the linked documents.", "sentence2": "the drop in performances is higher for the combination of surface and shallow features (-.09) than for the graph-based deep semantic features (-.04) on the five-level classification task.", "label": "neutral"}
{"id": "test_3692", "sentence1": "We use all 1,000 articles (200 titles on five complexity levels) as our dataset, and apply ten-fold cross-validation setup with ten repetitions (in Weka Experimenter) without controlling for which titles and text versions end up in which fold.", "sentence2": "this can be explained by the fact that in the binary classification task the system needs to decide which of the two versions of the same text is simpler.", "label": "neutral"}
{"id": "test_3693", "sentence1": "To the best of our knowledge, there were no other studies that attempted at five-level text classification in the scope of conceptual text complexity.", "sentence2": "we behave as we had 1,000 independent articles on five different complexity levels, but choose to have 200 titles on five complexity levels, in order to: (1) allow for learning subtle differences between different complexity levels of texts treating the same topic; and (2) avoid bias that might arise from topic differences if we used corpora with five complexity levels, in which each level has different topics (as in the case of typical language learners corpora).", "label": "neutral"}
{"id": "test_3694", "sentence1": "The task of automatically assessing conceptual complexity has only been proposed recently.", "sentence2": "on the five-level classification task, they were outperformed by all other feature sets.", "label": "neutral"}
{"id": "test_3695", "sentence1": "For ZuCo 1.0 the normal reading and task-specific reading paradigms were recorded in different sessions on different days.", "sentence2": "on the basis of the GECo and ZuCo 1.0 corpora, we extracted the following features: (i) gaze duration (GD), the sum of all fixations on the current word in the first-pass reading before the eye moves out of the word; (ii) total reading time (TRT), the sum of all fixation durations on the current word, including regressions; (iii) first fixation duration (FFD), the duration of the first fixation on the prevailing word; (iv) single fixation duration (SFD), the duration of the first and only fixation on the current word; and (v) go-past time (GPT), the sum of all fixations prior to progressing to the right of the current word, including regressions to previous words that originated from the current word.", "label": "neutral"}
{"id": "test_3696", "sentence1": "For the document (a) (slides) in Figure 1, only Str classifier correctly predicts the class label with a probability of 0.74.", "sentence2": "as an example, consider a scholarly works repository, which contains publications that are typical for an institutional repository such as research articles, white papers, slide decks from presentations, and other scholarly publications.", "label": "neutral"}
{"id": "test_3697", "sentence1": "All Train-1, Dev, and Test follow a similar distribution as the original datasets.", "sentence2": "co-training methods are semi-supervised and assume that all views are \"sufficient\" for learning.", "label": "neutral"}
{"id": "test_3698", "sentence1": "Hence, it depends on the mean frame size of the aspect flows generated from a dataset, so that the model can avoid the unwanted effect of generating various sub-frames in a short frame.", "sentence2": "frequencydomain features are extracted from the sound spectrum, a representation of the distribution of the frequency content of sounds (Giannakopoulos and Pikrakis, 2014d).", "label": "neutral"}
{"id": "test_3699", "sentence1": "It is remarkable that in both languages the most offensive tweets were associated with the Venezuelan political incident.", "sentence2": "the same can happen with the surprise emotion.", "label": "neutral"}
{"id": "test_3700", "sentence1": "Some of the most commonly used datasets in recent studies are listed below.", "sentence2": "anger, disgust and fear were more usual for the Venezuela situation.", "label": "neutral"}
{"id": "test_3701", "sentence1": "The tool is mainly divided into two parts.", "sentence2": "emotion carriers extraction, for example, could be a useful task for conversational mental healthcare applications.", "label": "neutral"}
{"id": "test_3702", "sentence1": "In this work, we present our experiments with manual annotation of emotion carriers in spoken PNs in the German language from the Ulm State-of-Mind in Speech (USoMS) corpus (Schuller et al., 2018).", "sentence2": "in this task, the dataset is provided with the sentiment (positive or negative) of the text, and our goal is to find the emotion carriers for that sentiment.", "label": "neutral"}
{"id": "test_3703", "sentence1": "Performances are lower on the LargeSet (wQBC = 1.67) than on the SmallSet (wQBC = 1.62).", "sentence2": "other than the anticipation of linguistic elements, hesitation might be provoked by uncertainty of the communicated content.", "label": "neutral"}
{"id": "test_3704", "sentence1": "This result is not surprising but could explain certain biases in the data set.", "sentence2": "to enable their comparison between chunks with various segmental contents, formant values in Bark scale were converted to distances to centroids.", "label": "neutral"}
{"id": "test_3705", "sentence1": "Table 3 shows the average VAD and EI scores of poems in PoKi and poems written by adults.", "sentence2": "we also know that emotion language shifts over development from a focus on subjective feelings to external features (O' Kearney and Dadds, 2004).", "label": "neutral"}
{"id": "test_3706", "sentence1": "The present work is the first step of a bigger project located at the cross-domain between semantic and paralinguistic information modeling in call center spontaneous speech directly from audio signal.", "sentence2": "in order to calibrate the perception of the satisfaction dimension, we extracted from the corpus two conversations that we thought were the extreme boundaries of frustration and satisfaction i.e. the conversations with the most frustrated caller and another one with the most satisfied caller.", "label": "neutral"}
{"id": "test_3707", "sentence1": "in order to calibrate the perception of the satisfaction dimension, we extracted from the corpus two conversations that we thought were the extreme boundaries of frustration and satisfaction i.e. the conversations with the most frustrated caller and another one with the most satisfied caller.", "sentence2": "if this maximum is high, the predicted satisfaction is likely to be good.", "label": "neutral"}
{"id": "test_3708", "sentence1": "This annotation procedure relaxes the reader perspective, as we encourage annotators (if in doubt) to annotate how they think the other annotators would annotate.", "sentence2": "even though the crowds' labels look inconsistent at first view, there appears to be a good signal in their aggregated annotations, helping to approximate expert annotations to a certain degree.", "label": "neutral"}
{"id": "test_3709", "sentence1": "Those ratings are used (2) to train sentiment-aware word embeddings.", "sentence2": "based on a Twitter corpus with hashtag-derived polarity labels, they (1) apply the method of Mohammad (2012) to generate a first set of word labels (see above).", "label": "neutral"}
{"id": "test_3710", "sentence1": "Another seemingly obvious evaluation strategy would be to predict document-level ratings from derived word-level lexica using the empathic reactions dataset in a cross-validation setup.", "sentence2": "this gives lexica an important role for building justifiable AI and addressing related ethical challenges (Clos et al., 2017).", "label": "neutral"}
{"id": "test_3711", "sentence1": "In light of this development, lexica, lists of words and associated weights for a particular affective variable, which used to be a key component for feature extraction (Mohammad and Bravo-Marquez, 2017a), may seem obsolete.", "sentence2": "lowempathy words, on the other hand, are often ones used for ridiculing, hence expressing a lack of empathy (joke, wacky).", "label": "neutral"}
{"id": "test_3712", "sentence1": "Furthermore, Lores (2004) investigated the usage of Theme and Rheme in abstracts of scholarly articles.", "sentence2": "academic Phrasebank (Morley, 2014) is one of them.", "label": "neutral"}
{"id": "test_3713", "sentence1": "The communicative function of the targeted sentence is also shown.", "sentence2": "we note that 64.7% of the data showed 100% accuracy, and the accuracy for 84.4% of the data is greater than 75%, which implies that the majority of the quizzes are easy to answer.", "label": "neutral"}
{"id": "test_3714", "sentence1": "Moreover, a few attempts have been made to create a list of formulaic expressions (Simpson-Vlach and Ellis, 2010; Ackermann and Chen, 2013).", "sentence2": "it cannot be used as a ground-truth dataset.", "label": "neutral"}
{"id": "test_3715", "sentence1": "Formulaic expressions are extracted from the example expressions by hand, but because they can be very specific or sometimes contain irrelevant content, some queries return no results.", "sentence2": "a low accuracy and high agreement indicate that the dataset is of low quality.", "label": "neutral"}
{"id": "test_3716", "sentence1": "A building block of characteristic metrics for text collections is the language representation method.", "sentence2": "with more outliers or more sub-clusters, the diversity metric can also reflect the increasing dispersion of cluster distributions but is less sensitive in high-dimensional spaces.", "label": "neutral"}
{"id": "test_3717", "sentence1": "To accommodate the impact of high-dimensionality, we impose a dimension normalization.", "sentence2": "when there are two or more class labels in a text collection, in an ideal scenario, we would expect the homogeneity to be monotonically decreasing.", "label": "neutral"}
{"id": "test_3718", "sentence1": "We down-sampled SST-2 and Snips training sets from 100% to 10% with intervals being 10%.", "sentence2": "how uniformly the embedding vectors of the samples in a group of texts are distributed in the embedding space.", "label": "neutral"}
{"id": "test_3719", "sentence1": "Event Mention Retrieval (EMR) task: given a query consists of a handful of event mentions, return all relevant event mentions in a corpus.", "sentence2": "the ad-hoc retrieval model does not increase when k increases.", "label": "neutral"}
{"id": "test_3720", "sentence1": "In this paper, we provide an adapted benchmark data set that is based on a test collection originally used to evaluate information retrieval systems.", "sentence2": "note that there are several different database schema designs already available if one uses the internet movie database directly as a data source.", "label": "neutral"}
{"id": "test_3721", "sentence1": "At the same time, (Chandran and Kasturi, 1993) designed a structural table detection method based on horizontal and vertical lines, as well as the item blocks.", "sentence2": "their recognition process differs significantly from previous approaches as it realizes a bottom-up clustering of given word segments, whereas conventional table structure recognizers all rely on the detection of some separators such as delineation or significant white space to analyze a page from the top-down.", "label": "neutral"}
{"id": "test_3722", "sentence1": "(3) Using weak supervision that consists in pre-training a supervised model on data labelled with an unsupervised approach (Dehghani et al., 2017).", "sentence2": "for example, if we consider the query \"Developmental disorder\", the most relevant (relevance = 2) document is \"Developmental disorders comprise a group of .", "label": "neutral"}
{"id": "test_3723", "sentence1": "The annotated corpus is split into training, development, and test sets.", "sentence2": "to compute mention embeddings, CONtES uses word embeddings from a large corpus.", "label": "neutral"}
{"id": "test_3724", "sentence1": "Habitat mentions are subject to much more variations, and, due to the microscopic nature of bacteria, any object or place can be construed as a habitat.", "sentence2": "we set a short symmetrical window of two tokens in all subsequent experiments.", "label": "neutral"}
{"id": "test_3725", "sentence1": "To the best of our knowledge, this is among the first publiclyavailable Chinese EL dataset derived from long text and annotated with two major Chinese KBs (Chinese Wikipedia and CN-DBpeida).", "sentence2": "we are not aware of any direct research in characterizing EL corpus in terms of difficulty.", "label": "neutral"}
{"id": "test_3726", "sentence1": "The evaluation results on CLEEK and the subsets divided according to difficulty metric reveal that our proposed corpus is of high quality with documents in different levels of difficulty, and the difficulty measure can well characterize the ambiguity of documents.", "sentence2": "far, numerous English EL corpora have been constructed from different types of sources, including news (Hoffart et al., 2011;Cucerzan, 2007;Rosales-M\u00e9ndez et al., 2018), tweets (Rowe et al., 2014) and RSS feeds (R\u00f6der et al., 2014).", "label": "neutral"}
{"id": "test_3727", "sentence1": "Bridging corpus linguistics and neuroimaging methodology may open new perspectives in language research.", "sentence2": "this methodology is similar to that described in Eklund and Ingvar's (2016) fMRI-based account on filled vs. unfilled hesitation pauses.", "label": "neutral"}
{"id": "test_3728", "sentence1": "Isolated disfluencies with SPs 158 Total 404 Table 1.", "sentence2": "it was demonstrated that annotated multichannel corpora like RUPEX can be an important resource for experimental research in interdisciplinary fields.", "label": "neutral"}
{"id": "test_3729", "sentence1": "Since the focus of this work is to introduce a new dataset for tasks involving entity salience, we run simple algorithms to showcase the use of our dataset.", "sentence2": "News articles in Wikinews are written by volunteers, who can write or edit a page by expanding it, correcting facts and so on.", "label": "neutral"}
{"id": "test_3730", "sentence1": "Given an article, there might be hundreds or thousands readers, while there can only be one or few writers.", "sentence2": "we observe that basic statistics show major differences between news articles in different years.", "label": "neutral"}
{"id": "test_3731", "sentence1": "If there was any disagreement in the annotation, all the annotators discussed and made the final decision.", "sentence2": "these teachers used minimal edits to make the learners' sentences grammatically correct.", "label": "neutral"}
{"id": "test_3732", "sentence1": "Many of the articles in the Lang-8 corpus are written as if the learner writes a diary.", "sentence2": "(2018) manually performed grammatical error correction limiting error types and adding error tags in the Lang-8 corpus to study a grammatical error correction system on Japanese functional expressions.", "label": "neutral"}
{"id": "test_3733", "sentence1": "The Lang-8 corpus has often only one corrected sentence per learner sentence, which is not enough for evaluation.", "sentence2": "we created and released a highly reliable evaluation corpus for a grammatical error correction system of JSL learners' sentences.", "label": "neutral"}
{"id": "test_3734", "sentence1": "We decided to not make corrections on the sentence but on the article level.", "sentence2": "in this study, we manually corrected the learner sentences extracted from the Lang-8 corpus using consistent rules and created a highly reliable evaluation corpus for the correction of grammatical errors in Japanese.", "label": "neutral"}
{"id": "test_3735", "sentence1": "(Kleedorfer et al., 2008) apply Non\u0002negative Matrix Factorization (NMF) to ca. 60k song texts and cluster them into 60 topics", "sentence2": "researchers have resorted to distant supervision, obtaining gold labels from social tags from lastfm.", "label": "neutral"}
{"id": "test_3736", "sentence1": "The Odinson index loading times are not averaged, since they were loaded only once per query.", "sentence2": "we introduce Odinson, a novel rule-based information extraction (IE) framework, which efficiently indexes syntactic information to rapidly execute patterns over a large corpus.", "label": "neutral"}
{"id": "test_3737", "sentence1": "Here we extend this expressivity, allowing for both surface and syntactic information in the same pattern, i.e., a single Odinson pattern can include a regular expression over both surface tokens and dependency syntax.", "sentence2": "because of the + marker on the instrument line, the rule also matches an additional instrument argument by continuing through the optional conj dependency.", "label": "neutral"}
{"id": "test_3738", "sentence1": "Other fields are helpful to index but not required, such as lemma, chunk, entity, and part-of-speech tags.", "sentence2": "a state-of-the-art Odin grammar for this domain had to backoff to surface information for 38% of its patterns (Valenzuela-Esc\u00e1rcega et al., 2018).", "label": "neutral"}
{"id": "test_3739", "sentence1": "In the example, two sentences match the query, but only one of them satisfies the metadata filter.", "sentence2": "because there is an intervening xcomp relation, the traversal fails.", "label": "neutral"}
{"id": "test_3740", "sentence1": "We describe the sub-tasks with the help of the following examples.", "sentence2": "extracting relevant information manually about any event from this large amount of data is a nearimpossible task.", "label": "neutral"}
{"id": "test_3741", "sentence1": "Their proposed method automatically learns which parts are relevant for a given classication.", "sentence2": "a neural network can learn those features automatically.", "label": "neutral"}
{"id": "test_3742", "sentence1": "If a company voluntarily hides a vital information for the market's wealth, they fall under the Financial Authority it depends on and might become the subject of a lawsuit for Statement Fraud.", "sentence2": "since the company is making business in every continent and sometimes in politically unstable countries, the risk has to appear in its Annual Report.", "label": "neutral"}
{"id": "test_3743", "sentence1": "Also, the repartition of those sectors vary between countries, due to countries market's structure such as France having more \"Consumer Staples\" 2 companies due to the important share of the agricultural sector.", "sentence2": "figure 5. shows that there is no pattern except that this section rarely occur near the end of ARs.", "label": "neutral"}
{"id": "test_3744", "sentence1": "More specifically, relation discovery was cast as a prediction of the most likely relation type between two concept entities.", "sentence2": "in EEG reports, certain words tend to be more ambiguous than others, suggesting that computing the encodings of these words requires additional processing to correctly capture their meaning from the contexts in which they appear.", "label": "neutral"}
{"id": "test_3745", "sentence1": "Finally, the clinical correlation section explains what the EEG findings mean in terms of clinical interpretation, (e.g. \"findings indicative of underlying metabolic encephalopathy\").", "sentence2": "the TNE leverages Adaptive Computation Time (Graves, 2016) to dynamically allocate more computational resources for the encoding of some words compared to others in the same EEG report.", "label": "neutral"}
{"id": "test_3746", "sentence1": "This relation schema is adapted from the schema reported in previous work (Maldonado et al., 2017b;Maldonado et al., 2018).", "sentence2": "several clinically relevant relations between concepts have also been identified and annotated in the corpus.", "label": "neutral"}
{"id": "test_3747", "sentence1": "Since some unit pairs only make sense within a larger context, we also displayed the full microtext for every pair.", "sentence2": "we want to investigate whether the distribution of the semantic properties we annotated for the inserted sentences -commonsense relation types and semantic clause types -respectively differs depending on the internal structure of an argument.", "label": "neutral"}
{"id": "test_3748", "sentence1": "Retrieved URIs are stored as part of the entity annotation.", "sentence2": "in addition, each of these tools has a specific functionality, while the Lynx platform combines them all in a single ecosystem.", "label": "neutral"}
{"id": "test_3749", "sentence1": "We are interested in a small fraction of the information belonging to these domains.", "sentence2": "in the following we briefly review several of these systems, which usually focus on one very specific feature or functionality.", "label": "neutral"}
{"id": "test_3750", "sentence1": "This is potentially because the explicit relations are a smaller set and easier for BERT to predict and this in turn helps Spatial BERT.", "sentence2": "we also relax the accuracy metric by counting a prediction as correct if the gold relation is in the top-5 predicted relations.", "label": "neutral"}
{"id": "test_3751", "sentence1": "Each sequence contains complete sentences.", "sentence2": "they can be difficult to implement because of the amount of data and computational resources needed for pretraining.", "label": "neutral"}
{"id": "test_3752", "sentence1": "The existing automatic evaluation methods for these are limited (Lin et al., 2011; Pitler et al., 2010; Ellouze et al., 2017), usually do not take into account the complex and subjective nature of the linguistic quality factors. ", "sentence2": "furthermore, this work does not include any special data cleaning or annotation aggregation method other than the calculating mean values over 24 different judgments for a single item.", "label": "neutral"}
{"id": "test_3753", "sentence1": "For the particular case of query-based extractive forum summarization, the source document consists of two bases: forum posts and the corresponding user query.", "sentence2": "further analysis needs to be performed in order to find out the optimal aggregation method along with the corresponding optimal repetition number, such that comparable results to the laboratory can be obtained in a reliable and cost-effective way.", "label": "neutral"}
{"id": "test_3754", "sentence1": "NH 2.0 contained 5,589,323 English words and and 2,651,414 Inuktitut words.", "sentence2": "The Nunavut Hansard Inuktitut\u2013English Parallel Corpus 3.0 (NH 3.0) consists of 17,330,271 English words in 1,452,347 sentences, and 8,068,977 Inuktitut words in 1,450,094 sen\u0002tences, yielding approximately 1.3 million aligned sentence pairs.5", "label": "neutral"}
{"id": "test_3755", "sentence1": "For a script that is not phonetic, e.g., Chinese characters, grapheme-tophoneme conversion is considered compulsory.", "sentence2": "the final 10,000 sentences with their length information are written to a file in the tab separated format (tsv).", "label": "neutral"}
{"id": "test_3756", "sentence1": "To improve the accuracy of curation classifiers, we do the following.", "sentence2": "this method works for very popular temples like 'tirumala Venkateswara temple'.", "label": "neutral"}
{"id": "test_3757", "sentence1": "A scientific study of temples can reveal valuable insights into Indian culture and heritage.", "sentence2": "the temple corpus consists of 4933 high accuracy facts about 573 temples.", "label": "neutral"}
{"id": "test_3758", "sentence1": "The generation of the boards happens manually in one of the applications, either by adapting existing available free boards 11 or creating completely new boards, which demands a high amount of manual work.", "sentence2": "(Small) language resources created for endangered and under-studied languages can be exploited for various applications for people with limitations, especially when utilizing further information and annotations in the resource instead of focusing on a large amount of data.", "label": "neutral"}
{"id": "test_3759", "sentence1": "When English is the source language, and Japanese is the target language, there are only 5 pairs in the test data where the source and target words are identical, i.e., cases where the copy baseline is correct.", "sentence2": "Details of the evaluation datasets are shown in Table 2.", "label": "neutral"}
{"id": "test_3760", "sentence1": "We did not consider Japanese and Russian because they do not use the Latin alphabet.", "sentence2": "in the case of OOV source words, we apply the copy baseline.", "label": "neutral"}
{"id": "test_3761", "sentence1": "A total of 100k articles were scrapped from the archive in the encoded format.", "sentence2": "if two or more annotators marked a given sentence as unsure, then such sentences were removed from the dataset in order to avoid ambiguity.", "label": "neutral"}
{"id": "test_3762", "sentence1": "Moreover, it can be observed that consistent performance improvements are seen for all the four three metrics of evaluation: Precision, Recall, F1-Score, and Accuracy.", "sentence2": "the annotators were advised to strictly avoid making annotation decisions based on their own point of view (e.g -personal prejudices) when it comes to such sentences.", "label": "neutral"}
{"id": "test_3763", "sentence1": "Last but not least, one should ensure that the set of learners consulted for a given question is heterogeneous enough in terms of proficiency and background to prevent the unlikely, yet possible, situation where an incorrect answer is excessively chosen by a too homogeneous set of learners with similar shortcomings.", "sentence2": "we could also observe that we were not able to identify exercises for some of the LRs targeted by our members such as Multiword-expression (MwE) datasets or Morphological Rules (see next section).", "label": "neutral"}
{"id": "test_3764", "sentence1": "Usually, users tend to express their intention with short and lack of context utterances so traditional rule-based or machine-learning methods are not good enough.", "sentence2": "in our experiments we use the same fine-tuning strategy as the original paper, feeding the output [CLS] token representation to an output layer for classification.", "label": "neutral"}
{"id": "test_3765", "sentence1": "We have already mentioned that we took FMTODes as starting point for projecting the training data into Basque.", "sentence2": "the number of epochs to fine-tune was selected based on the results from monolingual experiments (table 3), which were optimized on the dev set, to the point were standard deviation of micro F1-score between the five runs was lower than 1.", "label": "neutral"}
{"id": "test_3766", "sentence1": "As evoked in section 2, we have adopted the expert-sourced expand approach to building our wordnet resource, i.e. a subset of words, glosses, and examples from the English Princeton WordNet were translated and validated by Gaelic language experts.", "sentence2": "our USGW has its fair share of verbs but is relatively poor in adjectives with respect to the PWN (that has 15% of adjectives), which should be addressed in future work.", "label": "neutral"}
{"id": "test_3767", "sentence1": "Both versions were evaluated over our test dataset.", "sentence2": "with approaches that use feature engineering to extract features , in (Amir et al., 2016) features are automatically extracted by learning user embeddings which requires users' preceding messages.", "label": "neutral"}
{"id": "test_3768", "sentence1": "Overall, we have found that almost all types are strongly skewed towards either idiomatic or literal usage, and that truly balanced types are rare.", "sentence2": "since this latter category is a 'miscellaneous'-category that can contain anything unforeseen, it triggers the third tier.", "label": "neutral"}
{"id": "test_3769", "sentence1": "PIEs are most frequent in news, prose fiction, conversations, and popular magazines (pop lore), i.e. texts whose main purpose is entertainment.", "sentence2": "We were however encouraged by related work by Kato et al.  (2018), who use crowdsourcing for a similar annotation task (verbal multiword expressions, including some idioms), showing that annotators agree in approximately 67% of cases.", "label": "neutral"}
{"id": "test_3770", "sentence1": "For 'other'-labels, we also collected annotators' explanations for selecting that label.", "sentence2": "what we have done here in terms of analysis is limited to a relatively high-level view of idiom distributions and frequencies.", "label": "neutral"}
{"id": "test_3771", "sentence1": "As such, we collect more annotations for these lowagreement cases, until agreement is over 70%, up to a maximum nine annotations.", "sentence2": "we compromise a little bit on precision to get a higher number of expressions.", "label": "neutral"}
{"id": "test_3772", "sentence1": "The consonant system mostly relies on a three-way distinction in plosives /b, t, k/ and nasals /m, n, N/.", "sentence2": "single word utterances tend to delete the final burst and therefore end with a mere closure [p^, t^, k^].", "label": "neutral"}
{"id": "test_3773", "sentence1": "In addition to the language corpora, catalogue resources were generated and made available online.", "sentence2": "while the large-scale approach of the project allows for manifold cross-lingual, diachronic and interdisciplinary research on a very high level, the data situation that will be described in the following section puts new requirements to methods of data modelling and technology used within the project.", "label": "neutral"}
{"id": "test_3774", "sentence1": "Thereby, major challenges arise from the need for cross-resource data analysis and a rather complex resource landscape on the territory of the Russian Federation.", "sentence2": "in practice it seems to be common to only extract parts of information that is considered to be relevant and to leave the remaining information behind.", "label": "neutral"}
{"id": "test_3775", "sentence1": "When A is not a modal verb, the construction was treated as separate words.", "sentence2": "we leave these instances open to future researchers' interpretation.", "label": "neutral"}
{"id": "test_3776", "sentence1": "Section titles are found inside a capital letter and two line breaks.", "sentence2": "besides, we perform ten different experiments with each kind of filter by applying different random seeds, as we must make a valid statistical comparison to ensure that the results are not coincidental.", "label": "neutral"}
{"id": "test_3777", "sentence1": "Our work is focused on English, Swedish and Bulgarian, since the development of solid resources for other languages requires language expertise.", "sentence2": "most ex-isting resources are aligned on synset level with Princeton WordNet, but as we will show later, synset alignment is not the same as building a translation dictionary.", "label": "neutral"}
{"id": "test_3778", "sentence1": "It started with the primary goal of supporting Wikipedia, and in particular it provides structured, linked data about anything that has a Wikipedia article (called a topic).", "sentence2": "the ShEx files are all publicly available under a CC0 license (Creative Commons, 2009), and thus can be reused and modified as needed for the given use case.", "label": "neutral"}
{"id": "test_3779", "sentence1": "We also plan to expand this effort to cover Arabic dialects following the effort by Bouamor et al.  (2018) on the MADAR project; and target non-native speakers of Arabic (Saddiki et al., 2015; Saddiki et al., 2018).", "sentence2": "level II: Generally corresponding to Grades 2-3, this level begins to add an imaginative dimension to the sensory which is still dominant in this level.", "label": "neutral"}
{"id": "test_3780", "sentence1": "The formula is constructed based on selected features that are associated with text's lexical content and are considered important to determine the text's readability.", "sentence2": "We report on a detailed analysis of the major disagreements among our annotators.", "label": "neutral"}
{"id": "test_3781", "sentence1": "This information is repeated for all the vocabulary modules, although there is no way to go between languages on the TUFS website.", "sentence2": "translation sets that did not link directly are discussed further below.", "label": "neutral"}
{"id": "test_3782", "sentence1": "Table 4 show quantity information from OFrLex per UPoS.", "sentence2": "we filtered it using the dedicated ghost words base named Base des mots fant\u00f4mes [du Godefroy]12 dedicated to identify these entries and to clean them.", "label": "neutral"}
{"id": "test_3783", "sentence1": "Performance on Japanese (ja) beats the high-performing baseline because of a feature of the Japanese writing system: foreign words are written in katakana, while native words are written in hiragana or kanji.", "sentence2": "mW lists the first use of machine as 1545, though it was not found in GNG until after 1700.", "label": "neutral"}
{"id": "test_3784", "sentence1": "In principle, there exists a set of ISO 1 rules which can be applied when converting a proper noun from a source language into a different target language.", "sentence2": "to (Merhav and Ash, 2018), we used any language in the langtag of Wikipedia next to the word.", "label": "neutral"}
{"id": "test_3785", "sentence1": "The obtained values are used, later, for estimating the presence of Framing Bias by comparing, for each election and news outlet, whether the subjectivity of the news outlet's reports about two opposing parties/candidates are significantly different or not.", "sentence2": "each comment is finally represented by a five-dimensional subjectivity vector, where each dimension corresponds to the amount of a specific type of subjectivity.", "label": "neutral"}
{"id": "test_3786", "sentence1": "Here, we provide the resulting data in a format that is used in a series of shared tasks for Translation Inference Across Dictionaries (TIAD-2017, TIAD-2019, TIAD-2020) for which UPM Apertium served as training data.", "sentence2": "if the e2 argument is an entry with another language code, we point to the URi of the corresponding expression, i.e., a lexical form.", "label": "neutral"}
{"id": "test_3787", "sentence1": "At the moment, we provide a generic RDF conversion for each of the dictionary collections, we do not harmonize external vocabularies beyond the application of the OntoLex-Lemon vocabulary.", "sentence2": "each of these XML files is then transformed with an XSLT script to an RDF/XML representation in OntoLex-Lemon, with the concept mapping as described above.", "label": "neutral"}
{"id": "test_3788", "sentence1": "Through structured discussion papers based on the results of the questionnaires the workshop participants (20-30 participants in each workshop) identified the problem areas and proposals for the most effective actions.", "sentence2": "in this paper, we describe the process behind the development of the languagerelated parts of the strategy: A Danish Language Technology Committee was constituted and a comprehensive series of workshops were organised in which users, suppliers, developers, and researchers gave their valuable input based on their experiences.", "label": "neutral"}
{"id": "test_3789", "sentence1": "The recommendations of the committee were finalized in January 2019.", "sentence2": "governmental initiatives for artificial intelligence and especially for LT have been rather scarce.", "label": "neutral"}
{"id": "test_3790", "sentence1": "Over the coming years, AI is expected to transform not only every industry but society as a whole.", "sentence2": "there is a general initiative to foster digital transformation in industry, administration, and research.", "label": "neutral"}
{"id": "test_3791", "sentence1": "Hence, it helps to shed light on the historical background of the socio-cultural being of Southern France's Gascon speaking minority, on linguistic and cultural interactions between the Gascon, Occitan and French speaking populations in the area.", "sentence2": "a screenshot of the homepage is shown in Fig.", "label": "neutral"}
{"id": "test_3792", "sentence1": "Only the top part of the ontologydescribing individual aspects of query functionality at an abstract level -will be standardized.", "sentence2": "with conformance statements for a new (or newly added) CQL, or with entries for new Frames and Use Cases.", "label": "neutral"}
{"id": "test_3793", "sentence1": "Conformance against the CQLF Metamodel is stated by providing the full path ending in a Module, e.g. (1) single stream / complex / dependency", "sentence2": "there can be no positive conformance statement x that belongs to Q and A , nor to any Use Case U \u00c3\u00a2\u00c5\u00a0\u00e2\u20ac\u02dc A instantiating A .", "label": "neutral"}
{"id": "test_3794", "sentence1": "We developed a software to scrape sunnah.com pages and extracted the information from every Hadith.", "sentence2": "the Hadith segmenter pipeline is shown in Figure 3, where it applies the following steps: 1.", "label": "neutral"}
{"id": "test_3795", "sentence1": "One of the research areas that caught interest in AI methods is the study of religious texts to enhance understanding and discover new embedded knowledge.", "sentence2": "to the best of our knowledge, no parallel corpus of Hadith is freely available to the research community.", "label": "neutral"}
{"id": "test_3796", "sentence1": "The Hadith below is an example with parallel Isnad where the first chain of narrators is followed by the prophet's name, which is followed by another chain of narrators that ends with the prophet's name as well.", "sentence2": "we are only interested in those that include Hadith or classical Arabic text in general.", "label": "neutral"}
{"id": "test_3797", "sentence1": "KPIs are not only considered useful for measuring progress, but also for collecting feedback on the strategy of a research infrastructure.", "sentence2": "for new data sets, guidelines, best practices and awareness raising activities are planned that can help prevent avoidable interoperability gaps.", "label": "neutral"}
{"id": "test_3798", "sentence1": "Out of these, one KPI is related to the use and promotion of standards and mappings that are essential for interoperability.", "sentence2": "the ESFRI Monitoring group could not depart from actual objectives that were shared across infrastructures (there are some, but not many), but rather had to go for slightly more general objectives that could be agreed upon by all or many infrastructures, such as the aim to enable and support scientific excellence.", "label": "neutral"}
{"id": "test_3799", "sentence1": "As of this writing, Related Works have been cataloged for roughly eighty percent of LDC's holdings and the data indicates that each corpus has an average of about 2.7 relations.", "sentence2": "in order to support references to related works outside of the LDC Catalog, it was also necessary to store names and URLs for these exogenous resources.", "label": "neutral"}
{"id": "test_3800", "sentence1": "In line with the project objectives, the scope for selecting institutions was confined in two ways", "sentence2": "then we present the first step in how this objective was approached within a local language infrastructure project, namely by means of a structured documentation of the local language actors landscape in South tyrol.", "label": "neutral"}
{"id": "test_3801", "sentence1": "Then we present the first step in how this objective was approached within a local language infrastructure project, namely by means of a structured documentation of the local language actors landscape in South Tyrol.", "sentence2": "besides these principal players also a large number of smaller language actors could contribute to and benefit from language infrastructures.", "label": "neutral"}
{"id": "test_3802", "sentence1": "We will be using only the tokenizer portions from these models as comparisons.", "sentence2": "this is analogous to how subword tokenization methods have brought to the field guarantees of lossless encoding and decoding, which was not possible with conventional lossy encoding methods such as lemmatization, stemming, and other normalization methods.", "label": "neutral"}
{"id": "test_3803", "sentence1": "Korean is an outlier in the CJK family, which linguistically has a shared vocabulary in terms of roots, but uses an entirely different character representation.", "sentence2": "this also allows some level of sharing, which reduces the final budget needed in the vocabulary.", "label": "neutral"}
{"id": "test_3804", "sentence1": "In modern electronic text corpora, cuneiform text is represented in two distict latinizations: (1) sign-to-sign level graphemic transliteration and (2) phonemic transcription based on an approximation of the Akkadian language and its reconstructed sound system (Kouwenberg, 2011).", "sentence2": "it would be useful to minimize ambiguity by first using a large dictionary lookup (e.g. consisting of the whole corpus of a given dialect in Oracc), and then trying to predict the correct phonological render\u0002ing only if the transcription is clearly ambiguous", "label": "neutral"}
{"id": "test_3805", "sentence1": "We hope out resource will foster NLP research in the financial domain where datasets are currently very scarce.", "sentence2": "we observe a drop of 17% and 8% at the 3-and 4-gram levels respectively.", "label": "neutral"}
{"id": "test_3806", "sentence1": "We used the BLEU score for evaluating our system performance.", "sentence2": "we addressed this issue with BPE to make this whole process more efficient and reliable.", "label": "neutral"}
{"id": "test_3807", "sentence1": "Also, the Opus dataset is a much widely used parallel corpus resource in various researcher's works.", "sentence2": "In self-attention architecture (Vaswani et al., 2017) at every time step of an RNN, a weighted average of all the previous states will be used as an extra input to the function that computes the next state.", "label": "neutral"}
{"id": "test_3808", "sentence1": "After working on all these minor, but effective preprocessing we got our final dataset.", "sentence2": "manual translation is a very tedious, costly, and time-taking process.", "label": "neutral"}
{"id": "test_3809", "sentence1": "The noisier the training data becomes, the more the translation quality of NMT systems deteriorates.", "sentence2": "the NMt model trained with only the content-equivalent corpus achieved a BLEU score of 20.93, which was the best score for Japanese\u2192English news translation without using a domain-adaptation technique.", "label": "neutral"}
{"id": "test_3810", "sentence1": "The wrong word (adequado) is shown in bold accompanied by the indication of the error subcategory (syn numberConc).", "sentence2": "we believe that the worst performance of the NMT system was mainly due to the small size of the training corpus, which contains only about 162k sentences.", "label": "neutral"}
{"id": "test_3811", "sentence1": "This approach has the advantage of being able to be applied to, possibly, all language pairs and corpora types.", "sentence2": "the PBSMt was trained using Moses toolkit as detailed in (Martins and Caseli, 2015).", "label": "neutral"}
{"id": "test_3812", "sentence1": "Subcategories of lexical errors are: extra word, absent word, not translated word and incorrectly translated word.", "sentence2": "of this NMT approach's limitation, the most frequent error subcategories in the NMT system's output are all of the lexical error category: absent word (24.17%), incorrectly translated word (16.41%), not translated word (15.19%) and extra word (10.98%).", "label": "neutral"}
{"id": "test_3813", "sentence1": "Numbers of BPE merge operations considered are 10k, 32k and 64k.", "sentence2": "for under-resourced language pairs, the performance of MT systems can still be disappointing, as pointed out for instance by Koehn et al.", "label": "neutral"}
{"id": "test_3814", "sentence1": "Figure 1(b) shows an example of a test for an article.", "sentence2": "for preprocessing, the English sentences are tokenized and lowercased by the scripts in Moses toolkit (Koehn et al., 2007).", "label": "neutral"}
{"id": "test_3815", "sentence1": "We first looked for examples in bilingual corpora.", "sentence2": "As was also shown in Kimura et al. (2019), Japanese zero pronouns can basically be effectively handled by context-aware neural machine translation.", "label": "neutral"}
{"id": "test_3816", "sentence1": "The translation output abandons the translation of the subordinate clause, which is a typical behavior of neural machine translation.", "sentence2": "since we found that this approach is inefficient, we chose a different approach using linguistically annotated corpora.", "label": "neutral"}
{"id": "test_3817", "sentence1": "The current NMT systems introduce the subword tokenization, which transfers rare words to the sequence of its constituent characters (Sennrich et al., 2016).", "sentence2": "JPX has also enriched its childcare and caregiving leave systems to create an environment that allows employees to balance work and family commitments", "label": "neutral"}
{"id": "test_3818", "sentence1": "As is well known, one bottleneck to MT is the scarcity of quality data, which means primarily parallel texts, but recently monolingual data has been usefully employed through the technique of back translation (Sennrich et al., 2015).", "sentence2": "for this task we will use the systems and components from Wikifier (Brank et al., 2017), XLing (Rupnik et al., 2016) and EventRegistry (Leban et al., 2014) all dealing with statistical and semantic cross-lingual annotations and alignments.", "label": "neutral"}
{"id": "test_3819", "sentence1": "Besides the aligned abstracts and sentences, we included the family id for each abstract, such that researchers can use that information for other text mining purposes.", "sentence2": "load the n th individual file.", "label": "neutral"}
{"id": "test_3820", "sentence1": "Version 2 of the COPPA corpus contains almost 13 million parallel sentences in 8 language pairs.", "sentence2": "amazon EC2 r5dn.8xlarge instances, featuring 32 cores and 256GiB of RaM memory were used for this alignment step.", "label": "neutral"}
{"id": "test_3821", "sentence1": "Thus, the gains mainly come from better translation consistency contributed by document context.", "sentence2": "this task aims to consider both the current sentence and its large context in a unified model to improve translation performances, especially in terms of discourse properties.", "label": "neutral"}
{"id": "test_3822", "sentence1": "Taking news domain for example, one entity word usually needs to keep consistent translation across the whole document in newswire.", "sentence2": "the collected corpora contain 7 language pairs (e.g.", "label": "neutral"}
{"id": "test_3823", "sentence1": "Concatenative morphology is centered on stem and affix (prefixes, suffixes, circumfixes) morphemes, which are generally concatenated in a sequence to produce a surface form.", "sentence2": "an example is the hamza ligature (combination of lam and hamza characters e.g lI, lO)) due to neighboring characters.", "label": "neutral"}
{"id": "test_3824", "sentence1": "This result reinforces the observation we made in Table 2 that LIT methods are attractive for obtaining good performance with smaller vocabulary sizes.", "sentence2": "weighted + PC removal: After creating word embeddings using (1), we substract the first Principal Component (PC) as suggested by Arora et al. (2017) to remove information that is common to all words, thereby emphasising the relative semantic differences among words.", "label": "neutral"}
{"id": "test_3825", "sentence1": "For example, given the string \"Hello world\", where \" \" denotes the space character, a possible sequence of subtokens could be H/el/l/o/ /world.", "sentence2": "as discussed later in section 5., training time of BPE is significantly longer compared to that of LM, which prevented us from creating 1M model for BPE.", "label": "neutral"}
{"id": "test_3826", "sentence1": "To address this question,iIn a preliminary study, we mixed all corpora in Table 1 to create a single multilingual corpus and trained LM and BPE on it.", "sentence2": "For example, text compression methods such as byte pair encoding (BPE) (Gage, 1994; Sennrich et al., 2016) and language modelling (LM) methods (Kudo, 2018) automatically select frequent subwords as tokens, and segment a given text such that some loss function (e.g. negative likelihood or code length) is minimised.", "label": "neutral"}
{"id": "test_3827", "sentence1": "In de and fa where morphological agglutination and partial usage of fusional features are common (e.g. in the case system), we see that LIT methods such as BPE and LM outperform LST.", "sentence2": "as seen from our previous example, unlike LST, LIT often produces nonsensical subwords, which are not valid morphological units (Zhu et al., 2019).", "label": "neutral"}
{"id": "test_3828", "sentence1": "Exceedingly finer tokenisation is likely to return many irrelevant results with incorrect or partial matches, whereas not tokenising larger phrases will return zero results.", "sentence2": "applying more sophisticated supervised composition methods such as a recurrent neural network might help to create word embeddings from subtoken embeddings under such situations.", "label": "neutral"}
{"id": "test_3829", "sentence1": "We find that in very low settings, morphological analyzers help boost the performance of the full morphological disambiguation task.", "sentence2": "we observe three regions of different performance behaviors.", "label": "neutral"}
{"id": "test_3830", "sentence1": "We use the POS tagset introduced in (Habash et al., 2013) which consists of 36 tags.", "sentence2": "non-lexical features are bounded in the language and therefore can be captured easily.", "label": "neutral"}
{"id": "test_3831", "sentence1": "Since spelling modifications, especially insertions and deletions, will lead to a more complex full morphological evaluation process, we leave this effort to future work.", "sentence2": "for GLF, we use the approach of paradigm completion as demonstrated by Eskander et al.", "label": "neutral"}
{"id": "test_3832", "sentence1": "Morphological inflection is especially important and challenging for low-resource languages, where no or little annotated data is present.", "sentence2": "model is trained to optimize perplexity without any supervision, therefore our approach differs from language model pretraining in the sense of Peters et al.  (2018) and other related works.", "label": "neutral"}
{"id": "test_3833", "sentence1": "This issue is detailed further in Section 6.. Turkish morphology has a complex yet mostly regular morphotactics with a fixed order of morphemes with a notable exception concerning the interaction of the 3rd Person Plural morpheme -lAr with its surrounding context (Ozenc\u00b8 and Solak, 2019b).", "sentence2": "the number of analyses they return differs.", "label": "neutral"}
{"id": "test_3834", "sentence1": "The BiLSTM model is used to monitor the probability of an end-of-token symbol appearing after any character within a given token sequence.", "sentence2": "we also evaluate a version of this model with two BiLSTM layers.", "label": "neutral"}
{"id": "test_3835", "sentence1": "The results of the evaluation show that the BiLSTM models obtain a much higher precision and recall than the statistical method in Kvistur 1.0.", "sentence2": "this method identifies cognates, such as \"Abdominalangiographie\" in German and \"abdominal angiography\" in English, finding the split that maximizes the similarity between the constituent parts of the compound and the words in the non-compound.", "label": "neutral"}
{"id": "test_3836", "sentence1": "The model is shown in Figure 2.", "sentence2": "adding more layers to the BiLSTM model does not appear to have a significant impact on precision and recall.", "label": "neutral"}
{"id": "test_3837", "sentence1": "The UniSent lexica and a complete list of 1242 unique languages 4 covered by UniSent along with their language family information are provided in the supplementary material.", "sentence2": "(ii) Manual-Train-Lexicon: In order to obtain an upper bound for the UniSent performance, we compare the use of UniSent-Train-Lexicon against the use of words in the gold standard lexicon as sentiment seeds for the training in the target domain.", "label": "neutral"}
{"id": "test_3838", "sentence1": "Looking more closely at the neighbors, the word sensual in the biblical context has been associated with negative sentiment of sins.", "sentence2": "The creation of UniSent requires only a sentiment lexicon in one language (e.g. English) and a small, but massively parallel corpus in a specific domain.", "label": "neutral"}
{"id": "test_3839", "sentence1": "We have computed type to token ratio (TTR), calculated as vocabulary size divided by text length, based on the training transcriptions.", "sentence2": "are also among the morphologically complex languages.", "label": "neutral"}
{"id": "test_3840", "sentence1": "We presented a set of experiments meant to illustrate the usefulness of this resource.", "sentence2": "examples in WIKIBANK consists of semantically labelled sentences, where each sentence has partial-semantic annotation for the predicate and its semantic arguments (see example in Table 2).", "label": "neutral"}
{"id": "test_3841", "sentence1": "For example, for ES trained with 1000 target examples, the best model can be found in Table 5, for this example it is the one trained using DE as extra source language.", "sentence2": "the attention mechanism focuses on encoding the frame representation that the parser has created rather than encoding the tokens themselves.", "label": "neutral"}
{"id": "test_3842", "sentence1": "In order to avoid having the interviewers as common speakers across all sets, their utterances have been placed in the train set.", "sentence2": "all participants were asked to report the languages they currently speak, as well as the languages learnt before the age of 5.", "label": "neutral"}
{"id": "test_3843", "sentence1": "There is still a huge need to further collect corpora for the other language pairs, as well as extend the corpora for the previously mentioned languages, in order to give foundation for multilingual NLP applications to spur in that direction.", "sentence2": "the train set contains utterances from 4 female and 8 male interviewees, in addition to 1 female and 1 male interviewer.", "label": "neutral"}
{"id": "test_3844", "sentence1": "For k-best case, the maximum value across k predictions is taken.", "sentence2": "as only Roman-script languages were used, the number of possible common acronyms makes it possible to use string similarity distance for monolingual clustering.", "label": "neutral"}
{"id": "test_3845", "sentence1": "As shown in the mentioned paper, this approach helps to achieve maximum coverage despite transliteration ambiguity.", "sentence2": "the bilingual model from (Merhav and Ash, 2018) returns predictions ranked by probability in descending order, but doesn't return actual probability values.", "label": "neutral"}
{"id": "test_3846", "sentence1": "To analyse the model errors, we have sampled 200 random name pairs (English-Korean and English-Russian) for which the most probable three predictions of the model did not contain ground truth, i.e.", "sentence2": "in our dataset only few of the variations are present.", "label": "neutral"}
{"id": "test_3847", "sentence1": "The Entity linking task has been traditionally achieved on documents such as newspaper articles, which is rich in textual content but generally lacks visual information that could be used in the EL task.", "sentence2": "each entity in the knowledge base represents a twitter user characterized by its timeline (set of pair of text-image).", "label": "neutral"}
{"id": "test_3848", "sentence1": "For mention and entity textual context representations, we used the unsupervised Sent2Vec (Pagliardini et al., 2018) sentence embedding model, and more precisely, a pretrained version on a large Twitter corpus6", "sentence2": "we have drawn inspiration from this usage to elaborate a simple process for both candidate entity and ambiguous mention generations.", "label": "neutral"}
{"id": "test_3849", "sentence1": "We report in Table 3 the accuracy performance of our classifier for different feature combinations.", "sentence2": "social media posts like tweets provide poor and noisy textual contexts which make the Entity linking task harder, but is often associated with complementary visual information.", "label": "neutral"}
{"id": "test_3850", "sentence1": "Figure 1 shows a screenshot of the COCo platform.", "sentence2": "we decided to concatenate each title to the general title of the lecture.", "label": "neutral"}
{"id": "test_3851", "sentence1": "These predictions were combined to create the ensemble representation.", "sentence2": "to ensure the content being published in the platform complies with the policies and guidelines, Youtube has moderators working intensively to review videos flagged by users.", "label": "neutral"}
{"id": "test_3852", "sentence1": "Articles such as those on deforestation and drainage infrastructure are flood-related as they identify main (potential) causes of flooding.", "sentence2": "future work in multimedia analysis should not assume that only a single type of connection is possible between text and image.", "label": "neutral"}
{"id": "test_3853", "sentence1": "However, multimedia research often makes highly rigid assumptions about the relationship among the media.", "sentence2": "the difference is not a sharp as one might expect.", "label": "neutral"}
{"id": "test_3854", "sentence1": "We implement two neural models that use all modalities, TVQA (Lei et al., 2018) and MovieQA (Tapaswi et al., 2016).", "sentence2": "these datasets include rich annotations about human actions, objects, and scenes, but do not include questions and answers as in LifeQA.", "label": "neutral"}
{"id": "test_3855", "sentence1": "The graph shows that many questions reference basic visual features, such as count (how many),  color (what color), and location (where) answers.", "sentence2": "we use GloVe embeddings (Pennington et al., 2014) with size 300 pretrained on 6B tokens from wikipedia 2014 (Rajpurkar et al., 2016) and Gigaword5 (Parker et al., 2011).", "label": "neutral"}
{"id": "test_3856", "sentence1": "This paper provides a systematic evaluation of vector-space reduction variants across kinds, exploring reductions based on part-of-speech next to and also in combination with Principal Components Analysis using Singular Value Decomposition, and word2vec embeddings.", "sentence2": "next to identifying a clear winner (Word2Vec) we can induce from our results that using only the most frequent noun dimensions is a reasonable alternative.", "label": "neutral"}
{"id": "test_3857", "sentence1": "In a graph-based ranking model the terms extracted from the natural language text with a co-occurrence value within an n-sized window are represented as an undirected graph with nodes as single terms and co-occurrence values as unweighted edges.", "sentence2": "we conclude that the meaning shifts are effective in biasing the network.", "label": "neutral"}
{"id": "test_3858", "sentence1": "But also none of the results for the top k for DIY and ACL reach the results for COOK.", "sentence2": "the automatic recognition of terms represents an important basis for further Natural Language Processing (NLP) tasks, such as thesaurus creation, automatic translation, and, in general, for domain knowledge acquisition and comprehension.", "label": "neutral"}
{"id": "test_3859", "sentence1": "BPE tokenization has become a de-facto standard way for processing sub-words in the era of BERT (Devlin et al., 2019) and BERT-like models.", "sentence2": "this is a list of 82 309 split nominal compounds extracted from a German wordnet GermaNet (Henrich and Hinrichs, 2010).", "label": "neutral"}
{"id": "test_3860", "sentence1": "For the L2 speakers, we also collected more detailed information about their language background, as presented in Table 4.", "sentence2": "in this project we developed a set of tools and language resources that were considered crucial for this kind of multifaceted research.", "label": "neutral"}
{"id": "test_3861", "sentence1": "The Federal Patent Court (BPatG) dataset contains the lowest number of annotated entities (10.41 %).", "sentence2": "the dataset was originally annotated by the first author.", "label": "neutral"}
{"id": "test_3862", "sentence1": "A case report can contain more than one case description.", "sentence2": "Grouin et al. (2019) presented a corpus with medical entity anno\u0002tations of clinical cases written in French, Ju et al. (2019) presented a corpus focusing on phenotypic information for chronic obstructive pulmonary disease while Smalheiser et al. (2019) presented a corpus focusing on identifying main finding sentences in case reports.", "label": "neutral"}
{"id": "test_3863", "sentence1": "Additionally, span-based F1 score is used to serialize the best performing model.", "sentence2": "as mentioned above, only case presentation sections, headings and abstracts are annotated.", "label": "neutral"}
{"id": "test_3864", "sentence1": "The parser is fully defined in that unknown characters or rules will yield separate tokens.", "sentence2": "when sampling pages, no visible differences to the content or format was significantly evident.", "label": "neutral"}
{"id": "test_3865", "sentence1": "i love italian and i eat here often.", "sentence2": "due to the discreteness of the generated text, the gradients of sentiment classification loss could not be directly propagated from the classifier to our VAE model.", "label": "neutral"}
{"id": "test_3866", "sentence1": "In the Machine Learning community, similar problems are typically solved by using artificially generated data to augment or perhaps even replace an original dataset (Bachman, 2016) in e.g. image processing.", "sentence2": "since GPT-2 has been pre-trained on 40GB of internet text data, it has already learnt to model the English language and therefore needs considerably less data to achieve reasonable results and effectively learn how to write a discharge summary.", "label": "neutral"}
{"id": "test_3867", "sentence1": "We use the fine-tuning scripts provided by nshepperd.", "sentence2": "interestingly, this benefit only manifests itself when classifying with the BioBERT model.", "label": "neutral"}
{"id": "test_3868", "sentence1": "The remainder of this paper is organized as follows.", "sentence2": "to this end, we propose two stages of representation learning.", "label": "neutral"}
{"id": "test_3869", "sentence1": "As a future work, we plan to apply our method to other tasks such as named entity recognition using ProBase (Wu et al., 2012) which has a number of entity information as a form of semantic networks.", "sentence2": "the proposed model achieves as much as 8.1% improvement on average in test accuracy compared to strong baselines in the CR dataset.", "label": "neutral"}
{"id": "test_3870", "sentence1": "Common Crawl word vectors (FastText-officialcommon-crawl) were trained on Common Crawl and Wikipedia using CBOW with position-weights, with character n-grams of length 5, a window size 5 and 10 negatives (Grave et al., 2018).", "sentence2": "table 1 shows the composition of the corpus.", "label": "neutral"}
{"id": "test_3871", "sentence1": "The authors show that CamemBERT obtains significant improvements on many French tasks compared to the publicly available multilingual BERT.", "sentence2": "in many cases the teams that developed the algorithms also release their models, which facilitates both reproducibility and their application in downstream tasks.", "label": "neutral"}
{"id": "test_3872", "sentence1": "Being a clever sort, he started shouting loudly, \"Let me through!", "sentence2": "second, we propose an exploratory study investigating the links between smiling and humor.", "label": "neutral"}
{"id": "test_3873", "sentence1": "In line with such studies, laughter has even been considered \"the contextualization cue for humor par excellence\" (Kotthoff, 2000), and its absence has been seen as a mark of failure of humor (Norrick, 1993).", "sentence2": "first, the entire humorous sequences were annotated and classified either as canned joke (CJ) or conversational humor (CH).", "label": "neutral"}
{"id": "test_3874", "sentence1": "From the audio file of each speaker, the Inter-Pausal Units (IPUs) were automatically extracted.", "sentence2": "it was recorded following the American protocol, as closely as possible, especially concerning the tasks given to the participants (see section 2.2).", "label": "neutral"}
{"id": "test_3875", "sentence1": "Calculate the overlap between the reference sentence, Refs, and the raw prediction, Pred, as well as between Refs and the modified prediction, Pmod.", "sentence2": "the highest value in each column is indicated in Figure 2a and shows the relationship between each source token and its corresponding target token.", "label": "neutral"}
{"id": "test_3876", "sentence1": "In fact, Koehn and Knowles (2017) list raising the quality of out-of-domain translations as the first of \"Six Challenges for Neural Machine Translation.\"", "sentence2": "the training stage in NMt prepares a translation model from aligned bitexts in a given domain.", "label": "neutral"}
{"id": "test_3877", "sentence1": "Furthermore, our results, based on limited data, indicated that percentage improvement increases, on average, with the size of the corpus as measured with BLEU, though this may not be true in all cases.", "sentence2": "as discussed earlier, injection of target terminology sometimes introduces target-language grammatical errors when incompatibility with the rest of the sentence arises.", "label": "neutral"}
{"id": "test_3878", "sentence1": "In both Figures 1b and 2a, the highest value in the column under the source token \"report,\" a value of 0.8274, triggers the target token selection.", "sentence2": "(1) Your report is absolutely disgraceful.", "label": "neutral"}
{"id": "test_3879", "sentence1": "Dialogue data, techniques, and evaluation Social bots are expected to entertain the user hence and are often evaluated by the number of turns they can make in conversations (Khatri et al., 2018).", "sentence2": "starting from a user experience perspective, what would be the ideal world experience for the interrogator?", "label": "neutral"}
{"id": "test_3880", "sentence1": "and both TF-IDF and BERT models pick up the right question in the KB: 'Where are you from?'.", "sentence2": "we considered the similarity between a new question and every answer in the KB as an alternative model, but the results are so much weaker than question-similarity that it is not worth reporting them.", "label": "neutral"}
{"id": "test_3881", "sentence1": "The object property spokenIn relates a dialect with an administrative or geographic location where this dialect can be found.", "sentence2": "bgDialectsOnto, on the other hand, is designed to implement the methods from the IbGDialectsOntology interface and it handles only individuals.", "label": "neutral"}
{"id": "test_3882", "sentence1": "We find that the formality of naming in these tweets correlates positively with their stance.", "sentence2": "since the use of honorifics can be indicative of sarcasm (Liu et al., 2014), it is worth investigating whether the use of titles alongside explicit negative stance should be interpreted as sarcasm, and whether this sarcastic use plays a role in causing the weaker positive association with formal naming in left-leaning discourse.", "label": "neutral"}
{"id": "test_3883", "sentence1": "To our knowledge, cross-and joint-domain training on the SemEval 2014 Task 4 datasets has not been analyzed so far.", "sentence2": "as a special case of cross-domain training we expect performance to be optimal if D LM = T .", "label": "neutral"}
{"id": "test_3884", "sentence1": "To summarize, we find that in order to correctly predict aspect-target based sentiment, the context sensitivity of the sentiment expression plays an important role in difficult examples.", "sentence2": "we compare our method to two very strong baseline models: BERT-base and XLNet-base.", "label": "neutral"}
{"id": "test_3885", "sentence1": "Moreover, we can notice throughout Figure 4-6 a significant gap in scores between ML and DL models.", "sentence2": "from the previous confusion matrix, we have already observed that the DESCRIPTION did not perform well compared to other categories.", "label": "neutral"}
{"id": "test_3886", "sentence1": ", it attributes a property to the restaurant of which it represents the atmosphere.", "sentence2": "The room is a little gloomy and old-fashioned.", "label": "neutral"}
{"id": "test_3887", "sentence1": "The results show that the proactive assistant behavior has been rated similarly positively as for the non-proactive one, where users initiated the dialog.", "sentence2": "every subject interacted with both assistants and experienced both traffic conditions during the respective interaction phases.", "label": "neutral"}
{"id": "test_3888", "sentence1": "In this work, we are dealing with SA at document level.", "sentence2": "the neutral reviews are not considered.", "label": "neutral"}
{"id": "test_3889", "sentence1": "For embedding construction, we consider three types of corpora: polar, non polar and mixed.", "sentence2": "the first third of each document therefore seems to contain relevant information to polarity classification.", "label": "neutral"}
{"id": "test_3890", "sentence1": "It is also unclear how to use it in cases where shifting results in a neutral polarity expression (Taboada et al., 2011).", "sentence2": "wordNet provides a variety of semantic relations between words, such as hypernymy, antonymy, entailment and derivational relatedness.", "label": "neutral"}
{"id": "test_3891", "sentence1": "Table 1 shows some examples of nearduplicate tweets found in the previous version of the corpus.", "sentence2": "The dataset created in (Castro et al., 2018) was used by Castro et al. (2018) in the context of the HAHA 2018 competition for Humor Detection and Funniness Average Prediction", "label": "neutral"}
{"id": "test_3892", "sentence1": "We define two separate dimensions to conceptualize what we consider humorous.", "sentence2": "in 2018 the top system used an evolutionary algorithm for training the system (Ortiz-Bejar et al., 2018), while in 2019 the top system performed fine-tuning over a multilingual BERT language model (ismailov, 2019).", "label": "neutral"}
{"id": "test_3893", "sentence1": "If the user chooses the option \"no\", it will be recorded as a negative vote for that tweet (not humor) and no further questions will be asked.", "sentence2": "this could indicate that the process of presenting test tweets to all users helps ruling out some low-quality annotations.", "label": "neutral"}
{"id": "test_3894", "sentence1": "Current semantic annotation addresses lexical (ontologyderived) tags rather than functional semantic annotation (semantic roles), albeit the latter is being prepared by including semantic frame tags for verbs.", "sentence2": "the last linguistic topic we will present here is the use of complex tense, mode and aspect.", "label": "neutral"}
{"id": "test_3895", "sentence1": "The treebank contains linguistic annotation at four primary levels: lemma, part-of-speech (POS) and inflection, syntactic function (\"edge labels\") and dependency-head id's (attachment links).", "sentence2": "'forta' (strong) is tagged <jpower> if combined with human or civitas nouns, but <jdegree> if combined with perception nouns ('bruo' -noise or 'lumo' -light).", "label": "neutral"}
{"id": "test_3896", "sentence1": "Because attachment errors were counted separately, attachment direction arrows at the clause level were ignored when evaluating function tags (i.e. @<SUBJ and @SUBJ> were both counted as just @SUBJ, subject)", "sentence2": "sequential attachments of second and later conjuncts to the first conjunct can easily, and automatically, be raised to parallel attachment, if corpus users wish to use the latter format.", "label": "neutral"}
{"id": "test_3897", "sentence1": "Accuracy is measured based on a detailed error analysis of the grammatical sentences which were incorrectly annotated by the parser.", "sentence2": "the adjective \"red\" in a sentence like \"the car is red\") functions as the sentential head and selects for a subject.", "label": "neutral"}
{"id": "test_3898", "sentence1": "Section 2. highlights some key issues in Wolof and describes how these are addressed in the grammar.", "sentence2": "figure 1: C-and f-structure of sentence (1) expressed in the perfective aspect through the combination of the na morpheme and the lexical verb.", "label": "neutral"}
{"id": "test_3899", "sentence1": "Bhat et al. (2017a) presented the improvements of dependency parsing for HUTB by using syntactically rich features.", "sentence2": "the original PS treebank caters to flexible word order of Urdu and this design feature makes is naturally compatible with a dependency structure.", "label": "neutral"}
{"id": "test_3900", "sentence1": "In many cases this does not change the information available in the treebank.", "sentence2": "the most widely noted difference among annotation models for syntax is probably the divergence between constituency models that conceive of the sentence structure as consisting of hierarchically organized phrases or constituents, and dependency models that represent the sentence structure as a graph where the tokens (words) are the edges.", "label": "neutral"}
{"id": "test_3901", "sentence1": "The hyper parameters were tuned on English UD, by exploring 100 configurations.", "sentence2": "In the pool of exciting methods that simplify the parsing task, our approach is closer in spirit to the approach of Zhang et al. (2017) for dependency parsing, and Marcheggiani et al. (2017) for semantic role labeling.", "label": "neutral"}
{"id": "test_3902", "sentence1": "This leads us to say that the degree of interactivity of the spoken dialogues has little or no influence on the POS distribution.", "sentence2": "false starts are explicitly annotated in the ODIL Syntax treebank to offer the possibility to avoid those noisy structures when using machine learning techniques.", "label": "neutral"}
{"id": "test_3903", "sentence1": "There have been various attempts at universal ASR: \"designing a universal phone recognizer which can decode a new target language with neither adaptation nor retraining\" (Siniscalchi et al., 2008).", "sentence2": "this approach consists of a shared multilingual encoder and language-specific projection layer.", "label": "neutral"}
{"id": "test_3904", "sentence1": "Most mappings were initially encoded by non-experts with a few hours of training, but all were subsequently checked by the first author, a professional linguist with graduate training in phonetics and phonology.", "sentence2": "the Allosaurus model described on the right side of Figure 3 can overcome both issues of those standard models by taking advantage of AlloVera.", "label": "neutral"}
{"id": "test_3905", "sentence1": "Sentences are phonetically rich (consist of the entire Arabic phonemic inventory) and balanced (having the same appearance in the language).", "sentence2": "the annotation work for each speaker has been saved in Praat label files of the type 'textGrid'.", "label": "neutral"}
{"id": "test_3906", "sentence1": "It is considered to be the modern version of Classical Arabic (Al-Sobh et al., 2015) and is the language of formal speech in Arab countries, such as is used in governmental speeches, the education system and on the news.", "sentence2": "based on the protocol requirements, a dataset can be suitable for FVC research which fulfills three criteria: 1) non-contemporaneity of recording sessions for each speaker, 2) using different speaking styles for the recordings of each speaker, and 3) usability for research and casework involving recording and transmission-channel mismatch.", "label": "neutral"}
{"id": "test_3907", "sentence1": "We demonstrate the usefulness of the proposed framework by applying it to precisely describe and compare six contemporary MRC datasets.", "sentence2": "we are interested in different types of the expected answer.", "label": "neutral"}
{"id": "test_3908", "sentence1": "MRC is a generic task format that can be used to probe for various natural language understanding capabilities (Gardner et al., 2019).", "sentence2": "we aim to establish which linguistic phenomena are probed by gold standards and to which degree.", "label": "neutral"}
{"id": "test_3909", "sentence1": "We therefore calculate agreement by calculating the Euclidean distance instead of the majority vote and define agreement when two outputs have distances less than the threshold.", "sentence2": "we annotate (1) explanation on why the most plausible answer span cannot be the answer and (2) which part of the question causes unanswerability.", "label": "neutral"}
{"id": "test_3910", "sentence1": "For more details on this model, please refer to (Hu et al., 2019).", "sentence2": "another distinction of our dataset lies in scale: (1) SQuAD2-CR contains approximately 10K humanlabeled annotations about cause in total, and these are propagated to all unanswerable questions on SQuAD 2.0 by semi-supervised learning.", "label": "neutral"}
{"id": "test_3911", "sentence1": "The two inputs, s and q represent the segment text and a question.", "sentence2": "this localization task has been out of scope for previous studies.", "label": "neutral"}
{"id": "test_3912", "sentence1": "Combining facts to perform inference is an inherently noisy process that often drifts off-context to unrelated facts, a phenomenon referred to as semantic drift (Fried et al., 2015).", "sentence2": "that do not have any supporting facts, and thus lack lexical-overlap edges), and for the annotator to then include those additional supporting facts to solidify the explanation.", "label": "neutral"}
{"id": "test_3913", "sentence1": "\"Passing through\" is similar to \"entering\".", "sentence2": "A number of recent datasets have been made available to support multi-hop inference models", "label": "neutral"}
{"id": "test_3914", "sentence1": "We have created this dataset from the various computer science related journals of Elsevier (like ARTINT, COMNET etc).", "sentence2": "it could be a benchmark dataset for span-of-words-based MRC systems in the domain of scholarly articles.", "label": "neutral"}
{"id": "test_3915", "sentence1": "Little work has been done, however, in developing EHR QA models that learn to answer questions directly from pairs of questions and their answers in unstructured notes.", "sentence2": "this dataset can be considered a good representative example of an open-domain QA task.", "label": "neutral"}
{"id": "test_3916", "sentence1": "As these tests are not independent, they cannot be summarized by using, for example, a binomial test.", "sentence2": "how do we decide whether the difference observed between two conditions is large enough to be considered reproducible?", "label": "neutral"}
{"id": "test_3917", "sentence1": "We initially attempted to set this up as a labeling task by providing participants labels and definitions.", "sentence2": "yet, it remains unknown how many of these edits were used to clarify information, since Daxenberger and Gurevych (2012) did not expose the underlying reasons to edit texts, apart from obvious ones such as spelling or grammar edits.", "label": "neutral"}
{"id": "test_3918", "sentence1": " we describe two datasets providing disambiguations in the form of Wikipedia pages.", "sentence2": "to gain insights on the features of each sense-annotated corpora, we provide a small analysis on the entropy and ambiguity levels.", "label": "neutral"}
{"id": "test_3919", "sentence1": "Surprisingly, the performance drops significantly on every dataset as the weight of the original word vectors is decreased.", "sentence2": "(2) MSD-1030 has a more balanced score distribution and higher annotation consistency, compared to the other datasets.", "label": "neutral"}
{"id": "test_3920", "sentence1": "Figure 3 illustrates the box-and-whisker plots that represent the distribution of the scores' variance and range for the pairs in MSD-1030 and three other datasets.", "sentence2": "each question in this dataset asks whether a certain word has the same meaning in two given contexts, which is a binary classification task.", "label": "neutral"}
{"id": "test_3921", "sentence1": "In this paper, we raise six concerns about existing word embedding benchmarks.", "sentence2": "we will show in Section 5 that our data construction process does lead to better consistency and a more balanced score distribution.", "label": "neutral"}
{"id": "test_3922", "sentence1": "A semantic attribute of a concept, such as \"an apple is red\", explicitly dictates a semantic aspect of the concept.", "sentence2": "the resulting vectors are combined by element-wise multiplication, and subsequently fed into the MLP that is responsible for the final classification.", "label": "neutral"}
{"id": "test_3923", "sentence1": "Our aim is to provide the linguistic and NLP research communities with a gold standard sense-annotated corpus of French, using WordNet Unique Beginners as semantic tags, thus allowing for interoperability.", "sentence2": "for instance, they use Vehicle, Building and Container as subclasses of the Artifact supersense (Martinez Alonso et al., 2016).", "label": "neutral"}
{"id": "test_3924", "sentence1": "As mentioned earlier, no automatic pre-annotation was proposed for nouns and no wild card was allowed in case of difficulty.", "sentence2": "All other annotation projects using UBs as tags we know of also had to make adjustments, but to a more limited extent.", "label": "neutral"}
{"id": "test_3925", "sentence1": "They are those proposed as generalization in Table 1, column 2.", "sentence2": "annotators could consult the description of the target noun's English equivalent on the WordNet website -using the \"show lexical info\" option -in order to guide their decision, while keeping in mind the differences between the two tagsets.", "label": "neutral"}
{"id": "test_3926", "sentence1": "Closed and open form information extraction are important and well studied NLP tasks (Banko et al., 2007; Wu and Weld, 2010; Berant et al., 2011; Fader et al., 2014).", "sentence2": "exploiting unstructured data sources to obtain structured user attributes is a challenging research direction.", "label": "neutral"}
{"id": "test_3927", "sentence1": "Class names were given by choosing the most generic word member that suits the common meaning, as well as the visual.", "sentence2": "this skill allows humans to express themselves in more complex ways, such as in communicating ideas, opinions and arguments.", "label": "neutral"}
{"id": "test_3928", "sentence1": "Our 20 verb classes and visual representations cover only 500 abstract verbs, and the possibility of having more is not excluded.", "sentence2": "the survey was completed by approximately 100 participants.", "label": "neutral"}
{"id": "test_3929", "sentence1": "First, we notice that using more data improves results for LR.Tfidf, whereas LR.LIWC results remain relatively stable.", "sentence2": "section 6 discusses the early detection of mental health issues, and section 7 presents additional remarks and discusses the next steps in the current project.", "label": "neutral"}
{"id": "test_3930", "sentence1": "This is due to the fact that some joke posts are humorous short stories, while others are simple puns.", "sentence2": "in the areas of humor classification and generation we find much smaller datasets, due to the complexity of humorous natural language.", "label": "neutral"}
{"id": "test_3931", "sentence1": "Let us see an example for this issue: @USER @USER It's probably better to have an next to my name than a pink pussy hat on my head #MAGA #MakeAmericaGreatAgain In this section, we provide an intrinsic evaluation of the corpus by conducting cross-validation experiments.", "sentence2": "we obtained 0.788 in macro F 1 -score in sequence labeling setting by using BERT, and explored the role of different features, also related to affect, in a standard text classification setting, with the aim to shed a better light on the properties which allow to distinguish between abusive and not-abusive swearing.", "label": "neutral"}
{"id": "test_3932", "sentence1": "We found 154 tweets having more than one swear word, with a range of occurrences from 2 to 6 swear words.", "sentence2": "based on F 1 -score, the best performance is achieved by using all the features except Twitter features 15 with the LSVC model.", "label": "neutral"}
{"id": "test_3933", "sentence1": "Our results confirm that our annotation is robust based on the sequence labeling performance.", "sentence2": "we calculated the percentage of swear word use in each class and the percentage of each swear word used over both classes.", "label": "neutral"}
{"id": "test_3934", "sentence1": "The inter annotator agreement is 0.708, based on Cohen's Kappa coefficient, which denotes a substantial agreement.", "sentence2": "we found several difficult cases", "label": "neutral"}
{"id": "test_3935", "sentence1": "We applied monolingual learning, cross-lingual learning and bilingual learning, using several classification algorithms to approach this task.", "sentence2": "combining the word and character n-grams features can enable the models to capture the writing styles more comprehensively, which leads to better results.", "label": "neutral"}
{"id": "test_3936", "sentence1": "Besides, n-grams features are very easy to compute and the logistic regression runs faster than deep learning methods.", "sentence2": "machine translation methods may be less appropriate for cross-lingual learning using stylometric features.", "label": "neutral"}
{"id": "test_3937", "sentence1": "In the following sections, we present and discuss the guidelines and the agreement scores.", "sentence2": "we converted the normalization annotations to a list of binary decisions (e.g., normalize the token or not).", "label": "neutral"}
{"id": "test_3938", "sentence1": "Italian is one of the most popular languages on the Internet, estimated to be the 9th most popular by w3techs, and was the 13th most popular language on Twitter in 2018.", "sentence2": "the \"entification\" is often a subjective process without clear boundaries, that is driven by the ideology, worship and psychological and linguistic disposition of the individuals.", "label": "neutral"}
{"id": "test_3939", "sentence1": "Otherwise, we consider the tweet to be from an urban setting.", "sentence2": "it is not always necessary to look at multiple countries in order to view different cultures.", "label": "neutral"}
{"id": "test_3940", "sentence1": "Broadcast recordings are generally recorded in clean conditions using professional equipment and expertise.", "sentence2": "this indicates a good generalization of the model and suggests that the model is robust enough for operation in real-world applications.", "label": "neutral"}
{"id": "test_3941", "sentence1": "Currently, probably English is the language with the largest amount of available training data for speech recognition.", "sentence2": "the second baseline is a model that we train from scratch on the 25 hours of automatically aligned oral history data.", "label": "neutral"}
{"id": "test_3942", "sentence1": "As a default step of the acoustic model training, we train an i-vector extractor on the English data in this stage.", "sentence2": "the gain is less than 0.2% relative.", "label": "neutral"}
{"id": "test_3943", "sentence1": "The set is manually transcribed and segmented.", "sentence2": "this observation can contribute to the ongoing research on speech recognition for under-resourced language.", "label": "neutral"}
{"id": "test_3944", "sentence1": "Segmentation of periods applies 4 criteria: 1) pause lasting for at least 300 milliseconds; 2) difference in height between the mean value of fundamental frequency over all the signal before the pause and the last value of fundamental frequency before the pause; 3) difference in height between the last value of fundamental frequency before the pause and the first one after the pause; 4) absence of hesitation (\u00ab euh \u00bb) just before or after the pause.", "sentence2": "the data is organized by sequences of utterances, so one utterance can contain several periods.", "label": "neutral"}
{"id": "test_3945", "sentence1": "Analor (Avanzi, Lacheret-Dujour, Victorri, 2008) is a semi-automatic segmentation tool developed within this framework.", "sentence2": "this pilot corpus contains transcriptions of preparing a meal, meetings, conferences, radio transmissions, interviews, etc.", "label": "neutral"}
{"id": "test_3946", "sentence1": "The code, trained models, and a live demo will be made available publicly.", "sentence2": "the largest publicly available resource available for training text-to-speech systems is the IndicttS (Baby et al., 2016) corpus that contains about 8 hours of speech data for 13 Indian languages.", "label": "neutral"}
{"id": "test_3947", "sentence1": "Works like Tacotron (Wang et al., 2017),Tacotron 2 (Shen et al., 2017), Deep Voice 3 (Ping et al., 2017) are capable of producing high quality natural speech.", "sentence2": "newspapers contain texts from a wide variety of domains ranging from politics to sports and entertainment.", "label": "neutral"}
{"id": "test_3948", "sentence1": "RTS occurs in the environment where a Rising tone becomes a low tone when it is either followed by a High or Falling tone as clearly seen in Figure 1.", "sentence2": "a Deep Neural Network (DNN) (Chen et al., 2014) with 3 hidden layers is trained for Mizo tone recognition, using Keras toolkit (Chollet and others, 2015).", "label": "neutral"}
{"id": "test_3949", "sentence1": "Since speech recognition technology is essential for these robots to function effectively, improving the accuracy of recognition of elderly speech has become an urgent issue since conventional speech recognition technology has not demonstrated sufficient accuracy when processing elderly speech.", "sentence2": "although the number of speakers was insufficient, a mild positive correlation was found between age and WER (correlation coefficient: 0.59).", "label": "neutral"}
{"id": "test_3950", "sentence1": "There are 16 dialects in Japan, and these dialects have been found to effect the accuracy of speech recognition (Kudo, 1996).", "sentence2": "there was also a wider variety of speaking styles in our corpus than in the JNAS and S-JNAS corpora, so we thought that the spontaneous speaking style contained in the CSJ corpus might be more similar to utterances of our speakers.", "label": "neutral"}
{"id": "test_3951", "sentence1": "The average age of S-JNAS participants is 67.6 years old, but Japan's life expectancy has risen to 84.2.", "sentence2": "we had a sufficient number of participants in Nagasaki, but to match the conditions in Tokushima and Yamagata we also recorded the Nagasaki test and training data using the same speakers.", "label": "neutral"}
{"id": "test_3952", "sentence1": "The list also includes common compounds, phrases, proper nouns, foreign words and new words listed in CMUdict.", "sentence2": "the pronunciation of some IE words cannot be correctly transcribed.", "label": "neutral"}
{"id": "test_3953", "sentence1": "Such an analysis is outside the scope of this project.", "sentence2": "manually segmented transcriptions are available in both NIST SCTK's time-marked transcription format (Fiscus, 2008) and Praat's TextGrid format (Boersma and Weenink, 2019).", "label": "neutral"}
{"id": "test_3954", "sentence1": "The wizard would, assuming the issue was not critical.", "sentence2": "roughly five thousand word segments across 92 word types from the experiment (excluding contracted determiners, foreign words, non-words, and words with less than 30 instances) were labelled in a binary fashion as more or less native.", "label": "neutral"}
{"id": "test_3955", "sentence1": "Studies show though that if the whole process is automated, the correlation to human judgments drops considerably, therefore keeping the need for high-effort manual annotations (Peyrard and Eckle-Kohler, 2017).", "sentence2": "the next steps involve the verification of our results on other languages, which are for example available in the MultiLing data.", "label": "neutral"}
{"id": "test_3956", "sentence1": "As there were reportedly problems with the ROUGE evaluation in MultiLing, we aim to further investigate this outcome with variations of the PyrEval setup.", "sentence2": "the high Pearson's correlation between quality scores on manual and automatic pyramids, especially when we use emb 2m, leads us to argue that this could be an issue of coverage.", "label": "neutral"}
{"id": "test_3957", "sentence1": "Furthermore, improvements measured with one metric do not necessarily lead to improvements when using others.", "sentence2": "another problem is that the credibility of ROUGE was demonstrated for the systems which operated in the lowscoring range.", "label": "neutral"}
{"id": "test_3958", "sentence1": "This strengthens dependencies among neighboring elements and makes the model distance-aware when it searches for lowlevel patterns in a sequence.", "sentence2": "a summarization model trained via Reinforcement Learning with this metric as reward achieved higher scores in both human and ROUGEbased evaluation.", "label": "neutral"}
{"id": "test_3959", "sentence1": "They do not require time-intensive training and can be computed within a few seconds.", "sentence2": "the Fandom wikis, for example, use a category system, as most wikis do.", "label": "neutral"}
{"id": "test_3960", "sentence1": "In addition to the articles, this covers metadata on media files, discussion pages, category overviews, special pages and other sites not relevant to our task.", "sentence2": "the question how the quality of the summary really correlates to the score of the extraction remains.", "label": "neutral"}
{"id": "test_3961", "sentence1": "We work with a corpus of final reports of publicly funded research projects provided by the Leibniz Information Centre for Science and Technology (TIB 3 ).", "sentence2": "this has been remedied by more recent efforts, such as the altmetrics movement, that consider the impact of research beyond academia, for example, by analyzing mentions of research in traditional and social media, or tracking the sharing and reuse of resources and data (Piwowar, 2013; taylor, 2013).", "label": "neutral"}
{"id": "test_3962", "sentence1": "We refer to these empirically grounded categories as \"anticipated\" impact since these indicator phrases were stated in reports, which may precede the transfer of science to society.", "sentence2": "the intellectual, factual and material access of the public to research can be a challenging task due to a lack of language consistency across academic domains, domain-specific terminology, limited open access resources, and publishers' paywalls.", "label": "neutral"}
{"id": "test_3963", "sentence1": "The fruit pictures correspond to the images used in the cover story; the robot and confederate pictures illustrates episodes of live conversations (Image taken from (Rauchbauer et al., 2019)).", "sentence2": "a cover story framing the study as a neuromarketing experiment with the goal to extract the message behind a new advertisement campaign provided the topic of conversation.", "label": "neutral"}
{"id": "test_3964", "sentence1": "Some of the human-elicited hypotheses contain patterns that spuriously correlate to some specific labels.", "sentence2": "for the hard subsets, on the other side, the indications of the artificial patterns should be all different from gold labels.", "label": "neutral"}
{"id": "test_3965", "sentence1": "Instead, they were only empirically false or unlikely to be true presumably based on the MTurk workers' real-world experiences.", "sentence2": "this is the largest fact checking dataset of real claims and evidence documents to date; it will allow the development of fact checking systems that can effectively process claims that occur in the real world.", "label": "neutral"}
{"id": "test_3966", "sentence1": "Such aspects of this example, however, is not recognized by word pairs alone.", "sentence2": "the average length of the context in terms of number of tokens was about 81 (spanning multiple sentences).", "label": "neutral"}
{"id": "test_3967", "sentence1": "Some such data sets which have enabled the advancement of NLI (and fact verification) are SNLI (Bowman et al., 2015) MNLI (Williams et al., 2017), FEVER (Thorne et al., 2018), and FNC (Pomerleau and Rao, 2017).", "sentence2": "(2) We analyze and examine the effect of such delexicalization techniques on several state of the art methods in NLI and confirm that these methods can still achieve comparative performance in domain.", "label": "neutral"}
{"id": "test_3968", "sentence1": "Boonkwan and Supnithi (2017) suggested that word segmentation should be trained in combination with POS tagging.", "sentence2": "negative log-likelihood loss on the development set and Adam optimizer (Kingma and Ba, 2015) are used to optimize the model parameters.", "label": "neutral"}
{"id": "test_3969", "sentence1": "We suppose that the language model used in this study, which is trained mainly on hotel reviews, could be the most beneficial for segmenting user-generated data in the hotel domain.", "sentence2": "accordingly, the language model yields high performance boost for both novel and encyclopedia in most settings, while the improvement for news is often modest.", "label": "neutral"}
{"id": "test_3970", "sentence1": "The authors also suggested a few fine-tuning methods to adapt the pretrained LM to downstream tasks including discriminative fine-tuning, slanted triangular learning rates, and gradual unfreezing.", "sentence2": "in novel-news combination with similar initial F1 Score, the pretrained LM can only bring 0.85% improvement in F1 Score.", "label": "neutral"}
{"id": "test_3971", "sentence1": "For uttering these responses in appropriate timings, it is not necessary to deeply understand the content of narrative.", "sentence2": "furthermore, the degree of empathy shown by \"response 6\" is also thought to be higher than that by \"response 5.\"", "label": "neutral"}
{"id": "test_3972", "sentence1": "As mentioned above, this data has five listeners' responses to the same narrative speech.", "sentence2": "the start time of response was mapped onto the nearest position of the following one in the narrative speech, considering that responses tend to be uttered right after a linguistic or phonetic boundary, namely: 1. clause boundary (linguistic) 2. pause longer than 200 milliseconds (phonetic)", "label": "neutral"}
{"id": "test_3973", "sentence1": "The component Grammar allows the user to specify a finite grammar with two extensions.", "sentence2": "as the performance scores of all these systems are close to maximum values, it is impossible to use traditional test set for comparison.", "label": "neutral"}
{"id": "test_3974", "sentence1": "The Estonian Reference Corpus (ERC) was missing information about paragraph boundaries, which is crucial for sentence segmentation.", "sentence2": "if such correspondence is relevant, a single layer with a joint attribute set must be created.", "label": "neutral"}
{"id": "test_3975", "sentence1": "Arity of Verbal Predicates \u2013 Distribution of the arity of verbal nodes, where the arity is the number of dependency links with that node as head.", "sentence2": "Maximal Non-Verbal Phrase \u2013 Mean and standard deviation of the dimension of the maximal nominal phrases in the constituent trees of the inputted text, where the dimension of a node is the number of terminal nodes beneath that node.", "label": "neutral"}
{"id": "test_3976", "sentence1": "Maximal Non-Verbal Phrase \u2013 Mean and standard deviation of the dimension of the maximal nominal phrases in the constituent trees of the inputted text, where the dimension of a node is the number of terminal nodes beneath that node.", "sentence2": "in the absence of an objective difficulty measure, not only do subjective judgments lead to potential discrepancies between different individual evaluations made by teachers and/or test developers (Francois et al., 2014), but it also makes it impossible to gain insight into a large number of quantitative features that have an impact on the difficulty of a text, and on the cognitive load involved.", "label": "neutral"}
{"id": "test_3977", "sentence1": "relational databases as input formats.", "sentence2": "As for linguistic annotations, a comparable standard does not exist, but different community standards co-exist and/or compete with each other, see Ide et al. (2017) for annotations in general and Cimiano et al. (2020, p.61-122 and 197-212) for RDF-based data models in particular. ", "label": "neutral"}
{"id": "test_3978", "sentence1": "For RDF conversion of generic data into RDF, two prominent examples are the CSV2RDF and R2RML (Das et al., 2012) suites which focus on tabular formats resp.", "sentence2": "even after all resulting subgraphs have been processed and merged again, a significant amount of triples will be lost.", "label": "neutral"}
{"id": "test_3979", "sentence1": "Due to software issues we ended up with 186 WOz dialogues where we had both WOz participants' ratings and MTurkers' ratings.", "sentence2": "we also generated simulated dialogues between dialogue policies and simulated users and again asked MTurkers to rate them on the same aspects.", "label": "neutral"}
{"id": "test_3980", "sentence1": "Children with ASD prefer more limited social interaction compared to children without ASD, hence measurement of eye gaze as a screening tool may be an important contribution in this area (Vargas-Cuentas et al., 2017).", "sentence2": "another study presented an analysis of gaze aversion patterns distinguishing between positive and negative schizophrenia (Vail et al., 2017).", "label": "neutral"}
{"id": "test_3981", "sentence1": "In the current study, we combine these two functions where reference is part of the interaction.", "sentence2": "they did not address the integration of eye movements with speech.", "label": "neutral"}
{"id": "test_3982", "sentence1": "Due to the inclusion of the \"biographies\" section, the dynastic histories in the corpus contain not just purely historical data but also information on many aspects of everyday life in China, including family stories, where data on gender relations could be found.", "sentence2": "these terms could be called \"star terms\" because they are \"connected\" to most of the context terms, as well as between themselves (as shown later).", "label": "neutral"}
{"id": "test_3983", "sentence1": "One way of studying would be to create word vectors, based on counting words in a close context of a term and then comparing these vectors and establishing similarity between gender terms.", "sentence2": "this project introduces a new open-source corpus of twenty-four dynastic histories covered by Creative Commons license.", "label": "neutral"}
{"id": "test_3984", "sentence1": "It should be noted that it is not a comprehensive list of all such terms for every historical period.", "sentence2": "gender terms in Modern Chinese cannot form the immediate basis of investigation into a corpus of Classical Chinese because of language change.", "label": "neutral"}
{"id": "test_3985", "sentence1": "Note that all Sound Pattern of English (SPE)-style rules may be so encoded (Kaplan and Kay, 1994).", "sentence2": "in this paper, we take an informationtheoretic view of phonotactic complexity, and advocate for a measure that permits straightforward cross-linguistic comparison: bits per phoneme.", "label": "neutral"}
{"id": "test_3986", "sentence1": "First, we calculated the bitsper-phoneme for just the first three positions in the word, and then looked at the correlation between this word-onset bits per phoneme and the average (full) word length in phoneme segments.", "sentence2": "no other tonal languages were included in the corpus, so all reported results are over 106 languages.", "label": "neutral"}
{"id": "test_3987", "sentence1": "However, we are now in a position to exploit samples from p lex .", "sentence2": "in this study, we demonstrate that surprisal and related measures are not subject to the practical obstacles raised by Miestamo, independently of whichever class of complexity they fall into.", "label": "neutral"}
{"id": "test_3988", "sentence1": "QDMR is primarily inspired by SQL (Codd, 1970;Chamberlin and Boyce, 1974).", "sentence2": "better question understanding models should improve performance and generalization in tasks that require multi-step reasoning or that do not have access to substantial amounts of data.", "label": "neutral"}
{"id": "test_3989", "sentence1": "Instead, COPYNET opted to count both groups, then subtract the number of cylinders from the number of objects.", "sentence2": "a rule-based algorithm can map more than 93% of the annotations into a correct formal representation.", "label": "neutral"}
{"id": "test_3990", "sentence1": "Controllable Text Generation is an important problem in NLP that has received significant attention in recent times.", "sentence2": "rOUGE-based selection from the candidates favors paraphrases that have higher n-gram overlap with their respective source sentences, hence may capture source's meaning better.", "label": "neutral"}
{"id": "test_3991", "sentence1": "Exemplar-as-Output: Baseline where the output is the syntactic exemplar.", "sentence2": "table 3: Sample generations of the competitive models.", "label": "neutral"}
{"id": "test_3992", "sentence1": "We restricted validators to individuals currently located in the US who self-reported as native speakers of English.", "sentence2": "we see the shallowest slopes on phenomena with the worst performance: NPIS (0.0078) and ISLANDS (0.0036).", "label": "neutral"}
{"id": "test_3993", "sentence1": "We study how intervening material affects the LMs' sensitivity to mismatches in agreement in BLiMP.", "sentence2": "we consider frequent inclusion of a phenomenon in a syntax/semantics textbook as an informal proxy for what linguists consider to be core phenomena.", "label": "neutral"}
{"id": "test_3994", "sentence1": "9 Our benchmarks are exact reproducible in the sense that we provide the tables that record all model results (Section 3.3) and the code to run and evaluate our HPO algorithms (Section 6).", "sentence2": "GB_EIF_M: GB with Matern52 kernel and expected influence as acquisition function.", "label": "neutral"}
{"id": "test_3995", "sentence1": "In order to obtain reasonable results, such grammars need to be lexicalized because otherwise the independence assumptions of the PCFG are violated because of semantic relations, for example, between a verb and its subject.", "sentence2": "the start symbol will be anchored by the symbol that occurs most frequently as a whole sentence.", "label": "neutral"}
{"id": "test_3996", "sentence1": "He then uses this model to translate sentences in the in-probe and out-probe sets.", "sentence2": "bob can also add ''watermark sentences'' that have some distinguishable characteristics to influence the Alice model, making attack easier.", "label": "neutral"}
{"id": "test_3997", "sentence1": "To guard against these attacks, Alice\u2019s protection strategy may include random subsampling of training data or additional regularization terms.", "sentence2": "for Alice, we found that classifiers were almost always predicting in, resulting the accuracy to be around 50%.", "label": "neutral"}
{"id": "test_3998", "sentence1": "The additional classification task empowers our model to better capture the logicality in a story implicitly, namely, modeling the causal and temporal dependencies, inter-sentence coherence, and avoiding repetition.", "sentence2": "and we generated stories using a topk sampling scheme (Fan et al., 2018) with k = 40 and a softmax temperature of 0.7 (Goodfellow et al., 2016) to balance the trade-off between diversity and fluency.", "label": "neutral"}
{"id": "test_3999", "sentence1": "Some work has attempted to explicitly incorporate commonsense knowledge into language generation (Zhou et al., 2018;Guan et al., 2019;Yang et al., 2019b).", "sentence2": "to leverage commonsense knowledge in pretrained language models, we resort to existing large-scale knowledge bases ConceptNet (Li et al., 2016b) and AtOMIC .", "label": "neutral"}
