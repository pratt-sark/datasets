title,abstract,score,comment
Topical Coherence in LDA-based Models through Induced Segmentation,"This paper presents an LDA-based model that generates topically coherent segments within documents by jointly segmenting documents and assigning topics to their words. The coherence between topics is ensured through a copula, binding the topics associated to the words of a segment. In addition, this model relies on both document and segment specific topic distributions so as to capture fine grained differences in topic assignments. We show that the proposed model naturally encompasses other state-of-the-art LDA-based models designed for similar tasks. Furthermore, our experiments, conducted on six different publicly available datasets, show the effectiveness of our model in terms of perplexity, Normalized Pointwise Mutual Information, which captures the coherence between the generated topics, and the Micro F1 measure for text classification.","{'IMPACT': '3', 'SUBSTANCE': '4', 'APPROPRIATENESS': '4', 'MEANINGFUL_COMPARISON': '3', 'SOUNDNESS_CORRECTNESS': '3', 'ORIGINALITY': '3', 'CLARITY': '4'}","- Strengths:
1. The idea of assigning variable-length document segments with dependent
topics is novel. This prior knowledge is worth incorporated in the LDA-based
framework.
2. Whereas we do not have full knowledge on recent LDA literature, we find the
part of related work quite convincing.
3. The method proposed for segment sampling with O(M) complexity is impressive.
It is crucial for efficient computation. 

- Weaknesses:
1. Compared to Balikas COLING16's work, the paper has a weaker visualization
(Fig 5), which makes us doubt about the actual segmenting and assigning results
of document. It could be more convincing to give a longer exemplar and make
color assignment consistent with topics listed in Figure 4.
2. Since the model is more flexible than that of Balikas COLING16, it may be
underfitting, could you please explain this more?

- General Discussion:
The paper is well written and structured. The intuition introduced in the
Abstract and again exemplified in the Introduction is quite convincing. The
experiments are of a full range, solid, and achieves better quantitative
results against previous works. If the visualization part is stronger, or
explained why less powerful visualization, it will be more confident. Another
concern is about computation efficiency, since the seminal LDA work proposed to
use Variational Inference which is faster during training compared to MCMC, we
wish to see the authorâ€™s future development."
Topical Coherence in LDA-based Models through Induced Segmentation,"This paper presents an LDA-based model that generates topically coherent segments within documents by jointly segmenting documents and assigning topics to their words. The coherence between topics is ensured through a copula, binding the topics associated to the words of a segment. In addition, this model relies on both document and segment specific topic distributions so as to capture fine grained differences in topic assignments. We show that the proposed model naturally encompasses other state-of-the-art LDA-based models designed for similar tasks. Furthermore, our experiments, conducted on six different publicly available datasets, show the effectiveness of our model in terms of perplexity, Normalized Pointwise Mutual Information, which captures the coherence between the generated topics, and the Micro F1 measure for text classification.","{'IMPACT': '3', 'SUBSTANCE': '4', 'APPROPRIATENESS': '5', 'MEANINGFUL_COMPARISON': '3', 'SOUNDNESS_CORRECTNESS': '3', 'ORIGINALITY': '3', 'CLARITY': '4'}","### Strengths:
- Well-written, well-organized
- Incorporate topical segmentation to copula LDA to enable the joint learning
of segmentation and latent models
- Experimental setting is well-designed and show the superiority of the
proposed method from several different indicators and datasets

### Weaknesses:
- No comparison with ""novel"" segmentation methods

### General Discussion:
This paper presents segLDAcop, a joint latent model for topics and segments.
This model is based on the copula LDA and incorporates the topical segmentation
to the copula LDA. The authors conduct comprehensive experiments by using
several different datasets and evaluation metrics to show the superiority of
their model.

This paper is well-written and well-organized. The proposed model is a
reasonable extension of the copula LDA to enable the joint inference of
segmentations and topics. Experimental setting is carefully designed and the
superiority of the proposed model is fairly validated.
One concern is that the authors only use the simple NP segmentation and single
word segmentation as segments of the previous method. As noted in the paper,
there are many work to smartly generate segments before running LDA though it
is largely affected by the bias of statistical or linguistic tools used. The
comparison with more novel (state-of-the-art) segments would be preferable to
precisely show the validity of the proposed method.

### Minor comment
- In line 105, ""latent radom topics"" -> ""latent random topics"""
