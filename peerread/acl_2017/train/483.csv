title,abstract,score,comment
Here's My Point: Argumentation Mining with Pointer Networks,"Argumentation mining seeks to uncover the argument structure present in argumentative text. In order to determine this structure, one must understand how different individual components of the overall argument are linked. General consensus in this field dictates that the argument components form a hierarchy of persuasion, which manifests itself in a tree structure. This work provides the first neural network-based approach to argumentation mining, focusing on the dual tasks of extracting links between argument components, and classifying types of argument components. We propose to use a joint model based on a Pointer Network architecture to simultaneously solve these tasks. In doing so, we construct a joint model that simultaneously attempts to learn the type of argument component, as well as continuing to predict links between argument components. The proposed joint model achieves state-of-the-art results on two separate evaluation corpora, achieving far superior performance than a regular Pointer Network model. Our results show that optimizing for both tasks is crucial for high performance.","{'IMPACT': '3', 'SUBSTANCE': '4', 'APPROPRIATENESS': '5', 'MEANINGFUL_COMPARISON': '3', 'SOUNDNESS_CORRECTNESS': '5', 'ORIGINALITY': '5', 'CLARITY': '2'}","- Strengths:

This is the first neural network-based approach to argumentation
mining. The proposed method used a Pointer Network (PN) model with
multi-task learning and outperformed previous methods in the
experiments on two datasets.

- Weaknesses:

This is basically an application of PN to argumentation
mining. Although the combination of PN and multi-task learning for
this task is novel, its novelty is not enough for ACL long
publication. The lack of qualitative analysis and error analysis is
also a major concern.

- General Discussion:

Besides the weaknesses mentioned above, the use of PN is not
well-motivated. Although three characteristics of PN were described in
l.138-143, these are not a strong motivation against the use of
bi-directional LSTMs and the attention mechanism. The authors should
describe what problems are solved by PN and discuss in the experiments
how much these problems are solved.

Figures 2 and 3 are difficult to understand. What are the self link to
D1 and the links from D2 to E1 and D3/D4 to E2? These are just the
outputs from the decoder and not links. The decoder LSTM does not have
an input from e_j in these figures, but it does in Equation (3). Also,
in Figure 3, the abbreviation ""FC"" is not defined.

Equation (8) is strange. To calculate the probability of each
component type, the probability of E_i is calculated.

In the experiments, I did not understand why only ""PN"", which is not a
joint model, was performed for the microtext corpus.

It is not clear whether the BLSTM model is trained with the joint-task
objective.

There are some studies on discourse parsing using the attention
mechanism. The authors should describe the differences from these studies.

Minor issues:

l.128: should related -> should be related

l.215: (2015) is floating

l.706: it able -> it is able

I raised my recommendation score after reading the convincing author responses.
I strongly recommend that the authors should discuss improved examples by PN as
well as the details of feature ablation."
Here's My Point: Argumentation Mining with Pointer Networks,"Argumentation mining seeks to uncover the argument structure present in argumentative text. In order to determine this structure, one must understand how different individual components of the overall argument are linked. General consensus in this field dictates that the argument components form a hierarchy of persuasion, which manifests itself in a tree structure. This work provides the first neural network-based approach to argumentation mining, focusing on the dual tasks of extracting links between argument components, and classifying types of argument components. We propose to use a joint model based on a Pointer Network architecture to simultaneously solve these tasks. In doing so, we construct a joint model that simultaneously attempts to learn the type of argument component, as well as continuing to predict links between argument components. The proposed joint model achieves state-of-the-art results on two separate evaluation corpora, achieving far superior performance than a regular Pointer Network model. Our results show that optimizing for both tasks is crucial for high performance.","{'IMPACT': '3', 'SUBSTANCE': '4', 'APPROPRIATENESS': '5', 'MEANINGFUL_COMPARISON': '3', 'SOUNDNESS_CORRECTNESS': '5', 'ORIGINALITY': '5', 'CLARITY': '3'}","The paper presents an application of Pointer Networks, a recurrent neural
network model original used for solving algorithmic tasks, to two subtasks of
Argumentation Mining: determining the types of Argument Components, and finding
the links between them. The model achieves state-of-the-art results.

Strengths:

- Thorough review of prior art in the specific formulation of argument mining
handled in this paper.
- Simple and effective modification of an existing model to make it suitable
for
the task. The model is mostly explained clearly.
- Strong results as compared to prior art in this task.

Weaknesses:

- 071: This formulation of argumentation mining is just one of several proposed
subtask divisions, and this should be mentioned. For example, in [1], claims
are detected and classified before any supporting evidence is detected.
Furthermore, [2] applied neural networks to this task, so it is inaccurate to
say (as is claimed in the abstract of this paper) that this work is the first
NN-based approach to argumentation mining.
- Two things must be improved in the presentation of the model: (1) What is the
pooling method used for embedding features (line 397)? and (2) Equation (7) in
line 472 is not clear enough: is E_i the random variable representing the
*type* of AC i, or its *identity*? Both are supposedly modeled (the latter by
feature representation), and need to be defined. Furthermore, it seems like the
LHS of equation (7) should be a conditional probability.
- There are several unclear things about Table 2: first, why are the three
first
baselines evaluated only by macro f1 and the individual f1 scores are missing?
This is not explained in the text. Second, why is only the ""PN"" model
presented? Is this the same PN as in Table 1, or actually the Joint Model? What
about the other three?
- It is not mentioned which dataset the experiment described in Table 4 was
performed on.

General Discussion:

- 132: There has to be a lengthier introduction to pointer networks, mentioning
recurrent neural networks in general, for the benefit of readers unfamiliar
with ""sequence-to-sequence models"". Also, the citation of Sutskever et al.
(2014) in line 145 should be at the first mention of the term, and the
difference with respect to recursive neural networks should be explained before
the paragraph starting in line 233 (tree structure etc.).
- 348: The elu activation requires an explanation and citation (still not
enough
well-known).
- 501: ""MC"", ""Cl"" and ""Pr"" should be explained in the label.
- 577: A sentence about how these hyperparameters were obtained would be
appropriate.
- 590: The decision to do early stopping only by link prediction accuracy
should
be explained (i.e. why not average with type accuracy, for example?).
- 594: Inference at test time is briefly explained, but would benefit from more
details.
- 617: Specify what the length of an AC is measured in (words?).
- 644: The referent of ""these"" in ""Neither of these"" is unclear.
- 684: ""Minimum"" should be ""Maximum"".
- 694: The performance w.r.t. the amount of training data is indeed surprising,
but other models have also achieved almost the same results - this is
especially surprising because NNs usually need more data. It would be good to
say this.
- 745: This could alternatively show that structural cues are less important
for
this task.
- Some minor typos should be corrected (e.g. ""which is show"", line 161).

[1] Rinott, Ruty, et al. ""Show Me Your Evidence-an Automatic Method for Context
Dependent Evidence Detection."" EMNLP. 2015.

[2] Laha, Anirban, and Vikas Raykar. ""An Empirical Evaluation of various Deep
Learning Architectures for Bi-Sequence Classification Tasks."" COLING. 2016."
