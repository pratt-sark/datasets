title,abstract,comment,score
On the Quantitative Analysis of Decoder-Based Generative Models,"The past several years have seen remarkable progress in generative models which produce convincing samples of images and other modalities. A shared component of some popular models such as generative adversarial networks and generative moment matching networks, is a decoder network, a parametric deep neural net that defines a generative distribution. Unfortunately, it can be difficult to quantify the performance of these models because of the intractability of log-likelihood estimation, and inspecting samples can be misleading. We propose to use Annealed Importance Sampling for evaluating log-likelihoods for decoder-based models and validate its accuracy using bidirectional Monte Carlo. Using this technique, we analyze the performance of decoder-based models, the effectiveness of existing log-likelihood estimators, the degree of overfitting, and the degree to which these models miss important modes of the data distribution.","# Review
This paper proposes a quantitative evaluation for decoder-based generative models that use Annealed Importance Sampling (AIS) to estimate log-likelihoods. Quantitative evaluations are indeed much needed since for some models, like Generative Adversarial Networks (GANs) and Generative Moment Matching Networks (GMMNs), qualitative evaluation of samples is still frequently used to assess their generative capability. Even though, there exist quantitative evaluations like Kernel Density Estimation (KDE), the authors show how AIS is more accurate than KDE and how it can be used to perform fine-grained comparison between generative models (GAN, GMMs and Variational Autoencoders (VAE)).

The authors report empirical results comparing two different decoder architectures that were both trained, on the continuous MNIST dataset, using the VAE, GAN and GMMN objectives. They also trained an Importance Weighted Autoencoder (IWAE) on binarized MNIST and show that, in this case, the IWAE bound underestimates the true log-likelihoods by at least 1 nat (which is significant for this dataset) according to the AIS evaluation of the same model.


# Pros
Their evaluation framework is public and is definitely a nice contribution to the community.

This paper gives some insights about how GAN behaves from log-likelihood perspective. The authors disconfirm the commonly proposed hypothesis that GAN are memorizing training data. The authors also observed that GANs miss important modes of the data distribution.


# Cons/Questions
It is not clear for me why sometimes the experiments were done using different number of examples (100, 1000, 10000) coming from different sources (trainset, validset, testset or simulation/generated by the model). For instance, in Table 2 why results were not reported using all 10,000 examples of the testing set?

It is not clear why in Figure 2c, AIS is slower than AIS+encoder? Is the number of intermediate distributions the same in both?

16 independent chains for AIS seems a bit low from what I saw in the literature (e.g. in [Salakhutdinov & Murray, 2008] or [Desjardins etal., 2011], they used 100 chains). Could it be that increasing the number of chains helps tighten the confidence interval reported in Table 2?

I would have like the authors to give their intuitions as to why GAN50 has a BDMC gap of 10 nats, i.e. 1 order of magnitude compared to the others?


# Minor comments
Table 1 is not referenced in the text and lacks description of what the different columns represent.
Figure 2(a), are the reported values represents the average log-likelihood of 100 (each or total?) training and validation examples of MNIST (as described in Section 5.3.2).
Figure 2(c), I'm guessing it is on binarized MNIST? Also, why are there fewer points for AIS compared to IWAE and AIS+encoder?
Are the BDMC gaps mentioned in Section 5.3.1 the same as the ones reported in Table2 ?
Typo in caption of Figure 3: ""(c) GMMN-10"" but actually showing GMMN-50 according to the graph title and subcaption.","{'SUBSTANCE': 4, 'ORIGINALITY': 3}"
On the Quantitative Analysis of Decoder-Based Generative Models,"The past several years have seen remarkable progress in generative models which produce convincing samples of images and other modalities. A shared component of some popular models such as generative adversarial networks and generative moment matching networks, is a decoder network, a parametric deep neural net that defines a generative distribution. Unfortunately, it can be difficult to quantify the performance of these models because of the intractability of log-likelihood estimation, and inspecting samples can be misleading. We propose to use Annealed Importance Sampling for evaluating log-likelihoods for decoder-based models and validate its accuracy using bidirectional Monte Carlo. Using this technique, we analyze the performance of decoder-based models, the effectiveness of existing log-likelihood estimators, the degree of overfitting, and the degree to which these models miss important modes of the data distribution.","The paper describes a method to evaluate generative models such as VAE, GAN and GMMN. This is very much needed in our community where we still eyeball generated images to judge the quality of a model. However, the technical increment over the NIPS 16 paper: “Measuring the reliability of MCMC inference with bidirectional Monte Carlo” is very small, or nonexistent (but please correct me if I am wrong!).  (Grosse et al). The relative contribution of this paper is the application of this method to generative models. 
In section 2.3 the authors seem to make a mistake. They write E[p’(x)] <= p(x) but I think they mean: E[log p’(x)] <= log E[p’(x)] = log p(x). Also,  for what value of x? If p(x) is normalized it can’t be true for all values of x. Anyways, I think there are typos here and there and the equations could be more precise.
On page 5 top of the page it is said that the AIS procedure can be initialized with q(z|x) instead of p(z). However, it is unclear what value of x is then picked? Is it perhaps Ep(x)[q(z|x)] ?
I am confused with the use of the term overfitting (p8 bottom). Does a model A overfit relative to a another model B if the test accuracy of A is higher than that of B even though the gap between train and test accuracy is also higher for B than for A. I think not. Perhaps the last sentence on page 8 should say that VAE-50 underfits less than GMMN-50?
The experimental results are interesting in that it exposes the fact that GANs and GMMNs seem to have much lover test accuracy than VAE despite the fact that their samples look great. 
",{'SUBSTANCE': 4}
On the Quantitative Analysis of Decoder-Based Generative Models,"The past several years have seen remarkable progress in generative models which produce convincing samples of images and other modalities. A shared component of some popular models such as generative adversarial networks and generative moment matching networks, is a decoder network, a parametric deep neural net that defines a generative distribution. Unfortunately, it can be difficult to quantify the performance of these models because of the intractability of log-likelihood estimation, and inspecting samples can be misleading. We propose to use Annealed Importance Sampling for evaluating log-likelihoods for decoder-based models and validate its accuracy using bidirectional Monte Carlo. Using this technique, we analyze the performance of decoder-based models, the effectiveness of existing log-likelihood estimators, the degree of overfitting, and the degree to which these models miss important modes of the data distribution.",,"{'SUBSTANCE': 4, 'ORIGINALITY': 3}"
On the Quantitative Analysis of Decoder-Based Generative Models,"The past several years have seen remarkable progress in generative models which produce convincing samples of images and other modalities. A shared component of some popular models such as generative adversarial networks and generative moment matching networks, is a decoder network, a parametric deep neural net that defines a generative distribution. Unfortunately, it can be difficult to quantify the performance of these models because of the intractability of log-likelihood estimation, and inspecting samples can be misleading. We propose to use Annealed Importance Sampling for evaluating log-likelihoods for decoder-based models and validate its accuracy using bidirectional Monte Carlo. Using this technique, we analyze the performance of decoder-based models, the effectiveness of existing log-likelihood estimators, the degree of overfitting, and the degree to which these models miss important modes of the data distribution.","# Review
This paper proposes a quantitative evaluation for decoder-based generative models that use Annealed Importance Sampling (AIS) to estimate log-likelihoods. Quantitative evaluations are indeed much needed since for some models, like Generative Adversarial Networks (GANs) and Generative Moment Matching Networks (GMMNs), qualitative evaluation of samples is still frequently used to assess their generative capability. Even though, there exist quantitative evaluations like Kernel Density Estimation (KDE), the authors show how AIS is more accurate than KDE and how it can be used to perform fine-grained comparison between generative models (GAN, GMMs and Variational Autoencoders (VAE)).

The authors report empirical results comparing two different decoder architectures that were both trained, on the continuous MNIST dataset, using the VAE, GAN and GMMN objectives. They also trained an Importance Weighted Autoencoder (IWAE) on binarized MNIST and show that, in this case, the IWAE bound underestimates the true log-likelihoods by at least 1 nat (which is significant for this dataset) according to the AIS evaluation of the same model.


# Pros
Their evaluation framework is public and is definitely a nice contribution to the community.

This paper gives some insights about how GAN behaves from log-likelihood perspective. The authors disconfirm the commonly proposed hypothesis that GAN are memorizing training data. The authors also observed that GANs miss important modes of the data distribution.


# Cons/Questions
It is not clear for me why sometimes the experiments were done using different number of examples (100, 1000, 10000) coming from different sources (trainset, validset, testset or simulation/generated by the model). For instance, in Table 2 why results were not reported using all 10,000 examples of the testing set?

It is not clear why in Figure 2c, AIS is slower than AIS+encoder? Is the number of intermediate distributions the same in both?

16 independent chains for AIS seems a bit low from what I saw in the literature (e.g. in [Salakhutdinov & Murray, 2008] or [Desjardins etal., 2011], they used 100 chains). Could it be that increasing the number of chains helps tighten the confidence interval reported in Table 2?

I would have like the authors to give their intuitions as to why GAN50 has a BDMC gap of 10 nats, i.e. 1 order of magnitude compared to the others?


# Minor comments
Table 1 is not referenced in the text and lacks description of what the different columns represent.
Figure 2(a), are the reported values represents the average log-likelihood of 100 (each or total?) training and validation examples of MNIST (as described in Section 5.3.2).
Figure 2(c), I'm guessing it is on binarized MNIST? Also, why are there fewer points for AIS compared to IWAE and AIS+encoder?
Are the BDMC gaps mentioned in Section 5.3.1 the same as the ones reported in Table2 ?
Typo in caption of Figure 3: ""(c) GMMN-10"" but actually showing GMMN-50 according to the graph title and subcaption.","{'SUBSTANCE': 4, 'ORIGINALITY': 3}"
On the Quantitative Analysis of Decoder-Based Generative Models,"The past several years have seen remarkable progress in generative models which produce convincing samples of images and other modalities. A shared component of some popular models such as generative adversarial networks and generative moment matching networks, is a decoder network, a parametric deep neural net that defines a generative distribution. Unfortunately, it can be difficult to quantify the performance of these models because of the intractability of log-likelihood estimation, and inspecting samples can be misleading. We propose to use Annealed Importance Sampling for evaluating log-likelihoods for decoder-based models and validate its accuracy using bidirectional Monte Carlo. Using this technique, we analyze the performance of decoder-based models, the effectiveness of existing log-likelihood estimators, the degree of overfitting, and the degree to which these models miss important modes of the data distribution.","The paper describes a method to evaluate generative models such as VAE, GAN and GMMN. This is very much needed in our community where we still eyeball generated images to judge the quality of a model. However, the technical increment over the NIPS 16 paper: “Measuring the reliability of MCMC inference with bidirectional Monte Carlo” is very small, or nonexistent (but please correct me if I am wrong!).  (Grosse et al). The relative contribution of this paper is the application of this method to generative models. 
In section 2.3 the authors seem to make a mistake. They write E[p’(x)] <= p(x) but I think they mean: E[log p’(x)] <= log E[p’(x)] = log p(x). Also,  for what value of x? If p(x) is normalized it can’t be true for all values of x. Anyways, I think there are typos here and there and the equations could be more precise.
On page 5 top of the page it is said that the AIS procedure can be initialized with q(z|x) instead of p(z). However, it is unclear what value of x is then picked? Is it perhaps Ep(x)[q(z|x)] ?
I am confused with the use of the term overfitting (p8 bottom). Does a model A overfit relative to a another model B if the test accuracy of A is higher than that of B even though the gap between train and test accuracy is also higher for B than for A. I think not. Perhaps the last sentence on page 8 should say that VAE-50 underfits less than GMMN-50?
The experimental results are interesting in that it exposes the fact that GANs and GMMNs seem to have much lover test accuracy than VAE despite the fact that their samples look great. 
",{'SUBSTANCE': 4}
On the Quantitative Analysis of Decoder-Based Generative Models,"The past several years have seen remarkable progress in generative models which produce convincing samples of images and other modalities. A shared component of some popular models such as generative adversarial networks and generative moment matching networks, is a decoder network, a parametric deep neural net that defines a generative distribution. Unfortunately, it can be difficult to quantify the performance of these models because of the intractability of log-likelihood estimation, and inspecting samples can be misleading. We propose to use Annealed Importance Sampling for evaluating log-likelihoods for decoder-based models and validate its accuracy using bidirectional Monte Carlo. Using this technique, we analyze the performance of decoder-based models, the effectiveness of existing log-likelihood estimators, the degree of overfitting, and the degree to which these models miss important modes of the data distribution.",,"{'SUBSTANCE': 4, 'ORIGINALITY': 3}"
