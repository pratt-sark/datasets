title,abstract,comment,score
Learning to Generate Samples from Noise through Infusion Training,"In this work, we investigate a novel training procedure to learn a generative model as the transition operator of a Markov chain, such that, when applied repeatedly on an unstructured random noise sample, it will denoise it into a sample that matches the target distribution from the training set. The novel training procedure to learn this progressive denoising operation involves sampling from a slightly different chain than the model chain used for generation in the absence of a denoising target. In the training chain we infuse information from the training target example that we would like the chains to reach with a high probability. The thus learned transition operator is able to produce quality and varied samples in a small number of steps. Experiments show competitive results compared to the samples generated with a basic Generative Adversarial Net.","This paper trains a generative model which transforms noise into model samples by a gradual denoising process. It is similar to a generative model based on diffusion. Unlike the diffusion approach:
- It uses only a small number of denoising steps, and is thus far more computationally efficient.
- Rather than consisting of a reverse trajectory, the conditional chain for the approximate posterior jumps to q(z(0) | x), and then runs in the same direction as the generative model. This allows the inference chain to behave like a perturbation around the generative model, that pulls it towards the data. (This also seems somewhat related to ladder networks.)
- There is no tractable variational bound on the log likelihood.

I liked the idea, and found the visual sample quality given a short chain impressive. The inpainting results were particularly nice, since one shot inpainting is not possible under most generative modeling frameworks. It would be much more convincing to have a log likelihood comparison that doesn't depend on Parzen likelihoods.

Detailed comments follow:

Sec. 2:
""theta(0) the"" -> ""theta(0) be the""
""theta(t) the"" -> ""theta(t) be the""
""what we will be using"" -> ""which we will be doing""
I like that you infer q(z^0|x), and then run inference in the same order as the generative chain. This reminds me slightly of ladder networks.
""q*. Having learned"" -> ""q*. [paragraph break] Having learned""
Sec 3.3:
""learn to inverse"" -> ""learn to reverse""
Sec. 4:
""For each experiments"" -> ""For each experiment""
How sensitive are your results to infusion rate?
Sec. 5: ""appears to provide more accurate models"" I don't think you showed this -- there's no direct comparison to the Sohl-Dickstein paper.
Fig 4. -- neat!
","{'IMPACT': 4, 'SUBSTANCE': 3, 'APPROPRIATENESS': 3, 'SOUNDNESS_CORRECTNESS': 5}"
Learning to Generate Samples from Noise through Infusion Training,"In this work, we investigate a novel training procedure to learn a generative model as the transition operator of a Markov chain, such that, when applied repeatedly on an unstructured random noise sample, it will denoise it into a sample that matches the target distribution from the training set. The novel training procedure to learn this progressive denoising operation involves sampling from a slightly different chain than the model chain used for generation in the absence of a denoising target. In the training chain we infuse information from the training target example that we would like the chains to reach with a high probability. The thus learned transition operator is able to produce quality and varied samples in a small number of steps. Experiments show competitive results compared to the samples generated with a basic Generative Adversarial Net.","Summary:
This paper introduces a heuristic approach for training a deep directed generative model, where similar to the transition operator of a Markov chain each layer samples from the same conditional distribution. Similar to optimizing a variational lower bound, the approach is to approximate the gradient by replacing the posterior over latents with an alternative distribution. However, the approximating distribution is not updated to improve the lower bound but heuristically constructed in each step. A further difference to variational optimization is that the conditional distributions are optimized greedily rather than following the gradient of the joint log-likelihood.

Review:
The proposed approach is interesting and to me seems worth exploring more. Given that there are approaches for training the same class of models which are 1) theoretically more sound, 2) of similar computational complexity, and 3) work well in practice (e.g. Rezende & Mohamed, 2015), I am nevertheless not sure of its potential to generate impact. My bigger concern, however, is that the empirical evaluation is still quite limited.

I appreciate the authors included proper estimates of the log-likelihood. This will enable and encourage future comparisons with this method on continuous MNIST. However, the authors should point out that the numbers taken from Wu et al. (2016) are not representative of the performance of a VAE. (From the paper: “Therefore, the log-likelihood values we report should not be compared directly against networks which have a more flexible observation model.” “Such observation models can easily achieve much higher log-likelihood scores, […].”)

Comparisons with inpainting results using other methods would have been nice. How practical is the proposed approach compared to other approaches? Similar to the diffusion approach by Sohl-Dickstein et al. (2015), the proposed approach seems to be both efficient and effective for inpainting. Not making this a bigger point and performing the proper evaluations seems like a missed opportunity.

Minor:
– I am missing citations for “ordered visible dimension sampling”
– Typos and frequent incorrect use of \citet and \citep","{'SUBSTANCE': 4, 'ORIGINALITY': 4}"
Learning to Generate Samples from Noise through Infusion Training,"In this work, we investigate a novel training procedure to learn a generative model as the transition operator of a Markov chain, such that, when applied repeatedly on an unstructured random noise sample, it will denoise it into a sample that matches the target distribution from the training set. The novel training procedure to learn this progressive denoising operation involves sampling from a slightly different chain than the model chain used for generation in the absence of a denoising target. In the training chain we infuse information from the training target example that we would like the chains to reach with a high probability. The thus learned transition operator is able to produce quality and varied samples in a small number of steps. Experiments show competitive results compared to the samples generated with a basic Generative Adversarial Net.",,"{'SUBSTANCE': 4, 'ORIGINALITY': 4}"
Learning to Generate Samples from Noise through Infusion Training,"In this work, we investigate a novel training procedure to learn a generative model as the transition operator of a Markov chain, such that, when applied repeatedly on an unstructured random noise sample, it will denoise it into a sample that matches the target distribution from the training set. The novel training procedure to learn this progressive denoising operation involves sampling from a slightly different chain than the model chain used for generation in the absence of a denoising target. In the training chain we infuse information from the training target example that we would like the chains to reach with a high probability. The thus learned transition operator is able to produce quality and varied samples in a small number of steps. Experiments show competitive results compared to the samples generated with a basic Generative Adversarial Net.",,"{'IMPACT': 4, 'SUBSTANCE': 3, 'APPROPRIATENESS': 3, 'SOUNDNESS_CORRECTNESS': 5}"
Learning to Generate Samples from Noise through Infusion Training,"In this work, we investigate a novel training procedure to learn a generative model as the transition operator of a Markov chain, such that, when applied repeatedly on an unstructured random noise sample, it will denoise it into a sample that matches the target distribution from the training set. The novel training procedure to learn this progressive denoising operation involves sampling from a slightly different chain than the model chain used for generation in the absence of a denoising target. In the training chain we infuse information from the training target example that we would like the chains to reach with a high probability. The thus learned transition operator is able to produce quality and varied samples in a small number of steps. Experiments show competitive results compared to the samples generated with a basic Generative Adversarial Net.","This paper trains a generative model which transforms noise into model samples by a gradual denoising process. It is similar to a generative model based on diffusion. Unlike the diffusion approach:
- It uses only a small number of denoising steps, and is thus far more computationally efficient.
- Rather than consisting of a reverse trajectory, the conditional chain for the approximate posterior jumps to q(z(0) | x), and then runs in the same direction as the generative model. This allows the inference chain to behave like a perturbation around the generative model, that pulls it towards the data. (This also seems somewhat related to ladder networks.)
- There is no tractable variational bound on the log likelihood.

I liked the idea, and found the visual sample quality given a short chain impressive. The inpainting results were particularly nice, since one shot inpainting is not possible under most generative modeling frameworks. It would be much more convincing to have a log likelihood comparison that doesn't depend on Parzen likelihoods.

Detailed comments follow:

Sec. 2:
""theta(0) the"" -> ""theta(0) be the""
""theta(t) the"" -> ""theta(t) be the""
""what we will be using"" -> ""which we will be doing""
I like that you infer q(z^0|x), and then run inference in the same order as the generative chain. This reminds me slightly of ladder networks.
""q*. Having learned"" -> ""q*. [paragraph break] Having learned""
Sec 3.3:
""learn to inverse"" -> ""learn to reverse""
Sec. 4:
""For each experiments"" -> ""For each experiment""
How sensitive are your results to infusion rate?
Sec. 5: ""appears to provide more accurate models"" I don't think you showed this -- there's no direct comparison to the Sohl-Dickstein paper.
Fig 4. -- neat!
","{'IMPACT': 4, 'SUBSTANCE': 3, 'APPROPRIATENESS': 3, 'SOUNDNESS_CORRECTNESS': 5}"
Learning to Generate Samples from Noise through Infusion Training,"In this work, we investigate a novel training procedure to learn a generative model as the transition operator of a Markov chain, such that, when applied repeatedly on an unstructured random noise sample, it will denoise it into a sample that matches the target distribution from the training set. The novel training procedure to learn this progressive denoising operation involves sampling from a slightly different chain than the model chain used for generation in the absence of a denoising target. In the training chain we infuse information from the training target example that we would like the chains to reach with a high probability. The thus learned transition operator is able to produce quality and varied samples in a small number of steps. Experiments show competitive results compared to the samples generated with a basic Generative Adversarial Net.","Summary:
This paper introduces a heuristic approach for training a deep directed generative model, where similar to the transition operator of a Markov chain each layer samples from the same conditional distribution. Similar to optimizing a variational lower bound, the approach is to approximate the gradient by replacing the posterior over latents with an alternative distribution. However, the approximating distribution is not updated to improve the lower bound but heuristically constructed in each step. A further difference to variational optimization is that the conditional distributions are optimized greedily rather than following the gradient of the joint log-likelihood.

Review:
The proposed approach is interesting and to me seems worth exploring more. Given that there are approaches for training the same class of models which are 1) theoretically more sound, 2) of similar computational complexity, and 3) work well in practice (e.g. Rezende & Mohamed, 2015), I am nevertheless not sure of its potential to generate impact. My bigger concern, however, is that the empirical evaluation is still quite limited.

I appreciate the authors included proper estimates of the log-likelihood. This will enable and encourage future comparisons with this method on continuous MNIST. However, the authors should point out that the numbers taken from Wu et al. (2016) are not representative of the performance of a VAE. (From the paper: “Therefore, the log-likelihood values we report should not be compared directly against networks which have a more flexible observation model.” “Such observation models can easily achieve much higher log-likelihood scores, […].”)

Comparisons with inpainting results using other methods would have been nice. How practical is the proposed approach compared to other approaches? Similar to the diffusion approach by Sohl-Dickstein et al. (2015), the proposed approach seems to be both efficient and effective for inpainting. Not making this a bigger point and performing the proper evaluations seems like a missed opportunity.

Minor:
– I am missing citations for “ordered visible dimension sampling”
– Typos and frequent incorrect use of \citet and \citep","{'SUBSTANCE': 4, 'ORIGINALITY': 4}"
Learning to Generate Samples from Noise through Infusion Training,"In this work, we investigate a novel training procedure to learn a generative model as the transition operator of a Markov chain, such that, when applied repeatedly on an unstructured random noise sample, it will denoise it into a sample that matches the target distribution from the training set. The novel training procedure to learn this progressive denoising operation involves sampling from a slightly different chain than the model chain used for generation in the absence of a denoising target. In the training chain we infuse information from the training target example that we would like the chains to reach with a high probability. The thus learned transition operator is able to produce quality and varied samples in a small number of steps. Experiments show competitive results compared to the samples generated with a basic Generative Adversarial Net.",,"{'SUBSTANCE': 4, 'ORIGINALITY': 4}"
Learning to Generate Samples from Noise through Infusion Training,"In this work, we investigate a novel training procedure to learn a generative model as the transition operator of a Markov chain, such that, when applied repeatedly on an unstructured random noise sample, it will denoise it into a sample that matches the target distribution from the training set. The novel training procedure to learn this progressive denoising operation involves sampling from a slightly different chain than the model chain used for generation in the absence of a denoising target. In the training chain we infuse information from the training target example that we would like the chains to reach with a high probability. The thus learned transition operator is able to produce quality and varied samples in a small number of steps. Experiments show competitive results compared to the samples generated with a basic Generative Adversarial Net.",,"{'IMPACT': 4, 'SUBSTANCE': 3, 'APPROPRIATENESS': 3, 'SOUNDNESS_CORRECTNESS': 5}"
